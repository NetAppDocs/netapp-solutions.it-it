<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="summary"></block>
  <block id="97b39392e3b66691f26174f9392c96d0" category="doc">NVA-1143: NetApp HCI - controlli di sicurezza NIST per FISMA con HyTrust per infrastruttura multi-tenant - progettazione e implementazione NVA</block>
  <block id="2de6bbd06654b0c6d7bd5a6f2bb218f8" category="paragraph">Arvind Ramakrishnan, Abhinav Singh, NetApp</block>
  <block id="6fdf0a62913845390e552b0f7d42cbf7" category="paragraph">NVA-1143 descrive come NetApp HCI può essere progettato e implementato per soddisfare i controlli di sicurezza e privacy dell'Istituto nazionale di standard e tecnologia (NIST) SP 800-53 Revisione 4, che sono fondamentali per le infrastrutture di cloud privato e le implementazioni multi-tenant.</block>
  <block id="86e20b04ba1f19de7a30d7843155e285" category="paragraph"><block ref="86e20b04ba1f19de7a30d7843155e285" category="inline-link-macro-rx"></block></block>
  <block id="5e8c99d8eb1f9fde413c715abb6fa392" category="doc">TR-4320: NetApp e-Series e CommVault Data Platform V11 - architettura di riferimento e Best practice per lo storage</block>
  <block id="23b69f42a62554346d10d302e32866df" category="paragraph">Akash Gupta, NetApp Grish Chanchlani, CommVault</block>
  <block id="451f1cdad20049e4046b157a54826db1" category="paragraph">TR-4320 illustra l'architettura di riferimento e le Best practice per l'utilizzo dello storage NetApp e-Series in un ambiente CommVault Data Platform V11. CommVault e NetApp hanno sviluppato congiuntamente questa architettura di riferimento per fornire una guida per le implementazioni di CommVault Data Platform V11 con lo storage NetApp e-Series che accelereranno il time-to-application per questa soluzione.</block>
  <block id="b5132c157b5da84909699e1aad5ea13d" category="inline-link-macro">TR-4320: NetApp e-Series e CommVault Data Platform V11 - architettura di riferimento e Best practice per lo storage</block>
  <block id="65c8e697e97b6ce1bd59d8334eaaab6f" category="paragraph"><block ref="65c8e697e97b6ce1bd59d8334eaaab6f" category="inline-link-macro-rx"></block></block>
  <block id="849bdf40e7fa0e2cab1cb845682e6f56" category="doc">TR-4471: Architettura di riferimento e Best practice per lo storage e-Series ed EF-Series con Veeam Backup &amp; Replication 9.5</block>
  <block id="febdd047851001456a2f0c683cfcfd2b" category="paragraph">Akash Gupta, NetApp Shawn Lieu (Americhe), Stefan Renner (EMEA) e Michael Cade (Performance), Veeam</block>
  <block id="3bad2cd66e539f0136fbf484133914dd" category="paragraph">TR-4471 illustra l'architettura di riferimento e le Best practice per l'utilizzo dello storage NetApp e-Series in un ambiente Veeeam Backup &amp; Replication 9.5.</block>
  <block id="f86686bed105d7053fbb06167a05f38e" category="inline-link-macro">TR-4471: Architettura di riferimento e Best practice di storage e-Series ed EF-Series con Veeam Backup &amp;amp; Replication 9.5</block>
  <block id="8a9473d2b45da95a2d08524f5b182c4d" category="paragraph"><block ref="30941a222a593c860776bbf0831d36d0" category="inline-link-macro-rx"></block></block>
  <block id="f0a30c2a34036665913459cc735f4786" category="doc">TR-4704: Implementazione di Veritas NetBackup con lo storage NetApp e-Series</block>
  <block id="d223d0d947999082ea93b57a68b3614b" category="paragraph">Akash Gupta e Principled Technologies, NetApp</block>
  <block id="9c993f8d3d3aa7be9c86474635154c12" category="paragraph">TR-4704 descrive l'implementazione di Veritas NetBackup su storage NetApp e-Series.</block>
  <block id="7ff53b7713dd7f38a4729f8a1a48f24e" category="paragraph"><block ref="7ff53b7713dd7f38a4729f8a1a48f24e" category="inline-link-macro-rx"></block></block>
  <block id="b278438874f41a76068d02368e65aa3e" category="doc">A proposito di questo repository</block>
  <block id="404af48e0cb5f84306fbd93fac2ff8be" category="paragraph">Breve introduzione al repository delle soluzioni NetApp: Dove trovare soluzioni specifiche e come utilizzare questo repository.</block>
  <block id="45ac6b09a3b8f5ea07ca656ca8dea987" category="section-title">Navigazione del repository</block>
  <block id="c28e40ef527e43509a0fcd3b114ff824" category="paragraph">La navigazione del repository è gestita dalla barra laterale principale, che viene visualizzata sul lato sinistro della pagina. Le soluzioni sono classificate in aree tecniche di livello superiore definite come "tower tecnologici" per le soluzioni NetApp.</block>
  <block id="e9982e506e30915713c7485a2e77633b" category="section-title">Panoramica delle Technology Towers</block>
  <block id="d67372be0bd12a2ddbcf795ccfacc7de" category="cell">*Sezione*</block>
  <block id="f14c276c07197ebef1394a5a219087a1" category="cell">*Descrizione*</block>
  <block id="e6bec38fe69985a0817e3c0b2b3a0c20" category="cell">*Landing page dei contenuti*</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="cell">Intelligenza artificiale</block>
  <block id="b1dc18184f115680e9fe3b64295c4678" category="cell">Raccolta di soluzioni basate su ai. La landing page ai offre contenuti più diffusi presentati in "tessere" specifici per i contenuti.</block>
  <block id="e68818392f0eda6e918ccb9e7537e282" category="inline-link-macro">Contenuti ai</block>
  <block id="748eaad82fcc3f281aebd8c5467a4d91" category="cell"><block ref="748eaad82fcc3f281aebd8c5467a4d91" category="inline-link-macro-rx"></block></block>
  <block id="b0ac6120dada9135114784db22a59940" category="cell">Analisi dei dati moderna</block>
  <block id="53840db4921094507c6397fb6ee31d58" category="cell">Raccolta di moderne soluzioni di analisi dei dati (ad esempio Splunk SmartStore, Apache Spark, ecc.). La landing page di Modern Data Analytics offre i contenuti più diffusi presentati in "riquadri" specifici del contenuto.</block>
  <block id="1b1956b226e3085af9e004e60ce183b4" category="inline-link-macro">Contenuti moderni di Data Analytics</block>
  <block id="16321f09e6ea361ef5515d5939fa73f1" category="cell"><block ref="16321f09e6ea361ef5515d5939fa73f1" category="inline-link-macro-rx"></block></block>
  <block id="27f04e57a2bba90c65656f5f47785def" category="cell">Multicloud ibrido con VMware</block>
  <block id="24fef7dbaeab186ae1ddf8a1fa31ef68" category="cell">Definisce NetApp in un modello multicloud ibrido, incluse le opzioni VMware nel cloud pubblico e NetApp Storage in ciascuno degli hyperscaler. La landing page ibrida del Multibloud offre contenuti molto diffusi presentati in "tessere" specifici per i contenuti.</block>
  <block id="91ef1e01c1592f4e80d47d11c68ddf5c" category="inline-link-macro">Multicloud ibrido con contenuti VMware</block>
  <block id="356bcf8558d9911b876554df23345496" category="cell"><block ref="356bcf8558d9911b876554df23345496" category="inline-link-macro-rx"></block></block>
  <block id="ea4c55be196897a16d86999f5c16d582" category="cell">Virtualizzazione</block>
  <block id="87867e178542e6ed3cf6ea885807d4f1" category="cell">Raccolta di soluzioni principali per la virtualizzazione, inclusa la virtualizzazione dei desktop. La landing page della virtualizzazione offre contenuti molto diffusi, presentati in "tessere" specifici del contenuto.</block>
  <block id="5654a75155b39867a9f4372fcc292bab" category="inline-link-macro">Contenuti per la virtualizzazione</block>
  <block id="82e9b7248dcd1a1ae85e7fa485bf1f4b" category="cell"><block ref="82e9b7248dcd1a1ae85e7fa485bf1f4b" category="inline-link-macro-rx"></block></block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="cell">Container</block>
  <block id="24a8e607718680e8d1dd293b9d736add" category="cell">Raccolta di soluzioni basate su container. La landing page della virtualizzazione offre contenuti molto diffusi, presentati in "tessere" specifici del contenuto.</block>
  <block id="afb6dbef1b44c7f79b8883cae5cc3b30" category="inline-link-macro">Contenuto dei container</block>
  <block id="d76e9a2c09fc047c91b6cb4c2f340644" category="cell"><block ref="d76e9a2c09fc047c91b6cb4c2f340644" category="inline-link-macro-rx"></block></block>
  <block id="0cf49f958731e4b4c23d4b04f0802ba0" category="cell">Applicazioni e database di business</block>
  <block id="73c685140b2461529432f6e9628ef281" category="cell">Raccolta di applicazioni aziendali e soluzioni di database. La landing page di SAP e SAP HANA offre contenuti molto diffusi e presentati in "tessere" specifici del contenuto. In questa sezione vengono trattate anche le soluzioni di database Oracle e SQL Server.</block>
  <block id="ef0bea1a6ce6e68dd3ebae18ea2de71f" category="inline-link-macro">Contenuti SAP e SAP HANA</block>
  <block id="589c17157183d6295af608cccff7c8da" category="cell"><block ref="589c17157183d6295af608cccff7c8da" category="inline-link-macro-rx"></block></block>
  <block id="5d7b876a73a9025080fbf6dd921d1fdd" category="cell">Migrazione dei dati e protezione dei dati</block>
  <block id="d7339a230985e723af5d49a6470f4fc8" category="cell">Raccolta di soluzioni per la migrazione dei dati, la protezione dei dati e la sicurezza dei dati.</block>
  <block id="408649df4ac74ae19e47eef7d060c5cb" category="cell">Automazione della soluzione</block>
  <block id="d83d094e8e3ce7450bf099061814d148" category="cell">Panoramica sull'automazione della soluzione con Red Hat Ansible.</block>
  <block id="6174d88cc7c0409df3e035a5c9d089cb" category="section-title">Registro delle modifiche</block>
  <block id="a0067ab2420cbaebc335efc5c2433c45" category="inline-link-macro">registro delle modifiche</block>
  <block id="9e2a9bc8a2f8e27bba893554318c300a" category="paragraph">Tutte le principali modifiche apportate al repository (nuove soluzioni, aggiornamenti importanti, nuovi video/demo, ecc.) vengono registrate in <block ref="62716531525ec9f2f5022745ce51b3a4" category="inline-link-macro-rx"></block>.</block>
  <block id="bea4c2c8eb82d05891ddd71584881b56" category="section-title">Feedback</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link-macro">questo link</block>
  <block id="fb6b632cdd61e02434568081cbbf0fae" category="paragraph">Utilizzare <block ref="a5f81f398e43efd62a061a201309bfa7" category="inline-link-macro-rx"></block> per richiedere modifiche al contenuto o fornire un feedback sul contenuto. Ti chiediamo di essere il più specifico possibile per assicurarti che il tuo feedback sia indirizzato in modo appropriato.</block>
  <block id="2093983846bbd6cd7e3d486531259f7d" category="summary">Questa pagina descrive le funzionalità del cloud ibrido disponibili per ONTAP e VMware vSphere.</block>
  <block id="df94231e8c7a2b7372365ba3eb8ad621" category="doc">Cloud ibrido con ONTAP e vSphere</block>
  <block id="c689fcb3c54ae34ac006a005e03aad07" category="section-title">Informazioni sul cloud ibrido</block>
  <block id="cc81a55aaf5bd2bdf603a2aea92a875a" category="paragraph">Sia che si tratti di un cloud privato on-premise, di un'infrastruttura di cloud pubblico o di un cloud ibrido che combina il meglio di entrambi, le soluzioni ONTAP ti aiutano a costruire il tuo data fabric per ottimizzare e ottimizzare la gestione dei dati. Inizia con sistemi all-flash dalle performance elevate, quindi accoppiali con sistemi di storage su disco o cloud per la protezione dei dati e il cloud computing.</block>
  <block id="9afb01441ce427bb3863eaccd46b9b5d" category="paragraph">Scegli tra cloud Azure, AWS, IBM o Google per ottimizzare i costi ed evitare il lock-in. Sfrutta il supporto avanzato per le tecnologie OpenStack e container in base alle esigenze.</block>
  <block id="8a61dac106bf2a7f3b869c8ff58c4ce5" category="paragraph">La protezione dei dati è spesso la prima cosa che i clienti provano quando iniziano il loro percorso nel cloud. La protezione può essere semplice come la replica asincrona dei dati chiave o complessa come un sito di backup a caldo completo. La protezione dei dati si basa principalmente sulla tecnologia NetApp SnapMirror.</block>
  <block id="d059ff0a497ad1427248dbb8f770b1d5" category="paragraph">Alcuni clienti scelgono di spostare interi workload nel cloud. Questo può essere più complicato che utilizzare il cloud solo per la protezione dei dati, ma ONTAP rende più semplice lo spostamento perché non è necessario riscrivere le applicazioni per utilizzare lo storage basato sul cloud. ONTAP nel cloud funziona come fa on-premise ONTAP. Il sistema ONTAP on-premise offre funzionalità di efficienza dei dati che consentono di memorizzare più dati in meno spazio fisico e di eseguire il tiering dei dati utilizzati raramente per ridurre i costi dello storage. Che tu utilizzi una configurazione di cloud ibrido o sposti un intero workload nel cloud, ONTAP massimizza le performance e l'efficienza dello storage.</block>
  <block id="ad622d292f56f20b32a61fe1b8bd2f56" category="paragraph">NetApp offre inoltre backup basato sul cloud (SnapMirror Cloud, Cloud Backup Service e Cloud Sync) e tool di archiviazione e tiering dello storage (FabricPool) per ONTAP per ridurre le spese operative e sfruttare l'ampia portata del cloud.</block>
  <block id="49c437176039e1c910728eac1f332689" category="paragraph">La figura seguente fornisce un esempio di caso di utilizzo del cloud ibrido.</block>
  <block id="e61ead4102c89a9758572df81301a1d2" category="inline-image-macro">Cloud ibrido</block>
  <block id="9188eeccf6b5386d9573cea87cf05102" category="paragraph"><block ref="9188eeccf6b5386d9573cea87cf05102" category="inline-image-macro-rx" type="image"></block></block>
  <block id="293f510d2162f186910d817d97121159" category="inline-link">ONTAP e il cloud</block>
  <block id="3963100a9d31ca50911a23ac5c87aca1" category="admonition">Per ulteriori informazioni su ONTAP e i cloud ibridi, vedere<block ref="92883b1d8840f28e1ad4810811bf56b5" category="inline-link-rx"></block> Nel centro di documentazione di ONTAP 9.</block>
  <block id="334af7a3f788d83aa889d1ca7bd769f5" category="summary">In questa pagina vengono descritte le efficienze dello storage ONTAP.</block>
  <block id="c13f924c3ceac59a16a8a1ea96d43c91" category="doc">Efficienze dello storage ONTAP</block>
  <block id="241a4f0482dfad2f5fc79419b18356c0" category="section-title">Sulle efficienze dello storage</block>
  <block id="185081022bfbcfda8db4798eb4eed8c0" category="paragraph">Sebbene NetApp sia stata la prima azienda a offrire la deduplica per i workload di produzione, questa innovazione non è stata la prima o l'ultima in quest'area. È iniziato con le copie Snapshot di ONTAP, un meccanismo di protezione dei dati efficiente in termini di spazio senza alcun effetto sulle performance, insieme alla tecnologia FlexClone per eseguire istantaneamente copie in lettura/scrittura delle macchine virtuali per la produzione e l'utilizzo del backup. NetApp ha continuato a offrire funzionalità inline, tra cui deduplica, compressione e deduplica a blocchi zero, per eliminare il maggior numero di storage dai costosi SSD. Più di recente, ONTAP ha aggiunto la compattazione per rafforzare l'efficienza dello storage.</block>
  <block id="d019495551b4899a9019567122f1e076" category="list-text">*Deduplica inline a blocchi zero.* elimina lo spreco di spazio da parte di blocchi completamente zero.</block>
  <block id="7634d08ecc5702f74271a3313502ec02" category="list-text">*Compressione inline.* comprime i blocchi di dati per ridurre la quantità di storage fisico richiesta.</block>
  <block id="8b7bb53489bfc2a6808c1d76314fa0d4" category="list-text">*Deduplica inline.* Elimina i blocchi in entrata con i blocchi esistenti sul disco.</block>
  <block id="b762ae2f528b0eca55e7be3f599e909d" category="list-text">*Inline data compaction.* impacchi operazioni i/o e file più piccoli in ogni blocco fisico.</block>
  <block id="fba6442665875d123719f22baafc619d" category="inline-image-macro">Efficienza dello storage</block>
  <block id="f468c00b41afc3485647008dcf80cba1" category="paragraph"><block ref="f468c00b41afc3485647008dcf80cba1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8405ea940cfeab85adddf9d3ed915a97" category="paragraph">È possibile eseguire la deduplica, la compressione dei dati e la compattazione dei dati insieme o in modo indipendente per ottenere risparmi di spazio ottimali su un volume FlexVol. La combinazione di queste funzionalità ha consentito ai clienti di ottenere risparmi fino a 5:1 per VSI e fino a 30:1 per VDI.</block>
  <block id="b8c11cd315128247329c3d878c2143fe" category="inline-link">Utilizzo di deduplica, compressione dei dati e compattazione dei dati per aumentare l'efficienza dello storage</block>
  <block id="65bbb718266195d68e8d1accfc443e28" category="admonition">Per ulteriori informazioni sull'efficienza dello storage ONTAP, vedere<block ref="f358a7faf94e9f579d11f8fc4efdbdec" category="inline-link-rx"></block> Nel centro di documentazione di ONTAP 9.</block>
  <block id="d4f43ea12f3f521c93fb3dd4d93c428d" category="summary">In questa pagina viene illustrata la procedura per l'implementazione di uno storage NVMe/FC NetApp ONTAP per datastore VMFS in un ambiente VMware vSphere.</block>
  <block id="9e433440cdaf3b61716784200e8abf6d" category="doc">Archivio dati vSphere VMFS - NVMe/FC con ONTAP</block>
  <block id="bbe48fb854ea022537208eeeff822f91" category="section-title">A proposito di questa attività</block>
  <block id="9367f3df6c8d54eba1da3cd9c5fa2776" category="paragraph">In questa sezione viene descritta la creazione di un datastore VMFS con storage ONTAP utilizzando NVMe/FC.</block>
  <block id="1563a554e82b055714efd37bc6d1fdd6" category="paragraph">Per il provisioning automatizzato, utilizzare uno dei seguenti script: <block ref="a45ba722ee80832fb205d0588df91e01" category="inline-xref-macro-rx"></block>, <block ref="d9559d06f0afa5b213d78afb48b783e7" category="inline-xref-macro-rx"></block>, o. <block ref="e5e7d2f44064f3bfeddfdbea251f7835" category="inline-xref-macro-rx"></block>.</block>
  <block id="6ac65708de8f04eeb173ca99f3eb19fa" category="section-title">Di cosa hai bisogno</block>
  <block id="6af0e7a38739ed6e2658342101a7b51e" category="list-text">Competenze di base necessarie per gestire un ambiente vSphere e ONTAP.</block>
  <block id="7890464cdce93f078097395e27132775" category="inline-link-macro">Comprensione di base di NVMe/FC</block>
  <block id="c6e7cd589502f52a9398e779ede56d14" category="list-text"><block ref="62a43aa3bd2eb01e27a6091d3017311c" category="inline-link-macro-rx"></block>.</block>
  <block id="5422bc00db54a341b2c538f4cea614c0" category="list-text">Un sistema storage ONTAP (FAS/AFF/CVO/ONTAP Select/ASA) con {ontap_version}</block>
  <block id="fdb8f60c37b623874df816146436f56b" category="list-text">Credenziali ONTAP (nome SVM, ID utente e password)</block>
  <block id="2ec64af43682ffa45eeaf33a86950347" category="list-text">WWPN ONTAP per informazioni su host, destinazione, SVM e LUN</block>
  <block id="62eadfe081f86e1f9a72988a4feb7bfc" category="inline-link-macro">Un foglio di lavoro di configurazione FC completo</block>
  <block id="f186921a73873df63dc496b515bc2099" category="list-text"><block ref="f186921a73873df63dc496b515bc2099" category="inline-link-macro-rx"></block></block>
  <block id="c4436d4a190778b7ec1e9461f6454bdd" category="list-text">Server vCenter</block>
  <block id="5fd6c6da49bc906cc217c5aff2041a52" category="list-text">Informazioni sugli host vSphere ({vsphere_version})</block>
  <block id="63fc76a195a29345d466bc86f293ca14" category="list-text">Switch fabric</block>
  <block id="60ce38e4967c52c316eff771b7a3c4ec" category="list-text">Con porte dati ONTAP FC e host vSphere collegati.</block>
  <block id="32086766e64ae646fcadddc3e16b203b" category="list-text">Con la funzione NPIV (N_Port ID Virtualization) attivata.</block>
  <block id="b6e0bd021536c90aa87cfea18d73d453" category="list-text">Creare una singola zona di destinazione dell'iniziatore.</block>
  <block id="df7f994fb0c494b66708667a64b2c406" category="list-text">Creare una zona per ciascun iniziatore (singola zona iniziatore).</block>
  <block id="f386e9f209710f55d41a97e9502d1c7c" category="list-text">Per ciascuna zona, includere una destinazione che sia l'interfaccia logica FC ONTAP (WWPN) per le SVM. Devono essere presenti almeno due interfacce logiche per nodo per SVM. Non utilizzare la WWPN delle porte fisiche.</block>
  <block id="71d4977f0fd6be92644e1ff9f8096637" category="section-title">Provisioning del datastore VMFS</block>
  <block id="c9dd6bad4c7d561872f2e2d498a990bf" category="inline-link">Tool di matrice di interoperabilità (IMT)</block>
  <block id="a9df884192a193f56d8208439b4d1fca" category="list-text">Verificare la compatibilità con<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block>.</block>
  <block id="f42c50210dcc0a3a69c8258256e75e4b" category="inline-link-macro">Verificare che la configurazione NVMe/FC sia supportata.</block>
  <block id="5312bcc81ee6d7bce6549b2089c9d1ac" category="list-text"><block ref="5312bcc81ee6d7bce6549b2089c9d1ac" category="inline-link-macro-rx"></block></block>
  <block id="cfa5eceb5ac37d5ebd3af6f265d9ce4c" category="section-title">Attività di ONTAP</block>
  <block id="1a04100ec801e5e2d1708d89eb1159b6" category="inline-link-macro">Verificare la licenza ONTAP per FCP.</block>
  <block id="9d17f91ad987b7e7cf2fa7249cd97343" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block>Utilizzare<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> E verificare se NVMe_of è elencato. Utilizzare<block ref="b7dcb36bf321df4a59507f6e4d0e13fb" prefix=" " category="inline-code"></block> per aggiungere una licenza.</block>
  <block id="7193bed15c5b4f7c80f1f19630b57e1e" category="list-text">Verificare che il protocollo NVMe sia attivato sulla SVM.</block>
  <block id="5eabd2d7390fc49cb61f882324bdcac0" category="inline-link-macro">Configurare le SVM per NVMe.</block>
  <block id="3838b8ad26ea53cc8ddea76f2a58b20a" category="list-text"><block ref="3838b8ad26ea53cc8ddea76f2a58b20a" category="inline-link-macro-rx"></block></block>
  <block id="f2fd2de931ce484e947c89ae8207346a" category="list-text">Verificare che le interfacce logiche NVMe/FC siano disponibili sulle SVM.</block>
  <block id="aa01379022dd5b86e18f436c76f651f5" category="list-text">Utilizzare<block ref="e38d07be71f760e81ec7c17103cd57db" prefix=" " category="inline-code"></block> Per verificare l'adattatore FCP.</block>
  <block id="978583cfbb47e2700c599c43b7949a53" category="list-text">Quando si crea una SVM con la GUI, le interfacce logiche fanno parte di tale processo.</block>
  <block id="3866119a70b69102c1584c0baa386190" category="list-text">Per rinominare l'interfaccia di rete, utilizzare il comando<block ref="976ec076dd60d4d6296585d0275e7fbc" prefix=" " category="inline-code"></block>.</block>
  <block id="6ad7e9002145710745843d16314895e3" category="inline-link-macro">Creare lo spazio dei nomi e il sottosistema NVMe</block>
  <block id="06badf30aa173febc3374aceef25c5ce" category="list-text"><block ref="06badf30aa173febc3374aceef25c5ce" category="inline-link-macro-rx"></block></block>
  <block id="722a3f8fc9c281f41b6ca7a69ca15ec0" category="section-title">Attività di VMware vSphere</block>
  <block id="7407e0a15262132133381a890e36e47a" category="inline-link-macro">Informazioni sull'adattatore di storage</block>
  <block id="c6613394adcc7526a48f6e92b61ee067" category="list-text">Verificare che i driver HBA siano installati. Gli HBA supportati da VMware dispongono di driver implementati e devono essere visibili all'indirizzo <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block></block>
  <block id="9761a89a99469e468e71b7a0087be29d" category="inline-link-macro">Eseguire l'installazione del driver vSphere host NVMe e le attività di convalida</block>
  <block id="926e4d89379d3dde2510965ca53771af" category="list-text"><block ref="926e4d89379d3dde2510965ca53771af" category="inline-link-macro-rx"></block></block>
  <block id="e229fd9b7b8948ddebf276bda8a9145e" category="inline-link-macro">Crea datastore VMFS</block>
  <block id="3dbbea9263919f89335d7ba053f09a39" category="list-text"><block ref="3dbbea9263919f89335d7ba053f09a39" category="inline-link-macro-rx"></block></block>
  <block id="cb4afc4348edbcbc0ddb144315301438" category="summary">Scopri di più sulle soluzioni di virtualizzazione FlexPod consultando le guide alla progettazione di FlexPod.</block>
  <block id="4de89e2522c54dd93e1f7435cd5845e9" category="doc">Soluzioni di virtualizzazione desktop FlexPod</block>
  <block id="99f9c871e415b6401535b222011ec217" category="inline-link-macro">Guide alla progettazione di FlexPod</block>
  <block id="2de05ca96bfd006d0687e6e5b3edfcad" category="paragraph">Per ulteriori informazioni sulle soluzioni di virtualizzazione FlexPod, consulta la <block ref="7464c5c011fed90b6d391ce107d84818" category="inline-link-macro-rx"></block></block>
  <block id="3b2287aeb862e195f44c02694fff89fe" category="summary">SnapCenter consente di creare policy di backup che possono essere applicate a più processi. Questi criteri possono definire pianificazione, conservazione, replica e altre funzionalità. Continuano a consentire la selezione opzionale di snapshot coerenti con le macchine virtuali, che sfrutta la capacità dell'hypervisor di interrompere l'i/o prima di acquisire uno snapshot VMware.</block>
  <block id="b1c93d491ba776d955eb2e3b90908fb9" category="doc">Altre funzionalità per vSphere</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="section-title">Protezione dei dati</block>
  <block id="343775d7b18c4ca0af9b7fad57690839" category="paragraph">Il backup delle macchine virtuali e il loro rapido ripristino sono tra i grandi punti di forza di ONTAP per vSphere ed è facile gestirla all'interno di vCenter con il plug-in SnapCenter per VMware vSphere. Utilizza le copie Snapshot per creare copie rapide della tua macchina virtuale o del datastore senza influire sulle performance, quindi inviale a un sistema secondario utilizzando SnapMirror per una protezione dei dati off-site a lungo termine. Questo approccio riduce al minimo lo spazio di storage e la larghezza di banda della rete memorizzando solo le informazioni modificate.</block>
  <block id="0aef2da721f0ab14676f8d6ffb9e7e8c" category="inline-link">consigliato</block>
  <block id="8cc688149346249b3a92e59282755f3e" category="paragraph">SnapCenter consente di creare policy di backup che possono essere applicate a più processi. Questi criteri possono definire pianificazione, conservazione, replica e altre funzionalità. Continuano a consentire la selezione opzionale di snapshot coerenti con le macchine virtuali, che sfrutta la capacità dell'hypervisor di interrompere l'i/o prima di acquisire uno snapshot VMware. Tuttavia, a causa dell'effetto delle performance delle snapshot VMware, in genere non sono consigliate, a meno che non sia necessario interrompere il file system guest. Utilizzare invece le copie Snapshot di ONTAP per la protezione generale e strumenti applicativi come i plug-in di SnapCenter per proteggere i dati transazionali come SQL Server o Oracle. Queste copie Snapshot sono diverse dalle snapshot VMware (coerenza) e sono adatte per una protezione a lungo termine. Le snapshot VMware sono solo<block ref="75f5ad475d959e2ecb55267e1a9a54f1" category="inline-link-rx"></block> per uso a breve termine a causa delle performance e di altri effetti.</block>
  <block id="26aae91a7d92b32a60b1fbc86c29ee81" category="paragraph">Questi plug-in offrono funzionalità estese per proteggere i database in ambienti fisici e virtuali. Con vSphere, è possibile utilizzarli per proteggere i database SQL Server o Oracle in cui i dati vengono memorizzati su LUN RDM, LUN iSCSI direttamente connessi al sistema operativo guest o file VMDK su datastore VMFS o NFS. I plug-in consentono di specificare diversi tipi di backup del database, supportando backup online o offline e proteggendo i file di database insieme ai file di log. Oltre al backup e al ripristino, i plug-in supportano anche la clonazione dei database a scopo di sviluppo o test.</block>
  <block id="1556ba0bf6ea4783cda0ff40e96f0265" category="paragraph">La figura seguente mostra un esempio di implementazione di SnapCenter.</block>
  <block id="341d84aa26cb4521474864e04ea2a63b" category="inline-image-macro">Errore: Immagine grafica mancante</block>
  <block id="54ee9d8cd5db70a761321f3e7d168445" category="paragraph"><block ref="54ee9d8cd5db70a761321f3e7d168445" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c1bef29e8dc34a00e17b06c221d5efe" category="paragraph">Per funzionalità avanzate di disaster recovery, è consigliabile utilizzare NetApp SRA per ONTAP con VMware Site Recovery Manager. Oltre al supporto per la replica di datastore in un sito di DR, consente anche test senza interruzioni nell'ambiente di DR mediante il cloning dei datastore replicati. Anche il ripristino da un disastro e la riconprotezione della produzione dopo la risoluzione dell'interruzione sono semplificabili grazie all'automazione integrata in SRA.</block>
  <block id="650062685b0df8284f1b87f62fa3f9f3" category="inline-link">TR-4128</block>
  <block id="886a3fd32ec402d87ea2b090f8f701b2" category="paragraph">Infine, per ottenere il massimo livello di protezione dei dati, prendere in considerazione una configurazione vMSC (Metro Storage Cluster) di VMware vSphere che utilizza NetApp MetroCluster. VMSC è una soluzione certificata da VMware che combina la replica sincrona con il clustering basato su array, offrendo gli stessi vantaggi di un cluster ad alta disponibilità ma distribuito su siti separati per la protezione dai disastri del sito. NetApp MetroCluster offre configurazioni convenienti per la replica sincrona con ripristino trasparente da qualsiasi guasto a un singolo componente dello storage e ripristino a comando singolo in caso di disastro del sito. VMSC è descritto in maggiore dettaglio nella<block ref="737e6eedc4568d5bb72c6a6cf1fe681a" category="inline-link-rx"></block>.</block>
  <block id="752d71c042ef775879f6db705ccf6b31" category="section-title">Bonifica dello spazio</block>
  <block id="d490382851fbc5bd6720046bf9bc0c03" category="paragraph">Lo spazio può essere recuperato per altri utilizzi quando le macchine virtuali vengono eliminate da un datastore. Quando si utilizzano datastore NFS, lo spazio viene recuperato immediatamente quando una macchina virtuale viene eliminata (naturalmente, questo approccio ha senso solo quando il volume è thin provisioning, cioè la garanzia del volume è impostata su nessuno). Tuttavia, quando i file vengono cancellati all'interno del sistema operativo guest della macchina virtuale, lo spazio non viene recuperato automaticamente con un datastore NFS. Per gli archivi di dati VMFS basati su LUN, ESXi e il sistema operativo guest possono emettere primitive VAAI UNMAP allo storage (anche in questo caso, quando si utilizza il thin provisioning) per recuperare spazio. A seconda della release, questo supporto è manuale o automatico.</block>
  <block id="6a2bff0a8d10ca0fc6c782e7978f696a" category="inline-link">2057513</block>
  <block id="8927aab76c49d1deb0b407fd261d5aa6" category="inline-link">Storage Space Reclamation (ricostruzione dello spazio di storage)</block>
  <block id="9e925e9341b490bfd3b4c4ca3b0c1ef2" category="inline-link">questo</block>
  <block id="953fa9bc59561d97ed62ce854465ba35" category="paragraph">In vSphere 5.5 e versioni successive<block ref="6f8212383775d45bd700d7b24be4f64e" prefix=" " category="inline-code"></block> il comando viene sostituito da<block ref="d92a762ce0274ace04ac012fc760e989" prefix=" " category="inline-code"></block> Command, che specifica il numero di blocchi liberi (vedere VMware KB<block ref="1d61bd4e8925f7d5aac61e083b728439" category="inline-link-rx"></block> per ulteriori informazioni). In vSphere 6.5 e versioni successive, quando si utilizza VMFS 6, lo spazio deve essere recuperato automaticamente in modo asincrono (vedere<block ref="a9ae15a1c91a14939aefb313015202e6" category="inline-link-rx"></block> Nella documentazione di vSphere), ma può essere eseguito anche manualmente, se necessario. Questa funzione automatica è supportata da ONTAP e i tool ONTAP per VMware vSphere la impostano su una priorità bassa. Tenere presente che, quando si effettua il provisioning di un LUN per l'utilizzo come datastore VMFS, è necessario attivare manualmente l'opzione di allocazione dello spazio sul LUN. Quando si utilizzano i tool ONTAP per VMware vSphere, il LUN viene configurato automaticamente per supportare la richiesta di rimborso dello spazio e non sono necessarie ulteriori azioni. Vedere<block ref="fca823934ad533ca13947daa01d8e441" category="inline-link-rx"></block> articolo della knowledge base per ulteriori dettagli.</block>
  <block id="99a66df20e19a8e18fae37a7f714750a" category="section-title">Clonazione di VM e datastore</block>
  <block id="d355cf5d1a16095124a54902f7cf49db" category="paragraph">La clonazione di un oggetto storage consente di creare rapidamente copie da utilizzare ulteriormente, ad esempio il provisioning di macchine virtuali aggiuntive, operazioni di backup/recovery e così via. In vSphere, è possibile clonare una macchina virtuale, un disco virtuale, un vVol o un datastore. Dopo essere stato clonato, l'oggetto può essere ulteriormente personalizzato, spesso attraverso un processo automatizzato. VSphere supporta entrambi i cloni di copia completa e i cloni collegati, in cui tiene traccia delle modifiche separatamente dall'oggetto originale.</block>
  <block id="78f8f8d69825dfe8e6085151fa565f28" category="paragraph">I cloni collegati sono ideali per risparmiare spazio, ma aumentano la quantità di i/o che vSphere gestisce per la macchina virtuale, influenzando le performance di quella macchina virtuale e forse dell'host in generale. Ecco perché i clienti NetApp utilizzano spesso cloni basati su sistemi di storage per ottenere il meglio da entrambi i mondi: Utilizzo efficiente dello storage e performance migliorate.</block>
  <block id="17e1a153b5d05c5a642c93ba9ce3c6de" category="paragraph">La seguente figura illustra la clonazione ONTAP.</block>
  <block id="8ee3cd3dba25fb32f1bc38cb528ac998" category="paragraph"><block ref="8ee3cd3dba25fb32f1bc38cb528ac998" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ee7355875ad5e9f56186ff7da961f6" category="paragraph">La clonazione può essere scaricata su sistemi che eseguono il software ONTAP attraverso diversi meccanismi, in genere a livello di VM, vVol o datastore. Questi includono quanto segue:</block>
  <block id="3b6d066ffdecb2beb542ef68e773d4ae" category="list-text">VVol che utilizzano le API di NetApp vSphere per il provider di consapevolezza dello storage (VASA). I cloni ONTAP vengono utilizzati per supportare le copie Snapshot vVol gestite da vCenter che sono efficienti in termini di spazio con un minimo effetto i/o per crearle ed eliminarle. Le VM possono anche essere clonate utilizzando vCenter e vengono anche trasferite in ONTAP, sia all'interno di un singolo datastore/volume che tra datastore/volumi.</block>
  <block id="059e5a6b7f963e9876ba0129dc1b667d" category="list-text">Clonazione e migrazione di vSphere con API vSphere – integrazione array (VAAI). Le operazioni di cloning delle macchine virtuali possono essere trasferite su ONTAP in ambienti SAN e NAS (NetApp fornisce un plug-in ESXi per abilitare VAAI per NFS). VSphere scarica solo le operazioni su macchine virtuali fredde (spente) in un datastore NAS, mentre le operazioni su macchine virtuali hot (cloning e storage vMotion) vengono anche scaricate per LA SAN. ONTAP utilizza l'approccio più efficiente in base all'origine, alla destinazione e alle licenze dei prodotti installate. Questa funzionalità viene utilizzata anche da VMware Horizon View.</block>
  <block id="a603c207c7b5801942ff108502676c12" category="list-text">SRA (utilizzato con VMware Site Recovery Manager). In questo caso, i cloni vengono utilizzati per testare il ripristino della replica DR senza interruzioni.</block>
  <block id="bb300d356d258c084dbe5da2ca367e08" category="list-text">Backup e recovery con strumenti NetApp come SnapCenter. I cloni delle macchine virtuali vengono utilizzati per verificare le operazioni di backup e per montare un backup delle macchine virtuali in modo che i singoli file possano essere copiati.</block>
  <block id="524b5b8bc03312baeafbea86df667c4b" category="paragraph">La clonazione offload di ONTAP può essere invocata da VMware, NetApp e da strumenti di terze parti. I cloni che vengono scaricati su ONTAP presentano diversi vantaggi. Nella maggior parte dei casi, sono efficienti in termini di spazio e richiedono storage solo per le modifiche all'oggetto; non vi sono effetti aggiuntivi sulle performance per la lettura e la scrittura e in alcuni casi le performance sono migliorate grazie alla condivisione dei blocchi nelle cache ad alta velocità. Inoltre, consentono di trasferire cicli CPU e i/o di rete dal server ESXi. L'offload delle copie all'interno di un datastore tradizionale utilizzando un volume FlexVol può essere rapido ed efficiente con FlexClone concesso in licenza, ma le copie tra volumi FlexVol potrebbero essere più lente. Se si mantengono i modelli di macchine virtuali come origine dei cloni, è consigliabile posizionarli all'interno del volume datastore (utilizzare cartelle o librerie di contenuti per organizzarli) per cloni veloci ed efficienti in termini di spazio.</block>
  <block id="f3968368501d882b3969da59138db6e2" category="paragraph">È inoltre possibile clonare un volume o un LUN direttamente in ONTAP per clonare un datastore. Con gli archivi di dati NFS, la tecnologia FlexClone può clonare un intero volume e il clone può essere esportato da ONTAP e montato da ESXi come altro archivio di dati. Per gli archivi di dati VMFS, ONTAP può clonare un LUN all'interno di un volume o di un intero volume, inclusi uno o più LUN. Un LUN contenente un VMFS deve essere mappato a un gruppo di iniziatori ESXi (igroup) e quindi rassegnato da ESXi per essere montato e utilizzato come datastore regolare. Per alcuni casi di utilizzo temporaneo, è possibile montare un VMFS clonato senza disdire. Dopo aver clonato un datastore, è possibile registrare, riconfigurare e personalizzare le macchine virtuali all'interno dell'IT come se fossero macchine virtuali clonate singolarmente.</block>
  <block id="1c12a8dd266e356901d22c0b7711369d" category="paragraph">In alcuni casi, è possibile utilizzare funzionalità aggiuntive con licenza per migliorare la clonazione, ad esempio SnapRestore per il backup o FlexClone. Queste licenze sono spesso incluse nei bundle di licenze senza costi aggiuntivi. È necessaria una licenza FlexClone per le operazioni di cloning vVol e per supportare le copie Snapshot gestite di un vVol (che vengono trasferite dall'hypervisor a ONTAP). Una licenza FlexClone può anche migliorare alcuni cloni basati su VAAI se utilizzati all'interno di un datastore/volume (crea copie istantanee ed efficienti in termini di spazio invece di copie a blocchi). Viene inoltre utilizzato dall'SRA per il test del ripristino di una replica DR e da SnapCenter per le operazioni di clonazione e per sfogliare le copie di backup per ripristinare singoli file.</block>
  <block id="6d30b2619de7fa18e965516b291a1937" category="section-title">Efficienza dello storage e thin provisioning</block>
  <block id="616c027f14ee5f1bbc866171c4017141" category="paragraph">NetApp ha guidato il settore con innovazioni per l'efficienza dello storage, come la prima deduplica per i workload primari e la compattazione dei dati inline, che migliora la compressione e memorizza file di piccole dimensioni e i/o in modo efficiente. ONTAP supporta la deduplica in linea e in background, nonché la compressione inline e in background.</block>
  <block id="8f105eeb6dc3fc4ce0d4758aeab4a256" category="paragraph">La figura seguente mostra l'effetto combinato delle funzionalità di efficienza dello storage di ONTAP.</block>
  <block id="4b7a9b58ab55917c054d5a636481a8b8" category="paragraph"><block ref="4b7a9b58ab55917c054d5a636481a8b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e89f9787f44321e33f85595321efc66" category="paragraph">Ecco alcuni consigli sull'utilizzo dell'efficienza dello storage ONTAP in un ambiente vSphere:</block>
  <block id="c2eea4e122397fa75d749bdbdcd4302d" category="list-text">La quantità di risparmi ottenuti con la deduplica dei dati si basa sulla compatibilità dei dati. Con ONTAP 9.1 e versioni precedenti, la deduplica dei dati funzionava a livello di volume, ma con la deduplica aggregata in ONTAP 9.2 e versioni successive, i dati vengono deduplica in tutti i volumi in un aggregato sui sistemi AFF. Non è più necessario raggruppare sistemi operativi simili e applicazioni simili in un singolo datastore per massimizzare i risparmi.</block>
  <block id="59eb554aa77d0e4dfdc304b3b914dd76" category="list-text">Per sfruttare i vantaggi della deduplica in un ambiente a blocchi, è necessario eseguire il thin provisioning delle LUN. Sebbene il LUN sia ancora visto dall'amministratore della macchina virtuale come la capacità fornita, i risparmi della deduplica vengono restituiti al volume per essere utilizzati per altre esigenze. NetApp consiglia di implementare questi LUN in volumi FlexVol anche con thin provisioning (gli strumenti ONTAP per VMware vSphere dimensionano il volume di circa il 5% più grande rispetto al LUN).</block>
  <block id="1e84230a4e75abc233d64344b14fd511" category="list-text">Anche il thin provisioning è consigliato (ed è l'impostazione predefinita) per i volumi NFS FlexVol. In un ambiente NFS, i risparmi della deduplica sono immediatamente visibili agli amministratori di storage e macchine virtuali con volumi con thin provisioning.</block>
  <block id="b26ed63d0f1199652537e2c4b6752130" category="list-text">Il thin provisioning si applica anche alle macchine virtuali, dove NetApp consiglia generalmente VMDK con thin provisioning anziché thick. Quando si utilizza il thin provisioning, assicurarsi di monitorare lo spazio disponibile con gli strumenti ONTAP per VMware vSphere, ONTAP o altri strumenti disponibili per evitare problemi di spazio esaurito.</block>
  <block id="041f3a2c9d939c181dbd2a95595455d0" category="list-text">Si noti che non si verificano penalizzazioni delle performance quando si utilizza il thin provisioning con i sistemi ONTAP; i dati vengono scritti nello spazio disponibile in modo da massimizzare le performance di scrittura e lettura. Nonostante questo fatto, alcuni prodotti come il clustering di failover di Microsoft o altre applicazioni a bassa latenza potrebbero richiedere un provisioning garantito o fisso ed è consigliabile seguire questi requisiti per evitare problemi di supporto.</block>
  <block id="473c8efc5f9b8640820a9cc1f9c84862" category="list-text">Per ottenere il massimo risparmio sulla deduplica, è consigliabile pianificare la deduplica in background su sistemi basati su disco rigido o la deduplica automatica in background su sistemi AFF. Tuttavia, i processi pianificati utilizzano le risorse di sistema durante l'esecuzione, pertanto idealmente devono essere pianificati in tempi meno attivi (come i fine settimana) o eseguiti più frequentemente per ridurre la quantità di dati modificati da elaborare. La deduplica automatica in background sui sistemi AFF ha un effetto molto minore sulle attività in primo piano. Anche la compressione in background (per sistemi basati su disco rigido) consuma risorse, pertanto deve essere presa in considerazione solo per carichi di lavoro secondari con requisiti di performance limitati.</block>
  <block id="dd76252ea7a50def2a98f218cb1505b4" category="inline-link">Articolo della Knowledge base</block>
  <block id="ac2fab512a521d04e53c7257ef490187" category="list-text">I sistemi NetApp AFF utilizzano principalmente funzionalità di efficienza dello storage inline. Quando i dati vengono trasferiti su di essi utilizzando gli strumenti NetApp che utilizzano la replica a blocchi come 7-Mode Transition Tool, SnapMirror o Volume Move, può essere utile eseguire gli scanner di compressione e compattazione per massimizzare i risparmi in termini di efficienza. Consulta questo supporto NetApp<block ref="a24ae202a787a3e4695f02339b72bb57" category="inline-link-rx"></block> per ulteriori dettagli.</block>
  <block id="af21d2d4e0d0faaa6435e780ed7fbc49" category="list-text">Le copie Snapshot potrebbero bloccare blocchi che potrebbero essere ridotti dalla compressione o dalla deduplica. Quando si utilizzano gli scanner untantum o l'efficienza pianificata in background, assicurarsi che vengano eseguiti e completati prima di eseguire la copia Snapshot successiva. Esaminare le copie Snapshot e la conservazione per assicurarsi di conservare solo le copie Snapshot necessarie, soprattutto prima dell'esecuzione di un lavoro in background o dello scanner.</block>
  <block id="8f4468ee9f4f074a9f705cd8240de3d9" category="paragraph">La seguente tabella fornisce le linee guida per l'efficienza dello storage per i carichi di lavoro virtualizzati su diversi tipi di storage ONTAP:</block>
  <block id="68eaabb91b0d1c52be44217a24f27b91" category="cell">Carico di lavoro</block>
  <block id="84f3306d313cbbe707b0df3807aa77ef" category="cell">Linee guida per l'efficienza dello storage</block>
  <block id="c8984126713ed072b9cb0a44a162be4d" category="cell">AFF</block>
  <block id="5325da9878854628027602da18e5fc14" category="cell">Flash Pool</block>
  <block id="9aa1187640093122ffdb7e1c18f8586d" category="cell">Dischi rigidi</block>
  <block id="9bbf225892f3ce69fc504d145abe3ded" category="cell">VDI e SVI</block>
  <block id="1be6174441cf80d01c59eb7a9c004498" category="paragraph">Per i carichi di lavoro primari e secondari, utilizzare:</block>
  <block id="738b6df06bc30a1f2fa6d500095bfceb" category="list-text">Compressione adattiva in linea</block>
  <block id="f801303ba7009e27cce2fe9a73dc5ebe" category="list-text">Deduplica inline</block>
  <block id="f94a70bfe4407315e07db5e64706e531" category="list-text">Deduplica in background</block>
  <block id="95f3762d2d933ff2c0f6e30ef2c767c9" category="list-text">Compaction dei dati inline</block>
  <block id="22be9b04282591df89574efb0e9d2315" category="paragraph">Per i carichi di lavoro primari, utilizzare:</block>
  <block id="e37f23785e68eb0a9d5afd7457b0903e" category="paragraph">Per i carichi di lavoro secondari, utilizzare:</block>
  <block id="7901e1160498e7aff40dc0f858411c54" category="list-text">Compressione adattiva in background</block>
  <block id="be0ec3d9251292dd856ea0924ecc6873" category="section-title">Qualità del servizio (QoS)</block>
  <block id="f437881fa7e42bf0e4563bbec8176f81" category="paragraph">I sistemi che eseguono il software ONTAP possono utilizzare la funzione QoS dello storage ONTAP per limitare il throughput in Mbps e/o i/o al secondo (IOPS) per diversi oggetti di storage come file, LUN, volumi o intere SVM.</block>
  <block id="fb4aa9631cd742ae8a88f672b4464b37" category="paragraph">I limiti di throughput sono utili per il controllo di carichi di lavoro sconosciuti o di test prima dell'implementazione per assicurarsi che non influiscano su altri carichi di lavoro. Possono anche essere utilizzati per limitare un carico di lavoro ingombrante dopo l'identificazione. Sono supportati anche i livelli minimi di servizio basati sugli IOPS per fornire performance costanti per gli oggetti SAN in ONTAP 9.2 e per gli oggetti NAS in ONTAP 9.3.</block>
  <block id="3e4a2dc31acddb628ba286d25b1bd36e" category="paragraph">Con un datastore NFS, è possibile applicare una policy di QoS all'intero volume FlexVol o ai singoli file VMDK al suo interno. Con gli archivi di dati VMFS che utilizzano LUN ONTAP, è possibile applicare i criteri di qualità del servizio al volume FlexVol che contiene LUN o LUN singoli, ma non singoli file VMDK, poiché ONTAP non è consapevole del file system VMFS. Quando si utilizza vVol, è possibile impostare la QoS minima e/o massima su singole macchine virtuali utilizzando il profilo di capacità dello storage e la policy di storage delle macchine virtuali.</block>
  <block id="534ecd446aac2f9c809eef9064f44aab" category="paragraph">Il limite massimo di throughput QoS su un oggetto può essere impostato in Mbps e/o IOPS. Se vengono utilizzati entrambi, il primo limite raggiunto viene applicato da ONTAP. Un carico di lavoro può contenere più oggetti e una policy QoS può essere applicata a uno o più carichi di lavoro. Quando una policy viene applicata a più carichi di lavoro, i carichi di lavoro condividono il limite totale della policy. Gli oggetti nidificati non sono supportati (ad esempio, i file all'interno di un volume non possono avere una propria policy). I valori minimi di QoS possono essere impostati solo in IOPS.</block>
  <block id="040f184b126879657b253b6d258661d9" category="paragraph">I seguenti strumenti sono attualmente disponibili per la gestione delle policy di qualità del servizio ONTAP e per applicarle agli oggetti:</block>
  <block id="de134183bea5df515a6756a539ce6f18" category="list-text">CLI ONTAP</block>
  <block id="6ad5e0a20f49ad6a370454bb3afc9a9e" category="list-text">Gestore di sistema di ONTAP</block>
  <block id="8e23e05fc0865e950d6a3581e0dd8ce9" category="list-text">OnCommand Workflow Automation</block>
  <block id="5ecb6b24c169667ff1a176768115659e" category="list-text">Active IQ Unified Manager</block>
  <block id="8cc4e713850f67a131e9dbf8b997f61e" category="list-text">Kit di strumenti NetApp PowerShell per ONTAP</block>
  <block id="fcdb48d0d22627e4910a8352c80bd87a" category="list-text">Strumenti ONTAP per il provider VMware vSphere VASA</block>
  <block id="e6defd03e0f49585b6d47614713e97f7" category="paragraph">Per assegnare un criterio QoS a un VMDK su NFS, attenersi alle seguenti linee guida:</block>
  <block id="10509998e8d4c4d7be30fc1d0b6b2a1e" category="list-text">La policy deve essere applicata a<block ref="a1bb63c284b58c32f1afb554a12e3e9a" prefix=" " category="inline-code"></block> che contiene l'immagine effettiva del disco virtuale, non il<block ref="aa26c73336ecfd98ed727b3e249c7f90" prefix=" " category="inline-code"></block> (file di descrizione del disco virtuale) o.<block ref="092eb4dd2ca488962f4c22b3e8cc4ca0" prefix=" " category="inline-code"></block> (File descrittore VM).</block>
  <block id="2175e0e29bc4b213fa8b9c7afd591b6b" category="list-text">Non applicare policy ad altri file di macchine virtuali, ad esempio file di swap virtuali <block ref="aa33c3c1850a3f99cec7426e2c411d08" prefix="(" category="inline-code"></block>).</block>
  <block id="8230e9b5c1e9862fedb2c69f7cc5d3d1" category="list-text">Quando si utilizza il client Web vSphere per trovare i percorsi di file (datastore &gt; file), tenere presente che combina le informazioni di<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block> e.<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> e mostra semplicemente un file con il nome di<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> ma le dimensioni di<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block>. Aggiungi<block ref="4fc4e556dbb9dcede037ccd80fabd784" prefix=" " category="inline-code"></block> nel nome del file per ottenere il percorso corretto.</block>
  <block id="1d4614aca13104c98d5d8cc2d415b941" category="paragraph">Per assegnare una policy di QoS a un LUN, inclusi VMFS e RDM, è possibile ottenere la SVM di ONTAP (visualizzata come Vserver), il percorso del LUN e il numero di serie dal menu dei sistemi storage nella home page degli strumenti ONTAP per VMware vSphere. Selezionare il sistema di storage (SVM), quindi Related Objects (oggetti correlati) &gt; SAN. Utilizzare questo approccio quando si specifica la qualità del servizio utilizzando uno degli strumenti ONTAP.</block>
  <block id="8ce0096ff26ebe0a38466de6a64f461d" category="paragraph">La QoS massima e minima può essere facilmente assegnata a una macchina virtuale basata su vVol con gli strumenti ONTAP per VMware vSphere o la console di storage virtuale 7.1 e versioni successive. Quando si crea il profilo di capacità dello storage per il container vVol, specificare un valore IOPS massimo e/o minimo nella funzionalità delle performance, quindi fare riferimento a questo SCP con il criterio di storage della VM. Utilizzare questo criterio quando si crea la macchina virtuale o si applica il criterio a una macchina virtuale esistente.</block>
  <block id="421c9efa4ff1b039a5378be7bc1e2e49" category="paragraph">Gli archivi dati FlexGroup offrono funzionalità QoS avanzate quando si utilizzano gli strumenti ONTAP per VMware vSphere 9.8 e versioni successive. È possibile impostare facilmente la QoS su tutte le macchine virtuali di un datastore o su macchine virtuali specifiche. Per ulteriori informazioni, consultare la sezione FlexGroup di questo report.</block>
  <block id="77bb2ba950959bd3f1c55da523ace0be" category="section-title">QoS ONTAP e SIOC VMware</block>
  <block id="b2e21dac6070ea83831ff6521a66a447" category="paragraph">Il QoS di ONTAP e il controllo i/o dello storage VMware vSphere sono tecnologie complementari che vSphere e gli amministratori dello storage possono utilizzare insieme per gestire le performance delle macchine virtuali vSphere ospitate su sistemi che eseguono il software ONTAP. Ogni strumento ha i propri punti di forza, come mostrato nella tabella seguente. A causa dei diversi ambiti di VMware vCenter e ONTAP, alcuni oggetti possono essere visti e gestiti da un sistema e non dall'altro.</block>
  <block id="5ad234cb2cde4266195252a23ca7d84e" category="cell">Proprietà</block>
  <block id="b8b8d1ba8fa345f03438a90f29af5784" category="cell">QoS ONTAP</block>
  <block id="c2a4cb962db2a4a6782b69864f0e411c" category="cell">VMware SIOC</block>
  <block id="aa628d5a66888444926b4dc042458200" category="cell">Se attivo</block>
  <block id="688b10fcfff927dee65634e3b3636064" category="cell">La policy è sempre attiva</block>
  <block id="a981c4aa67c29ff2d36fc614d8b28808" category="cell">Attivo quando esiste un conflitto (latenza dell'archivio dati oltre la soglia)</block>
  <block id="f46e64a82c96db56f3d6657d4fb53f00" category="cell">Tipo di unità</block>
  <block id="878b4223bb85b95d8caf0429d9406cd5" category="cell">IOPS, Mbps</block>
  <block id="3e189a34f422a141311dad231f9ad5b5" category="cell">IOPS, condivisioni</block>
  <block id="7367a0ec46339213625cbc77d56a9572" category="cell">VCenter o ambito applicativo</block>
  <block id="1faff19290bb64ce8ff6bc1220496881" category="cell">Più ambienti vCenter, altri hypervisor e applicazioni</block>
  <block id="1e664a3cc0ab109fcabcc81b488cebb1" category="cell">Singolo server vCenter</block>
  <block id="ebccc9f5c939841d86e5382988dfcc47" category="cell">Impostare QoS su VM?</block>
  <block id="cddd0980ce99890d2ea90288f6b03117" category="cell">VMDK solo su NFS</block>
  <block id="928629d8a2a889f5274cad9940a06da0" category="cell">VMDK su NFS o VMFS</block>
  <block id="305e85b992089534091855224f60cf75" category="cell">Impostare QoS su LUN (RDM)?</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">Sì</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">No</block>
  <block id="e798014243cf5682e7fb3aaf4ee7cecf" category="cell">Impostare QoS su LUN (VMFS)?</block>
  <block id="9cd021ea9d3c88de723fe9a2e50a2380" category="cell">Impostare QoS sul volume (datastore NFS)?</block>
  <block id="c352b53c32380efcf4436926da6d0414" category="cell">Impostare QoS su SVM (tenant)?</block>
  <block id="86aad9b5d177180a5b9e828a8e05e819" category="cell">Approccio basato su policy?</block>
  <block id="b31c76176f26196c6379a9bcce212d99" category="cell">Sì; può essere condiviso da tutti i carichi di lavoro della policy o applicato in toto a ciascun carico di lavoro della policy.</block>
  <block id="1ff33557bad923d68973872cacf2e43a" category="cell">Sì, con vSphere 6.5 e versioni successive.</block>
  <block id="d5f1465492190ee9d30a09b36f64f4b7" category="cell">Licenza richiesta</block>
  <block id="4cec76d82991abd453484c23f7e3788a" category="cell">Incluso con ONTAP</block>
  <block id="6bb36803f4670824ff9ebdf665654829" category="cell">Enterprise Plus</block>
  <block id="400cc516a4a40acd605aef2cfd4ba4c0" category="section-title">VMware Storage Distributed Resource Scheduler</block>
  <block id="06604b0172f4ae639ffe8c44fa7c77d8" category="paragraph">VMware Storage Distributed Resource Scheduler (SDR) è una funzionalità vSphere che consente di posizionare le macchine virtuali sullo storage in base alla latenza i/o corrente e all'utilizzo dello spazio. Quindi, sposta le VM o i VMDK senza interruzioni tra gli archivi dati in un cluster di datastore (noto anche come pod), selezionando il migliore datastore in cui posizionare le VM o i VMDK nel cluster di datastore. Un cluster di datastore è un insieme di datastore simili che vengono aggregati in una singola unità di consumo dal punto di vista dell'amministratore di vSphere.</block>
  <block id="5735cfd4d72f50fd28717ac30361b503" category="paragraph">Quando si utilizzano GLI SDR con i tool NetApp ONTAP per VMware vSphere, è necessario prima creare un datastore con il plug-in, utilizzare vCenter per creare il cluster del datastore e quindi aggiungervi il datastore. Una volta creato il cluster di datastore, è possibile aggiungere ulteriori datastore al cluster di datastore direttamente dalla procedura guidata di provisioning nella pagina Dettagli.</block>
  <block id="b028cce2007c32457c41f20d2954c0c2" category="paragraph">Altre Best practice ONTAP per I DSP includono:</block>
  <block id="d11eff5be5178b7ba95b06270611ffc8" category="list-text">Tutti gli archivi dati del cluster devono utilizzare lo stesso tipo di storage (ad esempio SAS, SATA o SSD), tutti gli archivi dati VMFS o NFS e avere le stesse impostazioni di replica e protezione.</block>
  <block id="76db7ce67615bbc16da685df79ed0aa9" category="list-text">Considerare l'utilizzo DEGLI SDR in modalità predefinita (manuale). Questo approccio consente di rivedere i suggerimenti e decidere se applicarli o meno. Tenere presente i seguenti effetti delle migrazioni VMDK:</block>
  <block id="97f4ed95cb52bb29629002a25cb5039f" category="list-text">Quando GLI SDR spostano i VMDK tra datastore, qualsiasi risparmio di spazio derivante dalla clonazione o deduplica ONTAP viene perso. È possibile rieseguire la deduplica per recuperare questi risparmi.</block>
  <block id="cc1aa351f771fc36d1542fa93e1fac8e" category="list-text">Dopo che GLI SDR hanno spostato i VMDK, NetApp consiglia di ricreare le copie Snapshot nel datastore di origine, poiché lo spazio viene altrimenti bloccato dalla macchina virtuale spostata.</block>
  <block id="09a99cbc4fb85d10c7af970e79032a05" category="list-text">Lo spostamento di VMDK tra datastore sullo stesso aggregato ha pochi benefici e GLI SDR non hanno visibilità su altri carichi di lavoro che potrebbero condividere l'aggregato.</block>
  <block id="a30850531baecbfbe4486d4be9e79e30" category="section-title">VVol e gestione basata su policy di storage</block>
  <block id="f2606439d8a3fed353e38254458c0a32" category="paragraph">Le API VMware vSphere per Storage Awareness (VASA) semplificano la configurazione dei datastore da parte di un amministratore dello storage con funzionalità ben definite e consentono all'amministratore delle macchine virtuali di utilizzarle quando necessario per eseguire il provisioning delle macchine virtuali senza dover interagire tra loro. Vale la pena dare un'occhiata a questo approccio per scoprire come può ottimizzare le operazioni di storage per la virtualizzazione ed evitare un sacco di lavoro banale.</block>
  <block id="ad0bd815b4fb6f01acc94f160af3dca7" category="paragraph">Prima di VASA, gli amministratori delle macchine virtuali potevano definire le policy di storage delle macchine virtuali, ma dovevano collaborare con l'amministratore dello storage per identificare gli archivi dati appropriati, spesso utilizzando la documentazione o le convenzioni di denominazione. Con VASA, l'amministratore dello storage può definire una serie di funzionalità di storage, tra cui performance, tiering, crittografia e replica. Un insieme di funzionalità per un volume o un set di volumi viene definito SCP (Storage Capability Profile).</block>
  <block id="a3af04d147e48682c8be6bd0c1b66520" category="paragraph">SCP supporta la QoS minima e/o massima per i vVol di dati di una macchina virtuale. La QoS minima è supportata solo sui sistemi AFF. Gli strumenti ONTAP per VMware vSphere includono una dashboard che visualizza le performance granulari delle macchine virtuali e la capacità logica per i vVol sui sistemi ONTAP.</block>
  <block id="4240fa68f6d9919e6d039c4038175025" category="paragraph">La figura seguente mostra i tool ONTAP per il dashboard di VMware vSphere 9.8 vVol.</block>
  <block id="d3fcb217aa8b45eb8a95f8958c1f7746" category="paragraph"><block ref="d3fcb217aa8b45eb8a95f8958c1f7746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6257d346f635c1b16a2f39df0830a48" category="paragraph">Una volta definito il profilo di capacità dello storage, è possibile utilizzarlo per eseguire il provisioning delle macchine virtuali utilizzando la policy di storage che ne identifica i requisiti. La mappatura tra il criterio di storage delle macchine virtuali e il profilo di capacità dello storage del datastore consente a vCenter di visualizzare un elenco di datastore compatibili per la selezione. Questo approccio è noto come gestione basata su policy di storage.</block>
  <block id="ca100a4ba1d4641f17806479f93c8b1a" category="paragraph">VASA offre la tecnologia per eseguire query sullo storage e restituire un set di funzionalità di storage a vCenter. I vendor provider VASA forniscono la traduzione tra le API e i costrutti del sistema storage e le API VMware comprese da vCenter. Il provider VASA di NetApp per ONTAP viene offerto come parte degli strumenti ONTAP per le macchine virtuali dell'appliance VMware vSphere, mentre il plug-in vCenter fornisce l'interfaccia per il provisioning e la gestione dei datastore vVol, oltre alla possibilità di definire i profili di capacità dello storage (SCP).</block>
  <block id="dad160104969c39365dd2cd4c98dd300" category="inline-link">TR-4400</block>
  <block id="79f0d5feb7ec25a16c407f3f585eabb2" category="paragraph">ONTAP supporta gli archivi dati VMFS e NFS vVol. L'utilizzo di vVol con datastore SAN offre alcuni dei vantaggi di NFS, come la granularità a livello di macchine virtuali. Di seguito sono riportate alcune Best practice da prendere in considerazione e ulteriori informazioni sono disponibili in<block ref="4f23d4db151ca74200684ac8aef53fed" category="inline-link-rx"></block>:</block>
  <block id="bd490c925219bcb312338a370589bf70" category="list-text">Un datastore vVol può essere costituito da più volumi FlexVol su più nodi del cluster. L'approccio più semplice è un singolo datastore, anche quando i volumi hanno funzionalità diverse. SPBM garantisce l'utilizzo di un volume compatibile per la macchina virtuale. Tuttavia, tutti i volumi devono far parte di una singola SVM ONTAP e devono essere accessibili utilizzando un singolo protocollo. È sufficiente una LIF per nodo per ogni protocollo. Evitare di utilizzare più release di ONTAP all'interno di un singolo datastore vVol, poiché le funzionalità dello storage potrebbero variare tra le varie release.</block>
  <block id="0cc956d6da91fefae9dad9b2c8c9519b" category="list-text">Utilizza i tool ONTAP per il plug-in VMware vSphere per creare e gestire datastore vVol. Oltre a gestire il datastore e il relativo profilo, crea automaticamente un endpoint del protocollo per accedere ai vVol, se necessario. Se si utilizzano LUN, tenere presente che i LUN PES vengono mappati utilizzando LUN ID 300 e superiori. Verificare che l'impostazione di sistema avanzata dell'host ESXi sia corretta<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> Consente un numero di ID LUN superiore a 300 (il valore predefinito è 1,024). Eseguire questa operazione selezionando l'host ESXi in vCenter, quindi la scheda Configura e trova<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> Nell'elenco delle Advanced System Settings (Impostazioni di sistema avanzate).</block>
  <block id="fac85f355a1eb47127ef1b94e7603924" category="list-text">Non installare o migrare il provider VASA, il server vCenter (basato su appliance o Windows) o i tool ONTAP per VMware vSphere in sé su un datastore vVols, perché in tal caso sono dipendenti reciprocamente, limitando la possibilità di gestirli in caso di interruzione dell'alimentazione o di altre interruzioni del data center.</block>
  <block id="27bd00c8827fc3d77d1b5650103b676f" category="list-text">Eseguire regolarmente il backup della VM del provider VASA. Creare almeno copie Snapshot orarie del datastore tradizionale che contiene il provider VASA. Per ulteriori informazioni sulla protezione e il ripristino del provider VASA, consulta questa sezione<block ref="9d642870dca1748c69f7aa0b6fb95a89" category="inline-link-rx"></block>.</block>
  <block id="2d2d2e356f9ab117b7d2a58d42cc5988" category="paragraph">La figura seguente mostra i componenti di vVol.</block>
  <block id="6aadcb77504dae1dbfed2e4d1c969158" category="paragraph"><block ref="6aadcb77504dae1dbfed2e4d1c969158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ce8b0e3e0d7dc7f39c62fb74a28b3bf" category="section-title">Migrazione e backup del cloud</block>
  <block id="4fe11b4a91ff38ec9933009a15dd5b0b" category="paragraph">Un altro punto di forza di ONTAP è l'ampio supporto per il cloud ibrido, che unisce i sistemi nel tuo cloud privato on-premise con funzionalità di cloud pubblico. Ecco alcune soluzioni cloud NetApp che possono essere utilizzate insieme a vSphere:</block>
  <block id="67464b4510c09197c8a5e16ba6702435" category="list-text">*Cloud Volumes.* NetApp Cloud Volumes Service per AWS o GCP e Azure NetApp Files per ANF offrono servizi di storage gestito multiprotocollo e dalle performance elevate nei principali ambienti di cloud pubblico. Possono essere utilizzati direttamente dai guest delle macchine virtuali VMware Cloud.</block>
  <block id="0ac7b95ec26051fb8842ae35427ecc22" category="list-text">*Cloud Volumes ONTAP.* il software per la gestione dei dati NetApp Cloud Volumes ONTAP offre controllo, protezione, flessibilità ed efficienza ai tuoi dati sul cloud di tua scelta. Cloud Volumes ONTAP è un software per la gestione dei dati nativo del cloud basato sul software di storage NetApp ONTAP. Utilizzare insieme a Cloud Manager per implementare e gestire le istanze di Cloud Volumes ONTAP insieme ai sistemi ONTAP on-premise. Sfrutta le avanzate funzionalità NAS e SAN iSCSI insieme alla gestione unificata dei dati, incluse le copie Snapshot e la replica SnapMirror.</block>
  <block id="2a11701c0c01affc0ce96eb0d0c16ed9" category="list-text">*Servizi cloud.* Usa Cloud Backup Service o SnapMirror Cloud per proteggere i dati dai sistemi on-premise utilizzando lo storage di cloud pubblico. Cloud Sync consente di migrare e mantenere sincronizzati i dati tra NAS, archivi di oggetti e storage Cloud Volumes Service.</block>
  <block id="fa9b5353337118a51ced7968bccc02a0" category="inline-link">Memorizzare più copie Snapshot delle macchine virtuali</block>
  <block id="c79f1f00e1e3c8f100e8604eec888859" category="list-text">*FabricPool.* FabricPool offre tiering rapido e semplice per i dati ONTAP. È possibile migrare i cold block nelle copie Snapshot in un archivio di oggetti nei cloud pubblici o in un archivio di oggetti StorageGRID privato e richiamarli automaticamente quando si accede nuovamente ai dati ONTAP. Oppure utilizzare il Tier di oggetti come terzo livello di protezione per i dati già gestiti da SnapVault. Questo approccio può consentirti di farlo<block ref="1d0add9d2d81e2d7e790f727021e53aa" category="inline-link-rx"></block> Sui sistemi storage ONTAP primari e/o secondari.</block>
  <block id="1a7072854c9dd945a98f4314b3f77408" category="list-text">*ONTAP Select.* utilizza lo storage software-defined di NetApp per estendere il tuo cloud privato attraverso Internet a sedi e uffici remoti, dove puoi utilizzare ONTAP Select per supportare i servizi di file e blocchi e le stesse funzionalità di gestione dei dati vSphere presenti nel tuo data center aziendale.</block>
  <block id="79aec220098057ef8c0e46281a45d6c2" category="paragraph">Quando si progettano le applicazioni basate su macchine virtuali, considerare la futura mobilità del cloud. Ad esempio, invece di mettere insieme file di applicazioni e dati, utilizza un'esportazione LUN o NFS separata per i dati. Ciò consente di migrare la macchina virtuale e i dati separatamente ai servizi cloud.</block>
  <block id="af63597853dc0983258c8f86a12aae0b" category="section-title">Crittografia per i dati vSphere</block>
  <block id="eb969673f581d94df982f8e2a6001f30" category="paragraph">Oggi, la necessità di proteggere i dati inattivi è in aumento grazie alla crittografia. Anche se l'attenzione iniziale era incentrata sulle informazioni finanziarie e sanitarie, c'è sempre più interesse a proteggere tutte le informazioni, che siano memorizzate in file, database o altri tipi di dati.</block>
  <block id="77652ecf0c76f1d4194171dc720320be" category="paragraph">I sistemi che eseguono il software ONTAP semplificano la protezione dei dati con la crittografia a riposo. NetApp Storage Encryption (NSE) utilizza dischi con crittografia automatica e ONTAP per proteggere i dati SAN e NAS. NetApp offre inoltre NetApp Volume Encryption e NetApp aggregate Encryption come approccio semplice e basato su software per crittografare i volumi su qualsiasi disco. Questa crittografia software non richiede unità disco speciali o gestori di chiavi esterni ed è disponibile per i clienti ONTAP senza costi aggiuntivi. È possibile eseguire l'upgrade e iniziare a utilizzarlo senza alcuna interruzione per i client o le applicazioni e sono validati in base allo standard FIPS 140-2 livello 1, incluso il gestore delle chiavi integrato.</block>
  <block id="937a352e0f824ff55e4cd50c8e3b051e" category="paragraph">Esistono diversi approcci per la protezione dei dati delle applicazioni virtualizzate in esecuzione su VMware vSphere. Un approccio consiste nel proteggere i dati con il software all'interno della macchina virtuale a livello di sistema operativo guest. Gli hypervisor più recenti, come vSphere 6.5, ora supportano la crittografia a livello di VM come alternativa. Tuttavia, la crittografia del software NetApp è semplice e offre i seguenti vantaggi:</block>
  <block id="92fbd315c4413db381567a775570b78c" category="list-text">*Nessun effetto sulla CPU del server virtuale.* alcuni ambienti di server virtuali richiedono ogni ciclo di CPU disponibile per le proprie applicazioni, tuttavia i test hanno dimostrato che sono necessarie fino a 5 risorse di CPU con crittografia a livello di hypervisor. Anche se il software di crittografia supporta l'insieme di istruzioni AES-NI di Intel per trasferire il carico di lavoro di crittografia (come avviene per la crittografia software NetApp), questo approccio potrebbe non essere fattibile a causa del requisito di nuove CPU non compatibili con i server meno recenti.</block>
  <block id="6abee98aea26f85e6f0fe8d4db70f998" category="list-text">*Onboard Key Manager incluso.* la crittografia software NetApp include un gestore delle chiavi integrato senza costi aggiuntivi, il che rende semplice iniziare senza server di gestione delle chiavi ad alta disponibilità complessi da acquistare e utilizzare.</block>
  <block id="c216121021de8554d33503ef6616b256" category="list-text">*Nessun effetto sull'efficienza dello storage.* le tecniche di efficienza dello storage, come deduplica e compressione, sono ampiamente utilizzate oggi e sono fondamentali per utilizzare i supporti su disco flash in modo conveniente. Tuttavia, i dati crittografati non possono in genere essere deduplicati o compressi. La crittografia dello storage e dell'hardware NetApp opera a un livello inferiore e consente l'utilizzo completo delle funzionalità di efficienza dello storage NetApp leader del settore, a differenza di altri approcci.</block>
  <block id="5f9aa8333f218d1c21e67c8608a48672" category="list-text">*Crittografia granulare semplice del datastore.* con NetApp Volume Encryption, ogni volume ottiene la propria chiave AES a 256 bit. Se è necessario modificarlo, è possibile farlo con un singolo comando. Questo approccio è ideale se hai più tenant o hai bisogno di dimostrare una crittografia indipendente per diversi reparti o applicazioni. Questa crittografia viene gestita a livello di datastore, il che è molto più semplice della gestione di singole macchine virtuali.</block>
  <block id="088124cfa6d59c647e63177c5a4af318" category="paragraph">Iniziare a utilizzare la crittografia software è semplicissimo. Una volta installata la licenza, è sufficiente configurare il gestore delle chiavi integrato specificando una passphrase e quindi creare un nuovo volume o spostare un volume lato storage per abilitare la crittografia. NetApp sta lavorando per aggiungere un supporto più integrato per le funzionalità di crittografia nelle versioni future dei suoi strumenti VMware.</block>
  <block id="c95fa5b56a01e5c1a80c540c1ab1a750" category="paragraph">Active IQ Unified Manager offre visibilità sulle macchine virtuali dell'infrastruttura virtuale e consente il monitoraggio e la risoluzione dei problemi relativi a storage e performance nell'ambiente virtuale.</block>
  <block id="be75250c2f30870dc1e359b4ade2a767" category="paragraph">Una tipica implementazione di un'infrastruttura virtuale su ONTAP include diversi componenti distribuiti tra livelli di calcolo, rete e storage. Eventuali ritardi nelle performance in un'applicazione VM potrebbero verificarsi a causa di una combinazione di latenze affrontate dai vari componenti nei rispettivi layer.</block>
  <block id="d1734f6f2e65a1488896f74695db5254" category="paragraph">La seguente schermata mostra la vista macchine virtuali Active IQ Unified Manager.</block>
  <block id="8aa017c9f67ad32dd7301ecf52b61d72" category="paragraph"><block ref="8aa017c9f67ad32dd7301ecf52b61d72" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2118336fa447fcc0f213cb8c40c516af" category="paragraph">Unified Manager presenta il sottosistema sottostante di un ambiente virtuale in una vista topologica per determinare se si è verificato un problema di latenza nel nodo di calcolo, nella rete o nello storage. La vista evidenzia anche l'oggetto specifico che causa il ritardo delle performance per l'adozione di misure correttive e la risoluzione del problema sottostante.</block>
  <block id="d8a78b994fcd4e04901203a2e7bc6414" category="paragraph">La seguente schermata mostra la topologia espansa di AIQUM.</block>
  <block id="e9659be2b7d3d69eccdb443ed2acec75" category="paragraph"><block ref="e9659be2b7d3d69eccdb443ed2acec75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e69b470437a857bf2d9517ce4ef8d2c1" category="summary">In questa pagina viene illustrata la procedura per l'implementazione di un datastore FC VMFS per lo storage NetApp ONTAP in un ambiente VMware vSphere.</block>
  <block id="91d9498cf61618ef81368a106318efd2" category="doc">Datastore vSphere VMFS - backend dello storage Fibre Channel con ONTAP</block>
  <block id="b6e52e53cc59b8620dcdc05f2b812be4" category="paragraph">In questa sezione viene illustrata la creazione di un datastore VMFS con lo storage Fibre Channel (FC) ONTAP.</block>
  <block id="6b70d8f91894fa50b3c04af804f090b6" category="list-text">Le competenze di base necessarie per gestire un ambiente vSphere e ONTAP</block>
  <block id="0335588c7903659bdeaa310c8f7bcdf4" category="list-text">Un sistema storage ONTAP (FAS/AFF/CVO/ONTAP Select/ASA) con {ontap_version}</block>
  <block id="f2a03b032017931383878c3ef48cdb0a" category="list-text">WWPN ONTAP di host, destinazione e informazioni su SVM e LUN</block>
  <block id="d0a36a0dcdef62d026caa08afbaa4a42" category="inline-link-macro">Il foglio di lavoro di configurazione FC completo</block>
  <block id="5c42144bb611ba366591a823d4c2955e" category="list-text"><block ref="5c42144bb611ba366591a823d4c2955e" category="inline-link-macro-rx"></block></block>
  <block id="24c066a87410cc7b08ad4b5ca45565d7" category="list-text">Credenziali vCenter Server</block>
  <block id="c7f58b1f94665d7ebf6f107970d1b91b" category="list-text">Informazioni sugli host vSphere</block>
  <block id="cdce6351191da46d795898e4570b8da2" category="list-text">{vsphere_version}</block>
  <block id="6c2e28f86b2049d110f0e73e9bb78709" category="list-text">Con porte dati ONTAP FC e host vSphere collegati</block>
  <block id="52dd4b667b031cd80a33b9d176e43827" category="list-text">Con la funzione NPIV (N_Port ID Virtualization) attivata</block>
  <block id="46fdd1539543376bfbbf2cc6da976539" category="list-text">Creare una singola zona di destinazione dell'iniziatore.</block>
  <block id="5a1cb943a687396a356750829002d982" category="list-text">Per ciascuna zona, includere una destinazione che sia l'interfaccia logica FC ONTAP (WWPN) per le SVM. Devono essere presenti almeno due interfacce logiche per nodo per SVM. Non utilizzare la WWPN delle porte fisiche.</block>
  <block id="acd7065eaa19f6ad949216b6dcca52b6" category="list-text">Un tool ONTAP per VMware vSphere implementato, configurato e pronto all'uso.</block>
  <block id="d13dd15101d292f5b2c56e5be828fec8" category="section-title">Provisioning di un datastore VMFS</block>
  <block id="95877ca095b0f0a0a981f8a12d234ad5" category="paragraph">Per eseguire il provisioning di un datastore VMFS, attenersi alla seguente procedura:</block>
  <block id="94dafc85e46c3bc0d374c052b1075890" category="list-text">Verificare la compatibilità con<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="195e1a47999aff0fbaa4eb8d97be6c40" category="inline-link-macro">Configurazione FCP supportata</block>
  <block id="e1b87801d0d31fd947fb52aa411c2815" category="list-text">Verificare che il <block ref="a0240d867f430aa7cc80ec129fc2bdb1" category="inline-link-macro-rx"></block>.</block>
  <block id="0b3f75b021ef6bdc0a532e2d9b2a9d74" category="inline-link-macro">Verificare di disporre di una licenza ONTAP per FCP.</block>
  <block id="3c56f50608e95955ed2e1a3fb8b1dad1" category="list-text"><block ref="3c56f50608e95955ed2e1a3fb8b1dad1" category="inline-link-macro-rx"></block></block>
  <block id="e7dc6b39e7e5bd6df8fa93e90a426161" category="list-text">Utilizzare<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Per verificare che FCP sia presente nell'elenco.</block>
  <block id="f8aa00b1a94d3290ba6ac653b792dd8a" category="list-text">Utilizzare<block ref="79868b45624cf0644299a1019c0f9dc9" prefix=" " category="inline-code"></block> per aggiungere la licenza.</block>
  <block id="86a53381cefd41dcca81850274f0203a" category="list-text">Assicurarsi che il protocollo FCP sia attivato su SVM.</block>
  <block id="169e237a691059b9ac1933f0e7be8f56" category="inline-link-macro">Verificare l'FCP su una SVM esistente.</block>
  <block id="5bb60b756067a0334c310be1e2260c3b" category="list-text"><block ref="5bb60b756067a0334c310be1e2260c3b" category="inline-link-macro-rx"></block></block>
  <block id="fab6621b43b19a018afc1860a5b85c21" category="inline-link-macro">Configurare l'FCP su una SVM esistente.</block>
  <block id="7d4ca3fa89beb77990d305e17ed9ba64" category="list-text"><block ref="7d4ca3fa89beb77990d305e17ed9ba64" category="inline-link-macro-rx"></block></block>
  <block id="0d195904efc6cfb176bbc04e93c2947d" category="inline-link-macro">Crea la nuova SVM con FCP.</block>
  <block id="df062a6cafa16aee5f7ea64ea6991776" category="list-text"><block ref="df062a6cafa16aee5f7ea64ea6991776" category="inline-link-macro-rx"></block></block>
  <block id="5aab5d056538757626dd0562a563471a" category="list-text">Assicurarsi che le interfacce logiche FCP siano disponibili su una SVM.</block>
  <block id="f89eac3d097d3dae5c0159f0da84b1c7" category="list-text">Quando viene creata una SVM con la GUI, le interfacce logiche fanno parte di tale processo.</block>
  <block id="946b60eb8bd4945ad82b28fd9ccd3c63" category="list-text">Per rinominare le interfacce di rete, utilizzare<block ref="976ec076dd60d4d6296585d0275e7fbc" prefix=" " category="inline-code"></block>.</block>
  <block id="52fa81ab62bea2599ed516f01925678d" category="inline-link-macro">Creare e mappare un LUN.</block>
  <block id="c8ecf540bebb63423545ecd3d02c6ca0" category="list-text"><block ref="a2b18e9ce335dd856363e6613d961c1a" category="inline-link-macro-rx"></block> Saltare questo passaggio se si utilizzano i tool ONTAP per VMware vSphere.</block>
  <block id="e4f7ebeb9544fb23a73028ab714ca87c" category="section-title">Attività di VMware vSphere</block>
  <block id="25d85157bcfdbb601bbda056cd3a5bc6" category="list-text">Verificare che i driver HBA siano installati. Gli HBA supportati da VMware dispongono di driver implementati e devono essere visibili in <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block>.</block>
  <block id="c57f32bc5ce6f95f5f9bec8260ecdb08" category="inline-link-macro">Eseguire il provisioning di un datastore VMFS con gli strumenti ONTAP</block>
  <block id="b3a5f140339b1ca0940c5875b2a76d0b" category="list-text"><block ref="89ebfed741bd060c10a4a1472581f4e2" category="inline-link-macro-rx"></block>.</block>
  <block id="8b5fd5c25439f60370c36458db046f5e" category="doc">Novità di VMware vSphere 8</block>
  <block id="d64ac18d7cdc111af11284a04f9e8b1e" category="paragraph">Autore: Chris Reno, NetApp Solutions Engineering</block>
  <block id="5a16d86949ce13083d30d1c331be09cb" category="paragraph">L'integrazione delle tecnologie NetApp e VMware ha una tradizione che si estende su 20 anni e migliaia di ore di progettazione. Con l'avvento di vSphere 8 e ONTAP 9.12, entrambe le aziende offrono prodotti in grado di soddisfare i carichi di lavoro dei clienti più esigenti. Quando questi prodotti sono accoppiati in soluzioni, sono vere sfide per i clienti risolte sia on-premise che nei cloud pubblici. Quando questi prodotti vengono combinati in soluzioni, le sfide reali dei clienti vengono risolte sia on-premise che nei cloud pubblici.</block>
  <block id="4eba71964e65640552100b4af7c50e86" category="paragraph">Per aiutarti a determinare la capacità di supporto di prodotti, protocolli, sistemi operativi, ecc., consulta le risorse seguenti:</block>
  <block id="9ed4a475dd3705157a9fed8811f63ce2" category="inline-link">Tool di matrice di interoperabilità NetApp</block>
  <block id="bab924f6f70545a4aab5c02282b4321d" category="list-text">Il<block ref="cdfba3111aed90ef850f414330a864eb" category="inline-link-rx"></block> (IMT). Il IMT definisce i componenti e le versioni qualificate che è possibile utilizzare per creare configurazioni FC/FCoE, iSCSI, NFS e CIFS, nonché integrazioni con plug-in aggiuntivi e offerte software.</block>
  <block id="e08175c6fa64cba68719dea85ebd9d34" category="inline-link">Guida alla compatibilità VMware</block>
  <block id="e96d25b875cbad01256de32331620fce" category="list-text">Il<block ref="132c849774dbad448418b619a953cbd1" category="inline-link-rx"></block>. La Guida alla compatibilità VMware elenca la compatibilità di sistemi, i/o, storage/SAN, backup e molto altro ancora con VMware Infrastructure e i prodotti software.</block>
  <block id="0f0b69f9725d17d0a8d3ceebcf33f72f" category="inline-link">Tool NetApp ONTAP per VMware</block>
  <block id="cca95a1e810067767564618ea73079be" category="list-text"><block ref="ec744c32e869920be1556ab8ebc057ef" category="inline-link-rx"></block>. Gli strumenti ONTAP per VMware vSphere sono un plug-in vCenter Server singolo che include le estensioni della console di storage virtuale (VSC), del provider VASA e dell'adattatore di replica dello storage (SRA). Completamente supportato con VMware vSphere 8, OTV 9.12 offre ai clienti un valore reale su base giornaliera.</block>
  <block id="ae33d50ae700fed2ee8028004d9fa2d8" category="section-title">Versioni supportate da NetApp ONTAP e VMware</block>
  <block id="ed126bbe4f371826a7c7c9d6fdd35e54" category="admonition">Lasciare che le pagine si costruiscono quando si seleziona un collegamento nelle tabelle seguenti.</block>
  <block id="e450cac7ca4b207e6cb6c51eeb3c76dd" category="cell">*VMware vSphere Release*</block>
  <block id="54d1b3917151f3d89ddbd7aef9f811dd" category="cell">*SAN*</block>
  <block id="b4ccd4984cce17a35c772737cf9415b1" category="cell">*NFS*</block>
  <block id="ea2b80d118e24f4d3328c20552636f22" category="cell">*OTV*</block>
  <block id="dccf9c2e4a699b348abaf0369603c1a0" category="cell">*SnapCenter*</block>
  <block id="b97d2c4e1a2a118c500af6e32504301f" category="cell">*VSphere 8*</block>
  <block id="97e7c9a7d06eac006a28bf05467fcc8b" category="inline-link">Collegamento</block>
  <block id="3c30688c35eac25f7729ec4ee134e7e3" category="cell"><block ref="f010a57a1b1362e74ef056cd949b4f6b" category="inline-link-rx"></block></block>
  <block id="c538764856660dbf5ac35d08c5b7bcdf" category="cell"><block ref="5983a3bb611cf1b4562bfd78f97ed318" category="inline-link-rx"></block></block>
  <block id="a140bde1e447ebe74a0b6b693d05d3c6" category="cell"><block ref="c14e144a71a125f874ca16b78c671347" category="inline-link-rx"></block></block>
  <block id="8d153eb947f0747c73debd6aa0564387" category="cell"><block ref="9e4cfb7f25d7fb71f62ac8aad4b23fac" category="inline-link-rx"></block></block>
  <block id="87efc48b7f668d33418b1f846e08a0bf" category="cell">*VSphere 8u1*</block>
  <block id="adebed85a7d92b0f3fc4b5cfc97078b6" category="cell"><block ref="bdb3662ee535fb90a843ab7d85efbd16" category="inline-link-rx"></block></block>
  <block id="055cce5491290ec858a19e499e0d9e71" category="cell"><block ref="bd210893ee82e4c865fcf08bbaf31838" category="inline-link-rx"></block></block>
  <block id="336d5ebc5436534e61d16e63ddfca327" category="cell">-</block>
  <block id="1f0f8c35492e97597c98b9dc82afa362" category="cell">*Sistema di storage/protocolli*</block>
  <block id="e90637603dd7a81f8a9115bb4ffd28f9" category="cell">*OTV - SRA*</block>
  <block id="d7d7d2428ec9c1791dc7f644b043a8d4" category="cell">*OTV – Provider VASA*</block>
  <block id="81e3cc47d6ed146bbe1096018a69f40c" category="cell">*Plug-in SnapCenter per VMware vSphere*</block>
  <block id="1a718e68b847d8b2043c7f76af9a4858" category="cell"><block ref="34ab3c79d36e5a654b9402fe2fcf7f3b" category="inline-link-rx"></block></block>
  <block id="391de35bbb4cf1a51813527b129bb11e" category="cell"><block ref="e3a74d6b6b54621583ac737da6124d3a" category="inline-link-rx"></block></block>
  <block id="47c5c0877638b8f808901039637b1474" category="cell"><block ref="8ef8fc61fd753b52cc179e3463e5820b" category="inline-link-rx"></block></block>
  <block id="b8145535eda5b8ac300fd64bfa74cc26" category="cell"><block ref="64c621ea990d75acd1bb8fba7b272f2c" category="inline-link-rx"></block></block>
  <block id="315a0755b344c41b2a45eb62f3868930" category="cell"><block ref="c0dded1a1fb8dd474b19235d36c5c4c7" category="inline-link-rx"></block></block>
  <block id="3e4627f6667f830baceaaf35890b575a" category="summary">Per ulteriori informazioni sulle informazioni descritte in questo documento, consultare i seguenti documenti e/o siti Web.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="doc">Ulteriori informazioni</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">Per ulteriori informazioni sulle informazioni descritte in questo documento, consultare i seguenti documenti e/o siti Web:</block>
  <block id="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link"><block ref="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link-rx"></block></block>
  <block id="b17e2a7e5f42c90b40de5971850339ae" category="list-text">TR-4597: VMware vSphere per ONTAP<block ref="5938ff9651f6c5e53544676ba8504afc" category="inline-link-rx"></block></block>
  <block id="7d9ee37e3155d571b441d63bcbc54709" category="inline-link"><block ref="7d9ee37e3155d571b441d63bcbc54709" category="inline-link-rx"></block></block>
  <block id="52c629361849219069b336f56f1556d0" category="list-text">TR-4400: Volumi virtuali VMware vSphere con ONTAP<block ref="b7bf139d6051615d8c8e01b6b63dacc3" category="inline-link-rx"></block></block>
  <block id="18df8e05a5400abd9d0980b1c5bc9ef3" category="list-text">Guida alle Best practice per la configurazione di SnapMirror TR-4015 per ONTAP 9<block ref="e361bd9d6f7b20da762bc23fcb3d09c2" category="inline-link-rx"></block></block>
  <block id="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link"><block ref="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link-rx"></block></block>
  <block id="249b98331fa56dc46bf6ba51dc6c39d5" category="list-text">Creatore utente RBAC per ONTAP<block ref="6b15b91279acfce2bbee060bdb17db43" category="inline-link-rx"></block></block>
  <block id="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link"><block ref="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link-rx"></block></block>
  <block id="1a57e0f74e725c1a5e2d53b4d4b4460d" category="list-text">Strumenti ONTAP per le risorse VMware vSphere<block ref="80c496cd9ab75e5683007d8f66ca6fbf" category="inline-link-rx"></block></block>
  <block id="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link"><block ref="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link-rx"></block></block>
  <block id="91a48e1708df22b7464bced79c745ad2" category="list-text">Documentazione di VMware Site Recovery Manager<block ref="92ad802ced4838839b492be6d0bf427d" category="inline-link-rx"></block></block>
  <block id="014a2413d22e5ac39371ac1333e38898" category="paragraph">Fare riferimento a.<block ref="99cfde592e1d7fa7832b186d73ee4002" category="inline-link-rx"></block> Sul sito del supporto NetApp per verificare che le versioni esatte dei prodotti e delle funzionalità descritte in questo documento siano supportate per il tuo ambiente specifico. NetApp IMT definisce i componenti e le versioni dei prodotti che possono essere utilizzati per costruire configurazioni supportate da NetApp. I risultati specifici dipendono dall'installazione di ciascun cliente in conformità alle specifiche pubblicate.</block>
  <block id="5ed492cbbbf7e6d167035a7c10478daa" category="summary">VMware End-User Computing con NetApp HCI è un'architettura di data center pre-validata e Best-practice per l'implementazione di workload di desktop virtuali su scala aziendale.</block>
  <block id="85864e2699dfaceb7f8d1f85448939fe" category="doc">NVA-1132-DESIGN: VMware end-user computing con NetApp HCI</block>
  <block id="3d564c1c20cf4265a5094ead9dc937f6" category="paragraph">Suresh Thoppay, NetApp</block>
  <block id="52940073ac3f539b3c6d9ac1e41d5f06" category="paragraph">VMware End-User Computing con NetApp HCI è un'architettura di data center pre-validata e Best-practice per l'implementazione di workload di desktop virtuali su scala aziendale. Questo documento descrive la progettazione architetturale e le Best practice per l'implementazione della soluzione su scala di produzione in modo affidabile e privo di rischi.</block>
  <block id="8c40c45c2332a47a83ae257f42af2331" category="paragraph"><block ref="8c40c45c2332a47a83ae257f42af2331" category="inline-link-macro-rx"></block></block>
  <block id="93b94e62ad8cb02a1d1a7b0944a5445d" category="summary">Questo documento illustra la sicurezza dei prodotti per gli strumenti ONTAP per VMware vSphere.</block>
  <block id="289953e1dbd51c07cae2ecf1e6fb88a1" category="doc">WP-7353: Strumenti ONTAP per VMware vSphere - sicurezza del prodotto</block>
  <block id="595319f89334a6a0b8edd4f81172fc71" category="paragraph">Chance Bingen, Dan Tulledge, Jenn Schrie, NetApp</block>
  <block id="7ab9df3e4e38ca227c1b48b0f6740675" category="section-title">Attività di sviluppo sicure</block>
  <block id="1a79eb278bc02ebdbd2ab32925e316f6" category="paragraph">L'engineering del software con i tool NetApp ONTAP per VMware vSphere utilizza le seguenti attività di sviluppo sicuro:</block>
  <block id="39e5fc9eb192f011ab14dae6c2974c4e" category="list-text">*Modellazione delle minacce.* lo scopo della modellazione delle minacce è quello di individuare i difetti di sicurezza in una funzionalità, un componente o un prodotto nelle prime fasi del ciclo di vita dello sviluppo software. Un modello di minaccia è una rappresentazione strutturata di tutte le informazioni che influiscono sulla sicurezza di un'applicazione. In sostanza, si tratta di una vista dell'applicazione e del suo ambiente attraverso l'obiettivo della sicurezza.</block>
  <block id="9f16ab3a50bca32d19c4729319035c8d" category="list-text">*Dynamic Application Security Testing (DAST).* questa tecnologia è progettata per rilevare le condizioni vulnerabili delle applicazioni in esecuzione. DAST testa le interfacce HTTP e HTML esposte delle applicazioni web-enable.</block>
  <block id="267bed0525e4dab477e4c24ca5a1794e" category="list-text">*Valuta del codice di terze parti.* nell'ambito dello sviluppo di software con software open-source (OSS), è necessario risolvere le vulnerabilità di sicurezza che potrebbero essere associate a qualsiasi OSS incorporato nel prodotto. Si tratta di un'operazione continua, in quanto una nuova versione di OSS potrebbe presentare una vulnerabilità scoperta di recente in qualsiasi momento.</block>
  <block id="db7bc87c89c1ee76d313865a32fc0e06" category="list-text">*Scansione delle vulnerabilità.* lo scopo della scansione delle vulnerabilità è quello di rilevare vulnerabilità di sicurezza comuni e note nei prodotti NetApp prima che vengano rilasciate ai clienti.</block>
  <block id="1a4c104571630526efc77b84e82380fe" category="list-text">Test di penetrazione.* il test di penetrazione è il processo di valutazione di un sistema, di un'applicazione Web o di una rete per individuare le vulnerabilità di sicurezza che potrebbero essere sfruttate da un utente malintenzionato. I test di penetrazione (test delle penne) di NetApp vengono condotti da un gruppo di aziende terze approvate e fidate. Il loro scopo di test include il lancio di attacchi contro un'applicazione o un software simile a intrusi o hacker ostili che utilizzano sofisticati metodi o strumenti di sfruttamento.</block>
  <block id="7e98fc3ea1ec077cfd1727a58e9c9020" category="section-title">Funzionalità di sicurezza del prodotto</block>
  <block id="85d61648687f15050da0b86741b90358" category="paragraph">I tool NetApp ONTAP per VMware vSphere includono le seguenti funzionalità di sicurezza in ogni versione.</block>
  <block id="dff88c2ef0b49b09246ffd6f9ec55195" category="list-text">*Login banner.* SSH è disattivato per impostazione predefinita e consente l'accesso una sola volta, se abilitato dalla console della macchina virtuale. Il seguente banner di accesso viene visualizzato dopo che l'utente ha inserito un nome utente nel prompt di accesso:</block>
  <block id="399875025e8e96cc13102a4dd72f2434" category="paragraph">*ATTENZIONE:* l'accesso non autorizzato a questo sistema è vietato e sarà perseguito dalla legge. Accedendo a questo sistema, l'utente accetta che le proprie azioni possano essere monitorate in caso di sospetto di utilizzo non autorizzato.</block>
  <block id="2d8330ed99c80a842ffbd1362e038e5e" category="paragraph">Una volta completato l'accesso tramite il canale SSH, viene visualizzato il seguente testo:</block>
  <block id="677528ad13d460c058ac50e8a62092cf" category="list-text">*RBAC (role-based access control).* due tipi di controlli RBAC sono associati ai tool ONTAP:</block>
  <block id="ac38773d017495a97d5b88f242578cb8" category="list-text">Privilegi vCenter Server nativi</block>
  <block id="31cedac82fef311cb790a12f96897223" category="list-text">Privilegi specifici del plug-in vCenter. Per ulteriori informazioni, vedere<block ref="e5f6920797dbff91ef59367270a82669" category="inline-link-rx"></block>.</block>
  <block id="5d32469f8a65b884a8f70abf95fe485a" category="list-text">*Canali di comunicazione crittografati.* tutte le comunicazioni esterne avvengono su HTTPS utilizzando la versione 1.2 di TLS.</block>
  <block id="600d4f98483fae8e58054f976d7e0c0e" category="list-text">*Esposizione minima delle porte.* solo le porte necessarie sono aperte sul firewall.</block>
  <block id="0406f8902379502d1eba01f043c232b7" category="paragraph">La seguente tabella descrive i dettagli della porta aperta.</block>
  <block id="69fc9fe9cbb7709e97a433352aecf77d" category="cell">Porta TCP v4/v6 n.</block>
  <block id="02674a4ef33e11c879283629996c8ff8" category="cell">Direzione</block>
  <block id="86408593c34af77fdd90df932f8b5261" category="cell">Funzione</block>
  <block id="0c95054981de037de06e544a52eb3613" category="cell">8143</block>
  <block id="a8e6fe5b9e68f30a146cefebaa7edcc3" category="cell">in entrata</block>
  <block id="d16c4afdc5f340936b747baf91efc843" category="cell">Connessioni HTTPS per API REST</block>
  <block id="5bd529d5b07b647a8863cf71e98d651a" category="cell">8043</block>
  <block id="1f4deeb2f64336d4ff65ea3d2b4ffe2f" category="cell">Connessioni HTTPS</block>
  <block id="cb4b69eb9bd10da82c15dca2f86a1385" category="cell">9060</block>
  <block id="5852f8019b572f4cdef5bab783fa799f" category="cell">Connessioni HTTPS utilizzate per SOAP su connessioni https questa porta deve essere aperta per consentire a un client di connettersi al server API degli strumenti ONTAP.</block>
  <block id="b6d767d2f8ed5d21a44b0e5886680cb9" category="cell">22</block>
  <block id="f4e339608b243f9b57b78ffaf061b498" category="cell">SSH (Disattivato per impostazione predefinita)</block>
  <block id="d82d678e9583c1f5f283ec56fbf1abb7" category="cell">9080</block>
  <block id="ef34781e03f49b5db5dd8fa267c4c41b" category="cell">Connessioni HTTPS - VP e SRA - connessioni interne solo da loopback</block>
  <block id="a44ba9086b2b83ccf2baf7c678723449" category="cell">9083</block>
  <block id="fe01ac95967cd8cb5f5b5669b685277a" category="cell">Connessioni HTTPS - VP e SRA utilizzati per connessioni SOAP su https</block>
  <block id="abea47ba24142ed16b7d8fbf2c740e0d" category="cell">1162</block>
  <block id="4a0724da5c6f4e4817663ae822550800" category="cell">Pacchetti di trap SNMP VP</block>
  <block id="5cce8dede893813f879b873962fb669f" category="cell">1527</block>
  <block id="91c15b8eb529bf2100c10383d1010a1e" category="cell">solo interno</block>
  <block id="60135f95267c6e0711bf5a2858dfff2f" category="cell">Porta del database Derby, solo tra questo computer e se stesso, connessioni esterne non accettate -- solo connessioni interne</block>
  <block id="13f3cf8c531952d72e5847c4183e6910" category="cell">443</block>
  <block id="1ef2b5426b0824e93e33753fa87ddbf5" category="cell">bidirezionale</block>
  <block id="e4b8a8d8761aab7733e317b585d5d606" category="cell">Utilizzato per le connessioni ai cluster ONTAP</block>
  <block id="bf6184406d1e18fffc86ecf770fbb391" category="inline-link">articolo della knowledge base</block>
  <block id="fedac49792829de4ff38fcf7a3846faa" category="list-text">*Supporto dei certificati firmati dall'autorità di certificazione (CA).* i tool ONTAP per VMware vSphere supportano i certificati firmati CA. Vedi questo<block ref="0903a062b2072644a9b744a7fece4216" category="inline-link-rx"></block> per ulteriori informazioni.</block>
  <block id="9fca19988370da2a459b24505e9d23d5" category="list-text">*Registrazione audit.* i pacchetti di supporto possono essere scaricati e sono estremamente dettagliati. ONTAP Tools registra tutte le attività di login e logout degli utenti in un file di log separato. Le chiamate API VASA vengono registrate in un registro di controllo VASA dedicato (cxf.log locale).</block>
  <block id="7d60a2806aedd934b75cce55d6693689" category="list-text">*Criteri per le password.* vengono seguite le seguenti policy per le password:</block>
  <block id="f82f7513742f08b9d2784923213bdc75" category="list-text">Le password non vengono registrate in alcun file di log.</block>
  <block id="83040c348e071499488a8128db207545" category="list-text">Le password non vengono comunicate in testo normale.</block>
  <block id="bc319862df3312f423a50fece7730db9" category="list-text">Le password vengono configurate durante il processo di installazione.</block>
  <block id="853c2ea85b86882d0ea73b606a9800a4" category="list-text">La cronologia delle password è un parametro configurabile.</block>
  <block id="b3d3877bc96752ae50a409c72597d47a" category="list-text">La durata minima della password è impostata su 24 ore.</block>
  <block id="fb0bdec50022a37424a405b53da7c9c8" category="list-text">Il completamento automatico dei campi della password è disattivato.</block>
  <block id="3a04f054be8ad983ea82fd5079519810" category="list-text">Gli strumenti ONTAP crittografano tutte le informazioni sulle credenziali memorizzate utilizzando l'hashing SHA256.</block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="section-title">Cronologia delle versioni</block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">Versione</block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">Data</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">Cronologia delle versioni del documento</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">Versione 1.0</block>
  <block id="62783f5d69cb5d3cb22b077c1d2b8777" category="cell">Novembre 2021</block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">Release iniziale</block>
  <block id="8ce83a5c4c3183c4e25f0d8d7b657ffc" category="summary">Questa pagina fornisce il supporto degli archivi dati NFS nell'ambiente VMware vSphere.</block>
  <block id="3769193a46f06731838a6d904cf1da37" category="doc">Provisioning tradizionale dello storage di file vSphere con ONTAP</block>
  <block id="8d3005420a2cb4cc915402d9c5604538" category="paragraph">VMware vSphere supporta i seguenti protocolli NFS, entrambi compatibili con ONTAP.</block>
  <block id="78aa97ac78d1291969b5893edcfe448a" category="inline-link-macro">NFS versione 3</block>
  <block id="fb110cc4ad992a0846c0eaea7fbf2d94" category="list-text"><block ref="fb110cc4ad992a0846c0eaea7fbf2d94" category="inline-link-macro-rx"></block></block>
  <block id="2d6affbd5ec6eb1f6009383ca5ba9b2b" category="inline-link-macro">NFS versione 4.1</block>
  <block id="3f65d9416139ab7c1ff75966bccf6f7d" category="list-text"><block ref="3f65d9416139ab7c1ff75966bccf6f7d" category="inline-link-macro-rx"></block></block>
  <block id="fc5929c224818a87a89047d2813dd2c5" category="inline-link-macro">Questo confronto tra le versioni dei client NFS</block>
  <block id="ce51dd3c15b8a6638d0c212b990ae643" category="paragraph">Se hai bisogno di aiuto per selezionare la versione NFS corretta per vSphere, controlla <block ref="8055fbd4933fc4c8b583fa212ff14ff2" category="inline-link-macro-rx"></block>.</block>
  <block id="63d5049791d9d79d86e9a108b0a999ca" category="paragraph-title">Riferimento</block>
  <block id="809247403bb2b3e7178b69b038356678" category="inline-link-macro">Caratteristiche del datastore e del protocollo vSphere: NFS</block>
  <block id="0b59976821e81163a037c4ed7f21b209" category="paragraph"><block ref="0b59976821e81163a037c4ed7f21b209" category="inline-link-macro-rx"></block></block>
  <block id="5a44477fe5ac4beac2dc6574097cf079" category="summary">In questa pagina viene illustrata la procedura per l'implementazione di un datastore VMFS iSCSI per lo storage NetApp ONTAP in un ambiente VMware vSphere.</block>
  <block id="6fe85aae6e8fa231a1f417edfeef3759" category="doc">Datastore vSphere VMFS - backend storage iSCSI con ONTAP</block>
  <block id="4f6f7882fc7b858bc0eb3e3a41991494" category="paragraph">In questa sezione viene descritta la creazione di un datastore VMFS con lo storage iSCSI ONTAP.</block>
  <block id="383b1f30f341cb0eff11db96d70e9f50" category="list-text">Le competenze di base necessarie per gestire un ambiente vSphere e ONTAP.</block>
  <block id="47c341511ad626bfba98caeaa0762774" category="list-text">Informazioni su porta di rete ONTAP, SVM e LUN per iSCSI</block>
  <block id="f76f5dc5c6861d7938aa8d60b08976c8" category="inline-link-macro">Un foglio di lavoro di configurazione iSCSI completo</block>
  <block id="275e54409e966e03b62ee630e4856daa" category="list-text"><block ref="275e54409e966e03b62ee630e4856daa" category="inline-link-macro-rx"></block></block>
  <block id="c7e4d06c6b5e45fbb711be2b15976173" category="list-text">Informazioni IP sull'adattatore VMkernel iSCSI</block>
  <block id="9068992a529de63b07b7c2250be12f87" category="list-text">Switch di rete</block>
  <block id="980e76f4fd03b06bfe740133284e92a9" category="list-text">Con porte dati di rete del sistema ONTAP e host vSphere collegati</block>
  <block id="3a6f48cf422509b67592ce2a0b4dd558" category="list-text">VLAN configurate per iSCSI</block>
  <block id="44786c36009327ad04469602f3f96832" category="list-text">(Opzionale) link aggregation configurato per le porte dati di rete ONTAP</block>
  <block id="503023bddb3bd1c7803b35b4ace6aa7a" category="list-text">Tool ONTAP per VMware vSphere implementato, configurato e pronto all'uso</block>
  <block id="f3a29486bed19a90f2da6d007818b427" category="section-title">Fasi</block>
  <block id="881de4e9f9e9dba55f3d9f09d3fc8eac" category="inline-link-macro">Verificare che la configurazione iSCSI sia supportata.</block>
  <block id="6a2fb6d042919f5807315156f926ab10" category="list-text"><block ref="6a2fb6d042919f5807315156f926ab10" category="inline-link-macro-rx"></block></block>
  <block id="e103d9cdc55ef0be25a4fd8054bc28bc" category="list-text">Completare le seguenti attività di ONTAP e vSphere.</block>
  <block id="f04a1b9690234d25ff072d6719666947" category="inline-link-macro">Verificare la licenza ONTAP per iSCSI</block>
  <block id="41bf6980693d9ba9f5e7a797fe2f4417" category="list-text"><block ref="0767ceac1f7ac130ade75fb7fae3fc53" category="inline-link-macro-rx"></block>.</block>
  <block id="3ffc628bd3f213f0998146fb5262f366" category="list-text">Utilizzare<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Comando per verificare se iSCSI è presente nell'elenco.</block>
  <block id="d1b0a5732b3cb229ef0f788fbb095f05" category="list-text">Utilizzare<block ref="b7dcb36bf321df4a59507f6e4d0e13fb" prefix=" " category="inline-code"></block> per aggiungere la licenza.</block>
  <block id="97035bc2443de65f877c3fddd838c6ae" category="inline-link-macro">Verificare che il protocollo iSCSI sia attivato su SVM.</block>
  <block id="3807dbdaab3b890b6a293c99c7b46f63" category="list-text"><block ref="3807dbdaab3b890b6a293c99c7b46f63" category="inline-link-macro-rx"></block></block>
  <block id="cb66a92bc9fa6195f8b2914bcf868664" category="list-text">Verificare che le interfacce logiche di rete iSCSI siano disponibili su SVM.</block>
  <block id="da91d0d17d1f671a0af23e7ebb96ec92" category="admonition">Quando si crea una SVM utilizzando la GUI, vengono create anche le interfacce di rete iSCSI.</block>
  <block id="da6a83da2309e8dbd81bb5b55c7c9602" category="list-text">Utilizzare<block ref="ba500174804680d403063e56bca3cea6" prefix=" " category="inline-code"></block> per visualizzare o apportare modifiche all'interfaccia di rete.</block>
  <block id="53fd22677faa2085c1fc51f1d116faff" category="admonition">Si consigliano due interfacce di rete iSCSI per nodo.</block>
  <block id="69fea75e454b43e67ba176dddb604159" category="inline-link-macro">Creare un'interfaccia di rete iSCSI.</block>
  <block id="1bc0e04873be7c6291aef492ff2785cc" category="list-text"><block ref="d503e168b9096ac416caa1c8f13ab28a" category="inline-link-macro-rx"></block> È possibile utilizzare la policy di servizio default-data-block.</block>
  <block id="bd494b2c15d88a1dfa29c308b39e8f6e" category="inline-link-macro">Verificare che il servizio dati-iscsi sia incluso nella politica di servizio.</block>
  <block id="c436a9a899f5e1cfacf8828c90931ca9" category="list-text"><block ref="24788d985e181b3194881517c2ec7650" category="inline-link-macro-rx"></block> È possibile utilizzare<block ref="4e5efd8167f08c488fa3bc6f718e7db8" prefix=" " category="inline-code"></block> per verificare.</block>
  <block id="c0e1d066d0482fc5cc1554edaa3f36b2" category="inline-link-macro">Verificare che i frame jumbo siano attivati.</block>
  <block id="a355e4512cfabb746ee4c05a87a61107" category="list-text"><block ref="a355e4512cfabb746ee4c05a87a61107" category="inline-link-macro-rx"></block></block>
  <block id="5ccd820a879b8d1daef5e44125431184" category="inline-link-macro">Creare e mappare il LUN.</block>
  <block id="c49b54ab60508b16176724eeb8118049" category="list-text"><block ref="3a73ce9b9237c3e09863bf7b049ce423" category="inline-link-macro-rx"></block> Saltare questo passaggio se si utilizzano i tool ONTAP per VMware vSphere. Ripetere questo passaggio per ogni LUN.</block>
  <block id="5c9b297b088335a8562568dc59549c7d" category="list-text">Verificare che almeno una NIC sia disponibile per la VLAN iSCSI. Due schede di rete sono preferite per migliorare le performance e la tolleranza agli errori.</block>
  <block id="fe9e58c95c20042a4032ef737d6e8400" category="inline-link-macro">Identificare il numero di NIC fisiche disponibili sull'host vSphere.</block>
  <block id="96cf3cacac94299a7630f48f5cf5b7e3" category="list-text"><block ref="96cf3cacac94299a7630f48f5cf5b7e3" category="inline-link-macro-rx"></block></block>
  <block id="87d3329dab6e8f24601b6f45d40614ea" category="inline-link-macro">Configurare iSCSI Initiator.</block>
  <block id="536d7ac288972152b209e6f004917285" category="list-text"><block ref="95a6e2e5fae04247474cdc6a729342fc" category="inline-link-macro-rx"></block> Un caso d'utilizzo tipico è un iniziatore iSCSI software.</block>
  <block id="fd823eb37045485458bb3d5d52ddc46f" category="inline-link-macro">Verificare che lo stack TCPIP per iSCSI sia disponibile</block>
  <block id="875d65383afa504aad11a619d920adc7" category="list-text"><block ref="025b4ff12eca60b6c5b5be76597b5e95" category="inline-link-macro-rx"></block>.</block>
  <block id="e45f6655250b094b5a8370ff511869c3" category="inline-link-macro">Verificare che i portgroup iSCSI siano disponibili</block>
  <block id="4c93429599cf15be2af5aa0f59131c17" category="list-text"><block ref="5e67546a702454fa060946b3e582d0e9" category="inline-link-macro-rx"></block>.</block>
  <block id="b7b554d373b5992838a126134a03ba0d" category="list-text">In genere utilizziamo un singolo switch virtuale con più porte di uplink.</block>
  <block id="879d70f2184599f483fd94f0f274163f" category="list-text">Utilizzare la mappatura dell'adattatore 1:1.</block>
  <block id="9f60e3586ab900b8f879404be003b539" category="list-text">Verificare che gli adattatori VMkernel iSCSI siano abilitati per corrispondere al numero di NIC e che gli IP siano assegnati.</block>
  <block id="3e6e09b1cda3200c7407173a3473a103" category="inline-link-macro">Collegare l'adattatore software iSCSI agli adattatori VMkernel iSCSI.</block>
  <block id="70d687ef257c5d00e0d85844c0101c77" category="list-text"><block ref="70d687ef257c5d00e0d85844c0101c77" category="inline-link-macro-rx"></block></block>
  <block id="187fbd973609969af8f47e857f8579c4" category="inline-link-macro">Eseguire il provisioning del datastore VMFS con gli strumenti ONTAP</block>
  <block id="1e9df60603ff2a9fe2495b189aecc647" category="list-text"><block ref="efecd5d76f6fc92c9c9a8111cf809724" category="inline-link-macro-rx"></block>. Ripetere questo passaggio per tutti gli archivi dati.</block>
  <block id="5f4723c28ea2b13a27b86c1116720a8a" category="inline-link-macro">Verificare il supporto dell'accelerazione hardware.</block>
  <block id="aa0cfa24dd578f0629299a21b453583c" category="list-text"><block ref="aa0cfa24dd578f0629299a21b453583c" category="inline-link-macro-rx"></block></block>
  <block id="58eaebf972358f1cf03d386a4ade1a0f" category="section-title">Quali sono le prossime novità?</block>
  <block id="1d3fa7ee382266d716ba7a360f30f188" category="paragraph">Una volta completate queste attività, il datastore VMFS è pronto per il provisioning delle macchine virtuali.</block>
  <block id="53001b412ce4896686a413a19f6dcc5f" category="listing-title">Ansible Playbook</block>
  <block id="c9b6ad26821d78c27282a65584d5f485" category="summary">NetApp offre numerose Best practice e soluzioni per un ambiente di virtualizzazione solido, sia on-premise che nel cloud.</block>
  <block id="ba64ee63cc4950b57bfb868fabec0db3" category="doc">Soluzioni NetApp per la virtualizzazione</block>
  <block id="50b6e1c7f2e81842d993d8ce88acc979" category="summary">ONTAP supporta tutti i principali protocolli di storage utilizzati per la virtualizzazione, come iSCSI, Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) o non-volatile Memory Express over Fibre Channel (NVMe/FC) per ambienti SAN, oltre a NFS (v3 e v4.1) e SMB o S3 per connessioni guest. I clienti sono liberi di scegliere ciò che funziona meglio per il proprio ambiente e possono combinare i protocolli in base alle esigenze su un singolo sistema.</block>
  <block id="93b698fac9d8f378474fb0765494c4e6" category="doc">Funzionalità ONTAP per vSphere</block>
  <block id="9985b4390c40137573e6da05caf85874" category="section-title">Protocolli</block>
  <block id="d7a198a9254afae95101f5ba8a96e769" category="paragraph">ONTAP supporta tutti i principali protocolli di storage utilizzati per la virtualizzazione, come iSCSI, Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) o non-volatile Memory Express over Fibre Channel (NVMe/FC) per ambienti SAN, oltre a NFS (v3 e v4.1) e SMB o S3 per connessioni guest. I clienti sono liberi di scegliere ciò che funziona meglio per il proprio ambiente e possono combinare i protocolli in base alle esigenze su un singolo sistema. Ad esempio, è possibile aumentare l'utilizzo generale degli archivi dati NFS con alcune LUN iSCSI o condivisioni guest.</block>
  <block id="98f770b0af18ca763421bac22b4b6805" category="section-title">Caratteristiche</block>
  <block id="99dd82c3472eab7ec4ea64a848fe032d" category="paragraph">Esistono molte funzionalità di ONTAP utili per la gestione dei workload virtualizzati. Alcuni che richiedono licenze di prodotto aggiuntive sono descritti nella sezione successiva. Altri strumenti standalone, alcuni per ONTAP e altri per l'intero portfolio NetApp, vengono descritti in seguito.</block>
  <block id="671534601eb09388581f095632f815b2" category="paragraph">Di seguito sono riportati ulteriori dettagli sulle funzionalità ONTAP di base:</block>
  <block id="2df283d70436fd2d0a853af9fae00a91" category="list-text">*Copie Snapshot di NetApp.* ONTAP offre copie Snapshot istantanee di una macchina virtuale o di un datastore senza effetti sulle performance quando si crea o si utilizza una copia Snapshot. Possono essere utilizzati per creare un punto di ripristino per una macchina virtuale prima dell'applicazione delle patch o per una semplice protezione dei dati. Si noti che questi sono diversi dagli snapshot VMware (coerenza). Il modo più semplice per creare una copia Snapshot di ONTAP consiste nell'utilizzare il plug-in SnapCenter per VMware vSphere per eseguire il backup di macchine virtuali e datastore.</block>
  <block id="dbef3659822e80f91a3a561ed6d0b0cd" category="list-text">*Efficienza dello storage.* ONTAP supporta la deduplica e la compressione inline e in background, la deduplica a blocchi zero e la compattazione dei dati.</block>
  <block id="287c4830bc87771bdf2b3ae9880ab67e" category="list-text">*Lo spostamento di volumi e LUN.* consente lo spostamento senza interruzioni di volumi e LUN che supportano datastore e vVol vSphere all'interno del cluster ONTAP per bilanciare performance e capacità o supportare manutenzione e upgrade senza interruzioni.</block>
  <block id="ba96d4d48c1ff15e2732b37e2e7a435c" category="list-text">*QoS.* QoS consente di gestire le performance su un singolo LUN, volume o file. Questa funzione può essere utilizzata per limitare una macchina virtuale sconosciuta o ingombrante o per assicurarsi che una macchina virtuale importante riceva risorse di performance sufficienti.</block>
  <block id="0fed44d392929d099987f70fe23074b4" category="list-text">*NetApp Volume Encryption e NetApp aggregate Encryption.* le opzioni di crittografia NetApp offrono una semplice crittografia basata su software per proteggere i dati inattivi.</block>
  <block id="28f638810590337576cbbe9979329c21" category="list-text">*FabricPool.* questa funzione consente di eseguire automaticamente il Tier dei dati più freddi a livello di blocco in un archivio a oggetti separato, liberando il costoso storage flash.</block>
  <block id="ff8a0108cd7cd5019bfee6b6be672b17" category="inline-link">API REST di ONTAP</block>
  <block id="9455a10ec937dafee664ae1e0e4fd98c" category="inline-link">Moduli Ansible</block>
  <block id="1a4c4db8b74f04b9da9ab150ff36e301" category="list-text">*REST and Ansible.* Use<block ref="71191ff17e34498b2463e6167736896a" category="inline-link-rx"></block> per automatizzare la gestione dello storage e dei dati, e.<block ref="d4fc0de110866702e0b8608590b39b64" category="inline-link-rx"></block> Per la gestione della configurazione dei sistemi ONTAP.</block>
  <block id="86544be11c52b782f03ad1ff879f872d" category="paragraph">Alcune funzionalità di ONTAP non sono adatte per i carichi di lavoro vSphere. Ad esempio, la tecnologia FlexGroup precedente a ONTAP 9.8 non disponeva del supporto completo per la clonazione e non era stata testata con vSphere (consultare la sezione FlexGroup per le ultime informazioni sull'utilizzo con vSphere). Inoltre, la tecnologia FlexCache non è ottimale per vSphere in quanto è progettata per carichi di lavoro in gran parte in lettura. Le scritture possono essere problematiche quando la cache viene disconnessa dall'origine, causando errori del datastore NFS su entrambi i lati.</block>
  <block id="85402a535d923d0511a02d404893d1ba" category="section-title">Licenze ONTAP</block>
  <block id="4a9fdcb14826a67d38a7b84170c54ea9" category="paragraph">Alcune funzionalità di ONTAP utili per la gestione dei carichi di lavoro virtualizzati richiedono una licenza aggiuntiva, disponibile senza costi aggiuntivi, in bundle di licenza o à la carte. Per molti clienti, l'approccio più conveniente è con un bundle di licenze. Di seguito sono riportate le licenze principali relative a vSphere e il loro utilizzo:</block>
  <block id="c598be4d4f9f8c476e7f51d6ef5ff139" category="list-text">*FlexClone.* FlexClone consente cloni istantanei ed efficienti in termini di spazio di volumi e file ONTAP. Questo cloning viene utilizzato quando le operazioni vengono trasferite al sistema storage dalle API di storage VMware vSphere – integrazione array (VAAI), per la verifica e il ripristino del backup (software SnapCenter) e per la clonazione vVol e le copie Snapshot. Ecco come vengono utilizzati:</block>
  <block id="25d6e9f6ac28ecf0d97aaf9f6609f4d4" category="list-text">VAAI è supportato con ONTAP per le copie offloaded a supporto delle operazioni di clone e migrazione vSphere (Storage vMotion). La licenza FlexClone consente cloni veloci all'interno di un volume NetApp FlexVol, ma, se non concessa in licenza, consente comunque l'utilizzo di copie a blocchi più lente.</block>
  <block id="6f9f0acae1b8d33078f1c061dcc662a3" category="list-text">Per la funzionalità vVol è necessaria una licenza FlexClone. Consente la clonazione di vVol all'interno di un singolo datastore o tra datastore e consente copie Snapshot gestite da vSphere dei vVol, che vengono scaricati nel sistema storage.</block>
  <block id="4370ed35c8063100f2a5b8da39b82668" category="list-text">L'adattatore per la replica dello storage (SRA) viene utilizzato con VMware Site Recovery Manager ed è richiesta una licenza FlexClone per testare il ripristino in ambienti NAS e SAN. SRA può essere utilizzato senza FlexClone per i flussi di lavoro di rilevamento, ripristino e protezione.</block>
  <block id="3117cf0d132cfe6180ee3db3d5250f7f" category="list-text">La tecnologia *SnapRestore.* SnapRestore consente il ripristino istantaneo di un volume in uso senza copiare i dati. È richiesto dai tool di backup e ripristino NetApp, ad esempio SnapCenter, dove viene utilizzato per montare il datastore per le operazioni di verifica e ripristino.</block>
  <block id="a30ea87a20e5dd5b267ec41f29219a1d" category="list-text">*SnapMirror.* la tecnologia SnapMirror consente una replica semplice e rapida dei dati tra sistemi ONTAP on-premise e nel cloud. SnapMirror supporta la flessibilità della versione della replica logica con le prestazioni della replica a blocchi, inviando solo i dati modificati al sistema secondario. I dati possono essere protetti con policy di mirroring e/o vault, consentendo il disaster recovery e la conservazione dei dati a lungo termine per il backup. SnapMirror supporta relazioni asincrone e sincrone, mentre ONTAP 9.8 introduce il failover trasparente delle applicazioni con la business continuity di SnapMirror.</block>
  <block id="23862d7fc14d71369b9feaeb8d7f98b9" category="paragraph">SnapMirror è necessario per la replica SRA con Site Recovery Manager. È inoltre necessario che SnapCenter consenta la replica delle copie Snapshot su un sistema storage secondario.</block>
  <block id="0fdef6775eeade832499deceb497e1d8" category="list-text">Il software *SnapCenter.* SnapCenter offre una piattaforma e una suite plug-in unificati e scalabili per la protezione dei dati coerente con l'applicazione e la gestione dei cloni. Una licenza SnapCenter è inclusa nei bundle di licenza per la protezione dei dati per i sistemi AFF e FAS. Il plug-in SnapCenter per VMware vSphere è un prodotto gratuito se si utilizzano i seguenti sistemi storage: FAS, AFF, Cloud Volumes ONTAP o ONTAP Select. Tuttavia, sono richieste le licenze SnapRestore e FlexClone.</block>
  <block id="a20c69bb9262b2ab09ca5248996e7d63" category="list-text">*MetroCluster.* NetApp MetroCluster è una soluzione di replica sincrona che combina alta disponibilità e disaster recovery in un campus o in un'area metropolitana per proteggere da disastri del sito e interruzioni dell'hardware. Fornisce soluzioni con ripristino trasparente da guasti, con nessuna perdita di dati (0 RPO) e ripristino rapido (RTO in pochi minuti). Viene utilizzato negli ambienti vSphere come parte di una configurazione di vSphere Metro Storage Cluster.</block>
  <block id="ee8cc65cae83009c275cd4748f4c58ae" category="section-title">Strumenti di virtualizzazione per ONTAP</block>
  <block id="7b0abbba24b3ff594f013e524b352ef1" category="paragraph">NetApp offre diversi tool software standalone che possono essere utilizzati insieme a ONTAP e vSphere per gestire l'ambiente virtualizzato. I seguenti strumenti sono inclusi con la licenza ONTAP senza costi aggiuntivi. Vedere la Figura 1 per un'illustrazione del funzionamento di questi strumenti nell'ambiente vSphere.</block>
  <block id="ed9018b2e8611a3d2c03bb6a205b9715" category="section-title">Strumenti ONTAP per VMware vSphere</block>
  <block id="f364e3337f5237c93d7b5439c82d444b" category="paragraph">ONTAP Tools per VMware vSphere è un insieme di strumenti per l'utilizzo dello storage ONTAP insieme a vSphere. Il plug-in vCenter, precedentemente noto come Virtual Storage Console (VSC), semplifica le funzionalità di gestione ed efficienza dello storage, migliora la disponibilità e riduce i costi di storage e l'overhead operativo, sia che si utilizzi SAN che NAS. Utilizza le Best practice per il provisioning degli archivi dati e ottimizza le impostazioni degli host ESXi per gli ambienti di storage a blocchi e NFS. Per tutti questi vantaggi, NetApp consiglia di utilizzare questi tool ONTAP come Best practice quando si utilizza vSphere con sistemi che eseguono il software ONTAP. Include un'appliance server, estensioni dell'interfaccia utente per vCenter, VASA Provider e Storage Replication Adapter. Quasi tutto ciò che è contenuto negli strumenti ONTAP può essere automatizzato utilizzando semplici API REST, utilizzabili dalla maggior parte dei moderni strumenti di automazione.</block>
  <block id="0b266371a133b176a2ee883ccf72b46c" category="list-text">Le estensioni dell'interfaccia utente di vCenter.* le estensioni dell'interfaccia utente di ONTAP Tools semplificano il lavoro dei team operativi e degli amministratori di vCenter, integrando menu facili da utilizzare e sensibili al contesto per la gestione di host e storage, portlet informativi e funzionalità di avviso native direttamente nell'interfaccia utente di vCenter per flussi di lavoro semplificati.</block>
  <block id="e08c666b5127e745f8aacbacfce37dcf" category="list-text">*Provider VASA per ONTAP.* il provider VASA per ONTAP supporta il framework VMware vStorage API for Storage Awareness (VASA). Viene fornito come parte dei tool ONTAP per VMware vSphere come singola appliance virtuale per una maggiore facilità di implementazione. IL provider VASA connette vCenter Server a ONTAP per facilitare il provisioning e il monitoraggio dello storage delle macchine virtuali. Consente il supporto di VMware Virtual Volumes (vVol), la gestione dei profili di capacità dello storage e delle performance di VM vVol individuali e gli allarmi per il monitoraggio della capacità e della conformità con i profili.</block>
  <block id="1c7bb8764fc089dda8481678ad1ea0b5" category="list-text">*Storage Replication Adapter.* SRA viene utilizzato insieme a VMware Site Recovery Manager (SRM) per gestire la replica dei dati tra siti di produzione e disaster recovery e testare le repliche DR senza interruzioni. Consente di automatizzare le attività di rilevamento, ripristino e protezione. Include un'appliance server SRA e adattatori SRA per server SRM Windows e appliance SRM.</block>
  <block id="a1c13ec555198266776a3a7b904810dd" category="paragraph">La figura seguente mostra gli strumenti ONTAP per vSphere.</block>
  <block id="f7e876d450acee7c9ed7b18438440fb2" category="paragraph"><block ref="f7e876d450acee7c9ed7b18438440fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dd55e255500b9ec15305dc69dfa0e15b" category="section-title">Plug-in NFS per VMware VAAI</block>
  <block id="eff6699ec911b615a51eb7e9e0d89970" category="paragraph">Il plug-in NetApp NFS per VMware VAAI è un plug-in per gli host ESXi che consente loro di utilizzare le funzionalità VAAI con gli archivi dati NFS su ONTAP. Supporta l'offload delle copie per le operazioni di cloni, la riserva di spazio per i file di dischi virtuali spessi e l'offload delle copie Snapshot. L'offload delle operazioni di copia sullo storage non è necessariamente più veloce da completare, ma riduce i requisiti di larghezza di banda della rete e scarica le risorse host come cicli CPU, buffer e code. È possibile utilizzare i tool ONTAP per VMware vSphere per installare il plug-in sugli host ESXi o, se supportato, vSphere Lifecycle Manager (vLCM).</block>
  <block id="d336a329d910c32fb90337a372f596fc" category="summary">Il software NetApp ONTAP è da quasi vent'anni una soluzione di storage leader per gli ambienti VMware vSphere e continua ad aggiungere funzionalità innovative per semplificare la gestione e ridurre i costi. Questo documento presenta la soluzione ONTAP per vSphere, incluse le informazioni più recenti sui prodotti e le Best practice, per ottimizzare l'implementazione, ridurre i rischi e semplificare la gestione.</block>
  <block id="952fd691754e388c7b7ba473cf410aff" category="doc">TR-4597: VMware vSphere per ONTAP</block>
  <block id="b4191f5f6b40e39be6030dbbc9052330" category="paragraph">Karl Konnerth, NetApp</block>
  <block id="bfa7e7fc7c6bf4cc4e4c5c74b09763eb" category="paragraph">Le Best practice integrano altri documenti come guide ed elenchi di compatibilità. Sono sviluppati in base a test di laboratorio e a un'ampia esperienza sul campo da parte di tecnici e clienti NetApp. Potrebbero non essere le uniche pratiche supportate che funzionano in ogni ambiente, ma sono generalmente le soluzioni più semplici che soddisfano le esigenze della maggior parte dei clienti.</block>
  <block id="737453909be77692f8cfdf08a17cee61" category="inline-link-macro">Informazioni specifiche sulla release di ONTAP e vSphere</block>
  <block id="18b198d3d2381f05dd78bab3c8cec60c" category="paragraph">Questo documento è incentrato sulle funzionalità delle recenti release di ONTAP (9.x) eseguite su vSphere 6.0 o versioni successive. Vedere la sezione <block ref="4c9a6d8ccb9dfca3b5ae6e43e9663c99" category="inline-link-macro-rx"></block> per dettagli relativi a release specifiche.</block>
  <block id="74587fa4ad90f8713c0446529a3670e0" category="section-title">Perché scegliere ONTAP per vSphere?</block>
  <block id="4b401b0a40ae220c77961312c8238cdb" category="paragraph">Decine di migliaia di clienti hanno scelto ONTAP come soluzione di storage per vSphere per diversi motivi, ad esempio un sistema storage unificato che supporta protocolli SAN e NAS, solide funzionalità di protezione dei dati che utilizzano copie Snapshot NetApp efficienti in termini di spazio, e una vasta gamma di strumenti per aiutarti a gestire i dati delle applicazioni. L'utilizzo di un sistema storage separato dall'hypervisor consente di trasferire molte funzioni e massimizzare l'investimento nei sistemi host vSphere. Questo approccio non solo garantisce che le risorse host siano incentrate sui carichi di lavoro delle applicazioni, ma evita anche effetti casuali sulle performance delle applicazioni derivanti dalle operazioni di storage.</block>
  <block id="0f50acddbdbb9aa9712a471f2276e655" category="paragraph">L'utilizzo di ONTAP insieme a vSphere è un'ottima combinazione che consente di ridurre le spese relative all'hardware host e al software VMware. Puoi anche proteggere i tuoi dati a un costo inferiore con performance elevate e costanti. Poiché i carichi di lavoro virtualizzati sono mobili, è possibile esplorare diversi approcci utilizzando Storage vMotion per spostare le macchine virtuali tra datastore VMFS, NFS o vVol, tutti sullo stesso sistema storage.</block>
  <block id="90977175b761542615a11f2b96cc4cbd" category="paragraph">Ecco i fattori chiave che i clienti apprezzano oggi:</block>
  <block id="dc4489aacb3c4d74b8253c49732b73e9" category="list-text">*Storage unificato.* i sistemi che eseguono il software ONTAP sono unificati in diversi modi significativi. In origine, questo approccio si riferiva ai protocolli NAS e SAN e ONTAP continua a essere una piattaforma leader per SAN insieme alla sua forza originale nel NAS. Nel mondo vSphere, questo approccio potrebbe anche significare un sistema unificato per l'infrastruttura di desktop virtuale (VDI) insieme all'infrastruttura di server virtuale (VSI). I sistemi che eseguono il software ONTAP sono in genere meno costosi per VSI rispetto agli array aziendali tradizionali e dispongono tuttavia di funzionalità avanzate di efficienza dello storage per gestire VDI nello stesso sistema. ONTAP unifica inoltre una vasta gamma di supporti storage, da SSD a SATA, e può estenderli facilmente nel cloud. Non è necessario acquistare un flash array per le performance, un SATA array per gli archivi e sistemi separati per il cloud. ONTAP li lega tutti insieme.</block>
  <block id="ec8cd066c60323f007135b1f083b64de" category="list-text">*Virtual Volumes and storage policy-based management.* NetApp è stato un partner di progettazione iniziale con VMware nello sviluppo di vSphere Virtual Volumes (vVol), fornendo input architetturale e supporto iniziale per vVol e VMware vSphere API for Storage Awareness (VASA). Questo approccio non solo ha portato la gestione granulare dello storage delle macchine virtuali a VMFS, ma ha anche supportato l'automazione del provisioning dello storage attraverso la gestione basata su policy dello storage. Questo approccio consente agli architetti dello storage di progettare pool di storage con diverse funzionalità che possono essere facilmente utilizzate dagli amministratori delle macchine virtuali. ONTAP è leader nel settore dello storage in termini di scalabilità vVol, supportando centinaia di migliaia di vVol in un singolo cluster, mentre i vendor di array Enterprise e flash array più piccoli supportano solo diverse migliaia di vVol per array. NetApp sta inoltre guidando l'evoluzione della gestione granulare delle macchine virtuali con funzionalità imminenti a supporto di vVol 3.0.</block>
  <block id="fd5311fb87e61b58d3c3d278df26af4f" category="list-text">*Efficienza dello storage.* sebbene NetApp sia stata la prima a offrire la deduplica per i carichi di lavoro di produzione, questa innovazione non è stata la prima o l'ultima in quest'area. È iniziato con le copie Snapshot di ONTAP, un meccanismo di protezione dei dati efficiente in termini di spazio senza alcun effetto sulle performance, insieme alla tecnologia FlexClone per eseguire istantaneamente copie in lettura/scrittura delle macchine virtuali per la produzione e l'utilizzo del backup. NetApp ha continuato a offrire funzionalità inline, tra cui deduplica, compressione e deduplica a blocchi zero, per eliminare il maggior numero di storage dai costosi SSD. Più di recente, ONTAP ha aggiunto la possibilità di inserire file e operazioni i/o più piccole in un blocco di dischi utilizzando la compattazione. La combinazione di queste funzionalità ha consentito ai clienti di ottenere risparmi fino a 5:1 per VSI e fino a 30:1 per VDI.</block>
  <block id="bb73602f3344c326a7b63c94db24362a" category="list-text">*Cloud ibrido.* sia che venga utilizzato per il cloud privato on-premise, l'infrastruttura di cloud pubblico o un cloud ibrido che combina il meglio di entrambi, le soluzioni ONTAP ti aiutano a costruire il tuo data fabric per ottimizzare e ottimizzare la gestione dei dati. Inizia con i sistemi all-flash dalle performance elevate, quindi accoppiali con sistemi di storage su disco o cloud per la protezione dei dati e il cloud computing. Scegli tra cloud Azure, AWS, IBM o Google per ottimizzare i costi ed evitare il lock-in. Sfrutta il supporto avanzato per le tecnologie OpenStack e container in base alle esigenze. NetApp offre inoltre backup basato sul cloud (SnapMirror Cloud, Cloud Backup Service e Cloud Sync) e tool di archiviazione e tiering dello storage (FabricPool) per ONTAP per ridurre le spese operative e sfruttare l'ampia portata del cloud.</block>
  <block id="0c157ce4e4fd6289dbf0b282993c2f80" category="list-text">*E altro ancora.* sfrutta le performance estreme degli array NetApp AFF Serie A per accelerare l'infrastruttura virtualizzata e gestire i costi. Operazioni senza interruzioni, dalla manutenzione agli aggiornamenti fino alla sostituzione completa del sistema storage, utilizzando cluster ONTAP scale-out. Proteggi i dati inattivi con le funzionalità di crittografia NetApp senza costi aggiuntivi. Assicurati che le performance soddisfino i livelli di servizio di business grazie a funzionalità di qualità dei servizi. Fanno tutti parte dell'ampia gamma di funzionalità offerte da ONTAP, il software per la gestione dei dati aziendali leader del settore.</block>
  <block id="dcaf091737df278b1b4bdd2e37c10a75" category="summary">NetApp ONTAP è stata una soluzione storage leader per gli ambienti VMware vSphere sin dalla sua introduzione nel moderno data center nel 2002 e continua ad aggiungere funzionalità innovative per semplificare la gestione riducendo i costi.</block>
  <block id="1fdf67ffe178876efb8b8cacfb0f052b" category="doc">TR-4900: VMware Site Recovery Manager con NetApp ONTAP 9</block>
  <block id="cc6ab3d11d2dc330a573866f7c9f67aa" category="paragraph">Chance Bingen, NetApp</block>
  <block id="60398bdc931fc67a9b6d781434c3a15a" category="section-title">ONTAP per vSphere</block>
  <block id="09d6c6a1868cc36795c7a0f8f84e50c9" category="paragraph">NetApp ONTAP è stata una soluzione storage leader per gli ambienti VMware vSphere sin dalla sua introduzione nel moderno data center nel 2002 e continua ad aggiungere funzionalità innovative per semplificare la gestione riducendo i costi. Questo documento presenta la soluzione ONTAP per VMware Site Recovery Manager (SRM), il software di disaster recovery (DR) leader di settore di VMware, che include le informazioni più recenti sui prodotti e le Best practice per ottimizzare l'implementazione, ridurre i rischi e semplificare la gestione continua.</block>
  <block id="e3445c3aa798f5ad98665e33d34dd952" category="paragraph">Le Best practice integrano altri documenti come guide e strumenti di compatibilità. Sono sviluppati in base a test di laboratorio e a un'ampia esperienza sul campo da parte di tecnici e clienti NetApp. In alcuni casi, le Best practice consigliate potrebbero non essere adatte al tuo ambiente; tuttavia, sono generalmente le soluzioni più semplici che soddisfano le esigenze della maggior parte dei clienti.</block>
  <block id="c40f8c2af56356193284f6b46865d954" category="section-title">Perché utilizzare ONTAP con SRM?</block>
  <block id="3c41d5be62c97a13079e9c7abf078292" category="paragraph">Le piattaforme di gestione dei dati NetApp basate sul software ONTAP sono alcune delle soluzioni di storage più diffuse per SRM. I motivi sono molteplici: Una piattaforma di gestione dei dati sicura, ad alte performance, con protocollo unificato (NAS e SAN insieme) che offre efficienza dello storage, multi-tenancy, qualità dei controlli dei servizi, protezione dei dati con copie Snapshot efficienti in termini di spazio e replica con SnapMirror. Tutto questo sfrutta l'integrazione multi-cloud ibrida nativa per la protezione dei carichi di lavoro VMware e una vasta gamma di strumenti di automazione e orchestrazione a portata di mano.</block>
  <block id="0d573b6a27c08499fee406e3db49812f" category="paragraph">Quando si utilizza SnapMirror per la replica basata su array, è possibile sfruttare una delle tecnologie ONTAP più collaudate e avanzate. SnapMirror offre il vantaggio di trasferimenti di dati sicuri ed altamente efficienti, copiando solo i blocchi di file system modificati, non intere macchine virtuali o datastore. Anche questi blocchi sfruttano il risparmio di spazio, come deduplica, compressione e compattazione. I moderni sistemi ONTAP utilizzano ora SnapMirror indipendente dalla versione, consentendo di scegliere i cluster di origine e di destinazione in modo flessibile. SnapMirror è diventato uno dei tool più potenti disponibili per il disaster recovery.</block>
  <block id="36b04390d6103d8075862e4b825a485e" category="paragraph">Sia che stiate utilizzando datastore collegati a NFS, iSCSI o Fibre Channel tradizionali (ora con supporto per datastore vVol), SRM offre una solida offerta di prima parte che sfrutta il meglio delle funzionalità ONTAP per il disaster recovery o la pianificazione e l'orchestrazione della migrazione dei data center.</block>
  <block id="5d111e8a6885460b43ecf1f7abb6377e" category="section-title">In che modo SRM sfrutta ONTAP 9</block>
  <block id="16d4ec242c9f020f3a1fade311c776ed" category="paragraph">SRM sfrutta le tecnologie avanzate di gestione dei dati dei sistemi ONTAP integrandosi con i tool ONTAP per VMware vSphere, un'appliance virtuale che include tre componenti principali:</block>
  <block id="d54038ba1f2a04a5b5f26c96627ae3e7" category="list-text">Il plug-in vCenter, precedentemente noto come Virtual Storage Console (VSC), semplifica le funzionalità di gestione ed efficienza dello storage, migliora la disponibilità e riduce i costi di storage e l'overhead operativo, sia che si utilizzi SAN che NAS. Utilizza le Best practice per il provisioning degli archivi dati e ottimizza le impostazioni degli host ESXi per gli ambienti di storage a blocchi e NFS. Per tutti questi vantaggi, NetApp consiglia questo plug-in quando si utilizza vSphere con sistemi che eseguono il software ONTAP.</block>
  <block id="a106bb15d6dc2b11535ed4fefc81fbf4" category="list-text">Il provider VASA per ONTAP supporta il framework VMware vStorage API for Storage Awareness (VASA). IL provider VASA connette vCenter Server a ONTAP per facilitare il provisioning e il monitoraggio dello storage delle macchine virtuali. Consente il supporto di VMware Virtual Volumes (vVol) e la gestione dei profili di capacità dello storage (incluse le funzionalità di replica di vVol) e delle performance di VM vVol individuali. Fornisce inoltre allarmi per il monitoraggio della capacità e della conformità con i profili. Se utilizzato in combinazione con SRM, il provider VASA per ONTAP consente il supporto delle macchine virtuali basate su vVol senza richiedere l'installazione di un adattatore SRA sul server SRM.</block>
  <block id="f2007951062862f5f0d593acbb23bcb4" category="list-text">SRA viene utilizzato insieme a SRM per gestire la replica dei dati delle macchine virtuali tra siti di produzione e disaster recovery per datastore VMFS e NFS tradizionali e per il test senza interruzioni delle repliche DR. Consente di automatizzare le attività di rilevamento, ripristino e protezione. Include un'appliance server SRA e adattatori SRA per server SRM Windows e appliance SRM.</block>
  <block id="8ccaa60ee78ecc93c4870b3b2ad15284" category="paragraph">Dopo aver installato e configurato gli adattatori SRA sul server SRM per proteggere gli archivi dati non vVols e/o aver abilitato la replica vVols nelle impostazioni del provider VASA, è possibile iniziare l'attività di configurazione dell'ambiente vSphere per il disaster recovery.</block>
  <block id="0a1e25166326359cd5f50d0ab83e6a37" category="paragraph">I provider SRA e VASA offrono un'interfaccia di controllo e comando per il server SRM per gestire i FlexVol ONTAP che contengono le macchine virtuali VMware e la replica SnapMirror che li protegge.</block>
  <block id="38db855935949f86c5db7bfe7d49873e" category="paragraph">A partire da SRM 8.3, nel server SRM è stato introdotto un nuovo percorso di controllo SRM vVols Provider, che consente di comunicare con il server vCenter e, attraverso di esso, con il provider VASA senza la necessità di un SRA. Ciò ha consentito al server SRM di sfruttare un controllo molto più approfondito sul cluster ONTAP rispetto a quanto era possibile in precedenza, perché VASA offre un'API completa per un'integrazione strettamente accoppiata.</block>
  <block id="53e971f0dfb3ef96ca359dcb648176b9" category="paragraph">SRM è in grado di testare il piano di disaster recovery senza interruzioni utilizzando la tecnologia proprietaria FlexClone di NetApp per creare cloni quasi istantanei degli archivi dati protetti presso il sito di disaster recovery. SRM crea un sandbox per eseguire test in modo sicuro in modo che la tua organizzazione e i tuoi clienti siano protetti in caso di disastro reale, offrendo la sicurezza della capacità delle organizzazioni di eseguire un failover durante un disastro.</block>
  <block id="04a8f82007ed4bec45053912a49b6f85" category="paragraph">In caso di disastro reale o persino di migrazione pianificata, SRM consente di inviare eventuali modifiche dell'ultimo minuto al dataset tramite un aggiornamento finale di SnapMirror (se si sceglie di farlo). Quindi, interrompe il mirror e monta il datastore sugli host DR. A questo punto, le VM possono essere alimentate automaticamente in qualsiasi ordine in base alla strategia prepianificata.</block>
  <block id="b2560426a08ae6ceb167dad2bfb5e8ae" category="section-title">SRM con ONTAP e altri casi di utilizzo: Cloud ibrido e migrazione</block>
  <block id="ed4c730bd8636c27d3eaa876c63b3d45" category="inline-link">Storage privato NetApp in Equinix</block>
  <block id="b422e05bc5c6f52208b66ff51d718b9d" category="paragraph">L'integrazione dell'implementazione SRM con le funzionalità avanzate di gestione dei dati di ONTAP consente di migliorare notevolmente scalabilità e performance rispetto alle opzioni di storage locale. Ma oltre a questo, offre la flessibilità del cloud ibrido. Il cloud ibrido ti consente di risparmiare denaro tiering dei blocchi di dati inutilizzati dal tuo array dalle performance elevate all'hyperscaler preferito utilizzando FabricPool, che potrebbe essere un store S3 on-premise come NetApp StorageGRID. È inoltre possibile utilizzare SnapMirror per sistemi edge con software-defined ONTAP Select o DR basata su cloud utilizzando Cloud Volumes ONTAP (CVO) o.<block ref="37a666d3a37f1c4a8c4c8dba379664a4" category="inline-link-rx"></block> Per Amazon Web Services (AWS), Microsoft Azure e Google Cloud Platform (GCP) per creare uno stack di storage, networking e servizi di calcolo completamente integrato nel cloud.</block>
  <block id="10ae334f731d3c4fabafa8017f7a3ab2" category="paragraph">È quindi possibile eseguire il failover di test all'interno del data center di un provider di servizi cloud con un impatto dello storage quasi nullo grazie a FlexClone. Proteggere la tua organizzazione può ora costare meno che mai.</block>
  <block id="12d0cbcf61df7df30bf9b020f6fbb051" category="paragraph">SRM può anche essere utilizzato per eseguire migrazioni pianificate sfruttando SnapMirror per trasferire in modo efficiente le macchine virtuali da un data center all'altro o anche all'interno dello stesso data center, sia esso il tuo, o tramite un numero qualsiasi di partner service provider NetApp.</block>
  <block id="963739e9818c0bf4d8959b5cdf6a7956" category="summary">Il flusso di lavoro all'interno di SRM è significativamente diverso quando si utilizza la replica vVol da quello utilizzato con SRA e datastore tradizionali.</block>
  <block id="56687c1a324f03f5d1429500efea710e" category="doc">Risoluzione dei problemi di SRM quando si utilizza la replica vVol</block>
  <block id="14acf40cbe69d8682b4c844ac7fbf7f6" category="paragraph">Il flusso di lavoro all'interno di SRM è significativamente diverso quando si utilizza la replica vVol da quello utilizzato con SRA e datastore tradizionali. Ad esempio, non esiste alcun concetto di gestore di array. In quanto tale,<block ref="0ec64480a9620a1430c0ae1b6603ea01" prefix=" " category="inline-code"></block> e.<block ref="ba6c59072f543cb828e47d5bac560371" prefix=" " category="inline-code"></block> i comandi non vengono mai visualizzati.</block>
  <block id="ef74d715544e3b067a6bec3218ac5044" category="paragraph">Durante la risoluzione dei problemi, è utile comprendere i nuovi flussi di lavoro, elencati di seguito:</block>
  <block id="47f0942d341ee10381b2eff35089d75d" category="list-text">QueryReplicationPeer: Rileva gli accordi di replica tra due domini di errore.</block>
  <block id="136a299aae29998a147852cb0cba5b4a" category="list-text">QueryFaultDomain: Rileva la gerarchia di dominio di errore.</block>
  <block id="c071098c5df923c31f6245e4db2f3861" category="list-text">QueryReplicationGroup: Consente di individuare i gruppi di replica presenti nei domini di origine o di destinazione.</block>
  <block id="792cfe9ad3a3dc8528080a262e92989a" category="list-text">SyncReplicationGroup: Sincronizza i dati tra origine e destinazione.</block>
  <block id="39afb1e1e3b180a6230e07bb8571667e" category="list-text">QueryPointInTimeReplica: Consente di rilevare le repliche point-in-time di una destinazione.</block>
  <block id="9fb25fe2ff084dc9ccfb99eaccba7212" category="list-text">TestFailoverReplicationGroupStart: Avvia il failover del test.</block>
  <block id="bd4e1dacaca4c37a53b5286b6ae0239d" category="list-text">TestFailoverReplicationGroupStop: Termina il failover del test.</block>
  <block id="887f376a43cf9de1d6e14a8d69e588f6" category="list-text">PromoteReplicationGroup: Promuove un gruppo attualmente in fase di test in produzione.</block>
  <block id="17ab16c5c0786ff381e6a085318bad9b" category="list-text">PrepareFailoverReplicationGroup: Prepara per un disaster recovery.</block>
  <block id="665dd64ebcc4016bda94e0e8020d8c8e" category="list-text">FailoverReplicationGroup: Esegue il disaster recovery.</block>
  <block id="6936cf00e30b7cd4421225113a023c3e" category="list-text">ReverseReplicateGroup: Avvia la replica inversa.</block>
  <block id="61ac8950a043e6998b458d4f8171154c" category="list-text">QueryMatchingContainer: Trova i container (insieme agli host o ai gruppi di replica) che potrebbero soddisfare una richiesta di provisioning con una determinata policy.</block>
  <block id="05c9efdc056d2af4640bc441ab61b53a" category="list-text">QueryResourceMetadata: Rileva i metadati di tutte le risorse dal provider VASA, l'utilizzo delle risorse può essere restituito come risposta alla funzione QueryMatchingContainer.</block>
  <block id="01fa56986f885c588b1be8c206623de8" category="paragraph">L'errore più comune riscontrato durante la configurazione della replica di vVol è il mancato rilevamento delle relazioni di SnapMirror. Ciò si verifica perché i volumi e le relazioni di SnapMirror vengono creati al di fuori dell'ambito di applicazione degli strumenti ONTAP. Pertanto, è consigliabile assicurarsi sempre che la relazione di SnapMirror sia completamente inizializzata e che sia stata eseguita una riscoperta negli strumenti ONTAP in entrambi i siti prima di tentare di creare un datastore vVol replicato.</block>
  <block id="ce4df831657d2621e80bbef9271c33cd" category="summary">Con la transizione dall'appliance virtuale legacy, gli strumenti ONTAP offrono una vasta gamma di nuove funzionalità, limiti più elevati e nuovo supporto vVol.</block>
  <block id="45b1565c472fff4046d0f7ddbe1342f2" category="doc">Nuove funzionalità con gli strumenti SRM e ONTAP</block>
  <block id="116d20fc387d73c8e4a86e7998913947" category="section-title">Ultime versioni di vSphere e Site Recovery Manager</block>
  <block id="96ca6fcc2ffdab3c06d0875be8d4fe29" category="paragraph">NetApp ha condiviso una partnership profonda con VMware da quasi vent'anni e si impegna a fornire il supporto per le ultime release il più presto possibile. Consulta sempre il tool per la matrice di interoperabilità NetApp (IMT) per scoprire le più recenti combinazioni di software qualificate.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">qui</block>
  <block id="63fe9875fcf8108a4dca29a0795d8674" category="paragraph">NetApp IMT è disponibile<block ref="dd81e3609a71c92c2a90d9165ca7bb00" category="inline-link-rx"></block>.</block>
  <block id="23a6222620917211381cf4455d9e0a83" category="section-title">Supporto di vVol (e perché SPBM è importante, anche con SRM)</block>
  <block id="4567f5576b4577c63b126cac3f6aa5fa" category="paragraph">Uno dei vantaggi di questa architettura è che un SRA non è più necessario, poiché tutto viene gestito tramite VASA.</block>
  <block id="e04031e1cecdb6732f91d44b204dbcf3" category="paragraph">SPBM è un potente strumento della toolbox vSphere che consente servizi di storage semplificati, prevedibili e coerenti per l'utilizzo da parte dei framework di automazione in ambienti cloud privati e ibridi. Fondamentalmente, SPBM consente di definire le classi di servizio che soddisfano le esigenze della vostra base clienti diversificata. SRM consente ora di esporre le funzionalità di replica ai clienti per i carichi di lavoro critici che richiedono un'efficace orchestrazione e automazione del disaster recovery standard di settore.</block>
  <block id="6f1ad7cac2af0e3b92a3936efc393a0e" category="paragraph"><block ref="6f1ad7cac2af0e3b92a3936efc393a0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="925c477f139cce0692e13946a7f75eac" category="paragraph">I server SRM basati su sistema operativo Photon sono ora supportati, oltre alle piattaforme legacy basate su Windows.</block>
  <block id="62c2c4203aebe081ddbc6cdd489f8ad7" category="paragraph">È ora possibile installare gli adattatori SRA indipendentemente dal tipo di server SRM preferito.</block>
  <block id="7cb1700928c008eb817bc79250cc9002" category="section-title">Supporto per IPv6</block>
  <block id="ea9aacd1495949730de8eeab11e66459" category="paragraph">IPv6 è ora supportato con le seguenti limitazioni:</block>
  <block id="d6d7f3d43de975c07655ebba1936867a" category="list-text">VCenter 6.7 o versione successiva</block>
  <block id="eb26ee1a20fe3dbde98204ec8b3ab838" category="list-text">Non supportato con SRM 8.2 (8.1, 8.3 e 8. 4 sono supportati)</block>
  <block id="918d32b75f0ab883abba3a8dc0c3ae8d" category="inline-link">Tool di matrice di interoperabilità</block>
  <block id="02e7e71042609d3158020ab7befe45c6" category="list-text">Controllare<block ref="218f4ad7153f69cdc5467065434cd2f0" category="inline-link-rx"></block> per le ultime versioni qualificate.</block>
  <block id="e887aed8f9c3dbecd37e8896d96b6637" category="section-title">Performance migliorate</block>
  <block id="bd403c539a0c414afacd7477bf3d311f" category="list-text">*Supporto per operazioni simultanee di risproteggere.* introdotto per la prima volta in SRA 9.7.1, questa funzionalità consente di eseguire la risproteggere su due o più piani di ripristino contemporaneamente, riducendo così il tempo necessario per la risproteggere i datastore dopo un failover o una migrazione e rimanendo all'interno dei parametri RTO e RPO.</block>
  <block id="f63b947f655a5aee2cf69d4f30d7f96b" category="list-text">*Strumenti ONTAP 9.8 aggiunge una nuova modalità ottimizzata solo NAS.* quando si utilizzano account con ambito SVM e connessioni a cluster ONTAP con solo datastore basati su NFS, è possibile abilitare la modalità ottimizzata solo NAS per le massime performance negli ambienti supportati.</block>
  <block id="4a4842d7448ef71eb69b013e560b18bb" category="section-title">Maggiore scalabilità</block>
  <block id="26738e8d40ae8035805f13bdbf185c30" category="paragraph">Gli strumenti ONTAP SRA possono ora supportare fino a 500 gruppi di protezione (PG) se utilizzati con SRM 8.3 e versioni successive.</block>
  <block id="b56265ceb6311e42003e668438136a59" category="section-title">Replica sincrona</block>
  <block id="96cb4d41ca97bd9d3d446984d3170a57" category="paragraph">Una nuova funzionalità attesa da tempo e molto attesa è SnapMirror Synchronous (SM-S) con ONTAP 9.5 e versioni successive, che offre una soluzione di replica dei dati zero RPO granulare per le applicazioni mission-critical. SM-S richiede gli strumenti ONTAP 9.8 o versioni successive.</block>
  <block id="b9832b10a87d0c3793ed3b413ee1d839" category="section-title">Supporto API REST</block>
  <block id="0065ce57adc813187a8e9c640ba6223a" category="paragraph">La configurazione del server SRA può ora essere gestita dalle API REST. È stata aggiunta un'interfaccia utente Swagger per facilitare la creazione dei flussi di lavoro di automazione, disponibile sull'appliance ONTAP Tools all'indirizzo<block ref="579ce3ee0a7c1521f3dce6a507ea64a0" prefix=" " category="inline-code"></block>.</block>
  <block id="7be2e69e5d19c282db8d81c60a51c862" category="summary">Questa pagina descrive le Best practice per l'implementazione di una soluzione di storage NetApp ONTAP in un ambiente VMware vSphere.</block>
  <block id="d3ba101543fc97ba1dd9272c87bf65da" category="doc">Virtual Volumes (vVol) e Storage Policy Based Management (SPBM)</block>
  <block id="25e09c324ad3c89ee3aa01454fce14cd" category="section-title">A proposito di vVol e SPBM</block>
  <block id="ab3304a5226d57b9bcaf0c7b3f819735" category="paragraph">NetApp è stato un primo partner di progettazione di VMware nello sviluppo di vVol (vSphere Virtual Volumes), fornendo input architetturale e supporto iniziale per vVol e API VMware vSphere per la consapevolezza dello storage (VASA). Questo approccio non solo ha portato la gestione granulare dello storage delle macchine virtuali a VMFS, ma ha anche supportato l'automazione del provisioning dello storage attraverso la gestione basata su policy di storage (SPBM).</block>
  <block id="ce09fc365ce48a9d89c0fdb5222c3909" category="paragraph">SPBM fornisce un framework che funge da layer di astrazione tra i servizi di storage disponibili per l'ambiente di virtualizzazione e gli elementi di storage sottoposti a provisioning tramite policy. Questo approccio consente agli architetti dello storage di progettare pool di storage con diverse funzionalità che possono essere facilmente utilizzate dagli amministratori delle macchine virtuali. Gli amministratori possono quindi associare i requisiti di carico di lavoro delle macchine virtuali ai pool di storage con provisioning, consentendo un controllo granulare delle varie impostazioni a livello di macchina virtuale o disco virtuale.</block>
  <block id="2902acda09b9786460c2dd928a2d8f1a" category="paragraph">ONTAP è leader nel settore dello storage in termini di scalabilità vVol, supportando centinaia di migliaia di vVol in un singolo cluster, mentre i vendor di array Enterprise e flash array più piccoli supportano solo diverse migliaia di vVol per array. NetApp sta inoltre guidando l'evoluzione della gestione granulare delle macchine virtuali con funzionalità imminenti a supporto di vVol 3.0.</block>
  <block id="fda9c21a4aefd4a1f42ad0b195e6ef0a" category="inline-link">TR-4400: Volumi virtuali VMware vSphere con ONTAP</block>
  <block id="69173613658292fc2adeb513b12f29ca" category="admonition">Per ulteriori informazioni su VMware vSphere Virtual Volumes, SPBM e ONTAP, vedere<block ref="354226c2546b1aed39f1c0c484e6a98a" category="inline-link-rx"></block>.</block>
  <block id="fa7b524ea902bff51145e4279b653d84" category="summary">Questa pagina fornisce un'introduzione a video ed esercitazioni.</block>
  <block id="6309162dffb4a082a2a106613c448e9f" category="doc">Video e demo su cloud ibrido, virtualizzazione e container</block>
  <block id="ccf0b7773e492df3e851d36b689b69b1" category="paragraph">Guarda i seguenti video e demo che illustrano le funzionalità specifiche delle soluzioni di cloud ibrido, virtualizzazione e container.</block>
  <block id="2ffe7358ce461fb4d630742ed966cf0b" category="example-title">Strumenti NetApp ONTAP per VMware vSphere</block>
  <block id="f83bc0ebbeff6798c7394f8638db2695" category="example-title">Strumenti ONTAP per VMware - Panoramica</block>
  <block id="f1d501df2ff1e67b18b06eedd1bad6e8" category="example-title">Provisioning di archivi dati VMware iSCSI con ONTAP</block>
  <block id="a5e8a94cc8a28008eb4e2e719f658780" category="example-title">Provisioning di archivi dati VMware NFS con ONTAP</block>
  <block id="e78afc9f7bd61b3284539108287c91ca" category="example-title">VMware Cloud su AWS con AWS FSX per NetApp ONTAP</block>
  <block id="d69c8ea377286ab60d47066fa2946919" category="example-title">Storage connesso guest Windows con FSX ONTAP utilizzando iSCSI</block>
  <block id="113249c2329945af0bbbc9830088e9ea" category="example-title">Storage connesso guest Linux con FSX ONTAP con NFS</block>
  <block id="6f605e77e59dfe45ae918965ba0bd336" category="example-title">Risparmi sul TCO di VMware Cloud su AWS con Amazon FSX per NetApp ONTAP</block>
  <block id="638eb9310db06d086fac0c3c069669af" category="example-title">Archivio dati supplementare VMware Cloud su AWS con Amazon FSX per NetApp ONTAP</block>
  <block id="9de15a07d3a8b75e451c50d7fa64fae9" category="example-title">Azure servizi VMware su Azure con Azure NetApp Files (ANF)</block>
  <block id="62766d3266d403114a010bc02e7b4004" category="example-title">Panoramica del datastore supplementare della soluzione VMware Azure con Azure NetApp Files</block>
  <block id="4864ff1c07b9b500fd46c4a1c5918fd8" category="example-title">Soluzione VMware Azure DR con Cloud Volumes ONTAP, SnapCenter e JetStream</block>
  <block id="3390e3575b3e341afa2b7172ff5b33a7" category="example-title">Plug-in SnapCenter per VMware vSphere</block>
  <block id="7dcf4233280fcc0e80d2c5b8ce82af91" category="paragraph">Il software NetApp SnapCenter è una piattaforma aziendale di facile utilizzo per coordinare e gestire in modo sicuro la protezione dei dati tra applicazioni, database e file system.</block>
  <block id="7dc8c97b0d6d3055290baa0eb36dbfa5" category="paragraph">Il plug-in SnapCenter per VMware vSphere consente di eseguire operazioni di backup, ripristino e collegamento per macchine virtuali e operazioni di backup e montaggio per datastore registrati con SnapCenter direttamente in VMware vCenter.</block>
  <block id="00389b40803806e30e1877e1a0469e22" category="inline-link-macro">Panoramica del plug-in NetApp SnapCenter per VMware vSphere</block>
  <block id="ab5efb952cd51767fdde3f548f7d3f18" category="paragraph">Per ulteriori informazioni sul plug-in NetApp SnapCenter per VMware vSphere, consultare la <block ref="39b49e6fd504a137658d6db31d129abd" category="inline-link-macro-rx"></block>.</block>
  <block id="05799bad32c5bd80547efe4144fb57af" category="example-title">Plug-in SnapCenter per VMware vSphere - prerequisiti della soluzione</block>
  <block id="47d7646bd1c6577d907ac316431ae609" category="example-title">Plug-in SnapCenter per VMware vSphere - implementazione</block>
  <block id="11d13047d237d5bccdd941bafda45d9d" category="example-title">Plug-in SnapCenter per VMware vSphere - flusso di lavoro di backup</block>
  <block id="16bbc152851c33a02fcac2fbf943ffee" category="example-title">Plug-in SnapCenter per VMware vSphere - flusso di lavoro di ripristino</block>
  <block id="305f1daa74a8ec01eaf0ce2c9a8ce355" category="example-title">SnapCenter - flusso di lavoro di ripristino SQL</block>
  <block id="4267881eb271396086a3cc1387da9a3a" category="example-title">NetApp con VMware Tanzu</block>
  <block id="2dd739333b022cfeccd93e19c8c39d83" category="paragraph">VMware Tanzu consente ai clienti di implementare, amministrare e gestire il proprio ambiente Kubernetes tramite vSphere o VMware Cloud Foundation. Questo portfolio di prodotti VMware consente ai clienti di gestire tutti i cluster Kubernetes pertinenti da un singolo piano di controllo scegliendo l'edizione VMware Tanzu più adatta alle loro esigenze.</block>
  <block id="f8d0723a562ed498a977795477b75cb0" category="inline-link">Panoramica di VMware Tanzu</block>
  <block id="2d3e9ef8ae693e8ff80c4d6e70f0a876" category="paragraph">Per ulteriori informazioni su VMware Tanzu, consultare<block ref="1951d4038519ab642a1c0f8898cecfe0" category="inline-link-rx"></block>. Questa recensione illustra i casi d'utilizzo, le aggiunte disponibili e molto altro ancora su VMware Tanzu.</block>
  <block id="526cee55e2936716b5481f8a933bd217" category="inline-link">Come utilizzare vVol con NetApp e VMware Tanzu Basic, parte 1</block>
  <block id="31c49b154032d3d6039542b651e0f3d4" category="list-text"><block ref="31c49b154032d3d6039542b651e0f3d4" category="inline-link-rx"></block></block>
  <block id="2e933c421900ce4ed68883bfdf00a487" category="inline-link">Come utilizzare vVol con NetApp e VMware Tanzu Basic, parte 2</block>
  <block id="fcf1189eaf4e4e32d27ee5174d63ae3c" category="list-text"><block ref="fcf1189eaf4e4e32d27ee5174d63ae3c" category="inline-link-rx"></block></block>
  <block id="4c1c4ad5c7782eafb30ad4704dbf4419" category="inline-link">Come utilizzare vVol con NetApp e VMware Tanzu Basic, parte 3</block>
  <block id="5963b1ea39cb7cc8a0a4f5ce7c5ef816" category="list-text"><block ref="5963b1ea39cb7cc8a0a4f5ce7c5ef816" category="inline-link-rx"></block></block>
  <block id="20cf4402cce1622d010e58ef54b0c753" category="example-title">NetApp con Red Hat OpenShift</block>
  <block id="0454c59b86dfb678c92c2c7480958d1c" category="paragraph">Red Hat OpenShift, una piattaforma Kubernetes aziendale, consente di eseguire applicazioni basate su container con una strategia di cloud ibrido aperto. Disponibile come servizio cloud sui principali cloud pubblici o come software autogestiti, Red Hat OpenShift offre ai clienti la flessibilità di cui hanno bisogno per progettare la propria soluzione basata su container.</block>
  <block id="2426b725f5be26f50931584ae804c2eb" category="inline-link">Panoramica di Red Hat OpenShift</block>
  <block id="ad973740d0b3378d367abba8a74a610e" category="paragraph">Per ulteriori informazioni su Red Hat OpenShift, consulta questo articolo<block ref="dc6de73076240cafa99651f2d6acfef4" category="inline-link-rx"></block>. Puoi anche consultare la documentazione del prodotto e le opzioni di implementazione per saperne di più su Red Hat OpenShift.</block>
  <block id="3699cb747ce71b2fed488fef61ad35be" category="inline-link">Migrazione dei workload - Red Hat OpenShift con NetApp</block>
  <block id="ade88b04ec62ed28eb857e48bc32cef5" category="list-text"><block ref="ade88b04ec62ed28eb857e48bc32cef5" category="inline-link-rx"></block></block>
  <block id="68d13ef3d87e892878a6e6cbb44d1f21" category="inline-link">Red Hat OpenShift Deployment on RHV: Red Hat OpenShift con NetApp</block>
  <block id="a2f2cd3053597e34724347a57620122b" category="list-text"><block ref="a2f2cd3053597e34724347a57620122b" category="inline-link-rx"></block></block>
  <block id="02d4482d332e1aef3437cd61c9bcc624" category="doc">Contattaci</block>
  <block id="3dd3a0a8eebc543e239dc4af5d76b322" category="paragraph">Hai commenti su questo report tecnico?</block>
  <block id="3c48757505a122bf371d1bf0105b6871" category="paragraph">Inviateli all'indirizzo doccomments@netapp.com e includete TR-4597 nella riga dell'oggetto.</block>
  <block id="93ac3f76e97265952e309b2cbb980030" category="summary">In questa pagina viene illustrata la procedura per l'implementazione di un datastore NetApp ONTAP NFS versione 4 in un ambiente VMware vSphere.</block>
  <block id="11bbb95c80fd3935828f1472bade3ae4" category="doc">Archivio dati vSphere NFS - versione 4.1 con ONTAP</block>
  <block id="0a339846bb9d45c2252cf84f27f8390e" category="paragraph">Questa sezione descrive la creazione di un datastore NFS versione 4.1 con storage NAS ONTAP.</block>
  <block id="d5ffdd3b223c5bb3d1d66e5756977564" category="list-text">Le competenze di base necessarie per gestire un ambiente vSphere e ONTAP</block>
  <block id="a65c730562f6a5feffebe8a600829c71" category="list-text">Sistema storage ONTAP (file FAS/AFF/CVO/ONTAP Select/Cloud Volume Service/Azure NetApp) con {ontap_version}</block>
  <block id="d5ba6255ccf331629f7b1b4598223d33" category="list-text">Credenziali ONTAP (nome SVM, ID utente, password)</block>
  <block id="190ba592a6988abfd7566be9b5c8217a" category="list-text">Informazioni su porta di rete ONTAP, SVM e LUN per NFS</block>
  <block id="d5cb637f6500cfa77d4190ebdfd8cce0" category="inline-link-macro">Un foglio di lavoro di configurazione NFS completo</block>
  <block id="915142cb27ebec8265b54739a95840b5" category="list-text"><block ref="915142cb27ebec8265b54739a95840b5" category="inline-link-macro-rx"></block></block>
  <block id="8e7f2b8f8c015d7ce248683387c1daf5" category="list-text">Informazioni sugli host vSphere {vsphere_version}</block>
  <block id="d7850596008b347e3797ad7dcb7252e5" category="list-text">NFS VMkernel adapter IP information</block>
  <block id="7d0a7cdd836d94b19d4ecbce81ba2c1e" category="list-text">Con porte dati di rete del sistema ONTAP, host vSphere e connessi</block>
  <block id="a7fb6a7233e9c40554334921be362af1" category="list-text">VLAN configurate per NFS</block>
  <block id="d4e890b3139e840bac898dc24d2330a3" category="list-text">Tool ONTAP per VMware vSphere implementati, configurati e pronti all'uso</block>
  <block id="f2f6f93a63f235f63bf8a14ad398ddd0" category="inline-link">Tool di matrice di interoperabilità (IMT).</block>
  <block id="2c364f266e330209041f2cf854afab91" category="list-text">Verificare la compatibilità con<block ref="975c7893d48b02c6727b59b0582d74bc" category="inline-link-rx"></block></block>
  <block id="bc295a5edde99316e021476fd74118c6" category="inline-link-macro">Verificare che la configurazione NFS sia supportata.</block>
  <block id="564210524eadeca61542a5680bf0afca" category="list-text"><block ref="564210524eadeca61542a5680bf0afca" category="inline-link-macro-rx"></block></block>
  <block id="863feef43abaa752e441459bd37722c3" category="list-text">Completare le attività ONTAP e vSphere fornite di seguito.</block>
  <block id="1b2d2406823c016e35ebeddf0ec29c66" category="inline-link-macro">Verificare la licenza ONTAP per NFS</block>
  <block id="7209cd833425a764d216b4e565ac65c6" category="list-text"><block ref="7209cd833425a764d216b4e565ac65c6" category="inline-link-macro-rx"></block></block>
  <block id="55d2948d4abb6ad9ea1e2b6a5b73460b" category="list-text">Usareil<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Comando per verificare se NFS è elencato.</block>
  <block id="8b3434ec0db76b4d537ae9c645aa913c" category="list-text">Utilizzare<block ref="b7dcb36bf321df4a59507f6e4d0e13fb" prefix=" " category="inline-code"></block> per aggiungere una licenza.</block>
  <block id="0a5e80a3066e5036387d5026a58fe582" category="inline-link-macro">Seguire il workflow di configurazione di NFS</block>
  <block id="4b9e38c0f910614d9be47f85cf0f07bc" category="list-text"><block ref="4b9e38c0f910614d9be47f85cf0f07bc" category="inline-link-macro-rx"></block></block>
  <block id="4344c7f5d714fb1797033b7d9cca43fd" category="inline-link-macro">Seguire il flusso di lavoro Configurazione client NFS per vSphere.</block>
  <block id="c9fb47d82da1089992044972b4b65103" category="paragraph"><block ref="c9fb47d82da1089992044972b4b65103" category="inline-link-macro-rx"></block></block>
  <block id="883a5adf98ba177c28c5bc7d95e28763" category="paragraph">Una volta completate queste attività, il datastore NFS è pronto per il provisioning delle macchine virtuali.</block>
  <block id="f02207fb26160d7e47cf5ea35d07df03" category="doc">Datastore e protocolli</block>
  <block id="ff53ee8001042abcefe5c912d0b5012f" category="section-title">Datastore vSphere e funzionalità del protocollo</block>
  <block id="af8dcb8c7a1e8b7e614e570806d8dcee" category="paragraph">Per collegare VMware vSphere a datastore su un sistema con software ONTAP vengono utilizzati sette protocolli:</block>
  <block id="a7c815fafe60ae637d38216fa6300395" category="list-text">FCP</block>
  <block id="14eae6ee278098bfad4f8a10fd6c1195" category="list-text">FCoE</block>
  <block id="26bcb9f1cb6f391f4b2c18e676bb458d" category="list-text">NVMe/FC</block>
  <block id="8b7c42123642e2e4ea7dd426aeb2de58" category="list-text">NVMe/TCP</block>
  <block id="e4e1c13bb0b14f6cb7608cbecea948ef" category="list-text">ISCSI</block>
  <block id="f7d773fd2896401c143676940bc001fc" category="list-text">NFS v3</block>
  <block id="0b99b245267ef194ca3b9f6e694b0983" category="list-text">NFS v4.1</block>
  <block id="cfa070ed8af17c3125cfd1530fbd387a" category="paragraph">FCP, FCoE, NVMe/FC, NVMe/TCP e iSCSI sono protocolli a blocchi che utilizzano il file system della macchina virtuale vSphere per memorizzare le macchine virtuali all'interno di LUN ONTAP o spazi dei nomi NVMe contenuti in un volume ONTAP FlexVol. A partire da vSphere 7.0, VMware non supporta più il software FCoE negli ambienti di produzione. NFS è un protocollo di file che inserisce le macchine virtuali in datastore (che sono semplicemente volumi ONTAP) senza la necessità di VMFS. SMB (CIFS), iSCSI, NVMe/TCP o NFS possono essere utilizzati anche direttamente da un sistema operativo guest a ONTAP.</block>
  <block id="0f2f72ef3f176b98134caf100a06cf5f" category="inline-link">Massimi di configurazione VMware</block>
  <block id="7469c178e150e10730dcab1094765f10" category="paragraph">Le seguenti tabelle presentano le funzionalità datastore tradizionali supportate da vSphere con ONTAP. Queste informazioni non si applicano agli archivi dati vVol, ma in genere si applicano a vSphere 6.x e alle versioni successive che utilizzano le versioni supportate di ONTAP. È inoltre possibile consultare<block ref="26c5407c98ec413c85131fd8c0d178b4" category="inline-link-rx"></block> Per release specifiche di vSphere per confermare limiti specifici.</block>
  <block id="9da73946f1bc3be4a41898d06c9d2e8b" category="cell">Funzionalità</block>
  <block id="c982f804d02e2d7e937f125d2cac1024" category="cell">FC/FCoE</block>
  <block id="6151632541dcd80356c6c76b34d69d0c" category="cell">NVMe-of</block>
  <block id="1d1a594959ec615f56516f5d0f5e8ddb" category="cell">NFS</block>
  <block id="520d0db389f362bf79ef56ca0af3dcab" category="cell">Formato</block>
  <block id="99a3142584ca8ad0a3afadeaa6f2ef69" category="cell">VMFS o RDM (raw device mapping)</block>
  <block id="26aae26f61844ac20ab7b04ba6f5c515" category="cell">VMFS o RDM</block>
  <block id="18263a30df8afc60a733e59c60676ac0" category="cell">VMFS</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">N/A.</block>
  <block id="8dc6d0c66219ddb809322c0d248e55e6" category="cell">Numero massimo di datastore o LUN</block>
  <block id="aa23f9914ce1939ea7a4d479edfdc915" category="cell">1024 LUN per host</block>
  <block id="1af3b27207afc48a363629a315d76b59" category="cell">1024 LUN per server</block>
  <block id="0705fd627c25b5fba17cd9a022ed7d72" category="cell">256 namespeces per server</block>
  <block id="2774ddb6f193789c5d9a480b9e53a38d" category="cell">256 monta il NFS predefinito. MaxVolumes è 8. Utilizza i tool ONTAP per VMware vSphere per aumentare fino a 256.</block>
  <block id="51c0dc217976e27de06e262947947a62" category="cell">Dimensione massima datastore</block>
  <block id="856c997f909830b8249756c07dc9452b" category="cell">64 TB</block>
  <block id="8e5d3a4b085389c59a1a7af7c4067a9b" category="cell">100 TB di volume FlexVol o superiore con volume FlexGroup</block>
  <block id="b4fb1d41fedaec79072964cbb4d16e3d" category="cell">Dimensione massima del file del datastore</block>
  <block id="d10549beb2f7bd1e91e5ef8965edd84a" category="cell">62 TB</block>
  <block id="fe299bb060ce245b8fe190de21d3978e" category="cell">16 TB o 62 TB con ONTAP 9.12.1RC1 e versioni successive con file di grandi dimensioni abilitati</block>
  <block id="9aa56a79640231adaec83bc53e59c929" category="cell">Profondità ottimale della coda per LUN o file system</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="ca6e77250a239af7b4aed9a1ac058825" category="cell">Negoziazione automatica</block>
  <block id="6104c8ef7be4222a76596ab6a22bb422" category="inline-link">Host ESXi consigliato e altre impostazioni ONTAP</block>
  <block id="bad19bc2587cd465cab5cec5a13aa306" category="cell">Fare riferimento a NFS.MaxQueueDefelse in<block ref="0391a4aaf03ed2bf80fb4efb215797d0" category="inline-link-rx"></block>.</block>
  <block id="edc5121cb9b42a76b718b8ece9d67437" category="paragraph">La seguente tabella elenca le funzionalità supportate relative allo storage VMware.</block>
  <block id="130b78bfd6c9b050a912fec77e285e3f" category="cell">Capacità/funzionalità</block>
  <block id="6c1a84b789b54fd42511ce582be94d21" category="cell">VMotion</block>
  <block id="e95b58d02782c970bb339c6cc587ff39" category="cell">Storage vMotion</block>
  <block id="0486e0e3dc3e86859f43b6d8e32b8071" category="cell">VMware ha</block>
  <block id="8be6bd7f20474cbefdd496cb9fd495ca" category="cell">SDR (Storage Distributed Resource Scheduler)</block>
  <block id="4244919a64848265426dfd82a14f8248" category="cell">Software di backup abilitato VADP (VMware vStorage API for Data Protection)</block>
  <block id="28c2f8ab9cdbf296aa4261bc3c58ba0d" category="cell">Microsoft Cluster Service (MSCS) o clustering di failover all'interno di una macchina virtuale</block>
  <block id="01a9a3b8d0fcae3055dc91935e8ec6c6" category="cell">Sì*</block>
  <block id="aa7f77e663b832d5b0e544c5511e680c" category="cell">Non supportato</block>
  <block id="aa18abedec09bd4f85e612c307e2eaa6" category="cell">Tolleranza agli errori</block>
  <block id="bfd52522de4ac6efd6f680e0e754eeb5" category="cell">Site Recovery Manager</block>
  <block id="e11f298a5bd5344d2d975b5157c27b69" category="cell">No**</block>
  <block id="d6407966cf588d8d78d4f7e65f1ea6fd" category="cell">Solo V3**</block>
  <block id="17d495427086fa21259b9df40b27e00a" category="cell">Macchine virtuali con thin provisioning (dischi virtuali)</block>
  <block id="4ee7af004efef335d6a14c60ee758f5e" category="cell">Sì, questa impostazione è quella predefinita per tutte le macchine virtuali su NFS quando non si utilizza VAAI.</block>
  <block id="13bc264ff420559de4156ec40980a4b9" category="cell">Multipathing nativo di VMware</block>
  <block id="50ed43e1a7a22335069a344bc706b600" category="cell">Sì, utilizzando il nuovo plug-in ad alte prestazioni (HPP)</block>
  <block id="a06819d91a165d0491c5816c54b41234" category="paragraph">La tabella seguente elenca le funzionalità di gestione dello storage ONTAP supportate.</block>
  <block id="f8d61013f1a3bbf1342f4ced3279c7cf" category="cell">Deduplica dei dati</block>
  <block id="72167540968147afed9deb59f0e9fe00" category="cell">Risparmi nell'array</block>
  <block id="9a5473a6abaea16b736f096913a749be" category="cell">Risparmi nel datastore</block>
  <block id="6cd880eabbec3488232c6cba3fbcf998" category="cell">Thin provisioning</block>
  <block id="5caeb11c4ed379b808d7f7cdca7cfbf0" category="cell">Datastore o RDM</block>
  <block id="8a5227cc82d14862956938caffc1acf2" category="cell">Datastore</block>
  <block id="b71ba22dcd42deceac87150206f7bd12" category="cell">Ridimensiona datastore</block>
  <block id="c6b792bfd7aac8067d36337e67d11545" category="cell">Crescere solo</block>
  <block id="29e23534878bb63341e0b689426b7fb0" category="cell">Crescita, crescita automatica e riduzione</block>
  <block id="76021405cc62a4b8c542e7f65e3d24ed" category="cell">Plug-in SnapCenter per applicazioni Windows e Linux (in guest)</block>
  <block id="c0b3c629432c82a9e8500242abb35eaf" category="cell">Monitoraggio e configurazione dell'host con gli strumenti ONTAP per VMware vSphere</block>
  <block id="5a915a8215e9a66bcff0f034e8adff18" category="cell">Provisioning con gli strumenti ONTAP per VMware vSphere</block>
  <block id="6495c7cda42bf1b80bc1c2af6166ef58" category="paragraph">La tabella seguente elenca le funzionalità di backup supportate.</block>
  <block id="1208a2df45bea7d2edea13f0b0cbc686" category="cell">Copie Snapshot di ONTAP</block>
  <block id="bf22a1b5bc2b72a75825094826a942de" category="cell">SRM supportato da backup replicati</block>
  <block id="60d3f7d9f265eb34e826da352cb545be" category="cell">Volume SnapMirror</block>
  <block id="fabf31a57c142c986c5d88cb089b3d7b" category="cell">Accesso all'immagine VMDK</block>
  <block id="40b655e79545b3922b8095be28d59428" category="cell">Software di backup abilitato per VADP</block>
  <block id="8215e73d220182794dfbd75ad494c727" category="cell">Software di backup abilitato VADP, vSphere Client e il browser datastore di vSphere Web Client</block>
  <block id="d7605580ecad0fcb4528789d74cdcad5" category="cell">Accesso a livello di file VMDK</block>
  <block id="906ece32da286d6c4b323bc0d6443b7c" category="cell">Software di backup abilitato VADP, solo Windows</block>
  <block id="d17e2fa63a62622f88bf170612132383" category="cell">Software di backup abilitato VADP e applicazioni di terze parti</block>
  <block id="4e3d259d82a536e12c5c9c948b62e26a" category="cell">Granularità NDMP</block>
  <block id="90d45e02e50c81603c36a4e4ad3649d9" category="cell">Datastore o VM</block>
  <block id="8339c514e73f5cced3b83d504d60441b" category="inline-link">Configurazione per il clustering di failover di Windows Server</block>
  <block id="5663fa28fe2a703e07072185e3a90a94" category="paragraph">*NetApp consiglia di utilizzare iSCSI in-guest per cluster Microsoft piuttosto che VMDK abilitati per il multi-writer in un datastore VMFS. Questo approccio è completamente supportato da Microsoft e VMware, offre grande flessibilità con ONTAP (SnapMirror per sistemi ONTAP on-premise o nel cloud), è facile da configurare e automatizzare e può essere protetto con SnapCenter. VSphere 7 aggiunge una nuova opzione VMDK in cluster. Si tratta di un'operazione diversa dai VMDK abilitati per il multi-writer, che richiede un datastore presentato tramite il protocollo FC che ha attivato il supporto VMDK in cluster. Sono previste altre restrizioni. Vedi VMware<block ref="b158594c147457b5b6417413cb30f800" category="inline-link-rx"></block> documentazione per le linee guida di configurazione.</block>
  <block id="e2bd40041a6472b580305ce9017b0b2e" category="paragraph">**I datastore che utilizzano NVMe-of e NFS v4.1 richiedono la replica vSphere. La replica basata su array non è supportata da SRM.</block>
  <block id="54b3e11ce37eaaa9884f4086e72dd2be" category="section-title">Selezione di un protocollo di storage</block>
  <block id="4bbd62e7748dbf2416c644698342b5f9" category="paragraph">I sistemi che eseguono il software ONTAP supportano tutti i principali protocolli di storage, in modo che i clienti possano scegliere ciò che meglio si adatta al proprio ambiente, a seconda dell'infrastruttura di rete esistente e pianificata e delle competenze dello staff. I test di NetApp hanno generalmente mostrato poca differenza tra i protocolli eseguiti a velocità di linea simili, pertanto è meglio concentrarsi sull'infrastruttura di rete e sulle funzionalità del personale rispetto alle performance del protocollo raw.</block>
  <block id="0212b4e8bc965dcd8a7ff771dd96bf21" category="paragraph">I seguenti fattori potrebbero essere utili per valutare una scelta di protocollo:</block>
  <block id="c0ab9c6170165211885267a562d057a2" category="list-text">*Ambiente attuale del cliente.* sebbene i team IT siano generalmente esperti nella gestione dell'infrastruttura IP Ethernet, non tutti sono esperti nella gestione di un fabric SAN FC. Tuttavia, l'utilizzo di una rete IP generica non progettata per il traffico di storage potrebbe non funzionare correttamente. Prendi in considerazione l'infrastruttura di rete in uso, gli eventuali miglioramenti pianificati e le competenze e la disponibilità del personale per gestirli.</block>
  <block id="774f1348caf3e145710073eb634c4fa1" category="list-text">*Facilità di configurazione.* oltre alla configurazione iniziale del fabric FC (switch e cablaggio aggiuntivi, zoning e verifica dell'interoperabilità di HBA e firmware), i protocolli a blocchi richiedono anche la creazione e la mappatura di LUN e il rilevamento e la formattazione da parte del sistema operativo guest. Una volta creati ed esportati, i volumi NFS vengono montati dall'host ESXi e pronti all'uso. NFS non dispone di specifiche qualifiche hardware o firmware da gestire.</block>
  <block id="bf5169ce5bb544313eaf17435f756da2" category="list-text">*Facilità di gestione.* con i protocolli SAN, se è necessario più spazio, sono necessari diversi passaggi, tra cui la crescita di un LUN, la ricerca di nuove dimensioni e la crescita del file system). Sebbene sia possibile aumentare un LUN, non è possibile ridurre le dimensioni di un LUN e il ripristino dello spazio inutilizzato può richiedere ulteriore impegno. NFS consente un facile dimensionamento in alto o in basso e questo ridimensionamento può essere automatizzato dal sistema storage. LA SAN offre la bonifica dello spazio attraverso i comandi TRIM/UNMAP del sistema operativo guest, consentendo di restituire spazio dai file cancellati all'array. Questo tipo di recupero dello spazio è più difficile con gli archivi dati NFS.</block>
  <block id="530c759326761c6ac026b313985b255f" category="list-text">*Trasparenza dello spazio di storage.* l'utilizzo dello storage è in genere più semplice da visualizzare negli ambienti NFS perché il thin provisioning restituisce immediatamente risparmi. Allo stesso modo, i risparmi di deduplica e clonazione sono immediatamente disponibili per altre macchine virtuali nello stesso datastore o per altri volumi di sistemi storage. La densità delle macchine virtuali è in genere maggiore anche in un datastore NFS, che può migliorare i risparmi della deduplica e ridurre i costi di gestione grazie a un numero inferiore di datastore da gestire.</block>
  <block id="16ee928b12bc598bf52b0f312879ec95" category="section-title">Layout del datastore</block>
  <block id="066ed1c180617b2f9028c1f789078de4" category="paragraph">I sistemi storage ONTAP offrono una grande flessibilità nella creazione di datastore per macchine virtuali e dischi virtuali. Sebbene vengano applicate molte Best practice ONTAP quando si utilizza VSC per il provisioning dei datastore per vSphere (elencate nella sezione <block ref="311a0f5ed21de3c81d57d9c08f2ace49" category="inline-link-macro-rx"></block>), ecco alcune linee guida aggiuntive da prendere in considerazione:</block>
  <block id="b8c499c7b537f5bd4e51b0a6d6a1e9d0" category="list-text">L'implementazione di vSphere con datastore NFS di ONTAP offre un'implementazione facile da gestire e dalle performance elevate che offre rapporti VM-datastore che non possono essere ottenuti con protocolli di storage basati su blocchi. Questa architettura può comportare un aumento di dieci volte della densità degli archivi dati con una conseguente riduzione del numero di archivi dati. Anche se un datastore più grande può trarre beneficio dall'efficienza dello storage e offrire vantaggi operativi, è consigliabile utilizzare almeno quattro datastore (volumi FlexVol) per memorizzare le macchine virtuali su un singolo controller ONTAP per ottenere le massime prestazioni dalle risorse hardware. Questo approccio consente inoltre di stabilire datastore con policy di recovery diverse. Alcuni possono essere sottoposti a backup o replicati più frequentemente rispetto ad altri in base alle esigenze aziendali. I volumi FlexGroup non richiedono più datastore per le performance, in quanto sono scalabili in base alla progettazione.</block>
  <block id="241f8fed1e3a823fcd4d0c1eb705b1a2" category="list-text">NetApp consiglia l'utilizzo di volumi FlexVol e, a partire da ONTAP 9.8 FlexGroup Volumes, datastore NFS. Altri container di storage ONTAP, come i qtree, non sono generalmente consigliati perché attualmente non sono supportati dai tool ONTAP per VMware vSphere. L'implementazione di datastore come più qtree in un singolo volume potrebbe essere utile per ambienti altamente automatizzati che possono trarre vantaggio dalle quote a livello di datastore o dai cloni di file VM.</block>
  <block id="dc4d78be836807b32c7ef7f42028b1ef" category="list-text">Una buona dimensione per un datastore di volumi FlexVol è di circa 4TB - 8TB. Queste dimensioni rappresentano un buon punto di equilibrio per le performance, la facilità di gestione e la protezione dei dati. Inizia in piccolo (ad esempio, 4 TB) e fai crescere il datastore in base alle necessità (fino a un massimo di 100 TB). I datastore più piccoli sono più veloci da ripristinare dal backup o dopo un disastro e possono essere spostati rapidamente nel cluster. Prendere in considerazione l'utilizzo della funzione di dimensionamento automatico di ONTAP per aumentare e ridurre automaticamente il volume in base alle modifiche dello spazio utilizzato. Per impostazione predefinita, i tool ONTAP per il provisioning guidato degli archivi dati VMware vSphere utilizzano la dimensione automatica per i nuovi archivi dati. È possibile personalizzare ulteriormente le soglie di aumento e riduzione e le dimensioni massime e minime con System Manager o la riga di comando.</block>
  <block id="964a81e46088ae1cc6306072464a9d73" category="list-text">In alternativa, gli archivi dati VMFS possono essere configurati con LUN accessibili da FC, iSCSI o FCoE. VMFS consente l'accesso simultaneo alle LUN tradizionali da parte di ogni server ESX in un cluster. Gli archivi di dati VMFS possono avere dimensioni fino a 64 TB e sono costituiti da un massimo di 32 LUN da 2 TB (VMFS 3) o un singolo LUN da 64 TB (VMFS 5). La dimensione massima del LUN ONTAP è 16 TB sulla maggior parte dei sistemi e 128 TB sui sistemi all-SAN-array. Pertanto, è possibile creare un datastore VMFS 5 di dimensioni massime sulla maggior parte dei sistemi ONTAP utilizzando quattro LUN da 16 TB. Sebbene i carichi di lavoro con i/o elevati possano offrire un vantaggio in termini di performance con più LUN (con sistemi FAS o AFF high-end), questo vantaggio è compensato dalla complessità di gestione aggiunta per creare, gestire e proteggere le LUN degli archivi dati e dall'aumento del rischio di disponibilità. In genere, NetApp consiglia di utilizzare un singolo LUN di grandi dimensioni per ciascun datastore e solo se è necessario andare oltre un datastore da 16 TB. Come per NFS, puoi utilizzare più datastore (volumi) per massimizzare le performance su un singolo controller ONTAP.</block>
  <block id="c74cab014e402128efd8102b941c0b0c" category="list-text">I sistemi operativi guest precedenti necessitavano di un allineamento con il sistema storage per ottenere le migliori performance ed efficienza dello storage. Tuttavia, i moderni sistemi operativi supportati dai vendor dei distributori Microsoft e Linux come Red Hat non richiedono più modifiche per allineare la partizione del file system con i blocchi del sistema storage sottostante in un ambiente virtuale. Se si utilizza un sistema operativo precedente che potrebbe richiedere l'allineamento, cercare gli articoli nella Knowledge base del supporto NetApp utilizzando "allineamento delle macchine virtuali" o richiedere una copia di TR-3747 a un contatto commerciale o partner di NetApp.</block>
  <block id="3c8b400142a84af9ebe6262bce512ccb" category="list-text">Evitare l'utilizzo di utility di deframmentazione all'interno del sistema operativo guest, poiché questo non offre alcun beneficio in termini di performance e influisce sull'efficienza dello storage e sull'utilizzo dello spazio di copia Snapshot. È inoltre consigliabile disattivare l'indicizzazione della ricerca nel sistema operativo guest per i desktop virtuali.</block>
  <block id="14abb814748566a24367c4459a54840b" category="list-text">ONTAP ha guidato il settore con innovative funzionalità di efficienza dello storage, che ti consentono di sfruttare al massimo lo spazio su disco utilizzabile. I sistemi AFF aumentano ulteriormente questa efficienza con la deduplica e la compressione inline predefinite. I dati vengono deduplicati in tutti i volumi in un aggregato, quindi non è più necessario raggruppare sistemi operativi simili e applicazioni simili in un singolo datastore per massimizzare i risparmi.</block>
  <block id="154cd001dd3ef8eabdf209f4faf2ddde" category="inline-link">TR-3633: Database Oracle su Data ONTAP</block>
  <block id="8f2f733fd8f32e7aaa1ee62e48a55117" category="list-text">In alcuni casi, potrebbe non essere necessario un datastore. Per ottenere performance e gestibilità ottimali, evitare di utilizzare un datastore per applicazioni con i/o elevato, come database e alcune applicazioni. Si consiglia invece di prendere in considerazione file system di proprietà degli ospiti, come NFS o iSCSI, gestiti dal guest o con RDM. Per indicazioni specifiche sulle applicazioni, consulta i report tecnici NetApp relativi alla tua applicazione. Ad esempio,<block ref="8cb1dd6561aaa08584e14e742f429a3e" category="inline-link-rx"></block> contiene una sezione sulla virtualizzazione con informazioni utili.</block>
  <block id="6cda576d2fd323c1a728b7ac67d6034f" category="list-text">I dischi di prima classe (o dischi virtuali migliorati) consentono dischi gestiti da vCenter indipendenti da una macchina virtuale con vSphere 6.5 e versioni successive. Anche se gestiti principalmente da API, possono essere utili con vVol, soprattutto se gestiti da OpenStack o Kubernetes tools. Sono supportati da ONTAP e dai tool ONTAP per VMware vSphere.</block>
  <block id="71318121439b39fdf872bb0bd57494f2" category="section-title">Migrazione di datastore e macchine virtuali</block>
  <block id="e8824ce2062c6d1fc536163f7b8940bd" category="paragraph">Quando si esegue la migrazione delle macchine virtuali da un datastore esistente su un altro sistema storage a ONTAP, è necessario tenere presente alcune procedure:</block>
  <block id="73b729fbc964c7d78dd90b64aaaeb785" category="list-text">Utilizzare Storage vMotion per spostare la maggior parte delle macchine virtuali su ONTAP. Questo approccio non solo non è disgregativo per l'esecuzione di macchine virtuali, ma consente anche funzionalità di efficienza dello storage ONTAP come la deduplica inline e la compressione per elaborare i dati durante la migrazione. Prendere in considerazione l'utilizzo delle funzionalità di vCenter per selezionare più macchine virtuali dall'elenco di inventario e quindi pianificare la migrazione (utilizzare il tasto Ctrl mentre si fa clic su azioni) in un momento appropriato.</block>
  <block id="008116a0d875d0de070d1a10314abbaa" category="list-text">Sebbene sia possibile pianificare con attenzione una migrazione verso datastore di destinazione appropriati, spesso è più semplice eseguire la migrazione in blocco e poi organizzarla in un secondo momento. Se si hanno esigenze specifiche di protezione dei dati, ad esempio diverse pianificazioni Snapshot, è possibile utilizzare questo approccio per guidare la migrazione a diversi datastore.</block>
  <block id="616b2180a0659911fed5aa758dba722c" category="list-text">La maggior parte delle macchine virtuali e del relativo storage può essere migrata durante l'esecuzione (a caldo), ma la migrazione dello storage collegato (non nel datastore) come gli ISO, i LUN o i volumi NFS da un altro sistema storage potrebbe richiedere la migrazione a freddo.</block>
  <block id="fbb88da5639930a05f510729e473a216" category="inline-link">TR-4534</block>
  <block id="282806c282d96fdf15b71278587f2bfe" category="list-text">Le macchine virtuali che richiedono una migrazione più accurata includono database e applicazioni che utilizzano lo storage collegato. In generale, considerare l'utilizzo degli strumenti dell'applicazione per gestire la migrazione. Per Oracle, prendere in considerazione l'utilizzo di strumenti Oracle come RMAN o ASM per migrare i file di database. Vedere<block ref="6b3f565e7a7ce633fa62f4114c295216" category="inline-link-rx"></block> per ulteriori informazioni. Allo stesso modo, per SQL Server, prendere in considerazione l'utilizzo di SQL Server Management Studio o di strumenti NetApp come SnapManager per SQL Server o SnapCenter.</block>
  <block id="00f47a68ebd81ba943b17dbc30d78db6" category="paragraph">La Best practice più importante per l'utilizzo di vSphere con i sistemi che eseguono il software ONTAP consiste nell'installare e utilizzare i tool ONTAP per il plug-in di VMware vSphere (precedentemente noto come console di storage virtuale). Questo plug-in vCenter semplifica la gestione dello storage, migliora la disponibilità e riduce i costi di storage e l'overhead operativo, sia che si utilizzi SAN che NAS. Utilizza le Best practice per il provisioning degli archivi di dati e ottimizza le impostazioni degli host ESXi per i timeout multipath e HBA (descritti nell'Appendice B). Essendo un plug-in vCenter, è disponibile per tutti i client web vSphere che si connettono al server vCenter.</block>
  <block id="21eddd0bd26d119e0602b3ceb65aff45" category="paragraph">Il plug-in consente inoltre di utilizzare altri strumenti ONTAP in ambienti vSphere. Consente di installare il plug-in NFS per VMware VAAI, che consente l'offload delle copie su ONTAP per le operazioni di cloning delle macchine virtuali, la riserva di spazio per i file di dischi virtuali spessi e l'offload delle copie Snapshot di ONTAP.</block>
  <block id="80303385ad0f7147caa1af6d2162852b" category="paragraph">Il plug-in è anche l'interfaccia di gestione per molte funzioni del provider VASA per ONTAP, supportando la gestione basata su policy di storage con vVol. Una volta registrati i tool ONTAP per VMware vSphere, utilizzali per creare profili di capacità storage, mapparli allo storage e garantire la conformità dei datastore con i profili nel tempo. Il provider VASA fornisce anche un'interfaccia per creare e gestire datastore vVol.</block>
  <block id="9baea886f208a41896164d4ade5b3fde" category="paragraph">In generale, NetApp consiglia di utilizzare i tool ONTAP per l'interfaccia di VMware vSphere all'interno di vCenter per eseguire il provisioning di datastore tradizionali e vVol per garantire il rispetto delle Best practice.</block>
  <block id="6161d374e9022f89382fd63b4be15aa1" category="section-title">Rete generale</block>
  <block id="f0cd6847f2a7a0773ad0b58d0f9dc67d" category="paragraph">La configurazione delle impostazioni di rete quando si utilizza vSphere con sistemi che eseguono il software ONTAP è semplice e simile ad altre configurazioni di rete. Ecco alcuni aspetti da considerare:</block>
  <block id="9600865cce7d923667012211ddac46de" category="list-text">Separare il traffico di rete dello storage dalle altre reti. È possibile ottenere una rete separata utilizzando una VLAN dedicata o switch separati per lo storage. Se la rete di storage condivide percorsi fisici come gli uplink, potrebbe essere necessario QoS o porte di uplink aggiuntive per garantire una larghezza di banda sufficiente. Non connettere gli host direttamente allo storage; utilizzare gli switch per avere percorsi ridondanti e consentire a VMware ha di funzionare senza alcun intervento.</block>
  <block id="7c4904daaa282388097ad83bf382e1a5" category="list-text">I frame jumbo possono essere utilizzati se lo si desidera e supportati dalla rete, in particolare quando si utilizza iSCSI. Se vengono utilizzati, assicurarsi che siano configurati in modo identico su tutti i dispositivi di rete, VLAN e così via nel percorso tra lo storage e l'host ESXi. In caso contrario, potrebbero verificarsi problemi di connessione o di prestazioni. La MTU deve essere impostata in modo identico anche sullo switch virtuale ESXi, sulla porta VMkernel e anche sulle porte fisiche o sui gruppi di interfacce di ciascun nodo ONTAP.</block>
  <block id="8b6e7f43d1d697e8f99164f0aa2ab1b6" category="inline-link">TR-4182</block>
  <block id="3745abd352adaa2cdec42c798060eef6" category="list-text">NetApp consiglia di disattivare il controllo del flusso di rete solo sulle porte di rete del cluster all'interno di un cluster ONTAP. NetApp non fornisce altri consigli sulle Best practice per le restanti porte di rete utilizzate per il traffico dati. Attivare o disattivare secondo necessità. Vedere<block ref="bdfb81665a0ef86d871a52c0e6ebc591" category="inline-link-rx"></block> per ulteriori informazioni sul controllo di flusso.</block>
  <block id="730a8287f758961d602b1b050bbe2751" category="list-text">Quando gli array di storage ESXi e ONTAP sono collegati a reti di storage Ethernet, NetApp consiglia di configurare le porte Ethernet a cui questi sistemi si connettono come porte edge RSTP (Rapid Spanning Tree Protocol) o utilizzando la funzione PortFast di Cisco. NetApp consiglia di abilitare la funzione di trunk PortFast Spanning-Tree in ambienti che utilizzano la funzionalità Cisco PortFast e che dispongono di un trunking VLAN 802.1Q abilitato per il server ESXi o gli array di storage ONTAP.</block>
  <block id="ac4976538e1fc8726f77afc202561afc" category="list-text">NetApp consiglia le seguenti Best practice per l'aggregazione dei collegamenti:</block>
  <block id="040ffbbbbeda558bdae1e07f5371b4f5" category="list-text">Utilizzare switch che supportano l'aggregazione di collegamenti di porte su due chassis switch separati utilizzando un approccio di gruppo di aggregazione di collegamenti multiclochi, come Virtual PortChannel (VPC) di Cisco.</block>
  <block id="19d137845c7f6687c99b386dfad0aa97" category="list-text">Disattivare LACP per le porte dello switch connesse a ESXi, a meno che non si utilizzi dvSwitch 5.1 o versioni successive con LACP configurato.</block>
  <block id="30254a2bb3e4b3b958b06d08c724e7db" category="list-text">Utilizzare LACP per creare aggregati di link per sistemi storage ONTAP con gruppi di interfacce multimodali dinamiche con hash IP.</block>
  <block id="d608421cceb8e4c584a2a32d9127879e" category="list-text">Utilizzare un criterio di raggruppamento hash IP su ESXi.</block>
  <block id="2432030fc6183a1a6c52cf5e93f3e9ae" category="paragraph">La seguente tabella fornisce un riepilogo degli elementi di configurazione di rete e indica la posizione in cui vengono applicate le impostazioni.</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">Elemento</block>
  <block id="1aa66ef3a8e34a7a538960a80d2e1e31" category="cell">ESXi</block>
  <block id="bbc155fb2b111bf61c4f5ff892915e6b" category="cell">Switch</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">Nodo</block>
  <block id="0b7e67b6cdcf0432b624d53588d520fb" category="cell">SVM</block>
  <block id="75ba8d70e3692ba200f0e0df37b4d2ae" category="cell">Indirizzo IP</block>
  <block id="ee6c0f25c2881cc69947a2ef23be5b8c" category="cell">VMkernel</block>
  <block id="d6f0876f76c273b8962b749c36153157" category="cell">Aggregazione dei collegamenti</block>
  <block id="fabd320b3b2249377e53e93099e27657" category="cell">Switch virtuale</block>
  <block id="b1b40427c8eb8d0a083ddb16e250325b" category="cell">No*</block>
  <block id="9881f82f0dd89588831f9d1682bd5492" category="cell">VLAN</block>
  <block id="5fc0d231160fa9650ea5c877f146bbe6" category="cell">Gruppi di porte VMkernel e VM</block>
  <block id="39a3e05f380e583ae2887c79c7443f11" category="cell">Controllo di flusso</block>
  <block id="220071ab44b426f80ef21f1c552c363c" category="cell">NIC</block>
  <block id="6f2c08412f489e52a17a30217f50b3c1" category="cell">Spanning tree</block>
  <block id="4b1c0df98ba3f3d1681c3c3dbdc97746" category="cell">MTU (per frame jumbo)</block>
  <block id="7d6feaf896df4a937157d4ee5b91f4e1" category="cell">Switch virtuale e porta VMkernel (9000)</block>
  <block id="0110e50bd8629573701e73a4ba8b056f" category="cell">Sì (impostato su max)</block>
  <block id="061ff5255adf00e4ae68469f43a7bf55" category="cell">Sì (9000)</block>
  <block id="bcc0e5a3e08cd34e80692195d056b06d" category="cell">Gruppi di failover</block>
  <block id="a4d1a66a448e327c12d3e287098a31d5" category="cell">Sì (creare)</block>
  <block id="465d5674eb6808b997037470f4dace73" category="cell">Sì (selezionare)</block>
  <block id="ba78d695573c8d4f1205452c675fa539" category="paragraph">*Le LIF SVM si connettono a porte, gruppi di interfacce o interfacce VLAN con VLAN, MTU e altre impostazioni. Tuttavia, le impostazioni non vengono gestite a livello di SVM.</block>
  <block id="50ecdab93bf5a2f1bfb4cd8f81b9bd3d" category="paragraph">**Questi dispositivi dispongono di indirizzi IP propri per la gestione, ma non vengono utilizzati nel contesto dello storage di rete ESXi.</block>
  <block id="efd0bde36323238fec688b9cdf0c75a3" category="section-title">SAN (FC, FCoE, NVMe/FC, iSCSI), RDM</block>
  <block id="29cdd488736a6111699f7348320bbed7" category="paragraph">In vSphere, esistono tre modi per utilizzare le LUN dello storage a blocchi:</block>
  <block id="8982d243303f9d1a8c2470b7d55278e6" category="list-text">Con datastore VMFS</block>
  <block id="9a0098c8c1be287e8d1da1aaf3bd2e59" category="list-text">Con RDM (raw device mapping)</block>
  <block id="93e209176746ac6f25c618631a02643b" category="list-text">Come LUN accessibile e controllato da un iniziatore software da un sistema operativo guest VM</block>
  <block id="c25dc676ca39a05ee6067ac9a50dbce0" category="paragraph">VMFS è un file system in cluster dalle performance elevate che fornisce datastore che sono pool di storage condivisi. Gli archivi dati VMFS possono essere configurati con LUN a cui si accede utilizzando spazi dei nomi FC, iSCSI, FCoE o NVMe a cui si accede dal protocollo NVMe/FC. VMFS consente l'accesso simultaneo alle LUN tradizionali da parte di ogni server ESX in un cluster. La dimensione massima del LUN ONTAP è generalmente di 16 TB; pertanto, un datastore VMFS 5 di 64 TB (vedere la prima tabella di questa sezione) viene creato utilizzando quattro LUN da 16 TB (tutti i sistemi array SAN supportano la dimensione massima del LUN VMFS di 64 TB). Poiché l'architettura LUN di ONTAP non ha una profondità di coda singola ridotta, gli archivi dati VMFS in ONTAP possono scalare in maniera relativamente semplice rispetto alle architetture di array tradizionali.</block>
  <block id="43f67f108e50dab0978a343603cbfec9" category="paragraph">VSphere include il supporto integrato per più percorsi verso i dispositivi storage, definito NMP (Native Multipathing). NMP è in grado di rilevare il tipo di storage per i sistemi storage supportati e di configurare automaticamente lo stack NMP per supportare le funzionalità del sistema storage in uso.</block>
  <block id="6bf646772584de04f877d166e564b5ff" category="paragraph">Sia NMP che NetApp ONTAP supportano l'accesso ad unità logica asimmetrico (ALUA) per negoziare percorsi ottimizzati e non ottimizzati. In ONTAP, un percorso ottimizzato per ALUA segue un percorso di dati diretto, utilizzando una porta di destinazione sul nodo che ospita il LUN a cui si accede. ALUA è attivato per impostazione predefinita sia in vSphere che in ONTAP. NMP riconosce il cluster ONTAP come ALUA e utilizza il plug-in del tipo di array di storage ALUA <block ref="d4f7bd3bf4872a2f8cd0cbe400fb23d0" prefix="(" category="inline-code"></block>) e seleziona il plug-in di selezione del percorso round robin <block ref="4646bb781f9a95f64c182af129e43c7c" prefix="(" category="inline-code"></block>).</block>
  <block id="b284ee628d89c3e804c4def2a90f0520" category="paragraph">ESXi 6 supporta fino a 256 LUN e fino a 1,024 percorsi totali verso LUN. I LUN o i percorsi che superano questi limiti non sono visti da ESXi. Supponendo il numero massimo di LUN, il limite di percorso consente quattro percorsi per LUN. In un cluster ONTAP più grande, è possibile raggiungere il limite di percorso prima del limite di LUN. Per risolvere questo limite, ONTAP supporta la mappa LUN selettiva (SLM) nella versione 8.3 e successive.</block>
  <block id="8466b1e5abb4751e931c5feb1af4e469" category="inline-link">TR-4080</block>
  <block id="631e164314a103fe3183b00b759057b2" category="paragraph">SLM limita i nodi che pubblicizzano i percorsi a una determinata LUN. È una Best practice di NetApp avere almeno una LIF per nodo per SVM e utilizzare SLM per limitare i percorsi pubblicizzati al nodo che ospita la LUN e il suo partner ha. Sebbene esistano altri percorsi, non vengono pubblicizzati per impostazione predefinita. È possibile modificare i percorsi pubblicizzati con gli argomenti del nodo di reporting add e remove all'interno di SLM. Tenere presente che le LUN create nelle release precedenti alla 8.3 pubblicizzano tutti i percorsi e devono essere modificate solo per pubblicizzare i percorsi alla coppia ha di hosting. Per ulteriori informazioni su SLM, vedere la sezione 5.9 di<block ref="c6b12416d518b4689065ffe16afe88db" category="inline-link-rx"></block>. Il precedente metodo di portset può essere utilizzato anche per ridurre ulteriormente i percorsi disponibili per un LUN. I portset aiutano a ridurre il numero di percorsi visibili attraverso i quali gli iniziatori in un igroup possono vedere le LUN.</block>
  <block id="4157f0c23fc104508f492dc846f187f3" category="list-text">SLM è attivato per impostazione predefinita. A meno che non si utilizzino portset, non è necessaria alcuna configurazione aggiuntiva.</block>
  <block id="597f1433ad810b3b86c7ae0f8f95afa8" category="list-text">Per i LUN creati prima di Data ONTAP 8.3, applicare manualmente SLM eseguendo<block ref="886fd385b633a0746a8a08f8f00c67cd" prefix=" " category="inline-code"></block> Comando per rimuovere i nodi di reporting del LUN e limitare l'accesso del LUN al nodo proprietario del LUN e al partner ha.</block>
  <block id="43919b4d4d6d446ed498e26bff62db84" category="paragraph">I protocolli a blocchi (iSCSI, FC e FCoE) accedono alle LUN utilizzando ID LUN e numeri di serie, insieme a nomi univoci. FC e FCoE utilizzano nomi in tutto il mondo (WWNN e WWPN), mentre iSCSI utilizza nomi iSCSI qualificati (IQN). Il percorso delle LUN all'interno dello storage è privo di significato per i protocolli a blocchi e non viene presentato in alcun punto del protocollo. Pertanto, un volume che contiene solo LUN non deve essere montato internamente e non è necessario un percorso di giunzione per i volumi che contengono LUN utilizzati negli archivi dati. Il sottosistema NVMe in ONTAP funziona in modo simile.</block>
  <block id="ed0e76ed86e852bd7317a09d856ec4e8" category="paragraph">Altre Best practice da prendere in considerazione:</block>
  <block id="93586ad57931e0f16fff61cdba9d77df" category="list-text">Assicurarsi che venga creata un'interfaccia logica (LIF) per ogni SVM su ciascun nodo del cluster ONTAP per garantire la massima disponibilità e mobilità. La Best practice PER LE SAN ONTAP consiste nell'utilizzare due porte fisiche e LIF per nodo, una per ciascun fabric. ALUA viene utilizzato per analizzare i percorsi e identificare i percorsi attivi ottimizzati (diretti) rispetto ai percorsi attivi non ottimizzati. ALUA viene utilizzato per FC, FCoE e iSCSI.</block>
  <block id="b3cebb7381bddbabb1e950a46d264190" category="list-text">Per le reti iSCSI, utilizzare più interfacce di rete VMkernel su diverse subnet di rete con raggruppamento NIC quando sono presenti più switch virtuali. È inoltre possibile utilizzare più NIC fisiche collegate a più switch fisici per fornire ha e un throughput maggiore. La figura seguente mostra un esempio di connettività multipath. In ONTAP, configurare un gruppo di interfacce single-mode per il failover con due o più collegamenti connessi a due o più switch oppure utilizzare LACP o un'altra tecnologia di aggregazione dei collegamenti con gruppi di interfacce multimodali per fornire ha e i vantaggi dell'aggregazione dei collegamenti.</block>
  <block id="2968b9f3c141bf23bc73d0e6e15a174a" category="list-text">Se il protocollo CHAP (Challenge-Handshake Authentication Protocol) viene utilizzato in ESXi per l'autenticazione di destinazione, deve essere configurato anche in ONTAP utilizzando la CLI <block ref="199c9b970eacf1c35d84a383b7ceb210" prefix="(" category="inline-code"></block>) O con System Manager (modificare Initiator Security in Storage &gt; SVM &gt; SVM Settings &gt; Protocols &gt; iSCSI).</block>
  <block id="d31f2e075df4ca75ca0874fa08f74b12" category="list-text">Utilizza i tool ONTAP per VMware vSphere per creare e gestire LUN e igroups. Il plug-in determina automaticamente le WWPN dei server e crea gli igroups appropriati. Inoltre, configura i LUN in base alle Best practice e li associa agli igroups corretti.</block>
  <block id="de78559e8aed2cd62fbf852f73dc58c2" category="inline-link">modalità di compatibilità fisica e virtuale</block>
  <block id="905221150fdd103b5241870a0a1f2c42" category="list-text">Utilizza gli RDM con attenzione perché possono essere più difficili da gestire e utilizzano percorsi limitati, come descritto in precedenza. I LUN ONTAP supportano entrambi<block ref="27e1f8e5a88cfbb2836b083145b004c9" category="inline-link-rx"></block> RDM.</block>
  <block id="636da39a2033c6179a718983c5ce1222" category="inline-link">Guida alla configurazione degli host NVMe/FC di ONTAP</block>
  <block id="81ef6507a13da5635951bc5b533deb59" category="inline-link">TR-4684</block>
  <block id="15483b0826bb9a4b11d1c89af2029c5c" category="list-text">Per ulteriori informazioni sull'utilizzo di NVMe/FC con vSphere 7.0, consulta questo articolo<block ref="6b4ed262d14e47ef641cd57b65c32c38" category="inline-link-rx"></block> e.<block ref="7a29b2f31035a451d5b068728d2b79a7" category="inline-link-rx"></block>La figura seguente mostra la connettività multipath da un host vSphere a un LUN ONTAP.</block>
  <block id="f9fd9ea22ea7a2e8ec9e95254a449831" category="paragraph"><block ref="f9fd9ea22ea7a2e8ec9e95254a449831" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a693e1f056b96566c4551fcab418f2" category="paragraph">VSphere consente ai clienti di utilizzare array NFS di livello Enterprise per fornire l'accesso simultaneo agli archivi dati a tutti i nodi di un cluster ESXi. Come indicato nella sezione datastore, l'utilizzo di NFS con vSphere offre alcuni vantaggi in termini di facilità d'uso e visibilità dell'efficienza dello storage.</block>
  <block id="743fa5a7bc7d4ba215b096e34779d298" category="paragraph">Quando si utilizza ONTAP NFS con vSphere, si consiglia di seguire le seguenti Best practice:</block>
  <block id="265e673c00294cf97a90c3b0d4fcb076" category="list-text">Utilizzare una singola interfaccia logica (LIF) per ogni SVM su ciascun nodo del cluster ONTAP. Le raccomandazioni precedenti di un LIF per datastore non sono più necessarie. Anche se l'accesso diretto (LIF e datastore sullo stesso nodo) è la soluzione migliore, non preoccuparti dell'accesso indiretto perché l'effetto delle performance è generalmente minimo (microsecondi).</block>
  <block id="7b997b3be9c993d49799dd9d71d8c3f6" category="list-text">VMware supporta NFSv3 da VMware Infrastructure 3. VSphere 6.0 ha aggiunto il supporto per NFSv4.1, che abilita alcune funzionalità avanzate come la sicurezza Kerberos. Dove NFSv3 utilizza il blocco lato client, NFSv4.1 utilizza il blocco lato server. Anche se un volume ONTAP può essere esportato attraverso entrambi i protocolli, ESXi può essere montato solo attraverso un protocollo. Questo montaggio di protocollo singolo non impedisce ad altri host ESXi di montare lo stesso datastore attraverso una versione diversa. Assicurarsi di specificare la versione del protocollo da utilizzare durante il montaggio in modo che tutti gli host utilizzino la stessa versione e, di conseguenza, lo stesso stile di blocco. Non mischiare versioni NFS tra gli host. Se possibile, utilizzare i profili host per verificare la conformità.</block>
  <block id="ae4c5baa79e370d8f601cc7082f8123e" category="list-text">Poiché non esiste alcuna conversione automatica del datastore tra NFSv3 e NFSv4.1, creare un nuovo datastore NFSv4.1 e utilizzare Storage vMotion per migrare le macchine virtuali nel nuovo datastore.</block>
  <block id="8065bff4940ae8d7161f926b0df47ac4" category="inline-link">Tool NetApp Interoperability Matrix</block>
  <block id="1479ddf58c038ab7d220ff734c74deaf" category="list-text">Fare riferimento alle note della tabella di interoperabilità NFS v4.1 nella<block ref="8813559f5b95abb5411182be29200aff" category="inline-link-rx"></block> Per i livelli di patch ESXi specifici richiesti per il supporto.</block>
  <block id="d8119941da55a672db49a624330ea7f0" category="list-text">Le policy di esportazione NFS vengono utilizzate per controllare l'accesso da parte degli host vSphere. È possibile utilizzare un criterio con più volumi (datastore). Con NFSv3, ESXi utilizza lo stile di sicurezza sys (UNIX) e richiede l'opzione di montaggio root per eseguire le macchine virtuali. In ONTAP, questa opzione viene definita superutente e, quando viene utilizzata l'opzione superutente, non è necessario specificare l'ID utente anonimo. Tenere presente che le regole dei criteri di esportazione con valori diversi per<block ref="ea72d12ecaa06afdb0c8a3b15e485e95" prefix=" " category="inline-code"></block> e.<block ref="df809a941c1287d18c08bb5927b639dc" prefix=" " category="inline-code"></block> Può causare problemi di rilevamento SVM con gli strumenti ONTAP. Ecco un esempio di policy:</block>
  <block id="822366735aef72f1a9429ac86dda7338" category="list-text">Access Protocol (protocollo di accesso): Nfs3</block>
  <block id="69abbd5c7cd9c1b3828b9aa5a894ff47" category="list-text">Specifiche di corrispondenza del client: 192.168.42.21</block>
  <block id="bd6cc42f9cd65cca72cbd56d2f4bf43d" category="list-text">Regola di accesso RO: SIS</block>
  <block id="581c470a5099548fc9865a4bab8761f8" category="list-text">RW Access Rule (regola di accesso RW): SIS</block>
  <block id="0bbc71e6a4ea49af70dd616d3807e524" category="list-text">UID anonimo</block>
  <block id="59d5d8c898df18115bd4ced36c6bc0de" category="list-text">Superutente: SIS</block>
  <block id="c184ce6b86d2e6fbf8681d61637c101b" category="list-text">Se si utilizza il plug-in NetApp NFS per VMware VAAI, il protocollo deve essere impostato su<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> quando viene creata o modificata la regola dei criteri di esportazione. Il protocollo NFSv4 è necessario per l'offload delle copie VAAI e per specificare il protocollo come<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> Include automaticamente le versioni NFSv3 e NFSv4.</block>
  <block id="49bb4e84b97bfe104e9fe7eb7df07a38" category="list-text">I volumi del datastore NFS vengono svincoli dal volume root di SVM; pertanto, ESXi deve anche avere accesso al volume root per navigare e montare i volumi del datastore. Il criterio di esportazione per il volume root e per qualsiasi altro volume in cui la giunzione del volume datastore è nidificata, deve includere una regola o regole per i server ESXi che concedono loro l'accesso in sola lettura. Ecco un esempio di policy per il volume root, utilizzando anche il plug-in VAAI:</block>
  <block id="8c93fb3ff528165613797962f5a0ed9c" category="list-text">Access Protocol: nfs (che include sia nfs3 che nfs4)</block>
  <block id="80e6a4f964e826c69c1c62bd5ea67590" category="list-text">RW Access Rule: Never (miglior sicurezza per il volume root)</block>
  <block id="f96625174b4a06d13267f9b0a5a96d59" category="list-text">Superutente: SYS (richiesto anche per il volume root con VAAI)</block>
  <block id="4c571520a8128d1692fc709ffbfb2b1e" category="list-text">Utilizza i tool ONTAP per VMware vSphere (la Best practice più importante):</block>
  <block id="b8d278c6184cb65727ca5ae729db92d7" category="list-text">Utilizza i tool ONTAP per VMware vSphere per eseguire il provisioning degli archivi dati, poiché semplifica automaticamente la gestione delle policy di esportazione.</block>
  <block id="23aa7b9aeed3fba2a1ec43e630313af7" category="list-text">Quando si creano datastore per cluster VMware con il plug-in, selezionare il cluster anziché un singolo server ESX. Questa opzione attiva il montaggio automatico del datastore su tutti gli host del cluster.</block>
  <block id="e4e62770daaf9887c7868fbc8e248a4b" category="list-text">Utilizzare la funzione di montaggio del plug-in per applicare i datastore esistenti ai nuovi server.</block>
  <block id="928562eb576ed6ae31cb1a149d3e751a" category="list-text">Quando non si utilizzano gli strumenti ONTAP per VMware vSphere, utilizzare una singola policy di esportazione per tutti i server o per ciascun cluster di server in cui è necessario un controllo aggiuntivo degli accessi.</block>
  <block id="7bccab0fa4c0864835c645c9fde7ebf6" category="list-text">Sebbene ONTAP offra una struttura flessibile dello spazio dei nomi dei volumi per organizzare i volumi in un albero utilizzando le giunzioni, questo approccio non ha alcun valore per vSphere. Crea una directory per ogni VM nella directory principale dell'archivio dati, indipendentemente dalla gerarchia dello spazio dei nomi dello storage. Pertanto, la Best practice consiste nel montare semplicemente il percorso di giunzione per i volumi per vSphere nel volume root della SVM, che è il modo in cui i tool ONTAP per VMware vSphere prevedono il provisioning dei datastore. La mancanza di percorsi di giunzione nidificati significa anche che nessun volume dipende da un volume diverso dal volume root e che la sua eliminazione o la sua eliminazione, anche intenzionalmente, non influisce sul percorso verso altri volumi.</block>
  <block id="ea6fc1288f1d3b21238d29ff28cb867a" category="list-text">Una dimensione del blocco di 4K è adatta per le partizioni NTFS negli archivi dati NFS. La figura seguente mostra la connettività da un host vSphere a un datastore NFS ONTAP.</block>
  <block id="16c864cb4f3b00c59e1124932e49f342" category="paragraph"><block ref="16c864cb4f3b00c59e1124932e49f342" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e54433644e830ed1503561b778e9ded4" category="paragraph">La seguente tabella elenca le versioni di NFS e le funzionalità supportate.</block>
  <block id="9fb9dac7513c7ef8452aade8a52ad40d" category="cell">Funzionalità di vSphere</block>
  <block id="5b12ee0369243579651edca43ff65c85" category="cell">NFSv3</block>
  <block id="de841868c2911da76b8ae2da9fa3166d" category="cell">NFSv4.1</block>
  <block id="64e3cc476958b05086721cd6070004cf" category="cell">VMotion e Storage vMotion</block>
  <block id="05807e454c19f244770adae059b3c330" category="cell">Alta disponibilità</block>
  <block id="45a75e44a713fdf94dbf1dbaa0749188" category="cell">Tolleranza agli errori</block>
  <block id="f1e3446c69e4d87279ff7863482f9dcb" category="cell">DRS</block>
  <block id="6ca09f98e8925b2cb78bbf24eccc0186" category="cell">Profili host</block>
  <block id="ec8420797e3b089812499cce4047ded8" category="cell">DRS dello storage</block>
  <block id="7c19bf1cbe62a87a42857ef0b4fe22ae" category="cell">Controllo i/o dello storage</block>
  <block id="56d43ad1a280ada5e16fd2960ae44b32" category="cell">SRM</block>
  <block id="d595c8f30866b71ea121ced5cde66b1d" category="cell">Volumi virtuali</block>
  <block id="6ad5114acf73f68a85c72f11646920cb" category="cell">Accelerazione hardware (VAAI)</block>
  <block id="ad37ded9046268d8e5ea7cb253bb5dda" category="cell">Autenticazione Kerberos</block>
  <block id="45701e6ef9bc09dca07f8f4abe661dc6" category="cell">Sì (ottimizzato con vSphere 6.5 e versioni successive per supportare AES, krb5i)</block>
  <block id="76969a36155d2f41fc6cc3bd3faff244" category="cell">Supporto multipathing</block>
  <block id="54452390cac5f65f3bcec580ba079531" category="section-title">FlexGroup</block>
  <block id="f203949f2e35204098b66b9c1519b66e" category="paragraph">ONTAP 9.8 aggiunge il supporto per gli archivi dati FlexGroup in vSphere, insieme ai tool ONTAP per VMware vSphere 9.8. FlexGroup semplifica la creazione di datastore di grandi dimensioni e crea automaticamente una serie di volumi costituenti per ottenere le massime performance da un sistema ONTAP. Utilizza FlexGroup con vSphere per un singolo datastore vSphere scalabile con la potenza di un cluster ONTAP completo.</block>
  <block id="6829bc8d3038be0130fd2b409ad5e560" category="paragraph">Oltre ai test di sistema estesi con carichi di lavoro vSphere, ONTAP 9.8 aggiunge anche un nuovo meccanismo di offload delle copie per gli archivi dati FlexGroup. Questo utilizza un motore di copia migliorato per copiare i file tra i componenti in background, consentendo l'accesso sia all'origine che alla destinazione. Copie multiple utilizzano cloni di file immediatamente disponibili ed efficienti in termini di spazio all'interno di un costituente, se necessario, in base alla scala.</block>
  <block id="760383437e8e5cbe4a2560753da783fb" category="paragraph">ONTAP 9.8 aggiunge inoltre nuove metriche delle performance basate su file (IOPS, throughput e latenza) per i file FlexGroup, che possono essere visualizzate nei report del dashboard e delle macchine virtuali di ONTAP Tools. Il plug-in ONTAP Tools per VMware vSphere consente inoltre di impostare le regole di qualità del servizio (QoS) utilizzando una combinazione di IOPS massimo e/o minimo. Questi possono essere impostati su tutte le macchine virtuali in un datastore o singolarmente per macchine virtuali specifiche.</block>
  <block id="50783a97403d748762dff691da2d3723" category="paragraph">Ecco alcune Best practice aggiuntive sviluppate da NetApp:</block>
  <block id="d190c5fcdf8146c1dd7aad1140be4e64" category="list-text">Utilizza le impostazioni predefinite di provisioning FlexGroup. Mentre i tool ONTAP per VMware vSphere sono consigliati perché creano e montano il FlexGroup all'interno di vSphere, è possibile utilizzare Gestione di sistema ONTAP o la riga di comando per esigenze speciali. Anche in questo caso, utilizza le impostazioni predefinite, ad esempio il numero di membri costitutivi per nodo, perché questo è ciò che è stato testato con vSphere.</block>
  <block id="9f3fa65c2cc36eabd2228b984c30c5e1" category="list-text">Quando si ridimensiona un datastore FlexGroup, tenere presente che FlexGroup è costituito da più volumi FlexVol più piccoli che creano uno spazio dei nomi più grande. Di conseguenza, dimensionare l'archivio dati in modo che sia almeno 8 volte più grande della macchina virtuale più grande. Ad esempio, se nell'ambiente si dispone di una macchina virtuale da 6 TB, dimensionare il datastore FlexGroup non inferiore a 48 TB.</block>
  <block id="5fbee6b763967c822bb1e4a31665b11d" category="list-text">Consentire a FlexGroup di gestire lo spazio del datastore. Il dimensionamento automatico e il dimensionamento elastico sono stati testati con datastore vSphere. Nel caso in cui il datastore si avvicini alla capacità massima, utilizzare i tool ONTAP per VMware vSphere o un altro tool per ridimensionare il volume FlexGroup. FlexGroup mantiene la capacità e gli inode bilanciati tra i componenti, assegnando la priorità ai file all'interno di una cartella (VM) sullo stesso costituente, se la capacità lo consente.</block>
  <block id="1abaee3673de53b378351ee9dc679daa" category="list-text">VMware e NetApp attualmente non supportano un approccio di rete multipath comune. Per NFSv4.1, NetApp supporta pNFS, mentre VMware supporta il trunking di sessione. NFSv3 non supporta percorsi fisici multipli per un volume. Per FlexGroup con ONTAP 9.8, la Best practice consigliata consiste nel consentire ai tool ONTAP per VMware vSphere di eseguire il montaggio singolo, poiché l'effetto dell'accesso indiretto è generalmente minimo (microsecondi). È possibile utilizzare il DNS round-robin per distribuire host ESXi tra LIF su diversi nodi in FlexGroup, ma ciò richiederebbe la creazione e il montaggio di FlexGroup senza gli strumenti ONTAP per VMware vSphere. Le funzionalità di gestione delle performance non sarebbero quindi disponibili.</block>
  <block id="f5f11bb6aa98d02453eca36d5d1d2e19" category="list-text">Il supporto del datastore FlexGroup vSphere è stato testato fino a 1500 macchine virtuali con la release 9.8.</block>
  <block id="f48591b3ae898f29a551a2995a7dcfe8" category="list-text">Utilizzare il plug-in NFS per VMware VAAI per l'offload delle copie. Si noti che, sebbene il cloning sia migliorato all'interno di un datastore FlexGroup, ONTAP non offre vantaggi significativi in termini di performance rispetto alla copia host ESXi durante la copia di macchine virtuali tra volumi FlexVol e/o FlexGroup.</block>
  <block id="57a0d1deb8da99d321814990d26d21ed" category="list-text">Utilizza gli strumenti ONTAP per VMware vSphere 9.8 per monitorare le performance delle macchine virtuali FlexGroup utilizzando metriche ONTAP (report dashboard e macchine virtuali) e per gestire la qualità del servizio su singole macchine virtuali. Queste metriche non sono attualmente disponibili tramite i comandi o le API ONTAP.</block>
  <block id="ad971da24ec0a38449ebf31e4e2c9332" category="list-text">QoS (IOPS max/min) può essere impostato su singole macchine virtuali o su tutte le macchine virtuali in un datastore in quel momento. L'impostazione della QoS su tutte le macchine virtuali sostituisce le impostazioni separate per ogni macchina virtuale. Le impostazioni non si estendono alle macchine virtuali nuove o migrate in futuro; impostare la QoS sulle nuove macchine virtuali o riapplicare la QoS a tutte le macchine virtuali nel datastore.</block>
  <block id="3c9d41390700cbdfb2c273f00df0d6fd" category="list-text">Il plug-in SnapCenter per VMware vSphere release 4.4 supporta il backup e il ripristino delle macchine virtuali in un datastore FlexGroup sul sistema di storage primario. Mentre SnapMirror può essere utilizzato manualmente per replicare un FlexGroup su un sistema secondario, SCV 4.4 non gestisce le copie secondarie.</block>
  <block id="9db3527848e891e0a9340c443515e770" category="doc">Inizia a utilizzare NetApp e VMware</block>
  <block id="4b1c76979225b75a8e5f476356ed17e8" category="paragraph">VMware su NetApp: Il tuo viaggio inizia qui!</block>
  <block id="d7b056332bb039010d62c71ede534471" category="paragraph">Se sei pronto a iniziare a trasformare il tuo ambiente VMware, consulta la panoramica più recente delle soluzioni, consulta le nostre ultime soluzioni tecniche e le dimostrazioni dei prodotti. Se sei pronto per il passo successivo, contatta la community di esperti di NetApp e VMware per pianificare ed eseguire la modernizzazione del data center, il cloud ibrido o le iniziative applicative containerizzate.</block>
  <block id="bbaff12800505b22a853e8b7f4eb6a22" category="inline-link-macro">Contatto</block>
  <block id="be52ccc9c4dbcee449a6257062c0bcda" category="paragraph">Non sai da dove iniziare? <block ref="dcd7ec98fb935d9a5fd8ade723a47456" category="inline-link-macro-rx"></block> Membro degli esperti VMware di NetApp.</block>
  <block id="27b7a196b8196df4eeee9d21ade20a45" category="inline-link-macro">Formato PDF</block>
  <block id="e2fd99d21fbe7a1b2ed6388c40d48b0f" category="admonition">I contenuti presentati in questa pagina sono disponibili anche per il download in <block ref="a182addaadbc8a97de909268c8dc9bf0" category="inline-link-macro-rx"></block>.</block>
  <block id="11eb332ab75184a78c40c9174e16f520" category="paragraph-title">NetApp e VMware: Insieme è meglio</block>
  <block id="a3e92580de1a77cd25163bb63cd24a7d" category="inline-image-macro">link=<block ref="9b22e52230cfacf7992c01194e7a95d2" category="inline-link-rx"></block></block>
  <block id="f9da9dedda46425dea9fe2b0092e4b1a" category="paragraph"><block ref="f9da9dedda46425dea9fe2b0092e4b1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d3db539e5d56da6e251021138c5fe53f" category="section-title">Scopri le soluzioni NetApp e VMware</block>
  <block id="09f93ac387258fa68c085baba3c8fc44" category="inline-link-macro">NetApp &amp;amp; VMware: Insieme è meglio</block>
  <block id="fb758bbc93c23b25607ef41f302d4eef" category="list-text"><block ref="35ef54e3b8ad8ec505bab4b973f86177" category="inline-link-macro-rx"></block></block>
  <block id="b6741313b8f46ab1018ebd6a361c22a4" category="inline-link-macro">Panoramica delle ultime funzionalità di ONTAP 9.8</block>
  <block id="d393be6d50183d7362f0adb8bc92ae08" category="list-text"><block ref="d393be6d50183d7362f0adb8bc92ae08" category="inline-link-macro-rx"></block></block>
  <block id="b25a3522acbb33341ccacac99424fcce" category="inline-link-macro">Utilizzo del plug-in SnapCenter per VMware vSphere</block>
  <block id="a65898b7011ddfb663cdba62f90581c6" category="list-text"><block ref="a65898b7011ddfb663cdba62f90581c6" category="inline-link-macro-rx"></block></block>
  <block id="60b0390f50a5ad13d613d49cfe1bce0b" category="inline-link-macro">Ridefinire le performance di VMware con NetApp e NVMe</block>
  <block id="f6dde7f191b6b8f8351902b139ec8672" category="list-text"><block ref="f6dde7f191b6b8f8351902b139ec8672" category="inline-link-macro-rx"></block></block>
  <block id="c576371db342dc9cb166c73b0e157fb5" category="inline-link-macro">Un mondo dalle performance a basso costo per VMware Cloud su AWS</block>
  <block id="89487ceb1ada10e49befbbaed3b714ec" category="list-text"><block ref="89487ceb1ada10e49befbbaed3b714ec" category="inline-link-macro-rx"></block></block>
  <block id="92061b0dd7904e2299ac65ed9bc2d6af" category="inline-link-macro">Presentazione di VMware Tanzu con NetApp</block>
  <block id="ae7c9beb8e4adca6da75607ee83e2403" category="list-text"><block ref="ae7c9beb8e4adca6da75607ee83e2403" category="inline-link-macro-rx"></block></block>
  <block id="a88a91878fb958db59873117d16ad078" category="inline-link-macro">Virtual Desktop Infrastructure (VDI): Distribuzione di workstation dei dipendenti on-demand</block>
  <block id="9467ff6388811a059199513a0a484f0b" category="list-text"><block ref="9467ff6388811a059199513a0a484f0b" category="inline-link-macro-rx"></block></block>
  <block id="d5e64137a19403f8c1c89f50546b82c5" category="inline-link-macro">VMware su AWS: Architettura e opzioni di servizio</block>
  <block id="6cb2c8a80e576f132097e4d28cec24cd" category="list-text"><block ref="6cb2c8a80e576f132097e4d28cec24cd" category="inline-link-macro-rx"></block></block>
  <block id="cd4efd0ada1938b240dd48aa08010f04" category="inline-link-macro">Programmazione con le API Cloud Volumes Service di NetApp per ottimizzare l'esperienza di AWS</block>
  <block id="f61369e9428a21eb1090be340ef36f16" category="list-text"><block ref="f61369e9428a21eb1090be340ef36f16" category="inline-link-macro-rx"></block></block>
  <block id="6d14f3ca0f5be54f01fd579906dd80bb" category="inline-link-macro">Kubernetes: Esecuzione di K8s su vSphere e Tanzu</block>
  <block id="ef8e103737164442c629df5b5d98769d" category="list-text"><block ref="ef8e103737164442c629df5b5d98769d" category="inline-link-macro-rx"></block></block>
  <block id="7e0caac7f6d493fab662f4f4d65ae213" category="section-title">Crea il tuo data fabric virtualizzato</block>
  <block id="f1f4041236ed90e2a5e65e9a3c858875" category="section-title">Consulta le nostre più recenti soluzioni NetApp per VMware</block>
  <block id="0e8dd76bc961a90df87833953de6d067" category="inline-link-macro">VMware vSphere con ONTAP: Soluzioni NetApp</block>
  <block id="4e36e97d23b00520e4b573859ee4cb26" category="list-text"><block ref="4e36e97d23b00520e4b573859ee4cb26" category="inline-link-macro-rx"></block></block>
  <block id="b761cb4d962320708880627e8e2fe971" category="inline-link-macro">Volumi virtuali VMware vSphere con ONTAP</block>
  <block id="5b90454e2bf0f381c8f7fc928ef6fb9e" category="list-text"><block ref="5b90454e2bf0f381c8f7fc928ef6fb9e" category="inline-link-macro-rx"></block></block>
  <block id="730c2cf92bbe409c31ef1f39cf25377a" category="list-text"><block ref="730c2cf92bbe409c31ef1f39cf25377a" category="inline-link-macro-rx"></block></block>
  <block id="c375e5bb7184da46adef700a9a36d674" category="inline-link-macro">NetApp Modern NVMeoF VMware vSphere workload Design &amp;amp; convalida</block>
  <block id="b54be27467e63a98d65e6b17a914e373" category="list-text"><block ref="902dd483e9192a0b4645b4c8be7acbff" category="inline-link-macro-rx"></block></block>
  <block id="b860a89f6215a92f2320f0afe4e0ee05" category="inline-link-macro">NetApp Modern NVMeoF Cloud-Connected Flash Solution per VMware &amp;amp; SQL Server</block>
  <block id="0ebff16085636352cc1aa1e5b0003bdb" category="list-text"><block ref="ac70b8666634dd9095602966c4c61093" category="inline-link-macro-rx"></block></block>
  <block id="eccda9b55035b56259299545d5781136" category="inline-link-macro">Accelera il tuo percorso verso Kubernetes con VMware Tanzu &amp;amp; ONTAP</block>
  <block id="bb79e474557eb86fc30118354eef0039" category="list-text"><block ref="5dd92e330c2d45255a2025ee1eedd52d" category="inline-link-macro-rx"></block></block>
  <block id="7f8cf1c43494d40e935f5e99e38ce659" category="inline-link-macro">Ridurre i costi di esecuzione di VMware Cloud su AWS</block>
  <block id="f0d8a1b084d604c4db4319a2c5bbd522" category="list-text"><block ref="f0d8a1b084d604c4db4319a2c5bbd522" category="inline-link-macro-rx"></block></block>
  <block id="5ab6c918ee903c74a7d7c97b2432ebaf" category="section-title">Esplora le dimostrazioni video delle più recenti soluzioni VMware</block>
  <block id="7128c22bfdae1fe8be75c9a9ee56eca9" category="inline-link-macro">Best practice per VMware vSphere e NetApp ONTAP</block>
  <block id="4bff68299377013f00a500a01c7a2f19" category="list-text"><block ref="4bff68299377013f00a500a01c7a2f19" category="inline-link-macro-rx"></block></block>
  <block id="d2fa143a4aaef3477f2edb0d92676341" category="inline-link-macro">Il tuo ambiente VMware - eseguiamo su NVMe-of con ONTAP</block>
  <block id="207681662de4971035cc8d5c9347c986" category="list-text"><block ref="207681662de4971035cc8d5c9347c986" category="inline-link-macro-rx"></block></block>
  <block id="e9c2b8b8a9962013c07f83742ca35f0e" category="inline-link-macro">Disaster recovery vVol con gli strumenti ONTAP e VMware SRM</block>
  <block id="8ca7386c3cb63b01ffc6387ba41427ae" category="list-text"><block ref="8ca7386c3cb63b01ffc6387ba41427ae" category="inline-link-macro-rx"></block></block>
  <block id="e308c2a1dacddb5bc6ffa093081111e4" category="inline-link-macro">Backup e ripristino VMware per il Data Fabric</block>
  <block id="9934e59457fa5f31d39a58f1d55ac5d5" category="list-text"><block ref="9934e59457fa5f31d39a58f1d55ac5d5" category="inline-link-macro-rx"></block></block>
  <block id="c10a86f3b9530baf3bed3b02aaaf873f" category="section-title">Implementazione di un'infrastruttura flessibile di cloud ibrido e applicazioni modernizzate per VMware</block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="section-title">Video</block>
  <block id="f20368920280b50131814db2f83fda66" category="inline-link-macro">Architettura dei datastore VMware su NetApp All Flash FAS</block>
  <block id="8ff6498eeabd53b4271d75f543dc3bc4" category="list-text"><block ref="8ff6498eeabd53b4271d75f543dc3bc4" category="inline-link-macro-rx"></block></block>
  <block id="f1c2408ffc6e67ac6b34eb8da2b3039c" category="list-text"><block ref="f1c2408ffc6e67ac6b34eb8da2b3039c" category="inline-link-macro-rx"></block></block>
  <block id="253d309203cf1f2c1bb57255bd0a5bdc" category="inline-link-macro">Migrare le macchine virtuali VMware su Google Cloud</block>
  <block id="e5f4fe92e1832b16532011df56ee39a5" category="list-text"><block ref="c30f78a476776106411b5cd1ee097f4f" category="inline-link-macro-rx"></block></block>
  <block id="7518aab5e189037f632ee46ea9e3cf07" category="video-title">Implementazione dello storage NetApp persistente dinamico per VMware Tanzu, parte 1</block>
  <block id="f86bf601d6e42c44cf076ea1772ae13c" category="video-title">Implementazione dello storage NetApp persistente dinamico per VMware Tanzu, parte 2</block>
  <block id="bf5c12d4eed319d2dc2b2b7279944f71" category="video-title">Implementazione dello storage NetApp persistente dinamico per VMware Tanzu, parte 3</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="section-title">Blog</block>
  <block id="a398d57165e21c951dd9c9def41598a9" category="inline-link-macro">VMware Cloud su AWS: In che modo Fujitsu risparmia milioni utilizzando CVO</block>
  <block id="d750d47d5e87a6c526e7b40e12eab95b" category="list-text"><block ref="d750d47d5e87a6c526e7b40e12eab95b" category="inline-link-macro-rx"></block></block>
  <block id="3ca2b14e719d79aed66780282e879db4" category="section-title">Coinvolgi esperti NetApp e VMware</block>
  <block id="20475522c77401af1c203f23942ffda5" category="inline-link-macro">Partecipa al forum di discussione sulle soluzioni VMware</block>
  <block id="1dccc60a61431b3ef3f48709a0f68de7" category="list-text"><block ref="1dccc60a61431b3ef3f48709a0f68de7" category="inline-link-macro-rx"></block></block>
  <block id="a5810200dda7a3f37fc7eae5378cc8f3" category="inline-link-macro">Contatta il NetApp Global Services Team per iniziare</block>
  <block id="efb954cbfdbe0c54f04c904a2719b98a" category="list-text"><block ref="efb954cbfdbe0c54f04c904a2719b98a" category="inline-link-macro-rx"></block></block>
  <block id="a7ba4bd9aa10b0456b8f13ef40a2d1d5" category="summary">In questa pagina viene illustrata la procedura per l'implementazione di un datastore FCoE VMFS per lo storage NetApp ONTAP in un ambiente VMware vSphere.</block>
  <block id="1937a4bfde18bb02682d378132d0b6a9" category="doc">Datastore vSphere VMFS - protocollo storage Fibre Channel over Ethernet con ONTAP</block>
  <block id="66439ac6171413528646918952bff23e" category="paragraph">In questa sezione viene illustrata la creazione di un datastore VMFS con il protocollo di trasporto Fibre Channel over Ethernet (FCoE) allo storage ONTAP.</block>
  <block id="b087c7e1213b84e69de1a6e5214cd942" category="list-text">Un sistema storage ONTAP (FAS/AFF/CVO/ONTAP Select) con {ontap_version}</block>
  <block id="d9da372e69584852a9808bfa9fcc99a9" category="inline-link-macro">Una combinazione FCoE supportata</block>
  <block id="b61947ecee08267d1f6930ccbd646d52" category="list-text"><block ref="b61947ecee08267d1f6930ccbd646d52" category="inline-link-macro-rx"></block></block>
  <block id="08b42ec45ef1147093b9161cc743b0a0" category="inline-link-macro">Un foglio di lavoro di configurazione completo</block>
  <block id="bcf78e9148ebbc12ed4a54d2149cc2bc" category="list-text"><block ref="bcf78e9148ebbc12ed4a54d2149cc2bc" category="inline-link-macro-rx"></block></block>
  <block id="80ba2a0b5b5ae31742a18c682e724b6e" category="list-text">Con porte dati ONTAP FC o host vSphere collegati</block>
  <block id="d7b3fbe677a7bffd7e387a3578d6b481" category="inline-link-macro">Zoning FC/FCoE configurato</block>
  <block id="434da439fcd2a7729ac67cef537d6651" category="list-text"><block ref="434da439fcd2a7729ac67cef537d6651" category="inline-link-macro-rx"></block></block>
  <block id="5d914ccaef7b5404838cb47cff27fa11" category="list-text">Supporto FCoE</block>
  <block id="b74438cda33fca6618da9e30ef5fee5d" category="list-text">Supporto DCB</block>
  <block id="69b788fe29f78e1fb439efd1bec08ab6" category="inline-link-macro">Frame jumbo per FCoE</block>
  <block id="e92f4c11834e879e94fa441894d8e9c9" category="list-text"><block ref="e92f4c11834e879e94fa441894d8e9c9" category="inline-link-macro-rx"></block></block>
  <block id="42cdbee955a0e208306a321b74a948b1" category="section-title">Eseguire il provisioning di un datastore VMFS</block>
  <block id="f067d14dc86c5c0ec984803b3485a7a6" category="inline-link-macro">Verificare che la configurazione FCoE sia supportata</block>
  <block id="79d164739c1e0aaf7f56e13c2a4c66ac" category="list-text"><block ref="4201ef99768aac8f72883e5cb6ec656f" category="inline-link-macro-rx"></block>.</block>
  <block id="7fcd357d480b8eaa4a38cdbbddfd6c97" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block></block>
  <block id="f2a0a9000f5ff3910235e570c0ac5e44" category="list-text">Utilizzare<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Per verificare che l'FCP sia presente nell'elenco.</block>
  <block id="e5b8ca3e9ff580bcc9315fabcb34312e" category="list-text">Verificare che il protocollo FCP sia attivato su SVM.</block>
  <block id="015c565181667d59b83b7761e35682d1" category="inline-link-macro">Creare una nuova SVM con FCP.</block>
  <block id="de4606f963140e2d2d0a3df251ffd646" category="list-text"><block ref="de4606f963140e2d2d0a3df251ffd646" category="inline-link-macro-rx"></block></block>
  <block id="2d6fd01ea0767b50e214a74ff1fcfae0" category="list-text">Verificare che le interfacce logiche FCP siano disponibili su SVM.</block>
  <block id="46f04290f169589dff914e050d1a987b" category="list-text">Quando la SVM viene creata con la GUI, le interfacce logiche fanno parte di tale processo.</block>
  <block id="ee7f4720a3fc60686c4a9f7429a60cbc" category="list-text">Per rinominare l'interfaccia di rete, utilizzare<block ref="976ec076dd60d4d6296585d0275e7fbc" prefix=" " category="inline-code"></block>.</block>
  <block id="6e67c7d604ae439f60ceb51480fdbb1c" category="inline-link-macro">Creare e mappare un LUN</block>
  <block id="e4eeb9421963195597743339d2f38ff6" category="list-text"><block ref="96e32c32f267ac1d65d603f36f017a41" category="inline-link-macro-rx"></block>; Saltare questo passaggio se si utilizzano i tool ONTAP per VMware vSphere.</block>
  <block id="f6c0391a150cfd40a68682285c56e835" category="inline-link-macro">informazioni sull'adattatore di storage</block>
  <block id="60f05805eb8189d665c19856d5388e3c" category="list-text">Verificare che i driver HBA siano installati. Gli HBA supportati da VMware dispongono di driver implementati e devono essere visibili in <block ref="c5f1cce809af8cfecf09908d33f4c097" category="inline-link-macro-rx"></block>.</block>
  <block id="01a7d7174ccc6593753679eefec17d49" category="summary">Questa pagina descrive i vantaggi dell'automazione delle funzionalità ONTAP di base in un ambiente VMware vSphere.</block>
  <block id="1406aa071af210d31c6a2951fe66ddcc" category="doc">Introduzione all'automazione per ONTAP e vSphere</block>
  <block id="8e2b0503a0ad76f57c96738d7f0a3b0d" category="section-title">Automazione VMware</block>
  <block id="b5845209cb81dad561de4abe6e4481c4" category="paragraph">L'automazione è parte integrante della gestione degli ambienti VMware fin dai primi giorni di VMware ESX. La capacità di implementare l'infrastruttura come codice ed estendere le pratiche alle operazioni del cloud privato aiuta ad alleviare i problemi legati a scalabilità, flessibilità, self-provisioning ed efficienza.</block>
  <block id="f7c9a2e2ec395a7e4b605bb3df40abf8" category="paragraph">L'automazione può essere organizzata nelle seguenti categorie:</block>
  <block id="cba6f5a209d4f2ac1839f1c1e0a10051" category="list-text">*Implementazione dell'infrastruttura virtuale*</block>
  <block id="f41d0733c4edc0bf273a3d0587efb21e" category="list-text">*Operazioni della macchina guest*</block>
  <block id="7f2a4b0fa787b1f058accb56cc377af8" category="list-text">*Operazioni cloud*</block>
  <block id="290a03d97ea4e48144d20f313e0a0826" category="paragraph">Gli amministratori hanno a disposizione numerose opzioni per l'automazione dell'infrastruttura. Sia attraverso l'utilizzo di funzionalità vSphere native come profili host o specifiche di personalizzazione per le macchine virtuali alle API disponibili sui componenti software VMware, sui sistemi operativi e sui sistemi storage NetApp, sono disponibili documentazione e indicazioni significative.</block>
  <block id="217dd73ccc3bd89b5d4e35d0bf50ea6c" category="paragraph">Data ONTAP 8.0.1 e versioni successive supportano alcune API VMware vSphere per l'integrazione degli array (VAAI) quando l'host ESX esegue ESX 4.1 o versioni successive. VAAI è un insieme di API che consentono la comunicazione tra host VMware vSphere ESXi e dispositivi di storage. Queste funzionalità consentono di trasferire le operazioni dall'host ESX al sistema storage e aumentare il throughput di rete. L'host ESX attiva automaticamente le funzioni nell'ambiente corretto. È possibile determinare la misura in cui il sistema utilizza le funzioni VAAI controllando le statistiche contenute nei contatori VAAI.</block>
  <block id="16123583d64fd438c5d7f5b61a1c1d2f" category="paragraph">Il punto di partenza più comune per l'automazione dell'implementazione di un ambiente VMware è il provisioning di datastore a blocchi o basati su file. È importante definire i requisiti delle attività effettive prima di sviluppare l'automazione corrispondente.</block>
  <block id="a78bd4dd1db96affe0c2889376cccf53" category="paragraph">Per ulteriori informazioni sull'automazione degli ambienti VMware, consultare le seguenti risorse:</block>
  <block id="ebd98e15bf07fe37dfdc879f9d0d1f48" category="inline-link">Il NetApp Pub</block>
  <block id="6123648b7dec055b609781b4d47c1b26" category="list-text"><block ref="6c65ff4f1dfb7aa26df896b1c9c849eb" category="inline-link-rx"></block>. Automazione e gestione della configurazione NetApp.</block>
  <block id="7c4272bef0cc405b65fc74e3791664bc" category="inline-link">La community Ansible Galaxy per VMware</block>
  <block id="59fb42204e71850f7fd7024e5e6a1058" category="list-text"><block ref="c471bcaf7efa6fb129f37edaa7c41a56" category="inline-link-rx"></block>. Una raccolta di risorse Ansible per VMware.</block>
  <block id="1ec695bd70399ce37180f1d84a33d151" category="inline-link">Risorse VMware {code}</block>
  <block id="489c5322cef99651507b070e2240b6a8" category="list-text"><block ref="77e0562f07512a7a248241b7170b6944" category="inline-link-rx"></block>. Risorse necessarie per progettare soluzioni per il data center software-defined, inclusi forum, standard di progettazione, codice di esempio e tool per sviluppatori.</block>
  <block id="c5cd657df037c277c37216b73efb0b08" category="summary">Se possibile, utilizza sempre gli strumenti ONTAP per eseguire il provisioning di datastore e volumi. In questo modo si garantisce che volumi, percorsi di giunzione, LUN, igroups, policy di esportazione, e altre impostazioni sono configurate in modo compatibile.</block>
  <block id="d3b26e9021e83573a3d2a9050400a33a" category="doc">Best practice operative</block>
  <block id="4d15db58f26b374b36c283df6b5a5fc1" category="paragraph">SRM supporta iSCSI, Fibre Channel e NFS versione 3 con ONTAP 9 quando si utilizza la replica basata su array tramite SRA. SRM non supporta la replica basata su array per NFS versione 4.1 con datastore tradizionali o vVols.</block>
  <block id="61f54ceeb0338787a2ee2d801cbc62cd" category="paragraph">Per confermare la connettività, verificare sempre che sia possibile montare e smontare un nuovo datastore di test sul sito DR dal cluster ONTAP di destinazione. Verificare ogni protocollo che si intende utilizzare per la connettività del datastore. Una Best practice consiste nell'utilizzare gli strumenti ONTAP per creare il datastore di test, poiché sta eseguendo tutta l'automazione del datastore come indicato da SRM.</block>
  <block id="0ac3e8abbf45a28af68d22b0f59a973e" category="paragraph">I protocolli SAN devono essere omogenei per ciascun sito. È possibile combinare NFS e SAN, ma i protocolli SAN non devono essere combinati all'interno di un sito. Ad esempio, è possibile utilizzare FCP nel sito A e iSCSI nel sito B. Non utilizzare sia FCP che iSCSI nel sito A. Il motivo è che l'SRA non crea gruppi igroup misti nel sito di ripristino e l'SRM non filtra l'elenco di iniziatori fornito all'SRA.</block>
  <block id="150f8d9d5018ff00285d9aa158451d7b" category="paragraph">Le guide precedenti consigliano di creare LIF per la località dei dati. Vale a dire, montare sempre un datastore utilizzando una LIF situata sul nodo che fisicamente possiede il volume. Questo non è più un requisito nelle versioni moderne di ONTAP 9. Quando possibile, e se vengono fornite credenziali con ambito del cluster, gli strumenti ONTAP sceglieranno comunque di bilanciare il carico tra le LIF locali rispetto ai dati, ma non è un requisito per l'alta disponibilità o le performance.</block>
  <block id="ef6e8713285283721507f92e3c3ec674" category="paragraph">NetApp ONTAP 9 può essere configurato in modo da rimuovere automaticamente le copie Snapshot per preservare l'uptime in caso di esaurimento dello spazio quando la dimensione automatica non è in grado di fornire una capacità di emergenza sufficiente. L'impostazione predefinita per questa funzionalità non elimina automaticamente le copie Snapshot create da SnapMirror. Se le copie Snapshot di SnapMirror vengono eliminate, NetApp SRA non può invertire e risincronizzare la replica per il volume interessato. Per evitare che ONTAP elimini le copie Snapshot di SnapMirror, configurare la funzione di eliminazione automatica di Snapshot.</block>
  <block id="774a065cb3548cc61fb0ec3bc1494fbe" category="inline-link">Centro documentazione di ONTAP 9</block>
  <block id="a4f47f677f45e1e7075186d98e4f3ec1" category="paragraph">La dimensione automatica del volume deve essere impostata su<block ref="4d200fce73a8e1cc965cfc2c43343824" prefix=" " category="inline-code"></block> Per volumi contenenti datastore SAN e.<block ref="d89f4f8b1d7c18847b88b46142f61535" prefix=" " category="inline-code"></block> Per datastore NFS. Fare riferimento a.<block ref="ee2474fa4563985f2f3ebe16d4e1ab3a" category="inline-link-rx"></block> per una sintassi specifica.</block>
  <block id="e6955db66b8dc4aee170ebdb0b560249" category="section-title">SPBM e vVol</block>
  <block id="3077a08ffed60acebf18d37874130d44" category="paragraph">A partire da SRM 8.3, è supportata la protezione delle macchine virtuali che utilizzano datastore vVols. Le pianificazioni di SnapMirror sono esposte ai criteri di storage delle macchine virtuali dal provider VASA quando la replica di vVol è attivata nel menu delle impostazioni degli strumenti di ONTAP, come mostrato nelle seguenti schermate.</block>
  <block id="399c1894baf71c0529aa0fba66ea18fb" category="paragraph">Nell'esempio seguente viene illustrata l'abilitazione della replica vVol.</block>
  <block id="b180e7f35111dca8acd6c56cdbcabb3e" category="paragraph"><block ref="b180e7f35111dca8acd6c56cdbcabb3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be41c3baf700984021c43e2e6b661b0a" category="paragraph">La seguente schermata fornisce un esempio di pianificazioni SnapMirror visualizzate nella procedura guidata Crea policy di storage VM.</block>
  <block id="43c130b36e9e2b3d61409aa974f89fc7" category="paragraph"><block ref="43c130b36e9e2b3d61409aa974f89fc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6292d9eb6ea467a3c3560a65b7f63b5" category="paragraph">Il provider VASA di ONTAP supporta il failover su storage diverso. Ad esempio, il sistema può eseguire il failover da ONTAP Select in una posizione periferica a un sistema AFF nel data center principale. Indipendentemente dalla somiglianza dello storage, è necessario configurare sempre le mappature dei criteri di storage e le mappature inverse per le policy di storage delle macchine virtuali abilitate alla replica per garantire che i servizi forniti nel sito di recovery soddisfino le aspettative e i requisiti. La seguente schermata evidenzia un esempio di mappatura dei criteri.</block>
  <block id="783a951245ce43eb84161804072a38c6" category="paragraph"><block ref="783a951245ce43eb84161804072a38c6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb90dc8f7adfd00c74af3b815e2ac15" category="section-title">Creare volumi replicati per gli archivi dati vVols</block>
  <block id="18231879821321e0aed7de84fe876766" category="paragraph">A differenza dei datastore vVols precedenti, gli archivi dati vVols replicati devono essere creati dall'inizio con la replica abilitata e devono utilizzare volumi pre-creati sui sistemi ONTAP con relazioni SnapMirror. Ciò richiede la preconfigurazione di elementi come il peering dei cluster e il peering SVM. Queste attività devono essere eseguite dall'amministratore di ONTAP, in quanto ciò facilita una rigorosa separazione delle responsabilità tra coloro che gestiscono i sistemi ONTAP su più siti e coloro che sono principalmente responsabili delle operazioni di vSphere.</block>
  <block id="0a8c8293003bf411817ef3cedf18a2a9" category="paragraph">Questo viene fornito con un nuovo requisito per conto dell'amministratore di vSphere. Poiché i volumi vengono creati al di fuori dell'ambito degli strumenti di ONTAP, non è a conoscenza delle modifiche apportate dall'amministratore di ONTAP fino al periodo di riscoperta regolarmente pianificato. Per questo motivo, è consigliabile eseguire sempre la risDiscovery ogni volta che si crea un volume o una relazione SnapMirror da utilizzare con i vVol. È sufficiente fare clic con il pulsante destro del mouse sull'host o sul cluster e selezionare NetApp ONTAP Tools &gt; Update host and Storage Data (Aggiorna dati host e storage), come mostrato nella seguente schermata.</block>
  <block id="dd5e006520a09e3975e52f6fb8991fd2" category="paragraph"><block ref="dd5e006520a09e3975e52f6fb8991fd2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="550d51e15336d4a33bcbb0f26a6810f7" category="paragraph">Si consiglia di prestare attenzione quando si tratta di vVol e SRM. Non mischiare mai macchine virtuali protette e non protette nello stesso datastore vVols. Il motivo è che quando si utilizza SRM per eseguire il failover sul sito DR, solo le macchine virtuali che fanno parte del gruppo di protezione vengono messe in linea nel DR. Pertanto, quando si esegue una nuova protezione (reverse SnapMirror dal DR di nuovo alla produzione), è possibile sovrascrivere le macchine virtuali che non hanno eseguito il failover e che potrebbero contenere dati preziosi.</block>
  <block id="6d717f70d89096b731dfc63d7a1379e1" category="section-title">Informazioni sulle coppie di array</block>
  <block id="6dd3f3008fe81f402905b00c8dca007c" category="paragraph">Viene creato un gestore di array per ogni coppia di array. Con gli strumenti SRM e ONTAP, ogni accoppiamento di array viene eseguito con l'ambito di una SVM, anche se si utilizzano le credenziali del cluster. Ciò consente di segmentare i flussi di lavoro DR tra tenant in base alle SVM assegnate per la gestione. È possibile creare più gestori di array per un determinato cluster, che possono essere di natura asimmetrica. È possibile eseguire il fan-out o il fan-in tra diversi cluster di ONTAP 9. Ad esempio, è possibile utilizzare SVM-A e SVM-B nel cluster-1 in replica su SVM-C nel cluster-2, SVM-D nel cluster-3 o viceversa.</block>
  <block id="2219228418c053eb593ce0a1f318da47" category="paragraph">Quando si configurano le coppie di array in SRM, è necessario aggiungerle sempre in SRM nello stesso modo in cui sono state aggiunte agli strumenti ONTAP, ovvero devono utilizzare lo stesso nome utente, password e LIF di gestione. Questo requisito garantisce che SRA comunichi correttamente con l'array. La seguente schermata illustra come potrebbe essere visualizzato un cluster negli strumenti ONTAP e come potrebbe essere aggiunto a un gestore di array.</block>
  <block id="7ec48584a43ed8a9b1dda55398d97cf4" category="paragraph"><block ref="7ec48584a43ed8a9b1dda55398d97cf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b34135c8c4d2b14ceb7ebf595f00193" category="section-title">Informazioni sui gruppi di replica</block>
  <block id="6be59afd3c8bb91501f55a7e77ebe794" category="paragraph">I gruppi di replica contengono raccolte logiche di macchine virtuali che vengono ripristinate insieme. Il provider VASA di ONTAP Tools crea automaticamente i gruppi di replica. Poiché la replica di ONTAP SnapMirror avviene a livello di volume, tutte le macchine virtuali di un volume si trovano nello stesso gruppo di replica.</block>
  <block id="b57ec021fce4e5261ba61df6f0c013af" category="paragraph">Esistono diversi fattori da considerare per i gruppi di replica e il modo in cui si distribuiscono le macchine virtuali tra i volumi FlexVol. Il raggruppamento di macchine virtuali simili nello stesso volume può aumentare l'efficienza dello storage con sistemi ONTAP meno recenti che non dispongono di deduplica a livello di aggregato, ma il raggruppamento aumenta le dimensioni del volume e riduce la concorrenza i/o del volume. Il miglior equilibrio tra performance ed efficienza dello storage può essere ottenuto nei moderni sistemi ONTAP distribuendo le macchine virtuali tra volumi FlexVol nello stesso aggregato, sfruttando in tal modo la deduplica a livello di aggregato e ottenendo una maggiore parallelizzazione i/o tra più volumi. È possibile ripristinare le macchine virtuali nei volumi insieme perché un gruppo di protezione (discusso di seguito) può contenere più gruppi di replica. Il lato negativo di questo layout è che i blocchi potrebbero essere trasmessi via cavo più volte, perché il volume SnapMirror non tiene conto della deduplica aggregata.</block>
  <block id="c727c1020d3128dd7495a6e3e6f23736" category="paragraph">Un'ultima considerazione per i gruppi di replica è che ciascuno di essi è per sua natura un gruppo di coerenza logica (da non confondere con i gruppi di coerenza SRM). Questo perché tutte le VM nel volume vengono trasferite insieme utilizzando lo stesso snapshot. Pertanto, se si dispone di macchine virtuali che devono essere coerenti tra loro, è consigliabile memorizzarle nello stesso FlexVol.</block>
  <block id="9f8a350a2113ea4be6b4e5e5112514a3" category="section-title">A proposito dei gruppi di protezione</block>
  <block id="df77671ab2743af7f1d1457c200eb12c" category="paragraph">I gruppi di protezione definiscono macchine virtuali e datastore in gruppi che vengono ripristinati insieme dal sito protetto. Il sito protetto è il luogo in cui esistono le macchine virtuali configurate in un gruppo di protezione durante le normali operazioni in stato stazionario. È importante notare che anche se SRM potrebbe visualizzare più gestori di array per un gruppo di protezione, un gruppo di protezione non può estendersi a più gestori di array. Per questo motivo, non è necessario estendere i file delle macchine virtuali tra gli archivi dati su macchine virtuali SVM diverse.</block>
  <block id="b148467d645c3613c1c7a2607764c515" category="section-title">Sui piani di recovery</block>
  <block id="fd28cd9834ad3aa213c4fec2881064b5" category="paragraph">I piani di recovery definiscono quali gruppi di protezione vengono ripristinati nello stesso processo. È possibile configurare più gruppi di protezione nello stesso piano di ripristino. Inoltre, per abilitare più opzioni per l'esecuzione dei piani di ripristino, è possibile includere un singolo gruppo di protezione in più piani di ripristino.</block>
  <block id="77aa84394124509e5e4006dcfd18789f" category="paragraph">I piani di recovery consentono agli amministratori SRM di definire i flussi di lavoro di recovery assegnando le macchine virtuali a un gruppo di priorità da 1 (massimo) a 5 (minimo), con 3 (medio) come valore predefinito. All'interno di un gruppo di priorità, le VM possono essere configurate per le dipendenze.</block>
  <block id="6d72567442b1f361e3c0e89cbc7dfd6a" category="paragraph">Ad esempio, la tua azienda potrebbe disporre di un'applicazione business-critical di livello 1 che si affida a un server Microsoft SQL per il proprio database. Quindi, si decide di inserire le macchine virtuali nel gruppo di priorità 1. All'interno del gruppo di priorità 1, si inizia a pianificare l'ordine per visualizzare i servizi. Probabilmente si desidera che il controller di dominio Microsoft Windows venga avviato prima del server Microsoft SQL, che deve essere online prima del server dell'applicazione e così via. Aggiungere tutte queste macchine virtuali al gruppo di priorità e quindi impostare le dipendenze, perché le dipendenze si applicano solo all'interno di un determinato gruppo di priorità.</block>
  <block id="030d749269f8866de516a551b0286001" category="paragraph">NetApp consiglia vivamente di collaborare con i team delle applicazioni per comprendere l'ordine delle operazioni richieste in uno scenario di failover e per costruire di conseguenza i piani di recovery.</block>
  <block id="cebb1167d3e78885137c837f0abf8026" category="section-title">Test del failover</block>
  <block id="2772828493452c4a2ff21f8b2b66a1a7" category="paragraph">Come Best practice, eseguire sempre un test di failover ogni volta che viene apportata una modifica alla configurazione di uno storage VM protetto. In questo modo, in caso di disastro, puoi fidarti che Site Recovery Manager sia in grado di ripristinare i servizi entro l'obiettivo RTO previsto.</block>
  <block id="6ae8acfc86f5df3426d525fb95767506" category="paragraph">NetApp consiglia inoltre di confermare occasionalmente la funzionalità delle applicazioni in-guest, soprattutto dopo la riconfigurazione dello storage delle macchine virtuali.</block>
  <block id="bd47371bcd8b3d08d6b4b15481b08d93" category="paragraph">Quando viene eseguita un'operazione di test recovery, viene creata una rete bubble di test privata sull'host ESXi per le macchine virtuali. Tuttavia, questa rete non è connessa automaticamente ad alcun adattatore di rete fisico e pertanto non fornisce connettività tra gli host ESXi. Per consentire la comunicazione tra macchine virtuali in esecuzione su host ESXi diversi durante il test di DR, viene creata una rete fisica privata tra gli host ESXi nel sito di DR. Per verificare che la rete di test sia privata, è possibile separare fisicamente la rete a bolle di test oppure utilizzando VLAN o tag VLAN. Questa rete deve essere separata dalla rete di produzione, in quanto non è possibile posizionare le macchine virtuali sulla rete di produzione con indirizzi IP che potrebbero entrare in conflitto con i sistemi di produzione effettivi. Quando viene creato un piano di ripristino in SRM, la rete di test creata può essere selezionata come rete privata a cui connettere le macchine virtuali durante il test.</block>
  <block id="2be58fc410ddf2ba9c350135a617944a" category="paragraph">Una volta convalidato il test e non più necessario, eseguire un'operazione di pulizia. L'esecuzione della pulizia riporta le macchine virtuali protette al loro stato iniziale e ripristina il piano di ripristino allo stato Pronta.</block>
  <block id="6f07b53963ee80903f0f13654de2cc3a" category="section-title">Considerazioni sul failover</block>
  <block id="9d33d94019b4a595a1ea232926a4da1b" category="paragraph">Oltre all'ordine delle operazioni indicato in questa guida, è necessario considerare anche altri aspetti relativi al failover di un sito.</block>
  <block id="74abdd5cb502cd65bcf1d7ca484ab0c2" category="paragraph">Un problema che potrebbe essere dovuto affrontare è rappresentato dalle differenze di rete tra i siti. Alcuni ambienti potrebbero essere in grado di utilizzare gli stessi indirizzi IP di rete sia nel sito primario che nel sito di DR. Questa capacità viene definita come una LAN virtuale estesa (VLAN) o una configurazione di rete estesa. Altri ambienti potrebbero richiedere l'utilizzo di indirizzi IP di rete diversi (ad esempio, in VLAN diverse) nel sito primario rispetto al sito di DR.</block>
  <block id="1b41638d2115765dc12f82d77ce70138" category="paragraph">VMware offre diversi modi per risolvere questo problema. Per prima cosa, le tecnologie di virtualizzazione di rete come VMware NSX-T Data Center astraggono l'intero stack di rete dai livelli 2 fino a 7 dall'ambiente operativo, consentendo soluzioni più portatili. Scopri di più sulle opzioni NSX-T con SRM<block ref="99d78d594865360c3d4b527bf0a2a7f6" category="inline-link-rx"></block>.</block>
  <block id="09a74136e56a63c5aba38b89802d9080" category="paragraph">SRM consente inoltre di modificare la configurazione di rete di una macchina virtuale durante il ripristino. Questa riconfigurazione include impostazioni quali indirizzi IP, indirizzo gateway e impostazioni del server DNS. Diverse impostazioni di rete, che vengono applicate alle singole macchine virtuali durante il ripristino, possono essere specificate nelle impostazioni della proprietà di una macchina virtuale nel piano di ripristino.</block>
  <block id="99f0a91111e8acb2462e8df5ecf0ab8f" category="paragraph">Per configurare SRM in modo che applichi impostazioni di rete diverse a più macchine virtuali senza dover modificare le proprietà di ciascuna di esse nel piano di ripristino, VMware fornisce uno strumento chiamato dr-ip-customizer. Per informazioni su come utilizzare questa utility, consultare la documentazione di VMware<block ref="b959814092e3e6cdc8d22e768887e618" category="inline-link-rx"></block>.</block>
  <block id="3c8c527afa8ce5009c8f707f7fd4fabf" category="section-title">Proteggere di nuovo</block>
  <block id="3b496038cb575fc404f8b0783e570f7a" category="paragraph">Dopo un ripristino, il sito di ripristino diventa il nuovo sito di produzione. Poiché l'operazione di ripristino ha rotto la replica di SnapMirror, il nuovo sito di produzione non è protetto da eventuali disastri futuri. Una Best practice consiste nel proteggere il nuovo sito di produzione in un altro sito immediatamente dopo un ripristino. Se il sito di produzione originale è operativo, l'amministratore di VMware può utilizzare il sito di produzione originale come nuovo sito di ripristino per proteggere il nuovo sito di produzione, invertendo efficacemente la direzione della protezione. La protezione è disponibile solo in caso di guasti non catastrofici. Pertanto, i server vCenter originali, i server ESXi, i server SRM e i database corrispondenti devono essere ripristinabili. Se non sono disponibili, è necessario creare un nuovo gruppo di protezione e un nuovo piano di ripristino.</block>
  <block id="6d80a3efb80520f47b63dc279e1bea3d" category="section-title">Failback</block>
  <block id="2bf236f8aceaaff2b305848df524c42e" category="paragraph">Un'operazione di failback è fondamentalmente un failover in una direzione diversa rispetto a prima. Come Best practice, prima di tentare di eseguire il failback o, in altre parole, di eseguire il failover sul sito originale, è necessario verificare che il sito originale sia tornato a livelli di funzionalità accettabili. Se il sito originale è ancora compromesso, è necessario ritardare il failback fino a quando il guasto non viene risolto in modo adeguato.</block>
  <block id="cb03753531bad31391d7156433b98ae6" category="paragraph">Un'altra Best practice per il failback consiste nell'eseguire sempre un failover di test dopo aver completato la protezione e prima di eseguire il failback finale. In questo modo si verifica che i sistemi installati presso il sito originale possano completare l'operazione.</block>
  <block id="900a3b65ea54b6dcff72ed0d6ac66fdf" category="section-title">Protezione del sito originale</block>
  <block id="2a0c13d7b927063987bf931a141f2662" category="paragraph">Dopo il failback, devi confermare con tutti i possessori di azioni che i loro servizi sono stati riportati alla normalità prima di eseguire nuovamente la protezione,</block>
  <block id="12d059a2c7519f2e3497b30a71121503" category="paragraph">L'esecuzione di una nuova protezione dopo il failback riporta sostanzialmente l'ambiente nello stato in cui si trovava all'inizio, con la replica di SnapMirror nuovamente in esecuzione dal sito di produzione al sito di ripristino.</block>
  <block id="be493f1fc0b02ae45602c7c13f7b5dc7" category="summary">TR-4792 fornisce indicazioni per l'utilizzo di NetApp HCI 615C per carichi di lavoro di grafica 3D in un ambiente VMware Horizon con unità di elaborazione grafica NVIDIA (GPU) e software di virtualizzazione.</block>
  <block id="ff1d278a485c443dc5d8fc9f10f1a702" category="doc">NetApp HCI per l'infrastruttura di desktop virtuale con VMware Horizon 7: Potenzia i tuoi utenti più esperti con la grafica 3D</block>
  <block id="e3162938e0d7b1bbc74111cc5b5871c5" category="paragraph">TR-4792 fornisce indicazioni sull'utilizzo del nodo di calcolo NetApp H615C per carichi di lavoro di grafica 3D in un ambiente VMware Horizon con unità di elaborazione grafica NVIDIA (GPU) e software di virtualizzazione. Fornisce inoltre i risultati dei test preliminari di SPECviewperf 13 per H615C.</block>
  <block id="1de37c09602b46db5de57a946efe2768" category="paragraph"><block ref="1de37c09602b46db5de57a946efe2768" category="inline-link-macro-rx"></block></block>
  <block id="c0ddbacfe0f703e62904558059e40001" category="summary">Questa sezione fornisce indicazioni sulle funzionalità supportate da release specifiche di ONTAP e vSphere. NetApp consiglia di confermare una combinazione specifica di release con la matrice di interoperabilità NetApp.</block>
  <block id="bc8be72fdc9d6054f356bb2b7f80fd12" category="inline-link">Matrice di interoperabilità NetApp</block>
  <block id="2f6ae9fa35fbcb0ec3205505ee027642" category="paragraph">Questa sezione fornisce indicazioni sulle funzionalità supportate da release specifiche di ONTAP e vSphere. NetApp consiglia di confermare una combinazione specifica di release con<block ref="50c84d2622d2bc5cc86e7d8724309075" category="inline-link-rx"></block>.</block>
  <block id="7912c2100fd9b3b96b0b03e7a068fc9a" category="section-title">Release di ONTAP</block>
  <block id="8ee2892e0fb10cc58205a3d682abdb58" category="paragraph">Al momento della pubblicazione, NetApp offre il supporto completo per queste famiglie di release:</block>
  <block id="0fcf2ee62acd9eae83b609a0e7ecaa72" category="list-text">ONTAP 9.5</block>
  <block id="7dd2a92fd3f41a5334edf46f95d77e71" category="list-text">ONTAP 9.6</block>
  <block id="3447b91e516e4fc6b5dba827fcb68bee" category="list-text">ONTAP 9.7</block>
  <block id="2abfff2974f589f7a217325f304e0ec5" category="list-text">ONTAP 9.8</block>
  <block id="ee4651b72d795faf25a1382eb1315a95" category="section-title">Supporto di vSphere ed ESXi</block>
  <block id="c3123497dcfdcdf46908ad18a51928ca" category="paragraph">NetApp ONTAP offre un ampio supporto per gli host vSphere ESXi. Le quattro principali famiglie di release appena descritte (9.5, 9.6, 9.7 e 9.8) sono completamente supportate come piattaforme di storage dei dati per le recenti release di vSphere, tra cui 6.0, 6.5 e 7.0 (inclusi gli aggiornamenti per queste release). L'interoperabilità NFS v3 è ampiamente definita e NetApp supporta qualsiasi client, inclusi gli hypervisor, conforme allo standard NFS v3. Il supporto di NFSv4.1 è limitato a vSphere 6.0 fino a 7.0.</block>
  <block id="8276b4666ec9fee7d71b01f6ee2b9955" category="paragraph">Per gli ambienti SAN, NetApp esegue test approfonditi dei componenti SAN. In generale, NetApp supporta i server rack X86-64 standard e i server Cisco UCS insieme agli adattatori Ethernet standard per le connessioni iSCSI. Gli ambienti FC, FCoE e NVMe/FC dispongono di un supporto più specifico grazie al firmware e ai driver HBA necessari.</block>
  <block id="a9854fb3ed44e3b8e9236c5b70405101" category="paragraph">Controllare sempre<block ref="50c84d2622d2bc5cc86e7d8724309075" category="inline-link-rx"></block> per confermare il supporto per una configurazione hardware e software specifica.</block>
  <block id="eb3ac5aa51c1cacfa31cee70ac6586f0" category="paragraph">Questo plug-in per gli host ESXi consente di trasferire le operazioni a ONTAP utilizzando VAAI. L'ultima release, 1.1.2, include il supporto per datastore NFSv4.1, incluso il supporto Kerberos (krb5 e krb5i). È supportato con ESXi 6.0, 6.5 e 7.0 insieme a ONTAP 9.5-9.8.</block>
  <block id="b2dd36bd4918e00f8b2e15e6d62a4b94" category="section-title">Provider VASA</block>
  <block id="15c15a65e1486d45a44c6f61927ef836" category="paragraph">Il provider VASA di NetApp supporta il provisioning e la gestione di vVol (vedere la sezione 3.7). Le recenti release del provider VASA supportano ESXi 6.0, 6.5 e 7.0 insieme a ONTAP 9.5-9.8.</block>
  <block id="c13550c8bc0f9b77e92bd2533221de9d" category="paragraph">I tool ONTAP per VMware vSphere sono fondamentali per la gestione dello storage ONTAP insieme a vSphere (l'utilizzo è una Best practice). L'ultima versione, 9.8, è supportata con vSphere 6.5 e 7.0 insieme a ONTAP 9.5-9.8.</block>
  <block id="1f82b18dcba5f32a085bc502cdd0c6b7" category="summary">Con ONTAP, il concetto di storage virtual machine (SVM) offre una segmentazione rigorosa in ambienti multi-tenant sicuri.</block>
  <block id="7520e12a140ccf3de279fe2fd48889e4" category="doc">Best practice per l'implementazione</block>
  <block id="1b4574c516231b685bb37b013b789b06" category="section-title">Layout e segmentazione SVM per SMT</block>
  <block id="446e04546ec0567eeeeef8e07368ab40" category="paragraph">Con ONTAP, il concetto di storage virtual machine (SVM) offre una segmentazione rigorosa in ambienti multi-tenant sicuri. Gli utenti SVM su una SVM non possono accedere o gestire le risorse da un'altra. In questo modo, è possibile sfruttare la tecnologia ONTAP creando SVM separate per diverse business unit che gestiscono i propri flussi di lavoro SRM sullo stesso cluster per una maggiore efficienza dello storage globale.</block>
  <block id="f98c1d223f34b2fdaf90eab1a3bc6a25" category="paragraph">Valutare la possibilità di gestire ONTAP utilizzando account con ambito SVM e LIF di gestione SVM per non solo migliorare i controlli di sicurezza, ma anche le performance. Le performance sono intrinsecamente maggiori quando si utilizzano connessioni con ambito SVM perché l'SRA non è richiesto per elaborare tutte le risorse di un intero cluster, incluse le risorse fisiche. Al contrario, l'IT deve solo comprendere le risorse logiche astratte dalla specifica SVM.</block>
  <block id="849d4d5e8a5d5b2747d8375d2ec03b29" category="paragraph">Quando si utilizzano solo i protocolli NAS (senza accesso SAN), è anche possibile sfruttare la nuova modalità NAS ottimizzata impostando il seguente parametro (si noti che il nome è tale perché SRA e VASA utilizzano gli stessi servizi di back-end nell'appliance):</block>
  <block id="05f551a655f40911851a53ba0c721997" category="list-text">Accedere al pannello di controllo all'indirizzo<block ref="501a3478972ee5e3d6f109bdc0514bdc" prefix=" " category="inline-code"></block> E fare clic su interfaccia CLI basata su Web.</block>
  <block id="b0cc185c73ca964d1429a601551c68f5" category="list-text">Eseguire il comando<block ref="4f35e9b3adeccfaf0287d002b134221c" prefix=" " category="inline-code"></block>.</block>
  <block id="5f7e35f90689bef91afe9f01257c61ac" category="list-text">Eseguire il comando<block ref="aa610e3ab4e5162f432950793f30a387" prefix=" " category="inline-code"></block>.</block>
  <block id="ba2a1e4d95dc56709260e82cca20a789" category="list-text">Eseguire il comando<block ref="6d83e9fce5e947159c3c34b9f499e80e" prefix=" " category="inline-code"></block>.</block>
  <block id="2d14ca751c8ce5a724606e4f75f02c50" category="section-title">Implementare gli strumenti e le considerazioni di ONTAP per i vVol</block>
  <block id="fa3a193f1892cf0f45f4a95a35aa3c4b" category="paragraph">Se si intende utilizzare SRM con vVol, è necessario gestire lo storage utilizzando credenziali con ambito cluster e una LIF di gestione del cluster. Questo perché il provider VASA deve comprendere l'architettura fisica sottostante per soddisfare le policy richieste per le policy di storage delle macchine virtuali. Ad esempio, se si dispone di una policy che richiede storage all-flash, il provider VASA deve essere in grado di vedere quali sistemi sono tutti flash.</block>
  <block id="31d279d1cc3bc5a4281567ba697f678d" category="paragraph">Un'altra Best practice per l'implementazione consiste nel non memorizzare mai l'appliance ONTAP Tools su un datastore vVols gestito dall'IT. Ciò potrebbe causare l'impossibilità di accendere il provider VASA perché non è possibile creare lo swap vVol per l'appliance perché l'appliance non è in linea.</block>
  <block id="97399fb37deca0d463aa5c7dc8d064a6" category="section-title">Best practice per la gestione dei sistemi ONTAP 9</block>
  <block id="b4cbecf196108ad163c73c4e4194dde2" category="paragraph">Come indicato in precedenza, è possibile gestire i cluster ONTAP utilizzando credenziali cluster o SVM con ambito e LIF di gestione. Per ottenere performance ottimali, è consigliabile utilizzare credenziali con ambito SVM ogni volta che non si utilizza vVol. Tuttavia, in questo modo, è necessario conoscere alcuni requisiti e perdere alcune funzionalità.</block>
  <block id="fec05e53ca7d96aaf3e4c1a1b2502bea" category="list-text">L'account SVM vsadmin predefinito non dispone del livello di accesso richiesto per eseguire le attività degli strumenti ONTAP. Pertanto, è necessario creare un nuovo account SVM.</block>
  <block id="8557644859e03f54860c95ffb0bcfd53" category="list-text">Se si utilizza ONTAP 9.8 o versioni successive, si consiglia di creare un account utente RBAC con privilegi minimi utilizzando il menu utenti di Gestione di sistema di ONTAP e il file JSON disponibile sull'appliance ONTAP Tools all'indirizzo<block ref="137f8d4bb89dcc34c3bfe48f2a61c95e" prefix=" " category="inline-code"></block>. Utilizzare la password di amministratore per scaricare il file JSON. Può essere utilizzato per account SVM o con ambito cluster.</block>
  <block id="a7a83b5e4f375c0585588b9c7ff92219" category="inline-link">Toolchest del sito di supporto NetApp</block>
  <block id="fdfe9ba9104df6a32fff0f859291ea3c" category="paragraph">Se si utilizza ONTAP 9.6 o versioni precedenti, utilizzare lo strumento RBAC User Creator (RUC) disponibile in<block ref="bdbf96c18cf8ac76d01fba7057b81b87" category="inline-link-rx"></block>.</block>
  <block id="ea7a3d08d55dc3e8ecf89d2a5d5e302d" category="list-text">Poiché il plug-in dell'interfaccia utente di vCenter, il provider VASA e il server SRA sono tutti servizi completamente integrati, è necessario aggiungere storage all'adattatore SRM nello stesso modo in cui si aggiunge storage nell'interfaccia utente di vCenter per gli strumenti ONTAP. In caso contrario, il server SRA potrebbe non riconoscere le richieste inviate da SRM tramite l'adattatore SRA.</block>
  <block id="b473de4177eeaa79a66448798a446db3" category="list-text">Il controllo del percorso NFS non viene eseguito quando si utilizzano credenziali con ambito SVM. Questo perché la posizione fisica è logicamente astratta dalla SVM. Tuttavia, questo non è motivo di preoccupazione, in quanto i sistemi ONTAP moderni non subiscono più alcun calo significativo delle performance quando si utilizzano percorsi indiretti.</block>
  <block id="6e62430b92a7c5a0b8512436b163a10d" category="list-text">Il risparmio di spazio aggregato dovuto all'efficienza dello storage potrebbe non essere segnalato.</block>
  <block id="93d86aa51e0909549d1b1210f887aef3" category="list-text">Se supportati, i mirror di condivisione del carico non possono essere aggiornati.</block>
  <block id="647d380b52e259fe7ed2e2582bc54b27" category="list-text">La registrazione EMS potrebbe non essere eseguita sui sistemi ONTAP gestiti con credenziali SVM con ambito.</block>
  <block id="a9b73ebef33c98ef5a1044177d2b49f3" category="summary">VMware vCenter Site Recovery Manager è un'offerta di disaster recovery che offre orchestrazione automatica e test senza interruzioni di piani di recovery centralizzati per semplificare la gestione del disaster recovery per tutte le applicazioni virtualizzate.</block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">Conclusione</block>
  <block id="06f589670c0d0455912cc8bb70b78701" category="paragraph">Implementando Site Recovery Manager sui sistemi NetApp ONTAP, è possibile ridurre drasticamente i costi e la complessità del disaster recovery. Con appliance di storage scalabili, facili da gestire e dalle performance elevate e solide offerte software, NetApp offre soluzioni di storage e gestione dei dati flessibili per supportare gli ambienti vSphere.</block>
  <block id="00549aec33ddcae6a708ed7368a7bcd0" category="paragraph">Le Best practice e i consigli forniti in questa guida non sono una soluzione adatta a tutti. Questo documento contiene una raccolta di Best practice e consigli che forniscono linee guida per pianificare, implementare e gestire i piani di DR SRM. Per pianificare e implementare gli ambienti VMware vCenter Site Recovery VMware sullo storage NetApp, rivolgersi a un esperto VMware locale. Gli esperti VMware di NetApp sono in grado di identificare rapidamente le esigenze e le esigenze di qualsiasi ambiente vSphere e di adattare la soluzione di storage di conseguenza.</block>
  <block id="36f00397200c227ebfe56599e7bafcd5" category="doc">NVA-1129-DESIGN: Calcolo per l'utente finale VMware con GPU NetApp HCI e NVIDIA</block>
  <block id="8a36e2f35bf4a10959caf61f15d8df63" category="paragraph"><block ref="8a36e2f35bf4a10959caf61f15d8df63" category="inline-link-macro-rx"></block></block>
  <block id="0416d04b345b434b120840c30ddaf0a1" category="paragraph">NetApp ha sviluppato un set di impostazioni di multipathing host ESXi e timeout HBA per un comportamento corretto con ONTAP in base ai test NetApp. Questi sono facilmente impostabili utilizzando i tool ONTAP per VMware vSphere. Dalla dashboard Riepilogo, fare clic su Modifica impostazioni nel portlet sistemi host o fare clic con il pulsante destro del mouse sull'host in vCenter, quindi selezionare ONTAP Tools &gt; Set Recommended Values (Strumenti di configurazione &gt; Imposta valori consigliati). Di seguito sono riportate le impostazioni host attualmente consigliate per la versione 9.8.</block>
  <block id="678582eb0cbbe0e063e618d230b63223" category="cell">*Impostazione host*</block>
  <block id="dfe49b73bd7e747701b49f9ed21ea2d6" category="cell">*Valore consigliato da NetApp*</block>
  <block id="edceae57d92287f4f6200f94d3259cd0" category="cell">*Riavvio richiesto*</block>
  <block id="dc3a6955a23583876d020db0f6b80d4d" category="cell">*Configurazione avanzata ESXi*</block>
  <block id="73663d0d00956f0632e4ae75d811d53f" category="cell">VMFS3.HardwareAcceleratedLocking</block>
  <block id="5fffea5cb752d304de420a5efa158e13" category="cell">Lasciare come impostato (il valore predefinito di VMware è 1)</block>
  <block id="1b50110aedae4d8d2043a4eb9beb20af" category="cell">VMFS3.EnableBlockDelete</block>
  <block id="5d1b81f1885499e392018ebd7124ad37" category="inline-link-macro">VMware KB 2007427</block>
  <block id="36478566e3585eb8ea863e941dcb967a" category="cell">Lasciare come impostato (il valore predefinito di VMware è 0, ma non è necessario per VMFS6). Per ulteriori informazioni, vedere <block ref="68c2cf0ecb6a1c6abaf6e56c035d5866" category="inline-link-macro-rx"></block></block>
  <block id="571cc1d48c6d1ff3cf7e3a54cb035753" category="cell">*Impostazioni NFS*</block>
  <block id="c3b49a515dd0046685e06092642aa139" category="cell">NET.TcpipelHeapSize</block>
  <block id="875f6b98e20edfecb56f9013d00987f6" category="cell">VSphere 6.0 o versione successiva, impostato su 32. Tutte le altre configurazioni NFS, impostate su 30</block>
  <block id="504e96cc79e7efe30a8271cea152d9d1" category="cell">NET.TcpipelHeapMax</block>
  <block id="a8af33a99dd728969fd947da27a2f69f" category="cell">Impostato su 512 MB per la maggior parte delle release di vSphere 6.X. Impostare su 1024 MB per 6.5U3, 6.7U3 e 7.0 o versioni successive.</block>
  <block id="5f1e7b6431061565550e292d05c73588" category="cell">NFS.MaxVolumes</block>
  <block id="e787d5b0d643685421632a1af3914963" category="cell">VSphere 6.0 o versione successiva, impostato su 256 per tutte le altre configurazioni NFS, impostato su 64.</block>
  <block id="3058676a1cf088aa4a73312ac36f2a58" category="cell">NFS41.MaxVolumes</block>
  <block id="62c07f94c64184ee5d530e4c0917093f" category="cell">VSphere 6.0 o versione successiva, impostato su 256.</block>
  <block id="e18600af98c17fae10fdba0dc89979ed" category="cell">NFS.MaxQueueDepth^1^</block>
  <block id="be7707fa525d0124489c9fe3072f78de" category="cell">VSphere 6.0 o versione successiva, impostato su 128</block>
  <block id="18e1fb6924459470760771b20ab0c379" category="cell">NFS.HeartbeatMaxFailures</block>
  <block id="138989cbe5dd3a4997662e0f65c17878" category="cell">Impostare su 10 per tutte le configurazioni NFS</block>
  <block id="1aa26eb281359ba3b9a9a4b83a09ed46" category="cell">NFS.HeartbeatFrequency</block>
  <block id="7ea6e8664542e3beb1aea10425efb4db" category="cell">Impostare su 12 per tutte le configurazioni NFS</block>
  <block id="eb4182715f8cde98563dc59ea36461d3" category="cell">NFS.HeartbeatTimeout</block>
  <block id="45aa5481fa55802a29a96aefd2f5dab1" category="cell">Impostare su 5 per tutte le configurazioni NFS.</block>
  <block id="54a08b15243d9078d3b5a47f8242da6f" category="cell">SunRPC.MaxConnPerIP</block>
  <block id="9a9ccbecb3f315797ff8e709d85a0e18" category="cell">VSphere 7.0 o versione successiva, impostato su 128.</block>
  <block id="c0b3fd5512c2093847f753f398290f30" category="cell">*Impostazioni FC/FCoE*</block>
  <block id="2e556ad678160413b32dcca55c7d1f5f" category="cell">Policy di selezione del percorso</block>
  <block id="fb62337a3ef32f4701b639339a4ceb33" category="cell">Impostare su RR (round robin) quando si utilizzano percorsi FC con ALUA. Impostare su FISSO per tutte le altre configurazioni. L'impostazione di questo valore su RR consente di fornire il bilanciamento del carico in tutti i percorsi attivi/ottimizzati. Il valore FISSO è per le configurazioni precedenti non ALUA e aiuta a prevenire i/o proxy In altre parole, consente di evitare che l'i/o venga collegato all'altro nodo di una coppia ad alta disponibilità (ha) in un ambiente con Data ONTAP in 7-Mode</block>
  <block id="117704664d6cada78ac3107380f63d23" category="cell">Disk.QFullSampleSize</block>
  <block id="0e82e1f81de2159b0e9bee0b7be00dc9" category="cell">Impostare su 32 per tutte le configurazioni. L'impostazione di questo valore aiuta a prevenire gli errori di i/O.</block>
  <block id="f66a3c183f0e736240b77f8b755c880e" category="cell">Disk.QFullThreshold</block>
  <block id="bdd8c1d08eabb5e1923ed8f0c4b10ba4" category="cell">Impostare su 8 per tutte le configurazioni. L'impostazione di questo valore aiuta a prevenire gli errori di i/O.</block>
  <block id="19c08de7404551288e1274186e039ef4" category="cell">Timeout HBA FC Emulex</block>
  <block id="b4dbfc2d52627e923cbb563a31ff756d" category="cell">Utilizzare il valore predefinito.</block>
  <block id="d46cddda4da7ec11f17472d11df95b68" category="cell">Timeout HBA FC QLogic</block>
  <block id="19b5aaf3e2cb86809996ca63a2a416b0" category="cell">*Impostazioni iSCSI*</block>
  <block id="2aa077454308383f1e82025427cd7362" category="cell">Impostare su RR (round robin) per tutti i percorsi iSCSI. L'impostazione di questo valore su RR consente di fornire il bilanciamento del carico in tutti i percorsi attivi/ottimizzati.</block>
  <block id="0340eb1bcbfc6cd3c62b8a878d8d643b" category="cell">Impostare su 32 per tutte le configurazioni. L'impostazione di questo valore aiuta a prevenire gli errori di i/O.</block>
  <block id="891c10448731ad57490b9a932dabfff8" category="inline-link-macro">VMware KB 86331</block>
  <block id="2c572e3c397fe100b075a09359c9cc23" category="admonition">1 - l'opzione di configurazione avanzata di NFS MaxQueueDepth potrebbe non funzionare come previsto quando si utilizzano VMware vSphere ESXi 7.0.1 e VMware vSphere ESXi 7.0.2. Fare riferimento a. <block ref="861055760f3cd527823fd34a49459992" category="inline-link-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="fb55ee99c04280ac638757869929785d" category="paragraph">Gli strumenti ONTAP specificano anche alcune impostazioni predefinite durante la creazione di ONTAP FlexVol Volumes e LUN:</block>
  <block id="3f7502a5f109d7a73706aba1c0741a4b" category="cell">*Strumento ONTAP*</block>
  <block id="485577e97e8efcd504fc8e8b13e613f1" category="cell">*Impostazione predefinita*</block>
  <block id="5938fe448c8661febcef3f4e779e3adb" category="cell">Riserva di Snapshot (-percento-spazio-snapshot)</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="7218aec62575561a6de1cae8d5658390" category="cell">Riserva frazionaria (-riserva frazionaria)</block>
  <block id="3a7e09ff0fa38663ffe6d91324ea75d9" category="cell">Access time update (-atime-update)</block>
  <block id="f8320b26d30ab433c5a54546d21f414c" category="cell">Falso</block>
  <block id="e93200d5b0d16915bf04236790544b2f" category="cell">Readahead minimo (-min-readahead)</block>
  <block id="eee57b9c7d333899f3df6ffd10ec50df" category="cell">Copie Snapshot pianificate</block>
  <block id="6adf97f83acf6453d4a6a4b1070f3754" category="cell">Nessuno</block>
  <block id="fd18465573ec21a6218982055981f6b1" category="cell">Efficienza dello storage</block>
  <block id="00d23a76e43b46dae9ec7aa9dcbebb32" category="cell">Attivato</block>
  <block id="f65fd63b63c9e9f25bf6bc141e83de34" category="cell">Garanzia di volume</block>
  <block id="c2410aebdf425dabcc65e546e506b03e" category="cell">Nessuno (con thin provisioning)</block>
  <block id="f97c03bf3e9580446d70d479f5aad1e0" category="cell">Dimensionamento automatico del volume</block>
  <block id="d89f4f8b1d7c18847b88b46142f61535" category="cell">grow_shrink</block>
  <block id="ace72ec54e17777d27eb8bdb9d57e782" category="cell">Prenotazione di spazio LUN</block>
  <block id="b9f5c797ebbf55adccdd8539a65a0241" category="cell">Disattivato</block>
  <block id="514aa7792a71ab4ab677eb2385131aae" category="cell">Allocazione dello spazio del LUN</block>
  <block id="0464f851d84d05f0a9db9051354e5581" category="section-title">Altre considerazioni sulla configurazione del multipath host</block>
  <block id="5fcb3de72ca1920517439049153d961d" category="paragraph">Sebbene non sia attualmente configurato dai tool ONTAP disponibili, NetApp consiglia di considerare le seguenti opzioni di configurazione:</block>
  <block id="840731ae1cb9e4b23e19f645ab018b6f" category="inline-link">2069356</block>
  <block id="5073fc9da327263a7db04fd449991e6a" category="list-text">In ambienti dalle performance elevate o quando si testano le performance con un singolo datastore LUN, si consiglia di modificare l'impostazione del bilanciamento del carico del criterio di selezione del percorso (PSP) round-robin (VMW_PSP_RR) dall'impostazione IOPS predefinita di 1000 a un valore di 1. Consulta la Knowledge base di VMware<block ref="f3f4762788a6845119bdb5b9c9179bda" category="inline-link-rx"></block> per ulteriori informazioni.</block>
  <block id="1ea3eb55b985cf75e100607ee8bd935d" category="inline-link">Plug-in e policy per la selezione del percorso</block>
  <block id="249afbf456bd04d574e8d362d5bf133c" category="list-text">In vSphere 6.7 Update 1, VMware ha introdotto un nuovo meccanismo di bilanciamento del carico di latenza per la PSP Round Robin. La nuova opzione prende in considerazione la larghezza di banda i/o e la latenza del percorso quando si seleziona il percorso ottimale per i/O. Potrebbe essere utile utilizzarlo in ambienti con connettività di percorso non equivalente, ad esempio nei casi in cui vi sono più salti di rete su un percorso rispetto a un altro, o quando si utilizza un sistema NetApp All SAN Array. Vedere<block ref="f5ecc69f2970e2e9c8638ad278ec38f7" category="inline-link-rx"></block> per ulteriori informazioni.</block>
  <block id="53f8aa6361303e58854a4451a706df5e" category="doc">WP-7355: Plug-in SnapCenter VMware vSphere - sicurezza del prodotto</block>
  <block id="ae9e79ac4b60eba67cf1c7508417b42c" category="paragraph">Il plug-in NetApp SnapCenter per il software engineering VMware vSphere utilizza le seguenti attività di sviluppo sicuro:</block>
  <block id="b25a1098aff7d0c5ee590f1e1a114bb9" category="list-text">*Dynamic Application Security testing (DAST).* tecnologie progettate per rilevare condizioni vulnerabili sulle applicazioni in esecuzione. DAST testa le interfacce HTTP e HTML esposte delle applicazioni web-enable.</block>
  <block id="6cc1fee6b4fc48755d78e93170bbed93" category="list-text">*Valuta del codice di terze parti.* come parte dello sviluppo di software e dell'utilizzo di software open-source (OSS), è importante risolvere le vulnerabilità di sicurezza che potrebbero essere associate a OSS che è stato incorporato nel prodotto. Si tratta di un impegno continuo, in quanto la versione del componente OSS potrebbe presentare una vulnerabilità scoperta di recente in qualsiasi momento.</block>
  <block id="87bd0fb9b4198f33535e0e1888a809f5" category="list-text">Test di penetrazione.* il test di penetrazione è il processo di valutazione di un sistema, di un'applicazione Web o di una rete per individuare le vulnerabilità della sicurezza che potrebbero essere sfruttate da un utente malintenzionato. I test di penetrazione (test delle penne) di NetApp vengono condotti da un gruppo di aziende terze approvate e fidate. Il loro scopo di test include il lancio di attacchi contro un'applicazione o un software come intrusi o hacker ostili che utilizzano sofisticati metodi o strumenti di sfruttamento.</block>
  <block id="e3a3be4b4b04c5e0b6a5f1b5ea388380" category="list-text">*Attività Product Security Incident Response.* le vulnerabilità di sicurezza vengono rilevate sia internamente che esternamente all'azienda e possono rappresentare un grave rischio per la reputazione di NetAppâ™se non vengono affrontate in modo tempestivo. Per facilitare questo processo, un Product Security Incident Response Team (PSIRT) segnala e tiene traccia delle vulnerabilità.</block>
  <block id="e91db3b3278f7bd95cc704d74c5c9597" category="paragraph">Il plug-in NetApp SnapCenter per VMware vSphere include le seguenti funzionalità di sicurezza in ciascuna release:</block>
  <block id="4abd7d1d5d223683d3346671efb7e89c" category="list-text">*Accesso limitato alla shell.* SSH è disattivato per impostazione predefinita e gli accessi una tantum sono consentiti solo se sono abilitati dalla console della macchina virtuale.</block>
  <block id="8c264fa5ca2c588d960d98bd30cbc897" category="list-text">*Avviso di accesso nel banner di accesso.* il seguente banner di accesso viene visualizzato dopo che l'utente ha inserito un nome utente nel prompt di accesso:</block>
  <block id="0d6633ada3a9803e206b2359d859e892" category="paragraph">Una volta completato l'accesso tramite il canale SSH, viene visualizzato il seguente output:</block>
  <block id="83e463bb73b12d9ca6e419327073c8a4" category="list-text">*RBAC (role-based access control).* due tipi di controlli RBAC sono associati ai tool NetApp ONTAP:</block>
  <block id="b883bf79639dfce77e395b8458ee69e4" category="list-text">Privilegi vCenter Server nativi.</block>
  <block id="721796b1cb3468f0daf819180184d460" category="inline-link">RBAC (Role-Based Access Control)</block>
  <block id="1d08c46b7567a29be0690a92b9722a58" category="list-text">Privilegi specifici del plug-in VMware vCenter. Per ulteriori informazioni, vedere<block ref="f351263ad3706bd0a472039400dece78" category="inline-link-rx"></block>.</block>
  <block id="acab4c655c4a7b4db67fc07e22b86222" category="list-text">*Canali di comunicazione crittografati.* tutte le comunicazioni esterne avvengono su HTTPS utilizzando TLS.</block>
  <block id="47a37e2d5fc8b7c936ad9b2b7a569a08" category="paragraph">La seguente tabella fornisce i dettagli della porta aperta.</block>
  <block id="10bd16a816f831080065e807daa36a9a" category="cell">Numero della porta TCP v4/v6</block>
  <block id="edf0320adc8658b25ca26be5351b6c4a" category="cell">8144</block>
  <block id="d4a973e303ec37692cc8923e3148eef7" category="cell">8080</block>
  <block id="2c25c3d66f80eeaa8d6e5a144c6f942e" category="cell">Connessioni HTTPS per GUI OVA</block>
  <block id="14b3e670eec63cc0cc456fd904bbfbd9" category="cell">SSH (disattivato per impostazione predefinita)</block>
  <block id="16fc18d787294ad5171100e33d05d4e2" category="cell">3306</block>
  <block id="4cbf9c234f6b34c242a110cb993252bd" category="cell">MySQL (solo connessioni interne; connessioni esterne disattivate per impostazione predefinita)</block>
  <block id="29ab4efbdb7c727c81ee1382593bc5e2" category="cell">Nginx (servizi di protezione dei dati)</block>
  <block id="89f152cad33314315b4995ed1ca71535" category="inline-link">Come creare e/o importare un certificato SSL nel plug-in SnapCenter per VMware vSphere (SCV)</block>
  <block id="450adc59e39f23172756ac9369494a2d" category="list-text">*Supporto dei certificati firmati dall'autorità di certificazione (CA).* il plug-in SnapCenter per VMware vSphere supporta la funzione dei certificati firmati dalla CA. Vedere<block ref="9f83d87d5d9f604d96288df21d450fac" category="inline-link-rx"></block>.</block>
  <block id="05a1aa8021df4579874c4eeb8788e5c9" category="list-text">*Password policy.* sono in vigore i seguenti criteri relativi alle password:</block>
  <block id="2c87609dbbc3630573c64e271de8207d" category="list-text">Tutte le informazioni sulle credenziali vengono memorizzate utilizzando l'hashing SHA256.</block>
  <block id="0f1a6fa0a65f9d5c3c4a16b070104d7a" category="list-text">*Immagine del sistema operativo di base.* il prodotto viene fornito con il sistema operativo di base Debian per OVA con accesso limitato e accesso alla shell disattivato. In questo modo si riduce l'impatto degli attacchi. Ogni sistema operativo SnapCenter release base viene aggiornato con le ultime patch di sicurezza disponibili per la massima copertura di sicurezza.</block>
  <block id="83cd5867ba912e517fa1100299fd1cf3" category="paragraph">NetApp sviluppa funzionalità software e patch di sicurezza per quanto riguarda il plug-in SnapCenter per l'appliance VMware vSphere e le rilascia ai clienti come piattaforma software integrata. Poiché queste appliance includono dipendenze specifiche del sistema operativo secondario Linux e il nostro software proprietario, NetApp consiglia di non apportare modifiche al sistema operativo secondario, in quanto questo potrebbe influire sull'appliance NetApp. Ciò potrebbe influire sulla capacità di NetApp di supportare l'appliance. NetApp consiglia di testare e implementare la versione più recente del codice per le appliance, perché vengono rilasciate per correggere eventuali problemi relativi alla sicurezza.</block>
  <block id="e50e258ecc9eaa88d6c653c3a24cb319" category="cell">Marzo 2022</block>
  <block id="ea9349a37bfee247df0f87cbcacca796" category="cell">Release iniziale.</block>
  <block id="f5852a230bef6cf666f848c5a2137db2" category="doc">Storage unificato ONTAP</block>
  <block id="0dc14c0a294efec0c8cab98ebffa39f0" category="section-title">Informazioni sullo storage unificato</block>
  <block id="d00516b816f266ee64e7b1de5af59ff2" category="paragraph">I sistemi che eseguono il software ONTAP sono unificati in diversi modi significativi. In origine, questo approccio si riferiva al supporto dei protocolli NAS e SAN su un unico sistema di storage e ONTAP continua a essere una piattaforma leader per SAN insieme alla sua forza originale nel NAS. Una macchina virtuale per lo storage (SVM) è un costrutto logico che consente l'accesso del client ai sistemi che eseguono il software ONTAP. Le SVM possono servire i dati contemporaneamente attraverso più protocolli di accesso ai dati tramite le interfacce logiche (LIF). Le SVM forniscono l'accesso ai dati a livello di file attraverso protocolli NAS, come CIFS e NFS, e l'accesso ai dati a livello di blocco attraverso protocolli SAN, come iSCSI, FC/FCoE e NVMe. Le SVM possono fornire dati ai client SAN e NAS in modo indipendente allo stesso tempo.</block>
  <block id="92515b597b8c0784d6000b89ee47c5fd" category="inline-image-macro">Storage unificato</block>
  <block id="d6154a0901f9ca6bb5d8fb15c113581e" category="paragraph"><block ref="d6154a0901f9ca6bb5d8fb15c113581e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3d59082aeee25c59b01266eaef6cb14" category="paragraph">Nel mondo vSphere, questo approccio potrebbe anche significare un sistema unificato per l'infrastruttura di desktop virtuale (VDI) insieme all'infrastruttura di server virtuale (VSI). I sistemi che eseguono il software ONTAP sono in genere meno costosi per VSI rispetto agli array aziendali tradizionali e dispongono tuttavia di funzionalità avanzate di efficienza dello storage per gestire VDI nello stesso sistema. ONTAP unifica inoltre una vasta gamma di supporti storage, da SSD a SATA, e può estenderli facilmente nel cloud. Non è necessario acquistare un flash array per le performance, un SATA array per gli archivi e sistemi separati per il cloud. ONTAP li lega tutti insieme.</block>
  <block id="e9e0f5f2c513c7138ea70b4c929d6fef" category="inline-link">Virtualizzazione dello storage</block>
  <block id="54c9439ad8fb4842a5a86c34d2401e36" category="admonition">Per ulteriori informazioni su SVM, storage unificato e accesso client, vedere<block ref="2843f934dec816d79f9c394ad0533c28" category="inline-link-rx"></block> Nel centro di documentazione di ONTAP 9.</block>
  <block id="6d5f52fb3cf097647a57da8b55e5b08f" category="doc">Provisioning tradizionale dello storage a blocchi vSphere con ONTAP</block>
  <block id="7c2d57185437da757ecede58f5a842d4" category="paragraph">VMware vSphere supporta le seguenti opzioni di datastore VMFS con il supporto del protocollo SAN ONTAP indicato.</block>
  <block id="c90881491d716de5c0ed7f9f4b09a3ad" category="cell">Opzioni datastore VMFS</block>
  <block id="a9181ef164a32ec0949c2cf63315ca31" category="cell">Supporto del protocollo SAN ONTAP</block>
  <block id="5903a917b575023b60264c602c220771" category="inline-link-macro">Fibre Channel (FC)</block>
  <block id="a4bce6d7794ee38a14e6a6d3785039f9" category="cell"><block ref="a4bce6d7794ee38a14e6a6d3785039f9" category="inline-link-macro-rx"></block></block>
  <block id="a6105c0a611b41b08f1209506350279e" category="cell">sì</block>
  <block id="8da5577a58a95e2ebe9c6dd4f19f6c11" category="inline-link-macro">Fibre Channel over Ethernet (FCoE)</block>
  <block id="40b814244a055d57c1af5fd02e4a8747" category="cell"><block ref="40b814244a055d57c1af5fd02e4a8747" category="inline-link-macro-rx"></block></block>
  <block id="b26caac6068e09e5f849cfcb3e8c0c90" category="cell"><block ref="b26caac6068e09e5f849cfcb3e8c0c90" category="inline-link-macro-rx"></block></block>
  <block id="c38e870d503879d110dbddd5bf388ab2" category="cell">Estensioni iSCSI per RDMA (iSER)</block>
  <block id="7fa3b767c460b54a2be4d49030b349c7" category="cell">no</block>
  <block id="de5a656362f0d785d2cc7d3097a507ef" category="inline-link-macro">NVMe su fabric con FC (NVMe/FC)</block>
  <block id="71a94ffc9bd97f314990ee2cd7a87154" category="cell"><block ref="71a94ffc9bd97f314990ee2cd7a87154" category="inline-link-macro-rx"></block></block>
  <block id="16d2954ba1640e32b21c312695337233" category="cell">NVMe su fabric con RDMA su Ethernet convergente (NVMe/RoCE)</block>
  <block id="344567ba51767dd5805c908c602fb10e" category="admonition">Se è richiesto iSER o NVMe/RoCE VMFS, controllare i sistemi storage basati su SANtricity.</block>
  <block id="160f88ca0bed5b24e94c809f4e22f1e7" category="summary">In ONTAP 9, i componenti fisici di un cluster sono visibili agli amministratori del cluster, ma non sono direttamente visibili alle applicazioni e agli host che utilizzano il cluster.</block>
  <block id="89fafdb11a7e8cd8abebb1d4df053dad" category="doc">Topologie di replica</block>
  <block id="be01acd2f018d38f9446f06b99ee4a2a" category="paragraph">In ONTAP 9, i componenti fisici di un cluster sono visibili agli amministratori del cluster, ma non sono direttamente visibili alle applicazioni e agli host che utilizzano il cluster. I componenti fisici forniscono un pool di risorse condivise da cui vengono costruite le risorse del cluster logico. Le applicazioni e gli host accedono ai dati solo tramite SVM che contengono volumi e LIF.</block>
  <block id="7758fc02779ee5917b0a09ee22b52221" category="paragraph">Ogni SVM NetApp viene trattata come array in VMware vCenter Site Recovery Manager. SRM supporta determinati layout di replica array-to-array (o SVM-to-SVM).</block>
  <block id="58c0b55a67f4331cc49b073a7183e06c" category="paragraph">Una singola macchina virtuale non è in grado di gestire i dati (VMDK) o RDM) su più array SRM per i seguenti motivi:</block>
  <block id="880aeda0b58c0b30120b6319ae5f3beb" category="list-text">SRM vede solo la SVM, non un singolo controller fisico.</block>
  <block id="6f55124e085dbeb640e4cb8ad2c97905" category="list-text">Una SVM può controllare LUN e volumi che si estendono su più nodi in un cluster.</block>
  <block id="39d9903201320a83d45d3b36d512f051" category="cell">Best practice</block>
  <block id="d86019fe4ba86b184ac71cf24a22f0c6" category="cell">Per determinare la supportabilità, tenere presente questa regola: Per proteggere una macchina virtuale utilizzando SRM e NetApp SRA, tutte le parti della macchina virtuale devono esistere su un solo SVM. Questa regola si applica sia al sito protetto che al sito di ripristino.</block>
  <block id="2e4472d35f80aa8b7eca52ae3dd43dc6" category="section-title">Layout SnapMirror supportati</block>
  <block id="d070ad9d8397892aa7f317cbb9046661" category="paragraph">Le seguenti figure mostrano gli scenari di layout delle relazioni SnapMirror supportati da SRM e SRA. Ogni macchina virtuale nei volumi replicati possiede i dati su un solo array SRM (SVM) in ogni sito.</block>
  <block id="39d3085abe6ccb914d8535de8a5f3e37" category="paragraph"><block ref="39d3085abe6ccb914d8535de8a5f3e37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ae7670cf947a397bdf6a882fbcc912a" category="paragraph"><block ref="1ae7670cf947a397bdf6a882fbcc912a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="111d3212464dba203cbd675a0338dcbc" category="paragraph"><block ref="111d3212464dba203cbd675a0338dcbc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5dc3a606b05b41db22793ed3c1a72db" category="paragraph"><block ref="c5dc3a606b05b41db22793ed3c1a72db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86cf5bd2bdb1b1d67f8f907f41099509" category="section-title">Layout di Array Manager supportati</block>
  <block id="aacc8f18d659f75715d91a983e872233" category="paragraph">Quando si utilizza la replica basata su array (ABR) in SRM, i gruppi di protezione vengono isolati in una singola coppia di array, come illustrato nella seguente schermata. In questo scenario,<block ref="129864522ed0e4ac80f306ecfa130ef7" prefix=" " category="inline-code"></block> e.<block ref="ec87aa7f4c8e70a139fd988f87b6549f" prefix=" " category="inline-code"></block> sono in coppia con<block ref="387d04b65848414d4697f145a3782f90" prefix=" " category="inline-code"></block> e.<block ref="58bdbfcb72c2dd3d883a7ca754443a4c" prefix=" " category="inline-code"></block> presso il sito di recovery. Tuttavia, è possibile selezionare solo una delle due coppie di array quando si crea un gruppo di protezione.</block>
  <block id="68a1b289711a591ed50627014cd01ce9" category="paragraph"><block ref="68a1b289711a591ed50627014cd01ce9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ceb46f3e1c6c7995de4ec5f05601227" category="section-title">Layout non supportati</block>
  <block id="611b9b35ac984f20e6594baec9181dbf" category="paragraph">Le configurazioni non supportate dispongono di dati (VMDK o RDM) su più SVM di proprietà di una singola macchina virtuale. Negli esempi illustrati nelle seguenti figure,<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Impossibile configurare la protezione con SRM perché<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Dispone di dati su due SVM.</block>
  <block id="5c251a65e8394fbeaf104ba1a1cad2e1" category="paragraph"><block ref="5c251a65e8394fbeaf104ba1a1cad2e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="paragraph"><block ref="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69851ac8c2fa81b32799efc8522798d5" category="paragraph">Qualsiasi relazione di replica in cui un singolo volume NetApp viene replicato da una SVM di origine a più destinazioni nella stessa SVM o in SVM differenti viene definita fan-out di SnapMirror. Fan-out non supportato con SRM. Nell'esempio illustrato nella figura seguente,<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Impossibile configurare la protezione in SRM perché viene replicata con SnapMirror in due posizioni diverse.</block>
  <block id="688890bdbdfd2d73a05a09883f3c4b40" category="paragraph"><block ref="688890bdbdfd2d73a05a09883f3c4b40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f88384b0d5cdcdc25895c644126c1b0" category="section-title">Cascata di SnapMirror</block>
  <block id="7ebde774ad43c45667d5544308a6d688" category="paragraph">SRM non supporta la sovrapposizione delle relazioni SnapMirror, in cui un volume di origine viene replicato in un volume di destinazione e tale volume di destinazione viene replicato anche con SnapMirror in un altro volume di destinazione. Nello scenario illustrato nella figura seguente, SRM non può essere utilizzato per il failover tra siti.</block>
  <block id="2990fc44e9ba827a397e96e1c278a02a" category="paragraph"><block ref="2990fc44e9ba827a397e96e1c278a02a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd15e818d377a0a5cf6ebc429555f79" category="section-title">SnapMirror e SnapVault</block>
  <block id="d440734d1f5d9c6e59aa97f7cbbcd525" category="paragraph">Il software NetApp SnapVault consente il backup basato su disco dei dati aziendali tra i sistemi storage NetApp. SnapVault e SnapMirror possono coesistere nello stesso ambiente; tuttavia, SRM supporta il failover solo delle relazioni SnapMirror.</block>
  <block id="7878dfbf4b6ad3bc60d095cf89d79202" category="admonition">NetApp SRA supporta<block ref="e7d3e049f94ce3ff8a47f209f012173d" prefix=" " category="inline-code"></block> tipo di policy.</block>
  <block id="883e69a285ae2d5fd23c80cd29285804" category="paragraph">SnapVault è stato ricostruito da zero per ONTAP 8.2. Anche se gli utenti di Data ONTAP 7-Mode precedenti dovrebbero trovare delle analogie, in questa versione di SnapVault sono stati apportati importanti miglioramenti. Un importante progresso è la capacità di preservare l'efficienza dello storage sui dati primari durante i trasferimenti SnapVault.</block>
  <block id="9bc21373e0e299579a7ac86dcd4f513d" category="paragraph">Un'importante modifica architetturale è che SnapVault in ONTAP 9 replica a livello di volume anziché a livello di qtree, come nel caso di 7-Mode SnapVault. Questa configurazione indica che l'origine di una relazione SnapVault deve essere un volume e che tale volume deve replicarsi nel proprio volume sul sistema secondario SnapVault.</block>
  <block id="f7b20cbc14027c7711d53d03a84f31af" category="paragraph">In un ambiente in cui viene utilizzato SnapVault, le copie Snapshot denominate in modo specifico vengono create sul sistema di storage primario. A seconda della configurazione implementata, le copie Snapshot denominate possono essere create sul sistema primario mediante un programma SnapVault o un'applicazione come NetApp Active IQ Unified Manager. Le copie Snapshot denominate create sul sistema primario vengono quindi replicate nella destinazione SnapMirror e da qui vengono vault nella destinazione SnapVault.</block>
  <block id="5dd37b7cd36f7d38ba2e6a63c603be4c" category="paragraph">È possibile creare un volume di origine in una configurazione a cascata in cui un volume viene replicato in una destinazione SnapMirror nel sito DR e da qui viene vault in una destinazione SnapVault. È possibile creare un volume di origine anche in una relazione fan-out in cui una destinazione è una destinazione SnapMirror e l'altra destinazione è una destinazione SnapVault. Tuttavia, SRA non riconfigurerà automaticamente la relazione SnapVault per utilizzare il volume di destinazione SnapMirror come origine per il vault quando si verifica il failover SRM o l'inversione della replica.</block>
  <block id="5bc66b9c84b3f7cc0b375e729376b68d" category="inline-link">Guida alle Best practice per la configurazione di SnapMirror TR-4015 per ONTAP 9.</block>
  <block id="0d510e96259254d285c6aaeb8458f45d" category="paragraph">Per informazioni aggiornate su SnapMirror e SnapVault per ONTAP 9, vedere<block ref="32e7c991f675bf983c547a2a174c2caf" category="inline-link-rx"></block></block>
  <block id="75f8a2d99eea9f336120aec69d8c1010" category="cell">Se SnapVault e SRM vengono utilizzati nello stesso ambiente, NetApp consiglia di utilizzare una configurazione a cascata da SnapMirror a SnapVault in cui i backup di SnapVault vengono normalmente eseguiti dalla destinazione di SnapMirror nel sito di DR. In caso di disastro, questa configurazione rende il sito primario inaccessibile. Mantenendo la destinazione SnapVault nel sito di recovery, è possibile riconfigurare i backup SnapVault dopo il failover in modo che i backup SnapVault possano continuare mentre si opera nel sito di recovery.</block>
  <block id="e082a67e3ddd7f4f92096536440cbb34" category="paragraph">In un ambiente VMware, ogni datastore dispone di un UUID (Universal Unique Identifier) e ogni VM dispone di un MOID (Managed Object ID) univoco. Questi ID non vengono gestiti da SRM durante il failover o il failback. Poiché gli UUID degli archivi di dati e i MOID delle macchine virtuali non vengono mantenuti durante il failover da SRM, tutte le applicazioni che dipendono da questi ID devono essere riconfigurate dopo il failover di SRM. Un'applicazione di esempio è NetApp Active IQ Unified Manager, che coordina la replica SnapVault con l'ambiente vSphere.</block>
  <block id="657a41cce55646ab17754ac1427970af" category="paragraph">La figura seguente mostra una configurazione a cascata da SnapMirror a SnapVault. Se la destinazione SnapVault si trova nel sito di DR o in un sito terzo che non è interessato da un'interruzione nel sito primario, l'ambiente può essere riconfigurato per consentire ai backup di continuare dopo il failover.</block>
  <block id="b56afb9a43332c671116b9fa3d597867" category="paragraph"><block ref="b56afb9a43332c671116b9fa3d597867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e068178460f103498576eac8ddb7fb82" category="paragraph">La seguente figura illustra la configurazione dopo l'utilizzo di SRM per eseguire il reverse della replica di SnapMirror nel sito primario. L'ambiente è stato anche riconfigurato in modo che i backup di SnapVault si verifichino da quella che ora è l'origine di SnapMirror. Questa configurazione è una configurazione fan-out di SnapMirror SnapVault.</block>
  <block id="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="paragraph"><block ref="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4607a4ee7e1830ab6ba0007df206956" category="paragraph">Dopo che SRM esegue il failback e una seconda inversione delle relazioni SnapMirror, i dati di produzione vengono ripristinati nel sito primario. Questi dati sono ora protetti nello stesso modo in cui erano prima del failover al sito di DR, tramite i backup SnapMirror e SnapVault.</block>
  <block id="63fd1f18d5d53fa97fd05a7fd96090b4" category="section-title">Utilizzo di Qtree in ambienti Site Recovery Manager</block>
  <block id="2d88570ceb2de0d8699a068b0140454b" category="paragraph">I qtree sono directory speciali che consentono l'applicazione delle quote del file system per NAS. ONTAP 9 consente la creazione di qtree e qtree possono esistere in volumi replicati con SnapMirror. Tuttavia, SnapMirror non consente la replica di singoli qtree o replica a livello di qtree. Tutte le repliche di SnapMirror sono solo a livello di volume. Per questo motivo, NetApp sconsiglia l'utilizzo di qtree con SRM.</block>
  <block id="345cb3f040f9f7f3f1a4261ed260aa79" category="section-title">Ambienti misti FC e iSCSI</block>
  <block id="a60b166c2b69b4fdfbb733dc2193668a" category="paragraph">Con i protocolli SAN supportati (FC, FCoE e iSCSI), ONTAP 9 offre servizi LUN, ovvero la possibilità di creare e mappare LUN agli host collegati. Poiché il cluster è costituito da più controller, esistono più percorsi logici gestiti da i/o multipath verso qualsiasi LUN individuale. L'ALUA (Asymmetric Logical Unit Access) viene utilizzato sugli host in modo che il percorso ottimizzato per un LUN sia selezionato e reso attivo per il trasferimento dei dati. Se il percorso ottimizzato per qualsiasi LUN cambia (ad esempio, perché il volume contenente viene spostato), ONTAP 9 riconosce automaticamente e regola senza interruzioni per questa modifica. Se il percorso ottimizzato non è disponibile, ONTAP può passare senza interruzioni a qualsiasi altro percorso disponibile.</block>
  <block id="b9921ac732e72656bc2836f83bb09522" category="paragraph">VMware SRM e NetApp SRA supportano l'utilizzo del protocollo FC in un sito e del protocollo iSCSI nell'altro. Tuttavia, non supporta la combinazione di datastore FC-attached e datastore iSCSI-attached nello stesso host ESXi o in host diversi nello stesso cluster. Questa configurazione non è supportata con SRM perché, durante il failover SRM o il failover di test, SRM include tutti gli iniziatori FC e iSCSI negli host ESXi nella richiesta.</block>
  <block id="fccd44a96243e459128798803dca70aa" category="cell">SRM e SRA supportano protocolli FC e iSCSI misti tra i siti protetti e di ripristino. Tuttavia, ogni sito deve essere configurato con un solo protocollo, FC o iSCSI, non entrambi nello stesso sito. Se esiste un requisito per la configurazione dei protocolli FC e iSCSI nello stesso sito, NetApp consiglia che alcuni host utilizzino iSCSI e altri host utilizzino FC. In questo caso, NetApp consiglia anche di configurare le mappature delle risorse SRM in modo che le macchine virtuali siano configurate per il failover in un gruppo di host o nell'altro.</block>
  <block id="b1c770f25b823d4453567c0ff9d7cf67" category="summary">In questa pagina viene illustrata la procedura per l'implementazione di un datastore NetApp ONTAP NFS versione 3 in un ambiente VMware vSphere.</block>
  <block id="168dbfe414d4d4089585360152953a57" category="doc">Datastore vSphere NFS - versione 3 con ONTAP</block>
  <block id="2be27a78c84ba5629cd9f2c22983240a" category="paragraph">Creazione di datastore NFS versione 3 con storage NAS ONTAP.</block>
  <block id="106a118b8a267220cb2c40a4bb68b684" category="list-text">Le competenze di base necessarie per gestire un ambiente vSphere e ONTAP.</block>
  <block id="00c46d0ea9cdf9a5a37b8af04896741f" category="list-text">Un sistema storage ONTAP (file FAS/AFF/CVO/ONTAP Select/Cloud Volume Service/Azure NetApp) con ONTAP 9.8 o versione successiva</block>
  <block id="a9ab6317871b5547fc7bf0dd22151f00" category="list-text">Informazioni sugli host vSphere per vSphere 7.0 o versioni successive</block>
  <block id="0675fa9a38b420775f29ec7a62d9a8a0" category="list-text">Con porte dati di rete del sistema ONTAP e host vSphere collegati</block>
  <block id="4b18348d39655902cd0e183596a82856" category="list-text">Verificare la compatibilità con<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="c54d1c547e26987b98af73634278c77a" category="inline-link-macro">Verificare la licenza ONTAP per NFS.</block>
  <block id="8174503ab9e5dc2fe2f74068f651770d" category="list-text"><block ref="8174503ab9e5dc2fe2f74068f651770d" category="inline-link-macro-rx"></block></block>
  <block id="5d3f3e14f3096740cb085fa81836d595" category="list-text">Utilizzare<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Controllare che NFS sia presente nell'elenco.</block>
  <block id="135850bb72d05ca77b8b8f846429fe71" category="inline-link-macro">Seguire il workflow di configurazione di NFS.</block>
  <block id="01a85c06aae02abe9083e7e02d90661f" category="list-text"><block ref="01a85c06aae02abe9083e7e02d90661f" category="inline-link-macro-rx"></block></block>
  <block id="2281b9d958567868b171298a8df5cdee" category="inline-link-macro">Seguire il flusso di lavoro per la configurazione del client NFS per vSphere.</block>
  <block id="c80c5160cfe2127b3ab167103b20488c" category="paragraph"><block ref="c80c5160cfe2127b3ab167103b20488c" category="inline-link-macro-rx"></block></block>
  <block id="ff7854cc2ae62511b4a52320f31aa005" category="paragraph"><block ref="ff7854cc2ae62511b4a52320f31aa005" category="inline-link-macro-rx"></block></block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">Dove trovare ulteriori informazioni</block>
  <block id="9bf6b8df29f265cdaf3246f6645ca922" category="inline-link"><block ref="9bf6b8df29f265cdaf3246f6645ca922" category="inline-link-rx"></block></block>
  <block id="bc0f3321a29c580fa0e3cca0c00ee7cd" category="list-text">Documentazione del prodotto VMware<block ref="3bdcd80def6a1e2849d8b38049a04af9" category="inline-link-rx"></block></block>
  <block id="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link"><block ref="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link-rx"></block></block>
  <block id="0f185ccd88416daec4eee0a846d110b8" category="list-text">Documentazione sui prodotti NetApp<block ref="2e85fc867cab94d246e0bf6043b361cd" category="inline-link-rx"></block></block>
  <block id="1e6584aafa5ae98aebb88d3ddecdaae5" category="doc">Introduzione a ONTAP per amministratori vSphere</block>
  <block id="135b7f440129fbbacbc948adfb10ccec" category="paragraph">NetApp ONTAP semplifica le operazioni di storage e gestione dei dati e si integra perfettamente con gli ambienti VMware, sia che si tratti di implementazione on-premise che nel cloud. La protezione dei dati Best-in-class di NetApp, le innovazioni per l'efficienza dello storage e le performance eccezionali nelle architetture VMware basate SU SAN e NAS sono tra i motivi per cui decine di migliaia di clienti hanno scelto ONTAP come soluzione di storage per le implementazioni vSphere.</block>
  <block id="f93e431aaf745d4b5e4ecbd6c005b564" category="paragraph">NetApp offre numerosi plug-in, validazioni e qualifiche VMware di diversi prodotti VMware per supportare i clienti che devono affrontare le sfide specifiche dell'amministrazione di un ambiente di virtualizzazione. NetApp fa per lo storage e la gestione dei dati ciò che VMware fa per la virtualizzazione, consentendo ai clienti di concentrarsi sulle proprie competenze principali piuttosto che sulla gestione dello storage fisico. Questa partnership di quasi 20 anni tra VMware e NetApp continua a evolversi e ad aggiungere valore ai clienti con l'emergere di nuove tecnologie, come VMware Cloud Foundation e Tanzu, continuando a supportare le basi di vSphere.</block>
  <block id="b4e56252f38c98dde71bd489a93805fc" category="paragraph">I fattori chiave che i clienti apprezzano sono:</block>
  <block id="d6f750861d7ae27706ca32ed1f4c1ac8" category="list-text">*Storage unificato*</block>
  <block id="04d737333774adefb9817d0115bab79b" category="list-text">*Efficienza dello storage*</block>
  <block id="c44a0be5f0db0511994f2f8e76afeb25" category="list-text">*Volumi virtuali e gestione basata su policy di storage*</block>
  <block id="d78a5fe569360bb327d51dd5060d723c" category="list-text">*Cloud ibrido*</block>
  <block id="45649dc755190fc40be0b7e38ec84851" category="paragraph">Per ulteriori informazioni sulle soluzioni NetApp e VMware supportate, consultare le seguenti risorse:</block>
  <block id="ec1bd76731eb238fa601fb03391f78d4" category="inline-link">Il tool NetApp Interoperability Matrix</block>
  <block id="d46e58d91be6ffba761ab9bd05a46fc5" category="list-text"><block ref="b47ad5992ee82e05d51ff22d87ae20c3" category="inline-link-rx"></block> (IMT). IMT definisce i componenti e le versioni qualificate che è possibile utilizzare per creare configurazioni FC/FCoE, iSCSI, NFS e CIFS.</block>
  <block id="8034c6a17370dafb5b3f6f5add755c62" category="inline-link">Guida alla compatibilità VMware</block>
  <block id="f0c67c4d38f07e6eb4bead0202260ddb" category="list-text"><block ref="a9846c61dcf62d503a7738adf47f11be" category="inline-link-rx"></block>. La guida alla compatibilità VMware elenca la compatibilità di sistemi, i/o, storage/SAN e backup con VMware Infrastructure e i prodotti software</block>
  <block id="2be6bbf4ea543b07ab3b9a218eb509cc" category="list-text"><block ref="d1284fbca35bc1b47ead37f18b1c3ba2" category="inline-link-rx"></block>. ONTAP Tools per VMware vSphere è un plug-in vCenter Server singolo che include le estensioni VSC, VASA Provider e SRA (Storage Replication Adapter).</block>
  <block id="b4a3c2c985fcfc0d0e59c8d9c3259eb0" category="doc">NVA-1129-DEPLOY: VMware end-user computing con GPU NetApp HCI e NVIDIA</block>
  <block id="8b3f1e47da9509d2edf2f21012c6ec7e" category="paragraph">VMware End-User Computing with NetApp HCI è un'architettura di data center pre-validata e Best-practice per l'implementazione di workload di desktop virtuali su scala aziendale. Questo documento descrive come implementare la soluzione su scala di produzione in modo affidabile e privo di rischi</block>
  <block id="ba999af3664a8f6c5b43a92bc11de64a" category="paragraph"><block ref="ba999af3664a8f6c5b43a92bc11de64a" category="inline-link-macro-rx"></block></block>
  <block id="46b8f9361fae73f13467cd1aaff186ba" category="summary">Registro delle recenti modifiche al materiale collaterale sulle soluzioni NetApp</block>
  <block id="679ce0aa9d3d54bfddd37e1b78b802de" category="doc">Registro delle modifiche alle soluzioni NetApp</block>
  <block id="aceacf14369d872e8cb00f62613f52c6" category="paragraph">Modifiche recenti al materiale informativo sulle soluzioni NetApp. Vengono elencate per prime le modifiche più recenti.</block>
  <block id="e63695c4dea40eefb2ef481c7b242192" category="open-title">Tutte le modifiche</block>
  <block id="5edbe8c55546db896b55871b44a39263" category="cell">*Data*</block>
  <block id="12cd1425f32ad289dba28e35ae9096fb" category="cell">*Area soluzione*</block>
  <block id="b96941ac46daa357b1782f017746a57b" category="cell">*Descrizione della modifica*</block>
  <block id="e44925cb6b49254bb6fed8c411e15c4f" category="cell">05/19/2023</block>
  <block id="e307db07b3975fef922a80d07455ee5e" category="cell">Database</block>
  <block id="889806f0e07f1d0dd0672d1a1cd2cddf" category="cell">05/16/2023</block>
  <block id="cc03678283413ffdf1b4ab27cc12e6d9" category="cell">Multicloud ibrido con Red Hat OpenShift</block>
  <block id="b04739a706412f23675293cb0bce6e3d" category="cell">Aggiunto nuovo titolo nella barra laterale e nuovo contenuto</block>
  <block id="0963e46246e2115e2405b677b6116fd3" category="cell">Aggiunto nuovo contenuto</block>
  <block id="eb4f0aac15f7c10d0cae14b084022516" category="cell">05/10/2023</block>
  <block id="6c55fdff3e1fbf1476c8edd9169f1f2c" category="cell">Aggiunto TR-4955: Disaster recovery con Azure NetApp Files (ANF) e Azure VMware Solution (AVS)</block>
  <block id="3a20c678f6addcc9b8fec17f91c8cfa4" category="cell">05/05/2023</block>
  <block id="957df08ed5fbb9ca926ca88b2c974f4f" category="cell">Nuovo TR-4951: Backup e ripristino per Microsoft SQL Server su AWS FSX per ONTAP</block>
  <block id="1f791cf07735c71bdb472a0ccd42abc7" category="cell">05/04/2023</block>
  <block id="35cec0f40dca2af7a6d3c73676c4629d" category="cell">Aggiunta del contenuto "Novità di VMware vSphere 8"</block>
  <block id="d32927c975622dda9841402f1a1c8526" category="cell">04/27/2023</block>
  <block id="7624970b07a1f223fd6ce63511968dd0" category="cell">Aggiunto backup e ripristino Veeam in VMware Cloud con AWS FSX per ONTAP</block>
  <block id="4557eca5dd55b5b5ecc0b0ef61f1dd21" category="cell">03/31/2023</block>
  <block id="71cc1ac63221b4b22fee5b3615ed204b" category="cell">Aggiunta di implementazione e protezione del database Oracle in AWS FSX/EC2 con iSCSI/ASM</block>
  <block id="5df30196a94efca9537353cd93678f3a" category="cell">Aggiunta di backup, ripristino e clonazione di database Oracle con i servizi SnapCenter</block>
  <block id="8daba132ddff8c3d3fd4757eab8dd47a" category="cell">03/29/2023</block>
  <block id="caea8340e2d186a540518d08602aa065" category="cell">Automazione</block>
  <block id="74ed7031eb75ffbb784ebe9ffbd6be6a" category="cell">Blog aggiornato "FSX for ONTAP Monitoring and Auto-Resizing using AWS Lambda function" con opzioni per l'implementazione privata/pubblica e opzioni di implementazione manuale/automatica.</block>
  <block id="1260fc391141c4810f2e3a97eaef162e" category="cell">03/22/2023</block>
  <block id="2ab02c4627e2022ecdf98de0e3b6b18d" category="cell">Blog aggiunto: FSX per il monitoraggio ONTAP e il ridimensionamento automatico mediante la funzione lambda AWS</block>
  <block id="61c8e892dd7e1908020eb0a312fd4bbb" category="cell">02/15/2023</block>
  <block id="2ee6a0567aa163f6ace02183cb041cbd" category="cell">Aggiunta di implementazione ad alta disponibilità PostgreSQL e disaster recovery in AWS FSX/EC2</block>
  <block id="b46d6d6e100776ecf2985ff50a451beb" category="cell">02/07/2023</block>
  <block id="6e6d4a2ed2ec59b98f8da1da20e890bb" category="cell">Blog aggiunto: Annuncio della disponibilità generale del supporto del datastore NetApp Cloud Volumes Service per il motore VMware di Google Cloud</block>
  <block id="7240c168839eaf56e1bc86326fb29d5b" category="cell">Aggiunto TR-4955: Disaster recovery con FSX per ONTAP e VMC (AWS VMware Cloud)</block>
  <block id="2eded16d414f6935c27c95495a25eb53" category="cell">01/24/2023</block>
  <block id="d75c9f4acb46fbd1cc7aeecbd376940e" category="cell">Aggiunto TR-4954: Implementazione e protezione di database Oracle su Azure NetApp Files</block>
  <block id="839a1261c70db1f3c149f86d56e21d15" category="cell">01/12/2023</block>
  <block id="70542da4927194cf41c777029ebe56be" category="cell">Blog aggiunto: Proteggi i carichi di lavoro di SQL Server con NetApp SnapCenter con Amazon FSX per NetApp ONTAP</block>
  <block id="a94f1b9cbc89a005a38096b1750f907f" category="cell">12/15/2022</block>
  <block id="754451201969a73231c286ef8f4b2fd6" category="cell">Aggiunto TR-4923: SQL Server su AWS EC2 utilizzando Amazon FSX per NetApp ONTAP</block>
  <block id="3603e14740d8edd319e72186341cb0af" category="cell">12/06/2022</block>
  <block id="48461fa824ae344e0934144c7523c3f6" category="cell">Aggiunti 7 video per la modernizzazione dei database Oracle nel cloud ibrido con lo storage Amazon FSX</block>
  <block id="3cf6cddd26350e6a84e8bef869102647" category="cell">10/25/2022</block>
  <block id="ba7124a5ffeb6501794efa91cdcb129b" category="cell">Aggiunto link alla documentazione VMware per FSX ONTAP come datastore NFS</block>
  <block id="2937ec3775c4b0354bf359a5892c53f7" category="cell">Aggiunto riferimento al blog per la configurazione del cloud ibrido con FSX ONTAP e VMC su AWS SDDC utilizzando VMware HCX</block>
  <block id="16550c71fdf2102ec8face86a5d82746" category="cell">09/30/2022</block>
  <block id="8485ff07404cda7656a72c1d11b2e278" category="cell">Aggiunta di una soluzione per la migrazione dei carichi di lavoro al datastore FSxN utilizzando VMware HCX</block>
  <block id="bee0d36d9b0ec64a15bf59019a6ec2e2" category="cell">09/29/2022</block>
  <block id="b6942044de91f49e700f684f12314907" category="cell">Aggiunta di una soluzione per la migrazione dei carichi di lavoro al datastore ANF utilizzando VMware HCX</block>
  <block id="a401c5c75859d12743686229123750bc" category="cell">09/14/2022</block>
  <block id="d251fcb24842564580e4c994b283538e" category="cell">Aggiunti collegamenti ai calcolatori TCO e ai simulatori per FSxN / VMC e ANF / AVS</block>
  <block id="1063ab954566d1fe67239a1e96653a34" category="cell">Aggiunta dell'opzione aggiuntiva del datastore NFS per AWS / VMC</block>
  <block id="d15aa19396a83c3c15a1fb8ba83efda1" category="cell">08/25/2022</block>
  <block id="56991209ac6bc77f76e9e1828103cdfc" category="cell">Blog aggiunto: Modernizza il tuo funzionamento del database Oracle nel cloud ibrido con lo storage Amazon FSX</block>
  <block id="0a40e3c91a3a55c9a37428c6d194d0e5" category="cell">AI</block>
  <block id="f37741764b2517136f3747b14ec803a0" category="cell">Nuova soluzione: NVIDIA ai Enterprise con NetApp e VMware</block>
  <block id="bcd4c93e63ff96ec357bc67c62874e0c" category="cell">08/23/2022</block>
  <block id="10daf0bb04814721080056526de2b200" category="cell">Aggiornata la disponibilità più recente per tutte le opzioni aggiuntive del datastore NFS</block>
  <block id="55b61b011b735ba396a8dbd7e3f95f20" category="cell">08/05/2022</block>
  <block id="b7331610ced5770e91945f51e7656fcf" category="cell">Aggiunta delle informazioni "riavvio richiesto" per le impostazioni ESXi e ONTAP consigliate</block>
  <block id="5e86473217a757f4702d326176983651" category="cell">07/28/2022</block>
  <block id="e325d40f0256e06aa0a0f1c795ea68ee" category="cell">Aggiunta di una soluzione DR con SnapCenter e Veeam per AWS/VMC (storage connesso guest)</block>
  <block id="3fe4ff67f6902f4d03e2aff729e6ca40" category="cell">07/21/2022</block>
  <block id="c1cb2a6b83f79bd02d9023a9dc25d399" category="cell">Aggiunta di una soluzione DR con CVO e JetStream per AVS (storage guest connesso)</block>
  <block id="9f65880e605551f01ff1d2c03d3fa4c6" category="cell">06/29/2022</block>
  <block id="304bc05c6debf3075c4f25dcffcf50bd" category="cell">Aggiunto WP-7357: Implementazione di database Oracle su Best Practice EC2/FSX</block>
  <block id="36522cc6d4eb67d30ef19d321901fa6e" category="cell">06/16/2022</block>
  <block id="e1ea84e227dd99913363ade155774bcf" category="cell">Aggiunta della guida di progettazione NVIDIA DGX SuperPOD con NetApp</block>
  <block id="ac0f5de8cc00db2cb13da85ebd7e8780" category="cell">06/10/2022</block>
  <block id="e92ea8797c2bfc161566c53da6321114" category="cell">Aggiunta di AVS con panoramica del datastore nativo ANF e DR con JetStream</block>
  <block id="891220762a1a15ebfba11cf98afb3729" category="cell">06/07/2022</block>
  <block id="419f5ca56c881443509bda0a14523c9c" category="cell">Supporto regione AVS aggiornato per corrispondere al supporto/annuncio di anteprima pubblico</block>
  <block id="e19e98a669ae21f94ffd1659998fd072" category="cell">Analisi dei dati</block>
  <block id="c32698794f1279b1f46bacea38a72264" category="cell">Aggiunto link alla soluzione NetApp EF600 con Splunk Enterprise</block>
  <block id="32e9989956756ffe28b84c0dab24eb03" category="cell">06/02/2022</block>
  <block id="b481ba8b3ad7fbb6a9786c9907a7c1ba" category="cell">Aggiunta di un elenco della disponibilità regionale per gli archivi dati NFS per NetApp Hybrid Multifloud con VMware</block>
  <block id="92e704fe041898cac086cd4a192a1815" category="cell">05/20/2022</block>
  <block id="efae07e57b0f279c460d1361b379cf52" category="cell">Nuove guide alla progettazione e implementazione di BeeGFS per SuperPOD</block>
  <block id="821c35321bcc709868cdd0b7f31165ee" category="cell">04/01/2022</block>
  <block id="af2a34190d0729a3b5a2ed9d50d9e399" category="cell">Contenuto organizzato del multicloud ibrido con le soluzioni VMware: Landing page per ciascun hyperscaler e inclusione dei contenuti delle soluzioni disponibili (caso d'utilizzo)</block>
  <block id="d56302f459af314c7996db681d5b4696" category="cell">03/29/2022</block>
  <block id="ee0b2b1b7d5e8eb309b29d0051f84d0c" category="cell">Aggiunto un nuovo TR: DevOps con NetApp Astra</block>
  <block id="f2a59783d2b5c7be84fec0d6de7a5ae9" category="cell">03/08/2022</block>
  <block id="eab6f1cc9736be0f5d62999f998bf36a" category="cell">Aggiunta di una nuova demo video: Accelerare lo sviluppo software con Astra Control e la tecnologia NetApp FlexClone</block>
  <block id="5df42c63d444f6e9e40d96be8f17ac6f" category="cell">03/01/2022</block>
  <block id="75afdb5cd8c025ed0681bdb302fcdcda" category="cell">Aggiunte nuove sezioni a NVA-1160: Installazione di Astra Control Center tramite OperatorHub e Ansible</block>
  <block id="d064ecad73d9352507092f40af924057" category="cell">02/02/2022</block>
  <block id="0db377921f4ce762c62526131097968f" category="cell">Generale</block>
  <block id="c0598da0ea2338576f8d67854c56e3f6" category="cell">Creazione di landing page per organizzare meglio i contenuti per ai e Modern Data Analytics</block>
  <block id="84c45df200c907852c1e92875618b432" category="cell">01/22/2022</block>
  <block id="b385810d0a927b9d15a69218e3fb38c4" category="cell">TR aggiunto: Spostamento dei dati con e-Series e BeeGFS per i flussi di lavoro di ai e analytics</block>
  <block id="7d131526ee2a04107bbc50d52a29a7d7" category="cell">12/21/2021</block>
  <block id="9c00744e128712d7626e5c00edcfeaa1" category="cell">Creazione di landing page per organizzare meglio i contenuti per la virtualizzazione e il multicloud ibrido con VMware</block>
  <block id="c65463900a520919b522c30b6256e475" category="cell">Aggiunta di una nuova demo video: Sfruttare NetApp Astra Control per eseguire l'analisi post-mortem e ripristinare l'applicazione a NVA-1160</block>
  <block id="f63616bb6a8255ed08089231c746f285" category="cell">12/06/2021</block>
  <block id="5424d7e641fa7962888e16022445e1ae" category="cell">Creazione di un multicloud ibrido con contenuti VMware per ambienti di virtualizzazione e opzioni di storage guest connesso</block>
  <block id="16784caec2e047ddf59bd5a51bd35a73" category="cell">11/15/2021</block>
  <block id="1c20ad7a11d1c2856906d55171b50126" category="cell">Aggiunta di una nuova demo video: Data Protection in ci/CD Pipeline with Astra Control a NVA-1160</block>
  <block id="5cdb842b21b9f980df2b3ab63ee9a9e6" category="cell">Nuovo contenuto: Best Practice per Confluent Kafka</block>
  <block id="38562890365e144b467ec2813a6377f2" category="cell">11/02/2021</block>
  <block id="fb0ad99371abb3d02d60add8160c6dd9" category="cell">Requisiti di autenticazione AWS per CVO e Connector che utilizzano NetApp Cloud Manager</block>
  <block id="dfd39862c9cc158ad7b0e4e1e9a3024a" category="cell">10/29/2021</block>
  <block id="e7c456cd85cc15bd3faf7b65c0833d3e" category="cell">Nuovo contenuto: TR-4657 - soluzioni dati di cloud ibrido NetApp: Spark e Hadoop</block>
  <block id="63c0320f73b5f4e528bbe1488acc5103" category="cell">Protezione automatica dei dati per database Oracle</block>
  <block id="815425a7766095190649a3f9ecbc1828" category="cell">10/26/2021</block>
  <block id="6c6fb0f7e5fe3a7242028f22d2792fca" category="cell">Aggiunta sezione blog per applicazioni aziendali e database al riquadro soluzioni NetApp. Aggiunti due blog ai blog del database.</block>
  <block id="8493c4f1797303a6de2524a60adcf058" category="cell">10/18/2021</block>
  <block id="ade15f89ccc27958a743a992cea8c574" category="cell">TR-4908 - soluzioni di database per il cloud ibrido con SnapCenter</block>
  <block id="622eda32248f1c4d1fc31dd78ec74c4a" category="cell">10/14/2021</block>
  <block id="f6ecd264493db5fac4b21f19be4eb69d" category="cell">Aggiunta delle parti 1-4 di NetApp con la serie di blog VMware VCF</block>
  <block id="83a11da06ed8a3e338b5e8d2991cae0c" category="cell">10/04/2021</block>
  <block id="c95696f6146a5b8b56c74d4349687ec6" category="cell">Aggiunta di una nuova demo video: Migrazione dei workload con Astra Control Center a NVA-1160</block>
  <block id="4f41bdb2ec81835b66ffbbd18feea656" category="cell">09/23/2021</block>
  <block id="9b699c59be5ba510cd9c430a31843b23" category="cell">Migrazione dei dati</block>
  <block id="32ff1e0d02ec482c64fdac1af2a49372" category="cell">Nuovo contenuto: Best practice NetApp per NetApp XCP</block>
  <block id="42246d8ef9280d19cf1326197310630a" category="cell">09/21/2021</block>
  <block id="10c87c454d38afc0644c8c1fb75fa524" category="cell">Nuovi contenuti o ONTAP per amministratori VMware vSphere, automazione VMware vSphere</block>
  <block id="faaef04f2f0bb7bed9504fc3d357ba59" category="cell">09/09/2021</block>
  <block id="80245b1f322b07a9fcd385bb375d8182" category="cell">Aggiunta dell'integrazione del bilanciamento del carico F5 BIG-IP con OpenShift a NVA-1160</block>
  <block id="023cd4d7ed373df0d803d414e2e452bf" category="cell">08/05/2021</block>
  <block id="afb6b7f715f1bf6492efb8f3c279ddd7" category="cell">Aggiunta una nuova integrazione tecnologica a NVA-1160 - NetApp Astra Control Center su Red Hat OpenShift</block>
  <block id="2cd99fd0d69d62395a72dc7d4684299c" category="cell">07/21/2021</block>
  <block id="13d13fda6fbfbd83ab30f9a5bee17b08" category="cell">Implementazione automatica di Oracle19c per ONTAP su NFS</block>
  <block id="e88b179e97a156d13d1c9c4163513205" category="cell">07/02/2021</block>
  <block id="9f99e3ea14c0a44dde0fd7db13fa3bef" category="cell">TR-4897 - SQL Server su Azure NetApp Files: Vista della distribuzione reale</block>
  <block id="83d39ff0c36403ca3e183af9ca091a71" category="cell">06/16/2021</block>
  <block id="2891cb0fe31606ff172d0be4ec81732f" category="cell">Aggiunta una nuova demo video, Installazione della virtualizzazione OpenShift: Red Hat OpenShift con NetApp</block>
  <block id="77d29c989f99997794df55b2d9053ae8" category="cell">Aggiunta una nuova demo video, Deploying a Virtual Machine with OpenShift Virtualization: Red Hat OpenShift with NetAppp</block>
  <block id="fab25e19f7e186358ed7f1268e7af3b4" category="cell">06/14/2021</block>
  <block id="96da300b5faf4ae3a5ca09afabba4273" category="cell">Soluzione aggiunta: Microsoft SQL Server su Azure NetApp Files</block>
  <block id="67c877d4abd9acdbb0fa62c3720b6d60" category="cell">06/11/2021</block>
  <block id="a14851e0e2cb4c8e9176cdea01500288" category="cell">Aggiunta di una nuova demo video: Workload Migration Using Astra Trident and SnapMirror to NVA-1160</block>
  <block id="c5d2015481e39976c67e40778a449a2d" category="cell">06/09/2021</block>
  <block id="c4aad26d0bd9fb92610a1b5b3390bd46" category="cell">Aggiunto un nuovo caso d'utilizzo a NVA-1160 - Advanced Cluster Management for Kubernetes su Red Hat OpenShift con NetApp</block>
  <block id="53977250e4a69cab3688fcbede8fb73a" category="cell">05/28/2021</block>
  <block id="9c23aa040a3dc51dbbf59463247f4fec" category="cell">Aggiunto un nuovo caso d'utilizzo a NVA-1160 - virtualizzazione OpenShift con NetApp ONTAP</block>
  <block id="c02e5ac689072495b8af780302105253" category="cell">05/27/2021</block>
  <block id="f5abcac882b8caa17d3af1c14144f503" category="cell">Aggiunto un nuovo caso d'utilizzo alla multi-tenancy NVA-1160 su OpenShift con NetApp ONTAP</block>
  <block id="3202abe9084b2d9ec5b0b162721978e7" category="cell">05/26/2021</block>
  <block id="d58aa75910c54a80c6ba4de7e7f6949f" category="cell">Aggiunto NVA-1160 - Red Hat OpenShift con NetApp</block>
  <block id="a0be3ecb819e8e7215f946964346f547" category="cell">05/25/2021</block>
  <block id="95a74db23b085df59ef6412199e9e791" category="cell">Blog aggiunto: Installazione di NetApp Trident su Red Hat OpenShift – come risolvere il problema ‘toomanyrequests' di Docker!</block>
  <block id="2dec0489948dbe7f63f68743a085e98c" category="cell">05/19/2021</block>
  <block id="9045bfbeff51b83f9752fe549021a181" category="cell">Aggiunto link alle soluzioni FlexPod</block>
  <block id="af3192eaae3cb09641db4adcc45ed625" category="cell">Soluzione ai Control Plane convertita da PDF a HTML</block>
  <block id="8ff5be8d16e86e5284f8ba8a3428459a" category="cell">05/17/2021</block>
  <block id="a88789a4f83f213b256b57eb0884fd1d" category="cell">Aggiunta della sezione Solution Feedback alla pagina principale</block>
  <block id="027fb9451c491d9dcfb7db05f552788d" category="cell">05/11/2021</block>
  <block id="3e62d5f1a7f1b6907ad1ecaf11282dac" category="cell">Aggiunta dell'implementazione automatica di Oracle 19c per ONTAP su NFS</block>
  <block id="d2422eca0ff6f19afb6e1206b15fbe01" category="cell">05/10/2021</block>
  <block id="85c96a5f13e6dea61e003704f8d456e2" category="cell">Nuovo video: Come utilizzare vVol con NetApp e VMware Tanzu Basic, parte 3</block>
  <block id="29e9b684dbbdf5cc1828da82a146781d" category="cell">05/06/2021</block>
  <block id="c30dd1a85cf86d95b11c1a08f70130ce" category="cell">Database Oracle</block>
  <block id="508db167da7d74fc86c3f8024ce04558" category="cell">Aggiunto link ai database Oracle 19c RAC su FlexPod DataCenter con Cisco UCS e NetApp AFF A800 su FC</block>
  <block id="85fbf94a3ecf9a3af4a93f80a3681fe1" category="cell">05/05/2021</block>
  <block id="608f33919f16e9a23bd532ad6bcf480a" category="cell">Aggiunto il video sull'automazione e l'NVA di FlexPod (1155)</block>
  <block id="4dc6e14d2ad9dafd2cd72f8c77d22bea" category="cell">05/03/2021</block>
  <block id="3d21a9c32818fc58b044121ce91e053c" category="cell">Virtualizzazione dei desktop</block>
  <block id="4174d4c17e4b11e07d8dd581e16ba56c" category="cell">Aggiunto link alle soluzioni di virtualizzazione desktop FlexPod</block>
  <block id="b3cae16f1f895f4f9ceae98617a3bf0d" category="cell">04/30/2021</block>
  <block id="2764512d2fc00264d149a6142151aa1a" category="cell">Video: Come utilizzare vVol con NetApp e VMware Tanzu Basic, parte 2</block>
  <block id="4996fa0acf5cc54e889a50e9bdd2e56b" category="cell">04/26/2021</block>
  <block id="9c5316849ca2429400f8979f0ee0d963" category="cell">Blog aggiunto: Utilizzo di VMware Tanzu con ONTAP per accelerare il tuo percorso verso Kubernetes</block>
  <block id="911da11d01e00e9aa94c5b03b2e6e2cc" category="cell">04/06/2021</block>
  <block id="06cfdb63e0660d09f203a21e28520a1e" category="cell">Aggiunta di "informazioni su questo repository"</block>
  <block id="32edd80de3642c58e1a05df5f3e458e1" category="cell">03/31/2021</block>
  <block id="bbb1c8f8182403001f2e1f69085ca2ad" category="cell">Aggiunto TR-4886 - Inferenziazione ai alla periferia: NetApp ONTAP con progettazione della soluzione Lenovo ThinkSystem</block>
  <block id="d61c9a3748e1dd56535fbdaaa3e39eab" category="cell">03/29/2021</block>
  <block id="8575a367028bec3e86e25b102a8dced1" category="cell">Aggiunto NVA-1157 - Apache Spark workload con la soluzione di storage NetApp</block>
  <block id="8f10e64b04f6cc56cf66fd4f4eb0f4d9" category="cell">03/23/2021</block>
  <block id="7998f8ad3cabe02af607385cae780ce1" category="cell">Video: Come utilizzare vVol con NetApp e VMware Tanzu Basic, parte 1</block>
  <block id="f86fe8ec70f2003923e4000589747208" category="cell">03/09/2021</block>
  <block id="eea51e9c0dffabdea48ada8f53bbf0f5" category="cell">Aggiunto contenuto e-Series; contenuto ai categorizzato</block>
  <block id="0b218fa381bfd1c86fff15d165ab23a0" category="cell">03/04/2021</block>
  <block id="932af944058a758da919ca59d1af640b" category="cell">Nuovi contenuti: Introduzione all'automazione delle soluzioni NetApp</block>
  <block id="4be9c930c1a8a198115d499cb3223d9e" category="cell">02/18/2021</block>
  <block id="0c560038af98c5401dd10202e7937acd" category="cell">Aggiunto TR-4597 - VMware vSphere per ONTAP</block>
  <block id="aa1c3ec5e6dcfb94555ff987f061f1a0" category="cell">02/16/2021</block>
  <block id="3ecf1285a084b58473a7873e3f33e74a" category="cell">Aggiunta di fasi di implementazione automatizzate per ai Edge Inferencing</block>
  <block id="8138d0c3e613508050b6fec12c4322c7" category="cell">02/03/2021</block>
  <block id="999bc6b18351bbe817d26f559ba408ae" category="cell">SAP</block>
  <block id="91171755730ad15e6d79b5cb6682a8f1" category="cell">Aggiunta landing page per tutti i contenuti SAP e SAP HANA</block>
  <block id="e5099bd65458f8a8556c830ac4759296" category="cell">02/01/2021</block>
  <block id="09689218a7f330554f4e28a18e9e14a6" category="cell">VDI con NetApp VDS, contenuto aggiunto per i nodi GPU</block>
  <block id="c487c48f1528e49e3cb129fdbdd79990" category="cell">01/06/2021</block>
  <block id="868f7f9e78f90bcf0597030ffefd449b" category="cell">Nuova soluzione: NetApp ONTAP ai con sistemi NVIDIA DGX A100 e switch Ethernet dello spettro Mellanox (progettazione e implementazione)</block>
  <block id="0663765430d1ca93138f13429aef7c37" category="cell">12/22/2020</block>
  <block id="a4aae8f8849c453c6c67080c5d013301" category="cell">Release iniziale del repository delle soluzioni NetApp</block>
  <block id="245ab73d4b9beb43ff76c082e9bc77db" category="open-title">Ai / analisi dei dati</block>
  <block id="9c155d9143dcac03a6b69afd6ec499b0" category="open-title">Multicloud ibrido</block>
  <block id="901b32f6abd15fbb3d43fbd044218a64" category="open-title">Applicazioni aziendali e DB</block>
  <block id="18a2eb3f7faf7c44e3062e78cbeff089" category="inline-link-macro">Archivio di soluzioni SAP</block>
  <block id="412b2ee09f2fbaf8cddb69ee6fe43a2e" category="admonition">Per ulteriori informazioni sugli aggiornamenti SAP e SAP HANA, fare riferimento al contenuto "Cronologia aggiornamenti" presente per ciascuna delle soluzioni in <block ref="c4ed54a973fb1aa472c2443732d93c13" category="inline-link-macro-rx"></block>.</block>
  <block id="71fbb346a6b64c94052f0e171d5d3eed" category="open-title">Protezione dei dati e migrazione dei dati</block>
  <block id="c8d20ce0b6bb23d912f3368f706d5794" category="summary">Le soluzioni NetApp sono un insieme di funzionalità strategiche e tecnologiche che enfatizzano il portfolio di prodotti e servizi NetApp per supportare le esigenze aziendali più critiche dei nostri clienti.</block>
  <block id="fcf140abed196b8eba71c45f21312bce" category="doc">Soluzioni NetApp</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="doc">Panoramica</block>
  <block id="1357196e1dc18c4ad43fe26a6c1b30ad" category="inline-link-macro">Precedente: Ottimizzazione delle performance.</block>
  <block id="33672b776ede62bd1269689ea61e45aa" category="paragraph"><block ref="33672b776ede62bd1269689ea61e45aa" category="inline-link-macro-rx"></block></block>
  <block id="1ebf7a1cb4f3826913a58c19018c694e" category="paragraph">Questa sezione descrive gli scenari dei clienti e le loro architetture.</block>
  <block id="b58464d62b5399c457b8a1fcf6bbcd27" category="inline-link-macro">Successivo: Data Lake su NFS ONTAP.</block>
  <block id="a24139c6a89df9b0694c3ea695639ace" category="paragraph"><block ref="a24139c6a89df9b0694c3ea695639ace" category="inline-link-macro-rx"></block></block>
  <block id="0706a8a70e2892183b45c55ef1394714" category="summary">Questa sezione fornisce il tempo approssimativo per eseguire le operazioni di copia XCP e sincronizzazione XCP con una dimensione file diversa di un milione di file per NFS.</block>
  <block id="137e4d3e0bc5586af6fc7ca9441511e1" category="doc">Linee guida per il dimensionamento</block>
  <block id="f688414f56f567909ca9a570f161016e" category="inline-link-macro">Precedente: Fasi di implementazione.</block>
  <block id="fb58e731328976afe8beac53cbe55ee7" category="paragraph"><block ref="fb58e731328976afe8beac53cbe55ee7" category="inline-link-macro-rx"></block></block>
  <block id="5224a4cb1d59edb5630ae27e640409e9" category="section-title">Stima del tempo basata sui test</block>
  <block id="7e9b65699b01d35aeff9dc16008da7a5" category="paragraph">I test per le operazioni di copia e sincronizzazione XCP utilizzavano lo stesso test bed utilizzato per l'implementazione. Sono stati creati un milione di file di tre set di file da 8K, 16K e 1MB e le modifiche sono state eseguite in tempo reale. La funzione di sincronizzazione XCP ha eseguito gli aggiornamenti incrementali differenziali dall'origine alla destinazione a livello di file. L'operazione di aggiornamento incrementale prevede una o più di queste quattro operazioni: Rinominare file e cartelle esistenti, aggiungere dati a file esistenti, eliminare file e cartelle e includere ulteriori collegamenti rigidi, soft e multipli. A scopo di test, ci siamo concentrati sulle operazioni di ridenominazione, aggiunta, eliminazione e collegamento. In altre parole, le operazioni di modifica, come rinominare, aggiungere ed eliminare, sono state eseguite con un tasso di modifica compreso tra il 10% e il 90% su un milione di file.</block>
  <block id="1112334374c9149cc8ad8e80a76f2e56" category="paragraph">La figura seguente mostra i risultati dell'operazione di copia XCP.</block>
  <block id="d6852faef2642951731c8d64e3009dbe" category="paragraph"><block ref="d6852faef2642951731c8d64e3009dbe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58fe8c2d511caf443cb23313cb89181b" category="paragraph">La figura seguente mostra i risultati delle operazioni di ridenominazione e collegamento di XCP Sync.</block>
  <block id="319b9e8dee4108359b7ef17af2fb492d" category="paragraph"><block ref="319b9e8dee4108359b7ef17af2fb492d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2186640ac8cac7be2b0f3940d871bf04" category="paragraph">La dimensione del file non è proposizionale a<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> tempo di completamento per il trasferimento dei file di origine rinominati; i grafici sono lineari.</block>
  <block id="de54b82b6e27abb7d6f924e14d40a351" category="paragraph">I tipi di collegamento sono soft link, hard link e multi-link. I soft link sono considerati file normali. La dimensione dei file non è rilevante per il tempo necessario per completare l'operazione di sincronizzazione XCP.</block>
  <block id="db3eb29ec347d79a716c6235063b1955" category="paragraph">Le seguenti figure mostrano i risultati delle operazioni di aggiunta e cancellazione della sincronizzazione XCP.</block>
  <block id="feeff6134484088b1b404089dc5f92d9" category="paragraph"><block ref="feeff6134484088b1b404089dc5f92d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64c7d081568c95905b16364c19e1be1" category="paragraph">Per le operazioni di aggiunta ed eliminazione, le grandi dimensioni dei file richiedono più tempo rispetto alle piccole dimensioni dei file. Il tempo necessario per completare l'operazione è lineare rispetto alla percentuale di aggiunta ed eliminazione delle modifiche.</block>
  <block id="ecc8d4faf16ec3b08a8badd1d71421d3" category="section-title">Confronto tra XCP 1.6.1 e XCP 1.5</block>
  <block id="f599c9e924e3b854abd0ab58126fed43" category="paragraph">Rispetto alle versioni precedenti, XCP 1.6.3 e 1.7 offrono prestazioni migliori. La sezione seguente mostra un confronto delle prestazioni di sincronizzazione tra XCP 1.6.3 e 1.7 per dimensioni 8K, 16K e 1MB di un milione di file.</block>
  <block id="b53776fdc2fd9fc721aaa6f03fd3d6a0" category="paragraph">Le seguenti figure mostrano i risultati delle prestazioni di sincronizzazione XCP per XCP 1.6.3 rispetto a 1.7 (con una dimensione 8K di un milione di file).</block>
  <block id="ded6c17dda87ca50a7ecde2418543075" category="paragraph"><block ref="ded6c17dda87ca50a7ecde2418543075" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09a0804a78587affdd9192afd0f8c80c" category="paragraph">La figura seguente mostra i risultati delle prestazioni di sincronizzazione XCP per XCP 1.6.1 rispetto a 1.5 (con una dimensione 16K di un milione di file).</block>
  <block id="b2733f54373c0149b19c3b37afbcb7da" category="paragraph"><block ref="b2733f54373c0149b19c3b37afbcb7da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b201508f1de849d630f98c0001fdc29" category="paragraph">La figura seguente mostra i risultati delle prestazioni di sincronizzazione XCP per XCP 1.6.1 rispetto a 1.5 con una dimensione di 1 MB di un milione di file.</block>
  <block id="e7770abf0d9a0789407ea0a0e81cc5a6" category="paragraph"><block ref="e7770abf0d9a0789407ea0a0e81cc5a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71c6a3c1c59fc41b371a18011d1d5c9b" category="paragraph">In media, le prestazioni di XCP 1.7 sono migliorate o sono simili a quelle di XCP 1.6.3 per<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> Operazioni di aggiornamento incrementale differenziale: Ridenominazione, aggiunta, collegamento ed eliminazione con una dimensione di 1 MB di un milione di file.</block>
  <block id="61b90da0c91ea6cb7c16bfaca41b4920" category="paragraph">In base a questa convalida delle performance, NetApp consiglia di utilizzare XCP 1.7 per la migrazione dei dati on-premise e nel cloud.</block>
  <block id="dd6275237d7504aabd0c206384365206" category="inline-link-macro">Avanti: Ottimizzazione delle performance.</block>
  <block id="cb619c90f7b537d24a1473acda746a47" category="paragraph"><block ref="cb619c90f7b537d24a1473acda746a47" category="inline-link-macro-rx"></block></block>
  <block id="2246a929033f1d77a86efa97dda42849" category="inline-link-macro">Precedente: Risoluzione dei problemi.</block>
  <block id="49c4600bab96ae4bda03f252b43985b4" category="paragraph"><block ref="49c4600bab96ae4bda03f252b43985b4" category="inline-link-macro-rx"></block></block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">Per ulteriori informazioni sulle informazioni descritte in questo documento, consultare i seguenti documenti e/o siti Web:</block>
  <block id="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link"><block ref="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link-rx"></block></block>
  <block id="eba010943793fb5b647ad292a452b3ff" category="list-text">Blog di NetApp XCP<block ref="2639c38af267ba997fc1d85740cfc9a6" category="inline-link-rx"></block></block>
  <block id="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link"><block ref="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link-rx"></block></block>
  <block id="fb8d9f206204f9562c2a67c6b37a7d1b" category="list-text">Guida utente di NetApp XCP<block ref="05f41a166d52148335e3a0df2eafec23" category="inline-link-rx"></block></block>
  <block id="e2c2bd378a3ae3740034d637754af7e2" category="inline-link"><block ref="e2c2bd378a3ae3740034d637754af7e2" category="inline-link-rx"></block></block>
  <block id="79b44e54a5eac82beac2de86249cd862" category="list-text">Dati di Bigdata Analytics per l'intelligenza artificiale: Soluzione Data Mover per l'ai<block ref="79ced727b5c9638c0385a25671803fba" category="inline-link-rx"></block></block>
  <block id="a43c7ca8f7e6a4a034f6a940ec7566f5" category="inline-link-macro">Pagina successiva: Cronologia delle versioni.</block>
  <block id="9ebf058ce7a44ad4517e7033db8a90a7" category="paragraph"><block ref="9ebf058ce7a44ad4517e7033db8a90a7" category="inline-link-macro-rx"></block></block>
  <block id="322bc614a8031f8c334d233f8221a4ab" category="summary">In questa sezione vengono descritte le procedure dettagliate per la migrazione dei dati da NetApp Data ONTAP in 7-Mode a ONTAP.</block>
  <block id="30ee25b2188724428e827e97bab504fe" category="doc">Migrazione dei dati da 7-Mode a ONTAP</block>
  <block id="aecfc9b89f609bfde217a6cf8fc0b00a" category="inline-link-macro">Precedente: Creazione di un file CSV da una condivisione SMB/CIFS.</block>
  <block id="6da13b2cdb445320dc3e29759119f4e8" category="paragraph"><block ref="6da13b2cdb445320dc3e29759119f4e8" category="inline-link-macro-rx"></block></block>
  <block id="3ec8186e1900b95154cccf8ccea38023" category="section-title">Transizione dello storage NFSv3 7-Mode a ONTAP per i dati NFS</block>
  <block id="e70a6b3d23d1e0da94c71a9ea26747d1" category="paragraph">In questa sezione viene illustrata la procedura dettagliata illustrata nella seguente tabella per la transizione di un'esportazione NFSv3 di origine 7-Mode a un sistema ONTAP.</block>
  <block id="cad365d13740342c8f6199feb7229137" category="paragraph">NetApp presuppone che il volume NFSv3 7-Mode di origine venga esportato e montato sul sistema client e che XCP sia già installato su un sistema Linux.</block>
  <block id="b40dbfa52a308abff927380b983cd868" category="list-text">Verificare che il sistema ONTAP di destinazione sia integro.</block>
  <block id="39745ae9472f91abcd9e844389157858" category="list-text">Verificare che sul sistema di destinazione sia presente almeno un aggregato non root. L'aggregato è normale.</block>
  <block id="47e01226b4fdf549d938eb5c6196970d" category="paragraph">Se non è presente alcun aggregato di dati, crearne uno nuovo utilizzando<block ref="b83f9c30c432b834d5aa4c7b46881164" prefix=" " category="inline-code"></block> comando.</block>
  <block id="5c52d0e31e44663ee633be681387faa1" category="list-text">Creare una macchina virtuale di storage (SVM) sul sistema cluster di destinazione.</block>
  <block id="426b5839edbb7a7772be396e7eaceace" category="list-text">Rimuovere i protocolli FCP, iSCSI, NDMP e CIDS dalla SVM di destinazione.</block>
  <block id="d03930721e424cdac105ccd0172f7dbe" category="paragraph">Verificare che NFS sia il protocollo consentito per questa SVM.</block>
  <block id="4d6b5eb9160c3c34e9ff5535c403cea9" category="list-text">Creare un nuovo volume di dati di lettura/scrittura sulla SVM di destinazione. Verificare che lo stile di sicurezza, le impostazioni della lingua e i requisiti di capacità corrispondano al volume di origine.</block>
  <block id="a2cebf1e91b2a266a58458873c8980fd" category="list-text">Creare una LIF di dati per soddisfare le richieste del client NFS.</block>
  <block id="6817d90b89495074e679248b56128378" category="paragraph">Verificare che la LIF sia stata creata correttamente.</block>
  <block id="3a014fae7f5d70cc01c593a8401140ee" category="list-text">Creare un percorso statico con la SVM, se necessario.</block>
  <block id="84bb87c2987a4b39ea23430f38570808" category="paragraph">Verificare che il percorso sia stato creato correttamente.</block>
  <block id="54b19b8b3b6de7bce018de598a1645ea" category="list-text">Montare il volume di dati NFS di destinazione nello spazio dei nomi SVM.</block>
  <block id="6365adb4324221d944bc90c4663dfe5a" category="paragraph">Verificare che il volume sia montato correttamente.</block>
  <block id="991398c32a43bcf95d7fa14129a6fcb0" category="paragraph">È inoltre possibile specificare le opzioni di montaggio del volume (percorso di giunzione) con<block ref="4784dd0ffa42c3d1b43b0afd079dfc17" prefix=" " category="inline-code"></block> comando.</block>
  <block id="6c02d24a81dd4d9b1ad7a15079b4f122" category="list-text">Avviare il servizio NFS sulla SVM di destinazione.</block>
  <block id="e210fe657c5d46e3e11ca263d1a18af7" category="paragraph">Verificare che il servizio sia avviato e in esecuzione.</block>
  <block id="304683b37151feda067e3acfde300057" category="list-text">Verificare che il criterio di esportazione NFS predefinito sia stato applicato alla SVM di destinazione.</block>
  <block id="353fde8a37910716dc00dec81475c0d5" category="list-text">Se necessario, creare un nuovo criterio di esportazione personalizzato per la SVM di destinazione.</block>
  <block id="174608facfdad6448222d6d46c87fba5" category="paragraph">Verificare che la nuova policy di esportazione personalizzata sia stata creata correttamente.</block>
  <block id="4007cf260b496d35ba0e925f1e7a183d" category="list-text">Modificare le regole dei criteri di esportazione per consentire l'accesso ai client NFS.</block>
  <block id="5f249df749512e129505d18fd47d7010" category="list-text">Verificare che al client sia consentito l'accesso al volume.</block>
  <block id="94a80f56f92334f07fd30337692ca889" category="list-text">Connettersi al server NFS Linux. Creare un punto di montaggio per il volume esportato NFS.</block>
  <block id="725ae014e8d8f66f0f2d477fa656ba32" category="list-text">Montare il volume NFSv3 di destinazione esportato in questo punto di montaggio.</block>
  <block id="a345b19bdd483ecd745a2e643b756bc6" category="admonition">I volumi NFSv3 devono essere esportati ma non necessariamente montati dal server NFS. Se possono essere montati, il client host XCP Linux monta questi volumi.</block>
  <block id="b5b2af7fb88c03cfd258cdd77fc6fbe1" category="paragraph">Verificare che il punto di montaggio sia stato creato correttamente.</block>
  <block id="8d3ac4d5ea9c5d5c45d7322512d7b778" category="list-text">Creare un file di test sul mount point NFS esportato per abilitare l'accesso in lettura/scrittura.</block>
  <block id="07e483b5917b8a9e91a22b2ebc20961a" category="admonition">Una volta completato il test di lettura/scrittura, eliminare il file dal punto di montaggio NFS di destinazione.</block>
  <block id="09280cd628b820e696b87163b3fe0fde" category="list-text">Connettersi al sistema client Linux in cui è installato XCP. Accedere al percorso di installazione di XCP.</block>
  <block id="86de6eeea329a50737c7056637f43e49" category="list-text">Eseguire una query sulle esportazioni NFSv3 7-Mode di origine eseguendo il<block ref="b28233b6c0fdcbe5d1e403bc2be8f960" prefix=" " category="inline-code"></block> Sul sistema host del client XCP Linux.</block>
  <block id="080173849f5fec049b214897a2882295" category="list-text">Eseguire la scansione dei percorsi esportati NFSv3 di origine e stampare le statistiche della relativa struttura di file.</block>
  <block id="df86b239e412ba3ba7192b581381b444" category="paragraph">NetApp consiglia di mettere le esportazioni NFSv3 di origine in modalità di sola lettura durante xcp<block ref="53aefec08170b2ebed981a0a86d0dbe0" prefix=" " category="inline-code"></block>,<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block>, e.<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block> operazioni.</block>
  <block id="695efe20ffcfc7c261e44cbb1b62cc78" category="list-text">Copiare le esportazioni NFSv3 7-Mode di origine nelle esportazioni NFSv3 sul sistema ONTAP di destinazione.</block>
  <block id="50515e001679292835a498c6bd3f3c31" category="list-text">Al termine della copia, verificare che le esportazioni NFSv3 di origine e di destinazione dispongano di dati identici. Eseguire<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> comando.</block>
  <block id="70d6a53ca7c3c592cb4099e2988c226c" category="paragraph">Se<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> rileva le differenze tra i dati di origine e di destinazione, quindi l'errore<block ref="54779b0a97a87c0c6df786545eae5f68" prefix=" " category="inline-code"></block> viene riportato nel riepilogo. Per risolvere il problema, eseguire<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> per copiare le modifiche di origine nella destinazione.</block>
  <block id="505d73172f49d62bd99779ab53aa5eeb" category="list-text">Prima e durante il cutover, eseguire<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> di nuovo. Se l'origine contiene dati nuovi o aggiornati, eseguire aggiornamenti incrementali. Eseguire<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> comando.</block>
  <block id="887abb0b5917a0a6b0c47f5ef3eca1ce" category="list-text">Per riprendere un'operazione di copia precedentemente interrotta, eseguire<block ref="d932e9ef0438ae21326fc9becf98ace1" prefix=" " category="inline-code"></block> comando.</block>
  <block id="f807709818ec3fbc508863a00ea17044" category="paragraph">Dopo<block ref="69f2afc2390cec954f7c208b07212d39" prefix=" " category="inline-code"></block> termina la copia dei file, esegui<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> anche in questo caso, in modo che lo storage di origine e di destinazione abbia dati identici.</block>
  <block id="d78900410b9203071958256c3d6a7701" category="list-text">L'host client NFSv3 deve smontare le esportazioni NFSv3 di origine fornite dallo storage 7-Mode e montare le esportazioni NFSv3 di destinazione da ONTAP. Il cutover richiede un'interruzione.</block>
  <block id="6bd42ffcfd349b793e9f6c6f00c18cd8" category="section-title">Transizione delle copie Snapshot del volume 7-Mode a ONTAP</block>
  <block id="fefac3d628a2abc2d1677e073a0688e7" category="paragraph">In questa sezione viene descritta la procedura per la transizione di una copia Snapshot NetApp di un volume di origine 7-Mode a ONTAP.</block>
  <block id="721e28a3edb434ca3d7f37307126504c" category="admonition">NetApp presuppone che il volume 7-Mode di origine sia esportato e montato sul sistema client e che XCP sia già installato su un sistema Linux. Una copia Snapshot è un'immagine point-in-time di un volume che registra le modifiche incrementali dall'ultima copia Snapshot. Utilizzare<block ref="3e126213c93cfd745d918a1d244a79cf" prefix=" " category="inline-code"></block> Opzione con un sistema 7-Mode come origine.</block>
  <block id="e18566c8fe02de3e35e48df30daa5189" category="paragraph">*Attenzione:* conservare la copia Snapshot di base. Non eliminare la copia Snapshot di base al termine della copia di riferimento. La copia Snapshot di base è necessaria per ulteriori operazioni di sincronizzazione.</block>
  <block id="50bdf0eaa7b3716343ae0345a98e1a5f" category="list-text">Creare una SVM sul sistema cluster di destinazione.</block>
  <block id="2e4b636c74015de6d92a2eb874c15a88" category="list-text">Rimuovere i protocolli FCP, iSCSI, NDMP e CIFS dalla SVM di destinazione.</block>
  <block id="c45e0bc468a9249c2954fa84c21f833e" category="list-text">Se necessario, creare un percorso statico con la SVM.</block>
  <block id="f35ea333881cef53fcd944d5a052be9d" category="paragraph">Verificare che il volume sia stato montato correttamente.</block>
  <block id="71c0d546c4569fd9a5798bdbc9729ab6" category="paragraph">È inoltre possibile specificare le opzioni di montaggio del volume (percorso di giunzione) con<block ref="4784dd0ffa42c3d1b43b0afd079dfc17" prefix=" " category="inline-code"></block> comando.</block>
  <block id="7ec3f8d8dd165416936305e1ca1530f0" category="list-text">Verificare che il criterio di esportazione NFS predefinito sia applicato alla SVM di destinazione.</block>
  <block id="f69801ea46df8aed1b26399a9330f459" category="list-text">Modificare le regole dei criteri di esportazione per consentire l'accesso ai client NFS sul sistema di destinazione.</block>
  <block id="9fee35c8bded36b1931a6addb7635a81" category="list-text">Verificare che il client abbia accesso al volume di destinazione.</block>
  <block id="7633c6765c7399ce0f1ecbca891fb11c" category="paragraph">NetApp consiglia di mettere le esportazioni NFSv3 di origine in modalità di sola lettura durante<block ref="79b37c0e9765296c2ba8efc16a70d15f" prefix=" " category="inline-code"></block>,<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block>, e.<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block> operazioni. Poll<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block> operazione, è necessario superare il<block ref="3e126213c93cfd745d918a1d244a79cf" prefix=" " category="inline-code"></block> con un valore corrispondente.</block>
  <block id="486e9eb5a73ed3d87e070761d3ceeefe" category="list-text">Copiare lo snapshot NFSv3 7-Mode di origine (base) nelle esportazioni NFSv3 sul sistema ONTAP di destinazione.</block>
  <block id="160bb3a75d27ad175143123df09bce76" category="admonition">Conserva questa snapshot di base per ulteriori operazioni di sincronizzazione.</block>
  <block id="97ba1a5f7ee8f9243390e46469b6e8f3" category="list-text">Una volta completata la copia, verificare che le esportazioni NFSv3 di origine e di destinazione abbiano dati identici. Eseguire<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> comando.</block>
  <block id="44842ca325a3ba46b3b4703a79fab171" category="paragraph">Se<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> rileva le differenze tra i dati di origine e di destinazione, quindi l'errore<block ref="dc84cf44b83b105281c2d7846f1ed44f" prefix=" " category="inline-code"></block> per copiare le modifiche di origine nella destinazione.</block>
  <block id="030bc6fe403e876e1c932987ece73d61" category="list-text">Prima e durante il cutover, eseguire<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> di nuovo. Se l'origine contiene dati nuovi o aggiornati, eseguire aggiornamenti incrementali. In caso di modifiche incrementali, creare una nuova copia Snapshot per queste modifiche e passare il percorso di snapshot con<block ref="3e126213c93cfd745d918a1d244a79cf" prefix=" " category="inline-code"></block> opzione per le operazioni di sincronizzazione.</block>
  <block id="b29cfae254be5e3cfc339ed594ea9378" category="paragraph">Eseguire<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> con il<block ref="3e126213c93cfd745d918a1d244a79cf" prefix=" " category="inline-code"></block> opzione e percorso di snapshot.</block>
  <block id="2885d0e1370007423656773743ce189b" category="admonition">Per questa operazione, è necessaria l'istantanea di base.</block>
  <block id="121dba07a28112a093b812991271c895" category="list-text">L'host client NFSv3 deve smontare le esportazioni NFSv3 di origine fornite dallo storage 7-Mode e montare le esportazioni NFSv3 di destinazione da ONTAP. Questo cutover richiede un'interruzione.</block>
  <block id="6db55966f4a2b44c31ed7672f14d023e" category="section-title">Migrazione di ACLv4 da NetApp 7-Mode a un sistema storage NetApp</block>
  <block id="8f81754856c547fbd3e5295b9da06cc7" category="paragraph">In questa sezione viene descritta la procedura dettagliata per la transizione di un'esportazione NFSv4 di origine a un sistema ONTAP.</block>
  <block id="fd58e84bd534e0ff49a00942e9ee2002" category="admonition">NetApp presuppone che il volume NFSv4 di origine sia esportato e montato sul sistema client e che XCP sia già installato su un sistema Linux. L'origine deve essere un sistema NetApp 7-Mode che supporti gli ACL. La migrazione ACL è supportata solo da NetApp a NetApp. Per copiare i file con un carattere speciale nel nome, assicurarsi che l'origine e la destinazione supportino il linguaggio codificato UTF- 8.</block>
  <block id="88464fae780b488ca9d39f305a3b3777" category="section-title">Prerequisiti per la migrazione di un'esportazione NFSv4 di origine in ONTAP</block>
  <block id="078b760bc7ad8cae447a095cc53029af" category="paragraph">Prima di migrare un'esportazione NFSv4 di origine in ONTAP, devono essere soddisfatti i seguenti prerequisiti:</block>
  <block id="abb629da0d811e197b383d473d19f265" category="list-text">Il sistema di destinazione deve avere configurato NFSv4.</block>
  <block id="09e4d7a665b5df121af76a08951028cf" category="list-text">L'origine e la destinazione di NFSv4 devono essere montate sull'host XCP. Selezionare NFS v4.0 in modo che corrisponda allo storage di origine e di destinazione e verificare che gli ACL siano abilitati sul sistema di origine e di destinazione.</block>
  <block id="c36e1764174e8e6a7791e7afd73f3294" category="list-text">XCP richiede il montaggio del percorso di origine/destinazione sull'host XCP per l'elaborazione ACL.nel seguente esempio,<block ref="d07c77c05891b869ab2111118b006bed" prefix=" " category="inline-code"></block> è montato su<block ref="dfecb62ab540058a212419f33235e6da" prefix=" " category="inline-code"></block> percorso:</block>
  <block id="baa4716341f52ff4d0642ca1398e16f1" category="section-title">Opzioni delle sottodirectory</block>
  <block id="66f63b7de79aaf05b47a1b63467b2a84" category="paragraph">Le due opzioni per lavorare con le sottodirectory sono le seguenti:</block>
  <block id="5d1498ef6a2ee01cb9031bbf8a8dadc4" category="list-text">Per XCP lavorare su una sottodirectory<block ref="9ce87e1289284ccca8cf788db9dd7804" prefix=" " category="inline-code"></block>), montare il percorso completo <block ref="58753164ce38e8977360bb376dda6e76" prefix="(" category="inline-code"></block>) Sull'host XCP.</block>
  <block id="39b3225d42725e9616ca3fee7aa7cbb6" category="paragraph">Se il percorso completo non è montato, XCP segnala il seguente errore:</block>
  <block id="84274fa575b6d9b0177512a818215d91" category="list-text">Utilizzare la sintassi della sottodirectory <block ref="ca6c8952cf206b58c7fc63aa1552d665" prefix="(" category="inline-code"></block>), come mostrato nell'esempio seguente:</block>
  <block id="8dd9bb3f47ac0b27a42761c265b0c720" category="paragraph">Completare i seguenti passaggi per migrare ACLv4 da NetApp 7-Mode a un sistema storage NetApp.</block>
  <block id="b2f12804e995a318c2272527efb05774" category="paragraph">Verificare che la SVM sia stata creata correttamente.</block>
  <block id="b887d08ec971525ffbfec7f19d01d72d" category="list-text">Verificare che il criterio di esportazione NFS predefinito sia applicato alla SVM di destinazione.</block>
  <block id="1c94e1638450716cd57f55bafd07e60f" category="paragraph">Verificare che le regole dei criteri siano state modificate.</block>
  <block id="132fa7c123291d5007311a22ff8f5654" category="list-text">Montare il volume di destinazione esportato NFSv4 in questo punto di montaggio.</block>
  <block id="c686c09824f51c6e681d87d1deb44c71" category="admonition">I volumi NFSv4 devono essere esportati ma non necessariamente montati dal server NFS. Se possono essere montati, il client host XCP Linux monta questi volumi.</block>
  <block id="e943b6ad310412b689f42adec28acf3a" category="paragraph">Verificare che il file sia stato creato.</block>
  <block id="35ce5d99ee6b9bb871da972e459e7259" category="list-text">Eseguire una query sulle esportazioni NFSv4 di origine eseguendo<block ref="b28233b6c0fdcbe5d1e403bc2be8f960" prefix=" " category="inline-code"></block> Sul sistema host del client XCP Linux.</block>
  <block id="97cc35dcdaf8c5c5fa0e936cd31e9907" category="list-text">Eseguire la scansione dei percorsi esportati NFSv4 di origine e stampare le statistiche della relativa struttura di file.</block>
  <block id="5073080976611febfcee79295d42232e" category="paragraph">NetApp consiglia di mettere le esportazioni NFSv4 di origine in modalità di sola lettura durante<block ref="79b37c0e9765296c2ba8efc16a70d15f" prefix=" " category="inline-code"></block>,<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block>, e.<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block> operazioni.</block>
  <block id="f120bcab91519def54b7b66ee0fbecfe" category="list-text">Copiare le esportazioni NFSv4 di origine in esportazioni NFSv4 sul sistema ONTAP di destinazione.</block>
  <block id="39ff9cab7c62e62bf182a632271eb700" category="list-text">Dopo<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block> Verificare che le esportazioni NFSv4 di origine e di destinazione abbiano dati identici. Eseguire<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> comando.</block>
  <block id="977c8a5f0f7f70041a1c6359c72cb1cd" category="paragraph">Se<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> rileva le differenze tra i dati di origine e di destinazione, quindi l'errore<block ref="54779b0a97a87c0c6df786545eae5f68" prefix=" " category="inline-code"></block> viene riportato nel riepilogo. Per risolvere il problema, eseguire<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> per copiare le modifiche di origine nella destinazione.</block>
  <block id="29aee025cf0bcad3c355bd0aad4516e6" category="admonition">Per questa operazione, è necessario il nome o il numero dell'indice di copia precedente.</block>
  <block id="ee0fd4f8758695ad7502bee81363478a" category="list-text">Per riprendere un'interruzione precedente<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block> eseguire il<block ref="d932e9ef0438ae21326fc9becf98ace1" prefix=" " category="inline-code"></block> comando.</block>
  <block id="cdc35fb8de987dae3f48c142ffcb0686" category="section-title">Transizione dello storage SMB 7-Mode a ONTAP per i dati CIFS</block>
  <block id="74efc43b80fa7a84f709780789176e0d" category="paragraph">In questa sezione viene illustrata la procedura dettagliata per la transizione di una condivisione SMB di origine 7-Mode a un sistema ONTAP.</block>
  <block id="f6f758220d5d00061aaa03b99e14785b" category="admonition">NetApp presuppone che i sistemi 7-Mode e ONTAP siano dotati di licenza SMB. Viene creata la SVM di destinazione, vengono esportate le condivisioni SMB di origine e di destinazione e XCP viene installato e concesso in licenza.</block>
  <block id="281c766457d5499048f9440f61957421" category="list-text">Eseguire la scansione delle condivisioni SMB per individuare file e directory.</block>
  <block id="95c490ed8cb5d13c961fc2c50c372940" category="list-text">Copiare i file (con o senza ACL) dall'origine alla condivisione SMB di destinazione. Nell'esempio seguente viene illustrata una copia con ACL.</block>
  <block id="dc056263ce0a29568cee559ae8ec35dc" category="admonition">Se non esiste un aggregato di dati, crearne uno nuovo utilizzando lo storage<block ref="a3c52ca282dcb77dd824f54a7b270068" prefix=" " category="inline-code"></block> comando.</block>
  <block id="7c34f7c35c71ba790649c5563408e77e" category="list-text">Sincronizzare i file di origine e di destinazione.</block>
  <block id="974c1ef10ec8fef5b3ff19989555d061" category="list-text">Verificare che i file siano stati copiati correttamente.</block>
  <block id="8ae319b52e88ea41e78a01efdaab2143" category="inline-link-macro">Segue: Migrazione dei dati CIFS con ACL da un storage box di origine a ONTAP.</block>
  <block id="b6ea874ca7f1192a99c58fa3ff1199ba" category="paragraph"><block ref="b6ea874ca7f1192a99c58fa3ff1199ba" category="inline-link-macro-rx"></block></block>
  <block id="035fe4f74f99e66d6525774bf40236f9" category="summary">Questa sezione contiene Best practice, linee guida e consigli per la migrazione dei dati con NetApp XCP.</block>
  <block id="52f7ac44cac2d8d1a3f005648d7521e3" category="doc">Linee guida e consigli sulle Best practice</block>
  <block id="b5a13e4f32bf69c6814808ff6a11eb9b" category="inline-link-macro">Precedente: Migrazione dei dati CIFS con ACL da uno storage box di origine a ONTAP.</block>
  <block id="a930ea4d6e07241178b9fe2f3c054fd2" category="paragraph"><block ref="a930ea4d6e07241178b9fe2f3c054fd2" category="inline-link-macro-rx"></block></block>
  <block id="1cce79308861dd86d5e56af13afefaf2" category="list-text">Utilizzare il sistema operativo del client XCP, supportato da IMT. Il client supportato da IMT è qualificato da NetApp.</block>
  <block id="ec653488c4b3b9bb00702a4fb937f5b4" category="list-text">Eseguire XCP come utente root nel sistema operativo Linux per eseguire la migrazione. È possibile eseguire il comando xcp come utente sudo, ma non è supportato da XCP.</block>
  <block id="8c8f6415908fe0a235f0850d80a398a4" category="list-text">Eseguire una sola istanza di XCP per client. Tecnicamente è possibile eseguire più istanze di XCP sullo stesso host da una posizione diversa, tuttavia questa procedura non è supportata. In effetti, l'esecuzione di molte istanze potrebbe causare un errore.</block>
  <block id="cac486281cae3e805e89a64673c47eb3" category="list-text">Nella versione corrente di XCP, Live Source non è supportato. Se il volume NetApp di origine è attivo e continuamente modificato da applicazioni e utenti, è necessario creare un'istantanea del volume di origine per eseguire una migrazione.</block>
  <block id="c1f9797ffa66b762cf07348c6bc4a005" category="list-text">È consigliabile creare una nuova snapshot con un nome diverso per ogni sincronizzazione incrementale, in modo da creare facilmente un percorso di migrazione incrementale basato sul nome dello snapshot in caso di errore.</block>
  <block id="1309895bb5c78406c77a6cc2800160eb" category="list-text">Se si esegue una migrazione basata su snapshot, è consigliabile continuare la migrazione basata su snapshot fino al cutover.</block>
  <block id="cc9954d8dc3e80c40af9d0a7ca3de005" category="list-text">Se si dispone di più di 10 milioni di file e si dispone di una modifica incrementale dei dati superiore al 50%, è consigliabile utilizzare un numero di core più elevato e una quantità di memoria maggiore rispetto al valore minimo consigliato nella guida all'installazione e all'amministrazione.</block>
  <block id="f6cb936ed9c08627956daed52c6c3323" category="inline-link-macro">Avanti: Risoluzione dei problemi.</block>
  <block id="58c815a6f6adf3657aa40f96cb5f2d08" category="paragraph"><block ref="58c815a6f6adf3657aa40f96cb5f2d08" category="inline-link-macro-rx"></block></block>
  <block id="485f9678c52b78d051ddff564d873eb9" category="summary">Il comando in questa sezione scarica i dati in formato CSV. È possibile riassumere la colonna delle dimensioni per ottenere la dimensione totale dei dati.</block>
  <block id="92f6d6878e37105d20e75151b95d4e6a" category="doc">Creazione di un file CSV da una condivisione SMB/CIFS</block>
  <block id="bab825782f37e3f0cd908b20bc8aa74c" category="inline-link-macro">Precedente: Scansione e copia dei dati specifiche basate sulla data.</block>
  <block id="ad80673543d1d2744f55966060c4579b" category="paragraph"><block ref="ad80673543d1d2744f55966060c4579b" category="inline-link-macro-rx"></block></block>
  <block id="d122031c67144a65ca4721f8324ae0b3" category="paragraph">Il seguente comando scarica i dati nel formato CSV. È possibile riassumere la colonna delle dimensioni per ottenere la dimensione totale dei dati.</block>
  <block id="1bed902c0754e4abc7598b7f1a0450e0" category="paragraph">L'output dovrebbe essere simile a questo esempio:</block>
  <block id="f7c322db5a6c805aed8a38858c7ba770" category="paragraph">Per eseguire la scansione fino alla profondità di tre sottodirectory e fornire il risultato in ordine di ordinamento, eseguire<block ref="cadccce7ea0e7fd5923a57bff135b0f1" prefix=" " category="inline-code"></block> comando e dump delle dimensioni a ogni livello di directory fino alla profondità di tre sottodirectory.</block>
  <block id="7c12bd6fa64456eb3a61460a4bbb98e6" category="paragraph">Per ordinare le informazioni, eseguire il dump delle informazioni in un file CSV e ordinarle.</block>
  <block id="d0ecdc77c2c944d380e9fef0e01eb119" category="paragraph">Si tratta di un report personalizzato che utilizza<block ref="3c8468c40f21d7ea04242771207b5d3e" prefix=" " category="inline-code"></block> comando. Esegue la scansione di tutte le directory e scarica il nome della directory, il percorso e la dimensione della directory in un file CSV. È possibile ordinare la colonna delle dimensioni dall'applicazione per fogli di calcolo.</block>
  <block id="c2e9a8d6d376247b10a1ab4624bd2610" category="inline-link-macro">Pagina successiva: Migrazione dei dati da 7-Mode a ONTAP.</block>
  <block id="7155e60f207d105fa4db5d15efdce133" category="paragraph"><block ref="7155e60f207d105fa4db5d15efdce133" category="inline-link-macro-rx"></block></block>
  <block id="b25f76deff236f93a3afa73c8a5b2a2c" category="summary">Questo caso di utilizzo si basa sul più grande cliente del settore turistico di NetApp per la migrazione di milioni di piccoli file on-primes nel cloud.</block>
  <block id="4b1739353c6d18cea69ed6a274b7135f" category="doc">Utilizzo di XCP Data Mover per la migrazione di milioni di file di piccole dimensioni in uno storage flessibile</block>
  <block id="2b2142a0bf2476846ad59f7952380ca1" category="inline-link-macro">Precedente: Calcolo dalle performance elevate per NFS ONTAP.</block>
  <block id="c81efa558deea51a126490ba8d09b59a" category="paragraph"><block ref="c81efa558deea51a126490ba8d09b59a" category="inline-link-macro-rx"></block></block>
  <block id="bb29cc4e9e4447f7bad1e81c1c5a9a1f" category="paragraph">Questo caso di utilizzo si basa sul più grande cliente del settore del turismo di NetApp per la migrazione dei dati on-premise-to-cloud. Poiché COVID-19 ha ridotto la domanda nel settore dei viaggi, i clienti vogliono risparmiare sulle spese di capitale per lo storage high-end nel loro ambiente on-premise per l'applicazione di prezzi on-premise. Questo cliente dispone di un SLA stretto per la migrazione di milioni di piccoli file nel cloud.</block>
  <block id="81ec900a5387f7a686d1451adaddf399" category="paragraph">La figura seguente illustra la migrazione dei dati da on-premise a Azure NetApp Files per file di piccole dimensioni.</block>
  <block id="214c5e9894032cde0e65b576e32294b9" category="paragraph"><block ref="214c5e9894032cde0e65b576e32294b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="099a60093e7de3795f557974125ce82b" category="inline-link">Soluzione NetApp XCP Data Mover: On-premise per il cloud</block>
  <block id="50d4edabefc40ad9614b567197696a2e" category="paragraph">Per ulteriori informazioni, consultare<block ref="2c0eb3741003532ef113837d4b882a9a" category="inline-link-rx"></block> blog.</block>
  <block id="3242fe890cd89c89373a1bd576cef03a" category="inline-link-macro">Avanti: Utilizzo di XCP Data Mover per migrare file di grandi dimensioni.</block>
  <block id="c32441c7755c153b58450a597193448b" category="paragraph"><block ref="c32441c7755c153b58450a597193448b" category="inline-link-macro-rx"></block></block>
  <block id="89185de94c95d958df7a1d1f328c5d3d" category="summary">La migrazione prevede diverse fasi da seguire per una migliore pianificazione e completamento della migrazione. Per migrare i dati da storage NAS di terze parti o storage esportato NAS direttamente collegato utilizzando NetApp XCP, seguire le linee guida per la migrazione fornite in questa sezione.</block>
  <block id="ee5b035493cdde88f6472904ffe00677" category="doc">Workflow di migrazione</block>
  <block id="33af37ca0d75bc0783cc87782a94cb6e" category="inline-link-macro">Precedente: NetApp XCP.</block>
  <block id="c6f303d52bc03c848b2dde21f1b31f9d" category="paragraph"><block ref="c6f303d52bc03c848b2dde21f1b31f9d" category="inline-link-macro-rx"></block></block>
  <block id="5b312b66520bbb17746eeb5c9959e4ef" category="paragraph">La figura seguente illustra il flusso di lavoro di migrazione da qualsiasi NAS a NetApp NAS.</block>
  <block id="228d4a26c37192668bb7f7bf0d81ce40" category="paragraph"><block ref="228d4a26c37192668bb7f7bf0d81ce40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0e69ccbb7ad96f546f7924206944bfa" category="section-title">On-premise</block>
  <block id="8df17c51ab4a9817f3fe7cea57052110" category="paragraph">Il flusso di lavoro di migrazione da qualsiasi NAS a NAS NetApp include i seguenti passaggi:</block>
  <block id="3bd3dda9341b512ee536cc6e48d51a69" category="list-text">Rilevare le condivisioni e i dati NAS.</block>
  <block id="7800ed0aa4aebf1d63fd7120c2bcf538" category="list-text">Eseguire la scansione dei dati e creare un report per individuare il layout dei dati.</block>
  <block id="8e9880476ad79e202d93a0a7d0bb5f5b" category="list-text">Creare una linea di base eseguendo il comando XCP Copy. Per migrazioni più rapide, selezionare più istanze XCP e suddividere il carico di lavoro a livello di sottocartella per avviare processi di migrazione parallela.</block>
  <block id="57324e972ea87c8e788d9831e510bc6d" category="list-text">Per gli aggiornamenti incrementali, utilizzare XCP Sync fino a quando la velocità di modifica non è bassa per la finestra di cutover.</block>
  <block id="3812202d715addac73d7122672d3c8d0" category="list-text">Contrassegnare l'origine come di sola lettura per eseguire una sincronizzazione finale eseguendo il comando XCP Sync per completare la migrazione.</block>
  <block id="2c1d8a91f274a7723f6ad2ffefc81b62" category="list-text">Per verificare che i dati siano stati trasferiti correttamente, confrontare l'origine e la destinazione eseguendo il<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> comando.</block>
  <block id="c8e2277ecfb1427838c488c217f99466" category="section-title">Cloud</block>
  <block id="b98a6acc7ef428f1ae11e5177447df8c" category="paragraph">Per il cloud, è possibile seguire un flusso di lavoro di migrazione on-premise simile se la connettività tra on-premise e il cloud è Direct Connect (AWS), ExpressRoute (Azure) o Cloud Interconnect (GCP).</block>
  <block id="8f4cde54f5af74d15d142ad98344aab6" category="paragraph">La figura seguente illustra il flusso di lavoro di migrazione da on-premise al cloud.</block>
  <block id="9d1b3862e72bece8266c1c8b1098c696" category="paragraph"><block ref="9d1b3862e72bece8266c1c8b1098c696" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2fef7fa18bd688132425321b9188bb" category="paragraph">Se non esiste una connessione Internet diretta tra on-premise e il cloud, è necessario trasferire i dati da on-premise al cloud attraverso un metodo di trasporto dati offline, ad esempio Truck. Ogni cloud service provider ha un metodo diverso con terminologia diversa per spostare i dati nel proprio data center.</block>
  <block id="9e76bcaf48df4797c2e546f778fd72f8" category="paragraph">La figura seguente mostra la soluzione di trasmissione dati per Azure on-premise senza ExpressRoute.</block>
  <block id="e13bab0261f71ca4765f8b68cea20a43" category="paragraph"><block ref="e13bab0261f71ca4765f8b68cea20a43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="423066080659363cc444ec5dee611f48" category="paragraph">È possibile utilizzare un'architettura simile con i rispettivi componenti dei vari provider di servizi cloud.</block>
  <block id="050572d01f21dded8086b49419066add" category="inline-link-macro">Avanti: Analisi dei file.</block>
  <block id="ae292ee37a105844872f831698fb440f" category="paragraph"><block ref="ae292ee37a105844872f831698fb440f" category="inline-link-macro-rx"></block></block>
  <block id="69f55c7d7266874ad1ed57caf459c979" category="summary">Questo caso di utilizzo si basa sul più grande proof of concept finanziario per i clienti (CPOC) che abbiamo realizzato. Storicamente, abbiamo utilizzato il modulo di analisi in-place NetApp (NIPAM) per spostare i dati di analisi su NetApp ONTAP ai. Tuttavia, a causa dei recenti miglioramenti e delle migliori performance di NetApp XCP, nonché dell'esclusivo approccio alla soluzione per il data mover di NetApp, abbiamo rieseguito la migrazione dei dati utilizzando NetApp XCP.</block>
  <block id="5084e1c3bd53b6115df08f4c40aadbe6" category="doc">Data Lake su NFS ONTAP</block>
  <block id="ae8dcf06c5337995ca840fbd543188fc" category="inline-link-macro">Precedente: Scenari cliente.</block>
  <block id="82f418da831bb7ca7897e30f8bc5525a" category="paragraph"><block ref="82f418da831bb7ca7897e30f8bc5525a" category="inline-link-macro-rx"></block></block>
  <block id="b1a11a01b3bdf3150e0240a1f037cdf5" category="section-title">Sfide e requisiti dei clienti</block>
  <block id="9ed16d5ac47c336caaf9ca2b75930d78" category="paragraph">Le sfide e i requisiti dei clienti che meritano di essere notati includono quanto segue:</block>
  <block id="b6976e1a47e217f1a7c746e8f57e327c" category="list-text">I clienti dispongono di diversi tipi di dati, tra cui dati strutturati, non strutturati e semistrutturati, log, e dati machine-to-machine nei data lake. I sistemi ai richiedono tutti questi tipi di dati da elaborare per le operazioni di previsione. Quando i dati si trovano in un file system nativo di un data Lake, è difficile elaborarli.</block>
  <block id="d85cb5080a9e99841f0ff6c36abdadad" category="list-text">L'architettura ai del cliente non è in grado di accedere ai dati da Hadoop Distributed file System (HDFS) e Hadoop Compatible file System (HCFS), pertanto i dati non sono disponibili per le operazioni ai. Ai richiede dati in un formato di file system comprensibile come NFS.</block>
  <block id="982b6c87ace8f5b95c0523bd0557f4e2" category="list-text">Per spostare i dati dal data Lake sono necessari alcuni processi speciali a causa della grande quantità di dati e dell'elevato throughput, mentre per spostare i dati nel sistema ai è necessario un metodo conveniente.</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="section-title">Soluzione per il data mover</block>
  <block id="b0a9a6f2387f2a23e13931f68fc509c1" category="paragraph">In questa soluzione, il file system MapR (MapR-FS) viene creato dai dischi locali nel cluster MapR. Il gateway NFS MapR viene configurato su ciascun nodo dati con IP virtuali. Il servizio file server memorizza e gestisce i dati MapR-FS. NFS Gateway rende accessibili i dati Map-FS dal client NFS attraverso l'IP virtuale. Un'istanza XCP viene eseguita su ciascun nodo dati MapR per trasferire i dati dal gateway NFS di mappatura a NetApp ONTAP NFS. Ogni istanza di XCP trasferisce un set specifico di cartelle di origine nella posizione di destinazione.</block>
  <block id="01e1c2900284f91d77ea71ffd32c6d18" category="paragraph">La figura seguente illustra la soluzione NetApp per il data mover per cluster MapR che utilizza XCP.</block>
  <block id="a7dcdfa2099e01480afb3c060c679f10" category="paragraph"><block ref="a7dcdfa2099e01480afb3c060c679f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="409f476aa8c516a92f8d6a42e21db5a0" category="inline-link">Utilizzo di XCP per spostare i dati da un data Lake e dall'elaborazione ad alte performance a NFS ONTAP</block>
  <block id="4084b5f9c9bab8db38eb6e04a3b3a4cc" category="paragraph">Per i casi di utilizzo dettagliati dei clienti, le demo registrate e i risultati dei test, consulta la<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> blog.</block>
  <block id="6cef4abedb8153458ee404a47b193489" category="inline-link">TR-4732: Dai dati di analisi dei big data all'intelligenza artificiale</block>
  <block id="520ef13ea64298a652262e37756b6bd4" category="paragraph">Per informazioni dettagliate sullo spostamento dei dati MapR-FS in NFS ONTAP utilizzando NetApp XCP, vedere l'Appendice B in<block ref="c952a09d2ff4403056a594c41db26c8d" category="inline-link-rx"></block>.</block>
  <block id="b4dd66db226c58dbbcc8455a7576d491" category="inline-link-macro">Avanti: Calcolo dalle performance elevate per NFS ONTAP.</block>
  <block id="9ebf542ce4a3a8a997eb85e5b6e086ed" category="paragraph"><block ref="9ebf542ce4a3a8a997eb85e5b6e086ed" category="inline-link-macro-rx"></block></block>
  <block id="7776aec966d5a0c71bd4e8230f9470b8" category="summary">Questo caso di utilizzo si basa su un cliente di rete televisiva. Il cliente desiderava migrare i file di backup di Oracle Recovery Manager (RMAN) nel cloud ed eseguire l'applicazione Oracle e-Business Suite (EBS) utilizzando Azure NetApp Files con il software Pacemaker. Il cliente desiderava inoltre migrare i file di backup del database nello storage cloud on-demand e trasferire file di grandi dimensioni (nell'intervallo da 25 GB a 50 GB ciascuno) in Azure.</block>
  <block id="8108bac490ceb375198c578e8a439026" category="doc">Utilizzo di XCP Data Mover per la migrazione di file di grandi dimensioni</block>
  <block id="adec666d077f4afe1b4f2b8720ed1247" category="inline-link-macro">Precedente: Utilizzo di XCP Data Mover per migrare milioni di file di piccole dimensioni in uno storage flessibile.</block>
  <block id="d6be3aed77745a993a24266eaf05084d" category="paragraph"><block ref="d6be3aed77745a993a24266eaf05084d" category="inline-link-macro-rx"></block></block>
  <block id="06470d7a09a56d555bad98bdf38a6cad" category="paragraph">La figura seguente illustra la migrazione dei dati da on-premise a Azure NetApp Files per file di grandi dimensioni.</block>
  <block id="1b95efe3eae02043da6528de3cf9caf8" category="inline-link-macro">Successivo: File duplicati.</block>
  <block id="76fdb34470826293aaf52b30bf98fce0" category="paragraph"><block ref="76fdb34470826293aaf52b30bf98fce0" category="inline-link-macro-rx"></block></block>
  <block id="ddf97b6ffb913bd772848e3ebecfc8c1" category="summary">In questa sezione vengono descritte le fasi di implementazione di NetApp XCP per il trasferimento dei dati.</block>
  <block id="8388066510b59c8d3387373b6969a7af" category="doc">Fasi di implementazione</block>
  <block id="c6310b144c1666a29ec7cacf1c0dceab" category="inline-link-macro">Precedente: Analisi dei file.</block>
  <block id="57c4917a0617c8b675e6cc1dbad5c7fe" category="paragraph"><block ref="57c4917a0617c8b675e6cc1dbad5c7fe" category="inline-link-macro-rx"></block></block>
  <block id="8449c94058b7c2e686c3e19f7e772a65" category="section-title">Dettagli del letto di prova</block>
  <block id="94cb70bde9d89f0b10ffdca34b0bec22" category="paragraph">La seguente tabella fornisce i dettagli del test bed utilizzato per questa implementazione e convalida delle performance.</block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="cell">Componenti della soluzione</block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">Dettagli</block>
  <block id="57419d904381619fcf00bc94e4ce26f1" category="cell">XCP versione 1.7</block>
  <block id="0bf2dca8ce9b94406660e58b59a3dbbd" category="list-text">Un server Linux - Linux (RHEL 7.9 o RHEL 8)</block>
  <block id="d85d793ce9fe1772209fa5e17fb29449" category="list-text">Un server Windows – Windows Server 2019 standard</block>
  <block id="91ea491db15b6d672d79b23fb98eb089" category="cell">Coppia ha di storage array NetApp AFF per il volume di origine</block>
  <block id="23ec9249d03285a513eaaf182a7bcd49" category="list-text">AFF8080</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="list-text">NetApp ONTAP 9</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">Protocollo NFS</block>
  <block id="80fdc6d88149270be735269f2ff65645" category="cell">Coppia ha di storage array NetApp AFF per il volume di destinazione</block>
  <block id="53270fbfda62583949b287e08ae3d063" category="list-text">AFF A800</block>
  <block id="203165a49e3a391bdbc44e3a05d54279" category="list-text">ONTAP 9</block>
  <block id="28712ee052ea500eba0cdbb1d847277f" category="cell">Server Fujitsu PRIMERGY RX2540</block>
  <block id="539c5af1c2682685cd076697aaa6c700" category="cell">Ciascuno dotato di: * 48 CPU * memoria fisica Intel Xeon * 256 GB * doppia porta 10 GbE</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="cell">Networking</block>
  <block id="0cc5c79089d6ca0752529568758efc4c" category="cell">10 GbE</block>
  <block id="76e3e2a4e56301dafc50613d96fd624e" category="section-title">Fasi di implementazione - NAS</block>
  <block id="2879e817640f94636340918850eb6903" category="inline-link">Guida utente di NetApp XCP</block>
  <block id="f2dd54ec57ec5464ee3aa191a48a8a43" category="paragraph">Per implementare NetApp XCP per il trasferimento dei dati, installare e attivare il software XCP nella posizione di destinazione. È possibile rivedere i dettagli in<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>. A tale scopo, attenersi alla seguente procedura:</block>
  <block id="62e9f0426675b856daf874c75830c213" category="inline-link-macro">"Prerequisiti per XCP."</block>
  <block id="4f6583b152ef684b4492414bcdcdf877" category="list-text">Soddisfare i prerequisiti descritti in dettaglio nella sezione <block ref="958d961a425946e5195ca036cea97fab" category="inline-link-macro-rx"></block></block>
  <block id="c58c8903e33903d2e630277aa3a78795" category="inline-link">NetApp XCP (Downloads)</block>
  <block id="2d1acef34bb45f2c1878c6b576f3b400" category="list-text">Scaricare il software XCP da<block ref="13844fc5dba1627d28169d2acfff11e2" category="inline-link-rx"></block>.</block>
  <block id="8319752fe43598ddb329e536217c1cb5" category="list-text">Copiare i file TAR XCP scaricati sul server XCP.</block>
  <block id="c9b8e059d1597eaead43d286e91c91e3" category="list-text">Estrarre il tarfile.</block>
  <block id="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link"><block ref="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link-rx"></block></block>
  <block id="19f1deecf23a78878eb01c772b9233e0" category="list-text">Scaricare la licenza da<block ref="4da39fde529d1b69f60873c302229eed" category="inline-link-rx"></block> E copiare sul server XCP.</block>
  <block id="3df11515e644382207c1430c36ea48bb" category="list-text">Attivare la licenza.</block>
  <block id="ad7984249c2054b4da5fd3b57b1b91ef" category="list-text">Individuare la porta NFS di origine e il server NFS di destinazione. La porta predefinita è 2049.</block>
  <block id="79fe861b8c719b1a534bdbcace1444a2" category="list-text">Controllare la connessione NFS. Controllare il server NFS (sia per l'origine che per la destinazione) utilizzando telnet per la porta del server NFS.</block>
  <block id="5e471de79dbe02105770bcf04bc501d5" category="list-text">Configurare il catalogo.</block>
  <block id="67005679d502da10622f2104421e894b" category="list-text">Creare un volume NFS ed esportare NFS per il catalogo XCP. È inoltre possibile sfruttare l'esportazione NFS del sistema operativo per il catalogo XCP.</block>
  <block id="d6f2a18783592d1858e3e5bdcabd4567" category="list-text">Controllare l'esportazione NFS.</block>
  <block id="39b638480b201a7448774e8186012e4e" category="list-text">Aggiornare<block ref="d509f49d5d9a07934f91eefcf45a7334" prefix=" " category="inline-code"></block>.</block>
  <block id="9d44d1309af47903754b16c403f68774" category="list-text">Individuare le esportazioni NAS di origine utilizzando<block ref="b28233b6c0fdcbe5d1e403bc2be8f960" prefix=" " category="inline-code"></block>. Cerca:</block>
  <block id="fbff9a42f0ba33571594cb39da93ef4b" category="list-text">(Facoltativo) eseguire la scansione dei dati NAS di origine.</block>
  <block id="82d1938e7390e37babdea8d6fd359156" category="paragraph">La scansione dei dati NAS di origine consente di comprendere il layout dei dati e di individuare eventuali problemi di migrazione. Il tempo delle operazioni di scansione XCP è proporzionale al numero di file e alla profondità della directory. È possibile saltare questo passaggio se si ha familiarità con i dati NAS.</block>
  <block id="c6e94e11da5ba5bce0f27b8c782e4110" category="list-text">Controllare il report creato da<block ref="79b37c0e9765296c2ba8efc16a70d15f" prefix=" " category="inline-code"></block>. Cerca principalmente cartelle illeggibili e file illeggibili.</block>
  <block id="6a6a10773cfc849f638ac0137a5f08d6" category="list-text">(Facoltativo) modificare l'inode. Visualizzare il numero di inode e modificare il numero in base al numero di file da migrare o copiare per i volumi di catalogo e di destinazione (se necessario).</block>
  <block id="342779baf0b15fdf377f142c987e896a" category="list-text">Eseguire la scansione del volume di destinazione.</block>
  <block id="a88831977a2b62e982b722f6fa6662b5" category="list-text">Controllare lo spazio dei volumi di origine e di destinazione.</block>
  <block id="4b14d92fd07932987cf7416eb7f604ca" category="list-text">Copiare i dati dall'origine alla destinazione utilizzando<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> e controllare il riepilogo.</block>
  <block id="506aae448569ed08125f41ed940eb00b" category="admonition">Per impostazione predefinita, XCP crea sette processi paralleli per copiare i dati. È possibile sintonizzarlo.</block>
  <block id="5c46a2da3e6e0423829946fe877c50b8" category="admonition">NetApp consiglia di leggere il volume di origine. In tempo reale, il volume di origine è un file system attivo e attivo. Il<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> L'operazione potrebbe non riuscire perché NetApp XCP non supporta un'origine live che viene continuamente modificata da un'applicazione.</block>
  <block id="0f7dbc07af0b5c3ba51ff604b81ebe8a" category="paragraph">Per Linux, XCP richiede un ID di indice perché XCP Linux esegue la catalogazione.</block>
  <block id="764363dd147880ab6aca242a0417562e" category="list-text">(Facoltativo) controllare gli inode sul volume NetApp di destinazione.</block>
  <block id="ab3ba5fb62db279b7d07bac650a6c2d2" category="list-text">Eseguire l'aggiornamento incrementale utilizzando<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block>.</block>
  <block id="6cdfbe571ba2209e0a76f3bcabfee9f6" category="paragraph">Per questo documento, per simulare in tempo reale, un milione di file nei dati di origine è stato rinominato, quindi i file aggiornati sono stati copiati nella destinazione utilizzando<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block>. Per Windows, XCP necessita di percorsi di origine e destinazione.</block>
  <block id="13475b4ca9a916769b9d63f4fddfa18d" category="list-text">Convalidare il trasferimento dei dati. È possibile verificare che l'origine e la destinazione abbiano gli stessi dati utilizzando<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block>.</block>
  <block id="1cd06f171a5a99926a67bd673014f765" category="paragraph">La documentazione di XCP fornisce diverse opzioni (con esempi) per<block ref="53aefec08170b2ebed981a0a86d0dbe0" prefix=" " category="inline-code"></block>,<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block>,<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block>, e.<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> operazioni. Per ulteriori informazioni, consultare<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>.</block>
  <block id="efa146517859e051c07fabac4c88d3e7" category="admonition">I clienti Windows devono copiare i dati utilizzando gli elenchi di controllo degli accessi (ACL). NetApp consiglia di utilizzare il comando<block ref="1b5d03dc1e4b5c3623897fd210394888" prefix=" " category="inline-code"></block>. Per ottenere le massime performance, considerando il volume di origine che contiene dati SMB con ACL e i dati accessibili sia da NFS che da SMB, la destinazione deve essere un volume NTFS. Utilizzando XCP (versione NFS), copiare i dati dal server Linux ed eseguire la sincronizzazione XCP (versione SMB) con<block ref="4332bdcfbd72db6a4dae51bd101af3d6" prefix=" " category="inline-code"></block> e.<block ref="0e638f18c7569b1e062f20f430b0a5fc" prefix=" " category="inline-code"></block> Opzioni dal server Windows per copiare gli ACL dai dati di origine ai dati SMB di destinazione.</block>
  <block id="85760de676a9f74f28f26115c39c9a0b" category="inline-link">Configurazione della policy "Gestisci registro di controllo e sicurezza"</block>
  <block id="a0251b301ad566d86ffa3916c5510295" category="paragraph">Per informazioni dettagliate, vedere<block ref="06fdba77988da3047baf401e4fdefca5" category="inline-link-rx"></block>.</block>
  <block id="0957326f089aaf98a5b7b9110a2675cd" category="section-title">Fasi di implementazione - migrazione dei dati HDFS/MapRFS</block>
  <block id="1f43fc63f63aad0b707e06b0753182a1" category="paragraph">In questa sezione, discuteremo della nuova funzionalità XCP chiamata Hadoop Filesystem Data Transfer a NAS, che esegue la migrazione dei dati da HDFS/MapRFS a NFS e viceversa.</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">Prerequisiti</block>
  <block id="368666825ffae5710ab122fb63937cee" category="paragraph">Per la funzione MapRFS/HDFS, è necessario eseguire la seguente procedura in un ambiente utente non root. In genere, l'utente non root è hdfs, mapr o un utente che dispone dell'autorizzazione per apportare modifiche al file system HDFS e MapRFS.</block>
  <block id="9adbc05b1436b3e8962253577f1e6441" category="list-text">Impostare le variabili CLASSPATH, HADOOP_HOME, NHDFS_LIBJVM_PATH, LB_LIBRARY_PATH e NHDFS_LIBHDFS_PATH nel file CLI o .bashrc dell'utente insieme a<block ref="430e727eb7fa4c8fdeb29b396f232465" prefix=" " category="inline-code"></block> comando.</block>
  <block id="2a0eda7a7937e303f9e18a57a033fcb8" category="list-text">NHDFS_LIBHDFS_PATH punta al file libhdfs.so. Questo file fornisce API HDFS per interagire e manipolare i file e il file system HDFS/MapRFS come parte della distribuzione Hadoop.</block>
  <block id="13682a0461e750a2dfb4e86c2ddc1165" category="list-text">NHDFS_LIBJVM_PATH punta al file libjvm.so. Si tratta di una libreria di macchine virtuali JAVA condivisa nella posizione jre.</block>
  <block id="60ce276a5dde3f2d2e92b1986a2eb339" category="list-text">CLASSPATH punta a tutti i file jar utilizzando i valori (Hadoop classpath –glob).</block>
  <block id="84cbf778b2572cae5eba01d0ca330078" category="list-text">Percorso_LIBRERIA_LD punta alla posizione della cartella della libreria nativa di Hadoop.</block>
  <block id="68207eb9f168add2309e88b5223d57c6" category="paragraph">Vedere il seguente esempio basato su un cluster Cloudera.</block>
  <block id="91328810a5559a740f522f4c5a1da5f1" category="paragraph">In questa release, supportiamo operazioni di scansione, copia e verifica XCP e migrazione dei dati da HDFS a NFS. È possibile trasferire i dati da un singolo nodo di lavoro del cluster di data Lake e da più nodi di lavoro. Nella versione 1.8, gli utenti root e non root possono eseguire la migrazione dei dati.</block>
  <block id="dee4c2c7e685015e9f3cc1ad197f3ab5" category="section-title">Fasi di implementazione - l'utente non root migra i dati HDFS/MetrFS in NetApp NFS</block>
  <block id="5983f77acc016b8138698b32b0ab0405" category="list-text">Seguire gli stessi passaggi descritti nella sezione relativa ai passaggi per l'implementazione della sezione 1-9 passaggi.</block>
  <block id="c2765e27844a39bfc897cb964eec8711" category="list-text">Nell'esempio seguente, l'utente esegue la migrazione dei dati da HDFS a NFS.</block>
  <block id="e6f549e8013d1f24b8756cd11ff3083e" category="list-text">Creare una cartella e file (utilizzando<block ref="f45bd8fcd9fdd879ec3b59c5cb0cf396" prefix=" " category="inline-code"></block>) In HDFS.</block>
  <block id="2433ce85404dd68893a2e4abb99843e4" category="list-text">Controllare i permessi nella cartella HDFS.</block>
  <block id="befab6065ddb441f0b260ac75a8e84c8" category="list-text">Creare una cartella in NFS e controllare i permessi.</block>
  <block id="02341ea695e862c3a2d89461b1b8bf37" category="list-text">Copiare i file da HDFS a NFS utilizzando XCP e controllare le autorizzazioni.</block>
  <block id="d2bac014bbd39f6954893239102c5678" category="inline-link-macro">Segue: Linee guida per il dimensionamento.</block>
  <block id="b49cd7fb5a227da1698c527804f31bbb" category="paragraph"><block ref="b49cd7fb5a227da1698c527804f31bbb" category="inline-link-macro-rx"></block></block>
  <block id="dc0b758a04bbb9e380300887d831e4e1" category="summary">Questa sezione fornisce alcuni dei parametri di tuning che consentono di migliorare le prestazioni delle operazioni XCP.</block>
  <block id="9db3ca538820d0cfb7b44ef80f16ca98" category="doc">Tuning delle performance</block>
  <block id="7931b9aae255139b42cb605b3b62a6db" category="inline-link-macro">Precedente: Linee guida per il dimensionamento.</block>
  <block id="0ff4824165c6661bc016402e35d2a9fe" category="paragraph"><block ref="0ff4824165c6661bc016402e35d2a9fe" category="inline-link-macro-rx"></block></block>
  <block id="ec6136417c258c9b7f95c39765c5ca51" category="paragraph">Questa sezione fornisce alcuni dei parametri di tuning che consentono di migliorare le prestazioni delle operazioni XCP:</block>
  <block id="dd10b781bf6dd686a8631401ce0fba96" category="list-text">Per una migliore scalabilità e per distribuire il carico di lavoro tra più istanze XCP, dividere le sottocartelle per ogni istanza XCP per la migrazione e il trasferimento dei dati.</block>
  <block id="37e9b10f81fe31cb6b80609f724b34f8" category="list-text">XCP può utilizzare il massimo delle risorse della CPU: Più sono i core della CPU, migliori sono le performance. Pertanto, il server XCP dovrebbe disporre di un numero maggiore di CPU. Abbiamo testato in laboratorio 128 GB di RAM e 48 CPU core, che hanno fornito prestazioni migliori rispetto alle 8 CPU e 8 GB di RAM.</block>
  <block id="a02c6dbd226d5506c1b4b07f6d383615" category="list-text">Copia XCP con<block ref="7c497b25395c5c56889e20e941e5e84d" prefix=" " category="inline-code"></block> L'opzione si basa sul numero di CPU. Il numero predefinito di thread paralleli (sette) è talvolta sufficiente per la maggior parte delle operazioni di trasferimento e migrazione dei dati XCP. Per XCP Windows, per impostazione predefinita, il numero di processi paralleli è uguale al numero di CPU. Il numero massimo di<block ref="7c497b25395c5c56889e20e941e5e84d" prefix=" " category="inline-code"></block> l'opzione deve essere minore o uguale al numero di core.</block>
  <block id="740950b0e27cdd5def3c4295d5840851" category="list-text">10GbE è un buon punto di partenza per il trasferimento dei dati. Tuttavia, abbiamo testato con 25GbE e 100GbE, che hanno fornito un migliore trasferimento dei dati e sono consigliati per il trasferimento di dati di grandi dimensioni.</block>
  <block id="a174d00dcd4849e0653429de84c71cde" category="list-text">Per Azure NetApp Files, le performance variano in base al livello di servizio. Per ulteriori informazioni, consultare la seguente tabella, che mostra i livelli di servizio e i dettagli sulle prestazioni di Azure NetApp Files.</block>
  <block id="6d59be48f566a73e053e12167b279be5" category="cell">Livello di servizio</block>
  <block id="eb6d8ae6f20283755b339c0dc273988b" category="cell">Standard</block>
  <block id="8d5e7e72f12067991186cdf3cb7d5d9d" category="cell">Premium</block>
  <block id="7057376a419b3334cc7b8b7a9f064abb" category="cell">Ultra</block>
  <block id="0b85467ebafa7ca3c47e82dc38184484" category="cell">Throughput</block>
  <block id="adcda45ec4de9aeb48e1893272b078d1" category="cell">16 Mbps/terabyte (TB)</block>
  <block id="93209d2e9d1ed8d87a279cef886b5021" category="cell">64 MB/TB</block>
  <block id="f646efbbd60d091e92b32611965c4f1c" category="cell">128 MBps/TB</block>
  <block id="4a9cc851fc41c5762618832386fa4937" category="cell">Tipi di workload</block>
  <block id="11969136028e1ffaeed70de5e59bde33" category="cell">Condivisioni di file generiche, e-mail e web</block>
  <block id="76ab8c335a6bb24396ea1953bac75705" category="cell">BMS, database e applicazioni</block>
  <block id="9dab8e594b90062c0612cbb1676234ba" category="cell">Applicazioni sensibili alla latenza</block>
  <block id="0a568304277380e4cfb0f2d2abbd99b4" category="cell">Spiegazione delle performance</block>
  <block id="c55268b956eecd1d58f60723a410c808" category="cell">Performance standard: 1,000 IOPS per TB (16K i/o) e 16 Mbps/TB</block>
  <block id="536d2154a9035458ae8efd38b24f3ea7" category="cell">Prestazioni premium: 4,000 IOPS per TB (16k i/o) e 64 MBps/TB</block>
  <block id="91ff77656b0dc231fcbe8f488a15a253" category="cell">Performance estreme: 8,000 IOPS per TB (16k i/o) e 128 MBps/TB</block>
  <block id="121bc30e927e8a3d918fc90c0ec18fee" category="paragraph">È necessario scegliere il livello di servizio corretto in base al throughput e ai tipi di carico di lavoro. La maggior parte dei clienti inizia con il livello Premium e cambia il livello di servizio in base al carico di lavoro.</block>
  <block id="f44706d8f59ec82b48b083fb246a4fc7" category="inline-link-macro">Segue: Scenari cliente.</block>
  <block id="bb0eaaf9fa62e9175efd3145f00946ea" category="paragraph"><block ref="bb0eaaf9fa62e9175efd3145f00946ea" category="inline-link-macro-rx"></block></block>
  <block id="a01ed8ff3f6e9e3ac0c0068a083281f2" category="summary">Questa sezione fornisce indicazioni per la risoluzione dei problemi relativi alla migrazione dei dati con NetApp XCP.</block>
  <block id="231cf4c70d866b616c21baddaeed0696" category="doc">Risoluzione dei problemi</block>
  <block id="ae638a1049211e9956348a48a85bd359" category="inline-link-macro">Precedente: Linee guida e consigli sulle Best practice.</block>
  <block id="e19cdddb31b62a88048cfee77eb96e9d" category="paragraph"><block ref="e19cdddb31b62a88048cfee77eb96e9d" category="inline-link-macro-rx"></block></block>
  <block id="95109c432d89e67182659615993ba75d" category="section-title">Errore 1: XCP non riuscito con errore nfs3 70: Errore di gestione file obsoleta nel xcp.log</block>
  <block id="99b1b0e3547443c29793187326a64dbc" category="paragraph">*Motivo e guida.*</block>
  <block id="0774d3e8b775fcc34e680b302e85f3c1" category="paragraph">Montare la cartella di origine e verificare che esista. Se non esiste o se è stato rimosso, si riceverà un<block ref="00b68e4b07be7b89e91e391a70e312d1" prefix=" " category="inline-code"></block> errore, nel qual caso è possibile ignorare l'errore.</block>
  <block id="8fefb715a66a069c9e9318a58ecfdaee" category="section-title">Errore 2: Il volume di destinazione NetApp NFS ha spazio, ma XCP non è riuscito con errore nfs3 28: Spazio non disponibile sul dispositivo</block>
  <block id="bba52daa861e8093e201c3939f43057f" category="list-text">Controllare lo spazio del volume di destinazione NFS eseguendo il<block ref="eff7d5dba32b4da32d9a67a519434d3f" prefix=" " category="inline-code"></block> controllare o controllare lo storage.</block>
  <block id="20183145becc54cc822a80107f92f13d" category="list-text">Controllare gli inode nel controller di storage.</block>
  <block id="fe3a96130e3ec3092026a84e4dd12e50" category="list-text">Se si utilizza inode, aumentare il numero di inode eseguendo il seguente comando:</block>
  <block id="40a15e6807b47955e7b7a9b1bd330b01" category="inline-link-macro">Avanti: Dove trovare ulteriori informazioni.</block>
  <block id="00f1ec7e4f2acc8a9e2c5a06b2d62607" category="paragraph"><block ref="00f1ec7e4f2acc8a9e2c5a06b2d62607" category="inline-link-macro-rx"></block></block>
  <block id="3d5c39f585b0e679dbfe0855d556f0af" category="summary">NetApp XCP trasferisce i dati utilizzando multistrthread e funzionalità personalizzabili. È progettato per tre casi di utilizzo principali: Spostamento o migrazione dei dati, analisi del file system ed eliminazione rapida dell'albero delle directory.</block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="doc">XCP di NetApp</block>
  <block id="5231f9fa4d08024f4620b759f83d0e97" category="inline-link-macro">Precedente: Introduzione.</block>
  <block id="211c181ce8e8cb0472af3095c66dc5eb" category="paragraph"><block ref="211c181ce8e8cb0472af3095c66dc5eb" category="inline-link-macro-rx"></block></block>
  <block id="6416bf9c9c9445fbe2e15f69fa8371d2" category="paragraph">NetApp XCP trasferisce i dati utilizzando multistrthread e funzionalità personalizzabili. È progettato per tre casi di utilizzo principali: Spostamento o migrazione dei dati, analisi del file system ed eliminazione rapida dell'albero delle directory.</block>
  <block id="7817bd783e8db0557909483f54288eae" category="section-title">Spostamento o migrazione dei dati</block>
  <block id="a7786f240f16aadfd675c46be438f64e" category="paragraph">NetApp XCP trasferisce i dati da qualsiasi NAS a NetApp NAS. Questo processo consiste di quattro operazioni principali: Scansione, copia, sincronizzazione e verifica. Sono disponibili alcune funzionalità aggiuntive per il monitoraggio e il trasferimento dei dati:</block>
  <block id="1c026a57d7676d346dd0d44a2f595c1d" category="list-text">*Scan.* fornisce un layout di alto livello dei dati NAS e MapR/HDFS.</block>
  <block id="59e4194e1b171063beeb99722a68e7af" category="list-text">*Copy.* esegue un trasferimento di dati di riferimento.</block>
  <block id="a75ddee1308f2f19e478595122434544" category="list-text">*Sync.* esegue il trasferimento incrementale dei dati.</block>
  <block id="ae4ab572ec7de44b385c01df54f00d17" category="list-text">*Verify.* esegue una verifica completa della destinazione.</block>
  <block id="8ddbaa98ade9dcd56d4960b7abd22525" category="list-text">*Show (opzionale).* rileva le condivisioni NAS.</block>
  <block id="4f4544fb0f8ed8f32e27a8b8651a46e6" category="paragraph">La figura seguente illustra le operazioni di replica e migrazione dei dati XCP.</block>
  <block id="6d97d3e510fc0fba449ece8ddd3f3d10" category="paragraph"><block ref="6d97d3e510fc0fba449ece8ddd3f3d10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="657bad21acd4ceb926477ced53a4ec55" category="section-title">Analytics del file system</block>
  <block id="65424b0dc0515cfa3b67e71712012db0" category="paragraph">NetApp XCP consente di identificare, esaminare e analizzare in modo nativo i dati non strutturati per migliorare le informazioni, un requisito fondamentale per i clienti aziendali che desiderano utilizzare tali informazioni per una migliore pianificazione, per rendere operative le risorse digitali di alto valore e per la governance dei dati attraverso il reporting e la valutazione.</block>
  <block id="03c5a03e8b03794f5fa193e72245496c" category="paragraph">I clienti che si occupano di dati sensibili possono utilizzare NetApp XCP per rispondere a domande operative tipiche, come ad esempio:</block>
  <block id="6ad28c778baa08cff585599e160c12c8" category="list-text">Dove sono i miei dati?</block>
  <block id="5eccfafcfad0fb3dcd5f4f1036fed9f9" category="list-text">Quanti dati e quali tipi di file abbiamo?</block>
  <block id="b1c54971a6211d7b7e3d074bff16b4c9" category="list-text">Quali dati vengono utilizzati attivamente e quanto sono inattivi?</block>
  <block id="6b2c974b2ada5fba492b8dcda598b1f9" category="paragraph">La figura seguente illustra la comunicazione di NetApp XCP file analytics dalla GUI.</block>
  <block id="81ff19b428c80049b09f8e1e6e55cfde" category="paragraph"><block ref="81ff19b428c80049b09f8e1e6e55cfde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a6c498fb90ee345d997f888fce3b18" category="section-title">Eliminare</block>
  <block id="4125c56415a1c3b98b49ee7f8c2ebfc3" category="paragraph">Per i team di storage e i carichi di lavoro EDA (Electronic Design Automation) può essere molto difficile ripulire le grandi directory, sia che si tratti di dati obsoleti o di dati di test che devono essere ripuliti per ripristinare lo spazio di storage. XCP offre una funzionalità di eliminazione rapida che consente di eliminare un intero albero di directory. La funzione NetApp XCP Delete rimuove file e cartelle da un determinato percorso NAS. È possibile utilizzare i filtri di confronto per eliminare un set specifico di file e cartelle. Per un numero elevato di file e cartelle, è possibile utilizzare l'opzione Force (forza), che non richiede una conferma per l'eliminazione.</block>
  <block id="ecfd5328aaeaeb8ab72037598049a32c" category="section-title">Supporto della migrazione live source</block>
  <block id="2d3aa3941d30870beb3abde613ce14b1" category="paragraph">Il supporto Live Source Migration incluso in XCP 1.7 consente la migrazione da un'origine dati in uso attivo (attività di lettura e scrittura). XCP lascia i file utilizzati durante il processo di migrazione, ad esempio copia e sincronizzazione in esecuzione, mentre le informazioni sui file ignorati vengono acquisite nel registro XCP.</block>
  <block id="286a0f56c729672b0709605c558d0008" category="paragraph">Questa funzione supporta le modifiche sull'origine ma non supporta le modifiche sulla destinazione. Durante la migrazione, la destinazione non dovrebbe essere attiva. Il supporto Live Source Migration è disponibile solo per le migrazioni NFS.</block>
  <block id="2c346a482fcf83bd03d1d51f65d58b8d" category="admonition">Non sono richieste impostazioni speciali per le migrazioni Live Source.</block>
  <block id="ba41152bc4991a294ab26fbe691d52e3" category="section-title">Prerequisiti per XCP</block>
  <block id="010e3e2a3d44100784dac368cdb601c0" category="paragraph">Prima di implementare NetApp XCP, è necessario soddisfare i seguenti prerequisiti:</block>
  <block id="b76760dcfae800f7180ec4e8c57a8e2f" category="list-text">Verificare le porte NFS utilizzate dal server NFS eseguendo il seguente comando:</block>
  <block id="a9a9fca38da059af5a55e2fc58ef3851" category="list-text">Per accedere alla posizione in cui vengono eseguite le operazioni XCP, ad esempio istanze on-premise o cloud (ad esempio, Azure, AWS o istanze di macchine virtuali Google [VM]), aprire le porte del firewall per le porte NFS.</block>
  <block id="b22a57ce186f512ec584f5aac1d3de34" category="list-text">Verificare che la porta NFS sia accessibile dal server XCP utilizzando il comando telnet<block ref="450e3ef5096f09acecd7b33e07b6e190" prefix=" " category="inline-code"></block>. La porta predefinita è 2049. Se l'ambiente dispone di una porta diversa, utilizzare tale IP.</block>
  <block id="e54a7adb3b7e28ed3d693d972fc48fd0" category="list-text">Per NFS, verificare che le condivisioni siano accessibili dal server XCP utilizzando<block ref="3c4a3208b8bf46e9aa41c950ec1a73ba" prefix=" " category="inline-code"></block> comando.</block>
  <block id="da7f6a983e12f3b14b965ea651990ca9" category="list-text">Aumentare il numero di inode sul volume di destinazione a un valore superiore al numero di file (numero di file) sui file di origine.</block>
  <block id="71858e85f290ec0f6955841bab9f3aef" category="inline-link">Portale di licenza NetApp XCP</block>
  <block id="14324adbfb79ad4b6832f6a02a1275db" category="list-text">Scaricare la licenza XCP dal<block ref="eab886d42d2df7a710066e6d9bf6f5f5" category="inline-link-rx"></block>.</block>
  <block id="7481213bd7173438d06de418474e428b" category="list-text">Devi disporre di un account NetApp su mysupport.netapp.com o puoi registrarti gratuitamente.</block>
  <block id="d25e9f08475ddf6a2701e7cfbd67ff06" category="list-text">Scarica la licenza e preparala.</block>
  <block id="b9611b870758eac97bd0c3bcb3fc8026" category="list-text">Crea una condivisione NFS on-premise per ogni volume Azure NetApp o per il Cloud Volume Service (livello di servizio premium) nel cloud per il catalogo XCP.</block>
  <block id="3d19c697861d11cce0f1d78d41cfea64" category="list-text">Creare un volume NAS e configurare la condivisione per la destinazione dei dati.</block>
  <block id="4f2a304b9680876edc7cb61b5c4c7134" category="list-text">Per più istanze XCP, è necessario disporre di uno o più server o istanze cloud per trasferire i dati da più cartelle o file di origine alla destinazione.</block>
  <block id="adc4e34febc2f5919cfa03870630c2fc" category="list-text">La dimensione massima (predefinita è 308 MB) definisce il numero massimo di file (circa un milione) in una singola cartella. Aumentare il valore della dimensione massima per aumentare il numero di file. L'aumento del valore ha un effetto su cicli CPU aggiuntivi.</block>
  <block id="a1552408599f6e2171495d55ae375802" category="list-text">Nel cloud, NetApp consiglia di utilizzare ExpressRoute (Azure), Direct Connect (AWS) o Cloud Interconnect (GCP) tra on-premise e cloud.</block>
  <block id="fb41b0ab70237465636fc4267d1c00dd" category="inline-link-macro">Segue: Workflow di migrazione.</block>
  <block id="7480aca6b5f94dc27cc94b015284d5e9" category="paragraph"><block ref="7480aca6b5f94dc27cc94b015284d5e9" category="inline-link-macro-rx"></block></block>
  <block id="7e0710b4cb48030b7a4c065128b88194" category="summary">In questa sezione viene illustrata la procedura dettagliata per la migrazione dei dati CIFS con informazioni di sicurezza da un sistema ONTAP di origine a un sistema CIFS di destinazione.</block>
  <block id="82f0875c37eacadc40a7a7fb2a6b6313" category="doc">Migrazione dei dati CIFS con ACL da uno storage box di origine a ONTAP</block>
  <block id="0f17f55a868185c28a66d0817a780f53" category="inline-link-macro">Precedente: Migrazione dei dati da 7-Mode a ONTAP.</block>
  <block id="99b2c0d3f328317650f8748e47c7bedb" category="paragraph"><block ref="99b2c0d3f328317650f8748e47c7bedb" category="inline-link-macro-rx"></block></block>
  <block id="c55bb6c3381ca2d8a4016e387cc62883" category="list-text">Creare una LIF di dati per soddisfare le richieste dei client SMB.</block>
  <block id="5368b7f480b92b4a2a9b475e6e9cf953" category="list-text">Montare il volume di dati di destinazione nello spazio dei nomi SVM.</block>
  <block id="18f8848c17d02fd34b293885d5d3a215" category="list-text">Avviare il servizio CIFS sulla SVM di destinazione.</block>
  <block id="cf1269d629dc2110f2ae65edf8662b79" category="list-text">Verificare che il criterio di esportazione predefinito sia applicato alla SVM di destinazione.</block>
  <block id="74e1ca9e0b551a7349207f3d546b9f51" category="list-text">Modificare le regole dei criteri di esportazione per consentire l'accesso ai client CIFS.</block>
  <block id="3c19a2ac394a25f9ace05db18ad86c8b" category="paragraph">Verificare che le regole dei criteri siano state modificate.</block>
  <block id="876afc73f4771f46cfc9dba7fb687744" category="list-text">Connettersi al sistema client Windows in cui è installato XCP. Accedere al percorso di installazione di XCP.</block>
  <block id="e73a44af938fa16a4816d3639d2f3b69" category="list-text">Eseguire una query sulle esportazioni SMB del nodo di origine eseguendo<block ref="b28233b6c0fdcbe5d1e403bc2be8f960" prefix=" " category="inline-code"></block> Sul sistema host del client XCP Windows.</block>
  <block id="7132ef955ec5e0151ccd0790da2551d7" category="list-text">Eseguire<block ref="657f8b8da628ef83cf69101b6817150a" prefix=" " category="inline-code"></block> comando per la copia.</block>
  <block id="268b71a144890a49d97f8ca062fd48f9" category="list-text">Sul sistema ONTAP di destinazione, ottenere l'elenco dei nomi degli utenti locali e dei gruppi locali da fornire come valori per<block ref="7a80adbcbc4a0b2e96e8eb2710f30c85" prefix=" " category="inline-code"></block> e.<block ref="8d03d04d9c44ec2988a893826753f985" prefix=" " category="inline-code"></block> percorso degli argomenti.</block>
  <block id="ac9ad1198db0fb6f730a1f3aa97c35ab" category="list-text">Per migrare i dati CIFS con ACL dall'origine alla destinazione, eseguire<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> con il<block ref="4332bdcfbd72db6a4dae51bd101af3d6" prefix=" " category="inline-code"></block> e.<block ref="a72a6079b50973fd59860e6635a4ea62" prefix=" " category="inline-code"></block> opzioni.</block>
  <block id="a53e836d6264ad1778a4e1a7ae34f58c" category="paragraph">Per<block ref="a3fe89370a4bb214c60bfe40074b2c43" prefix=" " category="inline-code"></block> Opzioni, specificare qualsiasi utente o gruppo trovato in Active Directory o utente/gruppo locale nel sistema di destinazione.</block>
  <block id="9aa080e55cad2c9968cc50de60a3f88e" category="list-text">Se<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> genera il messaggio di errore<block ref="2400b6710d9959881ab1c252d8b07325" prefix=" " category="inline-code"></block>, aggiungere la casella di destinazione nel file hosts <block ref="803976de87f6862821bd3c4d94e0ff2b" prefix="(" category="inline-code"></block>).</block>
  <block id="b7ceaa0e08e9de5bf76572a50529f752" category="paragraph">Utilizzare il seguente formato per la voce della casella di destinazione dello storage NetApp.</block>
  <block id="569ccf25ad533b79cf2f639f0326d943" category="list-text">Se viene visualizzato ancora il messaggio di errore<block ref="2400b6710d9959881ab1c252d8b07325" prefix=" " category="inline-code"></block> dopo aver aggiunto la voce della casella di destinazione nei file hosts, l'utente/gruppo non esiste nel sistema di destinazione.</block>
  <block id="4a909d1b3a171fdcddc8da070e839ecc" category="list-text">Utilizzare<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> Per migrare i dati CIFS con ACL (con o senza la cartella root).</block>
  <block id="a4ebb620bc1fbff4f93249967cd47f4b" category="paragraph">Senza la cartella root, eseguire i seguenti comandi:</block>
  <block id="f6c1a65a9150853333bf43b4a6dc9e5b" category="paragraph">Con la cartella root, eseguire i seguenti comandi:</block>
  <block id="154ef40d43f003733406aef6be0ada62" category="inline-link-macro">Segue: Linee guida e consigli sulle Best practice.</block>
  <block id="7fd167e59284838d9e36c5c99e4d2943" category="paragraph"><block ref="7fd167e59284838d9e36c5c99e4d2943" category="inline-link-macro-rx"></block></block>
  <block id="7ed4381f9a10813d06ebeaf5c947c2c1" category="summary">La GUI di analisi dei file XCP di NetApp consente di eseguire scansioni del file system utilizzando XCP nel back-end e visualizzando statistiche come grafici e viste per qualsiasi file system NAS (NFS, SMB).</block>
  <block id="250a5d043009990eb69a399d7c630462" category="doc">Analisi dei file</block>
  <block id="47461303c8b8cbeb3e7558e2a9a1ca70" category="inline-link-macro">Precedente: Workflow di migrazione.</block>
  <block id="685a7e894721315c196897b76f95b8ce" category="paragraph"><block ref="685a7e894721315c196897b76f95b8ce" category="inline-link-macro-rx"></block></block>
  <block id="0f2604fbc18e6e91ba050460e6557361" category="paragraph">La GUI di analisi dei file XCP di NetApp consente di eseguire scansioni del file system utilizzando XCP nel back-end e visualizzando statistiche come grafici e viste per qualsiasi file system NAS (NFS, SMB). A partire dal 1.6, XCP può essere eseguito come servizio con l'aiuto di semplici fasi di implementazione utilizzando le opzioni Configure e systemctl. L'opzione di configurazione di XCP consente di installare e configurare Postgres e un server Web, nonché di raccogliere le credenziali. L'opzione systemctl esegue XCP come servizio per le comunicazioni API REST dalla GUI.</block>
  <block id="914cb171c700c273306e8265b56f4973" category="paragraph">La figura seguente illustra il flusso di analisi dei file XCP.</block>
  <block id="538e51b99e800ab65e133b5d57b2dc7f" category="paragraph"><block ref="538e51b99e800ab65e133b5d57b2dc7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9bcdbf2b32a87f7efd13f706d43954d5" category="inline-link">NetApp XCP 1.6 offre miglioramenti dell'infrastruttura e dell'analisi dei file aperti</block>
  <block id="46742b2c1e11cf6a3e230ec3da7e6800" category="admonition">Per ulteriori informazioni sull'architettura di alto livello di XCP file analytics, le visualizzazioni di dashboard basate su GUI come la vista delle statistiche e i dettagli della vista della distribuzione dei file, consulta il post del blog<block ref="924a0428223d35821b584a5368c0e3e5" category="inline-link-rx"></block>.</block>
  <block id="21bd6427119f8d9a06a7c5bce95d28ac" category="paragraph">XCP 1.6 dispone di una GUI limitata per i grafici personalizzati. Per creare i grafici richiesti, è possibile utilizzare la CLI per eseguire<block ref="430e727eb7fa4c8fdeb29b396f232465" prefix=" " category="inline-code"></block> comando di scansione con filtri corrispondenti. Vedere gli esempi seguenti.</block>
  <block id="168c81694a3b19988d829a9baeda23fd" category="list-text">Generare un elenco di file modificati oltre un anno utilizzando<block ref="79b37c0e9765296c2ba8efc16a70d15f" prefix=" " category="inline-code"></block> e a.<block ref="af7e4e4bdf56fd6022afd2b0cf443794" prefix=" " category="inline-code"></block> filtrare con lo spazio occupato.</block>
  <block id="de615506a73ca5960be54d36ba7fcd5b" category="list-text">Trova lo spazio utilizzato dai file che hanno più di un anno di vita.</block>
  <block id="d2d1f03d5f19a1229103a85cc9224a61" category="list-text">Trova le dimensioni totali e la visualizzazione grafica dei dati modificati più di un anno fa.</block>
  <block id="d706f3d28ee3e74f9a6829c882169af8" category="paragraph">Il seguente report è un esempio personalizzato di scansione dei file modificati più di un anno fa.</block>
  <block id="4d614048a495643d1c641a86e53b78d3" category="paragraph"><block ref="4d614048a495643d1c641a86e53b78d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59a703e67b19adc4bdb1373c25fbca94" category="inline-link-macro">Avanti: Fasi di implementazione.</block>
  <block id="54e4262e01c029cac8932a431c7e3d3f" category="paragraph"><block ref="54e4262e01c029cac8932a431c7e3d3f" category="inline-link-macro-rx"></block></block>
  <block id="c4e9391c8d60f1f326246cd6b6705492" category="summary">NetApp ha ricevuto una richiesta di ricerca di file duplicati da un singolo volume o da più volumi. NetApp ha fornito la seguente soluzione.</block>
  <block id="2e4e5fbe1f8f460b943ac3ed031c9dcf" category="doc">File duplicati</block>
  <block id="f89d6874c6cf2c5de0dae9564728c7cf" category="inline-link-macro">Precedente: Utilizzo di XCP Data Mover per la migrazione di file di grandi dimensioni.</block>
  <block id="6c8f161effcb72b9425f626e8733146b" category="paragraph"><block ref="6c8f161effcb72b9425f626e8733146b" category="inline-link-macro-rx"></block></block>
  <block id="dc4b36d55f5f1f0af63ed899a010c8f1" category="paragraph">Per un singolo volume, eseguire i seguenti comandi:</block>
  <block id="2d2f31777cf3433071b9bcd33f39279a" category="paragraph">Per più volumi, eseguire i seguenti comandi:</block>
  <block id="fdefb3eaaab41fef36db24700d399ef2" category="inline-link-macro">Successivo: Scansione e copia dei dati specifiche basate sulla data.</block>
  <block id="769f411db097d478d8d10a821946e501" category="paragraph"><block ref="769f411db097d478d8d10a821946e501" category="inline-link-macro-rx"></block></block>
  <block id="3993b517d983222c5b766976180367f0" category="inline-link-macro">Precedente: Dove trovare ulteriori informazioni.</block>
  <block id="24992328317a5b7b3c00507eb27776df" category="paragraph"><block ref="24992328317a5b7b3c00507eb27776df" category="inline-link-macro-rx"></block></block>
  <block id="d4f4c40bd169a262676284f5da7a191a" category="cell">Ottobre 2020</block>
  <block id="5dc302565fd7f552e134618ee18d2be2" category="summary">Questa soluzione si basa su un cliente che deve copiare i dati in base a una data specifica.</block>
  <block id="07f04efd2f421076b9aa06c4fee83be5" category="doc">Scansione e copia dei dati specifici in base alla data</block>
  <block id="7af90e46070dd59c121e31e1525d4af2" category="inline-link-macro">Precedente: File duplicati.</block>
  <block id="7f58802ce1d6245244bb449cd961f0f3" category="paragraph"><block ref="7f58802ce1d6245244bb449cd961f0f3" category="inline-link-macro-rx"></block></block>
  <block id="e0b5216bc931e3e5fd7efb74ad10b1d3" category="paragraph">Questa soluzione si basa su un cliente che deve copiare i dati in base a una data specifica. Verificare i seguenti dettagli:</block>
  <block id="c277b447e2e86b92f26c7dbcf8fecdf2" category="inline-link-macro">Avanti: Creazione di un file CSV da una condivisione SMB/CIFS.</block>
  <block id="7a9653d25343b8ddab24257e57b5be7a" category="paragraph"><block ref="7a9653d25343b8ddab24257e57b5be7a" category="inline-link-macro-rx"></block></block>
  <block id="89bddd14a9f02aeace6d5ffadf25e4f3" category="summary">Questo documento fornisce le linee guida sulle Best practice di NetApp XCP e una soluzione basata su scenari di test. Queste Best practice riguardano il flusso di lavoro di migrazione per il cloud, l'analisi del file system, la risoluzione dei problemi e l'ottimizzazione delle performance di XCP.</block>
  <block id="e7b1326bcbbf0b5513213b2373b5721a" category="doc">TR-4863: Linee guida sulle Best practice per NetApp XCP - Data Mover, migrazione dei file e analisi</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">Karthikeyan Nagalingam, NetApp</block>
  <block id="88d20f11fbf1788b5271fcc5d5297a41" category="paragraph">Questo documento fornisce le linee guida sulle Best practice di NetApp XCP e una soluzione basata su scenari di test. Queste Best practice riguardano il flusso di lavoro di migrazione per il cloud, l'analisi del file system, la risoluzione dei problemi e l'ottimizzazione delle performance di XCP. La sezione relativa allo scenario di test copre i casi di utilizzo dei clienti e i relativi requisiti, la soluzione NetApp che utilizza XCP e i vantaggi per il cliente.</block>
  <block id="842b5068483a5cd5b058644a5d000f1c" category="inline-link-macro">Pagina successiva: NetApp XCP.</block>
  <block id="10dbc4bbbec11552354dca73bcd59c78" category="paragraph"><block ref="10dbc4bbbec11552354dca73bcd59c78" category="inline-link-macro-rx"></block></block>
  <block id="945407c0c602d0c34ead1ebb5427a84b" category="summary">Abbiamo utilizzato NetApp XCP per migrare i dati da GPFS a NFS in modo che le GPU possano elaborare i dati. In genere, l'ai elabora i dati da un file system di rete.</block>
  <block id="1f797a3a419cdffd442fc4b662974908" category="doc">Calcolo dalle performance elevate per NFS ONTAP</block>
  <block id="95160fc4cfa09139af600f92561c7ef9" category="inline-link-macro">Precedente: Data Lake a ONTAP NFS.</block>
  <block id="9d82d327cabd66bd4cccb55cb5ed28ec" category="paragraph"><block ref="9d82d327cabd66bd4cccb55cb5ed28ec" category="inline-link-macro-rx"></block></block>
  <block id="a4a4d9553ba807d3f28f8f25ea56cfec" category="paragraph">Questo caso di utilizzo si basa sulle richieste delle organizzazioni sul campo. Alcuni clienti NetApp dispongono dei propri dati in un ambiente di calcolo dalle performance elevate, che fornisce analisi dei dati per i modelli di training e consente alle organizzazioni di ricerca di acquisire informazioni e comprendere una grande quantità di dati digitali. I tecnici sul campo di NetApp hanno bisogno di una procedura dettagliata per estrarre i dati dalla GPFS di IBM a NFS. Abbiamo utilizzato NetApp XCP per migrare i dati da GPFS a NFS in modo che le GPU possano elaborare i dati. In genere, l'ai elabora i dati da un file system di rete.</block>
  <block id="0ce008ed1a75e69e9f21d1ad29ed23dd" category="paragraph">Per ulteriori informazioni sul caso d'utilizzo del software High Performance Computing to ONTAP NFS, su una demo registrata e sui risultati dei test, consulta la<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> blog.</block>
  <block id="fb64727a5df67d0ceff6f0a11b531ab5" category="paragraph">Per informazioni dettagliate sullo spostamento dei dati MapR-FS in NFS ONTAP utilizzando NetApp XCP, consultare l'Appendice A: GPF in NFS―procedure dettagliate in<block ref="e760c508aca9c545c45aba81e95e5593" category="inline-link-rx"></block>.</block>
  <block id="1b5c563b4edac6a7e8566fac62f90b34" category="inline-link-macro">Successivo: Utilizzo di XCP Data Mover per migrare milioni di file di piccole dimensioni in uno storage flessibile.</block>
  <block id="0461d449643091f3bbb27cfbb215c6f2" category="paragraph"><block ref="0461d449643091f3bbb27cfbb215c6f2" category="inline-link-macro-rx"></block></block>
  <block id="7e9f968a139a25a62b6f7f581469c718" category="doc">Documentazione aggiuntiva</block>
  <block id="8887a9a417a1629326acdb917d224337" category="inline-link-macro">VMware vSphere</block>
  <block id="8b35ba920859760c3b7ab07c1f52df88" category="inline-link-macro">Documentazione sul prodotto della piattaforma container OpenShift</block>
  <block id="010bce66eda52af8597098e33d12e767" category="inline-link-macro">Installazione dei cluster di piattaforme container OpenShift</block>
  <block id="9e4f27bab2ba4dcc223eabe15d060c22" category="inline-link-macro">Documentazione sui prodotti per la gestione avanzata dei cluster</block>
  <block id="1a28b2dbd24896f9ae4e7ea905e79d07" category="inline-link-macro">Creazione di un cluster utilizzando ACM</block>
  <block id="88c39d9e07dd53d7dfe71bcc634dd892" category="inline-link-macro">Implementazione di Red Hat Quay su OpenShift</block>
  <block id="086e6c16e3fe8e13c336612ef636aa02" category="inline-link-macro">Astra Trident</block>
  <block id="9c634046a90a62883b122e76b9afcef2" category="inline-link-macro">Centro di controllo Astra</block>
  <block id="35b46e301702b6fcb16192f9f4cf4533" category="inline-link-macro">Servizio di controllo Astra</block>
  <block id="8c9552895e8b32d168c001c8cb0d41ac" category="inline-link-macro">Verda di NetApp</block>
  <block id="1273c8a63109161e6fd1f18d6998523f" category="inline-link-macro">NetApp BlueXP</block>
  <block id="d2154db2b88b25388e0f4a7a9080bfc9" category="inline-link-macro">Red Hat OpenShift Service su AWS</block>
  <block id="4d82a1ec1af02725042c8c785564ee7a" category="inline-link-macro">Amazon FSX per NetApp ONTAP</block>
  <block id="7c8fb58ea0c05ae5b636414d192fab49" category="paragraph">Di seguito sono riportati alcuni documenti aggiuntivi da utilizzare come riferimento: 1. <block ref="299437d2dfff10029aa68548910ed14a" category="inline-link-macro-rx"></block>2. <block ref="7113f7690b69458a12c8968b2e7b5c94" category="inline-link-macro-rx"></block>3. <block ref="bf8803e28a55e6b11cf02bdf9ab03853" category="inline-link-macro-rx"></block>4. <block ref="0de84e35816fe2bf24a2d62358c71ec0" category="inline-link-macro-rx"></block>5. <block ref="c17964cf4aee883c1f79b2b18d5cf8c5" category="inline-link-macro-rx"></block>6. <block ref="c4a315706dd2011b5383e54e9b2917d4" category="inline-link-macro-rx"></block>7. <block ref="e1b08234af7069664eedc35420a1cc41" category="inline-link-macro-rx"></block>8. <block ref="97e9aa45cc61b723d7185c3008313d78" category="inline-link-macro-rx"></block>9. <block ref="ac3186bd76a04d061f68b4574a7220d5" category="inline-link-macro-rx"></block>10. <block ref="2f4df966d6adc25fd002d42aba0522c1" category="inline-link-macro-rx"></block>11. <block ref="c2f5b2c54b56c4b456371849b6825da6" category="inline-link-macro-rx"></block> Verda (Open source) dispone di una raccolta di hook di esecuzione di riferimento per le applicazioni native ad uso intensivo di dati più diffuse nel cloud 12. <block ref="b0fea8555edb70fb5a01c464b6a09cbb" category="inline-link-macro-rx"></block>13. <block ref="ca0553647614febb5dfa86b86874cf2f" category="inline-link-macro-rx"></block>14. <block ref="c869624abab2a4d09eb6e20d1fe18e5e" category="inline-link-macro-rx"></block></block>
  <block id="fb01274428608cf188d499747738ea90" category="doc">Soluzioni NetApp ibride multicloud per i carichi di lavoro dei container Red Hat OpenShift</block>
  <block id="8de8322672190a0154e15dd15a2de38b" category="paragraph">NetApp sta assistendo a un significativo aumento dei clienti nella modernizzazione delle applicazioni aziendali legacy e nella creazione di nuove applicazioni utilizzando container e piattaforme di orchestrazione basate su Kubernetes. Red Hat OpenShift Container Platform è un esempio che vediamo adottato da molti dei nostri clienti.</block>
  <block id="91971d724db8a4834abc9e257cf521ab" category="paragraph">Man mano che un numero sempre maggiore di clienti inizia ad adottare container all'interno delle proprie aziende, NetApp si trova nella posizione ideale per soddisfare le esigenze di storage persistenti delle proprie applicazioni stateful e le esigenze di gestione dei dati classiche, come protezione dei dati, sicurezza dei dati e migrazione dei dati. Tuttavia, queste esigenze vengono soddisfatte utilizzando strategie, strumenti e metodi diversi.</block>
  <block id="46b942b569445b51bc9a3813940e581b" category="paragraph">**Le opzioni di storage basate su NetApp ONTAP** elencate di seguito offrono sicurezza, protezione dei dati, affidabilità e flessibilità per le implementazioni di container e Kubernetes.</block>
  <block id="d8b17b6efcac44f3002f0754abe68b9a" category="list-text">Storage autogestita on-premise:</block>
  <block id="fc86d68de50b558bf0e36b38845f3b9e" category="list-text">NetApp Fabric Attached Storage (FAS), NetApp All Flash FAS Array (AFF), NetApp All SAN Array (ASA) e ONTAP Select</block>
  <block id="427332fc886acd822d0fc6c0ee1a74f8" category="list-text">Storage gestito dal provider on-premise:</block>
  <block id="bce509449eda5b3850faf5d2f827807a" category="list-text">NetApp Keystone offre storage as a service (STaaS)</block>
  <block id="3e828a47721931842418753fbd6ce4a9" category="list-text">Storage autogestita nel cloud:</block>
  <block id="9e41a33f3c647aba754b638fb834ccb6" category="list-text">NetApp Cloud Volumes ONTAP (CVO) offre storage autogestiti negli hyperscaler</block>
  <block id="23c3c663b762f1321d6375c1b3ce61f8" category="list-text">Storage gestito dal provider nel cloud:</block>
  <block id="51420fda4b100ff1cec3007a9f85615d" category="list-text">Cloud Volumes Service per Google Cloud (CVS), Azure NetApp Files (ANF) e Amazon FSX per NetApp ONTAP offrono storage completamente gestito negli hyperscaler</block>
  <block id="7737d05ae0cdd6b2fbe4cd4e6c7b3873" category="paragraph"><block ref="7737d05ae0cdd6b2fbe4cd4e6c7b3873" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3fffb84816afb046037dcf3d52d23a4" category="paragraph">**NetApp BlueXP** consente di gestire tutte le risorse di storage e dati da un singolo piano di controllo/interfaccia.</block>
  <block id="a28e6578744ceeb545878235d414e497" category="paragraph">È possibile utilizzare BlueXP per creare e amministrare lo storage cloud (ad esempio, Cloud Volumes ONTAP e Azure NetApp Files), per spostare, proteggere e analizzare i dati e per controllare molti dispositivi storage on-premise e edge.</block>
  <block id="ccc05eb250d1954656f9e96b38186f1f" category="paragraph">**NetApp Astra Trident** è un orchestratore di storage conforme a CSI che consente un consumo rapido e semplice dello storage persistente supportato da una serie di opzioni di storage NetApp sopra menzionate. Si tratta di un software open-source gestito e supportato da NetApp.</block>
  <block id="4f1e9419dd2093869735a950da6bb17d" category="paragraph"><block ref="4f1e9419dd2093869735a950da6bb17d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5c4a3945e0cdaa7b705b00128180df4" category="paragraph">I carichi di lavoro dei container business-critical richiedono molto di più dei semplici volumi persistenti. I loro requisiti di gestione dei dati richiedono anche la protezione e la migrazione degli oggetti di kubernetes dell'applicazione.</block>
  <block id="e57b3f1bdaee7a2b21647555142e9653" category="admonition">I dati dell'applicazione includono oggetti kubernetes oltre ai dati dell'utente: Alcuni esempi sono i seguenti: - Kubernetes oggetti come specifiche di pod, PVC, implementazioni, servizi - oggetti di configurazione personalizzati come mappe di configurazione e segreti - dati persistenti come copie Snapshot, backup, cloni - risorse personalizzate come CRS e CRD</block>
  <block id="4b675e54aa1095b2b20f8c4019de37b0" category="inline-link-macro">Documentazione Astra</block>
  <block id="dadb28b9e22a0754b9d16e0e88a88c13" category="paragraph">**NetApp Astra Control**, disponibile sia come software completamente gestito che autogestita, offre un'orchestrazione per una solida gestione dei dati applicativi. Fare riferimento a. <block ref="40f1af172b66f2d17da6144d50df0f84" category="inline-link-macro-rx"></block> Per ulteriori informazioni sulla famiglia di prodotti Astra.</block>
  <block id="f15a63879d079401ef5fb8794ae8190d" category="paragraph">Questa documentazione di riferimento fornisce la convalida della migrazione e della protezione delle applicazioni basate su container, implementate sulla piattaforma container RedHat OpenShift, utilizzando NetApp Astra Control Center. Inoltre, la soluzione fornisce dettagli di alto livello per l'implementazione e l'utilizzo di Red Hat Advanced Cluster Management (ACM) per la gestione delle piattaforme container. Il documento evidenzia inoltre i dettagli per l'integrazione dello storage NetApp con le piattaforme container Red Hat OpenShift che utilizzano Astra Trident CSI Provisioner. Astra Control Center viene implementato nel cluster dell'hub e viene utilizzato per gestire le applicazioni container e il loro ciclo di vita dello storage persistente. Infine, offre una soluzione per la replica, il failover e il fail-back per i carichi di lavoro dei container su cluster Red Hat OpenShift gestiti in AWS (ROSA) utilizzando Amazon FSX per NetApp ONTAP (FSxN) come storage persistente.</block>
  <block id="bd61a264427ea5719a7598c9842bbdfc" category="summary">Le soluzioni NetApp ibride multicloud con la piattaforma container Red Hat OpenShift sono un insieme di funzionalità tecnologiche e strategiche che dimostrano la facilità di orchestrare le funzionalità di migrazione e protezione dei dati per i carichi di lavoro stateful container on-premise e nel cloud pubblico.</block>
  <block id="05a4585adb3c11a4d6ec744287d9c477" category="doc">Multicloud ibrido NetApp con carichi di lavoro container Red Hat OpenShift</block>
  <block id="a52f1a39d266680457efce511e919b88" category="doc">Versioni dei vari componenti utilizzati nella convalida della soluzione</block>
  <block id="5516d7182615c828448d9b348501eb1e" category="paragraph">La soluzione testa e convalida la migrazione e la protezione centralizzata dei dati con la piattaforma container OpenShift, l'Advanced Cluster Manager OpenShift, NetApp ONTAP e il centro di controllo NetApp Astra.</block>
  <block id="43f2468407fd92c3a33738017e3d08fb" category="paragraph">Diversi scenari della soluzione sono stati convalidati utilizzando le versioni indicate nella tabella seguente:</block>
  <block id="b4244340f0935c1a99a9f6b1a5c587ed" category="cell">*Componente*</block>
  <block id="45cc01ab5f209e8760027e9c30097025" category="cell">*Versione*</block>
  <block id="26ec1d0c63ce9794e6d0c6b5a70689a1" category="cell">*VMware*</block>
  <block id="9b458d345f0a59c6e2e7426349b2c81a" category="cell">VSphere Client versione 8.0.0.10200 VMware ESXi, 8.0.0, 20842819</block>
  <block id="02693cb8abf2b367ad7f12a7028387d0" category="cell">*Cluster hub*</block>
  <block id="d47e05659d8c9961d0025578f9bedf81" category="cell">OpenShift 4.11.34</block>
  <block id="6f63ca7a8d1582f6c5aecf3d98e15fea" category="cell">*Clusters di origine e destinazione*</block>
  <block id="e777190715e6ef3eedd09080d17156dc" category="cell">OpenShift 4.12.9 on-premise e in AWS</block>
  <block id="2740a3f02c7241398a3bd90d72be7a23" category="cell">*NetApp Astra Trident*</block>
  <block id="52bed1949aec792e351725583d586e38" category="cell">Trident Server e Client 23.04.0</block>
  <block id="9dbea4b6bf9a3c7db93960270b06cf21" category="cell">*NetApp Astra Control Center*</block>
  <block id="2bc5b4067c51b6d01052f2895cd2802f" category="cell">ACC 22.11.0-82</block>
  <block id="ac0df33e7e9d7127f5798ad2f7ea1e57" category="cell">*NetApp ONTAP*</block>
  <block id="594e1ec3daa27e540baa061f731f028f" category="cell">ONTAP 9.12.1</block>
  <block id="dc590521b479337b3c16fdc9b86fa862" category="cell">*AWS FSX per NetApp ONTAP*</block>
  <block id="725b1ab4e3e24634a0c63fe0aacf72c9" category="cell">AZ. Singola</block>
  <block id="602738666fc517b0fa1a28acbaa8753f" category="doc">Proposte a valore delle soluzioni NetApp ibride multicloud per i carichi di lavoro dei container Red Hat OpenShift</block>
  <block id="4995f10735f80116c1a9e76d0483dea0" category="paragraph">La maggior parte dei clienti non inizia a costruire ambienti basati su Kubernetes senza alcuna infrastruttura esistente. Forse si tratta di un negozio IT tradizionale che esegue la maggior parte delle applicazioni aziendali su macchine virtuali (ad esempio in ambienti VMware di grandi dimensioni). Quindi, iniziano a creare piccoli ambienti basati su container per soddisfare le esigenze dei moderni team di sviluppo delle applicazioni. Queste iniziative di solito iniziano a poco e iniziano a diventare più pervasive man mano che i team imparano queste nuove tecnologie e competenze, e iniziano a riconoscere i numerosi benefici derivanti dall'adozione di queste tecnologie. La buona notizia per i clienti è che NetApp può soddisfare le esigenze di entrambi gli ambienti. Questo set di soluzioni per il multicloud ibrido con Red Hat OpenShift consentirà ai clienti NetApp di adottare tecnologie e servizi cloud moderni senza dover rivedere l'intera infrastruttura e organizzazione. Sia che le applicazioni e i dati dei clienti siano ospitati on-premise, nel cloud, eseguiti su macchine virtuali o su container, NetApp è in grado di fornire gestione, protezione, sicurezza e portabilità dei dati coerenti. Con queste nuove soluzioni, lo stesso valore offerto da NetApp in ambienti di data center on-premise per decenni sarà disponibile nell'intero orizzonte dei dati dell'azienda, senza richiedere investimenti significativi per il ritool, l'acquisizione di nuove competenze o la creazione di nuovi team. NetApp è in grado di aiutare i clienti a risolvere queste sfide aziendali indipendentemente dalla fase del loro percorso cloud.</block>
  <block id="d22e1212d6861bd9f5154f99bd42f075" category="paragraph">Multi-cloud ibrido NetApp con Red Hat OpenShift:</block>
  <block id="f4a12877ded47f570208ae2fd2860bd6" category="list-text">Offre ai clienti design e pratiche validati che dimostrano i modi migliori per gestire, proteggere, proteggere e migrare i dati e le applicazioni quando utilizzano Red Hat OpenShift con le soluzioni di storage basate su NetApp.</block>
  <block id="67eaac350e7deee0d9da0da55965c85d" category="list-text">Presentare le Best practice per i clienti che utilizzano Red Hat OpenShift con lo storage NetApp in ambienti VMware, infrastruttura bare metal o una combinazione di entrambi.</block>
  <block id="069709db14b900262db621bbd5187e74" category="list-text">Dimostra strategie e opzioni per ambienti sia on-premise che cloud, nonché per ambienti ibridi in cui vengono utilizzati entrambi.</block>
  <block id="6f83ad56268110343d9aef0022b7f493" category="doc">Soluzioni supportate di NetApp Hybrid Multibloud per i carichi di lavoro dei container Red Hat OpenShift</block>
  <block id="e0484d0d50bc76897c6ed88afa8d69bf" category="paragraph">La soluzione verifica e convalida la migrazione e la protezione centralizzata dei dati con la piattaforma container OpenShift, l'Advanced Cluster Manager (ACM) OpenShift, NetApp ONTAP, NetApp BlueXP e il centro di controllo NetApp Astra (ACC).</block>
  <block id="0196288da3234f0b3a984fb859dbbe2e" category="paragraph">Per questa soluzione, i seguenti scenari sono testati e validati da NetApp. La soluzione è suddivisa in più scenari in base alle seguenti caratteristiche:</block>
  <block id="97a114682aee9996b96ccab927de04d7" category="list-text">on-premise</block>
  <block id="a1234b3161b4fbfdfb96dd576b65bbea" category="list-text">cloud</block>
  <block id="fc5b68fff5369eab614cea8a097a9da3" category="list-text">Cluster OpenShift autogestiti e storage NetApp autogestiti</block>
  <block id="6192817a2c883017154233f79143b526" category="list-text">Cluster OpenShift gestiti dal provider e storage NetApp gestito dal provider</block>
  <block id="346cce4487319e1b8f55333f07a7bfe6" category="paragraph">**In futuro verranno sviluppate soluzioni e casi di utilizzo aggiuntivi.**</block>
  <block id="642056fd59cfcf2e5c6ac845b30f8a89" category="section-title">Scenario 1: Protezione dei dati e migrazione all'interno dell'ambiente on-premise con ACC</block>
  <block id="e750828e5900c9e9e0080da69c59deee" category="paragraph">**On-premise: Cluster OpenShift autogestiti e storage NetApp autogestiti**</block>
  <block id="c0eaf6c42fe00cd346ed6b6e3840a87b" category="list-text">Utilizzando ACC, è possibile creare copie Snapshot, backup e ripristini per la protezione dei dati.</block>
  <block id="5bbe9f387a62f7e6da1a3479bae84aaf" category="list-text">Utilizzando ACC, eseguire una replica SnapMirror delle applicazioni container.</block>
  <block id="d42e8fbcf79f7de1303918aafa7d9fa7" category="section-title">Scenario 1</block>
  <block id="f0489d547da7e6c7860d78bc0e76b3fc" category="paragraph"><block ref="f0489d547da7e6c7860d78bc0e76b3fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba74a99f1a17bbc4323f970e92f65267" category="section-title">Scenario 2: Protezione dei dati e migrazione dall'ambiente on-premise all'ambiente AWS utilizzando ACC:</block>
  <block id="011c4a5ba5680b65be39323642e0c6e5" category="paragraph">**On-premise: Cluster OpenShift autogestiti e storage autogestiti** **AWS Cloud: Cluster OpenShift autogestiti e storage autogestiti**</block>
  <block id="6c440a8e8c4732064f0a2fe22d438916" category="list-text">Utilizzando ACC, eseguire backup e ripristini per la protezione dei dati.</block>
  <block id="3d2b891e87f58587dcf56e520915afef" category="section-title">Scenario 2</block>
  <block id="cb4581e6ea0741c82604502d38c43995" category="paragraph"><block ref="cb4581e6ea0741c82604502d38c43995" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73d95ebf5e02ecba9346225b7c750d96" category="section-title">Scenario 3: Protezione dei dati e migrazione dall'ambiente on-premise all'ambiente AWS:</block>
  <block id="02626a2e6e765a5df4816a825234dc2e" category="paragraph">**On-premise: Cluster OpenShift e storage autogestito** **AWS Cloud: Cluster OpenShift gestito dal provider (ROSA) e storage gestito dal provider (FSxN)**</block>
  <block id="5c1c8d2602eef78d62342564281ce1e2" category="list-text">Utilizzando BlueXP, eseguire la replica dei volumi persistenti (FSxN).</block>
  <block id="87536fdb761ec9bd49af92d0cf39f302" category="list-text">Utilizzando OpenShift GitOps, ricreare i metadati dell'applicazione.</block>
  <block id="c2447154da8ea0e9f40104cfe84c986a" category="section-title">Scenario 3</block>
  <block id="d50912075fbd317709a0c7722c0c765e" category="paragraph"><block ref="d50912075fbd317709a0c7722c0c765e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1522c369fc33aa74294fbd0cd08a1b03" category="paragraph">Per considerazioni sull'utilizzo di ONTAP in una configurazione MetroCluster, fare riferimento a. <block ref="5b6304ea4373a975ac8b2f8302d3d44b" category="inline-link-macro-rx"></block>.</block>
  <block id="16ef23462b663a9c6034549a75db04f2" category="doc">Integrazioni di storage NetApp supportate con Red Hat Open Shift Containers</block>
  <block id="46d3c033f73d0ee2be1fd01fd7b3bc9b" category="paragraph">Sia che i container Red Hat Open Shift siano in esecuzione su VMware o negli hyperscaler, NetApp Astra Trident può essere utilizzato come provider CSI per i vari tipi di storage NetApp di back-end supportati.</block>
  <block id="b9f60c4d5e949aec928443832fd0f567" category="paragraph">Il seguente diagramma illustra i vari storage NetApp di back-end che possono essere integrati con i cluster OpenShift utilizzando NetApp Astra Trident.</block>
  <block id="d115671a64afa53f0714cdf802de2a28" category="paragraph"><block ref="d115671a64afa53f0714cdf802de2a28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c57009523536c8cf1126736d023db8fd" category="paragraph">La macchina virtuale per lo storage ONTAP (SVM) offre una multi-tenancy sicura. Un singolo cluster OpenShift può connettersi a una singola SVM o a più SVM o persino a più cluster ONTAP. La classe di storage filtra lo storage back-end in base ai parametri o alle etichette. Gli amministratori dello storage definiscono i parametri per la connessione al sistema di storage utilizzando la configurazione backend trident. Una volta stabilita la connessione, crea il backend trident e popola le informazioni che la classe di storage può filtrare.</block>
  <block id="f7a2c532baf0284a5077caf9cad8791a" category="paragraph">Di seguito viene illustrata la relazione tra lo storageclass e il backend.</block>
  <block id="efe36ae733078bbe9a7d4971388b61df" category="inline-image-macro">Relazione tra classe di storage e ONTAP</block>
  <block id="0442e65b325d60f7fc9c602b320dd58c" category="paragraph"><block ref="0442e65b325d60f7fc9c602b320dd58c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90b82350db9212bd4d0c57a640d19232" category="paragraph">Il proprietario dell'applicazione richiede un volume persistente utilizzando la classe di storage. La classe di storage filtra lo storage back-end. Di seguito viene illustrata la relazione tra il pod e lo storage back-end.</block>
  <block id="a0f5fccacb6f4513b350db2e44d0a52f" category="inline-image-macro">Relazione tra pod e volume ONTAP</block>
  <block id="d9c6f609f7c707469f70a6b148f408a7" category="paragraph"><block ref="d9c6f609f7c707469f70a6b148f408a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e8c8ed944bd179a7ed5014748fb31de" category="section-title">Opzioni CSI (Container Storage Interface)</block>
  <block id="b79382adbee98b6603cb4ac95885af9e" category="paragraph">Negli ambienti vSphere, i clienti possono scegliere il driver VMware CSI e/o Astra Trident CSI da integrare con ONTAP. Con VMware CSI, i volumi persistenti vengono consumati come dischi SCSI locali, mentre con Trident viene consumato con la rete. Poiché VMware CSI non supporta le modalità di accesso RWX con ONTAP, le applicazioni devono utilizzare Trident CSI se è richiesta la modalità RWX. Con le implementazioni basate su FC, VMware CSI è la soluzione preferita e SnapMirror Business Continuity (SMBC) offre disponibilità elevata a livello di zona.</block>
  <block id="d2cba3ef557d6500cd0420d9bb36a4c7" category="section-title">Supporto di VMware CSI</block>
  <block id="216cd0f470eb203964b09af554b2f66c" category="list-text">Datastore basati su core block (FC, FCoE, iSCSI, NVMeoF)</block>
  <block id="dc64cd64093452f4efadcc36b20344a3" category="list-text">Archivi dati basati su file di base (NFS v3, v4)</block>
  <block id="1d89948bfc7a49c7c24ea6c174ba238a" category="list-text">Datastore vVol (blocco e file)</block>
  <block id="f4d669ddd2fadaee50bf3d976dc303fc" category="section-title">Trident ha i seguenti driver per supportare ONTAP</block>
  <block id="d34166b81b6a41af7f7e68ab1a706647" category="list-text">ontap-san (volume dedicato)</block>
  <block id="51f8b538584089b7767162debcf8e4b8" category="list-text">ontap-san-economy (volume condiviso)</block>
  <block id="0a8ce2b6a8e563cf981d283355ab4fec" category="list-text">ontap-nas (volume dedicato)</block>
  <block id="d3fb6fce8725812eb61f50ddb9a7d2d2" category="list-text">ontap-nas-economy (volume condiviso)</block>
  <block id="715a2804377bea12c12d2dfc86a3dcfc" category="list-text">ontap-nas-flexgroup (volume dedicato su larga scala)</block>
  <block id="3d8c841d5d9cfab6bcaea8932fb26d33" category="paragraph">Per VMware CSI e Astra Trident CSI, ONTAP supporta nconnect, trunking di sessione, kerberos, ecc. per NFS e multipathing, autenticazione chap, ecc. per i protocolli a blocchi.</block>
  <block id="86c5dadebaa1ddb48e303ff25ad2a146" category="inline-link-macro">Linee guida per le performance di AWS</block>
  <block id="7a6f37e13b28950f3e673e6ba257a242" category="paragraph">In AWS, FSX per NetApp ONTAP (FSxN) può essere implementato in una singola zona di disponibilità (AZ) o in più AZ. Per i carichi di lavoro di produzione che richiedono alta disponibilità, multi-AZ offre tolleranza di errore a livello zonale e una cache di lettura NVMe migliore rispetto a AZ singolo. Per ulteriori informazioni, consultare <block ref="e4c9b635745c064746324939979ac3ba" category="inline-link-macro-rx"></block>. Per risparmiare sui costi del sito di disaster recovery, è possibile utilizzare un singolo ONTAP AZ FSX.</block>
  <block id="8e9cfb71a7e863c2f209d5480941fd78" category="inline-image-macro">Replica tra Multi-AZ e Single-AZ</block>
  <block id="d945e872f3d86016e69cb70542c0cc6a" category="paragraph"><block ref="d945e872f3d86016e69cb70542c0cc6a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="935ca08bdd64725cdd1088c0fb91776b" category="inline-link-macro">Gestione della macchina virtuale per lo storage FSX ONTAP</block>
  <block id="0aa0b6b72c2288a10c437f6fd4b333b9" category="paragraph">Per il numero di SVM supportati da FSX ONTAP, fare riferimento a. <block ref="0a6e802412081ec42f8b1e7e94aea7a2" category="inline-link-macro-rx"></block></block>
  <block id="8ac66023d6d64852e30505c1e8d60986" category="doc">Soluzione NetApp con workload gestiti della piattaforma container Red Hat OpenShift su AWS</block>
  <block id="242d6ccbbd71ec647ddb86909c24827d" category="paragraph">I clienti possono "nascere nel cloud" o trovarsi in un punto del loro percorso di modernizzazione quando sono pronti a spostare alcuni carichi di lavoro selezionati o tutti i carichi di lavoro dai data center al cloud. Possono scegliere di utilizzare container OpenShift gestiti da provider e storage NetApp gestito da provider nel cloud per l'esecuzione dei carichi di lavoro. Devono pianificare e implementare i cluster di container gestiti Red Hat OpenShift (ROSA) nel cloud per un ambiente pronto per la produzione di successo per i carichi di lavoro dei container. Quando si trovano nel cloud AWS, potrebbero anche implementare FSX per NetApp ONTAP per le esigenze di storage.</block>
  <block id="51affed0f08c3d6d7d172db839089ac6" category="paragraph">FSX per NetApp ONTAP offre protezione dei dati, affidabilità e flessibilità per le implementazioni di container in AWS. Astra Trident funge da provider di storage dinamico per consumare lo storage FSxN persistente per le applicazioni stateful dei clienti.</block>
  <block id="16b422dedaa305f1e883d55d28f2d211" category="paragraph">Poiché ROSA può essere implementato in modalità ha con nodi del piano di controllo distribuiti in più zone di disponibilità, FSX ONTAP può anche essere fornito con l'opzione Multi-AZ che fornisce alta disponibilità e protegge dai guasti AZ.</block>
  <block id="aac86419bd7742807d0b65436a4fdcf2" category="admonition">Non sono previsti costi per il trasferimento dei dati quando si accede a un file system Amazon FSX dalla zona di disponibilità preferita (AZ) del file system. Per ulteriori informazioni sui prezzi, fare riferimento a. <block ref="2d4b4b449ef448fbb3000f58e542f4ee" category="inline-link-macro-rx"></block>.</block>
  <block id="804119dcd90c16f9cbe72822ed4932e7" category="section-title">Soluzione per la migrazione e la protezione dei dati per i carichi di lavoro dei container OpenShift</block>
  <block id="9b2f9698f9a33314b6eb0d86eb8929c9" category="doc">Implementa e configura la piattaforma container Managed Red Hat OpenShift su AWS</block>
  <block id="5887e8ade129892a39138d21f25b97a8" category="paragraph">Questa sezione descrive un workflow di alto livello per la configurazione dei cluster Managed Red Hat OpenShift su AWS(ROSA). Mostra l'utilizzo di FSX gestito per NetApp ONTAP (FSxN) come back-end di storage di Astra Trident per fornire volumi persistenti. Vengono forniti dettagli sull'implementazione di FSxN su AWS utilizzando BlueXP. Inoltre, vengono forniti dettagli sull'utilizzo di BlueXP e OpenShift GitOps (Argo CD) per eseguire attività di migrazione e protezione dei dati per le applicazioni stateful sui cluster ROSA.</block>
  <block id="f8c6204c5d3f0767c18bf3dfb691b015" category="paragraph">Di seguito è riportato un diagramma che illustra i cluster ROSA implementati su AWS e che utilizzano FSxN come storage back-end.</block>
  <block id="538b589a3f0d2786d874e26e9b3b3bee" category="inline-link-macro">sezione risorse</block>
  <block id="7429532c11d9b70502be86adcd09ecfc" category="admonition">Questa soluzione è stata verificata utilizzando due cluster ROSA in due VPC in AWS. Ogni cluster ROSA è stato integrato con FSxN utilizzando Astra Trident. Esistono diversi modi per implementare I cluster ROSA e FSxN in AWS. Questa descrizione di alto livello dell'installazione fornisce collegamenti alla documentazione per il metodo specifico utilizzato. È possibile fare riferimento agli altri metodi nei relativi collegamenti forniti in <block ref="ec30323d5c1ba24d6aabb0b3df901fd1" category="inline-link-macro-rx"></block>.</block>
  <block id="d6d7fade0a5d1cd7723c64125e595b08" category="paragraph">Il processo di installazione può essere suddiviso nei seguenti passaggi:</block>
  <block id="776e644936fa311303e288b8df968fc8" category="example-title">Installare I cluster ROSA</block>
  <block id="b3e83e12e2309b03bb799e34f55ac838" category="list-text">Creare due VPC e configurare la connettività di peering VPC tra i VPC.</block>
  <block id="8d550961a2333f8c7184c49f43b11441" category="list-text">Fare riferimento a. <block ref="703596d786038115126420be8929a2a3" category="inline-link-macro-rx"></block> Per istruzioni sull'installazione dei cluster ROSA.</block>
  <block id="6248f27e630f632c6a0b111e3a22f0c7" category="example-title">Installare FSxN</block>
  <block id="f378af26f16afdc1dc513c07113ad747" category="list-text">Installare FSxN sui VPC da BlueXP. Fare riferimento a. <block ref="34abba7bef53102fd63639b9b9679762" category="inline-link-macro-rx"></block> Per la creazione di un account BlueXP e per iniziare. Fare riferimento a. <block ref="2295d3162905f9dd45d3ca6c8a209ad1" category="inline-link-macro-rx"></block> Per l'installazione di FSxN. Fare riferimento a. <block ref="34abba7bef53102fd63639b9b9679762" category="inline-link-macro-rx"></block> Per creare un connettore in AWS per gestire FSxN.</block>
  <block id="f346bc83ad170b8604a8f8d59eb15587" category="list-text">Implementare FSxN utilizzando AWS. Fare riferimento a. <block ref="96729d098c0f6096edb6c44f431ce934" category="inline-link-macro-rx"></block> Per l'implementazione utilizzando la console AWS.</block>
  <block id="f8f96d37b9a3120cb1bb4a037d8195bd" category="example-title">Installare Trident sui cluster ROSA (utilizzando il grafico Helm)</block>
  <block id="7564d67237d9db6138e99e2acdb8a0cf" category="list-text">USA il grafico Helm per installare Trident sui cluster ROSA. url del grafico Helm:<block ref="dc0bfce78007eb90bab021eec0605ecf" category="inline-link-rx"></block></block>
  <block id="d9d7e23123aa2f2b6b36f2538c7079da" category="admonition">OpenShift GitOps può essere utilizzato per implementare Astra Trident CSI su tutti i cluster gestiti, man mano che vengono registrati su ArgoCD utilizzando ApplicationSet.</block>
  <block id="d77de958b0e511ac432517a88ccba762" category="paragraph"><block ref="d77de958b0e511ac432517a88ccba762" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b98c9ae66bee7ebb9143fb1f97c635a" category="example-title">Creare classi di storage e backend utilizzando Trident (per FSxN)</block>
  <block id="3dda1221f6e371517cb4fad0b6f46878" category="list-text">Fare riferimento a. <block ref="9086b317542fa4fec3c7a94ae13e221d" category="inline-link-macro-rx"></block> per informazioni dettagliate sulla creazione di classe di storage e backend.</block>
  <block id="a13d721aed664ec4974349a0a4cd1184" category="list-text">Rendere la classe di storage creata per FsxN con Trident CSI come predefinita da OpenShift Console. Vedere la schermata riportata di seguito:</block>
  <block id="ca6d43e36ba3ff60ddddd0b3dc9b39d0" category="paragraph"><block ref="ca6d43e36ba3ff60ddddd0b3dc9b39d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb2978b82e7eef8973a778154ed9d1d8" category="example-title">Implementare un'applicazione utilizzando OpenShift GitOps (CD Argo)</block>
  <block id="28832d59ac5a06d16e97fd07fb21b521" category="list-text">Installare l'operatore OpenShift GitOps sul cluster. Fare riferimento alle istruzioni <block ref="946032aa50bddc23d84d8e7c39ffd30b" category="inline-link-macro-rx"></block>.</block>
  <block id="356be904a2ad4050250d6fe2a3227030" category="list-text">Configurare una nuova istanza del CD Argo per il cluster. Fare riferimento alle istruzioni <block ref="119b4b110537aa2ea9e3e33df43cde60" category="inline-link-macro-rx"></block>.</block>
  <block id="abe8993411729ddd001265652209bf86" category="paragraph">Aprire la console del CD Argo e implementare un'applicazione. Ad esempio, puoi implementare un'applicazione Jenkins utilizzando il CD Argo con Helm Chart. Durante la creazione dell'applicazione, sono stati forniti i seguenti dettagli: Progetto: Cluster predefinito:<block ref="9f21a485a51630661e0fefa38fbbf6ca" category="inline-link-rx"></block>Spazio dei nomi: Jenkins l'URL per il grafico Helm:<block ref="0e94db883459a2938e67dc90b6e8375d" category="inline-link-rx"></block></block>
  <block id="c6900348e4c35229bfdef15cd046933d" category="paragraph">Parametri Helm: Global.storageClass: Fsxn-nas</block>
  <block id="7dd560122213e64b542e95018ff44ab1" category="paragraph">Questa pagina mostra le opzioni di protezione dei dati per Managed Red Hat OpenShift su AWS (ROSA) utilizzando Astra Control Service.</block>
  <block id="cd25a3e993cfcb7dc008e56db66965e0" category="section-title">FSX NetApp ONTAP per il servizio OpenShift di Red Hat su AWS (ROSA)</block>
  <block id="5866b98c049a53ea6dc7f50f9349f434" category="doc">Migrazione dei dati</block>
  <block id="7314163a6d61f383fe22eabc7f7478f4" category="paragraph">Questa pagina mostra le opzioni di migrazione dei dati per i carichi di lavoro container sui cluster gestiti Red Hat OpenShift che utilizzano FSX per NetApp ONTAP per lo storage persistente.</block>
  <block id="82352e8a86338ccc54d2fbc2c403810e" category="paragraph">Il servizio Red Hat OpenShift su AWS e FSX per NetApp ONTAP (FSxN) fanno parte del loro portfolio di servizi di AWS. FSxN è disponibile nelle opzioni AZ singolo o AZ multiplo. L'opzione Multi-Az offre la protezione dei dati dai guasti della zona di disponibilità. FSxN può essere integrato con Astra Trident per fornire storage persistente per le applicazioni sui cluster ROSA.</block>
  <block id="36aedde0793f8012855859992c3f80c7" category="section-title">Integrazione di FSxN con Trident utilizzando Helm Chart</block>
  <block id="529a6fab29dd793a36ea8d9e3d36c756" category="paragraph">La migrazione delle applicazioni container comporta:</block>
  <block id="dc01e4c3cbb8b6d977325df7eebba531" category="list-text">Volumi persistenti: Questa operazione può essere eseguita utilizzando BlueXP. Un'altra opzione consiste nell'utilizzare Astra Control Center per gestire le migrazioni delle applicazioni container dall'ambiente on-premise a quello cloud. L'automazione può essere utilizzata per lo stesso scopo.</block>
  <block id="04a50198afad51829cb74fca31795282" category="list-text">Metadati dell'applicazione: È possibile eseguire questa operazione utilizzando OpenShift GitOps (Argo CD).</block>
  <block id="39078498a020eaae2ab6f60a30c1cd6d" category="section-title">Failover e fail-back delle applicazioni sul cluster ROSA utilizzando FSxN per lo storage persistente</block>
  <block id="0733a4864ff0a27098003f35528fda51" category="doc">Soluzione NetApp con carichi di lavoro della piattaforma container Red Hat OpenShift nel cloud ibrido</block>
  <block id="7f224be1115f0425cbeb3e707e64be2a" category="paragraph">I clienti potrebbero trovarsi in un punto del loro percorso di modernizzazione quando sono pronti a spostare alcuni carichi di lavoro selezionati o tutti i carichi di lavoro dai data center al cloud. Possono scegliere di utilizzare container OpenShift autogestiti e storage NetApp autogestiti nel cloud per diversi motivi. Devono pianificare e implementare la piattaforma container Red Hat OpenShift (OCP) nel cloud per un ambiente pronto per la produzione di successo per la migrazione dei carichi di lavoro dei container dai data center. I loro cluster OCP possono essere implementati su VMware o bare metal nei loro data center e su AWS, Azure o Google Cloud nell'ambiente cloud.</block>
  <block id="dcf5b4626b26141690124b4d983c76d9" category="paragraph">Lo storage NetApp Cloud Volumes ONTAP offre protezione dei dati, affidabilità e flessibilità per le implementazioni di container in AWS, Azure e Google Cloud. Astra Trident funge da provider di storage dinamico per consumare lo storage Cloud Volumes ONTAP persistente per le applicazioni stateful dei clienti. Astra Control Center può essere utilizzato per orchestrare i numerosi requisiti di gestione dei dati delle applicazioni stateful come protezione dei dati, migrazione e business continuity.</block>
  <block id="ea1e0c0a154a2c9c52d9f60007ce5d91" category="section-title">Soluzione per la migrazione e la protezione dei dati per i carichi di lavoro dei container OpenShift in un cloud ibrido con Astra Control Center</block>
  <block id="ef11f1b3f77b7a623cf6c1f337f19810" category="doc">Implementa e configura la piattaforma container Red Hat OpenShift su AWS</block>
  <block id="ab7b4d146c15537b9acf20d97bff117a" category="paragraph">In questa sezione viene descritto un workflow di alto livello che illustra come configurare e gestire i cluster OpenShift in AWS e come implementare applicazioni stateful su di essi. Mostra l'utilizzo dello storage NetApp Cloud Volumes ONTAP con l'aiuto di Astra Trident per fornire volumi persistenti. Vengono forniti dettagli sull'utilizzo di Astra Control Center per eseguire attività di migrazione e protezione dei dati per le applicazioni stateful.</block>
  <block id="e98f4c710f7c9113ed0fca838ffa71f4" category="admonition">Esistono diversi modi per implementare i cluster di piattaforme container Red Hat OpenShift su AWS. Questa descrizione di alto livello dell'installazione fornisce collegamenti alla documentazione per il metodo specifico utilizzato. È possibile fare riferimento agli altri metodi nei relativi collegamenti forniti in <block ref="ec30323d5c1ba24d6aabb0b3df901fd1" category="inline-link-macro-rx"></block>.</block>
  <block id="15e2aee2febe456536514c300a17d5c9" category="paragraph">Di seguito è riportato un diagramma che illustra i cluster implementati su AWS e connessi al data center mediante una VPN.</block>
  <block id="a4763dc99c168c3d5c2cdff5c671fe06" category="example-title">Installare un cluster OCP su AWS da Advanced Cluster Management.</block>
  <block id="23ef950cd8b1e5468c8e76f96c176bf8" category="list-text">Creare un VPC con una connessione VPN sito-sito (utilizzando pfsense) per connettersi alla rete on-premise.</block>
  <block id="5240532c2919e7351934292a18054058" category="list-text">La rete on-premise dispone di connettività Internet.</block>
  <block id="2f9a622f50ad91f20ea33eb464dffed5" category="list-text">Creare 3 subnet private in 3 diversi AZS.</block>
  <block id="3bc0575c716ca54e3e3f3c18896d2073" category="list-text">Creare una zona host privata Route 53 e un resolver DNS per il VPC.</block>
  <block id="78e681da9aa719a4fa341bfefe7241dc" category="paragraph">Creare il cluster OpenShift su AWS dalla procedura guidata Advanced Cluster Management (ACM). Fare riferimento alle istruzioni <block ref="a8dc968cbec7f22006c56d08b612b183" category="inline-link-macro-rx"></block>.</block>
  <block id="308c1e3e719191b8ced2d38fd974ca8e" category="admonition">Puoi anche creare il cluster in AWS dalla console OpenShift Hybrid Cloud. Fare riferimento a. <block ref="2273fb526f12aab77cc8d6457769ac6c" category="inline-link-macro-rx"></block> per istruzioni.</block>
  <block id="fdb3ae874409cbcef80a6d9bfeb5f048" category="admonition">Quando si crea il cluster utilizzando ACM, è possibile personalizzare l'installazione modificando il file yaml dopo aver inserito i dettagli nella vista del modulo. Una volta creato il cluster, è possibile accedere ssh ai nodi del cluster per la risoluzione dei problemi o per un'ulteriore configurazione manuale. Utilizzare la chiave ssh fornita durante l'installazione e il nome utente principale per effettuare il login.</block>
  <block id="09896a8f2d501b8991dc697c7cbfa3db" category="example-title">Implementare Cloud Volumes ONTAP in AWS utilizzando BlueXP.</block>
  <block id="aac68d095e2a2a598854689d3a9118c3" category="list-text">Installare il connettore in ambiente VMware on-premise. Fare riferimento alle istruzioni <block ref="09bba0e8799e65970cd5db9fc029a18c" category="inline-link-macro-rx"></block>.</block>
  <block id="75cbb3865e297e8d229f20aefa0bc024" category="list-text">Implementare un'istanza CVO in AWS utilizzando il connettore. Fare riferimento alle istruzioni <block ref="789a1549fecc83ae6bfb4929c9c8d23c" category="inline-link-macro-rx"></block>.</block>
  <block id="2b71954d9c6d4c94a1ae68bbecd1cce4" category="admonition">Il connettore può essere installato anche nell'ambiente cloud. Fare riferimento a. <block ref="0631eaff036ce3419223357fb2a90da7" category="inline-link-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="31206dca8344fc90e6fae444b4ed25ac" category="example-title">Installare Astra Trident nel cluster OCP</block>
  <block id="201de1e883240abf227c15e36805365c" category="list-text">Implementare Trident Operator utilizzando Helm. Fare riferimento alle istruzioni <block ref="2b02799a23e3b4104fc737b9e328001b" category="inline-link-macro-rx"></block></block>
  <block id="26081a5f3033e3f0db9e432902c6f047" category="list-text">Creare un backend e una classe di storage. Fare riferimento alle istruzioni <block ref="9086b317542fa4fec3c7a94ae13e221d" category="inline-link-macro-rx"></block>.</block>
  <block id="872bd3e42a2bdb9c97d84fb9206f5b75" category="example-title">Aggiungere il cluster OCP su AWS all'Astra Control Center.</block>
  <block id="a2212fb9750ffed08e422fed3ae5804c" category="paragraph">Aggiungere il cluster OCP in AWS ad Astra Control Center.</block>
  <block id="bb476886963857408a744eea2885622d" category="paragraph-title">Utilizzo della funzionalità topologia CSI di Trident per architetture multi-zona</block>
  <block id="7ed73bdf4c4e2c0d457afe6f9f4031b0" category="paragraph">I cloud provider, oggi, consentono agli amministratori di cluster Kubernetes/OpenShift di generare nodi dei cluster basati su zone. I nodi possono essere collocati in diverse zone di disponibilità all'interno di una regione o in diverse regioni. Per facilitare il provisioning dei volumi per i carichi di lavoro in un'architettura multi-zona, Astra Trident utilizza la topologia CSI. Utilizzando la funzionalità topologia CSI, l'accesso ai volumi può essere limitato a un sottoinsieme di nodi, in base alle aree geografiche e alle zone di disponibilità. Fare riferimento a. <block ref="d4105e96f5d39fa667250cc3420bb2fe" category="inline-link-macro-rx"></block> per ulteriori dettagli.</block>
  <block id="638d185133876c481f9c7c55d167ce46" category="admonition">Kubernetes supporta due modalità di binding del volume: - Quando **_VolumeBindingMode_ è impostato su _immediate_** (default), Astra Trident crea il volume senza alcuna consapevolezza della topologia. I volumi persistenti vengono creati senza alcuna dipendenza dai requisiti di pianificazione del pod richiedente. - Quando **_VolumeBindingMode_ viene impostato su _WaitForFirstConsumer_**, la creazione e il binding di un volume persistente per un PVC viene ritardata fino a quando un pod che utilizza il PVC viene pianificato e creato. In questo modo, i volumi vengono creati per soddisfare i vincoli di pianificazione imposti dai requisiti di topologia. I backend di storage Astra Trident possono essere progettati per eseguire il provisioning selettivo dei volumi in base alle zone di disponibilità (back-end compatibile con la topologia). Per StorageClasses che utilizzano tale backend, un volume viene creato solo se richiesto da un'applicazione pianificata in una regione/zona supportata. (StorageClass consapevole della topologia) fare riferimento <block ref="d4105e96f5d39fa667250cc3420bb2fe" category="inline-link-macro-rx"></block> per ulteriori dettagli.</block>
  <block id="cdfa8f082e2d7715023a35b2735fceea" category="doc">Protezione dei dati mediante Astra Control Center</block>
  <block id="67ceaf3250ac3044e5b1ac1d959d53dd" category="paragraph">Questa pagina mostra le opzioni di protezione dei dati per le applicazioni basate su container Red Hat OpenShift eseguite su VMware vSphere utilizzando Astra Control Center (ACC).</block>
  <block id="77e741d4de2fa0a2ebeda0f3879c7e2c" category="paragraph">Mentre gli utenti intraprendono il percorso di modernizzazione delle proprie applicazioni con Red Hat OpenShift, è necessario adottare una strategia di protezione dei dati per proteggerli da cancellazioni accidentali o altri errori umani. Spesso, per proteggere i propri dati da un diaster, è necessaria anche una strategia di protezione a scopo normativo o di compliance.</block>
  <block id="2b4ffa904eb16d68fecf846cc9767cb0" category="paragraph">I requisiti di protezione dei dati variano dal ritorno a una copia point-in-time al failover automatico a un dominio di errore diverso senza alcun intervento umano. Molti clienti scelgono ONTAP come piattaforma di storage preferita per le loro applicazioni Kubernetes per le sue ricche funzionalità come multi-tenancy, multi-protocollo, offerte di capacità e performance elevate, replica e caching per ubicazioni multi-sito, sicurezza e flessibilità.</block>
  <block id="5cef3ebd5669ef6dbcf6372fe453664b" category="paragraph">I clienti possono avere un ambiente cloud configurato come estensione del data center, in modo che possano sfruttare i benefici del cloud e essere in grado di spostare i propri carichi di lavoro in un momento futuro. Per tali clienti, il backup delle applicazioni OpenShift e dei dati nell'ambiente cloud diventa una scelta inevitabile. Possono quindi ripristinare le applicazioni e i dati associati su un cluster OpenShift nel cloud o nel data center.</block>
  <block id="07a40de4830379d3ca7cc7f192a93312" category="section-title">Backup e ripristino con ACC</block>
  <block id="dff765515118d2dd275007616171d14f" category="paragraph">I proprietari delle applicazioni possono rivedere e aggiornare le applicazioni rilevate da ACC. ACC può eseguire copie Snapshot utilizzando CSI ed eseguire il backup utilizzando la copia Snapshot point-in-time. La destinazione del backup può essere un archivio di oggetti nell'ambiente cloud. È possibile configurare i criteri di protezione per i backup pianificati e il numero di versioni di backup da conservare. L'RPO minimo è di un'ora.</block>
  <block id="3df2258e47bca7a3ee653a9c77641629" category="section-title">Ripristino di un'applicazione da un backup mediante ACC</block>
  <block id="7c19c7318d54689f3bdb297f7e23fe89" category="inline-image-macro">Opzione di ripristino di Astra Control Center</block>
  <block id="304b64e420b615d88c3bdee212c8bd06" category="paragraph"><block ref="304b64e420b615d88c3bdee212c8bd06" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27ec99b325314a79ea3e5d3ca1942278" category="section-title">Hook di esecuzione specifici dell'applicazione</block>
  <block id="dc4b99b300d94b30cac207327eca6b3e" category="paragraph">Anche se sono disponibili funzionalità di protezione dei dati a livello di array di storage, spesso sono necessari ulteriori passaggi per rendere coerenti le applicazioni di backup e ripristino. I passaggi aggiuntivi specifici dell'applicazione potrebbero essere: - Prima o dopo la creazione di una copia Snapshot. - prima o dopo la creazione di un backup. - Dopo il ripristino da una copia Snapshot o da un backup. Astra Control può eseguire questi passaggi specifici dell'applicazione codificati come script personalizzati chiamati uncini di esecuzione.</block>
  <block id="6fc65b336c93cbda7e7e6a16b1cbb001" category="inline-link-macro">Progetto open source Verda</block>
  <block id="0108cbf1d785343393582518165b2acc" category="paragraph">Di NetApp <block ref="e8ef64368a60db519469fe3915b513cd" category="inline-link-macro-rx"></block> fornisce hook di esecuzione per le applicazioni native del cloud più diffuse per rendere la protezione delle applicazioni semplice, robusta e facile da orchestrare. Se si dispone di informazioni sufficienti per un'applicazione non presente nel repository, è possibile contribuire al progetto.</block>
  <block id="58d3e072cfa16653345a754a5a6d1448" category="section-title">Esempio di gancio di esecuzione per pre-Snapshot di un'applicazione redis.</block>
  <block id="b85d4f3b9ce88f321496fccb2f71f0af" category="image-alt">Gancio di esecuzione di Astra Control Center</block>
  <block id="d41736970e54ce96afd763ad67dc252f" category="section-title">Replica con ACC</block>
  <block id="511daa26775075560fb655c151291f95" category="paragraph">Per la protezione regionale o per una soluzione RPO e RTO bassa, un'applicazione può essere replicata in un'altra istanza di Kubernetes in esecuzione in un sito diverso, preferibilmente in un'altra regione. ACC utilizza SnapMirror asincrono ONTAP con RPO in soli 5 minuti. Fare riferimento a. <block ref="c38cfe7448528c0b52ee969f596aee97" category="inline-link-macro-rx"></block> Per le istruzioni di installazione di SnapMirror.</block>
  <block id="009a4d257485880614dc216576d57125" category="section-title">SnapMirror con ACC</block>
  <block id="9a1444b1c133e42ccb1d97ee2025cdac" category="image-alt">Replica di Astra Control Center</block>
  <block id="e9ff139910647d633d54b0fb5f970c3b" category="admonition">i driver di storage san-economy e nas-economy non supportano la funzione di replica. Fare riferimento a. <block ref="96b7ca19fdc8212e6e1a7f647be86fd3" category="inline-link-macro-rx"></block> per ulteriori dettagli.</block>
  <block id="5bed57ec15ba93e341876bf95c852684" category="section-title">Video dimostrativo:</block>
  <block id="096b02f12256f3c6a5dbd2bf4dae6b48" category="inline-link-macro">Video dimostrativo del disaster recovery con Astra Control Center</block>
  <block id="21d6e2c6b83f85bd50777e293ae89572" category="paragraph"><block ref="21d6e2c6b83f85bd50777e293ae89572" category="inline-link-macro-rx"></block></block>
  <block id="19c3bde99c8bff6dc76fef4a1ef18a79" category="paragraph">Sono disponibili dettagli sulle funzioni di protezione dei dati di Astra Control Center <block ref="5701e901fa686ac904f6ef8d7c56219a" category="inline-link-macro-rx"></block></block>
  <block id="fa6385abcbadab3651d099cbb8ffd292" category="doc">Migrazione dei dati con Astra Control Center</block>
  <block id="74262b249ea38631222f476198103a48" category="paragraph">Questa pagina mostra le opzioni di migrazione dei dati per i carichi di lavoro container sui cluster Red Hat OpenShift con Astra Control Center (ACC). In particolare, i clienti possono utilizzare l'ACC per trasferire alcuni workload selezionati o tutti i workload dai data center on-premise al cloud, clonare le loro applicazioni nel cloud a scopo di test o passare dal data center al cloud</block>
  <block id="2a529d0b05bbacac50f8502fe2e670bc" category="paragraph">Per migrare l'applicazione da un ambiente a un altro, è possibile utilizzare una delle seguenti funzionalità di ACC:</block>
  <block id="d046134dbee59ceee559caaee740734e" category="list-text">** replica **</block>
  <block id="7502d56aa1646347152e86a4fc41e691" category="list-text">** backup e ripristino **</block>
  <block id="92e06daec8f56328236212e3cc1589f2" category="list-text">** clone **</block>
  <block id="434bfe3fa874ac271fe4a58864eed525" category="inline-link-macro">sezione sulla protezione dei dati</block>
  <block id="2fbabbb6a6a4b39c94d7ff214be366fb" category="paragraph">Fare riferimento a. <block ref="3db733da05bd3e3967dc04592cc322a8" category="inline-link-macro-rx"></block> per le opzioni **replica e backup e ripristino**. Fare riferimento a. <block ref="b17026f8b157d793dc85ba49db8a185d" category="inline-link-macro-rx"></block> per ulteriori dettagli sulla clonazione **.</block>
  <block id="ff34f2d1d3b4a8e19535d52fa3161174" category="admonition">La funzione di replica Astra è supportata solo con Trident Container Storage Interface (CSI). Tuttavia, la replica non è supportata dai driver nas-economy e san-economy.</block>
  <block id="decf4ba07de4c0c590f687d6f4ae20c0" category="section-title">Esecuzione della replica dei dati con ACC</block>
  <block id="e4deb8e6d2d122cb9d8c89b367b4142c" category="paragraph"><block ref="e4deb8e6d2d122cb9d8c89b367b4142c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c097e1da19d035d4f07228f6b8e13793" category="doc">Soluzione NetApp con carichi di lavoro della piattaforma container Red Hat OpenShift su VMware</block>
  <block id="7ce666810e087fc109e0f94f94ad56a7" category="paragraph">Se i clienti hanno la necessità di eseguire le loro moderne applicazioni containerizzate su un'infrastruttura nei propri data center privati, possono farlo. Devono pianificare e implementare la piattaforma container Red Hat OpenShift (OCP) per un ambiente pronto per la produzione di successo per l'implementazione dei carichi di lavoro dei container. I cluster OCP possono essere implementati su VMware o bare metal.</block>
  <block id="04f13ada6e0062bf07f4a6bc4cfd0473" category="paragraph">Lo storage NetApp ONTAP offre protezione dei dati, affidabilità e flessibilità per le implementazioni di container. Astra Trident funge da provider di storage dinamico per consumare storage ONTAP persistente per le applicazioni stateful dei clienti. Astra Control Center può essere utilizzato per orchestrare i numerosi requisiti di gestione dei dati delle applicazioni stateful come protezione dei dati, migrazione e business continuity.</block>
  <block id="908657a98fea35209f3c29956a9b2bed" category="paragraph">Con VMware vSphere, i tool NetApp ONTAP forniscono un plug-in vCenter che può essere utilizzato per il provisioning dei datastore. Applica i tag e usali con OpenShift per memorizzare la configurazione del nodo e i dati. Lo storage basato su NVMe offre latenza inferiore e performance elevate.</block>
  <block id="5f24f5e6df026620962ac23d496e7362" category="paragraph">Questa soluzione fornisce dettagli sulla protezione dei dati e sulla migrazione dei carichi di lavoro dei container utilizzando Astra Control Center. Per questa soluzione, i carichi di lavoro dei container vengono implementati nei cluster Red Hat OpenShift su vSphere all'interno dell'ambiente on-premise. NOTA: In futuro forniremo una soluzione per i carichi di lavoro container sui cluster OpenShift su bare metal.</block>
  <block id="3037e288b8ba9d6259fa6ad9d3398b8f" category="section-title">Soluzione per la migrazione e la protezione dei dati per i carichi di lavoro dei container OpenShift con Astra Control Center</block>
  <block id="cb217a1a44f4d5fc78bf80f3442587fb" category="doc">Implementare e configurare la piattaforma container Red Hat OpenShift su VMware</block>
  <block id="ddd0b62f849b8e4ce53f6b702e4ec4a1" category="paragraph">In questa sezione viene descritto un workflow di alto livello che illustra come configurare e gestire i cluster OpenShift e gestire le applicazioni stateful su di essi. Mostra l'utilizzo degli storage array NetApp ONTAP con l'aiuto di Astra Trident per fornire volumi persistenti. Vengono forniti dettagli sull'utilizzo di Astra Control Center per eseguire attività di migrazione e protezione dei dati per le applicazioni stateful.</block>
  <block id="fdee92074ebfb0479bebaa75f729f428" category="admonition">Esistono diversi modi per implementare i cluster di piattaforme container Red Hat OpenShift. Questa descrizione di alto livello dell'installazione fornisce collegamenti alla documentazione per il metodo specifico utilizzato. È possibile fare riferimento agli altri metodi nei relativi collegamenti forniti in <block ref="ec30323d5c1ba24d6aabb0b3df901fd1" category="inline-link-macro-rx"></block>.</block>
  <block id="7157150173a2ad98f77ee0aaf3fd209c" category="paragraph">Di seguito è riportato un diagramma che illustra i cluster implementati su VMware in un data center.</block>
  <block id="ebee9d089ff5b775b007cf6049a2a17e" category="example-title">Implementare e configurare una macchina virtuale CentOS</block>
  <block id="cff8c3267077ed69174aa3527d1dc36e" category="list-text">Viene implementato nell'ambiente VMware vSphere.</block>
  <block id="cb1b5e668fc45052f3f24868ad7e60bc" category="list-text">Questa macchina virtuale viene utilizzata per l'implementazione di alcuni componenti come NetApp Astra Trident e NetApp Astra Control Center per la soluzione.</block>
  <block id="bc6be57de293aecbdd76179b49cf3d18" category="list-text">Un utente root viene configurato su questa macchina virtuale durante l'installazione.</block>
  <block id="32049ccafae47776aabbbc616d0f03c3" category="example-title">Implementare e configurare un cluster OpenShift Container Platform su VMware vSphere (Hub Cluster)</block>
  <block id="8f723b78972cfa193e65ef9f3a2344c8" category="inline-link-macro">Implementazione assistita</block>
  <block id="4032722c8375f3d8648bf18cdf7871cd" category="paragraph">Fare riferimento alle istruzioni del <block ref="c391027f88ae10e0813918c42a205aa9" category="inline-link-macro-rx"></block> Metodo per implementare un cluster OCP.</block>
  <block id="6f236f58666ae998668d5afce2ac9348" category="admonition">Tenere presente quanto segue: - Creare una chiave pubblica e privata ssh da fornire all'installatore. Queste chiavi verranno utilizzate per accedere ai nodi master e worker, se necessario. - Scaricare il programma di installazione dal programma di installazione assistito. Questo programma viene utilizzato per avviare le macchine virtuali create nell'ambiente VMware vSphere per i nodi master e worker. Le macchine virtuali devono avere i requisiti minimi di CPU, memoria e disco rigido. (Fare riferimento ai comandi di creazione della macchina virtuale su <block ref="1caa15c4f6b987248682d9b97caf205a" category="inline-link-macro-rx"></block> Per i nodi master e worker che forniscono queste informazioni) - diskUID deve essere abilitato su tutte le macchine virtuali. - Creare un minimo di 3 nodi per master e 3 nodi per worker. Una volta rilevati dal programma di installazione, attivare il pulsante di attivazione/disattivazione dell'integrazione VMware vSphere.</block>
  <block id="5ee7e5d095a85988457e6852e94af6e8" category="example-title">Installare Advanced Cluster Management sul cluster Hub</block>
  <block id="643c48205940ae10b1f2c5f6f8aa5f64" category="paragraph">Viene installato utilizzando Advanced Cluster Management Operator sul cluster Hub. Fare riferimento alle istruzioni <block ref="4bb39576c102d9630dc961b3998ecbd9" category="inline-link-macro-rx"></block>.</block>
  <block id="e32925fd5960e69787470b8e8050f9e4" category="example-title">Installare un registro Red Hat Quay interno sul cluster Hub.</block>
  <block id="d35063583c4a1472426b44ab39cf1289" category="list-text">Per inviare l'immagine Astra è necessario un registro interno. Un registro interno Quay viene installato utilizzando l'operatore nel cluster Hub.</block>
  <block id="e9376ceddbd8c3199dd0f9b58f969db1" category="list-text">Fare riferimento alle istruzioni <block ref="106db11ac4ec29af57ae501212b90c65" category="inline-link-macro-rx"></block></block>
  <block id="c0090a527266898baf1b6d9a9978eeb3" category="example-title">Installare due cluster OCP aggiuntivi (origine e destinazione)</block>
  <block id="a4fcf9c2586b5e93f63d9c1290438839" category="list-text">I cluster aggiuntivi possono essere implementati utilizzando ACM sul cluster Hub.</block>
  <block id="24ed1bd1ba2dc78d194e4186a2a7b0a1" category="list-text">Fare riferimento alle istruzioni <block ref="61a11e403c83c9c41ff797a7a780dbff" category="inline-link-macro-rx"></block>.</block>
  <block id="4cb2dca6265c22cd883513131d603c5f" category="example-title">Configurare lo storage NetApp ONTAP</block>
  <block id="31114fdb67ca9ac1afd2af9e1a830e4e" category="list-text">Installare un cluster ONTAP con connettività alle VM OCP nell'ambiente VMware.</block>
  <block id="15a89333d6100097518836f27ebc981d" category="list-text">Creare una SVM.</block>
  <block id="5c9914884527913b8fccd217cc6c8b11" category="list-text">Configurare i dati NAS per accedere allo storage in SVM.</block>
  <block id="7becc4cb9c4df5e8d5cb90ed1d181394" category="example-title">Installare NetApp Trident sui cluster OCP</block>
  <block id="f086eaa0b9f8b360a31c94f637c0d0b4" category="list-text">Installare NetApp Trident su tutti e tre i cluster: Hub, origine e destinazione</block>
  <block id="388489f610963550b7669f0a1294b958" category="list-text">Fare riferimento alle istruzioni <block ref="36ef4218bf5578859a7215d49db6401a" category="inline-link-macro-rx"></block>.</block>
  <block id="c80ffbf15474d7b48c471b4be5c7eea6" category="list-text">Creare un backend di storage per ontap-nas .</block>
  <block id="29dfff8b62823a687037af3caba8bde0" category="list-text">Creare una classe di storage per ontap-nas.</block>
  <block id="6fa9ba2800ce8267575f3934fc7a7c46" category="list-text">Fare riferimento alle istruzioni <block ref="9086b317542fa4fec3c7a94ae13e221d" category="inline-link-macro-rx"></block>.</block>
  <block id="bae25119b826b9ac3f0139d60666c5a2" category="example-title">Installare NetApp Astra Control Center</block>
  <block id="dcc7f9c17c22a8d859c7d80bbab266fd" category="list-text">NetApp Astra Control Center viene installato utilizzando Astra Operator sul cluster Hub.</block>
  <block id="d38e5dd6bd81bc5e1d30960b2bcd4937" category="list-text">Fare riferimento alle istruzioni <block ref="badde8c82c638a4d205deac0f9dfbab6" category="inline-link-macro-rx"></block>.</block>
  <block id="8c41383f8ea827ed90aaea3cad2a266e" category="paragraph">Punti da ricordare: * Scarica l'immagine di NetApp Astra Control Center dal sito di supporto. * Inserire l'immagine in un registro interno. * Fare riferimento alle istruzioni qui.</block>
  <block id="f1695603df9eff6b0631c2c5a3e023e5" category="example-title">Implementare un'applicazione sul cluster di origine</block>
  <block id="fc9da6996070c267e36ead9d0ec7feb9" category="paragraph">Utilizza OpenShift GitOps per implementare un'applicazione. (es. Postgres, Ghost)</block>
  <block id="9528b255237a8d325a14e2000be97573" category="example-title">Aggiungere i cluster di origine e destinazione in Astra Control Center.</block>
  <block id="09361c7ad370c2e7e53d015ad4fab4b0" category="inline-link-macro">Inizia a gestire le app di Astra Control Center</block>
  <block id="78fa07ec3b9ba9f22e548694264fe880" category="paragraph">Dopo aver aggiunto un cluster alla gestione di Astra Control, è possibile installare le applicazioni sul cluster (all'esterno di Astra Control) e quindi passare alla pagina delle applicazioni in Astra Control per definire le applicazioni e le relative risorse. Fare riferimento a. <block ref="c613c6401833c4841b0ab26745eb0b8c" category="inline-link-macro-rx"></block>.</block>
  <block id="378b41ea55cc0a1ff844e4ab0f04524d" category="paragraph">Il passaggio successivo consiste nell'utilizzare Astra Control Center per la protezione dei dati e la migrazione dei dati dal cluster di origine a quello di destinazione.</block>
  <block id="9645795f561430b8c7c8af462727e1c7" category="doc">Protezione dei dati con Astra</block>
  <block id="dfea6c0fea6ed37acf9e75b6a4549abb" category="paragraph">La protezione dei dati in ONTAP può essere ottenuta utilizzando ad-hoc o policy controllate - **Snapshot** - **backup e ripristino**</block>
  <block id="32645e18d7f4247905ad6890e438a838" category="paragraph">Sia le copie Snapshot che i backup proteggono i seguenti tipi di dati: - **I metadati dell'applicazione che rappresentano lo stato dell'applicazione** - **eventuali volumi di dati persistenti associati all'applicazione** - **eventuali artefatti delle risorse appartenenti all'applicazione**</block>
  <block id="60e419ba4534554b327dcc9d08a88051" category="section-title">Snapshot con ACC</block>
  <block id="b0be27a64b0f61f58d3aec742f01fbad" category="paragraph">È possibile acquisire una copia point-in-time dei dati utilizzando Snapshot con ACC. La policy di protezione definisce il numero di copie Snapshot da conservare. L'opzione di pianificazione minima disponibile è oraria. Le copie Snapshot manuali e on-demand possono essere eseguite in qualsiasi momento e a intervalli più brevi rispetto alle copie Snapshot pianificate. Le copie Snapshot vengono memorizzate sullo stesso volume sottoposto a provisioning dell'applicazione.</block>
  <block id="f70c55e82154bf66a6f83cb62a68c5d4" category="section-title">Configurazione di Snapshot con ACC</block>
  <block id="05a7ec3be5c459fbf39f36ddf3c800c8" category="image-alt">Vista Snapshot di Astra Control Center</block>
  <block id="251a2148a5d4efac4cff711b46a52b21" category="paragraph">Un backup si basa su un'istantanea. ACC può eseguire copie Snapshot utilizzando CSI ed eseguire il backup utilizzando la copia Snapshot point-in-time. Il backup viene memorizzato in un archivio di oggetti esterno (qualsiasi compatibile con s3, incluso ONTAP S3, in una posizione diversa). È possibile configurare i criteri di protezione per i backup pianificati e il numero di versioni di backup da conservare. L'RPO minimo è di un'ora.</block>
  <block id="eec7737a80f326b19b44d829e47c31f7" category="paragraph">ACC ripristina l'applicazione dal bucket S3 in cui sono memorizzati i backup.</block>
  <block id="92dab9911cf33fb36633339932ea1aa4" category="paragraph">Inoltre, è possibile configurare gli hook di esecuzione per l'esecuzione in combinazione con un'operazione di protezione dei dati di un'applicazione gestita. Anche se sono disponibili funzionalità di protezione dei dati a livello di array di storage, spesso sono necessari ulteriori passaggi per rendere coerenti backup e ripristini. I passaggi aggiuntivi specifici dell'applicazione potrebbero essere: - Prima o dopo la creazione di una copia Snapshot. - prima o dopo la creazione di un backup. - Dopo il ripristino da una copia Snapshot o da un backup.</block>
  <block id="ebbdb911301d0ec7cb4da5dc83c333d4" category="paragraph">Astra Control può eseguire questi passaggi specifici dell'applicazione codificati come script personalizzati chiamati uncini di esecuzione.</block>
  <block id="0370124d48bfc5af2def19c48f433283" category="inline-link">Progetto NetApp Verda GitHub</block>
  <block id="039a30c0463c68f7f8e1c222726b8bdd" category="paragraph"><block ref="9ad3989601b59e755170866a5329554c" category="inline-link-rx"></block> fornisce hook di esecuzione per le applicazioni native del cloud più diffuse per rendere la protezione delle applicazioni semplice, robusta e facile da orchestrare. Se si dispone di informazioni sufficienti per un'applicazione non presente nel repository, è possibile contribuire al progetto.</block>
  <block id="3d03d2aa94bb04967bc567d16b813d26" category="paragraph">Per la protezione regionale o per una soluzione RPO e RTO bassa, un'applicazione può essere replicata in un'altra istanza di Kubernetes in esecuzione in un sito diverso, preferibilmente in un'altra regione. ACC utilizza SnapMirror asincrono ONTAP con RPO in soli 5 minuti. La replica viene eseguita replicando in ONTAP, quindi un failover crea le risorse Kubernetes nel cluster di destinazione.</block>
  <block id="74713319c86022082cfafb127b906d08" category="admonition">Tenere presente che la replica è diversa dal backup e ripristino, dove il backup viene eseguito in S3 e il ripristino viene eseguito da S3. Fare riferimento al link: https://docs.netapp.com/us-en/astra-control-center/concepts/data-protection.html#replication-to-a-remote-cluster[here] per ulteriori dettagli sulle differenze tra i due tipi di protezione dei dati.</block>
  <block id="12e6f760044e842eeeed770fe1f045e0" category="paragraph">Fare riferimento a. <block ref="c38cfe7448528c0b52ee969f596aee97" category="inline-link-macro-rx"></block> Per le istruzioni di installazione di SnapMirror.</block>
  <block id="3e27528a048bdb90c1e5af896157ebcf" category="section-title">Continuità del business con MetroCluster</block>
  <block id="75173a4bfbc4b9d0487876943898d53a" category="paragraph">La maggior parte della nostra piattaforma hardware per ONTAP dispone di funzionalità ad alta disponibilità per la protezione dai guasti dei dispositivi, evitando la necessità di eseguire il disaster recovery. Tuttavia, per proteggere da incendi o altri disastri e continuare il business con un RPO zero e un RTO basso, spesso viene utilizzata una soluzione MetroCluster.</block>
  <block id="841630d0dba0d69babf2a06681abb90a" category="paragraph">I clienti che attualmente dispongono di un sistema ONTAP possono estendere a MetroCluster aggiungendo sistemi ONTAP supportati entro i limiti di distanza per fornire il disaster recovery a livello di zona. Astra Trident, CSI (Container Storage Interface) supporta NetApp ONTAP, inclusa la configurazione MetroCluster e altre opzioni come Cloud Volumes ONTAP, Azure NetApp Files, AWS FSX per NetApp ONTAP, ecc. Astra Trident offre cinque opzioni di driver di storage per ONTAP, tutte supportate per la configurazione MetroCluster. Fare riferimento a. <block ref="4ff141ef41caefdf95879d6959762462" category="inline-link-macro-rx"></block> Per ulteriori informazioni sui driver di storage ONTAP supportati da Astra Trident.</block>
  <block id="fdf1e99fd6fe9f1b22f62f0c5ff36829" category="paragraph">La soluzione MetroCluster richiede un'estensione di rete Layer 2 o la capacità di accedere allo stesso indirizzo di rete da entrambi i domini di errore. Una volta eseguita la configurazione MetroCluster, la soluzione è trasparente per i proprietari delle applicazioni, in quanto tutti i volumi nella svm MetroCluster sono protetti e ottengono i benefici di SyncMirror (zero RPO).</block>
  <block id="56142cf6bea785ab85e06c15d7593392" category="inline-image-macro">Soluzione per la business continuity con MetroCluster</block>
  <block id="e7a2e49de12de237d96c8edc922e5ad9" category="paragraph"><block ref="e7a2e49de12de237d96c8edc922e5ad9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4fcddfe6dfd1a15c842a3b7017dffec" category="admonition">Per la configurazione back-end Trident (TBC), non specificare dataLIF e SVM quando si utilizza la configurazione MetroCluster. Specificare l'IP di gestione SVM per la gestione LIF e utilizzare le credenziali del ruolo vsadmin.</block>
  <block id="0299f9898fbd6ab90ab2fb9535d62b7e" category="paragraph">Questa pagina mostra le opzioni di migrazione dei dati per i carichi di lavoro container sui cluster Red Hat OpenShift con Astra Control Center (ACC).</block>
  <block id="225f5856aa99c18e009bcb24f919f963" category="paragraph">Le applicazioni Kubernetes spesso devono essere spostate da un ambiente all'altro. Per migrare un'applicazione insieme ai suoi dati persistenti, è possibile utilizzare NetApp ACC.</block>
  <block id="b94dad5a79b4605eb1c357e1088d3d57" category="section-title">Migrazione dei dati tra diversi ambienti Kubernetes</block>
  <block id="86c59e7ba36ae51135e600ddf9fb2bad" category="paragraph">ACC supporta diversi tipi di Kubernetes, tra cui Google anthos, Red Hat OpenShift, Tanzu Kubernetes Grid, Rancher Kubernetes Engine, Kubernetes upstream, ecc. Per ulteriori dettagli, fare riferimento a. <block ref="0ceb66317efc123a6d617c493c18fdeb" category="inline-link-macro-rx"></block>.</block>
  <block id="a54acb3fa05f851f3ce9e93ed8a6fcee" category="paragraph">Per migrare l'applicazione da un cluster a un altro, è possibile utilizzare una delle seguenti funzionalità di ACC:</block>
  <block id="90305bb6fba97091f683e8b82f9bf805" category="summary">L'automazione delle soluzioni NetApp consente al cliente di automatizzare l'implementazione, la configurazione e l'esecuzione di molte attività applicative e infrastrutturate comuni.</block>
  <block id="a123daaac5749e4d0965aca160f0adfd" category="doc">Automazione delle soluzioni NetApp</block>
  <block id="d78228187c1a83d3bb4d8e97cd657807" category="paragraph">L'automazione semplifica il consumo delle soluzioni NetApp.</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">Introduzione</block>
  <block id="380fbb2dc2a4b42876553664c398fb3f" category="paragraph">Nel fornire soluzioni per affrontare le sfide aziendali odierne, NetApp offre soluzioni con i seguenti obiettivi:</block>
  <block id="008347e050bccf7e2812ae39dd816f41" category="list-text">Fornendo fasi di implementazione e configurazione validate,</block>
  <block id="4ef594072d2fdf53ad9ca6af7fe16569" category="list-text">Soluzioni facili da utilizzare,</block>
  <block id="3f68e576fe6e3e328b5feeea03707572" category="list-text">Fornire un'implementazione della soluzione che abbia un risultato prevedibile, sia facilmente ripetuta e scalabile nell'azienda del cliente.</block>
  <block id="928a4532882b0eb0208abcae9b7fd6f0" category="paragraph">Per raggiungere questi obiettivi, è fondamentale semplificare l'implementazione e la configurazione dell'infrastruttura e/o delle applicazioni attraverso le nostre soluzioni attraverso l'automazione. NetApp si impegna a semplificare il consumo delle soluzioni attraverso l'automazione.</block>
  <block id="d6d7e89b087a9e69ae7622847dc932e5" category="paragraph">Utilizzando strumenti di automazione open-source come Red Hat Ansible, HashiCorp Terraform o Microsoft PowerShell, le soluzioni NetApp sono in grado di automatizzare l'implementazione delle applicazioni, il provisioning del cloud, la gestione della configurazione e molte altre attività IT comuni. Le soluzioni NetApp sfruttano gli elementi di automazione disponibili al pubblico, oltre a fornire l'automazione creata da NetApp, per semplificare l'implementazione complessiva di una soluzione.</block>
  <block id="e532e5979d2ecc30b8177530683810e2" category="paragraph">Laddove sono disponibili funzionalità di automazione, il materiale collaterale della soluzione guiderà l'utente attraverso il processo di automazione della soluzione o delle fasi della soluzione attraverso gli strumenti di automazione specifici.</block>
  <block id="d82dd9b3245382b365106db0568113e8" category="summary">L'automazione delle soluzioni NetApp consente al cliente di automatizzare l'implementazione, la configurazione e l'esecuzione di molte attività comuni dell'infrastruttura e delle applicazioni.</block>
  <block id="aaac1ea7463ef799eaafc693b16b1f81" category="doc">Introduzione all'automazione delle soluzioni NetApp</block>
  <block id="66bd3dbe1f46a5715420e201e457ff65" category="paragraph">L'automazione della soluzione NetApp offre semplicità e ripetibilità per molte delle attività comuni utilizzate dalle soluzioni NetApp.</block>
  <block id="bf7d92f5ef43a7e0ab10c8d11d28ef6e" category="paragraph">Prima di eseguire qualsiasi automazione della soluzione, è necessario configurare l'ambiente in base alla modalità di esecuzione dell'automazione. Sono disponibili opzioni per eseguire l'automazione dalla riga di comando o tramite uno strumento come AWX o tower.</block>
  <block id="dcdcb9b7436ca5ceca042e84e9c3ccf5" category="paragraph">Le sezioni seguenti illustrano i passaggi necessari per configurare l'ambiente per ciascuno degli ambienti specificati.</block>
  <block id="3d45b043c5518eca1e47fb4ba8a813da" category="example-title">Configurare il nodo di controllo Ansible per le implementazioni CLI su RHEL/CentOS</block>
  <block id="d1029167179320d8b6d70b11c3d01bd3" category="list-text">Requisiti per il nodo di controllo Ansible:</block>
  <block id="5c263f30899f93ff7ccd457ad3eb956f" category="list-text">Una macchina RHEL/CentOS con i seguenti pacchetti installati:</block>
  <block id="ca60b3698dd3d27a5f91e4dc0a1a2546" category="list-text">Pito3</block>
  <block id="4ce3ea126bb844d4f8c4ce1a65cbe3ae" category="list-text">Pip3</block>
  <block id="881cbd1ce3fdb52f73a82f8674a2a364" category="list-text">Ansible (versione successiva alla 2.10.0)</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="list-text">Git</block>
  <block id="7b643b0eef9cf1199195fa05b77fc3c8" category="paragraph">Se si dispone di un computer RHEL/CentOS nuovo senza i requisiti sopra indicati, seguire la procedura riportata di seguito per configurare tale computer come nodo di controllo Ansible:</block>
  <block id="d2052f202108defaf6afc7831ba59362" category="list-text">Abilitare il repository Ansible per RHEL-8/RHEL-7</block>
  <block id="61fbc2f21db84f17551fda6893429d16" category="list-text">Per RHEL-8 (eseguire il seguente comando come root)</block>
  <block id="77cd42f765e6b40764459a64a979f90c" category="list-text">Per RHEL-7 (eseguire il seguente comando come root)</block>
  <block id="675f82a779038c3f679b04bc0aadca1a" category="list-text">Incollare il contenuto riportato di seguito nel terminale</block>
  <block id="2afb5cc3404c6c8162722fd41895c2de" category="example-title">Configurare il nodo di controllo Ansible per le implementazioni CLI su Ubuntu / Debian</block>
  <block id="9ced761647f5d80fe615526ffff63937" category="list-text">Una macchina Ubuntu/Debian con i seguenti pacchetti installati:</block>
  <block id="6e3d8a0ff7934b777031953fe936bac8" category="paragraph">Se si dispone di una nuova macchina Ubuntu/Debian senza i requisiti di cui sopra, seguire la procedura riportata di seguito per impostare la macchina come nodo di controllo Ansible:</block>
  <block id="56ee829a33ac57c3b6d427e35b3b2e86" category="list-text">Incollare il contenuto riportato di seguito nel terminale</block>
  <block id="6b8c64be0bad88fb867c6576ac777b25" category="example-title">Configurazione di Ansible Tower o AWX per implementazioni tower/AWX</block>
  <block id="2aa17d37bd2483f97468ab7653396786" category="paragraph">Questa sezione descrive i passaggi necessari per configurare i parametri in AWX/Ansible Tower che preparano l'ambiente per l'utilizzo delle soluzioni automatizzate di NetApp.</block>
  <block id="134d501fee5367069f0746f15302ce1f" category="list-text">Configurare l'inventario.</block>
  <block id="0fb1db9928d7fc107d96c13f1918b639" category="list-text">Accedere a Resources → Inventories → Add e fare clic su Add Inventory (Aggiungi inventario).</block>
  <block id="2623b8eb8fcaecc009c3b78cc6e7d391" category="list-text">Fornire i dettagli relativi al nome e all'organizzazione e fare clic su Save (Salva).</block>
  <block id="cc243ac3e015aef331656a4bff40241c" category="list-text">Nella pagina Inventories (inventari), fare clic sulle risorse di inventario appena create.</block>
  <block id="b0ddb214e9aa4a84bc80e6af8c6b2adf" category="list-text">Se sono presenti variabili di inventario, incollarle nel campo Variables (variabili).</block>
  <block id="5d7863780eab69b6b968cfc9dc6e66bc" category="list-text">Accedere al sottomenu Groups (gruppi) e fare clic su Add (Aggiungi).</block>
  <block id="ec51931bb91bc912d609f2099974dfd9" category="list-text">Fornire il nome del gruppo, copiare le variabili del gruppo (se necessario) e fare clic su Save (Salva).</block>
  <block id="8f9cbdc13fdcb31ff345f10ba333ac59" category="list-text">Fare clic sul gruppo creato, accedere al sottomenu hosts e fare clic su Add New host (Aggiungi nuovo host).</block>
  <block id="98e7a99b463b825a87899d25486e46ea" category="list-text">Fornire il nome host e l'indirizzo IP dell'host, incollare le variabili host (se necessario) e fare clic su Save (Salva).</block>
  <block id="3caf9a56384a30eb8dee819e3abc14d6" category="list-text">Creare tipi di credenziale. Per le soluzioni che includono ONTAP, Element, VMware o qualsiasi altra connessione di trasporto basata su HTTPS, è necessario configurare il tipo di credenziale in modo che corrisponda alle voci di nome utente e password.</block>
  <block id="615b6214c17105ae4915a8c8a632025b" category="list-text">Accedere a Administration → Credential Types (Amministrazione tipi di credenziali) e fare clic su Add (Aggiungi</block>
  <block id="e6bf632438290fdf98265b2b18943118" category="list-text">Fornire il nome e la descrizione.</block>
  <block id="846bb9303e5cc4395e96eba0d4c7d50a" category="list-text">Incollare il seguente contenuto nella configurazione di input:</block>
  <block id="333a40c5632e0507a83f6a191f0b69b3" category="list-text">Incollare il seguente contenuto nella configurazione dell'iniettore:</block>
  <block id="e31908e83a96aee8550446309c4ef7e0" category="list-text">Configurare le credenziali.</block>
  <block id="de06c7b54d4158f81a8c4d4a02b61eb0" category="list-text">Accedere a risorse → credenziali e fare clic su Aggiungi.</block>
  <block id="9c78f8d8687776e79018ded982e14c25" category="list-text">Inserire il nome e i dettagli dell'organizzazione.</block>
  <block id="e5b5f57b6910910a3f9a486e88088608" category="list-text">Selezionare il tipo di credenziale corretto; se si desidera utilizzare l'accesso SSH standard, selezionare il tipo macchina o, in alternativa, selezionare il tipo di credenziale personalizzato creato.</block>
  <block id="9256ee926473942ba849050ef0450b7f" category="list-text">Inserire gli altri dati corrispondenti e fare clic su Save (Salva).</block>
  <block id="29d192f714134f2e257058cfcf763722" category="list-text">Configurare il progetto.</block>
  <block id="1b892b7661c6a3ae2b57cbf4233c3af5" category="list-text">Accedere a risorse → progetti e fare clic su Aggiungi.</block>
  <block id="936784ca62c93ca666e77fd10733247c" category="list-text">Selezionare Git (Git) per il tipo di credenziale del controllo di origine.</block>
  <block id="9f4fd9b4a4c75c02d1b469e8dd75d9fb" category="list-text">Incollare l'URL del controllo di origine (o l'URL del clone git) corrispondente alla soluzione specifica.</block>
  <block id="95acbbc0424478165cdbe3a62849cbc3" category="list-text">Facoltativamente, se l'URL Git è controllato dall'accesso, creare e allegare la credenziale corrispondente nella credenziale di controllo del codice sorgente.</block>
  <block id="7557bd62e953fb4d48f07977151ea94f" category="list-text">Fare clic su Salva.</block>
  <block id="a934d780fa0cb0e8495a0a1cabd0f501" category="list-text">Configurare il modello di lavoro.</block>
  <block id="0fd181172a82ebe5219e9a30e5d97c0d" category="list-text">Accedere a risorse → modelli → Aggiungi e fare clic su Aggiungi modello di processo.</block>
  <block id="10c610c9225adcc92ca1b284b5bbb04b" category="list-text">Immettere il nome e la descrizione.</block>
  <block id="e33edf61d02fc69c2087dcc3c42177e1" category="list-text">Selezionare il tipo di lavoro; Esegui consente di configurare il sistema in base a un playbook e Check esegue un ciclo completo del playbook senza configurare effettivamente il sistema.</block>
  <block id="57cf64ce7890d12e5a41d18b83979ffd" category="list-text">Seleziona l'inventario, il progetto e le credenziali corrispondenti per il playbook.</block>
  <block id="fc6b15b1dd73bb25477aed453b9a02f2" category="list-text">Selezionare la guida che si desidera eseguire come parte del modello di lavoro.</block>
  <block id="9a7d90740af07bcdd2c628a6f6ae966c" category="list-text">In genere, le variabili vengono incollate durante il runtime. Pertanto, per visualizzare la richiesta di popolare le variabili durante l'esecuzione, assicurarsi di selezionare la casella di controllo prompt on Launch (prompt all'avvio) corrispondente al campo Variable (variabile).</block>
  <block id="3454f07e6f81a48099e0d144ca38ec7a" category="list-text">Fornire eventuali altri dettagli necessari e fare clic su Save (Salva).</block>
  <block id="31e2568c13fbdaaad088eb3b665dea9d" category="list-text">Avviare il modello di lavoro.</block>
  <block id="3624b34cb634949984bcb28c79fd327f" category="list-text">Accedere a risorse → modelli.</block>
  <block id="56ae7378358ba2b1c55c47283f544991" category="list-text">Fare clic sul modello desiderato, quindi fare clic su Launch (Avvia).</block>
  <block id="0b55c84dbc04b54418b0d507f7b8f669" category="list-text">Se richiesto all'avvio, inserire le variabili, quindi fare nuovamente clic su Launch (Avvia).</block>
  <block id="2fbb88fe90f9183c7eab541bc808795f" category="summary">In questa pagina viene descritto il metodo automatizzato per l'implementazione dei volumi NetApp sui provider cloud (AWS, Azure, GCP) utilizzando il terraform.</block>
  <block id="8eece2f5500ed61d5d5d24d6b8cc6da5" category="doc">Cloud Volumes Automation via Terraform</block>
  <block id="fbd9a83d6df239351ac0498cbaa58065" category="paragraph">Questa soluzione documenta le implementazioni automatizzate dei volumi cloud su AWS (CVO a nodo singolo, CVO ha e FSX ONTAP) e Azure (CVO a nodo singolo, CVO ha e ANF) utilizzando i moduli Terraform. Il codice è disponibile all'indirizzo<block ref="d07ec9f91b2ccc52b0d628a1b144c1d8" category="inline-link-rx"></block></block>
  <block id="e11da9afe91d381489a365c86cc614ab" category="section-title">Prerequisiti</block>
  <block id="95332f844502bac70e3783f2d906688c" category="list-text">Terraform &gt;= 0.13</block>
  <block id="82410a61f302c6bdce619218d5036674" category="list-text">Account Cloud Manager</block>
  <block id="77913a2ff2c55b56fd6d981e7d7d2303" category="list-text">Cloud Provider account – AWS, Azure</block>
  <block id="8fdcd620b2871b4f496213f43c8ee21f" category="list-text">Computer host (qualsiasi sistema operativo supportato da Terraform)</block>
  <block id="e5da768f23935e9c380799d86e27d695" category="section-title">Documentazione del provider</block>
  <block id="8443f23dd52e13e75f6a652a7e100fb6" category="inline-link-macro"><block ref="8443f23dd52e13e75f6a652a7e100fb6" category="inline-link-rx"></block></block>
  <block id="b78f34c8bc7d03e88e2a6d7d8907ef93" category="paragraph">La documentazione del provider Terraform per Cloud Manager è disponibile all'indirizzo: <block ref="05e9b3cbe087530696c6230448ff6b71" category="inline-link-macro-rx"></block></block>
  <block id="ef335030cde4c62e318574aa31ee49f7" category="section-title">Controllo della versione del provider</block>
  <block id="cc6d892dc2fbac39a7a00c3d822275b8" category="paragraph">Si noti che è anche possibile controllare la versione del provider. Questo è controllato da un blocco required_provider nella configurazione Terraform.</block>
  <block id="bf4e80680b83752f1f57ca7d4e99d09b" category="paragraph">La sintassi è la seguente:</block>
  <block id="c26cc3bad4e19f3604486c6e2d4dee15" category="paragraph">Scopri di più sul controllo della versione del provider.</block>
  <block id="c335a311e2b771c143fbe09512d98021" category="section-title">Esecuzione di moduli specifici</block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="example-title">AWS</block>
  <block id="169210ceac9b94f0632cd1182961e949" category="open-title">Implementazione CVO a nodo singolo</block>
  <block id="fe86efdcec6e779b5ef15f62d8f2bc90" category="paragraph-title">File di configurazione del terraform per l'implementazione di NetApp CVO (Single Node Instance) su AWS</block>
  <block id="610db6bf34b03f7873afe01d4eec8e58" category="paragraph">Questa sezione contiene diversi file di configurazione del terraform per implementare/configurare il CVO NetApp (Cloud Volumes ONTAP) a nodo singolo su AWS (Amazon Web Services).</block>
  <block id="4a537f87e89ac00b1276af84fa6f2da9" category="paragraph">Documentazione terraform:<block ref="e2ea72ce6afb985e72624e098135e8e1" category="inline-link-rx"></block></block>
  <block id="8c4271e6faf2cea4cfc8e5b7108d8ee9" category="paragraph-title">Procedura</block>
  <block id="c69eb42cd732c6d937af674afc73ba24" category="paragraph">Per eseguire il modello:</block>
  <block id="0b2fc5bb85de930f6b1d839951f8df6d" category="list-text">Clonare il repository.</block>
  <block id="6f5cc42a3e67b7edb3a2d4b86ebfae01" category="list-text">Selezionare la cartella desiderata</block>
  <block id="71046100fbc383dd8cd1cdd6160f6d6d" category="list-text">Configurare le credenziali AWS dalla CLI.</block>
  <block id="4a4f9b0378c89fa21da9e5528c8a7f47" category="list-text">AWS Access Key ID [None] (ID chiave di accesso AWS [Nessuno]): Access Key (chiave</block>
  <block id="6bbb2ea6e07d16e69748545bf2ee6a6d" category="list-text">AWS Secret Access Key [Nessuna]: Secretkey</block>
  <block id="7a31be9d48b53cd82a7160af0cd58fbe" category="list-text">Nome regione predefinita [Nessuno]: US-West-2</block>
  <block id="276bf14207394167e2ed4e3eed448680" category="list-text">Formato di output predefinito [Nessuno]: json</block>
  <block id="dd08960caafad89635926c55a0efd3a4" category="list-text">Aggiornare i valori delle variabili in<block ref="138255b51837a8bb57dce615f0b58218" prefix=" " category="inline-code"></block></block>
  <block id="e962d97debd0a377828855d79b5ccf66" category="admonition">È possibile scegliere di implementare il connettore impostando il valore della variabile "aws_Connector_Deploy_bool" su true/false.</block>
  <block id="88cefa0997a2272107223ee543b114db" category="list-text">Inizializzare il repository Terraform per installare tutti i prerequisiti e prepararsi all'implementazione.</block>
  <block id="046372e4315eccae02c5be2caaac1ac5" category="list-text">Verificare i file del terraform utilizzando il comando terraform validate.</block>
  <block id="144930ffd88cabf8795c7d4a6698e4ac" category="list-text">Eseguire un'analisi della configurazione per ottenere un'anteprima di tutte le modifiche previste dall'implementazione.</block>
  <block id="50a325adfbe874e5e14b044244efa49e" category="list-text">Eseguire l'implementazione</block>
  <block id="3125f7b5833c80fbd03966accb540bf8" category="paragraph">Per eliminare l'implementazione</block>
  <block id="4e91e39d32f2399e7c90059f4eea5684" category="paragraph-title">Ricipiti:</block>
  <block id="58c9aaf9cf3d4d0215afe012b77aa1bc" category="paragraph"><block ref="edf21d7ecb364e8210ddd3dfaeca6fbf" prefix="" category="inline-code"></block></block>
  <block id="251861170f071d1ebe67b948f5026905" category="paragraph">Variabili di terraform per l'istanza di NetApp AWS Connector per l'implementazione CVO.</block>
  <block id="496ee322ba138fdbc777e5ab2e30145e" category="cell">*Nome*</block>
  <block id="7464a7978b1ad9e7f36e5f0181e97eb5" category="cell">*Tipo*</block>
  <block id="22d8f94f4a088cb8d7c83ec5f44a03af" category="cell">*aws_connector_deploy_bool*</block>
  <block id="c26f15e86e3de4c398a8273272aba034" category="cell">Bool</block>
  <block id="95ab4e4a16c4f585ede4d3c63167c1ee" category="cell">(Obbligatorio) verificare l'implementazione del connettore.</block>
  <block id="e15fa495ec49ba53e0ba45d555c24027" category="cell">*aws_connector_name*</block>
  <block id="27118326006d3829667a400ad23d5d98" category="cell">Stringa</block>
  <block id="5548283861d04af602b7193306751df7" category="cell">(Obbligatorio) il nome di Cloud Manager Connector.</block>
  <block id="8c3a0cf46a98725e12d666e2e13dc06d" category="cell">*aws_connector_region*</block>
  <block id="efb4f51f6b08f54633b02a06b94210f2" category="cell">(Obbligatorio) la regione in cui verrà creato Cloud Manager Connector.</block>
  <block id="358040941579fe064f522f5b1eac2a33" category="cell">*aws_connector_key_name*</block>
  <block id="5c2f4db5972ecd2062c5f449f09c661f" category="cell">(Obbligatorio) il nome della coppia di chiavi da utilizzare per l'istanza del connettore.</block>
  <block id="0e46676177a5b007dfeefb6ada2b65af" category="cell">*aws_connector_company*</block>
  <block id="a7f1f5d73f372170ea283996e464af43" category="cell">(Obbligatorio) il nome della società dell'utente.</block>
  <block id="9b9081642589bb52bb20161632edc5a6" category="cell">*aws_connector_instance_type*</block>
  <block id="ddd1c9b22f94863b3de9a1b551188553" category="cell">(Obbligatorio) il tipo di istanza (ad esempio t3.xlarge). Sono richiesti almeno 4 CPU e 16 GB di memoria.</block>
  <block id="f8a700002db36fadde1ab9526f2cf8c3" category="cell">*aws_connector_subnet_id*</block>
  <block id="76788966b37b9b0df0b8ed78ad67eea9" category="cell">(Obbligatorio) l'ID della subnet per l'istanza.</block>
  <block id="fafb089eb14a5fe730cfadfd7bed4b4f" category="cell">*aws_connector_security_group_id*</block>
  <block id="728aafab2377ad85ce4ae3f6a4b3dd33" category="cell">(Obbligatorio) l'ID del gruppo di protezione per l'istanza, è possibile fornire più gruppi di protezione separati da ','.</block>
  <block id="52df26383575ad500acf38cc3df88e36" category="cell">*aws_connector_iam_instance_profile_name*</block>
  <block id="59409115b42184ffa519bd9aa24b6816" category="cell">(Obbligatorio) il nome del profilo di istanza per il connettore.</block>
  <block id="8953ca5d18d5f2c4a85fdfe10d30a002" category="cell">*aws_connector_account_id*</block>
  <block id="bba7484e58b18e8edafdbe619961f73f" category="cell">(Facoltativo) l'ID dell'account NetApp a cui verrà associato il connettore. Se non viene fornito, Cloud Manager utilizza il primo account. Se non esiste alcun account, Cloud Manager crea un nuovo account. L'ID dell'account è disponibile nella scheda account di Cloud Manager all'indirizzo<block ref="06d3516203a7f4d79163d93dd508b8c0" category="inline-link-rx"></block>.</block>
  <block id="1918f44c178eed586b6fa7d6739af317" category="cell">*aws_connector_public_ip_bool*</block>
  <block id="a4472307f162bdf147f02784bf81ab9d" category="cell">(Facoltativo) indica se associare un indirizzo IP pubblico all'istanza. Se non viene fornito, l'associazione viene eseguita in base alla configurazione della subnet.</block>
  <block id="9fb01bbff06d549bce01928fa2f7784c" category="paragraph"><block ref="2642a0976dba96af7529d6e1d27bff5f" prefix="" category="inline-code"></block></block>
  <block id="d166b6e004666a5a8daa6db1c3cf1a13" category="paragraph">Variabili di terraform per singola istanza CVO di NetApp.</block>
  <block id="19afa3a1ac092d450f21236f1973c705" category="cell">*cvo_name*</block>
  <block id="59935a520838700b451a3757f31fd4ac" category="cell">(Obbligatorio) il nome dell'ambiente di lavoro Cloud Volumes ONTAP.</block>
  <block id="ff855355eebbbfbd54d2734a61c43fd4" category="cell">*cvo_region*</block>
  <block id="b50ada32f992aba9f7055658a79132f2" category="cell">(Obbligatorio) la regione in cui verrà creato l'ambiente di lavoro.</block>
  <block id="0e9b90f836062c3007935370ef18245f" category="cell">*cvo_subnet_id*</block>
  <block id="6c7cb9b4623284c101253ed002625e53" category="cell">(Obbligatorio) l'id della subnet in cui verrà creato l'ambiente di lavoro.</block>
  <block id="a99ec45accc4987a7eb2eff5219f96b3" category="cell">*cvo_vpc_id*</block>
  <block id="a179f6c6854fc89c6f118f4d8c201cad" category="cell">(Facoltativo) l'ID VPC in cui verrà creato l'ambiente di lavoro. Se questo argomento non viene fornito, il VPC verrà calcolato utilizzando l'ID di sottorete fornito.</block>
  <block id="26ff13994e5fbad1e11fc231bc73a5b6" category="cell">*cvo_svm_password*</block>
  <block id="c82a889260bdc28c6136ddc6639a4f2e" category="cell">(Obbligatorio) la password admin per Cloud Volumes ONTAP.</block>
  <block id="3815749b59fbccfa0077df4f90c8aa1e" category="cell">*cvo_writing_speed_state*</block>
  <block id="e382698236dcb1567d375a4be3b12c2f" category="cell">(Facoltativo) impostazione della velocità di scrittura per Cloud Volumes ONTAP: ['NORMAL','HIGH']. L'impostazione predefinita è 'NORMALE'.</block>
  <block id="197b0ef64aabdc02a240f3f472eb4da2" category="open-title">Implementazione CVO ha</block>
  <block id="93726ca0be25ac3bef0f54da1e20751c" category="paragraph-title">File di configurazione del terraform per l'implementazione di NetApp CVO (coppia ha) su AWS</block>
  <block id="a082a9d97b4465f73e12cde3444a5296" category="paragraph">Questa sezione contiene diversi file di configurazione del terraform per implementare/configurare NetApp CVO (Cloud Volumes ONTAP) in coppia ad alta disponibilità su AWS (Amazon Web Services).</block>
  <block id="b31736be0fe5e59cc4905aa080c9ab16" category="list-text">Aggiornare i valori delle variabili in<block ref="d8fbe289f1062e79a6ecf2cb41d4650c" prefix=" " category="inline-code"></block>.</block>
  <block id="ff8f4d628633e3ceb42dcca91ef2948e" category="paragraph"><block ref="c6f18f9568d343bc6accef19de501a79" prefix="" category="inline-code"></block></block>
  <block id="f7fbe4e66ae4cece99ae14a24f1c44ef" category="paragraph">Variabili di terraform per istanze NetApp CVO in coppia ha.</block>
  <block id="018a56af12514193b08f44d59f92fe83" category="cell">*cvo_is_ha*</block>
  <block id="93d83a3a243548e55fb126d283923435" category="cell">(Facoltativo) indica se l'ambiente di lavoro è una coppia ha o meno [vero, falso]. L'impostazione predefinita è false.</block>
  <block id="cea330e4ead03fcfec439b1f44be7c07" category="cell">*cvo_node1_subnet_id*</block>
  <block id="3a0cbf54e2a847cd873a45840f9965f5" category="cell">(Obbligatorio) l'id della subnet in cui verrà creato il primo nodo.</block>
  <block id="d5d3a5e1275b1995e05472c7bfbcb53f" category="cell">*cvo_node2_subnet_id*</block>
  <block id="5691678a4c059b3a4ebad0f4c6bf6bb5" category="cell">(Obbligatorio) l'id della subnet in cui verrà creato il secondo nodo.</block>
  <block id="4377aa272f4cf89d4bbd39432ffb3b0e" category="cell">*cvo_failover_mode*</block>
  <block id="9d76030e2a28826bff45ea1dff4d6920" category="cell">(Facoltativo) per ha, la modalità di failover per la coppia ha: ['PrivateIP', 'FloatingIP']. 'PrivateIP' è per una singola zona di disponibilità e 'FloatingIP' è per più zone di disponibilità.</block>
  <block id="80c8a57adaed641642cd870951a1d4ed" category="cell">*cvo_mediator_subnet_id*</block>
  <block id="49ef0197555436f78dd87f582e510523" category="cell">(Facoltativo) per ha, l'ID subnet del mediatore.</block>
  <block id="3efb524d034b1e223cb9d31a64f9bbc4" category="cell">*cvo_mediator_key_pair_name*</block>
  <block id="224733036290c1421bed8ad8de688956" category="cell">(Facoltativo) per ha, il nome della coppia di chiavi per l'istanza del mediatore.</block>
  <block id="069dcc590a2acf756e6ca7f92d7d8355" category="cell">*cvo_cluster_floating_ip*</block>
  <block id="6325a8aefd56c67fab1d0d83b4cb8a2e" category="cell">(Facoltativo) per ha FloatingIP, l'indirizzo IP mobile per la gestione del cluster.</block>
  <block id="618070e07e603612f24fa88a7ab583a8" category="cell">*cvo_data_floating_ip*</block>
  <block id="d8abdbcf87e3308c6a8e731ef574625c" category="cell">(Facoltativo) per ha FloatingIP, l'indirizzo IP mobile dei dati.</block>
  <block id="f115ec8cf476ea0198405ca27346e423" category="cell">*cvo_data_floating_ip2*</block>
  <block id="754296c6c8a8cf70377730f6f126f24a" category="cell">*cvo_svm_floating_ip*</block>
  <block id="797d132b963a11de245eae1725911bfe" category="cell">(Opzionale) per ha FloatingIP, l'indirizzo IP mobile di gestione SVM.</block>
  <block id="418ba9c064c1fb64b11195c729d6a8b1" category="cell">*cvo_route_table_ids*</block>
  <block id="4ee29ca12c7d126654bd0e5275de6135" category="cell">Elenco</block>
  <block id="671a800e3791f7531a319e8b81e97c44" category="cell">(Facoltativo) per ha FloatingIP, l'elenco degli ID della tabella di routing che verranno aggiornati con gli IP mobili.</block>
  <block id="5d4a46c0a4567f819ba5935256b18297" category="open-title">Implementazione di FSX</block>
  <block id="99661bfb937ca0c49c78878d8d2b0e77" category="paragraph-title">File di configurazione del terraform per l'implementazione di NetApp ONTAP FSX su AWS</block>
  <block id="d43e39ffb05b35b72664b10dd8b8eb09" category="paragraph">Questa sezione contiene diversi file di configurazione del terraform per implementare/configurare NetApp ONTAP FSX su AWS (Amazon Web Services).</block>
  <block id="171cc8e4954beec5176905189f71a708" category="list-text">Formato di output predefinito [Nessuno]:</block>
  <block id="cbc2cee2851524f322f8d71e55d32a64" category="list-text">Aggiornare i valori delle variabili in<block ref="15f7e426a035ec7faf6715523364f143" prefix=" " category="inline-code"></block></block>
  <block id="1538b268d8f3b010dea63370c1a65935" category="paragraph-title">Ricette:</block>
  <block id="05bf1719b762d4d80bcb0e545b3db1d2" category="paragraph">Variabili di terraform per l'istanza di NetApp AWS Connector.</block>
  <block id="618716470abe9536903f3c6781c4ac81" category="paragraph"><block ref="8fa643108c81bb359c39d110fa732b76" prefix="" category="inline-code"></block></block>
  <block id="5869d95322d3c435fd999596f0cf2303" category="paragraph">Variabili di terraform per l'istanza FSX di NetApp ONTAP.</block>
  <block id="c64f672849455d583204c525f5ea39ad" category="cell">*fsx_name*</block>
  <block id="af87bb54b839634f865f7bd7e2be203a" category="cell">*fsx_region*</block>
  <block id="02a52209be6996bc01fd629ac6a5b472" category="cell">*fsx_primary_subnet_id*</block>
  <block id="5dcd0d05819e117f52d439bebd6d2b42" category="cell">(Obbligatorio) l'id della subnet primaria in cui verrà creato l'ambiente di lavoro.</block>
  <block id="0531247f461759a809214a03ea2f5f74" category="cell">*fsx_id_subnet_secondaria*</block>
  <block id="b2184e9a131868dbc2332805652a0f02" category="cell">(Obbligatorio) l'id della subnet secondaria in cui verrà creato l'ambiente di lavoro.</block>
  <block id="a333cc205644905efae2cf71519da619" category="cell">*fsx_account_id*</block>
  <block id="323c4fdc16ad2dd9e846afbcd4b69b10" category="cell">(Obbligatorio) l'ID dell'account NetApp a cui verrà associata l'istanza FSX. Se non viene fornito, Cloud Manager utilizza il primo account. Se non esiste alcun account, Cloud Manager crea un nuovo account. L'ID dell'account è disponibile nella scheda account di Cloud Manager all'indirizzo<block ref="06d3516203a7f4d79163d93dd508b8c0" category="inline-link-rx"></block>.</block>
  <block id="7355bef79bff8e33a86af33fe4dcca8e" category="cell">*fsx_workspace_id*</block>
  <block id="97377fef3f33f9c8d1fb21c0d81cdf92" category="cell">(Obbligatorio) l'ID dello spazio di lavoro Cloud Manager dell'ambiente di lavoro.</block>
  <block id="ab77fdca353b13807c947d554712d8eb" category="cell">*fsx_admin_password*</block>
  <block id="c4bd49cb0034d697fd71cae233c3966c" category="cell">*fsx_throughput_capacity*</block>
  <block id="e1ae53e33bf94a13f7d73cf885059ea6" category="cell">(Opzionale) capacità del throughput.</block>
  <block id="011dda542c81d29bda593f0cf6fafdfa" category="cell">*fsx_storage_capacity_size*</block>
  <block id="16b74c686b794890297f7ff7a9c98c9f" category="cell">(Opzionale) dimensione del volume EBS per il primo aggregato di dati. Per GB, l'unità può essere: [100 o 500]. Per i TB, l'unità può essere: [1,2,4,8,16]. Il valore predefinito è '1'</block>
  <block id="da7d44d0ad606f586a3b1f567c8502d6" category="cell">*fsx_storage_capacity_size_unit*</block>
  <block id="5ec54d3d7d1db9fbf915daed12667b29" category="cell">(Opzionale) ['GB' o 'TB']. Il valore predefinito è 'TB'.</block>
  <block id="07cc738168b47a86b740bc01e210b442" category="cell">*fsx_cloud_manager_aws_credential_name*</block>
  <block id="48dbb4d925fe4a46f28c0a8466a2f628" category="cell">(Obbligatorio) il nome dell'account AWS Credentials.</block>
  <block id="3a580f142203677f1f0bc30898f63f53" category="example-title">Azure</block>
  <block id="0d6f6c74055e04156e36ddb127070a54" category="open-title">AN</block>
  <block id="107933ea485144e916f16cd69884fea6" category="paragraph-title">File di configurazione del terraform per l'implementazione di ANF Volume su Azure</block>
  <block id="3f5bad999be275e4e9cf0728a13bf09c" category="paragraph">Questa sezione contiene diversi file di configurazione del terraform per implementare/configurare il volume ANF (Azure NetApp Files) su Azure.</block>
  <block id="61d66a29b98e4203b3fc2ea2884a6c5f" category="paragraph">Documentazione terraform:<block ref="745f55dd9f8ecc62d59e6b03ca9efbb7" category="inline-link-rx"></block></block>
  <block id="369baedac810ebc745ed2edf7754972b" category="list-text">Accedere all'interfaccia CLI di Azure (Azure CLI deve essere installato).</block>
  <block id="443ff7602b19f9692863937e763e1ad2" category="list-text">Aggiornare i valori delle variabili in<block ref="8c39601b8ab8961ff411cd5068a67f11" prefix=" " category="inline-code"></block>.</block>
  <block id="95f6ca118177fad8a1dd7e7abb74ce56" category="admonition">È possibile scegliere di implementare il volume ANF utilizzando una rete virtuale e una subnet esistenti impostando i valori delle variabili "vnet_creation_bool" e "subnet_creation_bool" su false e fornendo "subnet_id_for_ANF_vol". È inoltre possibile impostare questi valori su true e creare una nuova rete virtuale e una nuova subnet. In questo caso, l'ID della subnet verrà automaticamente prelevato dalla nuova subnet creata.</block>
  <block id="cb01f53471a55574a36eafb375d9493a" category="paragraph">Variabili di terraform per un singolo volume NetApp ANF.</block>
  <block id="98bcef9bf5f44342e688bc29fb3fcbca" category="cell">*az_location*</block>
  <block id="4b05afb76d83065313c3740cd392a5ca" category="cell">(Obbligatorio) specifica la posizione di Azure supportata in cui esiste la risorsa. La modifica di questo valore impone la creazione di una nuova risorsa.</block>
  <block id="861c040d5ed0212e4bc2aa4f92a2b861" category="cell">*az_prefix*</block>
  <block id="e6f149d38df85bed35faeca44370c01c" category="cell">(Obbligatorio) il nome del gruppo di risorse in cui deve essere creato il volume NetApp. La modifica di questo valore impone la creazione di una nuova risorsa.</block>
  <block id="7aa7ec2fc803d9041e6dfd5e142dcd23" category="cell">*az_vnet_address_space*</block>
  <block id="c8b090fd446e4181ed79e8e50bed7b91" category="cell">(Obbligatorio) lo spazio degli indirizzi utilizzato dal vnet appena creato per l'implementazione del volume ANF.</block>
  <block id="c5b9420927a71e0bcd6f4c621c66910f" category="cell">*az_subnet_address_prefix*</block>
  <block id="94c126b468fd9c408abdff2cccd827a4" category="cell">(Obbligatorio) il prefisso dell'indirizzo di sottorete da utilizzare per la nuova vnet creata per l'implementazione del volume ANF.</block>
  <block id="3c3133cb45a10a4ec442a4589636bfe1" category="cell">*az_volume_path*</block>
  <block id="c8fb8ccec1ede566cac7b410b7623186" category="cell">(Obbligatorio) un percorso di file univoco per il volume. Utilizzato per la creazione di destinazioni di montaggio. La modifica di questo valore impone la creazione di una nuova risorsa.</block>
  <block id="5e51835c1dd28fa3cab3636a6beb8016" category="cell">*az_capacity_pool_size*</block>
  <block id="a0faef0851b4294c06f2b94bb1cb2044" category="cell">Intero</block>
  <block id="0db20ddc31a427cc02802395aa53db7f" category="cell">(Obbligatorio) dimensione del pool di capacità indicata in TB.</block>
  <block id="32c4a6ca695ae0fd3f41efe5ab8d3ffc" category="cell">*az_vnet_creation_bool*</block>
  <block id="27226c864bac7454a8504f8edb15d95b" category="cell">Booleano</block>
  <block id="55a1cc8d235c0ca9bd0cf384e2db1fb2" category="cell">(Obbligatorio) impostare questo booleano su<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> se si desidera creare un nuovo vnet. Impostarlo su<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> per utilizzare un vnet esistente.</block>
  <block id="be85fde9f0fcdf86be8ede4b5939a9bf" category="cell">*az_subnet_creation_bool*</block>
  <block id="4b079d5e017c7403047fbbd37df93368" category="cell">(Obbligatorio) impostare questo booleano su<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> per creare una nuova subnet. Impostarlo su<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> per utilizzare una subnet esistente.</block>
  <block id="bb74e9c4e24089c59a6af0a7a016b586" category="cell">*az_subnet_id_for_anf_vol*</block>
  <block id="52c0fe6a129fdcf33be82680a15b2d37" category="cell">(Obbligatorio) indicare l'id subnet nel caso in cui si decida di utilizzare una subnet esistente mediante l'impostazione<block ref="1cceaecaa3b91a9f1e23ecb4681ce8af" prefix=" " category="inline-code"></block> a vero. Se impostata su false, lasciare il valore predefinito.</block>
  <block id="8376cf4b94c63b51d5e0113c299a75a0" category="cell">*az_netapp_pool_service_level*</block>
  <block id="061fce6317efb41fcda88b5333cb0cc2" category="cell">(Obbligatorio) le prestazioni di destinazione del file system. I valori validi includono<block ref="8d5e7e72f12067991186cdf3cb7d5d9d" prefix=" " category="inline-code"></block> ,<block ref="eb6d8ae6f20283755b339c0dc273988b" prefix=" " category="inline-code"></block> , o.<block ref="7057376a419b3334cc7b8b7a9f064abb" prefix=" " category="inline-code"></block>.</block>
  <block id="cd145efde532a4a27c5b6687f4b5f1c0" category="cell">*az_netapp_vol_service_level*</block>
  <block id="d655c67b837d5b3363d556955802b670" category="cell">*az_netapp_vol_protocol*</block>
  <block id="9e2a44ac250e0b60bce77fba70ebfd70" category="cell">(Facoltativo) il protocollo del volume di destinazione espresso come elenco. Il valore singolo supportato include<block ref="c6546b53840ec8245dd4d4d70fcdbc26" prefix=" " category="inline-code"></block>,<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block>, o.<block ref="de841868c2911da76b8ae2da9fa3166d" prefix=" " category="inline-code"></block>. Se l'argomento non è definito, l'impostazione predefinita è<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block>. La modifica di questo valore impone la creazione di una nuova risorsa e la perdita dei dati.</block>
  <block id="cac15590a2775bfeaf5f70c36186a840" category="cell">*az_netapp_vol_security_style*</block>
  <block id="80f43a817b6716a1a82af5fe18f178cd" category="cell">(Facoltativo) stile di sicurezza del volume, i valori accettati sono<block ref="6ec1bd1ea6a5d67a63b20c8f6172bddd" prefix=" " category="inline-code"></block> oppure<block ref="0984cd69051e659a6125cdff72c4996d" prefix=" " category="inline-code"></block>. Se non viene fornito, viene creato un volume a protocollo singolo per impostazione predefinita<block ref="6ec1bd1ea6a5d67a63b20c8f6172bddd" prefix=" " category="inline-code"></block> in caso affermativo<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block> oppure<block ref="de841868c2911da76b8ae2da9fa3166d" prefix=" " category="inline-code"></block> volume, se<block ref="c6546b53840ec8245dd4d4d70fcdbc26" prefix=" " category="inline-code"></block>per impostazione predefinita, l'impostazione predefinita è<block ref="0984cd69051e659a6125cdff72c4996d" prefix=" " category="inline-code"></block>. In un volume a doppio protocollo, se non fornito, il valore sarà<block ref="0984cd69051e659a6125cdff72c4996d" prefix=" " category="inline-code"></block>.</block>
  <block id="b095a46d015fe5581a97472eedb3e645" category="cell">*az_netapp_vol_storage_quota*</block>
  <block id="aaff31e02103a31c6f08943798a84789" category="cell">(Obbligatorio) la quota massima di storage consentita per un file system in gigabyte.</block>
  <block id="7bc40f4d4f846e8c7177d752ac52b775" category="open-title">PROTEZIONE dei dati ANF</block>
  <block id="c2d6144ea47815bb9e1c4e09c0918486" category="paragraph-title">File di configurazione del terraform per l'implementazione di ANF Volume con Data Protection su Azure</block>
  <block id="56978261632f1f36ad5f3f3ea6d2cb4b" category="paragraph">Questa sezione contiene diversi file di configurazione del terraform per implementare/configurare il volume ANF (Azure NetApp Files) con protezione dei dati su Azure.</block>
  <block id="9b3e184737a0a337479622611ba072b7" category="list-text">Aggiornare i valori delle variabili in<block ref="7faa6da7e229d163db53602f424f1f82" prefix=" " category="inline-code"></block>.</block>
  <block id="bf052e3d77cd2cde5fa905542df51c46" category="paragraph"><block ref="7bc40f4d4f846e8c7177d752ac52b775" prefix="" category="inline-code"></block></block>
  <block id="c47acd947f63c78f7729c5c176778d53" category="paragraph">Variabili di terraform per un singolo volume ANF con protezione dei dati attivata.</block>
  <block id="17745d8782266e5f08c77485447c8727" category="cell">*az_alt_location*</block>
  <block id="3bfeadf4c47a658ca94a6066aee32aaa" category="cell">(Obbligatorio) la posizione di Azure in cui verrà creato il volume secondario</block>
  <block id="2558355ccfd79f11c2c7771d473c28a9" category="cell">*az_vnet_primary_address_space*</block>
  <block id="cc551875f8711aaffc6141f504677c0b" category="cell">(Obbligatorio) lo spazio degli indirizzi utilizzato dal vnet appena creato per l'implementazione del volume primario ANF.</block>
  <block id="ea5f0cd471c631d7531bb7fd3b5bac8a" category="cell">*az_vnet_secondary_address_space*</block>
  <block id="fffcb59495331e54049ce33d3dcdf943" category="cell">(Obbligatorio) lo spazio degli indirizzi utilizzato dal vnet appena creato per l'implementazione del volume secondario ANF.</block>
  <block id="88220764f0745e8a07a6578ee5a34962" category="cell">*az_subnet_primary_address_prefix*</block>
  <block id="02b00c599f6c249474a4fa82513b5ae3" category="cell">(Obbligatorio) il prefisso dell'indirizzo di sottorete da utilizzare per la nuova vnet creata per l'implementazione del volume primario ANF.</block>
  <block id="1bef049d5f330664e35cad0a064c3b9c" category="cell">*az_subnet_secondary_address_prefix*</block>
  <block id="1b60506e52e47ecc443e5be52dca93d7" category="cell">(Obbligatorio) il prefisso dell'indirizzo di sottorete da utilizzare per la nuova vnet creata per l'implementazione del volume secondario ANF.</block>
  <block id="897362b63a34b0eb8e1453709c1f8403" category="cell">*az_volume_path_primary*</block>
  <block id="1240d8345e0d2e3e79133040103d900c" category="cell">(Obbligatorio) un percorso di file univoco per il volume primario. Utilizzato per la creazione di destinazioni di montaggio. La modifica di questo valore impone la creazione di una nuova risorsa.</block>
  <block id="b9dd6d654f6dd5777451c38ccbb3a90f" category="cell">*az_volume_path_secondary*</block>
  <block id="2d48913a4e9f87154afa26a5629292ac" category="cell">(Obbligatorio) un percorso file univoco per il volume secondario. Utilizzato per la creazione di destinazioni di montaggio. La modifica di questo valore impone la creazione di una nuova risorsa.</block>
  <block id="06c1e84417c5bf369b90b26dd5249917" category="cell">*az_capacity_pool_size_primary*</block>
  <block id="3d618d26614058ac7e5a064cbe202b90" category="cell">*az_capacity_pool_size_secondary*</block>
  <block id="900391b8f681698a00a1d7681c809eae" category="cell">*az_vnet_primary_creation_bool*</block>
  <block id="ee71ed057be46b5303595075681242b3" category="cell">(Obbligatorio) impostare questo booleano su<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> se si desidera creare un nuovo vnet per il volume primario. Impostarlo su<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> per utilizzare un vnet esistente.</block>
  <block id="1f3233bfcd515798625102d02489c9c2" category="cell">*az_vnet_secondary_creation_bool*</block>
  <block id="8a5a92fb6843cb45a9752dac34d8056a" category="cell">(Obbligatorio) impostare questo booleano su<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> se si desidera creare un nuovo vnet per il volume secondario. Impostarlo su<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> per utilizzare un vnet esistente.</block>
  <block id="0276da5ab0cbfd3afccac3236ff88906" category="cell">*az_subnet_primary_creation_bool*</block>
  <block id="ba2f66ccca4d07fb389900a4c72596a7" category="cell">(Obbligatorio) impostare questo booleano su<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> per creare una nuova subnet per il volume primario. Impostarlo su<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> per utilizzare una subnet esistente.</block>
  <block id="78a2830c902a8a1eb6bbedc95b8e859d" category="cell">*az_subnet_secondary_creation_bool*</block>
  <block id="1b869ff43f405cb5056d067f1ce0ea2c" category="cell">(Obbligatorio) impostare questo booleano su<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> per creare una nuova subnet per il volume secondario. Impostarlo su<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> per utilizzare una subnet esistente.</block>
  <block id="004f2f461ceadcb0d344b03f2f00c53d" category="cell">*az_primary_subnet_id_for_anf_vol*</block>
  <block id="387a4516572f71aa24490f3bbfc695ef" category="cell">(Obbligatorio) indicare l'id subnet nel caso in cui si decida di utilizzare una subnet esistente mediante l'impostazione<block ref="4480e01b6ddc0f64d89a995dcbd413f6" prefix=" " category="inline-code"></block> a vero. Se impostata su false, lasciare il valore predefinito.</block>
  <block id="2e9685846dda27855273fdf064f9e6ab" category="cell">*az_secondary_subnet_id_for_anf_vol*</block>
  <block id="bf5c8bfc6d7cc2d5fe6e7931244a30eb" category="cell">(Obbligatorio) indicare l'id subnet nel caso in cui si decida di utilizzare una subnet esistente mediante l'impostazione<block ref="963bc6d7f5ebc59003b8ef8f3f92a02c" prefix=" " category="inline-code"></block> a vero. Se impostata su false, lasciare il valore predefinito.</block>
  <block id="ac839f935b4bbb6bed9bda28a8e642c6" category="cell">*az_netapp_pool_service_level_primary*</block>
  <block id="8cb34f1d64a5bf358b0d3a349ca5bc2f" category="cell">*az_netapp_pool_service_level_secondary*</block>
  <block id="7ad9306273877be4925eef5c298c8082" category="cell">*az_netapp_vol_service_level_primary*</block>
  <block id="5614656fa00c06faf1c3484531a679a9" category="cell">*az_netapp_vol_service_level_secondary*</block>
  <block id="4f517398039e7c48806d41487b9419bc" category="cell">*az_netapp_vol_protocol_primary*</block>
  <block id="82b777cb90770b16388fa42e12e046ab" category="cell">*az_netapp_vol_protocol_secondary*</block>
  <block id="59783d86d863461df5e6d03ac2bb42df" category="cell">*az_netapp_vol_storage_quota_primaria*</block>
  <block id="de8fa216337d1b3497efb08ceeb2ba75" category="cell">*az_netapp_vol_storage_quota_secondaria*</block>
  <block id="0b11ea56e0e5211214ff431c4e076717" category="cell">*az_dp_replication_frequency*</block>
  <block id="79ce3fc5fe45b145bb343376fe5351b9" category="cell">(Obbligatorio) frequenza di replica, i valori supportati sono<block ref="3602ffca95e52ce3f66ae1c6de108997" prefix=" " category="inline-code"></block>,<block ref="745fd0ea7f576f350a0eed4b8c48a8e2" prefix=" " category="inline-code"></block>,<block ref="bea79186fd7af2da67e59b4b15df5a26" prefix=" " category="inline-code"></block>, i valori distinguono tra maiuscole e minuscole.</block>
  <block id="c623b4e11f7cb20ff0b7c24a72d3f0ef" category="open-title">ANF Dual Protocol</block>
  <block id="1ed1215fce9948e3bee78c99bf12de8d" category="paragraph-title">File di configurazione del terraform per l'implementazione di ANF Volume con doppio protocollo su Azure</block>
  <block id="d25220d03f7afcb6f5edcbc46e369d45" category="paragraph">Questa sezione contiene diversi file di configurazione del terraform per implementare/configurare il volume ANF (Azure NetApp Files) con il protocollo doppio attivato su Azure.</block>
  <block id="9568461c901e88398bed16e11ad813d3" category="list-text">Aggiornare i valori delle variabili in<block ref="b81cd75a858f9c9f13b2c366b4254eea" prefix=" " category="inline-code"></block>.</block>
  <block id="d263b475ab751de671d08455b33997c1" category="paragraph">Variabili di terraform per volume ANF singolo con protocollo doppio attivato.</block>
  <block id="b183512797a1d9ea69a8dab9e27df52c" category="cell">*az_netapp_vol_protocol1*</block>
  <block id="20fd02f6a193c7aeaee651654a332933" category="cell">(Obbligatorio) il protocollo del volume di destinazione espresso come elenco. Il valore singolo supportato include<block ref="c6546b53840ec8245dd4d4d70fcdbc26" prefix=" " category="inline-code"></block>,<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block>, o.<block ref="de841868c2911da76b8ae2da9fa3166d" prefix=" " category="inline-code"></block>. Se l'argomento non è definito, l'impostazione predefinita è<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block>. La modifica di questo valore impone la creazione di una nuova risorsa e la perdita dei dati.</block>
  <block id="cc032be5baf5b9484eb2d659f4e314c6" category="cell">*az_netapp_vol_protocol2*</block>
  <block id="910944ff76e7b2acfc482a34501df6f5" category="cell">*az_smb_server_username*</block>
  <block id="152372e48ac8f85f2e4908c5a1489a78" category="cell">(Obbligatorio) Nome utente per creare un oggetto ActiveDirectory.</block>
  <block id="239e5edf090c4c70025b340f651694cc" category="cell">*az_smb_server_password*</block>
  <block id="7b05e834084d190fe540481374f4fe0d" category="cell">(Obbligatorio) User Password (Password utente) per creare un oggetto ActiveDirectory.</block>
  <block id="4e2be381ec92158458ceef11bdf41ef7" category="cell">*az_smb_server_name*</block>
  <block id="533dd582bfe3528b9b6ae4ff1889bd8f" category="cell">(Obbligatorio) Nome server per creare un oggetto ActiveDirectory.</block>
  <block id="f17c01535ba9f04720700d5e0d17172a" category="cell">*az_smb_dns_servers*</block>
  <block id="e70256203c6e23fcee3efa8d56fcfa85" category="cell">(Obbligatorio) IP del server DNS per creare un oggetto ActiveDirectory.</block>
  <block id="bdf618611712c6caa6fd0340470ee9f2" category="open-title">VOLUME ANF da snapshot</block>
  <block id="15b915279743f1a43ce2c0f10062e69e" category="paragraph-title">File di configurazione del terraform per l'implementazione di volumi ANF da Snapshot su Azure</block>
  <block id="174e6e8f24023c93c7c470267f4c2376" category="paragraph">Questa sezione contiene diversi file di configurazione del terraform per implementare/configurare il volume ANF (Azure NetApp Files) da Snapshot su Azure.</block>
  <block id="215d5ed09cbe3ca5b10c6d616024053a" category="list-text">Aggiornare i valori delle variabili in<block ref="ef9d672e94eee49d10d74f858a44d14f" prefix=" " category="inline-code"></block>.</block>
  <block id="a753ff452c91c6e4de63b907e8253e05" category="paragraph">Variabili di terraform per un singolo volume ANF utilizzando snapshot.</block>
  <block id="57bd49c8f9a43967f48ec8f1f3ca2846" category="cell">*az_snapshot_id*</block>
  <block id="ff461cb79e6adda28ae488782f0da97f" category="cell">(Obbligatorio) Snapshot ID con il quale verrà creato il nuovo volume ANF.</block>
  <block id="664b1f8a02a683b16bb76004afb03be2" category="paragraph-title">File di configurazione del terraform per l'implementazione di un CVO a nodo singolo su Azure</block>
  <block id="ca7ce11916c29a2c94b4fd33dc0b6313" category="paragraph">Questa sezione contiene diversi file di configurazione del terraform per implementare/configurare CVO a nodo singolo (Cloud Volumes ONTAP) su Azure.</block>
  <block id="04107ff6b0460381c55ff620a1021254" category="list-text">Aggiornare le variabili in<block ref="094639eff38e0172690a0fb13cd97348" prefix=" " category="inline-code"></block>.</block>
  <block id="73b95097cc4819b49af28734c8da85f9" category="paragraph">Variabili di terraform per il CVO (Single Node Cloud Volumes ONTAP).</block>
  <block id="3226e634f46cb19ab313171144dd34bd" category="cell">*refresh_token*</block>
  <block id="d687ff26916f17fd879c87b138961b29" category="cell">(Obbligatorio) il token di refresh di NetApp Cloud Manager. Questo può essere generato da netapp Cloud Central.</block>
  <block id="2c64afa8a46290b632eba256c644932c" category="cell">*az_connector_name*</block>
  <block id="3eb8706ea09733709f78eddf34865fc5" category="cell">*az_connector_location*</block>
  <block id="758699b195f5916d500521462cf30da9" category="cell">(Obbligatorio) la posizione in cui verrà creato Cloud Manager Connector.</block>
  <block id="1fab22f54c2298a6c193e9dbf02a5f40" category="cell">*az_connector_subscription_id*</block>
  <block id="3eaa20b60039584fbaada041b1e9c27b" category="cell">(Obbligatorio) l'ID dell'abbonamento Azure.</block>
  <block id="15a22866556f3e50073015243ddd7953" category="cell">*az_connector_company*</block>
  <block id="d6da30a455e4a736b78aebafd5a574ec" category="cell">*az_connector_resource_group*</block>
  <block id="7869ff24b2017b68dfcffe9346969d04" category="cell">(Obbligatorio) il gruppo di risorse in Azure dove verranno create le risorse.</block>
  <block id="9ddf31c7bd196ef12b5afc14819332ae" category="cell">*az_connector_subnet_id*</block>
  <block id="a41a332f5c3dda90835d004d4471e0a8" category="cell">(Obbligatorio) il nome della subnet della macchina virtuale.</block>
  <block id="dabe6b258248c0eefb5e7f8ef812c828" category="cell">*az_connector_vnet_id*</block>
  <block id="5209c2acb9f23446cfa41482e2ff8ee2" category="cell">(Obbligatorio) il nome della rete virtuale.</block>
  <block id="d00bbff7436422db546132791ca30dd2" category="cell">*az_connector_network_security_group_name*</block>
  <block id="b5033b19e9c2388be995930fb1c49365" category="cell">(Obbligatorio) il nome del gruppo di protezione per l'istanza.</block>
  <block id="54dee4dedf4b10ae9a250e887c349324" category="cell">*az_connector_associate_public_ip_address*</block>
  <block id="c954a4a98e68d0734dcd6d7ad00db3f5" category="cell">(Obbligatorio) indica se associare l'indirizzo IP pubblico alla macchina virtuale.</block>
  <block id="d363651cb914dfbc47f512db8ce8a9c0" category="cell">*az_connector_account_id*</block>
  <block id="53b73bbe0bca0a3d51fbda15ecc058db" category="cell">(Obbligatorio) l'ID dell'account NetApp a cui verrà associato il connettore. Se non viene fornito, Cloud Manager utilizza il primo account. Se non esiste alcun account, Cloud Manager crea un nuovo account. L'ID dell'account è disponibile nella scheda account di Cloud Manager all'indirizzo<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="b851f892237fb399ca9999caee142ccf" category="cell">*az_connector_admin_password*</block>
  <block id="aa98915ce83ffe89562020e5b4d9a376" category="cell">(Obbligatorio) la password per il connettore.</block>
  <block id="1b9c1e319401f16966d7280c81cdc8dc" category="cell">*az_connector_admin_username*</block>
  <block id="e0f32faffed9caaca61e86caae050f17" category="cell">(Obbligatorio) il nome utente del connettore.</block>
  <block id="425624e10c5de04d471a55e4a8b35e31" category="cell">*az_cvo_name*</block>
  <block id="52ebf6980a494c352ee150c2b801af6e" category="cell">*az_cvo_location*</block>
  <block id="7bd8d7a58d3957cf7697ceb3467bffae" category="cell">(Obbligatorio) la posizione in cui verrà creato l'ambiente di lavoro.</block>
  <block id="8da06548b40415fd473a86a6dba80f82" category="cell">*az_cvo_subnet_id*</block>
  <block id="a5ab436e757f5af2106d5ed5e5dd9df0" category="cell">(Obbligatorio) il nome della subnet per il sistema Cloud Volumes ONTAP.</block>
  <block id="f71ced0388b772479b4e5fba15c83077" category="cell">*az_cvo_vnet_id*</block>
  <block id="7d2219b61301dda6352db570bb7c5034" category="cell">*az_cvo_vnet_resource_group*</block>
  <block id="fecf56abdc6b5472c8da399cad7791b3" category="cell">(Obbligatorio) il gruppo di risorse in Azure associato alla rete virtuale.</block>
  <block id="c63d2e90acb0448db277b1b5b8a8d1fa" category="cell">*az_cvo_data_encryption_type*</block>
  <block id="e472a1445850887a7f62ae832b27693a" category="cell">(Obbligatorio) il tipo di crittografia da utilizzare per l'ambiente di lavoro: <block ref="71335a48a021ae2aeb7df636ba3d2483" prefix="[" category="inline-code"></block>,<block ref="b50339a10e1de285ac99d4c3990b8693" prefix=" " category="inline-code"></block>]. L'impostazione predefinita è<block ref="71335a48a021ae2aeb7df636ba3d2483" prefix=" " category="inline-code"></block>.</block>
  <block id="a09db82d06138c721102bb24bf44745c" category="cell">*az_cvo_storage_type*</block>
  <block id="0f0f84813d06e378040fbcf33a733c2c" category="cell">(Obbligatorio) tipo di storage per il primo aggregato di dati: <block ref="31034b38323b8bba82b33017ce6c13ff" prefix="[" category="inline-code"></block>,<block ref="410e42479a4a7cfdbe16e3e285d05598" prefix=" " category="inline-code"></block>,<block ref="2d641bc6cd6c1342dced281e583a3993" prefix=" " category="inline-code"></block>]. L'impostazione predefinita è<block ref="31034b38323b8bba82b33017ce6c13ff" prefix=" " category="inline-code"></block></block>
  <block id="2dc6453586c69ea950eec68d5ac9658c" category="cell">*az_cvo_svm_password*</block>
  <block id="404c8599d393a19d0cd6354f8b6ae58c" category="cell">*az_cvo_workspace_id*</block>
  <block id="ec0d845babe316d32a485960e8788bd0" category="cell">(Obbligatorio) l'ID dello spazio di lavoro di Cloud Manager in cui si desidera implementare Cloud Volumes ONTAP. Se non viene fornito, Cloud Manager utilizza il primo spazio di lavoro. L'ID è disponibile nella scheda Workspace (Area di lavoro) in<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="868f934d26dc5bf64ab570c48f38be79" category="cell">*az_cvo_capacity_tier*</block>
  <block id="e8dcbe7d10f08e94b9057a584009a175" category="cell">(Obbligatorio) se abilitare il tiering dei dati per il primo aggregato di dati: <block ref="e8016c85ada38bdc5fac616ec1318047" prefix="[" category="inline-code"></block>,<block ref="b50339a10e1de285ac99d4c3990b8693" prefix=" " category="inline-code"></block>]. L'impostazione predefinita è<block ref="1649cff06611a6025da3dd511a97fb43" prefix=" " category="inline-code"></block>.</block>
  <block id="25390bc170c676096ec93edd61a5dca6" category="cell">*az_cvo_writing_speed_state*</block>
  <block id="b632952868dfa1143652e0c226514318" category="cell">(Obbligatorio) impostazione della velocità di scrittura per Cloud Volumes ONTAP: <block ref="1e23852820b9154316c7c06e2b7ba051" prefix="[" category="inline-code"></block> ,<block ref="b89de3b4b81c4facfac906edf29aec8c" prefix=" " category="inline-code"></block>]. L'impostazione predefinita è<block ref="1e23852820b9154316c7c06e2b7ba051" prefix=" " category="inline-code"></block>. Questo argomento non è rilevante per le coppie ha.</block>
  <block id="52742ffdac7415fc1d35c1a6d0d9fb7a" category="cell">*az_cvo_ontap_version*</block>
  <block id="90e696b73ff714675fc926a955cc68e1" category="cell">(Obbligatorio) la versione ONTAP richiesta. Ignorato se 'use_latest_version' è impostato su true. L'impostazione predefinita prevede l'utilizzo della versione più recente.</block>
  <block id="39a41303384652e186a359e5d96e8014" category="cell">*az_cvo_instance_type*</block>
  <block id="fb03bbd04a925d04740ba3d3eae2e8b6" category="cell">(Obbligatorio) il tipo di istanza da utilizzare, che dipende dal tipo di licenza scelto: Esplora:<block ref="ca3fc7c5e09a3c4fa0f4881f15167411" prefix="[" category="inline-code"></block>], Standard:<block ref="3e47288b0119e2f8cd128c5c1feb02e1" prefix="[" category="inline-code"></block>], Premium:<block ref="9985a34952917c6a4f0d465c59bb32e6" prefix="[" category="inline-code"></block><block ref="7ccab40e6fc8df111c44d0d3a37df667" prefix="," category="inline-code"></block>], BYOL: Tutti i tipi di istanze definiti per PayGo. Per ulteriori tipi di istanze supportati, fare riferimento alle Note di rilascio di Cloud Volumes ONTAP. L'impostazione predefinita è<block ref="a6f80faf58b4f8e337246cea4f984fc6" prefix=" " category="inline-code"></block> .</block>
  <block id="c0abbc4097de55ad558bd265d5e19b2e" category="cell">*az_cvo_license_type*</block>
  <block id="337fb3a0d6e4f27fa4187c6e10b9d41b" category="cell">(Obbligatorio) il tipo di licenza da utilizzare. Per nodo singolo: <block ref="47dfc9e0cae8289642a649a3d4b6f07f" prefix="[" category="inline-code"></block>,<block ref="6d7fd627acad65b22bc5bee7e03283c0" prefix=" " category="inline-code"></block>,<block ref="fda853806a97d134c59567534d1aabe6" prefix=" " category="inline-code"></block>,<block ref="371b5a766fa14dc8d36c07dc53ec816c" prefix=" " category="inline-code"></block>,<block ref="f87643778357d753d17f33bd44952668" prefix=" " category="inline-code"></block>]. Per ha: <block ref="18099bc4697504c468dd18adf279ac68" prefix="[" category="inline-code"></block>,<block ref="87d3f1b34e654923bcf9bc3b1b740e47" prefix=" " category="inline-code"></block>,<block ref="6db401109bfb00cf3ddd45edfbf1ecc0" prefix=" " category="inline-code"></block>,<block ref="709b724f9fdb1c96f55d9192b5be7a3f" prefix=" " category="inline-code"></block>]. L'impostazione predefinita è<block ref="6d7fd627acad65b22bc5bee7e03283c0" prefix=" " category="inline-code"></block>. Utilizzare<block ref="f87643778357d753d17f33bd44952668" prefix=" " category="inline-code"></block> oppure<block ref="709b724f9fdb1c96f55d9192b5be7a3f" prefix=" " category="inline-code"></block> Per ha selezionando Bring Your Own License type basato su capacità o Freemium. Utilizzare<block ref="371b5a766fa14dc8d36c07dc53ec816c" prefix=" " category="inline-code"></block> oppure<block ref="6db401109bfb00cf3ddd45edfbf1ecc0" prefix=" " category="inline-code"></block> Per ha selezionando Bring Your Own License type Node-based.</block>
  <block id="5e952a0432dfc8995121e15b76aa554a" category="cell">*az_cvo_nss_account*</block>
  <block id="c3ae78309504c231f8afd5bc3790d119" category="cell">(Obbligatorio) ID account del sito di supporto NetApp da utilizzare con questo sistema Cloud Volumes ONTAP. Se il tipo di licenza è BYOL e non viene fornito un account NSS, Cloud Manager tenta di utilizzare il primo account NSS esistente.</block>
  <block id="e7e63db47174977525dadf7a52fc6b39" category="cell">*az_tenant_id*</block>
  <block id="66093475775d81b74da52f4377ff5ce5" category="cell">(Obbligatorio) ID tenant dell'applicazione/servizio principale registrato in Azure.</block>
  <block id="7934d010494793aec0f365d710cdf720" category="cell">*az_application_id*</block>
  <block id="587bfaa720a64e832c9eef635797e8d8" category="cell">(Obbligatorio) ID dell'applicazione/servizio principale registrato in Azure.</block>
  <block id="67830019a9948cfd51759684b5f8a262" category="cell">*az_application_key*</block>
  <block id="56d6515673e3c08156696c47a943c020" category="cell">(Obbligatorio) la chiave applicativa dell'applicazione/servizio principale registrato in Azure.</block>
  <block id="f06bfa867f111b72b9e71b8a75d661da" category="paragraph-title">File di configurazione del terraform per l'implementazione di CVO ha su Azure</block>
  <block id="353190ef77d18ad13aeb6b4f0f3ddd66" category="paragraph">Questa sezione contiene diversi file di configurazione del terraform per implementare/configurare CVO (Cloud Volumes ONTAP) ha (alta disponibilità) su Azure.</block>
  <block id="522a4529185faee9fa34a9398ab7263f" category="list-text">Aggiornare le variabili in<block ref="3bdb269db9a3f1a5b57521aa62658bf3" prefix=" " category="inline-code"></block>.</block>
  <block id="e2da3e968f76091801635ce624569dcb" category="paragraph"><block ref="a82b90469ebb90af122c361dbb754fd8" prefix="" category="inline-code"></block></block>
  <block id="86ed32721429fbcc7b5e123836e3ebcd" category="paragraph">Variabili di terraform per ha Pair Cloud Volumes ONTAP (CVO).</block>
  <block id="72170ff3a9ca936d7855297f0bbd1eeb" category="cell">(Obbligatorio) il tipo di istanza da utilizzare, che dipende dal tipo di licenza scelto: Esplora:<block ref="ca3fc7c5e09a3c4fa0f4881f15167411" prefix="[" category="inline-code"></block>], Standard:<block ref="a23549be3ebc980aebe6cb120ab4e310" prefix="[" category="inline-code"></block>], Premium:<block ref="9985a34952917c6a4f0d465c59bb32e6" prefix="[" category="inline-code"></block>,<block ref="7ccab40e6fc8df111c44d0d3a37df667" prefix=" " category="inline-code"></block>], BYOL: Tutti i tipi di istanze definiti per PayGo. Per ulteriori tipi di istanze supportati, fare riferimento alle Note di rilascio di Cloud Volumes ONTAP. L'impostazione predefinita è<block ref="a6f80faf58b4f8e337246cea4f984fc6" prefix=" " category="inline-code"></block> .</block>
  <block id="b515d8e49b6ef626aa91dbd970708132" category="cell">(Obbligatorio) il tipo di licenza da utilizzare. Per nodo singolo: <block ref="3abe68da9038e8e4aabc1b0e2a6530cc" prefix="[" category="inline-code"></block>]. Per ha: <block ref="86e0c1bceadb9c08ef223996a3e33d86" prefix="[" category="inline-code"></block>]. L'impostazione predefinita è<block ref="6d7fd627acad65b22bc5bee7e03283c0" prefix=" " category="inline-code"></block>. Utilizzare<block ref="f87643778357d753d17f33bd44952668" prefix=" " category="inline-code"></block> oppure<block ref="709b724f9fdb1c96f55d9192b5be7a3f" prefix=" " category="inline-code"></block> Per ha selezionando Bring Your Own License type basato su capacità o Freemium. Utilizzare<block ref="371b5a766fa14dc8d36c07dc53ec816c" prefix=" " category="inline-code"></block> oppure<block ref="6db401109bfb00cf3ddd45edfbf1ecc0" prefix=" " category="inline-code"></block> Per ha selezionando Bring Your Own License type Node-based.</block>
  <block id="c731f72e1d22a7c5e01a7cb789a8885e" category="example-title">GCP</block>
  <block id="e10db5a03ff1c5409d1b9ef0cf32ae11" category="paragraph-title">File di configurazione del terraform per l'implementazione di NetApp CVO (Single Node Instance) su GCP</block>
  <block id="3adefdd7d79d9a7c848b2dd81fd4feff" category="paragraph">Questa sezione contiene diversi file di configurazione del terraform per implementare/configurare il CVO NetApp (Cloud Volumes ONTAP) a nodo singolo su GCP (piattaforma cloud Google).</block>
  <block id="b05dddcb6f00ee8dba8395d241b9d24d" category="list-text">Salvare il file JSON della chiave di autenticazione GCP nella directory.</block>
  <block id="44b4381353a1686f5b81f73f018d336c" category="list-text">Aggiornare i valori delle variabili in<block ref="0635645653586768460c826b4f319a80" prefix=" " category="inline-code"></block></block>
  <block id="2ac544064187c52d64d3eec81700dd42" category="admonition">È possibile scegliere di implementare il connettore impostando il valore della variabile "gcp_Connector_deploy_bool" su true/false.</block>
  <block id="283162995c6eba560352663fa7cafbb3" category="paragraph">Variabili di terraform per l'istanza di NetApp GCP Connector per l'implementazione CVO.</block>
  <block id="c0b4a62bb4903159c66ef5fd828dbb35" category="cell">*gcp_connector_deploy_bool*</block>
  <block id="3448a02a5105e0eeb2a6243836814f36" category="cell">*nome_connettore_gcp*</block>
  <block id="982137a628765a4ede6a620653ab8bf6" category="cell">*gcp_connector_project_id*</block>
  <block id="816194da363b92545a1114d46c4943f1" category="cell">(Obbligatorio) l'id_progetto GCP in cui verrà creato il connettore.</block>
  <block id="49a94de7b7e8762f961e471d657496eb" category="cell">*gcp_connector_zone*</block>
  <block id="ff9633a62f1e60af63fc951afd6966bc" category="cell">(Obbligatorio) la zona GCP in cui verrà creato il connettore.</block>
  <block id="c667eb31817317b5455e6a8883f4664a" category="cell">*gcp_connector_company*</block>
  <block id="9d1203849926481ebb6be1fb1d6ec3de" category="cell">*gcp_connector_service_account_email*</block>
  <block id="d4a302e18b412231fe06e54e038aed80" category="cell">(Obbligatorio) l'email dell'account_servizio per l'istanza del connettore. Questo account del servizio viene utilizzato per consentire al connettore di creare Cloud Volume ONTAP.</block>
  <block id="0e3852268e0e5a3a486b8fcf6e3ae1c1" category="cell">*percorso_account_servizio_connettore_gcp*</block>
  <block id="f863e677d176e63d3642e53ae6b336b5" category="cell">(Obbligatorio) il percorso locale del file Service_account JSON per l'autorizzazione GCP. Questo account di servizio viene utilizzato per creare il connettore in GCP.</block>
  <block id="cfd7e4961aa34c5626712429d469ed18" category="cell">*gcp_connector_account_id*</block>
  <block id="231d57c65fc42941f6a520976dc80ec3" category="cell">(Facoltativo) l'ID dell'account NetApp a cui verrà associato il connettore. Se non viene fornito, Cloud Manager utilizza il primo account. Se non esiste alcun account, Cloud Manager crea un nuovo account. L'ID dell'account è disponibile nella scheda account di Cloud Manager all'indirizzo<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="9ea10c86ddbbfa93db9af98d0a38e7d7" category="paragraph">Variabili di terraform per singola istanza NetApp CVO su GCP.</block>
  <block id="9d8a021dcdac02b1cffc5ee14bc79241" category="cell">*gcp_cvo_name*</block>
  <block id="bc023aad2be985e1a3252a959cb2c43b" category="cell">*gcp_cvo_project_id*</block>
  <block id="c7a61709c9cf6aa90f854f8e30110412" category="cell">(Obbligatorio) l'ID del progetto GCP.</block>
  <block id="6f74a6834cfd9c72b6694ae9ecb7f332" category="cell">*gcp_cvo_zone*</block>
  <block id="dea2d3525e8ec98bbd9a7931a8ed9921" category="cell">(Obbligatorio) la zona della regione in cui verrà creato l'ambiente di lavoro.</block>
  <block id="2c09e34e29e9c5f65d5d8ac921fd8105" category="cell">*gcp_cvo_gcp_service_account*</block>
  <block id="77853ddcc7178537c8d9c0301b71c991" category="cell">(Obbligatorio) l'e-mail gcp_Service_account per abilitare il tiering dei dati cold su Google Cloud Storage.</block>
  <block id="ffb5588c947a413a01016a81af9ddbc7" category="cell">*gcp_cvo_svm_password*</block>
  <block id="9507c3b760db1c7e6c8d1674933449e4" category="cell">*gcp_cvo_workspace_id*</block>
  <block id="4efb152d95f2b6b19ca1387a26e8f750" category="cell">(Facoltativo) l'ID dello spazio di lavoro di Cloud Manager in cui si desidera implementare Cloud Volumes ONTAP. Se non viene fornito, Cloud Manager utilizza il primo spazio di lavoro. L'ID è disponibile nella scheda Workspace (Area di lavoro) in<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="7cbf1746ddada50a540811a75b633bfa" category="cell">*gcp_cvo_license_type*</block>
  <block id="108ccbda23ae580baf5fb86c14613837" category="cell">(Facoltativo) il tipo di licenza da utilizzare. Per nodo singolo: ['Capacity-paygo', 'gcp-COT-Explore-paygo', 'gcp-COT-standard-paygo', 'gcp-COT-premium-paygo', 'gcp-COT-premium-byol'], Per ha: ['ha-Capacity-paygo', 'gcp-ha-COT-Explore-paygo', 'gcp-ha-COT-standard-paygo', 'gcp-ha-COT-premium-paygo', 'gcp-ha-COT-premium-byol']. L'impostazione predefinita è "Capacity-paygo" per nodo singolo e "ha-Capacity-paygo" per ha.</block>
  <block id="ec6c16de8b82f3fc6c55f03f1d9a0848" category="cell">*gcp_cvo_capacity_nome_pacchetto*</block>
  <block id="564565c1364213fe3ffcef055b61947b" category="cell">(Facoltativo) il nome del pacchetto di capacità: ['Essential', 'Professional', 'Freemium']. Il valore predefinito è "essenziale".</block>
  <block id="1e95e8962dbf55d78e03e8da38f9f408" category="paragraph-title">File di configurazione del terraform per l'implementazione di NetApp CVO (coppia ha) su GCP</block>
  <block id="ac245610a2b7e434b78946f9ab069afe" category="paragraph">Questa sezione contiene diversi file di configurazione del terraform per implementare/configurare NetApp CVO (Cloud Volumes ONTAP) in coppia ad alta disponibilità su GCP (piattaforma cloud Google).</block>
  <block id="00c7a940cc525046dc63cee112a8ef2d" category="list-text">Aggiornare i valori delle variabili in<block ref="aca245204ab77411a71da01b8d6ec7cb" prefix=" " category="inline-code"></block>.</block>
  <block id="657426021b9624d6c24fae901c9998c1" category="paragraph">Variabili di terraform per istanze NetApp CVO in coppia ha su GCP.</block>
  <block id="2a20062f50c253ff821e16ab60e9bd71" category="cell">*gcp_cvo_is_ha*</block>
  <block id="c7d1d567eb3eec5faac1c3efbf5c63d6" category="cell">*gcp_cvo_node1_zone*</block>
  <block id="2cb70db8c1982b17ac705ceace5b64ae" category="cell">(Facoltativo) zona per il nodo 1.</block>
  <block id="b231cdca0a533a8afcbf95810dcdd937" category="cell">*gcp_cvo_node2_zone*</block>
  <block id="2aad8f424dde09a3fb42570367a156de" category="cell">(Facoltativo) zona per il nodo 2.</block>
  <block id="7dd3bb55d8d71efcb06fc86bbb29993a" category="cell">*gcp_cvo_mediator_zone*</block>
  <block id="767c5594dfa391fbb74bd9360557a0a8" category="cell">(Facoltativo) zona per mediatore.</block>
  <block id="4ecd0da4e352bb336bd4c5925e627fbb" category="cell">*gcp_cvo_vpc_id*</block>
  <block id="0a49d29112682612dc74e881a68deed0" category="cell">(Facoltativo) il nome del VPC.</block>
  <block id="eedae790807f6f5998c1d5b2eccfcf91" category="cell">*gcp_cvo_subnet_id*</block>
  <block id="dbb13624053bb884443eb3a8a891a35e" category="cell">(Facoltativo) il nome della subnet per Cloud Volumes ONTAP. L'impostazione predefinita è 'Default'.</block>
  <block id="5fbbd2383d042b5ab01878b936e467ff" category="cell">*gcp_cvo_vpc0_node_and_data_connectivity*</block>
  <block id="24239aec58a00d53d32147d2e71cca4d" category="cell">(Opzionale) percorso VPC per nic1, richiesto per la connettività dei nodi e dei dati. Se si utilizza un VPC condiviso, è necessario fornire netrurik_project_id.</block>
  <block id="b1dd5e2b134fc3db50406e05c7ae6c38" category="cell">*gcp_cvo_vpc1_cluster_connectivity*</block>
  <block id="714e5d0cdfde4cbf4df83df266c672e7" category="cell">(Opzionale) percorso VPC per nic2, richiesto per la connettività del cluster.</block>
  <block id="f8d315b03e4b926495b923dfe4b49b23" category="cell">*gcp_cvo_vpc2_ha_connectivity*</block>
  <block id="5c144c2c76f5d988024f4d7398060d71" category="cell">(Opzionale) percorso VPC per nic3, richiesto per la connettività ha.</block>
  <block id="1366961106ddc181e83c467cf5559a14" category="cell">*gcp_cvo_vpc3_data_replication*</block>
  <block id="b4be5ce15bf4e51acd3167c47e79955f" category="cell">(Opzionale) percorso VPC per nic4, richiesto per la replica dei dati.</block>
  <block id="065308400ba1fac48f2ca62781d79dff" category="cell">*gcp_cvo_subnet0_node_and_data_connectivity*</block>
  <block id="2a33bb449fd47fa1f379b60f3e1473ca" category="cell">(Facoltativo) percorso di sottorete per nic1, richiesto per la connettività dei nodi e dei dati. Se si utilizza un VPC condiviso, è necessario fornire netrurik_project_id.</block>
  <block id="da8a35439720c0bc705f001b954bd61e" category="cell">*gcp_cvo_subnet1_cluster_connectivity*</block>
  <block id="01b515c3b8d74ae94df6572b47a3f06d" category="cell">(Facoltativo) percorso di sottorete per nic2, richiesto per la connettività del cluster.</block>
  <block id="7ea43f4ca8d2a868f20df11b9e0b39b2" category="cell">*gcp_cvo_subnet2_ha_connectivity*</block>
  <block id="a35bd275122015b3834d13c0dc72b87f" category="cell">(Opzionale) percorso di sottorete per nic3, richiesto per la connettività ha.</block>
  <block id="16c5273854a933d221200af8f06d106a" category="cell">*gcp_cvo_subnet3_data_replication*</block>
  <block id="b36fab455a4e11803791a090935906af" category="cell">(Facoltativo) percorso di sottorete per nic4, richiesto per la replica dei dati.</block>
  <block id="e69179170f564daf56d8694c1c5d35fe" category="cell">*gcp_cvo_gcp_volume_size*</block>
  <block id="eb01714b284e762b9c44adfa5575690c" category="cell">(Facoltativo) le dimensioni del volume GCP per il primo aggregato di dati. Per GB, l'unità può essere: [100 o 500]. Per i TB, l'unità può essere: [1,2,4,8]. L'impostazione predefinita è '1' .</block>
  <block id="4c767d9b6ddddf4abeaece5590c0b101" category="cell">*gcp_cvo_gcp_volume_size_unit*</block>
  <block id="944ce323a5a1ffb09543fd409911cc88" category="open-title">Volume CVS</block>
  <block id="f39b5c8ffff4c5fccbc9ca01bf3bacf8" category="paragraph-title">File di configurazione del terraform per l'implementazione di NetApp CVS Volume su GCP</block>
  <block id="ffcc65b297748299934a184d39035ae4" category="paragraph">Questa sezione contiene diversi file di configurazione Terraform per implementare/configurare il volume NetApp CVS (Cloud Volumes Services) su GCP (Google Cloud Platform).</block>
  <block id="732c3eabba1449281a4fddb59dbddcac" category="paragraph">Documentazione terraform:<block ref="35b7d5c9a11899e5d5e07079551e8cef" category="inline-link-rx"></block></block>
  <block id="d203294ba4c28418657d90a7f8a7510d" category="list-text">Aggiornare i valori delle variabili in<block ref="eb1510c0f29be1d144dce2bfa2e8caab" prefix=" " category="inline-code"></block>.</block>
  <block id="40686c9084c59387baf48000dd09e6ab" category="paragraph"><block ref="944ce323a5a1ffb09543fd409911cc88" prefix="" category="inline-code"></block></block>
  <block id="3efdf9b0e7f4af483444f271367d6361" category="paragraph">Variabili di terraform per NetApp GCP CVS Volume.</block>
  <block id="0ffdc0b2b4889601b216ab5087650d46" category="cell">*gcp_cvs_name*</block>
  <block id="8ff48dd93ed73eb9adc26090e58ed80b" category="cell">(Obbligatorio) il nome del volume NetApp CVS.</block>
  <block id="b6759cef3cfc5890deb6a790f73c8b79" category="cell">*gcp_cvs_project_id*</block>
  <block id="b0257576709acc899b5376a171c3cd98" category="cell">(Obbligatorio) l'id_progetto GCP in cui verrà creato il volume CVS.</block>
  <block id="447b0e81ae249b907128b7ea83e045c5" category="cell">*gcp_cvs_gcp_service_account_path*</block>
  <block id="820ecb1b7a653c1e2dece0176d15eaed" category="cell">(Obbligatorio) il percorso locale del file Service_account JSON per l'autorizzazione GCP. Questo account di servizio viene utilizzato per creare il volume CVS in GCP.</block>
  <block id="6cb8bdefdf91cd2d80f6d9849de25fb8" category="cell">*gcp_cvs_regione*</block>
  <block id="ec9461de174e3ad866c58b577c94034b" category="cell">(Obbligatorio) la zona GCP in cui verrà creato il volume CVS.</block>
  <block id="fc944aa114b94de895d84f5375000c0b" category="cell">*gcp_cvs_network*</block>
  <block id="23a1cb77eeeabfd36bbab18e5de9f0dc" category="cell">(Obbligatorio) il VPC di rete del volume.</block>
  <block id="31681a1878caf611cea11e159a4fc1aa" category="cell">*gcp_cvs_size*</block>
  <block id="6f84d4d0c83121512056657a2dc0e808" category="cell">(Obbligatorio) le dimensioni del volume sono comprese tra 1024 e 102400 (in formato GiB).</block>
  <block id="5c1eb3efe4738cb21efadc992aeeef81" category="cell">*gcp_cvs_volume_path*</block>
  <block id="bacdc6093d23e2f886b0cb0609418030" category="cell">(Facoltativo) il nome del percorso del volume.</block>
  <block id="0467ee670bdb8fff57da77368d6d5385" category="cell">*gcp_cvs_protocol_types*</block>
  <block id="b91db1bd1a57ea4c9953036d82a63e95" category="cell">(Obbligatorio) il tipo_protocollo del volume. Per NFS utilizzare 'NFSv3' o 'NFSv4' e per SMB utilizzare 'CIFS' o 'MB'.</block>
  <block id="b9b07f10c0ce1735548942e3abaa3447" category="summary">Questa pagina fornisce informazioni dettagliate per la raccolta dei token Refresh e delle chiavi Access/Secret necessari per le implementazioni CVO e Cloud Manager Connector tramite NetApp Cloud Manager.</block>
  <block id="bcc03f70ea2e77a98ddb6e8267e4892f" category="paragraph">Per configurare le implementazioni automatiche di CVO e connettori utilizzando i playbook Ansible tramite AWX/Ansible Tower, sono necessarie le seguenti informazioni:</block>
  <block id="193fc1c355935356ecd5d07811792512" category="section-title">Acquisizione delle chiavi di accesso/segreto da AWS</block>
  <block id="60b6439418495e0d1821d169b7d4b885" category="list-text">Per implementare CVO e Connector in Cloud Manager, abbiamo bisogno di AWS Access/Secret Key. Acquisire le chiavi nella console AWS avviando IAM--&gt;Users--&gt;il proprio nome utente--&gt;credenziali di sicurezza--&gt;Crea chiave di accesso.</block>
  <block id="ad1cc06192440312813c412c9cf08bc5" category="list-text">Copiare le chiavi di accesso e conservarle in modo sicuro per l'utilizzo nell'implementazione di connettori e CVO.</block>
  <block id="4ba9f13f5b12512f3651d5ea2d3ffa05" category="admonition">In caso di smarrimento della chiave, è possibile creare un'altra chiave di accesso ed eliminare quella persa</block>
  <block id="ad35fbaef240a8ec1f43e8a0d5e15099" category="image-alt">Aggiorna token</block>
  <block id="89d8fe92eb33da3c73df38422c3fa73e" category="section-title">Acquisizione del token di refresh da NetApp Cloud Central</block>
  <block id="3d7e1d21530a3a98c74b0b7484c84516" category="list-text">Accedi al tuo account cloud Central utilizzando le credenziali del tuo account all'indirizzo<block ref="ddbd83acb6424bbb7fa6878eff0976a1" category="inline-link-rx"></block></block>
  <block id="a95c6d24569073e45c394bcbd6a2c0e4" category="list-text">Generare un token di refresh e salvarlo per le implementazioni.</block>
  <block id="ecd636681b83fa2697020594594aea14" category="section-title">Acquisizione ID client in corso</block>
  <block id="2a1ed6ca97aeb484a26d6e0d625af96b" category="list-text">Accedere alla pagina API per copiare l'ID client all'indirizzo<block ref="06324b77583872f7e211b3e7ec3f882f" category="inline-link-rx"></block>.</block>
  <block id="1093ef7993a1f3824edbf581bb54b571" category="list-text">Fare clic su "Learn How to Authenticate" (informazioni sull'autenticazione), nell'angolo in alto a destra.</block>
  <block id="622dcb1fafb9f30d36b32341e23ae7a0" category="list-text">Dalla finestra di autenticazione visualizzata, copiare l'ID client da accesso regolare se si richiede un nome utente/password per l'accesso. Gli utenti federati con SSO devono copiare l'ID client dalla scheda "Refresh Token" (Aggiorna token).</block>
  <block id="76525f0f34b48475e5ca33f71d296f3b" category="image-alt">ID client</block>
  <block id="6090065e2462d5f96ebac132568bdf46" category="section-title">Acquisizione della coppia di chiavi da AWS</block>
  <block id="294b903c23e96b98876b04f51502cec4" category="list-text">Nella console AWS, cercare "Key Pair" e creare una coppia di chiavi con "pem". Ricordare il nome di coppia_chiave, che verrà utilizzato per implementare il connettore.</block>
  <block id="ddb20e807acdf5ddf189dd213ff6d0cf" category="image-alt">Coppia di chiavi</block>
  <block id="3ce1d7d6e1b4509256dd2574b6b5d290" category="section-title">Acquisizione ID account in corso</block>
  <block id="8f19980a36fbde35540547e8f630c9e5" category="list-text">In Cloud Manager, fare clic su account –&gt; Manage Accounts (account -&gt; Gestisci account), quindi copiare l'id account da utilizzare nelle variabili per AWX.</block>
  <block id="8be4a12c21ef3f52e24811e4ffe0d444" category="summary">Questa pagina descrive l'automazione del monitoraggio di AWS FSxN e il ridimensionamento automatico in base alla soglia.</block>
  <block id="cd2c2a58f3cb485687fd1f77834654e5" category="doc">FSX per il monitoraggio ONTAP e il ridimensionamento automatico mediante la funzione lambda di AWS</block>
  <block id="1ebfeec31c440a4fac484932940c73b1" category="paragraph">Autore: Dhruv Tyagi, Niyaz Mohamed</block>
  <block id="77b2a3f373c1bcab9cefd635e81303eb" category="section-title">Panoramica: Monitoraggio e ridimensionamento automatico di FSX per ONTAP tramite la funzione AWS Lambda</block>
  <block id="88f21a3befc798942cec953cec96af16" category="paragraph">FSX per ONTAP è un primo servizio di cloud storage Enterprise di livello Enterprise disponibile su AWS che offre un file storage altamente affidabile, scalabile, dalle performance elevate e ricco di funzionalità, basato sul popolare file system NetApp ONTAP.</block>
  <block id="2991ec0aa5bd4825c01d9bef4b9bdaad" category="paragraph">FSX per ONTAP offre un'esperienza di implementazione e gestione perfetta. Per iniziare, non è richiesta alcuna competenza in ambito storage. Per semplificare il monitoraggio, è possibile utilizzare una funzione lambda AWS (per automatizzare il ridimensionamento della capacità di storage totale, delle dimensioni del volume o delle dimensioni del LUN in base alla soglia). Questo documento fornisce una guida dettagliata per creare una configurazione automatica che monitora FSX per ONTAP a intervalli regolari, notifica e ridimensiona quando viene superata una soglia specificata dall'utente e notifica all'amministratore l'attività di ridimensionamento.</block>
  <block id="8799f4655655a26ca808c044ad467a88" category="paragraph">La soluzione offre le seguenti funzionalità:</block>
  <block id="c342d53b891fb460586d3a137ff99a6e" category="list-text">Possibilità di monitorare:</block>
  <block id="138be07c6f8ee03d211e5f345546b7af" category="list-text">Utilizzo della capacità di storage complessiva di FSX per ONTAP</block>
  <block id="e0f2ee8f41ba7bcb505bbabfcab0c31d" category="list-text">Utilizzo di ciascun volume (thin provisioning/thick provisioning)</block>
  <block id="34b7d0bb9429625764e4da258f94ae19" category="list-text">Utilizzo di ciascun LUN (thin provisioning/thick provisioning)</block>
  <block id="685d6918f18b4d0d12cf6582187aff57" category="list-text">Possibilità di ridimensionare uno qualsiasi dei punti precedenti in caso di superamento di una soglia definita dall'utente</block>
  <block id="378c1fc07823bfb610dec17052eacf6d" category="list-text">Meccanismo di avviso per ricevere avvisi sull'utilizzo e ridimensionare le notifiche via email</block>
  <block id="f4f72a76c2acbf4ea687920f5e120816" category="list-text">Possibilità di eliminare snapshot precedenti alla soglia definita dall'utente</block>
  <block id="91602eeac7d8a4cc46329128033d33d3" category="list-text">Possibilità di ottenere un elenco di volumi e snapshot FlexClone associati</block>
  <block id="8e8aff933e5047a57263663f8a18e3c3" category="list-text">Possibilità di monitorare i controlli a intervalli regolari</block>
  <block id="e2b4916d6d7f53cde2d5633fd6119cc4" category="list-text">Possibilità di utilizzare la soluzione con o senza accesso a Internet</block>
  <block id="a90d7c3c15ad351b936f52283c3587ef" category="list-text">Possibilità di implementare manualmente o utilizzando AWS CloudFormation Template</block>
  <block id="dd0679a0ea834bda0a34b306e7a09346" category="paragraph">Prima di iniziare, assicurarsi che siano soddisfatti i seguenti prerequisiti:</block>
  <block id="561d599e4e659439d1b142dbe29b15c7" category="list-text">Viene implementato FSX per ONTAP</block>
  <block id="1526ea467258021d67f8f59298e57f70" category="list-text">Subnet privata con connettività a FSX per ONTAP</block>
  <block id="7f42d2e23aac4d85dca59633ff2cf58d" category="list-text">La password "fsxadmin" è stata impostata per FSX per ONTAP</block>
  <block id="2f660e9fff52e5ac1b7818a029d3b447" category="example-title">Architettura di alto livello</block>
  <block id="eb99e653d349f732eb98619784a340ac" category="list-text">La funzione AWS Lambda effettua chiamate API a FSX per ONTAP per recuperare e aggiornare le dimensioni della capacità di storage, dei volumi e delle LUN.</block>
  <block id="f350c91a602035a3521ac328a432c7ed" category="list-text">La password "fsxadmin" viene memorizzata come stringa sicura nell'archivio dei parametri di AWS SSM per un ulteriore livello di sicurezza.</block>
  <block id="3eac8a068c2043f39b9aec5a2b7ee6af" category="list-text">AWS SES (Simple Email Service) viene utilizzato per notificare agli utenti finali quando si verifica un evento di ridimensionamento.</block>
  <block id="baebd0d5b177b5744e776be025952058" category="list-text">Se si implementa la soluzione in un VPC senza accesso a Internet, gli endpoint VPC per AWS SSM, FSX e SES vengono configurati in modo da consentire a Lambda di raggiungere questi servizi tramite la rete interna di AWS.</block>
  <block id="0048e42e38e4c6f587f210afe26fcb4a" category="inline-image-macro">Questa immagine mostra l'architettura di alto livello utilizzata in questa soluzione.</block>
  <block id="432a24ba141fb90355a80ec4c6d3825e" category="paragraph"><block ref="432a24ba141fb90355a80ec4c6d3825e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dd1d4adbfe73c3cd87fc248a003b05a0" category="section-title">Implementazione della soluzione</block>
  <block id="f674169036173cc4a9f01e223c275c8d" category="section-title">Implementazione automatica</block>
  <block id="5215f5ee52e78e416520bfecaf294472" category="paragraph">Seguire la serie di passaggi per completare l'implementazione automatica di questa soluzione:</block>
  <block id="974bba02716a5e7c8414499dd06bbb62" category="example-title">Fase 1: Clonare il repository di GitHub</block>
  <block id="3233c0d0dc9395d6085fb8167fdd8393" category="paragraph">Clonare il repository GitHub sul sistema locale:</block>
  <block id="6436b05fc0216b37135d2a66a585e96f" category="example-title">Fase 2: Configurare un bucket AWS S3</block>
  <block id="7d54d293b4849834117fc9160feb6cbc" category="list-text">Accedere a AWS Console &gt; *S3* e fare clic su *Create bucket* (Crea bucket). Creare il bucket con le impostazioni predefinite.</block>
  <block id="040d8a375b4543c424d11036c6faa0d7" category="list-text">Una volta all'interno del bucket, fare clic su *Upload* &gt; *Add Files* e selezionare *Paramiko.zip* e *Requests.zip* dal repository clonato di GitHub sul sistema.</block>
  <block id="66b09b43432fbb9814d51e48e9a98ade" category="inline-image-macro">Questa immagine mostra la finestra S3 con i file zip caricati</block>
  <block id="0f71a8c9bb8a785323461956bf9e217a" category="paragraph"><block ref="0f71a8c9bb8a785323461956bf9e217a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ea6ef5eae0a05760ec8bf19495d8645" category="example-title">Fase 3: Configurazione SMTP di AWS SES (necessaria se non è disponibile l'accesso a Internet)</block>
  <block id="90db95943ff24327f32dd935aa7395d5" category="paragraph">Seguire questa procedura se si desidera implementare la soluzione senza accesso a Internet (Nota: Verranno associati costi aggiuntivi a causa della configurazione degli endpoint VPC).</block>
  <block id="972167638becf55a9af0b4e5c414a75e" category="list-text">Accedere a AWS Console &gt; *AWS Simple Email Service (SES)* &gt; SMTP Settings (Impostazioni SMTP) e fare clic su *Create SMTP credentials* (Crea credenziali SMTP)</block>
  <block id="68d59bd0e9b2839f0843ab1b2d6b136f" category="list-text">Inserire un nome utente IAM o lasciarlo sul valore predefinito e fare clic su Create (Crea). Salvare il nome utente e la password per ulteriori utilizzi.</block>
  <block id="796d9a158268a6ea8a7895c4fc08b2f7" category="admonition">Saltare questo passaggio se la configurazione SMTP SES è già stata eseguita.</block>
  <block id="c492e5ad14c10d85050111f49b9ccd32" category="inline-image-macro">Questa immagine mostra la finestra Create SMTP Credentials (Crea credenziali SMTP) sotto AWS SES</block>
  <block id="311486bd300a1e6b104a8c2d1edc4b1d" category="paragraph"><block ref="311486bd300a1e6b104a8c2d1edc4b1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53f52a194e6b0e83b281c128d8c9536d" category="example-title">Fase 4: Implementazione di AWS CloudFormation</block>
  <block id="d2edefb4d7f05ffadcc2ce87ffde5e98" category="list-text">Accedere a AWS Console &gt; *CloudFormation* &gt; Create stack &gt; with New Resources (Standard) (Console AWS &gt; *CloudFormation* &gt; Crea stack &gt; con nuove risorse (Standard).</block>
  <block id="f9555c9e4ee9872bd73e1554f90b137c" category="inline-image-macro">Questa immagine mostra la finestra AWS CloudFormation Create Stack</block>
  <block id="302a433b27874ed6225d3a3553f31fdb" category="paragraph"><block ref="302a433b27874ed6225d3a3553f31fdb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a65108ded0e706a6c44742b2f313e4e" category="paragraph">Fare clic su Next (Avanti)</block>
  <block id="ef7b077619d0583a71ba9fda28bc53fc" category="list-text">Inserire i dettagli dello stack. Fare clic su Next (Avanti) e selezionare la casella di controllo "i acknowledge that AWS CloudFormation might creation IAM resources" (riconosco che AWS CloudFormation potrebbe creare risorse IAM), quindi fare clic su Submit</block>
  <block id="1b61f2cbcfae90671dbb048e72bb8918" category="admonition">Se "VPC dispone di accesso a Internet?" È impostato su Falso, sono richiesti "Nome utente SMTP per AWS SES" e "Password SMTP per AWS SES". In caso contrario, possono essere lasciati vuoti.</block>
  <block id="1f5aede37b8170af3cfbd901f22d591e" category="inline-image-macro">Questa immagine mostra la finestra AWS CloudFormation Stack Details</block>
  <block id="7e2652655cc5cfead2ca4bff65032215" category="paragraph"><block ref="7e2652655cc5cfead2ca4bff65032215" category="inline-image-macro-rx" type="image"></block></block>
  <block id="113624fc80b505576882228d73fc03c5" category="paragraph"><block ref="113624fc80b505576882228d73fc03c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13069c8f4182a2f6ab810369ebe8b0ad" category="paragraph"><block ref="13069c8f4182a2f6ab810369ebe8b0ad" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd90b3549ddb2a170121e2cae9d2e442" category="paragraph"><block ref="bd90b3549ddb2a170121e2cae9d2e442" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dcd7d4e3b6e000a6821009f7370ab47e" category="list-text">Una volta avviata l'implementazione di CloudFormation, l'ID e-mail menzionato nel "mittente ID e-mail" riceverà un'e-mail che chiede loro di autorizzare l'utilizzo dell'indirizzo e-mail con AWS SES. Fare clic sul collegamento per verificare l'indirizzo e-mail.</block>
  <block id="d22d74b4244b97ca549876dbaf6e5906" category="list-text">Una volta completata l'implementazione dello stack CloudFormation, in caso di avvisi/notifiche, verrà inviata un'e-mail all'ID e-mail del destinatario con i dettagli della notifica.</block>
  <block id="bb44dcc303804fcbbf13971e05b223b4" category="inline-image-macro">Questa immagine mostra la notifica e-mail ricevuta quando sono disponibili le notifiche</block>
  <block id="80b7092ae7ee31bafccb6f27ea2a5603" category="paragraph"><block ref="80b7092ae7ee31bafccb6f27ea2a5603" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e482488f8434036ccb78ddb9cea595f" category="paragraph"><block ref="5e482488f8434036ccb78ddb9cea595f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ae845e97e60673c293edce9fe3a65f9" category="section-title">Implementazione manuale</block>
  <block id="d4f4ecbc346d14b30240c605c5884282" category="paragraph">Seguire la serie di passaggi per completare l'implementazione manuale di questa soluzione:</block>
  <block id="c960dffe03501c470f4219bb16fab5ef" category="example-title">Fase 2: Configurazione SMTP di AWS SES (necessaria se non è disponibile l'accesso a Internet)</block>
  <block id="0aa7c69c57f475cc1f055c49b0e3136e" category="example-title">Fase 3: Creare il parametro SSM per la password fsxadmin</block>
  <block id="06df343d3a431a2f511aa7fef58e4a23" category="paragraph">Accedere a AWS Console &gt; *Parameter Store* e fare clic su *Create Parameter* (Crea parametro).</block>
  <block id="faec730272cd4b39d377b89835a6a82c" category="paragraph">Fare clic su *Create Parameter* (Crea parametro).</block>
  <block id="1cefa861aa6d9ba408841133e7325545" category="inline-image-macro">Questa immagine mostra la finestra di creazione dei parametri SSM sulla console AWS.</block>
  <block id="a19e362ed1a0d7ca174a7abf2c59853a" category="paragraph"><block ref="a19e362ed1a0d7ca174a7abf2c59853a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8a7ca52152a916f189b032d05768ed10" category="paragraph">Eseguire le stesse operazioni per memorizzare il nome utente smtp e la password smtp se si implementa la soluzione senza accesso a Internet. In caso contrario, ignorare l'aggiunta di questi 2 parametri.</block>
  <block id="06e0a02f6ce962b7038b6b2918585271" category="example-title">Fase 4: Configurazione del servizio e-mail</block>
  <block id="bcd5fa3fbab9dadf361d9eba36b8382c" category="paragraph">Accedere a AWS Console &gt; *Simple Email Service (SES)* e fare clic su *Create Identity* (Crea identità).</block>
  <block id="60461626b891b858b74da97b0ee89b6e" category="paragraph">Fare clic su *Create Identity* (Crea identità)</block>
  <block id="14bcb93088a1eb5d0e0d7ce578a73a08" category="paragraph">L'ID e-mail indicato nell'ID e-mail del mittente riceverà un'e-mail che chiede al proprietario di autorizzare l'utilizzo dell'indirizzo e-mail con AWS SES. Fare clic sul collegamento per verificare l'indirizzo e-mail.</block>
  <block id="af9b6260888bf7e72d2766823e7a2bb6" category="inline-image-macro">Questa immagine mostra la finestra di creazione dell'identità SES sulla console AWS.</block>
  <block id="59f38a9e267a3ea7e5d173c163613f58" category="paragraph"><block ref="59f38a9e267a3ea7e5d173c163613f58" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88adaee1fa88f871bc7cf8d579e59cdd" category="example-title">Fase 5: Configurazione degli endpoint VPC (necessaria se non è disponibile l'accesso a Internet)</block>
  <block id="0261907012c6fd6ed0e80ab991a9d462" category="admonition">Richiesto solo se implementato senza accesso a Internet. Saranno associati costi aggiuntivi a causa degli endpoint VPC.</block>
  <block id="71bb5fff33b1866d7266866fb9c94f45" category="list-text">Accedere a AWS Console &gt; *VPC* &gt; *Endpoint* e fare clic su *Create Endpoint* (Crea endpoint) e immettere i seguenti dettagli:</block>
  <block id="6683864f2c9e5bbb1fa4128837ed8eab" category="paragraph">Fare clic su Create endpoint (Crea endpoint).</block>
  <block id="5f80bfe9763fe273a3a7722c1c647604" category="inline-image-macro">Questa immagine mostra la finestra di creazione dell'endpoint VPC</block>
  <block id="9a4cd1bb8a39a7c230290453794b4429" category="paragraph"><block ref="9a4cd1bb8a39a7c230290453794b4429" category="inline-image-macro-rx" type="image"></block></block>
  <block id="603ef5b528d0bd1def7291cf6417ff56" category="paragraph"><block ref="603ef5b528d0bd1def7291cf6417ff56" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1c96306d4c766c38569c564c9bdb80a7" category="list-text">Seguire lo stesso processo per la creazione degli endpoint SES e SSM VPC. Tutti i parametri rimangono invariati, ad eccezione dei servizi che corrispondono rispettivamente a *com.amazonaws.&lt;region&gt;.smtp* e *com.amazonaws.&lt;region&gt;.ssm*.</block>
  <block id="a07090d2d501e8e696338339ab098115" category="example-title">Fase 6: Creare e configurare la funzione AWS Lambda</block>
  <block id="f7eef2aeccb65815a4f57ad9796278b3" category="list-text">Accedere alla console AWS &gt; *AWS Lambda* e fare clic su *Crea funzione* nella stessa regione di FSX per ONTAP</block>
  <block id="eb625a560eb6c02ecd5a6a9f47d5d768" category="list-text">Utilizza l'impostazione predefinita *Author from zero* e aggiorna i seguenti campi:</block>
  <block id="8af4ad16f59e1ac333921353c65b1492" category="paragraph">Fare clic su *Crea funzione*.</block>
  <block id="957437001751593737e6afeb8cd3163b" category="inline-image-macro">Questa immagine mostra la finestra di creazione di Lambda sulla console AWS.</block>
  <block id="e6242cbb73c003c124d84270c0afe97a" category="paragraph"><block ref="e6242cbb73c003c124d84270c0afe97a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="417809fda70cc9785afc8e3ceec62dff" category="paragraph"><block ref="417809fda70cc9785afc8e3ceec62dff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1659ba661865f087a67032f3c9be9fc2" category="list-text">Scorri verso il basso fino alla sezione *Layer* della nuova funzione lambda e fai clic su *Add a Layer*.</block>
  <block id="38752522b6aecd6cdf7355a1cdaa38ad" category="inline-image-macro">Questa immagine mostra il pulsante add layer sulla console delle funzioni di AWS Lambda.</block>
  <block id="cc07bde473345c3ce0ae0c8fc7097fdc" category="paragraph"><block ref="cc07bde473345c3ce0ae0c8fc7097fdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc8034a8cc3761841b945895d5bb5e74" category="list-text">Fare clic su *create a new layer* sotto *Layer source*</block>
  <block id="2be5f6c30358de16d6c4b531db0541b0" category="list-text">Creare 2 layer - 1 per le richieste e 1 per Paramiko e caricare i file *requests.zip* e *Paramiko.zip*. Selezionare *Python 3.9* come runtime compatibile e fare clic su *Create*.</block>
  <block id="44dec222c0e2e40e9770472e89813d69" category="inline-image-macro">Questa immagine mostra la finestra Create New Layer (Crea nuovo livello) sulla console AWS.</block>
  <block id="1a144f1799018bb0e4a3aff87c3ae15f" category="paragraph"><block ref="1a144f1799018bb0e4a3aff87c3ae15f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b67d38577d56792dd4197d29c7c25fd" category="list-text">Tornare ad AWS Lambda *Add Layer* &gt; *Custom Layer* e aggiungere il livello paramiko e Requests uno dopo l'altro.</block>
  <block id="018f803496bf51d7eca913d543f61cdc" category="inline-image-macro">Questa immagine mostra la finestra add layer sulla console delle funzioni di AWS Lambda.</block>
  <block id="74aec608a6fed03dea60e0a7998ac4c6" category="paragraph"><block ref="74aec608a6fed03dea60e0a7998ac4c6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6dcc7aaf4ab69d9f33228c8aca077bf7" category="inline-image-macro">Questa immagine mostra i layer aggiunti nella console delle funzioni di AWS Lambda.</block>
  <block id="87fcbd11f44be8b210a0adbfafc5f083" category="paragraph"><block ref="87fcbd11f44be8b210a0adbfafc5f083" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cdb5e7241bb52c5f33fc903e816595a6" category="list-text">Accedere alla scheda *Configurazione* della funzione lambda e fare clic su *Modifica* in *Configurazione generale*. Impostare Timeout su *5 min* e fare clic su Salva.</block>
  <block id="92997aae940f33750d6c43a65315fc0d" category="list-text">Accedere alla scheda *Permissions* della funzione lambda e fare clic sul ruolo assegnato. Nella scheda permessi del ruolo, fare clic su *Aggiungi permessi* &gt; *Crea policy inline*.</block>
  <block id="e80446ca49af46cfdbc8af6661176f5b" category="list-text">Fare clic sulla scheda JSON e incollare il contenuto del file policy.json dal repo GitHub.</block>
  <block id="85aff31d07a1ff90ecd6d3dc6401eed0" category="list-text">Sostituisci ogni occorrenza di{AWS::AccountId} con il tuo ID account e fai clic su *Review Policy*</block>
  <block id="de61df97ff6dba72d275469c25e01fe2" category="list-text">Specificare un nome per il criterio e fare clic su *Create policy* (Crea policy)</block>
  <block id="d36a4ee86f07b3ab1dac130b43608573" category="list-text">Copiare il contenuto di *fsxn_monitoring_resizing_lambda.py* da git repo a *lambda_function.py* nella sezione AWS Lambda Function Code Source.</block>
  <block id="aa2c2b9170ac97be5915c92e4d3d9624" category="list-text">Creare un nuovo file nello stesso livello di lambda_function.py e assegnargli il nome *vars.py* e copiare il contenuto di vars.py dal file git repo al file lambda function vars.py. Aggiornare i valori delle variabili in vars.py. Fare riferimento alle definizioni delle variabili riportate di seguito e fare clic su *Deploy*:</block>
  <block id="1b1b65a5b121a97f06bd0f40bfe04db2" category="cell">*FsxMgmtIp*</block>
  <block id="48aa922c7ed8d2e7d073ec505c5a679a" category="cell">(Obbligatorio) inserire "endpoint di gestione - indirizzo IP" dalla console FSX per ONTAP su AWS.</block>
  <block id="b458b0d72a95d6bd9cfcb7a5c23dcb1b" category="cell">*FsxId*</block>
  <block id="da337ce29255b2b81cd9e3a3204bbcfe" category="cell">(Obbligatorio) inserire l'ID del file system dalla console FSX per ONTAP su AWS.</block>
  <block id="68318b373e71a3da8e3dd4430fda3f2b" category="cell">*nome utente*</block>
  <block id="c0f05dbdc8c950570df5006e05838a13" category="cell">(Obbligatorio) inserire il "nome utente amministratore ONTAP" di FSX per ONTAP dalla console di ONTAP su AWS.</block>
  <block id="66139124af54a9bd769c36d775836d70" category="cell">*resize_threshold*</block>
  <block id="8c09ed6e498d70309d841ab06df44a38" category="cell">(Obbligatorio) inserire la percentuale di soglia compresa tra 0 e 100. Questa soglia verrà utilizzata per misurare la capacità di storage, il volume e l'utilizzo del LUN e quando l'utilizzo % di qualsiasi aumento oltre questa soglia, si verificherà un'attività di ridimensionamento.</block>
  <block id="497a76ab2a24f6810806482af6d4b406" category="cell">*sender_email*</block>
  <block id="e003b9f112112808c978c5154fda4ca5" category="cell">(Obbligatorio) inserire l'ID e-mail registrato su SES che verrà utilizzato dalla funzione lambda per inviare avvisi di notifica relativi al monitoraggio e al ridimensionamento.</block>
  <block id="fb154fba377735ccf71f62d4f67db056" category="cell">*email_destinatario*</block>
  <block id="84d1d8bc0deec1274356da96f7409f5a" category="cell">(Obbligatorio) inserire l'ID e-mail in cui si desidera ricevere le notifiche di avviso.</block>
  <block id="e405587a28590f4765b9cca9a439aee0" category="cell">*fsx_password_ssm_parameter*</block>
  <block id="fd6fdc9b8903fcc41d72463456f66547" category="cell">(Obbligatorio) inserire il nome del percorso utilizzato in AWS Parameter Store per memorizzare la password "fsxadmin".</block>
  <block id="a2b399451f43de7415c9c8d2f2430019" category="cell">*warn_notification*</block>
  <block id="6b0889223ab16d524cd0322c25d0b4b3" category="cell">(Obbligatorio) impostare questa variabile su True per ricevere una notifica quando l'utilizzo di capacità/volume/LUN dello storage supera il 75% ma è inferiore alla soglia.</block>
  <block id="4a011a0efb5e78112e4ed7930b4d4ac6" category="cell">*enable_snapshot_deletion*</block>
  <block id="f2a43adf70fef2a5bca3a335b60d96ec" category="cell">(Obbligatorio) impostare questa variabile su True per abilitare l'eliminazione dello snapshot a livello di volume per gli snapshot precedenti al valore specificato in "snapshot_age_threshold_in_days".</block>
  <block id="d7cef1097d40a983ff6c131976641be8" category="cell">*snapshot_age_threshold_in_days*</block>
  <block id="be6cbc09482802bc252464f7f9dc5176" category="cell">(Obbligatorio) inserire il numero di giorni di snapshot a livello di volume che si desidera conservare. Tutte le istantanee precedenti al valore fornito verranno eliminate e le stesse verranno notificate tramite e-mail.</block>
  <block id="785e900d8ea09cab57830ac6967cb709" category="cell">*accesso_internet*</block>
  <block id="24498a6850ca31bfb18f639aae517582" category="cell">(Obbligatorio) impostare questa variabile su True se l'accesso a Internet è disponibile dalla subnet in cui viene implementato questo lambda. In caso contrario, impostarlo su Falso.</block>
  <block id="cd9e7c04a0bb02c275868aa4344613da" category="cell">*smtp_region*</block>
  <block id="4a892fb521dc4ec57f770f02637e0d0d" category="cell">(Facoltativo) se la variabile "Internet_Access" è impostata su False, inserire la regione in cui viene implementato il valore lambda. Ad esempio US-East-1 (in questo formato)</block>
  <block id="07dba5c28924867968d12040d14d8b57" category="cell">*smtp_username_ssm_parameter*</block>
  <block id="611e6e1c3920f2514daecc54ecfb79d1" category="cell">(Facoltativo) se la variabile "Internet_Access" è impostata su Falso, immettere il nome del percorso utilizzato in AWS Parameter Store per memorizzare il nome utente SMTP.</block>
  <block id="00dc34bddd9d78c3a39608fed34bb12c" category="cell">*smtp_password_ssm_parameter*</block>
  <block id="7d7fbea26b1aa16fe546b51310bfd752" category="cell">(Facoltativo) se la variabile "Internet_Access" è impostata su Falso, immettere il nome del percorso utilizzato in AWS Parameter Store per memorizzare la password SMTP.</block>
  <block id="8983bb09e5de73133d38fd252364a173" category="inline-image-macro">Questa immagine mostra il codice lambda sulla console delle funzioni di AWS Lambda.</block>
  <block id="8355eb726273f03ca5f55fd35b0a710a" category="paragraph"><block ref="8355eb726273f03ca5f55fd35b0a710a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b474ff33c546908035499b53002f61bb" category="list-text">Fare clic su *Test*, creare un evento di test vuoto, eseguire il test e verificare che lo script sia in esecuzione correttamente.</block>
  <block id="44903daf5480dcfa1bb48a9ba24e0617" category="list-text">Una volta eseguito il test, accedere a *Configurazione* &gt; *Trigger* &gt; *Aggiungi trigger*.</block>
  <block id="6bb73947635f7fd1d1f74c0544fa89a6" category="paragraph">Fare clic su Add (Aggiungi).</block>
  <block id="e12ebba9179a3c37608a804ce282348d" category="inline-image-macro">Questa immagine mostra la finestra di creazione del bridge di eventi nella console delle funzioni di AWS Lambda.</block>
  <block id="4e8d49756f1c9d97f6044f5c9c1c5d02" category="paragraph"><block ref="4e8d49756f1c9d97f6044f5c9c1c5d02" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d140dcb54f7073751446004207785331" category="paragraph">Con la soluzione fornita, è facile configurare una soluzione di monitoraggio che monitora regolarmente FSX per lo storage ONTAP, ridimensiona il sistema in base alla soglia specificata dall'utente e fornisce un meccanismo di avviso. In questo modo, il processo di utilizzo e monitoraggio di FSX per ONTAP consente agli amministratori di concentrarsi sulle attività business-critical, mentre lo storage cresce automaticamente quando necessario.</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="summary">Le note legali forniscono l'accesso a dichiarazioni di copyright, marchi, brevetti e altro ancora.</block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">Note legali</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">Copyright</block>
  <block id="09e95b77ffe81fe465a83ba99efad5c8" category="paragraph"><block ref="09e95b77ffe81fe465a83ba99efad5c8" category="inline-link-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">Marchi</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NETAPP, il logo NETAPP e i marchi elencati nella pagina dei marchi NetApp sono marchi di NetApp, Inc. Altri nomi di società e prodotti potrebbero essere marchi dei rispettivi proprietari.</block>
  <block id="7aa531e9acfe2b98e34d2c92fe9846ff" category="paragraph"><block ref="7aa531e9acfe2b98e34d2c92fe9846ff" category="inline-link-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">Brevetti</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">Un elenco aggiornato dei brevetti di proprietà di NetApp è disponibile all'indirizzo:</block>
  <block id="d7f1fbcf9ce4e42f705add574d262b2c" category="paragraph"><block ref="d7f1fbcf9ce4e42f705add574d262b2c" category="inline-link-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">Direttiva sulla privacy</block>
  <block id="fc248f74f5e36542f7f5627b8610e9a3" category="paragraph"><block ref="fc248f74f5e36542f7f5627b8610e9a3" category="inline-link-rx"></block></block>
  <block id="c0227cef6f07a8cd2ac72f2945b031aa" category="section-title">Open source</block>
  <block id="9b73989307c1975dfa4d5e1581e4afe8" category="paragraph">I file di avviso forniscono informazioni sul copyright e sulle licenze di terze parti utilizzate nel software NetApp.</block>
  <block id="91af64270656f51ceebeabc4b79ecb07" category="summary">NetApp VDS può essere implementato su Microsoft Azure utilizzando un'applicazione di configurazione disponibile in base alla base di codice richiesta.</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="doc">Implementazione</block>
  <block id="29707848401dd26f02baed07b9a416c1" category="paragraph">NetApp VDS può essere implementato su Microsoft Azure utilizzando un'applicazione di configurazione disponibile in base alla base di codice richiesta. La versione corrente è disponibile<block ref="deb5bc0c1293f06a53a77d04b921abbd" category="inline-link-rx"></block> e la release di anteprima del prodotto in arrivo è disponibile<block ref="b5073644bfe6db36c388c6bdbca64b49" category="inline-link-rx"></block>.</block>
  <block id="201e09e85ad81db8a19ef9f20c05d1a5" category="inline-link">questo video</block>
  <block id="c4e1987e3c1416cefd772fd61f28dfb4" category="paragraph">Vedere<block ref="f8270911b627accef36841f0608bc58d" category="inline-link-rx"></block> per le istruzioni di implementazione.</block>
  <block id="4c9affd9b517fc81a601ea0861dc5399" category="inline-link-macro">Avanti: Ambiente di cloud ibrido</block>
  <block id="2045518eb8a77a5284f073d0387f9a58" category="paragraph"><block ref="2045518eb8a77a5284f073d0387f9a58" category="inline-link-macro-rx"></block></block>
  <block id="53cf9d36e61cc97b118ae4cc9589bac3" category="summary">Il portale NetApp VDS Cloud Workspace Management Suite consente la gestione centralizzata di varie implementazioni VDS, tra cui una con siti definiti per utenti on-premise, amministrativi, catalogo di applicazioni ed eventi con script. Il portale viene utilizzato anche dagli utenti amministrativi per il provisioning manuale delle applicazioni, se necessario, e per la connessione a qualsiasi computer per la risoluzione dei problemi.</block>
  <block id="e68a6dedaba6faaba6e7afd9197edc4f" category="doc">Portale di gestione</block>
  <block id="76368893e7696218fc60d77f96235f35" category="paragraph">È disponibile il portale NetApp VDS Cloud Workspace Management Suite<block ref="1640f4040bca8395064a2ee51cb5f0ae" category="inline-link-rx"></block> e la prossima versione è disponibile<block ref="b6375c31f2253ef964d998b5762ba440" category="inline-link-rx"></block>.</block>
  <block id="02655da204b103696191f5d52c33427f" category="paragraph">Il portale consente la gestione centralizzata di varie implementazioni VDS, tra cui una con siti definiti per utenti on-premise, amministrativi, catalogo di applicazioni ed eventi con script. Il portale viene utilizzato anche dagli utenti amministrativi per il provisioning manuale delle applicazioni, se necessario, e per la connessione a qualsiasi computer per la risoluzione dei problemi.</block>
  <block id="0499b0532cd51452b57a028f3973d9fa" category="paragraph">I service provider possono utilizzare questo portale per aggiungere i propri partner di canale e consentire loro di gestire i propri client.</block>
  <block id="8af19d014b76fa90ffc0c0477bd47be5" category="inline-link-macro">Avanti: Gestione degli utenti</block>
  <block id="631d677d75a0b47f9fe24a201cc8cb85" category="paragraph"><block ref="631d677d75a0b47f9fe24a201cc8cb85" category="inline-link-macro-rx"></block></block>
  <block id="a3af49b9146a6a36e8bea4c525797782" category="summary">In questa pagina vengono descritti lo strumento DCConfig, gli strumenti TestVdc e i file di log.</block>
  <block id="d56ee3058d1c4ab634cd3e1e606f2064" category="doc">Strumenti e registri</block>
  <block id="626b1761e15913fc6f955e1d76a0ac10" category="section-title">Tool DCConfig</block>
  <block id="65bbb1c25836b86f699bd2141a545958" category="paragraph">Lo strumento DCCconfig supporta le seguenti opzioni di hypervisor per l'aggiunta di un sito:</block>
  <block id="2c76e52255da65e5fcf88143f91aa431" category="paragraph"><block ref="2c76e52255da65e5fcf88143f91aa431" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da2595b668536baaea606e674ade5181" category="paragraph"><block ref="da2595b668536baaea606e674ade5181" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2eb34c5311117b56d2c8eb33494052a3" category="paragraph">È possibile gestire la mappatura delle lettere di unità specifiche dell'area di lavoro per i dati condivisi utilizzando l'oggetto Criteri di gruppo. Professional Services o il team di supporto possono utilizzare la scheda Advanced per personalizzare impostazioni come i nomi delle unità organizzative di Active Directory, l'opzione per attivare o disattivare la distribuzione di FSLogix, vari valori di timeout e così via.</block>
  <block id="8688a5dde644921ea673f5bc2dde55c3" category="paragraph"><block ref="8688a5dde644921ea673f5bc2dde55c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6c93f3609bb3be799ed32b6a601d5fc" category="section-title">Command Center (precedentemente noto come TestVdc Tools)</block>
  <block id="46433f623976c5af8ebdc7ab92816a48" category="inline-link-macro">Panoramica del Command Center</block>
  <block id="bf69b43c185864d35a461d8f1c3ea56e" category="paragraph">Per avviare Command Center e il ruolo richiesto, vedere <block ref="d7ce3bd63a8a34b9b1630abb82acb951" category="inline-link-macro-rx"></block>.</block>
  <block id="b425cca2998cc4a7041a0baf7681e912" category="paragraph">È possibile eseguire le seguenti operazioni:</block>
  <block id="b462233b13790bce7e4c6449d02cf930" category="list-text">Modificare il percorso SMB per un'area di lavoro.</block>
  <block id="ee347a7998de9774369e6853f1ed7bcc" category="paragraph"><block ref="ee347a7998de9774369e6853f1ed7bcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c524c01ee30f2f1597bb3e90c721dd8c" category="list-text">Modificare il sito per la raccolta di provisioning.</block>
  <block id="ccb9931a262a0b169576103526fa2ab2" category="paragraph"><block ref="ccb9931a262a0b169576103526fa2ab2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af6ba12de0b8c93d5f768c83143c7d99" category="section-title">File di log</block>
  <block id="017b9aa293da801da252c728736f02db" category="inline-link-macro">log di automazione</block>
  <block id="580acc766c3f0e464b462d271028dc32" category="paragraph"><block ref="5f6615a18cd0f2f0bcfb7578db5d1c9e" category="inline-image-macro-rx" type="image"></block>Controllare <block ref="11597d7347faee3da56e0e01d5ba1de2" category="inline-link-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="254a4a0ddc892d6a01d7e7ef286fbb71" category="inline-link-macro">Prossimo: Conclusione</block>
  <block id="881784d32d0ec795e6fd477e7c0fe8f7" category="paragraph"><block ref="881784d32d0ec795e6fd477e7c0fe8f7" category="inline-link-macro-rx"></block></block>
  <block id="bf6d8e47240024519d1dbb6f5582ce66" category="summary">Le workstation grafiche sono generalmente utilizzate in settori come produzione, sanità, energia, media e intrattenimento, istruzione, e così via. La mobilità è spesso limitata per le applicazioni a uso intensivo di grafica.</block>
  <block id="942cd85feff07ce32d619d2f724254a8" category="doc">Soluzioni per il settore</block>
  <block id="fb987436787e4263bfee440b93703026" category="paragraph">Per risolvere il problema della mobilità, i servizi di desktop virtuale offrono un ambiente desktop per tutti i tipi di lavoratori, dai task worker agli utenti esperti, utilizzando risorse hardware nel cloud o con NetApp HCI, incluse le opzioni per configurazioni flessibili della GPU. VDS consente agli utenti di accedere al proprio ambiente di lavoro da qualsiasi luogo con laptop, tablet e altri dispositivi mobili.</block>
  <block id="68ae3286d2356ff8dd51c2a397ca20eb" category="paragraph">Per eseguire carichi di lavoro di produzione con software come ANSYS Fluent, ANSYS Mechanical, Autodesk AutoCAD, Autodesk Inventor, Autodesk 3ds Max, Dassault Systèmes SOLIDWORKS, Dassault Systèmes CATIA, PTC Creo, Siemens PLM NX e così via, Le GPU disponibili su diversi cloud (a gennaio 2021) sono elencate nella seguente tabella.</block>
  <block id="f5168df5bb95078acdfb440f5975a601" category="cell">Modello GPU</block>
  <block id="1668ca1bd914c1d847f23b491319ac91" category="cell">Microsoft Azure</block>
  <block id="b314ebdba178173db01ffda8d3a5af67" category="cell">Google Compute (GCP)</block>
  <block id="943ca3782b28d89aff2f86a50b332b3c" category="cell">Amazon Web Services (AWS)</block>
  <block id="8df8a98ff17d4d77329f5da80da051e8" category="cell">On-premise (NetApp HCI)</block>
  <block id="aaba9e920b39aa997c69800a9e589cd4" category="cell">NVIDIA M60</block>
  <block id="e095ad80d900786110d53ecd5cbd3e3e" category="cell">NVIDIA T4</block>
  <block id="c909ed1507c6d5537f0cc0966e83d3f1" category="cell">NVIDIA P100</block>
  <block id="c015c1cc95335d3b867c145c056df10b" category="cell">NVIDIA P4</block>
  <block id="e8130bb14c9382769c22861fb54683b3" category="paragraph">Sono inoltre disponibili sessioni desktop condivise con altri utenti e desktop personali dedicati. I desktop virtuali possono avere da una a quattro GPU o utilizzare GPU parziali con NetApp HCI. NVIDIA T4 è una scheda GPU versatile in grado di soddisfare le esigenze di un'ampia gamma di carichi di lavoro degli utenti. Ogni scheda GPU su NetApp HCI H615C dispone di 16 GB di memoria frame buffer e tre schede per server. Il numero di utenti che possono essere ospitati su un singolo server H615C dipende dal carico di lavoro dell'utente.</block>
  <block id="4d8b78a5288c49df59136421211718c9" category="cell">Utenti/Server</block>
  <block id="704316eb872cbca84a8b30d74c2708a4" category="cell">Leggero (4 GB)</block>
  <block id="6f3a945a32dd8eba9f2fae42715f7246" category="cell">Media (8 GB)</block>
  <block id="adb5e5b63d256f3854fc7276b3e8d14a" category="cell">Pesante (16 GB)</block>
  <block id="bd40934d28717a37aa4087f1622d8f0b" category="cell">H615C</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3</block>
  <block id="8938ba807f25f2cd88559b9f84bbc3de" category="paragraph">Per determinare il tipo di utente, eseguire il profiler GPU mentre gli utenti lavorano con le applicazioni che eseguono attività tipiche. Il profiler GPU acquisisce le richieste di memoria, il numero di display e la risoluzione richiesta dagli utenti. È quindi possibile scegliere il profilo vGPU che soddisfa i requisiti.</block>
  <block id="1b014a2b6e4c329b9696aae7afac88db" category="paragraph">I desktop virtuali con GPU possono supportare una risoluzione dello schermo fino a 8K, mentre l'utility nView può suddividere un singolo monitor in regioni per lavorare con diversi set di dati.</block>
  <block id="30f1a84c728d67b9606115a1531aa9c3" category="paragraph">Con lo storage di file ONTAP, puoi ottenere i seguenti vantaggi:</block>
  <block id="826f3d14d0c34cd0f8ced37e07a1537d" category="list-text">Un singolo namespace in grado di crescere fino a 20 PB di storage con 400 miliardi di file, senza molti input amministrativi</block>
  <block id="1d7ab3c9a162bc81b216bdc0948094f2" category="list-text">Uno spazio dei nomi che può estendersi a livello globale con una Global file cache</block>
  <block id="2d4169e0cb52db60fd11576990b38a54" category="list-text">Multi-tenancy sicura con lo storage NetApp gestito</block>
  <block id="a44c13ec320997e84b87b0fef150c39f" category="list-text">Migrazione dei dati cold in archivi di oggetti utilizzando NetApp FabricPool</block>
  <block id="3749fba0ca78e5e5c70f899da89be2c3" category="list-text">Statistiche rapide sui file con analisi del file system</block>
  <block id="63d0ec819ea12b4e83e0ef4a1cd2bb1c" category="list-text">Scalabilità di un cluster di storage fino a 24 nodi per aumentare capacità e performance</block>
  <block id="818a13118ddb0908ba00c1b7ca18dc2c" category="list-text">Possibilità di controllare lo spazio di storage utilizzando quote e performance garantite con limiti di QoS</block>
  <block id="ef94cd0a62341c72316393b1044582f8" category="list-text">Protezione dei dati con crittografia</block>
  <block id="c1e36bb7dca3b0da98164eb5956e3f0f" category="list-text">Soddisfare i più ampi requisiti di protezione e conformità dei dati</block>
  <block id="6a632279908ad5d56ab46a826de6c9f2" category="list-text">Offrire opzioni flessibili di business continuity</block>
  <block id="3c2622109ae4dc55b73e9bb6516e5616" category="paragraph"><block ref="3c2622109ae4dc55b73e9bb6516e5616" category="inline-link-macro-rx"></block></block>
  <block id="868ab86f19065016e9a2f077c5ec1ede" category="summary">I task worker possono avviare rapidamente un'applicazione dall'elenco di applicazioni disponibili. I servizi app pubblicano le applicazioni dagli host della sessione di servizi Desktop remoto. Con WVD, i gruppi di applicazioni offrono funzionalità simili dai pool di host di Windows 10 a più sessioni.</block>
  <block id="aa08bd8b0522ea3a5e9ace598db7162c" category="doc">Gestione delle applicazioni</block>
  <block id="f83a66a518ff3f3f44725a09d9666710" category="paragraph">Per consentire agli impiegati di potenziare gli utenti, è possibile eseguire il provisioning manuale delle applicazioni necessarie utilizzando una scheda di servizio oppure eseguire il provisioning automatico utilizzando la funzionalità di script degli eventi di NetApp VDS.</block>
  <block id="546d3f7d3bb8a664a6ba4a3fb2f68c30" category="inline-link">Pagina NetApp Application Entitlement</block>
  <block id="175ba74f5b7d0ecd3f531c5fce21a240" category="paragraph">Per ulteriori informazioni, consultare<block ref="03e02ecfc967e94041a86f599e14ac44" category="inline-link-rx"></block>.</block>
  <block id="fd324b11a163d2dae6bf3f9654381d16" category="inline-link-macro">Avanti: Funzionalità di ONTAP per il servizio di desktop virtuale</block>
  <block id="25838148a81bcaa2b7e931ef8cd65a13" category="paragraph"><block ref="25838148a81bcaa2b7e931ef8cd65a13" category="inline-link-macro-rx"></block></block>
  <block id="c6aaad7e04b9605d83a2a2aa661fc1b4" category="summary">Con NetApp VDS, gli amministratori possono delegare le attività ad altri. Possono connettersi ai server implementati per risolvere i problemi, visualizzare i log ed eseguire i report di audit. Mentre assistono i clienti, l'helpdesk o i tecnici di livello 3 possono affiancare le sessioni degli utenti, visualizzare gli elenchi dei processi e, se necessario, eliminare i processi.</block>
  <block id="3a1e041969ddc2d8e0e399260d9159a7" category="doc">Test di carico di un singolo server con Login VSI</block>
  <block id="12d80b6f529069c8b2bc8d45947a0379" category="paragraph">Il NetApp Virtual Desktop Service utilizza il protocollo Microsoft Remote Desktop per accedere alle sessioni e alle applicazioni del desktop virtuale, mentre il tool Login VSI determina il numero massimo di utenti che possono essere ospitati su un modello di server specifico. Login VSI simula l'accesso dell'utente a intervalli specifici ed esegue operazioni dell'utente come l'apertura di documenti, la lettura e la composizione di e-mail, l'utilizzo di Excel e PowerPoint, la stampa di documenti, la compressione dei file e l'esecuzione di interruzioni casuali. Quindi, misura i tempi di risposta. I tempi di risposta dell'utente sono bassi quando l'utilizzo del server è basso e aumentano quando vengono aggiunte più sessioni dell'utente. Login VSI determina la linea di base in base alle sessioni di accesso utente iniziali e riporta la sessione utente massima quando la risposta dell'utente supera i 2 secondi dalla linea di base.</block>
  <block id="4be1d7a9b1a8d85ed7d1cf5c72b23928" category="paragraph">NetApp Virtual Desktop Service utilizza Microsoft Remote Desktop Protocol per accedere alle applicazioni e alle sessioni di Virtual Desktop. Per determinare il numero massimo di utenti che possono essere ospitati su un modello di server specifico, è stato utilizzato il tool Login VSI. Login VSI simula l'accesso dell'utente a intervalli specifici ed esegue operazioni dell'utente come l'apertura di documenti, la lettura e la composizione di e-mail, l'utilizzo di Excel e PowerPoint, la stampa di documenti, la compressione di file, l'esecuzione di interruzioni casuali e così via. Inoltre, misura i tempi di risposta. I tempi di risposta dell'utente sono bassi quando l'utilizzo del server è basso e aumentano quando vengono aggiunte più sessioni dell'utente. Login VSI determina la linea di base in base alle sessioni di accesso utente iniziali e riporta il numero massimo di sessioni utente quando la risposta dell'utente supera i 2 secondi dalla linea di base.</block>
  <block id="481e9968651d6bd0d36d67a776a0f32a" category="paragraph">La seguente tabella contiene l'hardware utilizzato per questa convalida.</block>
  <block id="a559b87068921eec05086ce5485e9784" category="cell">Modello</block>
  <block id="e93f994f01c537c4e2f7d8528c3eb5e9" category="cell">Conta</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">Descrizione</block>
  <block id="8417ade953d75aa6fa3c64813e005e17" category="cell">NetApp HCI H610C</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4</block>
  <block id="ec1d568aa57f1e1231acef5759640fc6" category="cell">Tre in un cluster per i lanciatori, ad, DHCP e così via. Un server per il test del carico.</block>
  <block id="5b68b81817d64cfa84c65e2e185efe97" category="cell">NetApp HCI H615C</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1</block>
  <block id="c36af9ab64be0b8bd4d5097f58b8a5ba" category="cell">2 x 24 C Intel Xeon Gold 6282 @2,1 GHz. 1,5 TB DI RAM.</block>
  <block id="825c03a9f78635bec804883dde1bd6bf" category="paragraph">La seguente tabella contiene il software utilizzato per la convalida.</block>
  <block id="f5bf48aa40cad7891eb709fcf1fde128" category="cell">prodotto</block>
  <block id="f80ee94fe4a9c10f8d85e442e7521687" category="cell">NetApp VDS 5.4</block>
  <block id="d9cc1f843ea62c12a3e59afbbdc2f9ce" category="cell">Orchestrazione</block>
  <block id="bb15f84d3b96a9b33719b8a71bc62207" category="cell">Modelli di macchine virtuali Windows 2019 1809</block>
  <block id="f6a3c0d463e2ae697b02a9893e2062a3" category="cell">Sistema operativo server per RDSH</block>
  <block id="5a264c4e5b7b75d4ead67bf3ff7988bc" category="cell">Accedere a VSI</block>
  <block id="5227da0541209a94c7dc0a07cf3e0740" category="cell">4.1.32.1</block>
  <block id="123995603a5e237810bf85a8e3c73f2e" category="cell">VMware vSphere 6.7 Update 3</block>
  <block id="1b21b0d71706897b69f108572c444d40" category="cell">Hypervisor</block>
  <block id="2752fcc90cb7cc7439b827d762e89166" category="cell">VMware vCenter 6.7 Update 3f</block>
  <block id="436bc441be68b676a199df5c1ea02263" category="cell">Tool di gestione VMware</block>
  <block id="9ad541af6dac1be0c6655522128a386c" category="paragraph">I risultati del test Login VSI sono i seguenti:</block>
  <block id="17126aef3e415713552604218f448967" category="cell">Configurazione delle macchine virtuali</block>
  <block id="084abcce930cefa047af15fc0836639a" category="cell">Accesso VSI baseline</block>
  <block id="8bb9799dff9f679e2305879f7dc1a9f0" category="cell">Accesso VSI Max</block>
  <block id="e49775052ecbe49b489c84d0b09e916e" category="cell">H610C</block>
  <block id="a9cc7da7b66d8162a44a176bb1109440" category="cell">8 vCPU, 48 GB di RAM, disco da 75 GB, profilo 8Q vGPU</block>
  <block id="28267ab848bcf807b2ed53c3a8f8fc8a" category="cell">799</block>
  <block id="8f85517967795eeef66c225f7883bdcb" category="cell">178</block>
  <block id="4052d2c7017812dc33333a4dc7e83dc9" category="cell">12 vCPU, 128 GB di RAM, disco da 75 GB</block>
  <block id="eefc9e10ebdc4a2333b42b2dbb8f27b6" category="cell">763</block>
  <block id="7a614fd06c325499f1680b9896beedeb" category="cell">272</block>
  <block id="71c62dd6d64bb960471819c829a777fd" category="paragraph">Considerando i limiti inferiori a NUMA e l'hyperthreading, le otto macchine virtuali scelte per il test e la configurazione delle macchine virtuali dipendono dai core disponibili sull'host.</block>
  <block id="0f57e9c52f3aa2d44da0de48ac87443a" category="paragraph">Abbiamo utilizzato 10 macchine virtuali di avvio sull'H610C, che utilizzavano il protocollo RDP per connettersi alla sessione utente. La figura seguente mostra le informazioni di connessione Login VSI.</block>
  <block id="ad1351ac01d5fe0ac5546c8a2fd2d170" category="paragraph"><block ref="ad1351ac01d5fe0ac5546c8a2fd2d170" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dba4e8b5ffc06c0ccce673fd6f48159" category="paragraph">La figura seguente mostra il tempo di risposta di Login VSI rispetto alle sessioni attive per H610C.</block>
  <block id="8d58d21e6be9e4be37d3c42935a380b5" category="paragraph"><block ref="8d58d21e6be9e4be37d3c42935a380b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65f671ed80b2c6f0cc371ab295230a3a" category="paragraph">La figura seguente mostra il tempo di risposta di Login VSI rispetto alle sessioni attive per H615C.</block>
  <block id="72cce33d21386089f9a521f893c14d41" category="paragraph"><block ref="72cce33d21386089f9a521f893c14d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c29ae1e9123280c1975dbc407f3eca3" category="paragraph">Le metriche delle performance di Cloud Insights durante il test VSI di accesso H615C per host vSphere e macchine virtuali sono illustrate nella figura seguente.</block>
  <block id="d64755ae2a4094876fbaf88a161ddec2" category="paragraph"><block ref="d64755ae2a4094876fbaf88a161ddec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ab628831ed501803e9da2a64f12dd6e" category="inline-link-macro">Pagina successiva: Portale di gestione</block>
  <block id="20fcc4e371ed448b0d5ffee3f4aecb43" category="paragraph"><block ref="20fcc4e371ed448b0d5ffee3f4aecb43" category="inline-link-macro-rx"></block></block>
  <block id="57eae0e26c1c0bbaec9110d010f68f7a" category="summary">NetApp HCI è un'infrastruttura di cloud ibrido costituita da una combinazione di nodi di storage e nodi di calcolo. È disponibile come unità a due rack o come unità a rack singolo, a seconda del modello. L'installazione e la configurazione necessarie per implementare le macchine virtuali sono automatizzate con NetApp Deployment Engine (NDE). I cluster di calcolo vengono gestiti con VMware vCenter e i cluster di storage vengono gestiti con il plug-in vCenter implementato con NDE.</block>
  <block id="855faa205a8f23993f1a0fe1ac2cde2f" category="doc">Panoramica di NetApp HCI</block>
  <block id="95404d16cb98456e438a61d79a0a31d9" category="paragraph">NetApp HCI è un'infrastruttura di cloud ibrido costituita da una combinazione di nodi di storage e nodi di calcolo. È disponibile come unità a due rack o come unità a rack singolo, a seconda del modello. L'installazione e la configurazione necessarie per implementare le macchine virtuali sono automatizzate con NetApp Deployment Engine (NDE). I cluster di calcolo vengono gestiti con VMware vCenter e i cluster di storage vengono gestiti con il plug-in vCenter implementato con NDE. Una VM di gestione chiamata mNode viene implementata come parte di NDE.</block>
  <block id="b6ab683d50d83f639ae697569117a54b" category="paragraph">NetApp HCI gestisce le seguenti funzioni:</block>
  <block id="d15278d453245d004f8fd55cff421171" category="list-text">Aggiornamenti della versione</block>
  <block id="b783caf332f2c3190dcb6ced64290f5a" category="list-text">Invio di eventi a vCenter</block>
  <block id="79adeb760f6909dd746e1e7adae6cd58" category="list-text">Gestione del plug-in vCenter</block>
  <block id="a45e04274259a13dff2a10641a0fd97f" category="list-text">Tunnel VPN per il supporto</block>
  <block id="227590ca6f7ff3f3cc72e49cf277625f" category="list-text">NetApp Active IQ Collector</block>
  <block id="b0088ee645cccd0951013eb53d0b3816" category="list-text">L'estensione dei NetApp Cloud Services on-premise, consentendo un'infrastruttura di cloud ibrido. La figura seguente mostra i componenti HCI.</block>
  <block id="1a811712e3bea62b6f5bd1851b149fc3" category="paragraph"><block ref="1a811712e3bea62b6f5bd1851b149fc3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4725a4744390b735ea1bb4e3fc99b686" category="section-title">Nodi di storage</block>
  <block id="65f0d96af236e344bd739fd20df1fa5d" category="paragraph">I nodi di storage sono disponibili come unità rack a mezza larghezza o a larghezza intera. Inizialmente sono necessari almeno quattro nodi di storage e un cluster può espandersi fino a 40 nodi. Un cluster di storage può essere condiviso tra più cluster di calcolo. Tutti i nodi di storage contengono un controller della cache per migliorare le performance di scrittura. Un singolo nodo fornisce 50.000 o 100.000 IOPS con una dimensione del blocco 4K.</block>
  <block id="d31f04e865057f7055f2d8287b92ba2d" category="paragraph">I nodi di storage NetApp HCI eseguono il software NetApp Element, che fornisce limiti di QoS minimi, massimi e burst. Il cluster di storage supporta una combinazione di nodi di storage, anche se un nodo di storage non può superare un terzo della capacità totale.</block>
  <block id="0f66538edca95cf4d42667cfa5d6a362" category="section-title">Nodi di calcolo</block>
  <block id="449aaf51a6dfa9c0e17423ae5938d674" category="inline-link">Guida alla compatibilità VMware</block>
  <block id="1046a3e2377d26c40f75eb2cd2f268da" category="admonition">NetApp supporta lo storage connesso a qualsiasi server di calcolo elencato nella<block ref="72cc7e3e2b2d7f777e05aa309ef5f733" category="inline-link-rx"></block>.</block>
  <block id="bc1a52314ab38efacf0a83e9df0b01cc" category="paragraph">I nodi di calcolo sono disponibili in metà larghezza, larghezza completa e due dimensioni di unità rack. I modelli NetApp HCI H410C e H610C sono basati su processori scalabili Intel Skylake. H615C è basato su processori scalabili Intel Cascade Lake di seconda generazione. Esistono due modelli di calcolo che contengono GPU: Il modello H610C contiene due schede NVIDIA M10 e il modello H615C contiene tre schede NVIDIA T4.</block>
  <block id="683876986e8fe1045fa768b4a8675ea9" category="paragraph"><block ref="683876986e8fe1045fa768b4a8675ea9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9667ae1b4be7e4c088e175844fd675e6" category="paragraph">NVIDIA T4 dispone di 40 core RT che forniscono la potenza di calcolo necessaria per fornire il ray tracing in tempo reale. Lo stesso modello di server utilizzato da progettisti e ingegneri può ora essere utilizzato anche dagli artisti per creare immagini fotorealistiche con luce che rimbalza dalle superfici proprio come nella vita reale. Questa GPU compatibile con RTX produce prestazioni di ray tracing in tempo reale fino a cinque Giga raggi al secondo. NVIDIA T4, se combinata con il software quadro Virtual Data Center Workstation (quadro VDWS), consente agli artisti di creare design fotorealistici con ombre, riflessi e rifrazioni precise su qualsiasi dispositivo da qualsiasi posizione.</block>
  <block id="bee5034948808ff859affdc8ba03b52c" category="paragraph">I core Tensor ti consentono di eseguire carichi di lavoro di deduzione per l'apprendimento approfondito. Durante l'esecuzione di questi carichi di lavoro, NVIDIA T4 con quadro VDWS offre prestazioni fino a 25 volte più veloci rispetto a una macchina virtuale gestita da un server solo CPU. NetApp H615C con tre schede NVIDIA T4 in un'unità rack è la soluzione ideale per la grafica e i carichi di lavoro a elaborazione intensiva.</block>
  <block id="1f99f286804bf2f5a91a1cdd1733decf" category="paragraph">La figura seguente elenca le schede NVIDIA GPU e ne confronta le caratteristiche.</block>
  <block id="67c0c3f98979352a9ed10f0de3d551f3" category="paragraph"><block ref="67c0c3f98979352a9ed10f0de3d551f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b4fc2931642829391b479ea5fb1e9d" category="paragraph">La GPU M10 rimane la migliore soluzione TCO per i casi di utilizzo dei knowledge worker. Tuttavia, il T4 rappresenta un'ottima alternativa quando si desidera standardizzare su una GPU che può essere utilizzata in diversi casi di utilizzo, come workstation virtuali, performance grafiche, rendering interattivo in tempo reale e deduzione. Con il T4, L'IT può sfruttare le stesse risorse GPU per eseguire carichi di lavoro misti―ad esempio, eseguendo VDI durante il giorno e riutilizzando le risorse per eseguire i carichi di lavoro di calcolo di notte.</block>
  <block id="bdced20c33601e0149aecb44114cfdc5" category="paragraph">Il nodo di calcolo H610C è costituito da due unità rack; il modello H615C è un'unità rack di dimensioni pari a una e consuma meno energia. Il modello H615C supporta la codifica e la decodifica H.264 e H.265 (High Efficiency Video Coding [HEVC]) 4:4:4. Supporta anche il decoder VP9 sempre più diffuso; anche il pacchetto container WebM fornito da YouTube utilizza il codec VP9 per il video.</block>
  <block id="fe046fc197d12a64da1ea78423a2a809" category="paragraph">Il numero di nodi in un cluster di calcolo è determinato da VMware; attualmente è 96 con VMware vSphere 7.0 Update 1. La combinazione di diversi modelli di nodi di calcolo in un cluster è supportata quando è attivata la compatibilità vMotion avanzata (EVC).</block>
  <block id="f0bee2b90db3a99440b1a724c49ce1a2" category="inline-link-macro">Successivo: Licenza NVIDIA</block>
  <block id="e0bca2831f4cccfcaebc75e9555a1719" category="paragraph"><block ref="e0bca2831f4cccfcaebc75e9555a1719" category="inline-link-macro-rx"></block></block>
  <block id="60ece3fee8421729100872ec44f1cda9" category="summary">Come parte dell'implementazione, è possibile scegliere il metodo di file-service per ospitare il profilo utente, i dati condivisi e la cartella del disco principale. Le opzioni disponibili sono file server, Azure Files o Azure NetApp Files. Tuttavia, dopo l'implementazione, è possibile modificare questa scelta con il tool Command Center per puntare a qualsiasi condivisione SMB. L'hosting con NetApp ONTAP offre diversi vantaggi.</block>
  <block id="568483e9bd85504f3c9dcef24ecd3235" category="doc">Gestione dei dati</block>
  <block id="1b8c33cc721641b8b0555f2d7b5c2773" category="inline-link-macro">L'hosting con NetApp ONTAP offre diversi vantaggi</block>
  <block id="ef9fd867f3eaed93e0806bd027825218" category="inline-link">Modifica livello dati</block>
  <block id="698e77d7e678617a2ae27ca2525bfbf7" category="paragraph">Come parte dell'implementazione, è possibile scegliere il metodo di file-service per ospitare il profilo utente, i dati condivisi e la cartella del disco principale. Le opzioni disponibili sono file server, Azure Files o Azure NetApp Files. Tuttavia, dopo l'implementazione, è possibile modificare questa scelta con il tool Command Center per puntare a qualsiasi condivisione SMB. <block ref="50056d02f0a90e2e837160c093f1b22b" category="inline-link-macro-rx"></block>. Per informazioni su come modificare la condivisione SMB, consulta<block ref="336429df384a16f14c12cbc8dba62525" category="inline-link-rx"></block>.</block>
  <block id="24e6e2f6171b43a847fe194a9a9b5cd0" category="section-title">Global file cache</block>
  <block id="ce29b83c61cdf6a56b49dbde9a4d57e0" category="paragraph">Quando gli utenti sono distribuiti in più siti all'interno di uno spazio dei nomi globale, Global file cache può contribuire a ridurre la latenza per i dati ad accesso frequente. L'implementazione di Global file cache può essere automatizzata utilizzando una raccolta di provisioning ed eventi con script. Global file cache gestisce le cache di lettura e scrittura a livello locale e mantiene i blocchi dei file in diverse posizioni. Global file cache può funzionare con qualsiasi file server SMB, incluso Azure NetApp Files.</block>
  <block id="87db7a122a37ab4a28f2223fa123a5be" category="paragraph"><block ref="87db7a122a37ab4a28f2223fa123a5be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d726de6a27bb533c6c8c44ea508dffa8" category="paragraph">Global file cache richiede quanto segue:</block>
  <block id="2f28046ff208122796d51bafd8d4bc9c" category="list-text">Server di gestione (server di gestione delle licenze)</block>
  <block id="83168e6cb289d732cc78427b51f93153" category="list-text">Core</block>
  <block id="e7704357fe6a312ecafae725be93b8c2" category="list-text">Edge con capacità disco sufficiente per memorizzare i dati nella cache</block>
  <block id="d70c88e6a13ca1af40b966d8d7d831c4" category="inline-link">Documentazione GFC</block>
  <block id="154c48fd725e7207d36baa74bba5fd7a" category="paragraph">Per scaricare il software e calcolare la capacità della cache del disco per Edge, consultare<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>.</block>
  <block id="1afc494dd7d35016d9524e06b68dbf2a" category="paragraph">Per la nostra convalida, abbiamo implementato le risorse di base e di gestione sulla stessa macchina virtuale in Azure e le risorse edge in NetApp HCI. Si noti che il core è il luogo in cui è richiesto l'accesso ai dati per volumi elevati e l'edge è un sottoinsieme del core. Una volta installato il software, è necessario attivare la licenza attivata prima dell'uso. A tale scopo, attenersi alla seguente procedura:</block>
  <block id="70366038f1d44fef6c71f615b677b9cf" category="list-text">Nella sezione License Configuration (Configurazione licenza), utilizzare il collegamento fare clic qui per completare l'attivazione della licenza. Quindi registrare il core.</block>
  <block id="a51a182b58a11b12770fbd2bd9643852" category="paragraph"><block ref="a51a182b58a11b12770fbd2bd9643852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d666527802938c89b9f895300aea220b" category="list-text">Fornire l'account di servizio da utilizzare per Global file cache. Per le autorizzazioni richieste per questo account, consultare<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>.</block>
  <block id="ab698dd081619e8f6dc264df6c99b73e" category="paragraph"><block ref="ab698dd081619e8f6dc264df6c99b73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b1486d5cfb9e0c5394a50e2515b53c" category="list-text">Aggiungere un nuovo file server back-end e fornire il nome del file server o l'IP.</block>
  <block id="ffeac1f6b14ca75f608539cb6c673f37" category="paragraph"><block ref="ffeac1f6b14ca75f608539cb6c673f37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="643c94b6eb5664ed3cca98d31d7dbd39" category="list-text">Sul bordo, l'unità cache deve avere la lettera D. In caso contrario, utilizzare diskpart.exe per selezionare il volume e modificare la lettera dell'unità. Effettuare la registrazione con il server di licenza come edge.</block>
  <block id="e9b41aa1ac49113064748a9c6e0f48a9" category="paragraph"><block ref="e9b41aa1ac49113064748a9c6e0f48a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="156666d997fd17a94bed67fe95334273" category="paragraph">Se la configurazione automatica principale è attivata, le informazioni principali vengono recuperate automaticamente dal server di gestione delle licenze.</block>
  <block id="891d862f33aaeafcd8ecc43e102febd3" category="paragraph"><block ref="891d862f33aaeafcd8ecc43e102febd3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a2184b1f206fd35eeb448e9937bdabe7" category="paragraph">Da qualsiasi computer client, gli amministratori che hanno utilizzato per accedere alla condivisione sul file server possono accedervi con GFC edge utilizzando UNC Path<block ref="4fe16e12c05517e32740fd6ba0c0691f" prefix=" " category="inline-code"></block>. Gli amministratori possono includere questo percorso nello script di accesso utente o nell'oggetto Criteri di gruppo per la mappatura dei dischi degli utenti nella posizione edge.</block>
  <block id="a08e5ca253097ac5ad7741e20d9dd090" category="paragraph">Per fornire un accesso trasparente agli utenti di tutto il mondo, un amministratore può configurare il Microsoft Distributed Filesystem (DFS) con collegamenti che puntano alle condivisioni del file server e alle ubicazioni edge.</block>
  <block id="0c9f570b7b5b34f0fbdab873e122d432" category="paragraph"><block ref="0c9f570b7b5b34f0fbdab873e122d432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9e8ad2bf50c8da3a637a8858d3a1391" category="paragraph">Quando gli utenti accedono con credenziali Active Directory in base alle subnet associate al sito, il client DFS utilizza il collegamento appropriato per accedere ai dati.</block>
  <block id="6a6b2107f2b5daadfd13df04f769a587" category="paragraph"><block ref="6a6b2107f2b5daadfd13df04f769a587" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8aabec6a7d3f54b83478824808357c91" category="paragraph">Le icone dei file cambiano a seconda che un file venga memorizzato nella cache; i file non memorizzati nella cache hanno una X grigia nell'angolo inferiore sinistro dell'icona. Dopo che un utente in una posizione edge accede a un file, tale file viene memorizzato nella cache e l'icona cambia.</block>
  <block id="1014b6d5d432758e9041c845e4da7830" category="paragraph"><block ref="1014b6d5d432758e9041c845e4da7830" category="inline-image-macro-rx" type="image"></block></block>
  <block id="610eee89db61eda57b4b6da39d799845" category="paragraph">Quando un file è aperto e un altro utente sta tentando di aprire lo stesso file da una posizione edge, all'utente viene richiesto di selezionare la seguente opzione:</block>
  <block id="5a31b6c180e91d3c3d3c1053bbab642c" category="paragraph"><block ref="5a31b6c180e91d3c3d3c1053bbab642c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1c6f3b21447f91b42ceee404afc53720" category="paragraph">Se l'utente seleziona l'opzione per ricevere una notifica quando la copia originale è disponibile, l'utente riceve una notifica come segue:</block>
  <block id="922c6f30fa0f74f32df2fac11a3bf378" category="paragraph"><block ref="922c6f30fa0f74f32df2fac11a3bf378" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b9bc3a03a8ae9cef2c5a66238e5ab25" category="inline-link">Video sull'implementazione di Talon e Azure NetApp Files</block>
  <block id="e725329a19c23f541a0bdbead9c9b1e7" category="paragraph">Per ulteriori informazioni, consulta questa sezione<block ref="92818ea025c5b78ace999366164c2c46" category="inline-link-rx"></block>.</block>
  <block id="fc95bd8bc19564339fe05c7bad1b7662" category="section-title">Backup SaaS</block>
  <block id="482cadbeebfa6f9c4f062c1f2724d546" category="paragraph">NetApp VDS offre protezione dei dati per Salesforce e Microsoft Office 365, inclusi Exchange, SharePoint e Microsoft OneDrive. La figura seguente mostra come NetApp VDS fornisce SaaS Backup per questi servizi dati.</block>
  <block id="0e3aff181138166393e5e5e698c994d2" category="paragraph"><block ref="0e3aff181138166393e5e5e698c994d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cde65566156674196c087d89ded5c3b" category="paragraph">Per una dimostrazione della protezione dei dati di Microsoft Office 365, vedere<block ref="158107d7e819a2ef8c2e8f24519fc9a9" category="inline-link-rx"></block>.</block>
  <block id="a067b7082c28e7dbf856ab55b29d1acb" category="paragraph">Per una dimostrazione della protezione dei dati di Salesforce, consulta<block ref="dd6e5767407887626a36af7b68defda9" category="inline-link-rx"></block>.</block>
  <block id="2cb2b89213bccd89f81cfbb17b2e070b" category="inline-link-macro">Avanti: Gestione delle operazioni</block>
  <block id="1f3d3eae36241941c6f7a1eaf3615eac" category="paragraph"><block ref="1f3d3eae36241941c6f7a1eaf3615eac" category="inline-link-macro-rx"></block></block>
  <block id="7b0f97bc4856c6b0645650d13b53acb5" category="summary">NetApp Virtual Desktop Service può essere esteso a on-premise quando esiste una connettività tra risorse on-premise e risorse cloud. Le aziende possono stabilire il collegamento a Microsoft Azure utilizzando Express Route o una connessione VPN IPSec site-to-site. È inoltre possibile creare collegamenti ad altri cloud in modo simile utilizzando un collegamento dedicato o un tunnel VPN IPSec.</block>
  <block id="995d0ae58fc48c0007c3a45046221736" category="doc">Ambiente di cloud ibrido</block>
  <block id="610e3513c7222cae8d2a7c450741211a" category="paragraph">Per la convalida della soluzione, abbiamo utilizzato l'ambiente illustrato nella figura seguente.</block>
  <block id="0d9e9a129d4eb3389af12248eb017ef1" category="paragraph"><block ref="0d9e9a129d4eb3389af12248eb017ef1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60ca94382604fd3deb8a198feed31f1b" category="paragraph">On-premise, avevamo più VLAN per la gestione, host di sessione desktop remoto e così via. Si trovavano nella subnet 172.21.146-150.0/24 e venivano instradati alla rete aziendale utilizzando il servizio di accesso di routing remoto Microsoft. Abbiamo anche eseguito le seguenti attività:</block>
  <block id="b613a58cb27d96b09550b74a616e43d8" category="list-text">Abbiamo preso nota dell'IP pubblico di Microsoft Routing and Remote Access Server (RRAS), identificato con IPchicken.com.</block>
  <block id="b0aa9d967a62cfeb9427c31c3968fb31" category="list-text">Abbiamo creato una risorsa Virtual Network Gateway (VPN basata su routing) con Azure Subscription.</block>
  <block id="2db3e884a3b1d82162c06df081b8e8f0" category="list-text">È stata creata la connessione che fornisce l'indirizzo del gateway di rete locale per l'IP pubblico del server Microsoft RRAS.</block>
  <block id="ac7b5e31749488bdca809cc69e83bcec" category="list-text">Abbiamo completato la configurazione VPN su RRAS per creare un'interfaccia virtuale utilizzando l'autenticazione pre-condivisa fornita durante la creazione del gateway VPN. Se configurata correttamente, la VPN deve trovarsi nello stato connesso. Invece di Microsoft RRAS, è possibile utilizzare pfSense o altri strumenti pertinenti per creare il tunnel VPN IPSec sito-sito. Poiché è basato su route, il tunnel reindirizza il traffico in base alle subnet specifiche configurate.</block>
  <block id="064b2713bd54ad7c04715d629ea8d77e" category="paragraph">Microsoft Azure Active Directory fornisce l'autenticazione dell'identità basata su oAuth. Le autenticazioni dei client aziendali richiedono in genere l'autenticazione basata su NTLM o Kerberos. I servizi di dominio Active Directory di Microsoft Azure eseguono la sincronizzazione dell'hash delle password tra Azure Active Directory e i controller di dominio on-premise utilizzando ADConnect.</block>
  <block id="c9ced395d02e614104c13dc687b8d960" category="paragraph">Per la convalida di questa soluzione VDS ibrida, abbiamo inizialmente implementato Microsoft Azure e aggiunto un sito aggiuntivo con vSphere. Il vantaggio di questo approccio è che i servizi della piattaforma sono stati implementati in Microsoft Azure e quindi sono stati prontamente sottoposti a backup utilizzando il portale. È quindi possibile accedere facilmente ai servizi da qualsiasi luogo, anche se il collegamento VPN del sito non è attivo.</block>
  <block id="759e5787427ba679d146727a04400c46" category="paragraph">Per aggiungere un altro sito, abbiamo utilizzato uno strumento chiamato DCConfig. Il collegamento a tale applicazione è disponibile sul desktop della macchina virtuale CWMgr (Cloud Workspace Manager). Una volta avviata l'applicazione, accedere alla scheda DataCenter Sites (Siti DataCenter), aggiungere il nuovo sito del data center e inserire le informazioni richieste come mostrato di seguito. L'URL punta all'IP vCenter. Assicurarsi che la macchina virtuale CWMgr possa comunicare con vCenter prima di aggiungere la configurazione.</block>
  <block id="ae5bd963078c278284e2aabaefb99232" category="admonition">Assicurarsi che vSphere PowerCLI 5.1 su CloudWorkspace Manager sia installato per consentire la comunicazione con l'ambiente VMware vSphere.</block>
  <block id="e0072a2f037098ba3ee9ec9e1113f1ee" category="paragraph">La seguente figura illustra la configurazione del sito del data center on-premise.</block>
  <block id="30efb5f8dd999c0f737bf30327346d6f" category="paragraph"><block ref="30efb5f8dd999c0f737bf30327346d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f823fddfaa31c0b2b910c651849fe1e0" category="paragraph">Tenere presente che sono disponibili opzioni di filtraggio per le risorse di calcolo in base al cluster specifico, al nome host o allo spazio libero della RAM. Le opzioni di filtraggio per le risorse di storage includono lo spazio libero minimo sugli archivi dati o il numero massimo di macchine virtuali per archivio dati. Gli archivi di dati possono essere esclusi utilizzando espressioni regolari. Fare clic sul pulsante Save (Salva) per salvare la configurazione.</block>
  <block id="40cf95c01dfbdb8adc110507697330bf" category="paragraph">Per convalidare la configurazione, fare clic sul pulsante Test o fare clic su Load Hypervisor (carica hypervisor) e selezionare un menu a discesa nella sezione vSphere. Deve essere compilato con i valori appropriati. È consigliabile mantenere l'hypervisor primario impostato su yes per il sito di provisioning predefinito.</block>
  <block id="b081b97ab471a870119bb85e196c0d63" category="paragraph">I modelli di macchine virtuali creati su VMware vSphere vengono utilizzati come raccolte di provisioning su VDS. Le raccolte di provisioning sono disponibili in due forme: Condivisa e VDI. Il tipo di raccolta di provisioning condiviso viene utilizzato per i servizi di desktop remoto per i quali viene applicata una singola policy di risorse a tutti i server. Il tipo di VDI viene utilizzato per le istanze di WVD per le quali il criterio di risorsa viene assegnato singolarmente. Ai server di una raccolta di provisioning può essere assegnato uno dei tre ruoli seguenti:</block>
  <block id="9a0b479d2d7eaed435c14e20818841d9" category="list-text">*TSDATA.* combinazione di servizi terminal e ruolo del server dati.</block>
  <block id="286b69ba39f77189135fbf4c39786e12" category="list-text">*TS.* servizi terminal (host di sessione).</block>
  <block id="0b39ab3df8d28606b4bb8f5891022692" category="list-text">*DATA.* file server o database server. Quando si definisce il ruolo del server, è necessario scegliere il modello di macchina virtuale e lo storage (datastore). Il datastore scelto può essere limitato a un datastore specifico oppure è possibile utilizzare l'opzione meno utilizzata in cui il datastore viene scelto in base all'utilizzo dei dati.</block>
  <block id="fb89cc64fafb0e1626269bc00c07ae73" category="paragraph">Ogni implementazione dispone di risorse VM predefinite per l'allocazione delle risorse cloud in base a utenti attivi, fissi, carico del server o numero di utenti.</block>
  <block id="d00f03f39f8119980cb5240353d345b1" category="inline-link-macro">Successivo: Test di carico del server singolo con Login VSI</block>
  <block id="af5c949297d5415f4710bd1af3f1e7a7" category="paragraph"><block ref="af5c949297d5415f4710bd1af3f1e7a7" category="inline-link-macro-rx"></block></block>
  <block id="2cdacde3c74a59c779ff64324954b86f" category="summary">NetApp Virtual Desktop Service (VDS) consente di orchestrare Remote Desktop Services (RDS) nei principali cloud pubblici e nei cloud privati. VDS supporta Windows Virtual Desktop (WVD) su Microsoft Azure. VDS automatizza molte attività che devono essere eseguite dopo l'implementazione di WVD o RDS, tra cui la configurazione delle condivisioni di file SMB (per profili utente, dati condivisi e disco principale utente), l'abilitazione delle funzionalità Windows, l'installazione di applicazioni e agenti, firewall e policy e così via.</block>
  <block id="acb7add6e3cf0ca01c52e60466c321ca" category="doc">TR-4861: Cloud ibrido VDI con Virtual Desktop Service</block>
  <block id="bb6a5b934db24610665e58e743983ae4" category="paragraph">Gli utenti utilizzano VDS per desktop dedicati, desktop condivisi e applicazioni remote. VDS fornisce eventi con script per l'automazione della gestione delle applicazioni per i desktop e riduce il numero di immagini da gestire.</block>
  <block id="38e3c8e108e8e361d0712cdfe23e0b38" category="paragraph">VDS offre un singolo portale di gestione per la gestione delle implementazioni in ambienti cloud pubblici e privati.</block>
  <block id="9abac747d764180a5fe55920e00e887d" category="section-title">Valore per il cliente</block>
  <block id="07d07e20c1ad9bd1a3e99e2303879ff9" category="paragraph">L'esplosione della forza lavoro remota del 2020 ha cambiato i requisiti di business continuity. I reparti IT devono affrontare nuove sfide per il provisioning rapido di desktop virtuali e quindi richiedere agilità di provisioning, gestione remota e i vantaggi TCO di un cloud ibrido che semplifica il provisioning on-premise e delle risorse cloud. Hanno bisogno di una soluzione di cloud ibrido che:</block>
  <block id="44ff202cbab5f506b48c6021b19c4b1c" category="list-text">Affronta la realtà dello spazio di lavoro post-COVID per consentire modelli di lavoro flessibili con dinamiche globali</block>
  <block id="53f994926861d0a62f2893b66d8b2025" category="list-text">Consente di eseguire turni di lavoro semplificando e accelerando l'implementazione degli ambienti di lavoro per tutti i dipendenti, dai task worker agli utenti più esigenti</block>
  <block id="831955bd9eabf6724f4e4b01acbb833c" category="list-text">Mobilizza la forza lavoro fornendo risorse VDI ricche e sicure indipendentemente dalla posizione fisica</block>
  <block id="ab02aa4712e65c237e92874eeef51ecd" category="list-text">Semplifica l'implementazione del cloud ibrido</block>
  <block id="074890ea8810b95d9b381027ff9baef2" category="list-text">Automatizza e semplifica la gestione della riduzione dei rischi</block>
  <block id="5eed1e48d8861a1192e8694a3d24021b" category="inline-link-macro">Successivo: Casi d'utilizzo</block>
  <block id="60e1de201d0c183e889577e990975f1a" category="paragraph"><block ref="60e1de201d0c183e889577e990975f1a" category="inline-link-macro-rx"></block></block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">Dove trovare ulteriori informazioni</block>
  <block id="b5ed404fa434aeee227f550cddf89892" category="inline-link">Cloud di NetApp</block>
  <block id="d823edbaf98641c5959f3a596de3df66" category="list-text"><block ref="d823edbaf98641c5959f3a596de3df66" category="inline-link-rx"></block></block>
  <block id="b1eb0510d1bc6ffab71faa53637ecde2" category="inline-link">Documentazione sui prodotti NetApp VDS</block>
  <block id="c5b41ed257411dffc1cc80a4c00cf17c" category="list-text"><block ref="c5b41ed257411dffc1cc80a4c00cf17c" category="inline-link-rx"></block></block>
  <block id="272427e7f4e6650df3749f83086acde6" category="inline-link">Connetti la tua rete on-premise ad Azure con VPN Gateway</block>
  <block id="c460b4e40e6d4709ed15a2e8dba39833" category="list-text"><block ref="c460b4e40e6d4709ed15a2e8dba39833" category="inline-link-rx"></block></block>
  <block id="440e11297e8634c052b1bfd29a90309c" category="inline-link">Portale Azure</block>
  <block id="8284aff5fcde6ba43a0ca21712739cae" category="list-text"><block ref="8284aff5fcde6ba43a0ca21712739cae" category="inline-link-rx"></block></block>
  <block id="8867b143d669949d3948e3816324ec75" category="inline-link">Desktop virtuale Microsoft Windows</block>
  <block id="0db816b3393ed224b26131285b4e3dff" category="list-text"><block ref="0db816b3393ed224b26131285b4e3dff" category="inline-link-rx"></block></block>
  <block id="7c033f9cfba6e06ff2ee6cb852ce10f4" category="inline-link">Registrazione Azure NetApp Files</block>
  <block id="aff481c4855a001492901fbefcab7d17" category="list-text"><block ref="aff481c4855a001492901fbefcab7d17" category="inline-link-rx"></block></block>
  <block id="56b4cb3c337694fdafc2164dddad87fa" category="summary">Le GPU vengono generalmente utilizzate per la visualizzazione grafica (rendering) eseguendo calcoli aritmetici ripetitivi. Questa funzionalità di calcolo ripetitivo viene spesso utilizzata per i casi di utilizzo di ai e deep learning.</block>
  <block id="ca32c5a534baaf5f6dc3e6e6fed62450" category="doc">Considerazioni sulla GPU</block>
  <block id="ceeb28ce3b9ce753f02856fffb7ba66c" category="paragraph">Per le applicazioni ad uso intensivo di grafica, Microsoft Azure offre la serie NV basata sulla scheda NVIDIA Tesla M60 con una o quattro GPU per macchina virtuale. Ogni scheda NVIDIA Tesla M60 include due GPU basate su Maxwell, ciascuna con 8 GB di memoria GDDR5 per un totale di 16 GB.</block>
  <block id="cb433c3099845f0ac8f3ba53d162db7b" category="admonition">La serie NV include una licenza NVIDIA.</block>
  <block id="0f0c98cc175dc7cda319a35afcd199e5" category="paragraph"><block ref="0f0c98cc175dc7cda319a35afcd199e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ead26a90008a32871b53cb37bbe8431a" category="paragraph">Con NetApp HCI, la GPU H615C contiene tre schede NVIDIA Tesla T4. Ogni scheda NVIDIA Tesla T4 dispone di una GPU basata su Touring con 16 GB di memoria GDDR6. Se utilizzate in un ambiente VMware vSphere, le macchine virtuali sono in grado di condividere la GPU, con ogni macchina virtuale dotata di una memoria frame buffer dedicata. Il ray tracing è disponibile con le GPU sul NetApp HCI H615C per produrre immagini realistiche, inclusi i riflessi della luce. Tenere presente che è necessario disporre di un server di licenza NVIDIA con una licenza per le funzioni GPU.</block>
  <block id="148811d448421f6a42c549400b7201c0" category="paragraph"><block ref="148811d448421f6a42c549400b7201c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc6992cca0b3d14a85c456d0890f3e37" category="paragraph">Per utilizzare la GPU, è necessario installare il driver appropriato, che può essere scaricato dal portale di licenza NVIDIA. In un ambiente Azure, il driver NVIDIA è disponibile come estensione del driver GPU. Quindi, i criteri di gruppo nella seguente schermata devono essere aggiornati per utilizzare l'hardware GPU per le sessioni di servizio di desktop remoto. È necessario assegnare la priorità alla modalità grafica H.264 e attivare la funzionalità del codificatore.</block>
  <block id="5b0ff68b017720dd46aa6d1923fdfa95" category="paragraph"><block ref="5b0ff68b017720dd46aa6d1923fdfa95" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7d3d3d6dd94c69620cd3edfb005691c" category="paragraph">Convalidare il monitoraggio delle performance della GPU con Task Manager o utilizzando nvidia-smi CLI quando si eseguono esempi WebGL. Assicurarsi che le risorse della GPU, della memoria e dell'encoder siano in uso.</block>
  <block id="d13ca37d387c1bb473c0343278d0477d" category="paragraph"><block ref="d13ca37d387c1bb473c0343278d0477d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f2b53ac98ef55a900849ead654ca636" category="paragraph">Per assicurarsi che la macchina virtuale venga implementata in NetApp HCI H615C con servizio di desktop virtuale, definire un sito con la risorsa di cluster vCenter che dispone di host H615C. Il modello di macchina virtuale deve avere il profilo vGPU richiesto allegato.</block>
  <block id="818fad61fba48977b2293819f37e950a" category="paragraph">Per gli ambienti multi-sessione condivisi, considerare l'allocazione di più profili vGPU omogenei. Tuttavia, per le applicazioni grafiche professionali di fascia alta, è meglio avere ogni macchina virtuale dedicata a un utente per mantenere le macchine virtuali isolate.</block>
  <block id="a2db30df8af33b0e661aaed00ce2c1d3" category="paragraph">Il processore GPU può essere controllato da una policy QoS e ciascun profilo vGPU può avere frame buffer dedicati. Tuttavia, l'encoder e il decoder sono condivisi per ogni scheda. Il posizionamento di un profilo vGPU su una scheda GPU è controllato dalla policy di assegnazione della GPU host di vSphere, che può enfatizzare le performance (macchine virtuali distribuite) o il consolidamento (macchine virtuali di gruppo).</block>
  <block id="9411dea29d318927759a55cff454b3dd" category="inline-link-macro">Avanti: Soluzioni per il settore.</block>
  <block id="ee3f381f10f3f075a22913a348a89edf" category="paragraph"><block ref="ee3f381f10f3f075a22913a348a89edf" category="inline-link-macro-rx"></block></block>
  <block id="0581202e42d61d6dfe4875c70d00cdac" category="summary">NetApp Virtual Desktop Service offre un ambiente di applicazioni e desktop virtuali di facile utilizzo, con un'attenzione particolare alle sfide aziendali. Estendendo VDS con NetApp HCI, è possibile utilizzare le potenti funzionalità NetApp in un ambiente VDS, tra cui deduplica in linea, compattazione, thin provisioning e compressione.</block>
  <block id="33491606222aecbfbdfa3fc8f13ffded" category="paragraph">NetApp Virtual Desktop Service offre un ambiente di applicazioni e desktop virtuali di facile utilizzo, con un'attenzione particolare alle sfide aziendali. Estendendo i VDS con l'ambiente ONTAP on-premise, è possibile utilizzare le potenti funzionalità NetApp in un ambiente VDS, tra cui cloni rapidi, deduplica in-line, compaction, thin provisioning, e compressione. Queste funzionalità consentono di risparmiare sui costi di storage e migliorare le performance con lo storage all-flash. Con l'hypervisor VMware vSphere, che riduce al minimo i tempi di provisioning dei server utilizzando Virtual Volumes e vSphere API per l'integrazione degli array. Utilizzando il cloud ibrido, i clienti possono scegliere l'ambiente giusto per i carichi di lavoro esigenti e risparmiare denaro. La sessione desktop in esecuzione on-premise può accedere alle risorse cloud in base alle policy.</block>
  <block id="b872d0389acf826cc7cf1939cd17a05d" category="inline-link-macro">Avanti: Dove trovare ulteriori informazioni</block>
  <block id="df6f0981c6f92ef3adb9059f5b387e4a" category="paragraph"><block ref="df6f0981c6f92ef3adb9059f5b387e4a" category="inline-link-macro-rx"></block></block>
  <block id="0ccea8702c360d2d159b0e8477fe81d6" category="summary">Quando si utilizza un H610C o H615C, la licenza per la GPU deve essere acquistata dai partner NVIDIA autorizzati a rivendere le licenze.</block>
  <block id="1f26c520bd4eba393348dedea38da7b7" category="doc">Licenze NVIDIA</block>
  <block id="b548ee560d6fa4ee980d777df0300d09" category="inline-link">ricerca partner</block>
  <block id="72d760f4e8266e660fa7126e42f63bbe" category="paragraph">Quando si utilizza un H610C o H615C, la licenza per la GPU deve essere acquistata dai partner NVIDIA autorizzati a rivendere le licenze. È possibile trovare i partner NVIDIA con<block ref="32da44153625c96a28e5bf10161bbc42" category="inline-link-rx"></block>. Cerca competenze come GPU virtuale (vGPU) o Tesla.</block>
  <block id="7709fb92e99b3458d440c5212792a0de" category="paragraph">Il software NVIDIA vGPU è disponibile in quattro edizioni:</block>
  <block id="31473f257c4cfabfcba0c506fefcf4ca" category="list-text">NVIDIA GRID Virtual PC (GRID VPC)</block>
  <block id="75cc5be2167cc23ca9d32aa78a164907" category="list-text">Applicazioni virtuali NVIDIA GRID (GRID vApps)</block>
  <block id="53b933a69a5adecaa6c8c8817d2d87a5" category="list-text">Workstation NVIDIA quadro Virtual Data Center (quadro VDWS)</block>
  <block id="2d655109b3aad5a539482617b4aa3b6b" category="list-text">NVIDIA Virtual ComputeServer (vComputeServer)</block>
  <block id="38f26d9fb2d58dd577140e84010a059d" category="section-title">PC virtuale GRID</block>
  <block id="e43876de331b666ca7fd1c7bbb8a844d" category="paragraph">Questo prodotto è ideale per gli utenti che desiderano un desktop virtuale che offra un'esperienza utente ottimale per applicazioni Microsoft Windows, browser, video ad alta definizione e supporto multi-monitor. NVIDIA GRID Virtual PC offre un'esperienza nativa in un ambiente virtuale, consentendo di eseguire tutte le applicazioni del PC a piene performance.</block>
  <block id="06a4851adc711a27ef53d0577d69e210" category="section-title">APPLICAZIONI Grid Virtual</block>
  <block id="2c20bf668630521a8f76995b0c04c398" category="paragraph">LE APPLICAZIONI GRID vApps sono destinate alle organizzazioni che implementano un Remote Desktop Session host (RDSH) o altre soluzioni basate su sessioni o streaming di applicazioni. Progettati per offrire applicazioni Microsoft Windows alle massime performance, i desktop RDSH ospitati da Windows Server sono supportati anche DA GRID vApps.</block>
  <block id="5de115addc6579e1d30075a2a92c9ae7" category="section-title">Quadro Virtual Data Center Workstation</block>
  <block id="74fec534073fb87750193748093ada5a" category="paragraph">Questa edizione è ideale per i designer mainstream e high-end che utilizzano potenti applicazioni per la creazione di contenuti 3D come Dassault CATIA, SOLIDWORKS, 3Dexcite, Siemens NX, PTC Creo, Schlumberger Petrel, o Autodesk Maya. NVIDIA quadro VDWS consente agli utenti di accedere alle proprie applicazioni grafiche professionali con funzionalità e prestazioni complete, ovunque si trovino su qualsiasi dispositivo.</block>
  <block id="fb5cc5533386fd1b00e6b986dec8cba1" category="section-title">NVIDIA Virtual ComputeServer</block>
  <block id="087877c8284ea313c79d65cb22d48329" category="paragraph">Molte organizzazioni eseguono carichi di lavoro server a elaborazione intensiva come intelligenza artificiale (ai), deep learning (DL) e data science. In questi casi di utilizzo, il software NVIDIA vComputeServer virtualizza la GPU NVIDIA, che accelera i carichi di lavoro dei server a elaborazione intensiva con funzionalità come codice di correzione degli errori, eliminazione delle pagine, peer-to-peer su NVLink e multi-vGPU.</block>
  <block id="e1f54ed77362f191ac08c4db8d9c44cd" category="admonition">Una licenza quadro VDWS consente di utilizzare GRID VPC e NVIDIA vComputeServer.</block>
  <block id="d685cba160011e42327272678904bcbc" category="inline-link-macro">Avanti: Implementazione</block>
  <block id="fed95bc65003dcb3d5ee273e3926bb25" category="paragraph"><block ref="fed95bc65003dcb3d5ee273e3926bb25" category="inline-link-macro-rx"></block></block>
  <block id="c775b248c55d253008c58d1ecd60e66f" category="doc">Soluzioni di End User Computing (EUC) / Virtual Desktop Infrastructure (VDI)</block>
  <block id="599725d881295777d3740ac33e953ced" category="paragraph">Sia che stiate implementando desktop virtuali on-premise o nel cloud, NetApp offre una vasta gamma di soluzioni EUC/VDI per soddisfare le vostre esigenze.</block>
  <block id="75fc33fcc3ef968fd3bf30c8da19bf9b" category="section-title">NetApp Virtual Desktop Services (VDS)</block>
  <block id="0593c3151fa252cdb4e997dd1255c608" category="paragraph">NetApp Virtual Desktop Service (VDS) consente di orchestrare Remote Desktop Services (RDS) nei principali cloud pubblici e nei cloud privati.</block>
  <block id="3b96d802308faf1d6ff7e5563ea3d29b" category="paragraph">Soluzioni disponibili per VDS:</block>
  <block id="dede82866780d163734b443c5f4d484e" category="inline-link-macro">Cloud ibrido VDI con NetApp Virtual Desktop Service</block>
  <block id="2ccf8775db4706ac42c0a600eca82163" category="list-text"><block ref="2ccf8775db4706ac42c0a600eca82163" category="inline-link-macro-rx"></block></block>
  <block id="d4a0768ddf4ac449658ace06000fa76e" category="section-title">End User Computing con VMware Horizon</block>
  <block id="959f3d9cc20e0e9bfbc01c2d36cdc894" category="paragraph">NetApp ha verificato le architetture per VMware Horizon in diverse configurazioni di calcolo. Le soluzioni disponibili includono:</block>
  <block id="3acc5e85d752378c6f1b9154f379b475" category="inline-link-macro">End User Computing con VMware (Guida alla progettazione)</block>
  <block id="01606c27121f18cf231b4700ddf252e1" category="list-text"><block ref="01606c27121f18cf231b4700ddf252e1" category="inline-link-macro-rx"></block></block>
  <block id="87e25a8d0e462ac8d7158e587f376605" category="inline-link-macro">End User Computing con GPU VMware e NVIDIA (guida alla progettazione)</block>
  <block id="4e5b466ff852e362d888b555cdcf62b7" category="list-text"><block ref="4e5b466ff852e362d888b555cdcf62b7" category="inline-link-macro-rx"></block></block>
  <block id="d840a196af6c9e07c3ac3b20b15fb724" category="inline-link-macro">End User Computing con GPU VMware e NVIDIA (Guida all'implementazione)</block>
  <block id="06e0780100d16763670aed1df8526b2e" category="list-text"><block ref="06e0780100d16763670aed1df8526b2e" category="inline-link-macro-rx"></block></block>
  <block id="f93781578174ca3309bd3ac126884af4" category="inline-link-macro">End User Computing con VMware per la grafica 3D</block>
  <block id="128fc080215971e783f68c8be31bd85d" category="list-text"><block ref="128fc080215971e783f68c8be31bd85d" category="inline-link-macro-rx"></block></block>
  <block id="d1c59e5cbf684efb4f69f300e72a4ac9" category="doc">Gestione delle operazioni</block>
  <block id="787e198d8fa4e242ef62df0a63fc0f5d" category="inline-link">Risoluzione dei problemi della pagina azioni VDA non riuscite</block>
  <block id="8086a7a818fcf045c7b05845b97629ed" category="paragraph">Per informazioni sui file di log VDS, consultare<block ref="0ecc734e7dc5f9a5685babbaab9faaa5" category="inline-link-rx"></block>.</block>
  <block id="88a80237ffcd0c20f5f4d4e7f9eda875" category="inline-link">Pagina componenti e autorizzazioni VDA</block>
  <block id="000ea3efdd5a83f774a0c189fa2dcdc3" category="paragraph">Per ulteriori informazioni sulle autorizzazioni minime richieste, vedere<block ref="573c5bde2dc73c6cb4f63bbc5571c0e2" category="inline-link-rx"></block>.</block>
  <block id="81bb80b99b1ba5d80f9ba049cbd0c42f" category="inline-link">Pagina cloning Virtual Machines</block>
  <block id="91aa73f3df8edb27ce6b20c984ff5d3e" category="paragraph">Se si desidera clonare manualmente un server, vedere<block ref="837d5521d53fff809b7ef3ad6b17ecfa" category="inline-link-rx"></block>.</block>
  <block id="7d71ba8ea6767ea10d7cd61cbd787f89" category="inline-link">Pagina delle funzionalità di aumento automatico dello spazio su disco</block>
  <block id="abf872062b9eb23bdf6d671c27508d96" category="paragraph">Per aumentare automaticamente le dimensioni del disco della macchina virtuale, consultare<block ref="627eb07506141f4255cfbedd7fe89646" category="inline-link-rx"></block>.</block>
  <block id="cc6d8546c611bac5ab11fa1a5948ac1d" category="inline-link">Pagina dei requisiti per l'utente finale</block>
  <block id="9b368ea783a99ed08472f5ee27e26dc9" category="paragraph">Per identificare l'indirizzo del gateway per la configurazione manuale del client, consultare<block ref="65651a617c871e663f36b036935811c9" category="inline-link-rx"></block>.</block>
  <block id="b4f83b03956523a39e8bbbd0895f0f29" category="section-title">Cloud Insights</block>
  <block id="efb9afc2e01262d41bf1fa60ddc36414" category="paragraph">NetApp Cloud Insights è uno strumento di monitoraggio basato su web che offre una visibilità completa dell'infrastruttura e delle applicazioni eseguite su NetApp e su altri componenti dell'infrastruttura di terze parti. Cloud Insights supporta cloud privati e pubblici per il monitoraggio, la risoluzione dei problemi e l'ottimizzazione delle risorse.</block>
  <block id="4894eb73d4d2ad7eaebb0968e871cb70" category="paragraph">Solo la macchina virtuale dell'unità di acquisizione (può essere Windows o Linux) deve essere installata su un cloud privato per raccogliere le metriche dai data colleer senza la necessità di agenti. I data raccoglitori basati su agenti consentono di ottenere metriche personalizzate da Windows Performance Monitor o da qualsiasi agente di input supportato da Telegraf.</block>
  <block id="32e49e2645f559763ede8e346bbcb816" category="paragraph">La figura seguente mostra la dashboard di Cloud Insights VDS.</block>
  <block id="cb9ecf4f0010c9ec12b73a00e06a9237" category="paragraph"><block ref="cb9ecf4f0010c9ec12b73a00e06a9237" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3bd1406c323c740b5b2f2a7615ad62ca" category="paragraph">Per ulteriori informazioni su NetApp Cloud Insights, vedere<block ref="5fdb6e8524eb99916602753c65f2f24e" category="inline-link-rx"></block>.</block>
  <block id="8a883bd6e43add9d94d923704bc177a7" category="inline-link-macro">Avanti: Strumenti e log</block>
  <block id="28f1e69837c0c21f4dcb8260d6ab5e97" category="paragraph"><block ref="28f1e69837c0c21f4dcb8260d6ab5e97" category="inline-link-macro-rx"></block></block>
  <block id="48a2bc9c10adbea95074594015793272" category="summary">Uno spazio di lavoro è costituito da un ambiente desktop, che può essere condiviso sessioni di desktop remoto ospitate on-premise o su qualsiasi ambiente cloud di supporto. Con Microsoft Azure, l'ambiente desktop può essere persistente con i desktop virtuali Windows. Ogni area di lavoro è associata a un'organizzazione o a un client specifico.</block>
  <block id="1da2374b50f497e208c8dab11e6b2c98" category="doc">Gestione dell'area di lavoro</block>
  <block id="fb67e63246489555a7e8929a138ced4c" category="paragraph">Un'area di lavoro è costituita da un ambiente desktop, che può essere condiviso in sessioni di desktop remoto ospitate on-premise o in qualsiasi ambiente cloud supportato. Con Microsoft Azure, l'ambiente desktop può essere persistente con i desktop virtuali Windows. Ogni area di lavoro è associata a un'organizzazione o a un client specifico. Le opzioni disponibili durante la creazione di una nuova area di lavoro sono illustrate nella figura seguente.</block>
  <block id="42a6c6312ce8b92836d9e74d89998e89" category="paragraph"><block ref="42a6c6312ce8b92836d9e74d89998e89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d49083c2604eac2881e01b4acea428e" category="admonition">Ogni area di lavoro è associata a un'implementazione specifica.</block>
  <block id="2a1fdca12b05c0f5292a8670b24cb478" category="paragraph">Le aree di lavoro contengono applicazioni e servizi app associati, cartelle di dati condivise, server e un'istanza WVD. Ogni area di lavoro può controllare le opzioni di sicurezza come l'applicazione della complessità delle password, l'autenticazione a più fattori, i controlli dei file e così via.</block>
  <block id="f29490b04a344e19674ee8d1db337d14" category="paragraph">Le aree di lavoro possono controllare la pianificazione del carico di lavoro per accendere server aggiuntivi, limitare il numero di utenti per server o impostare la pianificazione delle risorse disponibili per un determinato periodo (sempre acceso/spento). Le risorse possono anche essere configurate per l'attivazione on-demand.</block>
  <block id="421b47ffd946ca083b65cd668c6b17e6" category="inline-link">video</block>
  <block id="5a70681d968007936b9d092ba1a93313" category="paragraph">Se necessario, lo spazio di lavoro può sostituire le impostazioni predefinite delle risorse delle macchine virtuali di implementazione. Per WVD, i pool di host WVD (che contengono host di sessione e gruppi di applicazioni) e le aree di lavoro WVD possono essere gestiti anche dal portale della suite di gestione dell'area di lavoro cloud. Per ulteriori informazioni sul pool di host WVD, consultare questa sezione<block ref="283c24f69dac0d05b60b041138870b19" category="inline-link-rx"></block>.</block>
  <block id="ff13351bb4dc0c877064ec1672d6723f" category="inline-link-macro">Avanti: Gestione delle applicazioni</block>
  <block id="bb974af58c318849f0fce8f7c3ecdf37" category="paragraph"><block ref="bb974af58c318849f0fce8f7c3ecdf37" category="inline-link-macro-rx"></block></block>
  <block id="18dbdef148da0fb68861cf1b6aeeeb40" category="summary">L'infrastruttura VDI ibrida con NetApp VDS consente ai service provider e agli amministratori dei desktop virtuali aziendali di espandere facilmente le risorse in altri ambienti cloud senza influire sugli utenti. La disponibilità di risorse on-premise su NetApp HCI offre un migliore controllo delle risorse GPU e consente di espandere i nodi di calcolo o storage in base alla richiesta.</block>
  <block id="1cf7e301510c711b73d2b182b9dcf084" category="doc">Casi di utilizzo</block>
  <block id="0fe8a299bf61a0d1bbca5d975dc94fcc" category="paragraph">L'infrastruttura VDI ibrida con NetApp VDS consente ai service provider e agli amministratori dei desktop virtuali aziendali di espandere facilmente le risorse in altri ambienti cloud senza influire sugli utenti. La disponibilità di risorse on-premise offre un migliore controllo delle risorse e un'ampia scelta di opzioni (calcolo, GPU, storage e rete) per soddisfare la domanda.</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">Questa soluzione si applica ai seguenti casi di utilizzo:</block>
  <block id="f9bfa55b1c8ab8884a1452fa3c9cb975" category="list-text">Nel cloud per i picchi della domanda di desktop e applicazioni remoti</block>
  <block id="6b53dc409ecc50a533e93345ddf1f2ee" category="list-text">Riduzione del TCO per applicazioni e desktop remoti a esecuzione prolungata ospitandoli on-premise con storage flash e risorse GPU</block>
  <block id="f1de7e15d0b0c3caaafa1a47204338c7" category="list-text">Facilità di gestione di desktop e applicazioni remoti negli ambienti cloud</block>
  <block id="f9ce5b54f5428c82364a39f17156cc4f" category="list-text">Sperimenta desktop e applicazioni remoti utilizzando un modello software-as-a-service con risorse on-premise</block>
  <block id="3190a811a89bc9da4384152bc43d1b94" category="section-title">Pubblico di destinazione</block>
  <block id="549c608b9fe93192110cc2552d28da22" category="paragraph">Il pubblico di riferimento per la soluzione comprende i seguenti gruppi:</block>
  <block id="675ee473db5bbe3911c19a4e43f8ec3f" category="list-text">EUC/VDI Architect che vogliono comprendere i requisiti per un VDS ibrido</block>
  <block id="a7f381741a2ff77b61bc4b7bc2e3d04f" category="list-text">Partner NetApp che desiderano assistere i clienti nelle loro esigenze di desktop remoto e applicazioni</block>
  <block id="efa648658230830c2b9ac1a0647002d7" category="list-text">Clienti NetApp HCI esistenti che desiderano soddisfare le esigenze di desktop remoto e applicazioni</block>
  <block id="2fa4089eb34d18d2b64eaab8eed9692d" category="inline-link-macro">Pagina successiva: Panoramica del servizio Virtual Desktop di NetApp</block>
  <block id="bf817f81e35d1d9f2620def86f22dcc3" category="paragraph"><block ref="bf817f81e35d1d9f2620def86f22dcc3" category="inline-link-macro-rx"></block></block>
  <block id="7d37fde7375502ef1013412159477502" category="summary">NetApp offre numerosi servizi cloud, tra cui il provisioning rapido di desktop virtuale con applicazioni WVD o remote, inclusa la rapida integrazione con Azure NetApp Files.</block>
  <block id="28850fd0c108cc5f990fc4b4b52ab60d" category="doc">Panoramica del servizio Virtual Desktop di NetApp</block>
  <block id="c70675dc3857ae45ab2475f60c0f1f85" category="paragraph">NetApp offre numerosi servizi cloud, tra cui il provisioning rapido di desktop virtuale con applicazioni WVD o remote e la rapida integrazione con Azure NetApp Files.</block>
  <block id="8b32dee3fc7d9223248420cb828c5527" category="paragraph">Tradizionalmente, il provisioning e l'erogazione di servizi desktop remoti ai clienti richiedono settimane. Oltre al provisioning, può essere difficile gestire applicazioni, profili utente, dati condivisi e oggetti di policy di gruppo per applicare le policy. Le regole del firewall possono aumentare la complessità e richiedere un set di competenze e strumenti separati.</block>
  <block id="0276a1f5f692f2e9635f3733b371cf70" category="paragraph">Con il servizio Microsoft Azure Windows Virtual Desktop, Microsoft si occupa della manutenzione dei componenti di Remote Desktop Services, consentendo ai clienti di concentrarsi sul provisioning delle aree di lavoro nel cloud. I clienti devono eseguire il provisioning e gestire lo stack completo, che richiede competenze speciali per gestire gli ambienti VDI.</block>
  <block id="51db16f7b26a08952beb43836ad3f31d" category="paragraph">Con NetApp VDS, i clienti possono implementare rapidamente desktop virtuali senza doversi preoccupare di dove installare i componenti dell'architettura come broker, gateway, agenti e così via. I clienti che richiedono il controllo completo del proprio ambiente possono collaborare con un team di servizi professionali per raggiungere i propri obiettivi. I clienti utilizzano i VDS come servizio e possono quindi concentrarsi sulle principali sfide aziendali.</block>
  <block id="139562ef7df2deed82d586ebe297a082" category="paragraph">NetApp VDS è un'offerta software-as-a-service per la gestione centralizzata di implementazioni multiple in ambienti AWS, Azure, GCP o cloud privato. Microsoft Windows Virtual Desktop è disponibile solo su Microsoft Azure. NetApp VDS consente di orchestrare i servizi di desktop remoto Microsoft in altri ambienti.</block>
  <block id="fd9a0083b0a0e084ce6fb8d2ca64272f" category="paragraph">Microsoft offre sessioni multiple su Windows 10 esclusivamente per ambienti Windows Virtual Desktop su Azure. L'autenticazione e l'identità sono gestite dalla tecnologia dei desktop virtuali; WVD richiede Azure Active Directory sincronizzato (con ad Connect) con Active Directory e le VM di sessione collegate ad Active Directory. RDS richiede Active Directory per l'identità e l'autenticazione dell'utente e l'Unione e la gestione del dominio delle macchine virtuali.</block>
  <block id="416feb9f77def2ffedaab40a538d47e5" category="paragraph">Nella figura seguente viene illustrata una topologia di implementazione di esempio.</block>
  <block id="e377917f3505cdb9fc72b74164df5928" category="paragraph"><block ref="e377917f3505cdb9fc72b74164df5928" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d271ca257d56879fcc9ed95d82aabaa7" category="paragraph">Ogni implementazione è associata a un dominio Active Directory e fornisce ai client un punto di accesso per aree di lavoro e applicazioni. Un provider di servizi o un'azienda che dispone di più domini Active Directory ha in genere più implementazioni. Un singolo dominio Active Directory che si estende in più regioni ha in genere una singola implementazione con più siti.</block>
  <block id="9ea3c4f34057d91531ae286e3efe62c3" category="paragraph">Per WVD in Azure, Microsoft fornisce un servizio Platform-as-a-Service utilizzato da NetApp VDS. Per altri ambienti, NetApp VDS orchestrerà l'implementazione e la configurazione dei servizi di desktop remoto Microsoft. NetApp VDS supporta sia WVD Classic che WVD ARM e può essere utilizzato anche per aggiornare le versioni esistenti.</block>
  <block id="3e8cd47ad0ab71d0b3891f85212ccdbc" category="paragraph">Ogni implementazione dispone di servizi per la propria piattaforma, che comprendono Cloud Workspace Manager (endpoint REST API), un gateway HTML 5 (connessione alle macchine virtuali da un portale di gestione VDS), RDS Gateway (Access Point per i client) e un controller di dominio. La figura seguente mostra l'architettura del piano di controllo VDS per l'implementazione RDS.</block>
  <block id="38606818aeffd06d174e51013afc23a1" category="paragraph"><block ref="38606818aeffd06d174e51013afc23a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58cad6a2c8c8ff1a585bf8d6ca94560" category="paragraph">Per le implementazioni RDS, NetApp VDS può essere facilmente accessibile da Windows e dai browser utilizzando software client che può essere personalizzato per includere logo e immagini del cliente. In base alle credenziali dell'utente, fornisce all'utente l'accesso a aree di lavoro e applicazioni approvate. Non è necessario configurare i dettagli del gateway.</block>
  <block id="c2dcf4d443be38a737d1e580fb4b86ec" category="paragraph">La figura seguente mostra il client NetApp VDS.</block>
  <block id="8e7d56f1d99fdc8080a747bf8b1eda75" category="paragraph"><block ref="8e7d56f1d99fdc8080a747bf8b1eda75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71110c8ffc8b198bc951f6e587fbcddf" category="paragraph">Nell'implementazione di Azure WVD, Microsoft gestisce l'access point per i client e può essere utilizzato da un client Microsoft WVD disponibile in modalità nativa per diversi sistemi operativi. È inoltre possibile accedervi da un portale basato su web. La configurazione del software client deve essere gestita dall'oggetto Criteri di gruppo (GPO) o in altri modi preferiti dai clienti.</block>
  <block id="9e4318c1c6ae62544ba67e7c0fe55649" category="paragraph">La seguente figura illustra l'architettura del piano di controllo VDS per le implementazioni di Azure WVD.</block>
  <block id="ba9e4c82a95db68279bffa8ca8a8803f" category="paragraph"><block ref="ba9e4c82a95db68279bffa8ca8a8803f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d648a5d4acf66674fb86cc7be05bd5e" category="paragraph">Oltre all'implementazione e alla configurazione dei componenti richiesti, NetApp VDS gestisce anche la gestione degli utenti, la gestione delle applicazioni, la scalabilità delle risorse e l'ottimizzazione.</block>
  <block id="3ea30729e0e7f0d666400ccc1a6f7bc3" category="paragraph">NetApp VDS può creare utenti o concedere agli account utente esistenti l'accesso allo spazio di lavoro cloud o ai servizi applicativi. Il portale può essere utilizzato anche per la reimpostazione delle password e la delega dell'amministrazione di un sottoinsieme di componenti. Gli amministratori dell'helpdesk o i tecnici di livello 3 possono affiancare le sessioni degli utenti per la risoluzione dei problemi o connettersi ai server dall'interno del portale.</block>
  <block id="061d5215d4dd8b8e2b7d9f2498a4a8c3" category="paragraph">NetApp VDS può utilizzare i modelli di immagine creati dall'utente oppure quelli esistenti sul mercato per il provisioning basato sul cloud. Per ridurre il numero di immagini da gestire, è possibile utilizzare un'immagine di base e il provisioning di eventuali applicazioni aggiuntive necessarie utilizzando il framework fornito per includere qualsiasi tool della riga di comando come chocolatey, MSIX app attach, PowerShell e così via. Anche gli script personalizzati possono essere utilizzati come parte degli eventi del ciclo di vita delle macchine.</block>
  <block id="91d75bd7e517ef4b563021e6d23d8cb9" category="inline-link-macro">Pagina successiva: Panoramica di NetApp HCI</block>
  <block id="3806ab54895f78b6c34b626314f84e6e" category="paragraph"><block ref="3806ab54895f78b6c34b626314f84e6e" category="inline-link-macro-rx"></block></block>
  <block id="64241e0b33fb869cb12ff8e1ec74f806" category="summary">NetApp VDS utilizza Azure Active Directory per l'autenticazione dell'identità e Azure Active Directory Domain Services per l'autenticazione NTLM/Kerberos. Lo strumento ADConnect può essere utilizzato per sincronizzare un dominio Active Directory on-premise con Azure Active Directory.</block>
  <block id="92726ab5faeb2cb9208eaac9af0346bd" category="doc">Gestione utenti</block>
  <block id="c758de7e1477d6707c6709441d41a5e9" category="paragraph">È possibile aggiungere nuovi utenti dal portale oppure attivare lo spazio di lavoro cloud per gli utenti esistenti. Le autorizzazioni per le aree di lavoro e i servizi applicativi possono essere controllate da singoli utenti o da gruppi. Dal portale di gestione, è possibile definire gli utenti amministrativi per controllare le autorizzazioni per il portale, le aree di lavoro e così via.</block>
  <block id="b1bb3db86aec5efef6f7cc0d0d7c6331" category="paragraph">La seguente figura illustra la gestione degli utenti in NetApp VDS.</block>
  <block id="ed5018356119de97fa1ab09c0eeab65a" category="paragraph"><block ref="ed5018356119de97fa1ab09c0eeab65a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1350c851c78a6cdb31c6fe46ddb499c2" category="paragraph">Ogni area di lavoro risiede nella propria unità organizzativa (OU) di Active Directory sotto l'unità organizzativa Cloud Workspace, come illustrato nella figura seguente.</block>
  <block id="a5484d6de39aa020af1aa382d6d52c5e" category="paragraph"><block ref="a5484d6de39aa020af1aa382d6d52c5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3fad2f68853fae9ef870ed5535896790" category="paragraph">Per ulteriori informazioni, vedere<block ref="b5d59c719b42a4e7d2b711482aa2f54d" category="inline-link-rx"></block> Sulle autorizzazioni degli utenti e sulla gestione degli utenti in NetApp VDS.</block>
  <block id="48a8649f1ce9d97848d70480ce7fea9c" category="paragraph">Quando un gruppo Active Directory viene definito come CRAUserGroup utilizzando una chiamata API per il data center, tutti gli utenti di tale gruppo vengono importati in CloudWorkspace per la gestione mediante l'interfaccia utente. Quando l'area di lavoro cloud è attivata per l'utente, VDS crea le cartelle principali dell'utente, i permessi delle impostazioni, gli aggiornamenti delle proprietà dell'utente e così via.</block>
  <block id="9e30d1bf5e5278a123ad0ddab43066b7" category="paragraph">Se l'opzione VDI User Enabled (utente VDI abilitato) è selezionata, VDS crea una macchina RDS a sessione singola dedicata a tale utente. Richiede il provisioning del modello e del datastore.</block>
  <block id="093d2ddf98cacaf853b6f986ca9bd647" category="paragraph"><block ref="093d2ddf98cacaf853b6f986ca9bd647" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46bccf4889fab263d6edc63e631883a7" category="inline-link-macro">Avanti: Gestione dell'area di lavoro</block>
  <block id="e98fdb0b8697a2cf005527be51872d0d" category="paragraph"><block ref="e98fdb0b8697a2cf005527be51872d0d" category="inline-link-macro-rx"></block></block>
  <block id="aaca2e6fe88c6861582a8d1a20acfd4f" category="summary">Funzionalità di ONTAP per il servizio di desktop virtuale.</block>
  <block id="bc9c47c8423d4537fdbf118b09a80084" category="doc">Funzionalità di ONTAP per il servizio di desktop virtuale</block>
  <block id="472986236003195075a1428fe6103f4c" category="paragraph">Le seguenti funzionalità di ONTAP lo rendono una scelta interessante da utilizzare con un servizio di desktop virtuale.</block>
  <block id="6128a47ce6baa55dbad9293234f2f65c" category="list-text">*Filesystem scale-out.* i volumi ONTAP FlexGroup possono crescere fino a oltre 20 PB e possono contenere più di 400 miliardi di file all'interno di un singolo namespace. Il cluster può contenere fino a 24 nodi di storage, ciascuno con un numero flessibile di schede di interfaccia di rete a seconda del modello utilizzato.</block>
  <block id="960f11687b64143d44db7f4ffcb33ef2" category="paragraph">I desktop virtuali, le cartelle home, i container dei profili utente, i dati condivisi e così via possono crescere in base alla domanda senza alcuna preoccupazione per le limitazioni del file system.</block>
  <block id="ab7ad572d2251b9b27fa0213fde8531f" category="list-text">*Analisi del file system.* puoi utilizzare il tool XCP per ottenere informazioni sui dati condivisi. Con ONTAP 9.8+ e ActiveIQ Unified Manager, è possibile eseguire query e recuperare facilmente le informazioni sui metadati dei file e identificare i dati cold.</block>
  <block id="885f3e34ca03dc8ff35c0bac51b384f7" category="list-text">*Cloud Tiering.* puoi migrare i dati cold in un archivio di oggetti nel cloud o in qualsiasi storage compatibile con S3 nel tuo data center.</block>
  <block id="fb38ee94b865e67571a08316a3baac38" category="list-text">*Versioni dei file.* gli utenti possono ripristinare i file protetti dalle copie Snapshot di NetApp ONTAP. Le copie Snapshot di ONTAP sono molto efficienti in termini di spazio perché registrano solo i blocchi modificati.</block>
  <block id="9b7db1dd6f422e5f07ded1d3b7b04d90" category="list-text">*Namespace globale.* la tecnologia ONTAP FlexCache consente il caching remoto dello storage dei file, semplificando la gestione dei dati condivisi tra ubicazioni contenenti sistemi di storage ONTAP.</block>
  <block id="827aa7cb1ad6ddbf99e040efe34725a8" category="list-text">*Supporto multi-tenancy sicuro.* Un singolo cluster di storage fisico può essere presentato come più array di storage virtuali ciascuno con i propri volumi, protocolli di storage, interfacce di rete logiche, dominio di identità e autenticazione, utenti di gestione e così via. Pertanto, è possibile condividere l'array di storage tra più business unit o ambienti, come test, sviluppo e produzione.</block>
  <block id="6c36afe01468d888b334a4432dcac4b2" category="paragraph">Per garantire le performance, è possibile utilizzare la QoS adattiva per impostare i livelli di performance in base allo spazio utilizzato o allocato e controllare la capacità dello storage utilizzando le quote.</block>
  <block id="b1a678f5f86de8ff8a5b9b1c4b3772b8" category="list-text">*Integrazione VMware.* i tool ONTAP per VMware vSphere forniscono un plug-in vCenter per il provisioning dei datastore, l'implementazione delle Best practice per gli host vSphere e il monitoraggio delle risorse ONTAP.</block>
  <block id="9b12997ae1d332c9003c444a6ff8918a" category="paragraph">ONTAP supporta le API vStorage per l'integrazione degli array (VAAI) per l'offload delle operazioni SCSI/file nell'array di storage. ONTAP supporta inoltre le API vStorage per la consapevolezza dello storage (VASA) e il supporto dei volumi virtuali per protocolli a blocchi e file.</block>
  <block id="025e05e390f2d7ef7708bb42d81e1eeb" category="paragraph">Il plug-in SnapCenter per VMware vSphere offre un metodo semplice per eseguire il backup e il ripristino delle macchine virtuali utilizzando la funzione Snapshot su un array di storage.</block>
  <block id="3452f822915108b5d640f3288959e7fd" category="paragraph">ActiveIQ Unified Manager offre visibilità della rete storage end-to-end in un ambiente vSphere. Gli amministratori possono identificare facilmente qualsiasi problema di latenza che potrebbe verificarsi negli ambienti di desktop virtuali ospitati su ONTAP.</block>
  <block id="c9559fb9abb51cf76cc973d06c7e730c" category="list-text">*Conformità alla sicurezza.* con ActiveIQ Unified Manager, è possibile monitorare più sistemi ONTAP con avvisi per eventuali violazioni delle policy.</block>
  <block id="875c0a88cb08e888c642bbcc19cb33a2" category="list-text">*Supporto multiprotocollo.* ONTAP supporta blocchi (iSCSI, FC, FCoE e NVMe/FC), file (NFSv3, NFSv4.1, SMB2.x e SMB3.x) e protocolli di storage a oggetti (S3).</block>
  <block id="4ac79aa8e1431a96a08ba58c1e17a104" category="list-text">*Supporto per l'automazione.* ONTAP fornisce moduli REST API, Ansible e PowerShell per automatizzare le attività con il portale di gestione VDS.</block>
  <block id="ba5e495048f0fa35302184aa505386a9" category="inline-link-macro">Avanti: Gestione dei dati</block>
  <block id="51688bc4609022e20e8c1cb051fb4489" category="paragraph"><block ref="51688bc4609022e20e8c1cb051fb4489" category="inline-link-macro-rx"></block></block>
  <block id="e80842c9211bc376ee42d583c70ae408" category="doc">Piattaforme NetApp</block>
  <block id="932ba7da1da9b241bfc5ddbb10e49da2" category="paragraph">Le aziende stanno adottando sempre più pratiche DevOps per creare nuovi prodotti, abbreviare i cicli di rilascio e aggiungere rapidamente nuove funzionalità. A causa della loro natura innata e agile, i container e i microservizi svolgono un ruolo cruciale nel supporto delle pratiche DevOps. Tuttavia, la pratica di DevOps su scala di produzione in un ambiente aziendale presenta le proprie sfide e impone determinati requisiti all'infrastruttura sottostante, come ad esempio:</block>
  <block id="43ee156205e7f74e32a02d556537fe90" category="list-text">Alta disponibilità a tutti i livelli dello stack</block>
  <block id="b59807af538b77fee1fb3d1d3c81f9a8" category="list-text">Procedure di implementazione semplici</block>
  <block id="2748d7182409b378e23f62724be778fd" category="list-text">Operazioni e aggiornamenti senza interruzioni</block>
  <block id="1a4af279491c72d7c36b4c9767ae712f" category="list-text">Infrastruttura programmabile e basata su API per restare al passo con l'agilità dei microservizi</block>
  <block id="0cdff7d38ef496f6b5510c5034fedf15" category="list-text">Multi-tenancy con garanzie di performance</block>
  <block id="8ca11bfd783c730b04c0c77fc7574406" category="list-text">Possibilità di eseguire contemporaneamente carichi di lavoro virtualizzati e containerizzati</block>
  <block id="0111977afdb7fa380f806edbe8438163" category="list-text">Possibilità di scalare l'infrastruttura in modo indipendente in base alle esigenze dei carichi di lavoro</block>
  <block id="2b8932b35916e8cecb6216546111322e" category="paragraph">Red Hat OpenShift Container Platform è una piattaforma aziendale Kubernetes completamente supportata. Red Hat apporta diversi miglioramenti a Kubernetes open-source per offrire una piattaforma applicativa con tutti i componenti completamente integrati per la creazione, l'implementazione e la gestione delle applicazioni containerizzate.</block>
  <block id="70240bc0debcb080aa08dbd9e7b9a525" category="paragraph">Per ulteriori informazioni, visita il sito Web di OpenShift<block ref="35d5a627a33ce17e4bd125258d59fbc4" category="inline-link-rx"></block>.</block>
  <block id="660d073f0987fac312dc40bd5dc868bd" category="paragraph">NetApp dispone di diversi sistemi storage perfetti per data center aziendali e implementazioni di cloud ibrido. Il portfolio NetApp include i sistemi storage NetApp ONTAP, NetApp Element e NetApp e-Series, tutti in grado di fornire storage persistente per le applicazioni containerizzate.</block>
  <block id="aa4193984de53d2a6d8fcc2d77c09bda" category="paragraph">Per ulteriori informazioni, visitare il sito Web di NetApp<block ref="95da63d781dead5af723667a3f69096a" category="inline-link-rx"></block>.</block>
  <block id="b4186621511a622be24ad982b0a8ec32" category="paragraph">NetApp Astra Control Center offre un'ampia gamma di servizi di gestione dei dati application-aware e storage per carichi di lavoro Kubernetes stateful, implementati in un ambiente on-premise e basati sulla tecnologia di protezione dei dati NetApp.</block>
  <block id="947496ade2e4a2c8e929d9aa9f00be04" category="paragraph">Per ulteriori informazioni, visitare il sito Web di NetApp Astra<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="54fe0fc00087535e613994102131f164" category="paragraph">Astra Trident è un orchestrator di storage open-source e completamente supportato per container e distribuzioni Kubernetes come {k8s_distribution_name}.</block>
  <block id="593fdc7a2167cd2ada3e71219ceb0ecb" category="paragraph">Per ulteriori informazioni, visita il sito web di Astra Trident<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="b36bddb7c9d9a83be2a0353a3a744767" category="paragraph">NetApp dispone di diverse piattaforme storage qualificate con Astra Trident e Astra Control per il provisioning, la protezione e la gestione dei dati per le applicazioni containerizzate.</block>
  <block id="0186ffea1bd2c7ff6458a3a619d01ea2" category="paragraph"><block ref="0186ffea1bd2c7ff6458a3a619d01ea2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50bc4bb14f0d89a22c593112574d0fb3" category="list-text">I sistemi AFF e FAS eseguono NetApp ONTAP e forniscono storage per i casi di utilizzo basati su file (NFS) e basati su blocchi (iSCSI).</block>
  <block id="bf3bfadca5040d5a50a8703c7dbb7ef1" category="list-text">Cloud Volumes ONTAP e ONTAP Select offrono gli stessi vantaggi rispettivamente nel cloud e nello spazio virtuale.</block>
  <block id="3cc957c67b836ddc993931d8d2253032" category="list-text">NetApp Cloud Volumes Service (AWS/GCP) e Azure NetApp Files offrono storage basato su file nel cloud.</block>
  <block id="faad8e024544c328d584c28118fb4102" category="list-text">I sistemi storage NetApp Element offrono casi di utilizzo basati su blocchi (iSCSI) in un ambiente altamente scalabile.</block>
  <block id="cb050b8fb8c2102a0ab337119eb19f0f" category="admonition">Ogni sistema storage del portfolio NetApp può semplificare la gestione dei dati e lo spostamento tra i siti on-premise e il cloud, garantendo che i dati si trovino nella posizione in cui si trovano le applicazioni.</block>
  <block id="8d866fd138999801041cd8ebf044c39f" category="paragraph">Le pagine seguenti contengono informazioni aggiuntive sui sistemi di storage NetApp validati nella soluzione {Solution_NAME}:</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="inline-link-macro">NetApp ONTAP</block>
  <block id="31190025c7f2a3470ada77c7c360ad75" category="list-text"><block ref="31190025c7f2a3470ada77c7c360ad75" category="inline-link-macro-rx"></block></block>
  <block id="fcda5b98e8c212807dc088477e802757" category="inline-link-macro">NetApp Element</block>
  <block id="15155104ed4dffb0c6f48a716c490eb6" category="list-text"><block ref="15155104ed4dffb0c6f48a716c490eb6" category="inline-link-macro-rx"></block></block>
  <block id="9d312703c40c2d87b835076063682d59" category="paragraph">NetApp ONTAP è un potente tool software per lo storage con funzionalità come GUI intuitiva, API REST con integrazione dell'automazione, analisi predittive e azioni correttive informate dell'ai, aggiornamenti hardware senza interruzioni e importazione di storage incrociato.</block>
  <block id="48235fec2427a785c4a09d7150fc11fc" category="inline-link">Sito Web di NetApp ONTAP</block>
  <block id="e65027864c84a42fc0799d878ffa0005" category="paragraph">Per ulteriori informazioni sul sistema di storage NetApp ONTAP, visitare il sito<block ref="be9464a7a83e639a645a801fff2791d9" category="inline-link-rx"></block>.</block>
  <block id="3716516b242be48f15f8cbce6557a296" category="paragraph">ONTAP offre le seguenti funzionalità:</block>
  <block id="3e23168685787e9deffccb3bdb29d98a" category="list-text">Un sistema storage unificato con accesso e gestione simultanei dei dati di NFS, CIFS, iSCSI, FC, FCoE, E protocolli FC-NVMe.</block>
  <block id="11927aa24f71bc959d85115c8dd8c3a9" category="list-text">Diversi modelli di implementazione includono configurazioni hardware on-premise su all-flash, ibride e all-HDD, piattaforme di storage basate su VM su un hypervisor supportato come ONTAP Select e nel cloud come Cloud Volumes ONTAP.</block>
  <block id="65c42edcb28a34e276f92dd9b2172613" category="list-text">Maggiore efficienza dello storage dei dati sui sistemi ONTAP con supporto per tiering automatico dei dati, compressione dei dati inline, deduplica e compaction.</block>
  <block id="f0a8a62c8d7ea4d12a7f1c95b40d3cb3" category="list-text">Storage basato su workload e controllato dalla QoS.</block>
  <block id="1e16ebc829d46d68a51d55ac22293b1e" category="list-text">Integrazione perfetta con un cloud pubblico per tiering e protezione dei dati. ONTAP offre inoltre solide funzionalità di protezione dei dati che lo differenziano in qualsiasi ambiente:</block>
  <block id="613db5a747bd15eeccbcbedce5bd8888" category="list-text">*NetApp Snapshot Copies.* Backup rapido e point-in-time dei dati utilizzando una quantità minima di spazio su disco senza alcun overhead delle performance aggiuntivo.</block>
  <block id="8f666d296151faf9c472110831227243" category="list-text">*NetApp SnapMirror.* Mirror le copie Snapshot dei dati da un sistema storage a un altro. ONTAP supporta il mirroring dei dati su altre piattaforme fisiche e servizi nativi del cloud.</block>
  <block id="5685b3f13393b751231ff096f77e6747" category="list-text">*NetApp SnapLock.* Amministrazione efficiente dei dati non riscrivibili, scrivendo su volumi speciali che non possono essere sovrascritti o cancellati per un determinato periodo.</block>
  <block id="dff1063d1e007396b7fb75f266dd48b7" category="list-text">*NetApp SnapVault.* esegue il backup dei dati da più sistemi storage in una copia Snapshot centrale che funge da backup su tutti i sistemi designati.</block>
  <block id="779cb4084f09228e9562ca3bedc5555c" category="list-text">*NetApp SyncMirror.* offre mirroring dei dati in tempo reale a livello RAID su due diversi plessi di dischi collegati fisicamente allo stesso controller.</block>
  <block id="929a0581ca4b2982313e21e51effbc10" category="list-text">*NetApp SnapRestore.* offre un rapido ripristino dei dati di backup on-demand dalle copie Snapshot.</block>
  <block id="4e3f9a03501932f914205c4ad0e682ea" category="list-text">*NetApp FlexClone.* fornisce il provisioning istantaneo di una copia leggibile e scrivibile di un volume NetApp basata su una copia Snapshot.</block>
  <block id="d06c8b79097ede1a26446d68bec0ca39" category="paragraph">Per ulteriori informazioni su ONTAP, consultare<block ref="b961dc88c1ac3ab8c78f9fff5ef05edb" category="inline-link-rx"></block>.</block>
  <block id="c389369b80a8ce8ead607b4c7088682e" category="admonition">NetApp ONTAP è disponibile on-premise, virtualizzato o nel cloud.</block>
  <block id="81bf516f5b38ea41d503a2670a9dc144" category="paragraph"><block ref="81bf516f5b38ea41d503a2670a9dc144" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a69e0f8303b40f9f4d56038d3d260c9" category="section-title">NetApp AFF/FAS</block>
  <block id="f4fc33973424c12639f93790b1c6f370" category="paragraph">NetApp offre solide piattaforme di storage all-flash (AFF) e ibride scale-out (FAS), realizzate su misura con performance a bassa latenza, protezione integrata dei dati e supporto multiprotocollo.</block>
  <block id="d4c312c600a949fb72436c2d10568a90" category="paragraph">Entrambi i sistemi sono basati sul software per la gestione dei dati NetApp ONTAP, il software per la gestione dei dati più avanzato del settore per una gestione dello storage semplificata, integrata nel cloud e ad alta disponibilità, in grado di offrire velocità, efficienza e sicurezza di livello Enterprise di cui ha bisogno il data fabric.</block>
  <block id="992c24be8f66e4259b38ce763c115251" category="paragraph">Per ulteriori informazioni sulle piattaforme NETAPP AFF/FAS, fare clic su<block ref="629508ef5a91b5835f70894f34eed424" category="inline-link-rx"></block>.</block>
  <block id="3a3a5cd068731551120f43f37950768b" category="section-title">ONTAP Select</block>
  <block id="b008e805d13d953ddb5cbb220d8ef9b6" category="paragraph">ONTAP Select è un'implementazione software-defined di NetApp ONTAP che può essere implementata su un hypervisor nel tuo ambiente. Può essere installato su VMware vSphere o su KVM e offre tutte le funzionalità e l'esperienza di un sistema ONTAP basato su hardware.</block>
  <block id="3f0bbee5abf3eed060d4147cb0d060b9" category="paragraph">Per ulteriori informazioni su ONTAP Select, fare clic su<block ref="7c1424ed7be035c303f12b0763e38ece" category="inline-link-rx"></block>.</block>
  <block id="117bdbda976fe8b3212bc3b6327a0a1b" category="section-title">Cloud Volumes ONTAP</block>
  <block id="f0f4b6de2040d7dc57e7f4f6baee7ec3" category="paragraph">NetApp Cloud Volumes ONTAP è una versione di NetApp ONTAP implementata nel cloud e disponibile per l'implementazione in diversi cloud pubblici, tra cui: Amazon AWS, Microsoft Azure e Google Cloud.</block>
  <block id="c7fa0d52c3955385f084d0e67c59f963" category="paragraph">Per ulteriori informazioni su Cloud Volumes ONTAP, fare clic su<block ref="75c9b0075008bbe40ac851ad7f6dda6a" category="inline-link-rx"></block>.</block>
  <block id="963b3936c1baa510ebca7a5496ece873" category="paragraph">NetApp offre una serie di prodotti per aiutarvi nell'orchestrazione, nella gestione, nella protezione e nella migrazione di applicazioni stateful containerizzate e dei relativi dati.</block>
  <block id="a4d4eca64bc27dfd5dc959bc05745797" category="paragraph"><block ref="a4d4eca64bc27dfd5dc959bc05745797" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8a52e85b93902c27be7f0b5fa8493e52" category="paragraph">NetApp Astra Control offre un set completo di servizi di gestione dei dati application-aware e storage per carichi di lavoro Kubernetes stateful, basati sulla tecnologia di protezione dei dati di NetApp. Astra Control Service è disponibile per supportare carichi di lavoro stateful nelle implementazioni Kubernetes native nel cloud. Astra Control Center è disponibile per supportare carichi di lavoro stateful in implementazioni on-premise di piattaforme Enterprise Kubernetes come {k8s_distribution_name}. Per ulteriori informazioni, visita il sito Web di NetApp Astra Control<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="40de36ed0c5ebc385749ac6095c24949" category="paragraph">NetApp Astra Trident è un orchestrator di storage open-source e completamente supportato per container e distribuzioni Kubernetes come {k8s_distribution_name}. Per ulteriori informazioni, visita il sito web di Astra Trident<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="ccbb3765ebd50818c2e13a7aba362360" category="paragraph">Le pagine seguenti contengono informazioni aggiuntive sui prodotti NetApp validati per la gestione delle applicazioni e dello storage persistente nella soluzione {Solution_NAME}:</block>
  <block id="12c17259bf3f3b36e970c9e3abbc6b43" category="inline-link-macro">NetApp Astra Control Center</block>
  <block id="9dc16d6a3e39a8a9654ccfa622d163cf" category="list-text"><block ref="9dc16d6a3e39a8a9654ccfa622d163cf" category="inline-link-macro-rx"></block></block>
  <block id="8de59ec369b10820d0dd336b9765c79b" category="inline-link-macro">NetApp Astra Trident</block>
  <block id="65b4726a91c7e38728e01572140c82b3" category="list-text"><block ref="65b4726a91c7e38728e01572140c82b3" category="inline-link-macro-rx"></block></block>
  <block id="9b0d9ae1197ded2c7d52147e5056475d" category="paragraph">NetApp Astra Control Center offre un'ampia gamma di servizi di gestione dei dati basati su applicazioni e storage per carichi di lavoro Kubernetes stateful implementati in un ambiente on-premise e basati sulla tecnologia di protezione dei dati di NetApp.</block>
  <block id="c4a7756da710a87248298a14bd0c21e6" category="paragraph"><block ref="c4a7756da710a87248298a14bd0c21e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61e8a38bc32bac1a07ee434aa2849ff7" category="paragraph">NetApp Astra Control Center può essere installato su un cluster {k8s_distribution_name} che ha installato e configurato Astra Trident Storage orchestrator con classi di storage e backend di storage per i sistemi storage NetApp ONTAP.</block>
  <block id="8cc4d72a7129322eb1f39ea9b9cfb2f6" category="inline-link-macro">questo documento qui</block>
  <block id="ca272f711326de89f484505d0ad670ab" category="paragraph">Per ulteriori informazioni su Astra Trident, vedere <block ref="fdebacf9b174a956e59f11468f6dd03c" category="inline-link-macro-rx"></block>.</block>
  <block id="876ae62d75901b9ef80277fd884aa5e9" category="paragraph">In un ambiente connesso al cloud, il centro di controllo Astra utilizza Cloud Insights per fornire monitoraggio avanzato e telemetria. In assenza di una connessione Cloud Insights, sono disponibili funzioni limitate di monitoraggio e telemetria (7 giorni di metriche) ed esportate negli strumenti di monitoraggio nativi di Kubernetes (Prometheus e Grafana) attraverso endpoint di metriche aperte.</block>
  <block id="54a5ba4de846d3c3ba8c0322f5139893" category="paragraph">Il centro di controllo Astra è completamente integrato nell'ecosistema NetApp AutoSupport e Active IQ per fornire supporto agli utenti, fornire assistenza per la risoluzione dei problemi e visualizzare le statistiche di utilizzo.</block>
  <block id="34610c3089a79a0b0e58bcc24da4c16c" category="paragraph">Oltre alla versione a pagamento di Astra Control Center, è disponibile una licenza di valutazione di 90 giorni. La versione di valutazione è supportata tramite e-mail e community (canale slack). I clienti hanno accesso a questi e ad altri articoli della Knowledge base e alla documentazione disponibile nella dashboard di supporto dei prodotti.</block>
  <block id="b3d5fa878980b3f5b771ced3fa94111a" category="inline-link-macro">Sito web Astra</block>
  <block id="8b05a70d35504af755eb73a78fd137f0" category="paragraph">Per ulteriori informazioni sul portfolio Astra, visitare il <block ref="230f9d60eb4e7cc8be41a0e702c37eff" category="inline-link-macro-rx"></block>.</block>
  <block id="6026755482efeb14efb7399db02c4e5e" category="paragraph">Astra Trident è un orchestrator di storage open-source e completamente supportato per container e distribuzioni Kubernetes come {k8s_distribution_name}. Trident lavora con l'intero portfolio di storage NetApp, inclusi i sistemi storage NetApp ONTAP ed Element, e supporta anche connessioni NFS e iSCSI. Trident accelera il workflow DevOps consentendo agli utenti finali di eseguire il provisioning e gestire lo storage dai sistemi storage NetApp senza richiedere l'intervento di un amministratore dello storage.</block>
  <block id="a4957cf974ce20219897bbbf5b131cb8" category="paragraph">Un amministratore può configurare una serie di backend di storage in base alle esigenze di progetto e ai modelli di sistemi di storage che consentono funzionalità di storage avanzate, tra cui compressione, tipi di dischi specifici o livelli di QoS che garantiscono un certo livello di performance. Una volta definiti, questi backend possono essere utilizzati dagli sviluppatori nei loro progetti per creare dichiarazioni di volume persistenti (PVC) e per collegare storage persistente ai propri container on-demand.</block>
  <block id="ecfb2402c181e98da49a5d763378b116" category="paragraph"><block ref="ecfb2402c181e98da49a5d763378b116" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0626021388a8dcc9b1e26b1209550b8d" category="paragraph">Astra Trident ha un rapido ciclo di sviluppo e, proprio come Kubernetes, viene rilasciato quattro volte all'anno.</block>
  <block id="0e60ae06a3d7bec5f8950d8ea76b57d4" category="paragraph">L'ultima versione di Astra Trident è la 22.04 rilasciata ad aprile 2022. Matrice di supporto per quale versione di Trident è stata testata con la quale è possibile trovare la distribuzione Kubernetes<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>.</block>
  <block id="b62bb4786ef52ad76706950add6991dd" category="paragraph">A partire dalla versione 20.04, l'impostazione di Trident viene eseguita dall'operatore Trident. L'operatore semplifica le implementazioni su larga scala e fornisce supporto aggiuntivo, inclusa la riparazione automatica dei pod implementati nell'installazione di Trident.</block>
  <block id="4a85fdd5a26454abc330a5ec2a46a326" category="paragraph">Con la versione 21.01, è stato reso disponibile un grafico Helm per facilitare l'installazione dell'operatore Trident.</block>
  <block id="3a724344bfc1b086a678d66814f20dd7" category="summary">In questa sezione vengono fornite le fasi necessarie per implementare una pipeline di implementazione o di integrazione continua con Jenkins per convalidare il funzionamento della soluzione.</block>
  <block id="b830a759b7bbee23da50f11979fb8f27" category="doc">Implementa una pipeline ci/CD Jenkins con storage persistente: Red Hat OpenShift con NetApp</block>
  <block id="ff587ce314d6f90660779e9d75cafe53" category="paragraph">In questa sezione vengono fornite le fasi necessarie per implementare una pipeline ci/CD (Continuous Integration/Continuous Delivery or Deployment) con Jenkins per convalidare il funzionamento della soluzione.</block>
  <block id="9eb8af4dd2c3557a24b914601b6ae465" category="section-title">Creare le risorse necessarie per l'implementazione di Jenkins</block>
  <block id="93b3852e5c67975dd33b1769b24a4a85" category="paragraph">Per creare le risorse necessarie per l'implementazione dell'applicazione Jenkins, attenersi alla seguente procedura:</block>
  <block id="9fd493573e73cb0e5e55e97306249596" category="list-text">Crea un nuovo progetto chiamato Jenkins.</block>
  <block id="5690195262fb589b6021733b4a5a4432" category="paragraph"><block ref="5690195262fb589b6021733b4a5a4432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d256abce3dbdfed83e337956e42f60f" category="list-text">In questo esempio, abbiamo implementato Jenkins con storage persistente. Per supportare la build Jenkins, creare il PVC. Selezionare Storage &gt; Persistent Volume Claims (Storage &gt; Reclami volumi persistenti) e fare clic su Create Persistent Selezionare la classe di storage creata, assicurarsi che il nome della richiesta di rimborso del volume persistente sia jenkins, selezionare la dimensione e la modalità di accesso appropriate, quindi fare clic su Create (Crea).</block>
  <block id="f9db9f308c8ed7f5d0ed0851d8d605cb" category="paragraph"><block ref="f9db9f308c8ed7f5d0ed0851d8d605cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9272f40a21ca3dad814c4e3886b40776" category="section-title">Implementare Jenkins con lo storage persistente</block>
  <block id="939a7b51bfb262627185af768c3c1024" category="paragraph">Per implementare Jenkins con lo storage persistente, attenersi alla seguente procedura:</block>
  <block id="d31d340fd6b135cac2cfac7b04a34c10" category="list-text">Nell'angolo in alto a sinistra, modificare il ruolo da Amministratore a sviluppatore. Fare clic su +Add (Aggiungi) e selezionare From Catalog (dal catalogo) Nella barra Filtra per parola chiave, cercare jenkins. Selezionare Servizio Jenkins con storage persistente.</block>
  <block id="bc5512ef7a17a0cfb58cb1ede30a6137" category="paragraph"><block ref="bc5512ef7a17a0cfb58cb1ede30a6137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6baa4bd25992de2d17278ade0d3090ad" category="list-text">Fare clic su<block ref="42dcbbaa226af66223d0680206ea8547" prefix=" " category="inline-code"></block>.</block>
  <block id="949381804bf1e16ca04ba9ac5fabc6a4" category="paragraph"><block ref="949381804bf1e16ca04ba9ac5fabc6a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7b4a6da6ab2733552de61d67b38a39e" category="list-text">Per impostazione predefinita, i dettagli dell'applicazione Jenkins vengono popolati. In base alle proprie esigenze, modificare i parametri e fare clic su Create (Crea). Questo processo crea tutte le risorse necessarie per supportare Jenkins su OpenShift.</block>
  <block id="cc9a211dac876290bd6ed039cf1afdcf" category="paragraph"><block ref="cc9a211dac876290bd6ed039cf1afdcf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb86f2dea9912af1bb1677c9cf33e619" category="list-text">I pod Jenkins impiegano circa 10 - 12 minuti per entrare nello stato Pronta.</block>
  <block id="274c247b7612630006e3d87d5ed5d46f" category="paragraph"><block ref="274c247b7612630006e3d87d5ed5d46f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da33835bff86a0b0c8be6c67dcf677bb" category="list-text">Una volta creata l'istanza dei pod, accedere a Networking &gt; routes (rete &gt; percorsi). Per aprire la pagina Web di Jenkins, fare clic sull'URL fornito per il percorso jenkins.</block>
  <block id="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="paragraph"><block ref="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d59d1324dea050a2c0ffc376de411aa0" category="list-text">Poiché OpenShift OAuth è stato utilizzato durante la creazione dell'applicazione Jenkins, fare clic su Accedi con OpenShift.</block>
  <block id="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="paragraph"><block ref="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70a742210f3e3599821b3a11b682144c" category="list-text">Autorizzare l'account del servizio Jenkins ad accedere agli utenti OpenShift.</block>
  <block id="9359288fc248319fa9acef62e4686d1c" category="paragraph"><block ref="9359288fc248319fa9acef62e4686d1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b07934b6023389a7e3e183b45e3b7448" category="list-text">Viene visualizzata la pagina di benvenuto di Jenkins. Poiché stiamo utilizzando una build Maven, completare prima l'installazione di Maven. Accedere a Manage Jenkins &gt; Global Tool Configuration (Gestisci Jenkins &gt; Configurazione globale strumenti), quindi fare clic su Add Maven (Aggiungi Maven) nella sottotesta di Maven. Immettere il nome desiderato e assicurarsi che l'opzione Installa automaticamente sia selezionata. Fare clic su Salva.</block>
  <block id="00713894c16827219fd5ab50c5fc3794" category="paragraph"><block ref="00713894c16827219fd5ab50c5fc3794" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fd32305bf380bf893ef2407eae75f5d" category="list-text">È ora possibile creare una pipeline per dimostrare il flusso di lavoro ci/CD. Nella home page, fare clic su Create New Jobs (Crea nuovi lavori) o New Item (nuovo elemento) dal menu a sinistra.</block>
  <block id="24f99be3c7033ab08c3baec1cdf32702" category="paragraph"><block ref="24f99be3c7033ab08c3baec1cdf32702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b6fc174a3fad5c396413febe1d4ba50" category="list-text">Nella pagina Create Item (Crea elemento), immettere il nome desiderato, selezionare Pipeline e fare clic su OK.</block>
  <block id="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="paragraph"><block ref="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd55d787cacfb25983e0a24b58ba6d48" category="list-text">Selezionare la scheda pipeline. Dal menu a discesa Try Sample Pipeline, selezionare Github + Maven. Il codice viene compilato automaticamente. Fare clic su Salva.</block>
  <block id="dedbf53849830e8b275b69e9b98159ce" category="paragraph"><block ref="dedbf53849830e8b275b69e9b98159ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0191ad3b841f8db403ec4749d571eb4b" category="list-text">Fare clic su Build Now (Crea ora) per avviare lo sviluppo attraverso la fase di preparazione, creazione e test. Il completamento dell'intero processo di creazione e la visualizzazione dei risultati della creazione possono richiedere alcuni minuti.</block>
  <block id="1d11f84feef51515ab9fdaafb3f02f3a" category="paragraph"><block ref="1d11f84feef51515ab9fdaafb3f02f3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b04b355d9fc6a2e23965649ebdd0aa31" category="list-text">Ogni volta che si verifica una modifica del codice, la pipeline può essere ricostruita per applicare patch alla nuova versione del software, consentendo un'integrazione continua e un'erogazione continua. Fare clic su Recent Changes (modifiche recenti) per tenere traccia delle modifiche rispetto alla versione precedente.</block>
  <block id="43d9a2fc4d89e82c869a466778811ab3" category="paragraph"><block ref="43d9a2fc4d89e82c869a466778811ab3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b41ceffa053ec5210732b1f8d0f0c5d" category="inline-link-macro">Avanti: Video e demo.</block>
  <block id="232b127190e97018e70ee81d28e36117" category="paragraph"><block ref="232b127190e97018e70ee81d28e36117" category="inline-link-macro-rx"></block></block>
  <block id="7eba670f1ea5a6e2fba9cff6b6399064" category="summary">In questa pagina sono riportate le istruzioni di installazione e configurazione per il bilanciamento del carico MetalLB.</block>
  <block id="79a2d2fa50d2b47d02c0e9dbdfadc07f" category="doc">Installazione di bilanciatori di carico MetalLB: Red Hat OpenShift con NetApp</block>
  <block id="0b2da9b5fe81e13e88c9a05981a95a9e" category="paragraph">Questa pagina elenca le istruzioni di installazione e configurazione per il bilanciamento del carico MetalLB.</block>
  <block id="d719c733d0cd8753c048c8c3a025fd51" category="paragraph">MetalLB è un bilanciamento del carico di rete self-hosting installato sul cluster OpenShift che consente la creazione di servizi OpenShift di bilanciamento del carico di tipo in cluster che non vengono eseguiti su un provider cloud. Le due funzionalità principali di MetalLB che lavorano insieme per supportare i servizi LoadBalancer sono l'allocazione degli indirizzi e l'annuncio esterno.</block>
  <block id="28a4ce0a0514d0f6a6596fc7a9c5e725" category="section-title">Opzioni di configurazione di MetalLB</block>
  <block id="04c22d763ca95631f9c8789eb2c6e68f" category="paragraph">In base al modo in cui MetalLB annuncia l'indirizzo IP assegnato ai servizi LoadBalancer all'esterno del cluster OpenShift, opera in due modalità:</block>
  <block id="92f98c10e5e0c86bcae2e9cb58b700e3" category="list-text">*Layer 2 mode.* in questa modalità, un nodo del cluster OpenShift assume la proprietà del servizio e risponde alle richieste ARP per quell'IP per renderlo raggiungibile all'esterno del cluster OpenShift. Poiché solo il nodo annuncia l'IP, presenta un collo di bottiglia nella larghezza di banda e limitazioni di failover lente. Per ulteriori informazioni, consultare la documentazione <block ref="4a1d14cac7ed68a2326a050e0f1fed80" category="inline-link-macro-rx"></block>.</block>
  <block id="13f78a1c753a58b3786e5664e7b01344" category="list-text">*Modalità BGP.* in questa modalità, tutti i nodi del cluster OpenShift stabiliscono sessioni di peering BGP con un router e pubblicizzano i route per inoltrare il traffico agli IP del servizio. Il prerequisito per questa operazione è l'integrazione di MetalLB con un router in tale rete. A causa del meccanismo di hashing in BGP, il mapping IP-to-Node per un servizio presenta una certa limitazione. Per ulteriori informazioni, consultare la documentazione <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>.</block>
  <block id="5fe238de20fea7c5ec86dde0a98c5841" category="admonition">Ai fini di questo documento, stiamo configurando MetalLB in modalità Layer-2.</block>
  <block id="32333b5f74abf17bffedb6e7abeb7b5f" category="section-title">Installazione del bilanciamento del carico MetalLB</block>
  <block id="70bd399edc6825961c98dc29c2a49299" category="list-text">Scarica le risorse di MetalLB.</block>
  <block id="d95ae9e4bae10f240e5577110ccbd7e6" category="list-text">Modificare il file<block ref="130d214581bb0aa3e8759729c9fbc133" prefix=" " category="inline-code"></block> e rimuovere<block ref="635a57f17cd40dc65b36973c9e14f9d1" prefix=" " category="inline-code"></block> Da Controller Deployment e dal DemonSet dell'oratore.</block>
  <block id="39bb715a16a6f4c1ab16bc3ad3654f0b" category="paragraph">*Righe da eliminare:*</block>
  <block id="803519c541b237245faa09039c50dcaa" category="list-text">Creare il<block ref="48f2018beab0b13a2087fae3aff05306" prefix=" " category="inline-code"></block> namespace.</block>
  <block id="980aff973ca30f65ec180530f40def06" category="list-text">Creare il CR MetalLB.</block>
  <block id="f87be5542b64a7f94a807699fd549479" category="list-text">Prima di configurare l'altoparlante MetalLB, concedere al relatore i privilegi elevati DemonSet in modo che possa eseguire la configurazione di rete richiesta per far funzionare i bilanciatori di carico.</block>
  <block id="53747915d8e79873876b08edb1ce3671" category="list-text">Configurare MetalLB creando un<block ref="a941f8adb5ae079ebc739cb59407fd30" prefix=" " category="inline-code"></block> in<block ref="48f2018beab0b13a2087fae3aff05306" prefix=" " category="inline-code"></block> namespace.</block>
  <block id="2b1e829362de1a86eeb131cdc4619908" category="list-text">Ora, quando vengono creati i servizi loadbalancer, MetalLB assegna un IP esterno ai servizi e annuncia l'indirizzo IP rispondendo alle richieste ARP.</block>
  <block id="234ce2b9b198f2acf2193cbd06120ff2" category="admonition">Se si desidera configurare MetalLB in modalità BGP, saltare il punto 6 e seguire la procedura nella documentazione di MetalLB <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>.</block>
  <block id="0f07e63979900ab2abf6d2d578850a47" category="inline-link-macro">Pagina successiva: Convalida della soluzione/casi d'utilizzo: Red Hat OpenShift con NetApp.</block>
  <block id="3a29a96f08f4066b544db012326464ed" category="paragraph"><block ref="3a29a96f08f4066b544db012326464ed" category="inline-link-macro-rx"></block></block>
  <block id="a0c55f3c40b8bb2d3e26f8d11ca73cbc" category="summary">Questo documento di riferimento fornisce la convalida dell'implementazione della soluzione Red Hat OpenShift, implementata tramite l'infrastruttura IPI (Installer Provised Infrastructure) in diversi ambienti di data center come validati da NetApp. Inoltre, descrive in dettaglio l'integrazione dello storage con i sistemi di storage NetApp utilizzando Astra Trident Storage orchestrator per la gestione dello storage persistente. Infine, vengono analizzate e documentate una serie di validazioni delle soluzioni e casi di utilizzo reali.</block>
  <block id="a0e01d06503f271c1de7acc0acd01733" category="doc">NVA-1160: Red Hat OpenShift con NetApp</block>
  <block id="3f4b17e041e63192875c654812122484" category="paragraph">Alan Cowles e Nikhil M Kulkarni, NetApp</block>
  <block id="2a3b399798aa16ecfbc1425cc560bfad" category="section-title">Casi di utilizzo</block>
  <block id="4711a0fd2fa3c3625080f399e5261ecd" category="paragraph">La soluzione Red Hat OpenShift con NetApp è progettata per offrire un valore eccezionale ai clienti con i seguenti casi di utilizzo:</block>
  <block id="44815e873492015d6a8ab6362de8da6c" category="list-text">Facile da implementare e gestire Red Hat OpenShift implementato utilizzando IPI (Installer Provised Infrastructure) su bare metal, Red Hat OpenStack Platform, Red Hat Virtualization e VMware vSphere.</block>
  <block id="03bb323d052d033ea0b5b2cab17f1219" category="list-text">Potenza combinata dei container aziendali e dei carichi di lavoro virtualizzati con Red Hat OpenShift implementato virtualmente su OSP, RHV o vSphere o su bare metal con la virtualizzazione OpenShift.</block>
  <block id="a2ac5b8f3de7c17418af38c828121a15" category="list-text">Configurazione e casi d'utilizzo reali che evidenziano le funzionalità di Red Hat OpenShift se utilizzato con lo storage NetApp e Astra Trident, l'orchestrator dello storage open source per Kubernetes.</block>
  <block id="f08561bbd831bfa1923e6acf045ef13a" category="section-title">Valore di business</block>
  <block id="42c487483a8feee3cc0365881a4cc265" category="paragraph">Red Hat OpenShift con NetApp riconosce queste sfide e presenta una soluzione che aiuta a risolvere ogni problema implementando l'implementazione completamente automatizzata di RedHat OpenShift IPI nell'ambiente del data center scelto dal cliente.</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="section-title">Panoramica della tecnologia</block>
  <block id="d3d8eb53a347d6ffc9fb157d9ac8398b" category="paragraph">La soluzione Red Hat OpenShift con NetApp comprende i seguenti componenti principali:</block>
  <block id="fd89bb4228981d3b22187eb451421cd6" category="section-title">Red Hat OpenShift Container Platform</block>
  <block id="81f74b2a02db97d708bd7cbf08d2463a" category="section-title">Sistemi storage NetApp</block>
  <block id="069b087e8e1e69cc928f18a85f683523" category="section-title">Integrazioni di storage NetApp</block>
  <block id="05cd0cf0962d29806df78d956f772deb" category="paragraph">Astra Trident è un orchestrator di storage open-source e completamente supportato per container e distribuzioni Kubernetes, incluso Red Hat OpenShift.</block>
  <block id="0bc570c518e7c4f356ebceb14fa8372f" category="section-title">Opzioni di configurazione avanzate</block>
  <block id="aa44798f04a58b33c3699abd02a59c57" category="paragraph">Questa sezione è dedicata alle personalizzazioni che gli utenti reali dovrebbero eseguire durante l'implementazione di questa soluzione in produzione, ad esempio la creazione di un registro di immagini private dedicato o l'implementazione di istanze personalizzate di bilanciamento del carico.</block>
  <block id="382742bb5fff6a719c144a0a01cd17e3" category="section-title">Matrice di supporto corrente per le release validate</block>
  <block id="e7e767d7c0e58b16e57d3ab16150db80" category="cell">Tecnologia</block>
  <block id="261addf78c7b2c961032b3dd08ba0b1f" category="cell">Scopo</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">Versione del software</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="cell">Storage</block>
  <block id="bd4a2d19c5168aa8c2b89b4affba2402" category="cell">9.8, 9.9.1</block>
  <block id="601712ded7a71b0842984ad41b6aad39" category="cell">12.3</block>
  <block id="8d96276332b02a2ef892828c1d4fbab4" category="cell">Gestione dei dati consapevole dell'applicazione</block>
  <block id="3d930ae98e9d9fc9a418d6b8e5e5639f" category="cell">21.12.60</block>
  <block id="765bb3744268ca0de607208bfdc8a37a" category="cell">Orchestrazione dello storage</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="b175d08ac03101cd40f077848d436e1f" category="cell">Red Hat OpenShift</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="cell">Orchestrazione di container</block>
  <block id="2bb7e89d50aed884078c4b7857f5bb39" category="cell">4.6 EUS, 4.7, 4.8</block>
  <block id="9c4e78a1b7e7b4981aced1e10d037c6d" category="cell">Piattaforma Red Hat OpenStack</block>
  <block id="de45aa336111dfa1825c54726464307c" category="cell">Infrastruttura di cloud privato</block>
  <block id="3c5825a0d4bdb85c67182ef89bc9c7eb" category="cell">16.1</block>
  <block id="80e910f35b12e9c61335fa88de36edd0" category="cell">Virtualizzazione Red Hat</block>
  <block id="e3024b13494086daa1b9813a799ba41a" category="cell">Virtualizzazione del data center</block>
  <block id="f9a97ed4e88eeab44f2693afa0eb2089" category="cell">4.4</block>
  <block id="9c295b8302ac546bb93a346b68089f50" category="cell">6.7U3</block>
  <block id="aacc79f269e716528198eabb064b216b" category="inline-link-macro">Pagina successiva: Panoramica di Red Hat OpenShift.</block>
  <block id="62857c2aca7eeae2c1f44104c3fc7dde" category="paragraph"><block ref="62857c2aca7eeae2c1f44104c3fc7dde" category="inline-link-macro-rx"></block></block>
  <block id="f79c612e785ac74789a25e8dda9e8731" category="doc">Panoramica di Astra Trident</block>
  <block id="78c43863df60a7808264e8659cfa6b54" category="paragraph">Astra Trident è un orchestrator di storage open-source e completamente supportato per container e distribuzioni Kubernetes, incluso Red Hat OpenShift. Trident lavora con l'intero portfolio di storage NetApp, inclusi i sistemi storage NetApp ONTAP ed Element, e supporta anche connessioni NFS e iSCSI. Trident accelera il workflow DevOps consentendo agli utenti finali di eseguire il provisioning e gestire lo storage dai sistemi storage NetApp senza richiedere l'intervento di un amministratore dello storage.</block>
  <block id="8b70487815961b708f216595f5817311" category="paragraph">L'ultima versione di Astra Trident è la 22.01 rilasciata a gennaio 2022. Matrice di supporto per quale versione di Trident è stata testata con la quale è possibile trovare la distribuzione Kubernetes<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>.</block>
  <block id="4281e618126caa3d322e78eafddba1b2" category="section-title">Scarica Astra Trident</block>
  <block id="f95d0437e813349fa018b7f0e68e9a7d" category="paragraph">Per installare Trident sul cluster di utenti implementato ed eseguire il provisioning di un volume persistente, attenersi alla seguente procedura:</block>
  <block id="b5d9e69ac9444a6a1cfd78cf106c057e" category="list-text">Scaricare l'archivio di installazione sulla workstation di amministrazione ed estrarre il contenuto. La versione corrente di Trident è la 22.01, che può essere scaricata<block ref="defadeb91446b93776c7f5696677985c" category="inline-link-rx"></block>.</block>
  <block id="422269f9bb560b76869cbd586b8370d5" category="list-text">Estrarre l'installazione di Trident dal bundle scaricato.</block>
  <block id="52d012c119e8e080d08f6a1592f8f9ec" category="section-title">Installare l'operatore Trident con Helm</block>
  <block id="68602d0447fae81afa9d0528ef0c6420" category="list-text">Innanzitutto, impostare la posizione del cluster utente<block ref="deabc6332aa53495b56c51d2e3eca54f" prefix=" " category="inline-code"></block> File come variabile di ambiente in modo da non doverla fare riferimento, perché Trident non ha alcuna opzione per passare questo file.</block>
  <block id="449774824d889f1d6ebc0bbcc4920493" category="list-text">Eseguire il comando Helm per installare l'operatore Trident dal tarball nella directory helm durante la creazione dello spazio dei nomi Trident nel cluster di utenti.</block>
  <block id="64e437a845e5de3c8e50925ebdfce295" category="list-text">È possibile verificare che Trident sia installato correttamente controllando i pod in esecuzione nello spazio dei nomi o utilizzando il binario tridentctl per controllare la versione installata.</block>
  <block id="3ce67d5de6974f67e0048e6fdbf89498" category="admonition">In alcuni casi, gli ambienti dei clienti potrebbero richiedere la personalizzazione dell'implementazione di Trident. In questi casi, è anche possibile installare manualmente l'operatore Trident e aggiornare i manifesti inclusi per personalizzare l'implementazione.</block>
  <block id="8bd534d3b6bc8d2541df052e053ed65d" category="section-title">Installare manualmente l'operatore Trident</block>
  <block id="1315b42a551dafb715ab654d8eb5af40" category="list-text">Innanzitutto, impostare la posizione del cluster utente<block ref="deabc6332aa53495b56c51d2e3eca54f" prefix=" " category="inline-code"></block> File come variabile di ambiente in modo da non doverla fare riferimento, perché Trident non ha alcuna opzione per passare questo file.</block>
  <block id="5d710ec7d521df428edd75c1885ee89b" category="list-text">Il<block ref="c84ef67352bb6783ff2881f9f2821c2a" prefix=" " category="inline-code"></block> la directory contiene i manifesti per la definizione di tutte le risorse richieste. Utilizzando i manifesti appropriati, creare<block ref="ae61bf6af1a7406b62c72a4bef1ab62d" prefix=" " category="inline-code"></block> definizione personalizzata delle risorse.</block>
  <block id="0ac11186fb38b2e9d4acd38d03f61b5c" category="list-text">Se non ne esiste uno, creare uno spazio dei nomi Trident nel cluster utilizzando il manifesto fornito.</block>
  <block id="004c51fe71b5c654f88a31270ec6c8e9" category="list-text">Creare le risorse necessarie per l'implementazione dell'operatore Trident, ad esempio un<block ref="5c24ffd6438853b537bd99b3fccd3340" prefix=" " category="inline-code"></block> per l'operatore, un<block ref="d7d354d0f9d0780e168c895c92a32c24" prefix=" " category="inline-code"></block> e.<block ref="e866afd8290d5c73cda6260e04e6eef0" prefix=" " category="inline-code"></block> al<block ref="5c24ffd6438853b537bd99b3fccd3340" prefix=" " category="inline-code"></block>, un dedicato<block ref="316707d12484dd3afede08839dee49bc" prefix=" " category="inline-code"></block>o l'operatore stesso.</block>
  <block id="f7b9c678b684e969a3ee5ac971514f48" category="list-text">È possibile controllare lo stato dell'operatore dopo l'implementazione con i seguenti comandi:</block>
  <block id="b34dd67c198ad4cf0088bd29c7ef4658" category="list-text">Con l'implementazione dell'operatore, ora possiamo utilizzarlo per installare Trident. Per eseguire questa operazione, è necessario creare un<block ref="ae61bf6af1a7406b62c72a4bef1ab62d" prefix=" " category="inline-code"></block>.</block>
  <block id="e32d70a13ba1767d9a373fe9a0535531" category="section-title">Preparare i nodi di lavoro per lo storage</block>
  <block id="4b4d60be85b0c53c72ae4b8a05deacef" category="paragraph">La maggior parte delle distribuzioni Kubernetes viene fornita con i pacchetti e le utility per montare i backend NFS installati di default, incluso Red Hat OpenShift.</block>
  <block id="89c771069f269704306d4ca7b118cc7d" category="paragraph">Tuttavia, per NFSv3, non esiste alcun meccanismo per negoziare la concorrenza tra il client e il server. Pertanto, il numero massimo di voci della tabella degli slot sunrpc lato client deve essere sincronizzato manualmente con il valore supportato sul server per garantire le migliori prestazioni per la connessione NFS senza che il server debba ridurre le dimensioni della finestra della connessione.</block>
  <block id="9c2d7353683234845149cb6710dc11f8" category="paragraph">Per ONTAP, il numero massimo supportato di voci della tabella degli slot sunrpc è 128, ovvero ONTAP può gestire 128 richieste NFS simultanee alla volta. Tuttavia, per impostazione predefinita, Red Hat CoreOS/Red Hat Enterprise Linux ha un massimo di 65,536 voci della tabella degli slot sunrpc per connessione. È necessario impostare questo valore su 128 e questo può essere fatto usando Machine Config Operator (MCO) in OpenShift.</block>
  <block id="88cd6afaae477b942c9ab5d396e43cfb" category="paragraph">Per modificare il numero massimo di voci della tabella degli slot sunrpc nei nodi di lavoro OpenShift, attenersi alla seguente procedura:</block>
  <block id="7b8e6ef8272a81ebcc108ee3fcf4eac8" category="list-text">Accedere alla console Web di OCP e selezionare Compute &gt; Machine Configs (calcolo &gt; configurazioni macchina). Fare clic su Create Machine Config. Copiare e incollare il file YAML e fare clic su Create (Crea).</block>
  <block id="e7a7478f209d8b5dcaf38a593ce749b3" category="list-text">Dopo aver creato l'MCO, la configurazione deve essere applicata a tutti i nodi di lavoro e riavviata uno alla volta. L'intero processo richiede da 20 a 30 minuti circa. Verificare se la configurazione del computer viene applicata utilizzando<block ref="1b2628e311828c98f0307b49309b67ee" prefix=" " category="inline-code"></block> e assicurarsi che il pool di configurazione del computer per i lavoratori sia aggiornato.</block>
  <block id="693642fbb464db49c22715a536e99c3f" category="paragraph">Per preparare i nodi di lavoro per consentire la mappatura dei volumi di storage a blocchi tramite il protocollo iSCSI, è necessario installare i pacchetti necessari per supportare tale funzionalità.</block>
  <block id="cccb85b5e6a9a19187087f71254d1fb2" category="paragraph">In Red Hat OpenShift, questo viene gestito applicando un MCO (Machine Config Operator) al cluster dopo averlo implementato.</block>
  <block id="068d2023b916134a0573aaad841124e4" category="paragraph">Per configurare i nodi di lavoro per l'esecuzione dei servizi iSCSI, attenersi alla seguente procedura:</block>
  <block id="c25282bfd8c140d1f79c25362637f744" category="paragraph">Quando non si utilizza il multipathing:</block>
  <block id="541c76e8762c84e3e0488f91c8062e08" category="paragraph">Quando si utilizza il multipathing:</block>
  <block id="d9f036d3b9f84b626f8a777480066cab" category="list-text">Una volta creata la configurazione, sono necessari circa 20 - 30 minuti per applicarla ai nodi di lavoro e ricaricarla. Verificare se la configurazione del computer viene applicata utilizzando<block ref="1b2628e311828c98f0307b49309b67ee" prefix=" " category="inline-code"></block> e assicurarsi che il pool di configurazione del computer per i lavoratori sia aggiornato. È inoltre possibile accedere ai nodi di lavoro per confermare che il servizio iscsid è in esecuzione (e il servizio multipath è in esecuzione se si utilizza il multipathing).</block>
  <block id="6e16409ed6038c106c7fa1dfbfb9da0f" category="admonition">È inoltre possibile confermare che MachineConfig sia stato applicato correttamente e che i servizi siano stati avviati come previsto eseguendo il<block ref="5c237bbde25a8cf47cdca465191a6c1d" prefix=" " category="inline-code"></block> con i flag appropriati.</block>
  <block id="b09d268106fd9cbfffd1dc848382a150" category="section-title">Creazione di backend per il sistema storage</block>
  <block id="f71051465199267cbb540658a51e2957" category="paragraph">Dopo aver completato l'installazione di Astra Trident Operator, è necessario configurare il backend per la piattaforma di storage NetApp specifica in uso. Seguire i collegamenti riportati di seguito per continuare l'installazione e la configurazione di Astra Trident.</block>
  <block id="615767b52353571ac174e22f1a984aa3" category="inline-link-macro">NetApp ONTAP NFS</block>
  <block id="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="list-text"><block ref="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="inline-link-macro-rx"></block></block>
  <block id="c93e7ef2934826b1393251e9f7d9e331" category="inline-link-macro">ISCSI NetApp ONTAP</block>
  <block id="d7b539d4bc16fbdf1477adddfda6c802" category="list-text"><block ref="d7b539d4bc16fbdf1477adddfda6c802" category="inline-link-macro-rx"></block></block>
  <block id="d0e0904111acb167badbf5f196ad1205" category="inline-link-macro">ISCSI NetApp Element</block>
  <block id="2e5d36490241211379006b7f6934bf06" category="list-text"><block ref="2e5d36490241211379006b7f6934bf06" category="inline-link-macro-rx"></block></block>
  <block id="7f3417590f5bba5cf5eb34fb288135f1" category="inline-link-macro">Pagina successiva: Convalida della soluzione/casi di utilizzo: Red Hat OpenShift con NetApp.</block>
  <block id="7a38916784a7216f98837f315958c175" category="paragraph"><block ref="7a38916784a7216f98837f315958c175" category="inline-link-macro-rx"></block></block>
  <block id="4c37a5afd480a0042f69d7628cadd57d" category="summary">Gestione avanzata dei cluster per Kubernetes su Red Hat OpenShift con NetApp</block>
  <block id="43288d8129021b1fe8b4bc6784e65b32" category="doc">Funzionalità: Gestione avanzata dei cluster per Kubernetes su Red Hat OpenShift con NetApp</block>
  <block id="de59be6e44d20d9dd12412571b745c5f" category="section-title">Gestione del ciclo di vita dell'applicazione</block>
  <block id="fa19c463235a810b3a93333d6ee51d6c" category="paragraph">Per creare un'applicazione e gestirla in un insieme di cluster,</block>
  <block id="920db239cf01c8ded4b7f364194ab540" category="list-text">Accedere a Manage Applications (Gestisci applicazioni) dalla barra laterale e fare clic su Create Application (Crea applicazione). Fornire i dettagli dell'applicazione che si desidera creare e fare clic su Save (Salva).</block>
  <block id="6b41f909eb299f214abfb15580583456" category="image-alt">Creare l'applicazione</block>
  <block id="bcb3e5b76f189a87ea350550f86de83f" category="list-text">Una volta installati i componenti dell'applicazione, l'applicazione viene visualizzata nell'elenco.</block>
  <block id="d70fc022d09a33f4044c81cd670a71b6" category="image-alt">Elenco delle applicazioni</block>
  <block id="672d326704c3be4bebf6c816a48495e7" category="list-text">L'applicazione può ora essere monitorata e gestita dalla console.</block>
  <block id="0787d747a308cc786b50363313ccf714" category="inline-link-macro">Avanti: Funzionalità - governance e rischi.</block>
  <block id="f4c7ffc89dab76d5a6dccad54114c204" category="paragraph"><block ref="f4c7ffc89dab76d5a6dccad54114c204" category="inline-link-macro-rx"></block></block>
  <block id="3605e05aa598ff405b5edffc1bf474f1" category="summary">Configurazione della multitenancy su Red Hat OpenShift con NetApp</block>
  <block id="ec22e01e7cd5087ef746b3db5852da6e" category="doc">Scalabilità: Aggiunta di più progetti</block>
  <block id="0e4136a9f4ad3204c07db26d3c28a546" category="paragraph">In una configurazione multi-tenant, l'aggiunta di nuovi progetti con risorse di storage richiede una configurazione aggiuntiva per garantire che la multi-tenancy non venga violata. Per aggiungere altri progetti in un cluster multi-tenant, attenersi alla seguente procedura:</block>
  <block id="c8acb1fa89b1ec9d78799a2dd4aa8b59" category="list-text">Accedere al cluster NetApp ONTAP come amministratore dello storage.</block>
  <block id="d0ed0d7b81278233c852e4a0d8aa123b" category="list-text">Selezionare<block ref="ba7ff8660fabd8daa8e7fbd0c74dd990" prefix=" " category="inline-code"></block> e fare clic su<block ref="ec211f7c20af43e742bf2570c3cb84f9" prefix=" " category="inline-code"></block>. Creare una nuova SVM dedicata al progetto 3. Inoltre, creare un account vsadmin per gestire SVM e le relative risorse.</block>
  <block id="5790e2b8b367726e78500054d959d6f7" category="image-alt">Creare SVM per la scalabilità</block>
  <block id="b0c67e9a89c7ece3169ab5849bb0e411" category="list-text">Accedere al cluster Red Hat OpenShift come amministratore del cluster.</block>
  <block id="c9e86337c7483c8d45e5e535829d2163" category="list-text">Creare un nuovo progetto.</block>
  <block id="1c01b62cc887329b006a88e9f959b5d4" category="list-text">Assicurarsi che il gruppo di utenti per il project-3 sia creato su IdP e sincronizzato con il cluster OpenShift.</block>
  <block id="46c82384780a492254c43d461363d9ac" category="list-text">Creare il ruolo di sviluppatore per il progetto 3.</block>
  <block id="21ac9e9bbb2cfc707143311f4601af1c" category="admonition">La definizione del ruolo fornita in questa sezione è solo un esempio. Il ruolo dello sviluppatore deve essere definito in base ai requisiti dell'utente finale.</block>
  <block id="8efa8222e644f71e636f98917439566d" category="list-text">Creare il RoleBinding per gli sviluppatori nel progetto-3 che legano il ruolo di sviluppatore-progetto-3 al gruppo corrispondente (ocp-progetto-3) nel progetto-3.</block>
  <block id="e1f01c3341da15c9079bf5996c059811" category="list-text">Accedere al cluster Red Hat OpenShift come amministratore dello storage</block>
  <block id="2ca2d57f42208b6e7e9026b491595f41" category="list-text">Creare un backend Trident e mapparlo sulla SVM dedicata al progetto 3. NetApp consiglia di utilizzare l'account vsadmin della SVM per connettere il backend alla SVM invece di utilizzare l'amministratore del cluster ONTAP.</block>
  <block id="c4dcda95616fac9215b5dac3cde37220" category="admonition">Per questo esempio, viene utilizzato il driver ontap-nas. Utilizzare il driver appropriato per creare il backend in base al caso d'utilizzo.</block>
  <block id="8628ed29313534f54f01e0da36e66ab7" category="admonition">Supponiamo che Trident sia installato nel progetto Trident.</block>
  <block id="55da75937cfedfe97c220c1e9d556d84" category="list-text">Creare la classe di storage per il progetto 3 e configurarla per utilizzare i pool di storage dal back-end dedicato al progetto 3.</block>
  <block id="6efdcf6ed405066371d23375541816a1" category="list-text">Creare un ResourceQuota per limitare le risorse nel progetto 3, richiedendo storage da storageclasses dedicati ad altri progetti.</block>
  <block id="1dea1d57247580b530335ec2d484f8a5" category="list-text">Applicare patch alle ResourceQuotas in altri progetti per limitare l'accesso alle risorse in tali progetti dallo storage dallo storageclass dedicato al progetto-3.</block>
  <block id="e690fa655ec589e6d0abb58164d5ccfd" category="doc">Ulteriori informazioni: Red Hat OpenShift con NetApp</block>
  <block id="1be465260df7c846768e06c988594a6a" category="paragraph">Per ulteriori informazioni sulle informazioni descritte in questo documento, visitare i seguenti siti Web:</block>
  <block id="6f4e4d9fbe846fd8bf7decf7dcffbd63" category="list-text">Documentazione NetApp</block>
  <block id="1497398039e94eb756be9a3cff5649c7" category="inline-link"><block ref="1497398039e94eb756be9a3cff5649c7" category="inline-link-rx"></block></block>
  <block id="f2d3084aa0f70da5e15757ee3292cda7" category="paragraph"><block ref="f2d3084aa0f70da5e15757ee3292cda7" category="inline-link-rx"></block></block>
  <block id="824bd84e05db30b27e73f839dae3b8e5" category="list-text">Documentazione di Astra Trident</block>
  <block id="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link"><block ref="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link-rx"></block></block>
  <block id="086fce5f74cc93b0516aadec33636e09" category="paragraph"><block ref="086fce5f74cc93b0516aadec33636e09" category="inline-link-rx"></block></block>
  <block id="fe549ebd8a3f0fea1803cbaa947ef198" category="list-text">Documentazione di NetApp Astra Control Center</block>
  <block id="ad837604b59ea6a89754d8e75f595c7b" category="inline-link"><block ref="ad837604b59ea6a89754d8e75f595c7b" category="inline-link-rx"></block></block>
  <block id="4af69e66dd3d513168080d177919dd21" category="paragraph"><block ref="4af69e66dd3d513168080d177919dd21" category="inline-link-rx"></block></block>
  <block id="21b11dbf6ab3c6d36a76f280fe8ec75d" category="list-text">Documentazione di Red Hat OpenShift</block>
  <block id="74201863479cf5c9b89330c920283301" category="inline-link"><block ref="74201863479cf5c9b89330c920283301" category="inline-link-rx"></block></block>
  <block id="3e10ed3875c45f9dc9064324660fc2b1" category="paragraph"><block ref="3e10ed3875c45f9dc9064324660fc2b1" category="inline-link-rx"></block></block>
  <block id="06fd33ae9f869a89e860634ec94b9793" category="list-text">Documentazione sulla piattaforma Red Hat OpenStack</block>
  <block id="647d438a62673b6a6c9830682f6bc128" category="inline-link"><block ref="647d438a62673b6a6c9830682f6bc128" category="inline-link-rx"></block></block>
  <block id="705a39bc1a12c50103a847633c3f7493" category="paragraph"><block ref="705a39bc1a12c50103a847633c3f7493" category="inline-link-rx"></block></block>
  <block id="8d79e9650a1f62f89d77743225e203c0" category="list-text">Documentazione sulla virtualizzazione Red Hat</block>
  <block id="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link"><block ref="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link-rx"></block></block>
  <block id="6d6038842b529e3d97aa9a8a9d81d866" category="paragraph"><block ref="6d6038842b529e3d97aa9a8a9d81d866" category="inline-link-rx"></block></block>
  <block id="4666fc2f640685636f115f8b2b6b8ce0" category="list-text">Documentazione VMware vSphere</block>
  <block id="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link"><block ref="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link-rx"></block></block>
  <block id="71aa41fc980571d5a324adedae614f9c" category="paragraph"><block ref="71aa41fc980571d5a324adedae614f9c" category="inline-link-rx"></block></block>
  <block id="ad8905a47eb465223ebe7acf569732b1" category="doc">Configurazione: Attività di amministrazione del cluster</block>
  <block id="552eab1d1ea09d0d1733b97dee6609a1" category="paragraph">Le seguenti attività vengono eseguite dall'amministratore del cluster Red Hat OpenShift:</block>
  <block id="8a4ffd494b5e8af3ac1be2cd9ab254fb" category="list-text">Accedere al cluster Red Hat OpenShift come amministratore del cluster.</block>
  <block id="7ccd4d72e4addf5c27c53bafaeb3fdbd" category="list-text">Creare due progetti corrispondenti a progetti diversi.</block>
  <block id="6c98bfb16f2e9bbebd943c1f8592306d" category="list-text">Creare il ruolo di sviluppatore per il progetto-1.</block>
  <block id="14bd8c5f1032dd20f94d4434365c6530" category="admonition">La definizione del ruolo fornita in questa sezione è solo un esempio. I ruoli dello sviluppatore devono essere definiti in base ai requisiti dell'utente finale.</block>
  <block id="3c73122271c9219b54ca745b732adc28" category="list-text">Allo stesso modo, creare ruoli di sviluppatore per il progetto 2.</block>
  <block id="7428df2e0e503f4cabb43a4667bc1983" category="list-text">Tutte le risorse storage di OpenShift e NetApp sono generalmente gestite da un amministratore dello storage. L'accesso per gli amministratori dello storage è controllato dal ruolo di operatore trident creato al momento dell'installazione di Trident. Inoltre, l'amministratore dello storage richiede l'accesso a ResourceQuotas per controllare il modo in cui lo storage viene utilizzato.</block>
  <block id="cf17c458ea3abaad557d7cfc69886dbe" category="list-text">Creare un ruolo per la gestione di ResourceQuotas in tutti i progetti del cluster per associarlo all'amministratore dello storage.</block>
  <block id="db99ab183aa8f56c951cf20e25e7465c" category="list-text">Assicurarsi che il cluster sia integrato con il provider di identità dell'organizzazione e che i gruppi di utenti siano sincronizzati con i gruppi di cluster. L'esempio seguente mostra che il provider di identità è stato integrato con il cluster e sincronizzato con i gruppi di utenti.</block>
  <block id="36e36b60ddb8f46fe0b9b4e8f4dce56f" category="list-text">Configurare ClusterRoleBinding per gli amministratori dello storage.</block>
  <block id="38f22acd9ae9c74099644738d613baaa" category="admonition">Per gli amministratori dello storage, devono essere associati due ruoli: trident-operator e Resource-quote.</block>
  <block id="ced38b1f1c19446862c601754b82b94c" category="list-text">Creare i RoleBinding per gli sviluppatori che associano il ruolo Developer-project-1 al gruppo corrispondente (ocp-project-1) nel progetto-1.</block>
  <block id="2aa292f2ff8b13fe141ca55c27bc29c2" category="list-text">Allo stesso modo, creare RoleBinding per gli sviluppatori che associano i ruoli di sviluppatore al gruppo di utenti corrispondente nel progetto-2.</block>
  <block id="7d03daab3e74958fc08ebc0c90e0a6a2" category="inline-link-macro">Avanti: Attività dell'amministratore dello storage.</block>
  <block id="f3d9bb76442ab5c11e6af4dd328b2559" category="paragraph"><block ref="f3d9bb76442ab5c11e6af4dd328b2559" category="inline-link-macro-rx"></block></block>
  <block id="cb8e8e87ec9c630a0a27910fe29abceb" category="summary">RHV è una piattaforma per data center virtuale aziendale che viene eseguita su Red Hat Enterprise Linux (RHEL) e utilizza l'hypervisor KVM.</block>
  <block id="f88eb30a75027b557910958c7306cb4e" category="doc">OpenShift sulla virtualizzazione Red Hat</block>
  <block id="932e95da8a59703292a426466e703c7a" category="paragraph">Red Hat Virtualization (RHV) è una piattaforma per data center virtuale aziendale che viene eseguita su Red Hat Enterprise Linux (RHEL) e utilizza l'hypervisor KVM.</block>
  <block id="603bc85f6f6f4d9e5095745d9252f1d3" category="inline-link">Sito Web Red Hat Virtualization</block>
  <block id="8a961382f0c47dc86706f0aa8bb93fb4" category="paragraph">Per ulteriori informazioni su RHV, consultare<block ref="ac07861257bcab0c21d310fa00cb324b" category="inline-link-rx"></block>.</block>
  <block id="7adf04762320f012179ffe68fb0aeb9f" category="paragraph">RHV offre le seguenti funzionalità:</block>
  <block id="0178ef6806a57586f6c66dde7e0e86d2" category="list-text">*Gestione centralizzata di macchine virtuali e host.* il gestore RHV viene eseguito come macchina fisica o virtuale (VM) nell'implementazione e fornisce un'interfaccia grafica basata su web per la gestione della soluzione da un'interfaccia centrale.</block>
  <block id="c29d3f9be705e3dcf947c6d2464cb090" category="list-text">*Motore self-hosting.* per ridurre al minimo i requisiti hardware, RHV consente di implementare RHV Manager (RHV-M) come macchina virtuale sugli stessi host che eseguono macchine virtuali guest.</block>
  <block id="e2545c34b3a35dbcd93423b539eae91a" category="list-text">*High Availability.* per evitare interruzioni in caso di guasti dell'host, RHV consente di configurare le macchine virtuali per l'alta disponibilità. Le macchine virtuali ad alta disponibilità vengono controllate a livello di cluster utilizzando policy di resilienza.</block>
  <block id="8f91b3a5c6d176cad584bb5f06c53684" category="list-text">*Elevata scalabilità.* Un singolo cluster RHV può disporre di un massimo di 200 host hypervisor che consentono all'IT di supportare i requisiti di macchine virtuali di grandi dimensioni per ospitare carichi di lavoro di livello Enterprise e avidi in termini di risorse.</block>
  <block id="a175fea9b8830c0cdbe1b268cb114738" category="list-text">*Sicurezza migliorata.* ereditato da RHV, le tecnologie di virtualizzazione sicura (sVirt) e Security Enhanced Linux (SELinux) sono utilizzate da RHV per garantire sicurezza e protezione avanzata elevate per host e macchine virtuali. Il vantaggio principale di queste funzionalità è l'isolamento logico di una macchina virtuale e delle risorse associate.</block>
  <block id="01b0ee840ef208c283c3f4e959aa9427" category="paragraph"><block ref="01b0ee840ef208c283c3f4e959aa9427" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">Progettazione di rete</block>
  <block id="cd4c83df745cf56330120fb3ac308da2" category="paragraph">La soluzione Red Hat OpenShift su NetApp utilizza due switch dati per fornire connettività dati primaria a 25 Gbps. Utilizza inoltre due switch di gestione aggiuntivi che forniscono connettività a 1 Gbps per la gestione in banda dei nodi di storage e gestione out-of-band per la funzionalità IPMI. OCP utilizza la rete logica della macchina virtuale su RHV per la gestione del cluster. Questa sezione descrive la disposizione e lo scopo di ciascun segmento di rete virtuale utilizzato nella soluzione e illustra i prerequisiti per l'implementazione della soluzione.</block>
  <block id="f1744781b12c15ad3b748bea44d9582b" category="section-title">Requisiti VLAN</block>
  <block id="2d7e48e226974692ed3f522a2baef6db" category="paragraph">Red Hat OpenShift su RHV è progettato per separare logicamente il traffico di rete per scopi diversi utilizzando Virtual Local Area Network (VLAN). Questa configurazione può essere scalata per soddisfare le esigenze dei clienti o per fornire un ulteriore isolamento per servizi di rete specifici. La seguente tabella elenca le VLAN necessarie per implementare la soluzione durante la convalida della soluzione in NetApp.</block>
  <block id="87495e311a3944910e3cc0c7bee3d754" category="cell">VLAN</block>
  <block id="05808f0e86c04c2a062c2e041f9e0827" category="cell">ID VLAN</block>
  <block id="b7dff125c9fce628900142990708436f" category="cell">Rete di gestione fuori banda</block>
  <block id="3c8c5d8387f173924ffeb2bf88084dba" category="cell">Gestione per nodi fisici e IPMI</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16</block>
  <block id="c61d980d5248923d65a5dfe7f8818011" category="cell">Rete di macchine virtuali</block>
  <block id="f33bd5bca507f2b59fc0a43383ade71b" category="cell">Accesso alla rete guest virtuale</block>
  <block id="36a1694bce9815b7e38a9dad05ad42e0" category="cell">1172</block>
  <block id="7b9993fac4b9a60605aa2884eb40f4a3" category="cell">Rete di gestione in-band</block>
  <block id="c347686b0750301dfca053b321126bcc" category="cell">Gestione dei nodi RHV-H, RHV-Manager e della rete ovirtmgmt</block>
  <block id="21c5bba1dd6aed9ab48c2b34c1a0adde" category="cell">3343</block>
  <block id="cd3718e8610b820344c9a0284fe84f90" category="cell">Rete di storage</block>
  <block id="11967d5f57969ea4713204eace8fbf4e" category="cell">Rete storage per iSCSI NetApp Element</block>
  <block id="3083202a936b7d0ef8b680d7ae73fa1a" category="cell">3344</block>
  <block id="3de18ffc25309bd0755d8543a30ded78" category="cell">Rete di migrazione</block>
  <block id="c87f7de78a1912f53050e58df90e1445" category="cell">Rete per la migrazione dei guest virtuali</block>
  <block id="38a77aa456fc813af07bb428f2363c8d" category="cell">3345</block>
  <block id="35b5078b5953437a59ffd4f77c464800" category="section-title">Risorse di supporto dell'infrastruttura di rete</block>
  <block id="0bad9231e1bf61bc343a986739f155c1" category="paragraph">Prima dell'implementazione della piattaforma container OpenShift, è necessario installare la seguente infrastruttura:</block>
  <block id="9335616a8b7dc0e6f94fd0c6aa720efe" category="list-text">Almeno un server DNS che fornisce una risoluzione completa del nome host accessibile dalla rete di gestione in-band e dalla rete VM.</block>
  <block id="905a394004d9055ec4708e53880cac66" category="list-text">Almeno un server NTP accessibile dalla rete di gestione in-band e dalla rete VM.</block>
  <block id="447cb4a01965e3df01476db3576e0399" category="list-text">(Opzionale) connettività Internet in uscita per la rete di gestione in banda e la rete VM.</block>
  <block id="a181412a291a7d0ae8a71300abf746b8" category="section-title">Best practice per le implementazioni in produzione</block>
  <block id="0f19aa91cffca51fd061e34dee1e5c79" category="paragraph">In questa sezione sono elencate diverse Best practice che un'organizzazione deve prendere in considerazione prima di implementare questa soluzione in produzione.</block>
  <block id="7e4be32047fe5b09a23fd956cd4e82f0" category="section-title">Implementare OpenShift in un cluster RHV di almeno tre nodi</block>
  <block id="de4e964e7be880b328384cfedd5873d9" category="paragraph">L'architettura verificata descritta in questo documento presenta l'implementazione hardware minima adatta per le operazioni ha implementando due nodi hypervisor RHV-H e garantendo una configurazione a tolleranza di errore in cui entrambi gli host possono gestire il motore in hosting e le macchine virtuali implementate possono migrare tra i due hypervisor.</block>
  <block id="4a3fe6077a529bcbe033bbb7d13027d6" category="paragraph">Poiché Red Hat OpenShift viene inizialmente implementato con tre nodi master, in una configurazione a due nodi è garantito che almeno due master occuperanno lo stesso nodo, il che può causare un'interruzione di OpenShift se quel nodo specifico non è disponibile. Pertanto, è una Best practice di Red Hat che almeno tre nodi di hypervisor RHV-H siano implementati come parte della soluzione, in modo che i master OpenShift possano essere distribuiti in modo uniforme e la soluzione riceva un ulteriore grado di tolleranza agli errori.</block>
  <block id="7a595c63e0ebc069af3da46e3d1c8fee" category="section-title">Configurare l'affinità di macchine virtuali/host</block>
  <block id="b98f17dd49fc6d1c2a9b58922fae2686" category="paragraph">È possibile distribuire i master OpenShift su più nodi hypervisor abilitando l'affinità VM/host.</block>
  <block id="df1b58247681ba5f974a572d530dbdf9" category="paragraph">Affinity è un modo per definire le regole per un insieme di macchine virtuali e/o host che determinano se le macchine virtuali vengono eseguite insieme sullo stesso host o su host del gruppo o su host diversi. Viene applicato alle macchine virtuali creando gruppi di affinità costituiti da macchine virtuali e/o host con un insieme di parametri e condizioni identici. A seconda che le macchine virtuali di un gruppo di affinità vengano eseguite sullo stesso host o su host del gruppo o separatamente su host diversi, i parametri del gruppo di affinità possono definire affinità positiva o affinità negativa.</block>
  <block id="02d7502b2b132a675665088322fde9b0" category="paragraph">Le condizioni definite per i parametri possono essere l'applicazione forzata o forzata. La rigida applicazione garantisce che le macchine virtuali di un gruppo di affinità seguano sempre l'affinità positiva o negativa rigorosamente senza alcun riferimento alle condizioni esterne. La soft enforcement garantisce che venga impostata una preferenza più elevata per le macchine virtuali di un gruppo di affinità per seguire l'affinità positiva o negativa quando possibile. Nella configurazione di due o tre hypervisor descritta in questo documento, l'impostazione consigliata è affinità soft. Nei cluster più grandi, la hard affinità può distribuire correttamente i nodi OpenShift.</block>
  <block id="5c00bc5cb1bdae240d18551e77806abd" category="inline-link">Red Hat 6.11. Documentazione di Affinity Groups</block>
  <block id="f38d8cd9caeb9a037c470b7d061392a0" category="paragraph">Per configurare i gruppi di affinità, vedere<block ref="eb1587f3cb611d53dba5bde41d49122a" category="inline-link-rx"></block>.</block>
  <block id="ed3ecd4254cc054c70ddee702d7ed519" category="section-title">Utilizzare un file di installazione personalizzato per la distribuzione di OpenShift</block>
  <block id="2b083bcbbb2d2208e64c13cb183af44f" category="paragraph">IPI semplifica l'implementazione dei cluster OpenShift attraverso la procedura guidata interattiva descritta in precedenza in questo documento. Tuttavia, è possibile che alcuni valori predefiniti debbano essere modificati nell'ambito dell'implementazione del cluster.</block>
  <block id="1050f3dc9e3ee559789e3b25f2e4f77e" category="inline-link">Red Hat OpenShift Installazione di un cluster su RHV con personalizzazioni</block>
  <block id="a5867d73fa54e5b850ff2642c45ade52" category="paragraph">In questi casi, è possibile eseguire e gestire la procedura guidata senza implementare immediatamente un cluster. Viene invece creato un file di configurazione da cui è possibile implementare il cluster in un secondo momento. Questo è molto utile se si desidera modificare le impostazioni predefinite IPI o se si desidera implementare più cluster identici nel proprio ambiente per altri utilizzi, ad esempio la multi-tenancy. Per ulteriori informazioni sulla creazione di una configurazione di installazione personalizzata per OpenShift, vedere<block ref="15427a9f842d7a49b872cf64115f33bc" category="inline-link-rx"></block>.</block>
  <block id="b611590ed189a9cbc27648402168f00a" category="inline-link-macro">Pagina successiva: Panoramica dello storage NetApp.</block>
  <block id="2be0276ec05c9b03a47573ad9795095a" category="paragraph"><block ref="2be0276ec05c9b03a47573ad9795095a" category="inline-link-macro-rx"></block></block>
  <block id="13148717f8faa9037f37d28971dfc219" category="doc">Convalida</block>
  <block id="286c0d2f200233e63709210881b700c4" category="paragraph">Per convalidare l'architettura multi-tenant configurata nei passaggi precedenti, attenersi alla seguente procedura:</block>
  <block id="627fd2c5e0310dc7409ea377e5d13045" category="section-title">Convalidare l'accesso per creare PVC o pod nel progetto assegnato</block>
  <block id="f4da6475fc7e97756adf2751840e077d" category="list-text">Accedi come ocp-project-1-user, Developer in project-1.</block>
  <block id="2d7fbbcee3114769610fea6ef6f4cdf0" category="list-text">Controllare l'accesso per creare un nuovo progetto.</block>
  <block id="12cdc5f68c3a0ca10544c0a57e866249" category="list-text">Creare un PVC nel progetto 1 utilizzando lo storageclass assegnato al progetto 1.</block>
  <block id="145d2249af633a497182f76e714d1f2e" category="list-text">Controllare il PV associato al PVC.</block>
  <block id="d424ec829e7a6f56de4d74835b97103a" category="list-text">Convalida che il PV e il suo volume siano creati in una SVM dedicata al progetto 1 su NetApp ONTAP.</block>
  <block id="a345b6be662b316a3b3e3cfbc7566b31" category="list-text">Creare un pod nel progetto 1 e montare il PVC creato nel passaggio precedente.</block>
  <block id="7b929f9e235c85c6b73ed2ee867c5514" category="list-text">Verificare che il pod sia in funzione e che il volume sia stato montato.</block>
  <block id="8c9885c86a67cc4c47a30d7e8d14badb" category="section-title">Convalidare l'accesso per creare PVC o pod in un altro progetto o utilizzare risorse dedicate a un altro progetto</block>
  <block id="8e27501b578972bd7b65468deaa482ca" category="list-text">Creare un PVC nel progetto 1 utilizzando lo storageclass assegnato al progetto 2.</block>
  <block id="71bc5a6f1f0141981e0034b388233917" category="list-text">Creare un PVC nel progetto 2.</block>
  <block id="1149bf04288dfa82d0e3b713a6e66aa1" category="list-text">Assicurarsi che i PVC<block ref="1ff946dbad16e896f78812f54d491d28" prefix=" " category="inline-code"></block> e.<block ref="146dc2badf14b242d7e386acd7f9b2aa" prefix=" " category="inline-code"></block> non sono stati creati.</block>
  <block id="0d843e91c3b8f62457e19b2d32ecace3" category="list-text">Creare un pod nel progetto 2.</block>
  <block id="83aa0a39007c30e71adde6fbf8180d9f" category="section-title">Convalida l'accesso per visualizzare e modificare progetti, ResourceQuotas e StorageClasses</block>
  <block id="43700888cdcd166f379f95bd1751ae63" category="list-text">Controllare l'accesso per creare nuovi progetti.</block>
  <block id="32579947c29f341292c3ce775140178b" category="list-text">Convalidare l'accesso per visualizzare i progetti.</block>
  <block id="9e97a1398bb4a0499bb69bf1c9e67d6a" category="list-text">Verificare se l'utente può visualizzare o modificare ResourceQuotas nel progetto-1.</block>
  <block id="17a658c4329ed475a82d2e02c0406118" category="list-text">Verificare che l'utente abbia accesso per visualizzare gli storageclasses.</block>
  <block id="aa177e49bfc4cc0182f57218ce6bdd4d" category="list-text">Controllare l'accesso per descrivere i magazzini.</block>
  <block id="997cef2cfb8ccc12d8739c63e69794f3" category="list-text">Convalidare l'accesso dell'utente per modificare gli storageclasses.</block>
  <block id="9eb6f7c0e27dd8274a30b43a4aee8d53" category="inline-link-macro">Avanti: Scalabilità.</block>
  <block id="acd8a990c476bd6cb45a9044361ba723" category="paragraph"><block ref="acd8a990c476bd6cb45a9044361ba723" category="inline-link-macro-rx"></block></block>
  <block id="eeaa3ef2816f113fd1978b036eefc4a4" category="doc">Convalida della soluzione e casi d'utilizzo: Red Hat OpenShift con NetApp</block>
  <block id="9e766e668731b912ea84be747f0d6b4b" category="paragraph">Gli esempi forniti in questa pagina sono validazioni di soluzioni e casi di utilizzo per Red Hat OpenShift con NetApp.</block>
  <block id="6f60a8e202d6d4f297230695ffa9c1a6" category="inline-link-macro">Implementare una pipeline ci/CD Jenkins con storage persistente</block>
  <block id="20b131c747c2ab8c4c617107b04dfe76" category="list-text"><block ref="20b131c747c2ab8c4c617107b04dfe76" category="inline-link-macro-rx"></block></block>
  <block id="e85b6a5686bf01c916e1c3b442e8db44" category="inline-link-macro">Configura la multitenancy su Red Hat OpenShift con NetApp</block>
  <block id="29a3155f4e27ac61f0e6d1e00866c981" category="list-text"><block ref="29a3155f4e27ac61f0e6d1e00866c981" category="inline-link-macro-rx"></block></block>
  <block id="65cd53ff19e601ea00bf9688be4dd86a" category="inline-link-macro">Virtualizzazione Red Hat OpenShift con NetApp ONTAP</block>
  <block id="781cf19a6329e508987456098cde8c79" category="list-text"><block ref="781cf19a6329e508987456098cde8c79" category="inline-link-macro-rx"></block></block>
  <block id="ddb9608f0f25d56d00a539a63333efa0" category="list-text"><block ref="ddb9608f0f25d56d00a539a63333efa0" category="inline-link-macro-rx"></block></block>
  <block id="9480fd8950471a46e6b29b165ba7ae41" category="summary">NetApp Astra Control Center offre un'ampia gamma di servizi di gestione dei dati application-aware e storage per carichi di lavoro Kubernetes stateful, implementati in un ambiente on-premise, basati sulla tecnologia di protezione dei dati di NetApp.</block>
  <block id="3d210170d7f07fe3c907e8ac619f003a" category="doc">Panoramica di NetApp Astra Control Center</block>
  <block id="f0358bd53d50b55aa0509189dd381ca9" category="paragraph">È possibile installare NetApp Astra Control Center su un cluster Red Hat OpenShift che dispone di Astra Trident Storage orchestrator implementato e configurato con classi di storage e backend di storage per i sistemi storage NetApp ONTAP.</block>
  <block id="1c2ddd920580e1a7860afb96d7ac352e" category="paragraph">Per l'installazione e la configurazione di Astra Trident per il supporto di Astra Control Center, vedere <block ref="a581b27b235a239b8b186164c4dbebd1" category="inline-link-macro-rx"></block>.</block>
  <block id="83d307afe7b187cee5d096f65402182f" category="paragraph">Per iniziare a utilizzare NetApp Astra Control Center, visita il <block ref="230f9d60eb4e7cc8be41a0e702c37eff" category="inline-link-macro-rx"></block>.</block>
  <block id="7f9648de128837be473a3b24e53ff823" category="section-title">Prerequisiti per l'installazione di Astra Control Center</block>
  <block id="8ffc0d45ec909884b280603fd2556021" category="list-text">Uno o più cluster Red Hat OpenShift. Le versioni 4.6 EUS e 4.7 sono attualmente supportate.</block>
  <block id="526a5a0f546838d61791ded926113f71" category="list-text">Astra Trident deve essere già installato e configurato su ogni cluster Red Hat OpenShift.</block>
  <block id="e7a6c3c568d213db46836511343c4965" category="list-text">Uno o più sistemi storage NetApp ONTAP con ONTAP 9.5 o superiore.</block>
  <block id="7433dd0f15704f71764248a0ca105fad" category="admonition">Per ogni installazione di OpenShift in un sito è consigliabile disporre di una SVM dedicata per lo storage persistente. Le implementazioni multi-sito richiedono sistemi storage aggiuntivi.</block>
  <block id="c927c560df09d5ca001f99cd07b14700" category="list-text">È necessario configurare un backend di storage Trident su ciascun cluster OpenShift con una SVM supportata da un cluster ONTAP.</block>
  <block id="67a56d728807272d2a01df50c6548f4f" category="list-text">StorageClass predefinita configurata su ciascun cluster OpenShift con Astra Trident come storage provisioning.</block>
  <block id="dda5c1363ac68168c83f72fc2645f51f" category="list-text">È necessario installare e configurare un bilanciamento del carico su ciascun cluster OpenShift per il bilanciamento del carico e l'esposizione dei servizi OpenShift.</block>
  <block id="e32d2cb3312c2c7797ca52bd8d6ff26f" category="admonition">Vedere il link <block ref="0065297854ca0573913043e80b99a2d1" category="inline-link-macro-rx"></block> per informazioni sui bilanciatori di carico validati per questo scopo.</block>
  <block id="7dbcc72cc3a693b8f89b064e38ed7a23" category="list-text">È necessario configurare un registro di immagini privato per ospitare le immagini di NetApp Astra Control Center.</block>
  <block id="aa32c16385a1b749687956188e4f0d9a" category="admonition">Vedere il link <block ref="9d2000c3bba4885fe5f36ed192264583" category="inline-link-macro-rx"></block> Per installare e configurare un registro privato OpenShift a tale scopo.</block>
  <block id="3123a26626e19f387157faf3a8e35e86" category="list-text">È necessario disporre dell'accesso Cluster Admin al cluster Red Hat OpenShift.</block>
  <block id="537f97bbcef0e2e67d6840aa5845aa65" category="list-text">È necessario disporre dell'accesso come amministratore ai cluster NetApp ONTAP.</block>
  <block id="0507b40de1fbd59b7a77b9054689e92b" category="list-text">Una workstation di amministrazione con i tool docker o podman, tridentctl e oc o kubectl installati e aggiunti al percorso dei dollari.</block>
  <block id="abfe00e88b26a267771078e0295b1573" category="admonition">Le installazioni di Docker devono avere una versione di Docker superiore alla 20.10 e le installazioni di Podman devono avere una versione di podman superiore alla 3.0.</block>
  <block id="8c7c70cb991e0295e289054b79308c5d" category="section-title">Installare Astra Control Center</block>
  <block id="1e90637438eb06672159d2998d220e86" category="open-title">Utilizzo di OperatorHub</block>
  <block id="bff0144772c74d96da07b6ccefb79f96" category="list-text">Accedere al NetApp Support Site e scaricare l'ultima versione di NetApp Astra Control Center. Per farlo, è necessaria una licenza allegata al tuo account NetApp. Dopo aver scaricato il tarball, trasferirlo sulla workstation di amministrazione.</block>
  <block id="121c2592ea226f655d357a8ecd8caf2e" category="inline-link">Sito di registrazione Astra</block>
  <block id="ba6df9237a2774d7ca28cdf134cf9314" category="admonition">Per iniziare a utilizzare una licenza di prova per Astra Control, visitare il sito<block ref="dd61f8f3fbfa8ca8b0a268b985d55b0e" category="inline-link-rx"></block>.</block>
  <block id="ccab5cf8842d06d8d4e2f7f778657c4b" category="list-text">Disimballare il tar ball e modificare la directory di lavoro nella cartella risultante.</block>
  <block id="baac643870c95006b4243d078606a15d" category="list-text">Prima di iniziare l'installazione, trasferire le immagini di Astra Control Center in un registro di immagini. Puoi scegliere di farlo con Docker o Podman; in questo passaggio vengono fornite le istruzioni per entrambi.</block>
  <block id="455cbd59356abfa16dcf7666d4ae6c2b" category="list-title">Podman</block>
  <block id="e83d8437c3befea11906e730883605bf" category="list-text">Esportare ‘reFQDN del Registro di sistema con il nome dell'organizzazione/namespace/progetto come variabile di ambiente 'gistry'.</block>
  <block id="9acf317cba8637e151b8daae04e3e998" category="list-text">Accedere al Registro di sistema.</block>
  <block id="e2f745ac603721ed9903b0acea00d059" category="admonition">Se si utilizza<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> utente per accedere al registro privato, quindi utilizzare il token invece della password -<block ref="7d7ac4e834205786dd5590244b8666d4" prefix=" " category="inline-code"></block>.</block>
  <block id="e4b91f5b748fa6ef8813d2871257b134" category="admonition">In alternativa, è possibile creare un account di servizio, assegnare un ruolo di editor del Registro di sistema e/o di visualizzatore del Registro di sistema (a seconda che si richieda l'accesso push/pull) e accedere al Registro di sistema utilizzando il token dell'account di servizio.</block>
  <block id="a53846d7be2355a59af69a47e2cf4637" category="list-text">Creare un file script della shell e incollarne il contenuto seguente.</block>
  <block id="d5ca81c242aff843ea151d778578cbfc" category="admonition">Se si utilizzano certificati non attendibili per il Registro di sistema, modificare lo script della shell e utilizzare<block ref="0f5007fcae9fe13c2bbe7c6669b72178" prefix=" " category="inline-code"></block> per il comando podman push<block ref="fec4f991fbdc39b7083cbf10fdc5cd9d" prefix=" " category="inline-code"></block>.</block>
  <block id="326c4e96ff06709dede5c03038f00e78" category="list-text">Rendere il file eseguibile.</block>
  <block id="ed85c18933b4b240788294af279f8624" category="list-text">Eseguire lo script della shell.</block>
  <block id="c5fd214cdd0d2b3b4272e73b022ba5c2" category="list-title">Docker</block>
  <block id="ad533c54cadd80fbf8f60e58b7d3abd6" category="admonition">Se si utilizza<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> utente per accedere al registro privato, quindi utilizzare il token invece della password -<block ref="4c3c383f59a35199b206c06cf64ebc7c" prefix=" " category="inline-code"></block>.</block>
  <block id="ee9b41d8a22021826def077c661525f4" category="list-text">Quando si utilizzano registri di immagini private non pubblicamente attendibili, caricare i certificati TLS del registro di immagini nei nodi OpenShift. A tale scopo, creare una configurazione nello spazio dei nomi openshift-config utilizzando i certificati TLS e applicarla alla configurazione dell'immagine del cluster per rendere attendibile il certificato.</block>
  <block id="508ca0ca5ae419c052d9a8487bb0b2d0" category="admonition">Se si utilizza un registro interno di OpenShift con certificati TLS predefiniti dall'operatore di ingresso con un percorso, è comunque necessario seguire la procedura precedente per applicare la patch ai certificati con il nome host del percorso. Per estrarre i certificati dall'operatore di ingresso, è possibile utilizzare il comando<block ref="f3181390f5ac7b194eebf3ad3042d2f7" prefix=" " category="inline-code"></block>.</block>
  <block id="9c656c969a87783fcf4b94b721f34bc9" category="list-text">Creare uno spazio dei nomi<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> Per Astra Control Center.</block>
  <block id="e3990b0b892faaf03261a0a1bcd00b9b" category="list-text">Creare un segreto con le credenziali per accedere al registro delle immagini in<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> namespace.</block>
  <block id="788e8355bdd3a21f3a9017a0610940f4" category="list-text">Accedi alla console GUI di Red Hat OpenShift con accesso cluster-admin.</block>
  <block id="3f4b86cf3e8a535371d3937bd126d789" category="list-text">Selezionare Administrator (Amministratore) dal menu a discesa Perspective (prospettiva).</block>
  <block id="3d68b5654b778f026ac691bc6ed70cc5" category="list-text">Accedere a Operator &gt; OperatorHub e cercare Astra.</block>
  <block id="78146e6a44100deebbe276c19e6c437a" category="image-alt">OpenShift Operator Hub</block>
  <block id="dc7add750562c445f72d8d016a79ae29" category="list-text">Selezionare<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> affiancare e fare clic su<block ref="349838fb1d851d3e2014b9fe39203275" prefix=" " category="inline-code"></block>.</block>
  <block id="c80be3093b470ca8092538e58a261952" category="image-alt">Tessera operatore ACC</block>
  <block id="c65c283737dc37cea2358a91588ff272" category="list-text">Nella schermata Install Operator (Installa operatore), accettare tutti i parametri predefiniti e fare clic su<block ref="349838fb1d851d3e2014b9fe39203275" prefix=" " category="inline-code"></block>.</block>
  <block id="3677d31e24a1853c961f3f1a9a39a1d6" category="image-alt">Dettagli operatore ACC</block>
  <block id="11458c333e4903e54ca46f822ba6a3b6" category="list-text">Attendere il completamento dell'installazione da parte dell'operatore.</block>
  <block id="ba14525c4ccc9b2f692d062104885b19" category="image-alt">L'operatore ACC attende l'installazione</block>
  <block id="fea3120ff933c367a5882d58dbbe8a08" category="list-text">Una volta completata l'installazione dell'operatore, selezionare per fare clic su<block ref="6423332325de5a7100cc070ffad7a372" prefix=" " category="inline-code"></block>.</block>
  <block id="a573acc0621ea72a06ce987a341768bf" category="image-alt">Installazione dell'operatore ACC completata</block>
  <block id="f99196bf6b988223fab800f28cf0323c" category="list-text">Quindi fare clic su<block ref="43f8527e733785e2ca7a92853d30e4f7" prefix=" " category="inline-code"></block> Nel riquadro Astra Control Center dell'operatore.</block>
  <block id="11f7c569d04eecd142ba5989efcc2da3" category="image-alt">Creare un'istanza ACC</block>
  <block id="02780e148f03f25db76204c23985d753" category="list-text">Riempire<block ref="9eca463036a902158489237df8eb93bf" prefix=" " category="inline-code"></block> campi del modulo e fare clic su<block ref="686e697538050e4664636337cc3b834f" prefix=" " category="inline-code"></block>.</block>
  <block id="e31f3b85c5179d88bcf0629842c5342f" category="list-text">Se si desidera, modificare il nome dell'istanza di Astra Control Center.</block>
  <block id="3336a2124154da151aecfe1809d7c821" category="list-text">Se si desidera, attivare o disattivare il supporto automatico. Si consiglia di mantenere la funzionalità di supporto automatico.</block>
  <block id="14ddbb7fd85c2907073b06492b95191b" category="list-text">Inserire il nome FQDN per Astra Control Center.</block>
  <block id="fbcd656fecc902b1994e346dc0627266" category="list-text">Inserire la versione di Astra Control Center; per impostazione predefinita viene visualizzata la versione più recente.</block>
  <block id="311a20c50b8e2d72cf9b31eb6339bff4" category="list-text">Inserisci un nome account per Astra Control Center e i dettagli dell'amministratore come nome, cognome e indirizzo e-mail.</block>
  <block id="163e6534daeb1cbd7c56b20a9477802f" category="list-text">Inserire il criterio di recupero del volume, l'impostazione predefinita è Mantieni.</block>
  <block id="5863d7f52b409374d0d80b1bcbba68fd" category="list-text">In Image Registry (Registro immagini), immettere l'FQDN del registro insieme al nome dell'organizzazione assegnato durante l'invio delle immagini al registro (in questo esempio,<block ref="6bde403d563a0c848b35e178652a7a84" prefix=" " category="inline-code"></block>)</block>
  <block id="95279718d2829cd5ed7772d6f0a77ca9" category="list-text">Se si utilizza un registro che richiede l'autenticazione, inserire il nome segreto nella sezione Registro immagini.</block>
  <block id="b8f9ae819a2d6559f55aed837fdc2a47" category="list-text">Configurare le opzioni di scalabilità per i limiti delle risorse di Astra Control Center.</block>
  <block id="3b489b9fd690a8cdf710454d0ccb5288" category="list-text">Inserire il nome della classe di storage se si desidera inserire PVC in una classe di storage non predefinita.</block>
  <block id="6b9265a82fa5bd326052ec55e040a54a" category="list-text">Definire le preferenze di gestione CRD.</block>
  <block id="90aa5928482975bc6ff56f0eaf052451" category="open-title">Automatizzato [Ansible]</block>
  <block id="c9e4df26177106ff846782e8ee98f56a" category="list-text">Per utilizzare i playbook Ansible per implementare Astra Control Center, è necessaria una macchina Ubuntu/RHEL con Ansible installato. Seguire le procedure<block ref="33c646d34972887e04f4f11763cd42b6" category="inline-link-rx"></block> Per Ubuntu e RHEL.</block>
  <block id="b8571b33af3335fed61ab0d7985d007f" category="list-text">Clonare il repository GitHub che ospita il contenuto Ansible.</block>
  <block id="703fd9e283392bf196948a4c2ed72680" category="list-text">Accedi al sito NetApp Support e scarica l'ultima versione di NetApp Astra Control Center. Per farlo, è necessaria una licenza allegata al tuo account NetApp. Dopo aver scaricato il tarball, trasferirlo sulla workstation.</block>
  <block id="42042ccfc3ffee97e94beca237148ed4" category="list-text">Creare o ottenere il file kubeconfig con accesso amministratore al cluster OpenShift su cui deve essere installato Astra Control Center.</block>
  <block id="b736c713f352ab43e7543fda4589e96f" category="list-text">Modificare la directory in na_astra_control_suite.</block>
  <block id="aff7b433e7f33e585c67f69803192117" category="list-text">Modificare il<block ref="014d194d817c312b5ce910e74b4d3836" prefix=" " category="inline-code"></block> e inserire le variabili con le informazioni richieste.</block>
  <block id="cfcf9f0f05f9790927b65e14214edc6e" category="list-text">Esegui il manuale per implementare Astra Control Center. Il playbook richiede privilegi root per alcune configurazioni.</block>
  <block id="3c0e37ba6fc2025cda3b9ec88b955aab" category="paragraph">Se l'utente che esegue il playbook è root o ha configurato sudo senza password, eseguire il seguente comando per eseguire il playbook.</block>
  <block id="b4ca5df207a7b1e22a2f19cac43dd6ad" category="paragraph">Se l'utente ha configurato l'accesso sudo basato su password, eseguire il seguente comando per eseguire il manuale, quindi inserire la password sudo.</block>
  <block id="8d1e5f9175948d3e6f932794744cde16" category="section-title">Fasi successive all'installazione</block>
  <block id="e3cd33ca69b8e508c973939783f528db" category="list-text">Il completamento dell'installazione potrebbe richiedere alcuni minuti. Verificare che tutti i pod e i servizi in<block ref="cde5355ebfdfe468e0d3516b20d95313" prefix=" " category="inline-code"></block> namespace in esecuzione.</block>
  <block id="9904a774f242f31a5ae37c8f75bda92b" category="list-text">Controllare<block ref="83f93b05da174976bd534cc67ad9f7b4" prefix=" " category="inline-code"></block> registri per garantire che l'installazione sia completata.</block>
  <block id="4af39dbe40f8a0467bbdd739a971f0ea" category="admonition">Il seguente messaggio indica la corretta installazione di Astra Control Center.</block>
  <block id="c27deb19babf146e6377dce25b1e70e7" category="list-text">Il nome utente per l'accesso ad Astra Control Center è l'indirizzo e-mail dell'amministratore fornito nel file CRD e la password è una stringa<block ref="4e68cdd4eb0ff1a79e44dac42b52abd8" prefix=" " category="inline-code"></block> Aggiunto all'UUID di Astra Control Center. Eseguire il seguente comando:</block>
  <block id="57a7aa2eaf00ddaa73ef6b49299ade6e" category="admonition">In questo esempio, la password è<block ref="bf7a8daff076079f839129b59f2bb759" prefix=" " category="inline-code"></block>.</block>
  <block id="5946314197ad84982efa6561d9da8302" category="list-text">Ottieni l'IP del bilanciamento del carico del servizio traefik.</block>
  <block id="298a1e8781e536e60684ab1700c60962" category="list-text">Aggiungere una voce nel server DNS che punta all'FQDN fornito nel file CRD di Astra Control Center<block ref="23edb0469b69e61c98ac7a9e1dca82e8" prefix=" " category="inline-code"></block> del servizio traefik.</block>
  <block id="0c64767e085896708adcbcc1c32c55fe" category="inline-image-macro">Aggiungi voce DNS per GUI ACC</block>
  <block id="1c278e58c0255ae1f09fc4fa520160b6" category="paragraph"><block ref="1c278e58c0255ae1f09fc4fa520160b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f436b7e192eae471d7abf1265bb4c02" category="list-text">Accedere alla GUI di Astra Control Center esplorando il relativo FQDN.</block>
  <block id="cc2ba6bb5620162b64bafdca9f089718" category="inline-image-macro">Accesso ad Astra Control Center</block>
  <block id="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="paragraph"><block ref="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19bae630567610f1955167595b8daae3" category="list-text">Quando si accede all'interfaccia grafica di Astra Control Center per la prima volta utilizzando l'indirizzo email admin fornito in CRD, è necessario modificare la password.</block>
  <block id="90fbead2d113af1a2680805778908d98" category="inline-image-macro">Modifica obbligatoria della password di Astra Control Center</block>
  <block id="247e9fd0170ec4d9550de59ebd54787b" category="paragraph"><block ref="247e9fd0170ec4d9550de59ebd54787b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c62383e1115b208212b5a634214ae37" category="list-text">Se si desidera aggiungere un utente ad Astra Control Center, accedere a account &gt; Users (account &gt; utenti), fare clic su Add (Aggiungi), inserire i dettagli dell'utente e fare clic su Add (Aggiungi).</block>
  <block id="0dd5915bd7ca0f5d34df18bf7a183d50" category="inline-image-macro">Astra Control Center crea un utente</block>
  <block id="0ea309ed2f56bdc52dd6184b9043e683" category="paragraph"><block ref="0ea309ed2f56bdc52dd6184b9043e683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a37ba7c36c036650f5e1e7ded5232245" category="list-text">Astra Control Center richiede una licenza per il funzionamento di tutte le funzionalità IT. Per aggiungere una licenza, accedere a account &gt; License (account &gt; licenza), fare clic su Add License (Aggiungi licenza) e caricare il file di licenza.</block>
  <block id="54936e9fda3da1e56a25c0056f054bce" category="inline-image-macro">Astra Control Center aggiunge licenza</block>
  <block id="02fd0244de299d20dfbaf9113b883030" category="paragraph"><block ref="02fd0244de299d20dfbaf9113b883030" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2044ecf5033cd4a7b9530b83075af99e" category="admonition">In caso di problemi con l'installazione o la configurazione di NetApp Astra Control Center, è disponibile la knowledge base dei problemi noti<block ref="d775d2705bd260971e4d33c3d1094402" category="inline-link-rx"></block>.</block>
  <block id="9204faa817ce36107d052d3cd7c886c7" category="inline-link-macro">Pagina successiva: Registrate Red Hat OpenShift Clusters: Red Hat OpenShift con NetApp.</block>
  <block id="8d167505bef11e381036abf56e79f457" category="paragraph"><block ref="8d167505bef11e381036abf56e79f457" category="inline-link-macro-rx"></block></block>
  <block id="3fc5f6755312b7edeef9542bd55ef639" category="section-title">Governance e rischi</block>
  <block id="9d7264067197bc9ff368288f98750fd6" category="paragraph">Questa funzionalità consente di definire le policy di conformità per diversi cluster e di assicurarsi che i cluster aderiscano ad esso. È possibile configurare le policy per informare o correggere eventuali deviazioni o violazioni delle regole.</block>
  <block id="87f4e127e0ecf99187b35830ca7e78aa" category="list-text">Accedere a Governance and Risk (Governance e rischi) dalla barra laterale.</block>
  <block id="0ecc505d3375f8bb3bd959aaaf7e710a" category="list-text">Per creare policy di compliance, fare clic su Create Policy (Crea policy), inserire i dettagli degli standard dei policy e selezionare i cluster che devono aderire a tali policy. Se si desidera correggere automaticamente le violazioni di questa policy, selezionare la casella di controllo Applica se supportato e fare clic su Crea.</block>
  <block id="f6262e5369e2b989638aaa9d4f333d91" category="image-alt">Creare policy di compliance</block>
  <block id="0a1575621f2b12d5216e6d1c95eed2e6" category="list-text">Dopo aver configurato tutti i criteri richiesti, è possibile monitorare e correggere eventuali violazioni di policy o cluster da Advanced Cluster Management.</block>
  <block id="38c080ff2128a92954fb61942ea497c0" category="image-alt">Monitoraggio delle policy</block>
  <block id="465d1c9d2d9ea711e43e2e20077e10f9" category="inline-link-macro">Avanti: Caratteristiche - osservabilità.</block>
  <block id="056789fad8ccaddf0ac3b4ef0a68b61a" category="paragraph"><block ref="056789fad8ccaddf0ac3b4ef0a68b61a" category="inline-link-macro-rx"></block></block>
  <block id="5e217c79c499978721e658f868053d3f" category="inline-link-macro">Pagina successiva: Ulteriori informazioni: Red Hat OpenShift con NetApp.</block>
  <block id="d2fb587a433995783f0688b22359272d" category="paragraph"><block ref="d2fb587a433995783f0688b22359272d" category="inline-link-macro-rx"></block></block>
  <block id="e38be1dc20a2b358b917b60fe2677b39" category="doc">Configurazione iSCSI NetApp Element</block>
  <block id="dc5fa659e0452a77d6006f5b72f8b334" category="paragraph">Per abilitare l'integrazione di Trident con il sistema storage NetApp Element, è necessario creare un backend che consenta la comunicazione con il sistema storage utilizzando il protocollo iSCSI.</block>
  <block id="05ca7295321cb9b417a251e75557c6c5" category="list-text">Nell'archivio di installazione scaricato in sono disponibili file backend di esempio<block ref="75e4a0ceb294a9d74374c938e4e8ddc8" prefix=" " category="inline-code"></block> gerarchia di cartelle. Per i sistemi NetApp Element che utilizzano iSCSI, copiare<block ref="7989420add0b5baae954e866987ef264" prefix=" " category="inline-code"></block> nella directory di lavoro e modificare il file.</block>
  <block id="27ef1192cd037c8978195be045fa054e" category="list-text">Modificare i valori di utente, password e MVIP su<block ref="b7ae24ea48e61624a7e4078daa60bd78" prefix=" " category="inline-code"></block> linea.</block>
  <block id="d1b7418d19df7144a98dfde725db068c" category="list-text">Modificare il<block ref="dcda39e13b00bf6bd40a507e1833a6f5" prefix=" " category="inline-code"></block> valore.</block>
  <block id="dd7f72325e6f60ea7163b071e4d5e2cc" category="list-text">Una volta creato questo file back-end, eseguire il seguente comando per creare il primo backend.</block>
  <block id="d8f188eff4c16fa87dd87f51db847f73" category="list-text">Una volta creato il backend, è necessario creare una classe di storage. Come per il backend, esiste un file di esempio della classe di storage che può essere modificato per l'ambiente disponibile nella cartella di input di esempio. Copiarlo nella directory di lavoro e apportare le modifiche necessarie per riflettere il backend creato.</block>
  <block id="eb22c0d536e50f388da6dfd91ba4c0b6" category="list-text">L'unica modifica che deve essere apportata a questo file è definire<block ref="55b56fb238360663afa6230ad82e74a0" prefix=" " category="inline-code"></block> valore al nome del driver di storage dal backend appena creato. Annotare anche il valore del campo nome, a cui si deve fare riferimento in un passaggio successivo.</block>
  <block id="b73d05719d0ea2964c963f6f83a34d3d" category="admonition">Esiste un campo opzionale chiamato<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> definito in questo file. Nei backend iSCSI, questo valore può essere impostato su un tipo di filesystem Linux specifico (XFS, ext4 e così via), oppure può essere cancellato per consentire a OpenShift di decidere quale filesystem usare.</block>
  <block id="7183f006fd74d941c838f003380f3f46" category="list-text">Eseguire<block ref="fb024832e51eb5f6da9113a745f1eb59" prefix=" " category="inline-code"></block> per creare la classe di storage.</block>
  <block id="71cb54ab06aa16af27a0ec2157972648" category="list-text">Una volta creata la classe di storage, è necessario creare la prima dichiarazione di volume persistente (PVC). C'è un esempio<block ref="a46b72c0e3ff39640d78567a663da1aa" prefix=" " category="inline-code"></block> file che può essere utilizzato per eseguire questa azione, disponibile anche in input di esempio.</block>
  <block id="afc499f2f95809cedce5c8922067065f" category="list-text">L'unica modifica che deve essere apportata a questo file è garantire che il<block ref="ee822781a3bd0ae0f8f6331dc4865d9c" prefix=" " category="inline-code"></block> il campo corrisponde a quello appena creato. La definizione PVC può essere ulteriormente personalizzata in base alle esigenze del carico di lavoro da fornire.</block>
  <block id="02eb9c3824b0b8eae9723daa7a2912d1" category="list-text">Creare il PVC emettendo il<block ref="fb024832e51eb5f6da9113a745f1eb59" prefix=" " category="inline-code"></block> comando. La creazione può richiedere del tempo a seconda delle dimensioni del volume di backup da creare, in modo da poter guardare il processo mentre viene completato.</block>
  <block id="90dc29cb8c225faef816aefeaad3027d" category="inline-link-macro">Successivo: Validazione della soluzione/casi d'utilizzo.</block>
  <block id="99632a9c8a0d8380e77d9d11f96edfdc" category="paragraph"><block ref="99632a9c8a0d8380e77d9d11f96edfdc" category="inline-link-macro-rx"></block></block>
  <block id="501195b19cb60bfec4c2e4899a2a460c" category="summary">Dopo aver registrato i cluster Red Hat OpenShift, è possibile individuare le applicazioni implementate e gestirle tramite Astra Control Center.</block>
  <block id="d19de154f02438c6d6918a4e016c7c62" category="doc">Scegliere le applicazioni da proteggere</block>
  <block id="a022d74e2b8b62dd9f1caa37a51aa3f3" category="section-title">Gestire le applicazioni</block>
  <block id="d8c780951f3271e7d72b116e5f41d46b" category="list-text">Una volta registrati i cluster OpenShift e i backend ONTAP con il centro di controllo Astra, il centro di controllo inizia automaticamente a rilevare le applicazioni in tutti gli spazi dei nomi che utilizzano lo storageclass configurato con il backend ONTAP specificato.</block>
  <block id="3b5963749d054f288f27dfb2f20d0370" category="inline-image-macro">Applicazioni di Astra Control Center rilevate</block>
  <block id="a78e618a70881e5c5dda311aaa61c250" category="paragraph"><block ref="a78e618a70881e5c5dda311aaa61c250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c46442de8c982973aeee99a9441b746" category="list-text">Accedere a Apps &gt; Dovered (applicazioni &gt; rilevate) e fare clic sul menu a discesa accanto all'applicazione che si desidera gestire utilizzando Astra. Quindi fare clic su Manage (Gestisci)</block>
  <block id="22d84cdf10d4c1059d68b1ab7da5b375" category="inline-image-macro">Astra Control Center gestisce le applicazioni</block>
  <block id="4afca1ab36db499d54b08ff38dff8a5c" category="paragraph"><block ref="4afca1ab36db499d54b08ff38dff8a5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d694cfe5907a4790ea939388a8cfd25" category="list-text">L'applicazione entra nello stato Available (disponibile) e può essere visualizzata nella scheda Managed (gestito) nella sezione Apps (applicazioni).</block>
  <block id="dc496d6799e0c6ab3bdfdbdc6a086b48" category="inline-image-macro">Applicazioni disponibili per Astra Control Center</block>
  <block id="872adedc4ac847cec0aa8fb9299d32e5" category="paragraph"><block ref="872adedc4ac847cec0aa8fb9299d32e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2c2a82496277a88b32b0e8d27249d3d" category="inline-link-macro">Avanti: Proteggi le tue applicazioni.</block>
  <block id="d5be948b8a7fea6618eb171c64927be2" category="paragraph"><block ref="d5be948b8a7fea6618eb171c64927be2" category="inline-link-macro-rx"></block></block>
  <block id="ad3a2e9007d848afd0c15ffc402781bb" category="doc">Workflow: Virtualizzazione Red Hat OpenShift con NetApp ONTAP</block>
  <block id="4e42a1e911325b5048e50f7b5ea73d1f" category="section-title">Migrazione VM Live</block>
  <block id="7df52e0f8b2cb2af1e107fde51d06945" category="paragraph">Live Migration è un processo di migrazione di un'istanza di macchina virtuale da un nodo all'altro in un cluster OpenShift senza downtime. Affinché la migrazione live funzioni in un cluster OpenShift, le macchine virtuali devono essere associate a PVC con modalità di accesso condivisa ReadWriteMany. Il backend Astra Trident configurato con una SVM su un cluster NetApp ONTAP abilitato per il protocollo NFS supporta l'accesso ReadWriteMany condiviso per i PVC. Pertanto, le macchine virtuali con PVC richieste da StorageClasses fornite da Trident da SVM abilitato NFS possono essere migrate senza downtime.</block>
  <block id="09e113cd46b4487f140ee07899ea3359" category="image-alt">Architettura VM Live Migration</block>
  <block id="660b7fa756d01df7c4338afb9050abb1" category="paragraph">Per creare una macchina virtuale associata a PVC con accesso condiviso ReadWriteMany:</block>
  <block id="842f7d4793f116332f5b12b648dfd539" category="list-text">Accedere a workload &gt; virtualizzazione &gt; macchine virtuali e fare clic su Crea &gt; con Wizard.</block>
  <block id="416d6e9d0df33a74dd38603be60453c1" category="list-text">Selezionare il sistema operativo desiderato e fare clic su Next (Avanti). Supponiamo che il sistema operativo selezionato abbia già configurato una fonte di avvio.</block>
  <block id="e1b595d3037639bdea165dde4b1f3906" category="list-text">Nel riquadro Review and Create (Revisione e creazione), selezionare il progetto in cui si desidera creare la macchina virtuale e fornire i dettagli della macchina virtuale. Assicurarsi che l'origine di boot sia selezionata come Clone (Clona) e boot from CD-ROM (Avvio da CD-ROM) con il PVC appropriato assegnato per il sistema operativo selezionato.</block>
  <block id="998a8df469c318f9cd606b44664cea5d" category="list-text">Fare clic su Customize Virtual Machine (Personalizza macchina virtuale), quindi su Storage (Storage).</block>
  <block id="ae024d48dbfaaf4badad7bf9c812a98f" category="list-text">Fare clic sui puntini di sospensione accanto a rootdisk e assicurarsi che sia selezionato lo storageclass con provisioning mediante Trident. Espandere Advanced (Avanzate) e selezionare Shared Access (RWX) (accesso condiviso) per Access Mode (modalità di accesso). Quindi fare clic su Save (Salva).</block>
  <block id="ef44ba6bf4a3e677b41b361628554b88" category="image-alt">Rendere il disco RWX accessibile</block>
  <block id="2ae6b586f76075c7d71faff7ba9d2a41" category="list-text">Fare clic su Revisiona e conferma, quindi su Crea macchina virtuale.</block>
  <block id="18c830e61a7a92c60804118ef362933c" category="paragraph">Per migrare manualmente una macchina virtuale in un altro nodo del cluster OpenShift, attenersi alla seguente procedura.</block>
  <block id="289f346dbeb0185de2648a24955ca887" category="list-text">Accedere a workload &gt; virtualizzazione &gt; macchine virtuali.</block>
  <block id="cc58a226305ad2362de0317c1fd8261b" category="list-text">Per la macchina virtuale che si desidera migrare, fare clic sui puntini di sospensione, quindi fare clic su Migrate the Virtual Machine (Migra macchina virtuale).</block>
  <block id="b5839595a4132807edfc858d9f6d90ad" category="list-text">Fare clic su Migrate (Migra) quando viene visualizzato il messaggio per confermare.</block>
  <block id="d0f501bd9588700bc91fe10b7d3f761a" category="admonition">Un'istanza della macchina virtuale in un cluster OpenShift esegue automaticamente la migrazione a un altro nodo quando il nodo originale viene messo in modalità di manutenzione se evictionStrategy è impostato su LiveMigrate.</block>
  <block id="ca77161ad6ca11bca347f347b181c25f" category="inline-link-macro">Segue: Workflow: Clonazione di macchine virtuali.</block>
  <block id="294f8e986041208286bb2300b191a2ff" category="paragraph"><block ref="294f8e986041208286bb2300b191a2ff" category="inline-link-macro-rx"></block></block>
  <block id="d10b633b8bd8d022c66a52d93e0ed6ce" category="section-title">Gestione del ciclo di vita del cluster</block>
  <block id="8b9449bdfc859a900fc4da7c79420145" category="paragraph">Per gestire diversi cluster OpenShift, è possibile crearli o importarli in Advanced Cluster Management.</block>
  <block id="0ef06ef8df800cf71fb95c66e0e08f1a" category="list-text">Prima di tutto, automatizza le infrastrutture &gt; Clusters.</block>
  <block id="0becde0fcfda03aec9c722d042326324" category="list-text">Per creare un nuovo cluster OpenShift, attenersi alla seguente procedura:</block>
  <block id="e056bb6efa17796fc810edad8410280d" category="list-text">Creare una connessione al provider: Accedere a connessioni provider e fare clic su Aggiungi una connessione, fornire tutti i dettagli corrispondenti al tipo di provider selezionato e fare clic su Aggiungi.</block>
  <block id="50dfc508091b37338da8357e63e6a405" category="image-alt">Aggiungi connessione provider</block>
  <block id="401b252566122602a82ff66bc7ed3e6c" category="list-text">Per creare un nuovo cluster, accedere a Clusters e fare clic su Add a Cluster (Aggiungi cluster) &gt; Create a Cluster (Crea cluster). Fornire i dettagli del cluster e del provider corrispondente, quindi fare clic su Create (Crea).</block>
  <block id="2984cab36bd51d5446963e671e808f5d" category="image-alt">Aggiungere cluster</block>
  <block id="2da6eeb34cf16de43ab8fa2f939d81c7" category="list-text">Una volta creato, il cluster viene visualizzato nell'elenco dei cluster con lo stato Ready (Pronto).</block>
  <block id="e6d9a6b38dd36fd9870260249ba5fc1f" category="list-text">Per importare un cluster esistente, attenersi alla seguente procedura:</block>
  <block id="f52ae06380cfd00cae7839562f550e87" category="list-text">Accedere a Clusters e fare clic su Add a Cluster (Aggiungi cluster) &gt; Import an Existing Cluster (Importa cluster esistente).</block>
  <block id="63b7276dd1b569babc28304e786e2041" category="list-text">Inserire il nome del cluster e fare clic su Save Import and generate Code (Salva importazione e genera codice). Viene visualizzato un comando per aggiungere il cluster esistente.</block>
  <block id="be87809a27ab2944f89ccaebd89b7596" category="list-text">Fare clic su Copy Command (Copia comando) ed eseguire il comando sul cluster da aggiungere al cluster hub. In questo modo viene avviata l'installazione degli agenti necessari sul cluster e, al termine di questo processo, il cluster viene visualizzato nell'elenco dei cluster con lo stato Ready.</block>
  <block id="9a618414b83afe67c19abcf935be6dbd" category="image-alt">Importare il cluster esistente</block>
  <block id="c812d1382d834648706b3bf1e6848135" category="list-text">Dopo aver creato e importato più cluster, è possibile monitorarli e gestirli da una singola console.</block>
  <block id="068e5ec1cc0eaa7c2596be7eb1b40194" category="inline-link-macro">Avanti: Funzionalità - Gestione del ciclo di vita delle applicazioni.</block>
  <block id="0405bd6ea905b8d563fd501d933a3e51" category="paragraph"><block ref="0405bd6ea905b8d563fd501d933a3e51" category="inline-link-macro-rx"></block></block>
  <block id="ef55276f0238c6b1a3f893bc026b5644" category="summary">Le soluzioni container NetApp sono implementazioni validate di numerosi orchestratori di container basati su Kubernetes e la loro integrazione con i sistemi e il software di gestione dello storage NetApp.</block>
  <block id="d56bc5e4affc2f557b7bb79afe47b1be" category="doc">Soluzioni container NetApp</block>
  <block id="1630dbfdd4887ce201ea82c71cde3d11" category="doc">Implementare Advanced Cluster Management per Kubernetes</block>
  <block id="39d08ecbb9add7bd87659df206457a73" category="list-text">Un cluster Red Hat OpenShift (superiore alla versione 4.5) per il cluster hub</block>
  <block id="f41043c73a62a435944d8abfb45094cb" category="list-text">Cluster Red Hat OpenShift (superiori alla versione 4.4.3) per cluster gestiti</block>
  <block id="d60c66eb778a488709534045787b6a26" category="list-text">Accesso cluster-admin al cluster Red Hat OpenShift</block>
  <block id="374185e020d06ceed3f020af518a1c14" category="list-text">Un abbonamento Red Hat per Advanced Cluster Management per Kubernetes</block>
  <block id="9afcd045ce0197d71ba631e3fbe43095" category="paragraph">Advanced Cluster Management è un add-on per il cluster OpenShift, pertanto esistono determinati requisiti e restrizioni sulle risorse hardware in base alle funzionalità utilizzate nell'hub e nei cluster gestiti. È necessario tenere conto di questi problemi durante il dimensionamento dei cluster. Consultare la documentazione<block ref="a5d2b81b971715f092f7296621743e22" category="inline-link-rx"></block> per ulteriori dettagli.</block>
  <block id="65a62318377ddbc5fe3f73548dc3d677" category="paragraph">Se il cluster hub dispone di nodi dedicati per l'hosting dei componenti dell'infrastruttura e si desidera installare risorse di Advanced Cluster Management solo su tali nodi, è necessario aggiungere di conseguenza tolleranze e selettori a tali nodi. Per ulteriori informazioni, consultare la documentazione<block ref="df4d7b25534e8f26e8ab3acc1c646101" category="inline-link-rx"></block>.</block>
  <block id="3f71071db67a1d6b5b63e2d9cc6b0e93" category="inline-link-macro">Successivo: Installazione.</block>
  <block id="2a9cc50366c16ec40c1a5132f8fe5533" category="paragraph"><block ref="2a9cc50366c16ec40c1a5132f8fe5533" category="inline-link-macro-rx"></block></block>
  <block id="122aacda8785e42ca8fd7bd6ebce84f8" category="summary">VMware vSphere è una piattaforma di virtualizzazione per la gestione centralizzata di un gran numero di server e reti virtualizzati in esecuzione sull'hypervisor ESXi.</block>
  <block id="2772c11e552b243e60a34490c4174ff9" category="doc">OpenShift su VMware vSphere</block>
  <block id="68bc8529d7c57946fe13e6b3399ee287" category="inline-link">Sito Web di VMware vSphere</block>
  <block id="80888e73d00a224bebfc22e8e4539b6d" category="paragraph">Per ulteriori informazioni su VMware vSphere, consultare<block ref="8e822bbeb5824c0a05189bf9ff98da5c" category="inline-link-rx"></block>.</block>
  <block id="cb4d59b9004b7c584811a3d656f78bc5" category="paragraph">VMware vSphere offre le seguenti funzionalità:</block>
  <block id="a542faac65568ba146d392d835d7fb33" category="list-text">*VMware vCenter Server.* VMware vCenter Server offre una gestione unificata di tutti gli host e le macchine virtuali da una singola console e aggrega il monitoraggio delle performance di cluster, host e macchine virtuali.</block>
  <block id="413563ec6c2672beb7df15f465cb4a48" category="list-text">*VMware vSphere vMotion.* VMware vCenter consente di eseguire la migrazione a caldo delle macchine virtuali tra i nodi del cluster, su richiesta e senza interruzioni.</block>
  <block id="e6583703b8777be27f8db85d741711b4" category="list-text">*VSphere High Availability.* per evitare interruzioni in caso di guasti agli host, VMware vSphere consente di eseguire il clustering e la configurazione degli host per l'alta disponibilità. Le macchine virtuali che vengono interrompite da un guasto dell'host vengono riavviati a breve su altri host del cluster, ripristinando i servizi.</block>
  <block id="46b35ead34118cb2c50327c71e4aa640" category="list-text">*Distributed Resource Scheduler (DRS).* Un cluster VMware vSphere può essere configurato per bilanciare il carico delle esigenze di risorse delle macchine virtuali ospitate. È possibile eseguire la migrazione a caldo delle macchine virtuali con risorse in altri nodi del cluster per assicurarsi che siano disponibili risorse sufficienti.</block>
  <block id="cfb123c76f1c7a506310e1162d7ae235" category="paragraph"><block ref="cfb123c76f1c7a506310e1162d7ae235" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c6371faa8d72dee8337811921707a4b" category="paragraph">La soluzione Red Hat OpenShift su NetApp utilizza due switch dati per fornire connettività dati primaria a 25 Gbps. Utilizza inoltre due switch di gestione aggiuntivi che forniscono connettività a 1 Gbps per la gestione in-band dei nodi di storage e gestione out-of-band per la funzionalità IPMI. OCP utilizza la rete logica VM su VMware vSphere per la gestione del cluster. Questa sezione descrive la disposizione e lo scopo di ciascun segmento di rete virtuale utilizzato nella soluzione e illustra i prerequisiti per l'implementazione della soluzione.</block>
  <block id="e75b582a8823d532f6022b43ac209538" category="paragraph">Red Hat OpenShift su VMware vSphere è progettato per separare logicamente il traffico di rete per scopi diversi utilizzando Virtual Local Area Network (VLAN). Questa configurazione può essere scalata per soddisfare le esigenze dei clienti o per fornire un ulteriore isolamento per servizi di rete specifici. La seguente tabella elenca le VLAN necessarie per implementare la soluzione durante la convalida della soluzione in NetApp.</block>
  <block id="fc221309746013ac554571fbd180e1c8" category="cell">181</block>
  <block id="c846a1f843522d592b784a66368abed3" category="cell">Rete di storage per NFS ONTAP</block>
  <block id="6cdd60ea0045eb7a6ec44c54d29ed402" category="cell">184</block>
  <block id="5e6094f6f2176409f469ee445fcf3f50" category="cell">Rete storage per iSCSI ONTAP</block>
  <block id="eecca5b6365d9607ee5a9d336962c534" category="cell">185</block>
  <block id="45cf0331a91fdc3679a78fdd8f7c60a7" category="cell">Gestione per nodi ESXi, server vCenter, ONTAP Select</block>
  <block id="e8e0dd181e4ee545195120626098bfba" category="cell">3480</block>
  <block id="3fb04953d95a94367bb133f862402bce" category="cell">3481</block>
  <block id="b7fede84c2be02ccb9c77107956560eb" category="cell">3482</block>
  <block id="bd690c49b77b8274786240fa94d9d880" category="section-title">Implementare OpenShift in un cluster ESXi di almeno tre nodi</block>
  <block id="3500f2194985ef1b586c649fbe519d8d" category="paragraph">L'architettura verificata descritta in questo documento presenta l'implementazione hardware minima adatta per le operazioni ha implementando due nodi hypervisor ESXi e garantendo una configurazione con tolleranza di errore abilitando VMware vSphere ha e VMware vMotion. Questa configurazione consente alle macchine virtuali implementate di migrare tra i due hypervisor e di riavviare il sistema in caso di mancata disponibilità di un host.</block>
  <block id="e79fa01ec6b411cfda4f8baad9f95cb0" category="paragraph">Poiché Red Hat OpenShift inizialmente viene implementato con tre nodi master, almeno due master in una configurazione a due nodi possono occupare lo stesso nodo in alcune circostanze, il che può causare un'interruzione di OpenShift se quel nodo specifico non è disponibile. Pertanto, è una Best practice di Red Hat che devono essere implementati almeno tre nodi di hypervisor ESXi in modo che i master OpenShift possano essere distribuiti in modo uniforme, fornendo un ulteriore grado di tolleranza agli errori.</block>
  <block id="9dc31e1598f94b9476a025632cee3e19" category="section-title">Configurare l'affinità della macchina virtuale e dell'host</block>
  <block id="f5428382aa8b44d7ef6ca71195afc8ca" category="paragraph">Garantire la distribuzione dei master OpenShift su più nodi hypervisor abilitando l'affinità di macchine virtuali e host.</block>
  <block id="c23c2371397ad3490af42526283948a4" category="paragraph">Affinità o anti-affinità è un metodo per definire le regole per un insieme di macchine virtuali e/o host che determinano se le macchine virtuali vengono eseguite insieme sullo stesso host o su host del gruppo o su host diversi. Viene applicato alle macchine virtuali creando gruppi di affinità costituiti da macchine virtuali e/o host con un insieme di parametri e condizioni identici. A seconda che le macchine virtuali di un gruppo di affinità vengano eseguite sullo stesso host o su host del gruppo o separatamente su host diversi, i parametri del gruppo di affinità possono definire affinità positiva o affinità negativa.</block>
  <block id="9934283c0bf98610b4be1803b9ad3430" category="inline-link">Documentazione vSphere 6.7: Utilizzo delle regole di affinità DRS</block>
  <block id="291f24f63dc31f9f921b09c567fc963f" category="paragraph">Per configurare i gruppi di affinità, vedere<block ref="4b14049244eae7b3d11ef8e44785dd4e" category="inline-link-rx"></block>.</block>
  <block id="5e059b05dcf86db414d6b8cdd66bcf0f" category="paragraph">IPI semplifica l'implementazione dei cluster OpenShift attraverso la procedura guidata interattiva descritta in precedenza in questo documento. Tuttavia, potrebbe essere necessario modificare alcuni valori predefiniti come parte di una distribuzione del cluster.</block>
  <block id="7b65abec68958867d7dd5f43b3b06e08" category="inline-link">Red Hat OpenShift Installazione di un cluster su vSphere con personalizzazioni</block>
  <block id="6e7315bf45cda77f0a1477ed6f712eb6" category="paragraph">In questi casi, è possibile eseguire la procedura guidata senza implementare immediatamente un cluster, ma la procedura guidata crea un file di configurazione da cui il cluster può essere distribuito in un secondo momento. Questa funzione è molto utile se si desidera modificare le impostazioni predefinite dell'IPI o se si desidera implementare più cluster identici nell'ambiente per altri utilizzi, ad esempio la multi-tenancy. Per ulteriori informazioni sulla creazione di una configurazione di installazione personalizzata per OpenShift, vedere<block ref="fc4239653f75b84dd3ca03fe8b28dd64" category="inline-link-rx"></block>.</block>
  <block id="f5b3b6b5d5a71b2934abd61ddb561ce2" category="inline-link-macro">Pagina successiva: Panoramica dello storage NetApp.</block>
  <block id="dd2c34a46e688e4fd1c53e1a8d8af1d0" category="paragraph"><block ref="dd2c34a46e688e4fd1c53e1a8d8af1d0" category="inline-link-macro-rx"></block></block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="doc">Architettura</block>
  <block id="1d45b25ba986072287aaf72b6cf94130" category="paragraph">Sebbene Red Hat OpenShift e Astra Trident supportati da NetApp ONTAP non forniscano l'isolamento tra i carichi di lavoro per impostazione predefinita, offrono un'ampia gamma di funzionalità che possono essere utilizzate per configurare la multi-tenancy. Per comprendere meglio la progettazione di una soluzione multi-tenant su un cluster Red Hat OpenShift con Astra Trident supportato da NetApp ONTAP, prendiamo in considerazione un esempio con una serie di requisiti e descriviamo la configurazione che lo circonda.</block>
  <block id="385df0e95c28430fb792ec836529f371" category="paragraph">Supponiamo che un'organizzazione esegue due dei propri workload su un cluster Red Hat OpenShift nell'ambito di due progetti su cui lavorano due team diversi. I dati per questi carichi di lavoro risiedono su PVC che vengono forniti dinamicamente da Astra Trident su un backend NAS NetApp ONTAP. L'organizzazione deve progettare una soluzione multi-tenant per questi due carichi di lavoro e isolare le risorse utilizzate per questi progetti per garantire il mantenimento della sicurezza e delle performance, concentrandosi principalmente sui dati che servono tali applicazioni.</block>
  <block id="9c965c0beb472bc9265925ebbc55507e" category="paragraph">La seguente figura illustra la soluzione multi-tenant su un cluster Red Hat OpenShift con Astra Trident supportato da NetApp ONTAP.</block>
  <block id="2ed5156911e542a4d3d64a6e160f6446" category="image-alt">Multi-tenancy su cluster Red Hat OpenShift con Astra Trident supportato da NetApp ONTAP</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">Requisiti tecnologici</block>
  <block id="ff94444190436ee7694d15be2dde0f29" category="list-text">Cluster di storage NetApp ONTAP</block>
  <block id="b645e117fe786bf56128cde2dec3971a" category="list-text">Cluster Red Hat OpenShift</block>
  <block id="0d46ef98dfe52c8d01c0c5ace93d8165" category="section-title">Red Hat OpenShift – risorse cluster</block>
  <block id="72710b926f57dad99b29203c63f4e3fd" category="paragraph">Dal punto di vista del cluster Red Hat OpenShift, la risorsa di primo livello da iniziare è il progetto. Un progetto OpenShift può essere visto come una risorsa di cluster che divide l'intero cluster OpenShift in più cluster virtuali. Pertanto, l'isolamento a livello di progetto fornisce una base per la configurazione della multi-tenancy.</block>
  <block id="20e1834bb9396599a6dcf7d743aa1b36" category="paragraph">Successivamente, configurare RBAC nel cluster. La Best practice consiste nell'avere tutti gli sviluppatori che lavorano su un singolo progetto o workload configurati in un singolo gruppo di utenti nel provider di identità (IdP). Red Hat OpenShift consente l'integrazione di IdP e la sincronizzazione dei gruppi di utenti, consentendo così l'importazione di utenti e gruppi da IdP nel cluster. Ciò consente agli amministratori del cluster di separare l'accesso delle risorse del cluster dedicate a un progetto a un gruppo di utenti o a gruppi che lavorano su tale progetto, limitando in tal modo l'accesso non autorizzato a qualsiasi risorsa del cluster. Per ulteriori informazioni sull'integrazione di IdP con Red Hat OpenShift, consulta la documentazione<block ref="213cff8958909b80a9514e0c8321d8ef" category="inline-link-rx"></block>.</block>
  <block id="6d4e96186b1f4267def393ec42bf2d9e" category="paragraph">È importante isolare lo storage condiviso che funge da provider di storage persistente per un cluster Red Hat OpenShift per assicurarsi che i volumi creati sullo storage per ogni progetto appaiano agli host come se fossero creati su storage separato. A tale scopo, è possibile creare un numero di SVM (macchine virtuali di storage) su NetApp ONTAP pari al numero di progetti o carichi di lavoro e dedicare ogni SVM a un carico di lavoro.</block>
  <block id="0611f127a7e1e7ef5bbd782030c2e34a" category="paragraph">Dopo aver creato diverse SVM per diversi progetti su NetApp ONTAP, è necessario mappare ciascuna SVM su un backend Trident diverso. La configurazione di back-end su Trident determina l'allocazione dello storage persistente alle risorse del cluster OpenShift e richiede il mapping dei dettagli della SVM. Questo dovrebbe essere il driver del protocollo per il backend al minimo. Facoltativamente, consente di definire il provisioning dei volumi sullo storage e di impostare limiti per la dimensione dei volumi o l'utilizzo degli aggregati e così via. È possibile trovare i dettagli relativi alla definizione dei backend Trident<block ref="47a77763732c6cebe093a4a4d61aaa5b" category="inline-link-rx"></block>.</block>
  <block id="c4ff2177ae2f8ed9c3e5353068cf2195" category="section-title">Red Hat OpenShift – risorse di storage</block>
  <block id="891c9b8b0ce367c5e377a1ec23199619" category="paragraph">Dopo aver configurato i backend Trident, il passaggio successivo consiste nella configurazione di StorageClasses. Configura quante sono le classi di storage in cui sono presenti i backend, fornendo a ciascuna classe di storage l'accesso per eseguire lo spin up dei volumi su un solo backend. È possibile mappare StorageClass a un particolare backend Trident utilizzando il parametro storagePools durante la definizione della classe di storage. È possibile trovare i dettagli per definire una classe di storage<block ref="1266deb20a7d7c4814b1225e5e572606" category="inline-link-rx"></block>. Pertanto, esiste una mappatura uno a uno da StorageClass a Trident backend che punta a una SVM. In questo modo, tutte le attestazioni di storage tramite la StorageClass assegnata a quel progetto vengono gestite solo dalla SVM dedicata a quel progetto.</block>
  <block id="76245f392269db8492c3610e325b1963" category="paragraph">Poiché le classi di storage non sono risorse con spazio dei nomi, come possiamo garantire che le attestazioni di storage alla classe di storage di un progetto per pod in un altro namespace o progetto vengano rifiutate? La risposta è utilizzare ResourceQuotas. ResourceQuotas sono oggetti che controllano l'utilizzo totale delle risorse per progetto. Può limitare il numero e la quantità totale di risorse che possono essere utilizzate dagli oggetti nel progetto. Quasi tutte le risorse di un progetto possono essere limitate utilizzando ResourceQuotas e questo può aiutare le organizzazioni a ridurre i costi e le interruzioni dovute all'overprovisioning o all'eccessivo consumo di risorse. Consultare la documentazione<block ref="9b2bb9683c8f6144876bed616f252527" category="inline-link-rx"></block> per ulteriori informazioni.</block>
  <block id="5402bb91006fe391aea122e11c3607db" category="paragraph">In questo caso di utilizzo, dobbiamo limitare i pod di un progetto specifico al fine di richiedere storage da classi di storage non dedicate al loro progetto. A tale scopo, è necessario limitare le richieste di rimborso persistenti per volumi per altre classi di storage mediante l'impostazione<block ref="a21be23447e555ea751318f1aded4a38" prefix=" " category="inline-code"></block> a 0. Inoltre, un amministratore del cluster deve garantire che gli sviluppatori di un progetto non abbiano accesso per modificare le ResourceQuotas.</block>
  <block id="6c7eefdca8e3859011afa00995879a32" category="inline-link-macro">Pagina successiva: Configurazione.</block>
  <block id="0c86c0f2c0ad5b82864ef1b20a904132" category="paragraph"><block ref="0c86c0f2c0ad5b82864ef1b20a904132" category="inline-link-macro-rx"></block></block>
  <block id="810a039d1a8524388b75a0fe8d837afc" category="summary">Per consentire ad Astra Control Center di gestire i carichi di lavoro, devi prima registrare il cluster Red Hat OpenShift.</block>
  <block id="3557f7a93216446476c40d54e0426c40" category="doc">Registra i tuoi Red Hat OpenShift Clusters con Astra Control Center</block>
  <block id="349c99fe6f384da92e5b8289b828791c" category="section-title">Registra i cluster Red Hat OpenShift</block>
  <block id="c179429ab818c9d0cca3d1db55f788bf" category="list-text">Il primo passo consiste nell'aggiungere i cluster OpenShift all'Astra Control Center e gestirli. Accedere a Clusters e fare clic su Add a Cluster (Aggiungi cluster), caricare il file kubeconfig per il cluster OpenShift e fare clic su Select Storage (Seleziona storage).</block>
  <block id="8dfc7d6b819f8c17b51391e3b3159add" category="inline-image-macro">Astra Control Center crea il cluster</block>
  <block id="7470624615914e8e3d5fdf4ea1aa31de" category="paragraph"><block ref="7470624615914e8e3d5fdf4ea1aa31de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7d9a690231a2d896f69e9b45c9ff4a1" category="admonition">Il file kubeconfig può essere generato per l'autenticazione con un nome utente e una password o un token. I token scadono dopo un periodo di tempo limitato e potrebbero non essere raggiungibili dal cluster registrato. NetApp consiglia di utilizzare un file kubeconfig con nome utente e password per registrare i cluster OpenShift su Astra Control Center.</block>
  <block id="2fb91f8695d5dc9db4bf5a7ef710ec73" category="list-text">Astra Control Center rileva le classi di storage idonee. Selezionare ora il modo in cui lo storageclass effettua il provisioning dei volumi utilizzando Trident supportato da una SVM su NetApp ONTAP e fare clic su Review (esamina). Nel riquadro successivo, verificare i dettagli e fare clic su Add Cluster (Aggiungi cluster).</block>
  <block id="cab7d2cb072914c0a5a89baab41d38e8" category="inline-image-macro">Astra Control Center crea uno storage cluster Select</block>
  <block id="68ac91074dd3b4e5514e5f56a6c9c756" category="paragraph"><block ref="68ac91074dd3b4e5514e5f56a6c9c756" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3edb3c83eb1bede6778cc1960a651973" category="list-text">Registrare entrambi i cluster OpenShift come descritto al punto 1. Una volta aggiunti, i cluster passano allo stato di rilevamento mentre Astra Control Center li ispeziona e installa gli agenti necessari. Lo stato del cluster diventa in esecuzione dopo che sono stati registrati correttamente.</block>
  <block id="420b9c40f78cc4825914319af51801b9" category="inline-image-macro">Sono disponibili cluster di Astra Control Center</block>
  <block id="1b017a62213661e1ed3c5c581fcf74a2" category="paragraph"><block ref="1b017a62213661e1ed3c5c581fcf74a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed5c1a60b8165b8bc691cbdf1b0d122c" category="admonition">Tutti i cluster Red Hat OpenShift che devono essere gestiti da Astra Control Center devono avere accesso al registro delle immagini utilizzato per l'installazione, poiché gli agenti installati sui cluster gestiti estraggono le immagini da tale registro.</block>
  <block id="8d01de34ef9b9b934d18009a1e3273a9" category="list-text">Importa i cluster ONTAP come risorse storage da gestire come back-end dal centro di controllo Astra. Quando i cluster OpenShift vengono aggiunti ad Astra e viene configurato uno storageclass, il cluster ONTAP viene automaticamente ispezionato e ispezionato per il backup dello storageclass, ma non viene importato nel centro di controllo Astra da gestire.</block>
  <block id="781ffd1df517a65b302412f53de974da" category="inline-image-macro">Rilevamento back-end Astra Control Center</block>
  <block id="1fcc7977dffdc8fd8fc53582c67da895" category="paragraph"><block ref="1fcc7977dffdc8fd8fc53582c67da895" category="inline-image-macro-rx" type="image"></block></block>
  <block id="feab1371530d1ef069d928e811bcb08b" category="list-text">Per importare i cluster ONTAP, accedere a Backend, fare clic sul menu a discesa e selezionare Manage (Gestisci) accanto al cluster ONTAP da gestire. Immettere le credenziali del cluster ONTAP, fare clic su informazioni di revisione, quindi fare clic su Importa backend storage.</block>
  <block id="4da0c23c38cf0da34e1e6660ff74542b" category="inline-image-macro">Astra Control Center crea il backend</block>
  <block id="69dbaffc2661024ee0b5095bc3674f60" category="paragraph"><block ref="69dbaffc2661024ee0b5095bc3674f60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edb4425c04926a17b6ff9a4a2ecdc669" category="list-text">Una volta aggiunti i backend, lo stato diventa disponibile. Questi backend ora dispongono delle informazioni sui volumi persistenti nel cluster OpenShift e sui volumi corrispondenti nel sistema ONTAP.</block>
  <block id="92c130f9be24925c7dee36f7580ea347" category="inline-image-macro">Disponibilità di backend Astra Control Center</block>
  <block id="e9f487b0aad6779edbf50c6092477bd5" category="paragraph"><block ref="e9f487b0aad6779edbf50c6092477bd5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2d10d92dc9d83e3cf3514e8e883e5cb" category="list-text">Per il backup e il ripristino tra cluster OpenShift utilizzando Astra Control Center, è necessario eseguire il provisioning di un bucket di storage a oggetti che supporti il protocollo S3. Le opzioni attualmente supportate sono ONTAP S3, StorageGRID e AWS S3. Ai fini di questa installazione, configureremo un bucket AWS S3. Accedere a Bucket, fare clic su Add bucket (Aggiungi bucket) e selezionare Generic S3. Inserisci i dettagli sul bucket S3 e le credenziali per accedervi, fai clic sulla casella di controllo "Rendi questo bucket il bucket predefinito per il cloud", quindi fai clic su Aggiungi.</block>
  <block id="6910cb9051734be0129cb1e7dd84ce5c" category="inline-image-macro">Astra Control Center crea bucket</block>
  <block id="2786d0b632389f7cbd6c4e67fba0061f" category="paragraph"><block ref="2786d0b632389f7cbd6c4e67fba0061f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5a9f831c51dc05a9b40eae2850329fc" category="inline-link-macro">Avanti: Scegliere le applicazioni da proteggere.</block>
  <block id="74dd157086250792afa856d5a6c32777" category="paragraph"><block ref="74dd157086250792afa856d5a6c32777" category="inline-link-macro-rx"></block></block>
  <block id="d55adbfc40b7bcdb0606eb0bd4d88cae" category="summary">Questa sezione è dedicata alla creazione e alla configurazione di un registro di immagini privato supportato dallo storage persistente fornito da Astra Trident.</block>
  <block id="8252479af4b1df9b77ceaf67fa8cd07d" category="doc">Creazione di registri immagine privati</block>
  <block id="9c864113b9e4202e111b818a53d4f506" category="inline-link">Quay.io</block>
  <block id="4b4141875f954447d204e6f73d93e2a0" category="inline-link">DockerHub</block>
  <block id="508888fd9f92f35e5edd97bd8083e289" category="paragraph">Per la maggior parte delle implementazioni di Red Hat OpenShift, utilizzando un registro pubblico come<block ref="b9eeebbe4a68a648d570ea2173e5ef99" category="inline-link-rx"></block> oppure<block ref="0252a6b70cc5017fa1445a78532155b6" category="inline-link-rx"></block> soddisfa la maggior parte delle esigenze dei clienti. Tuttavia, in alcuni casi un cliente potrebbe voler ospitare le proprie immagini private o personalizzate.</block>
  <block id="00a3f196d7f27a1f41f5d6a7f48759d0" category="paragraph">Questa procedura documenta la creazione di un registro di immagini privato supportato da un volume persistente fornito da Astra Trident e NetApp ONTAP.</block>
  <block id="d9d5e29b1b83dd9c215f5ea158ca2475" category="admonition">Astra Control Center richiede un registro per ospitare le immagini richieste dai container Astra. La sezione seguente descrive i passaggi per configurare un registro privato sul cluster Red Hat OpenShift e per inviare le immagini necessarie per supportare l'installazione di Astra Control Center.</block>
  <block id="3434f6853d017037506e47f83a18c3eb" category="section-title">Creazione Di un registro di immagine privato</block>
  <block id="8b2aacc194c3dc4c36ce93a57e31685c" category="list-text">Rimuovere l'annotazione predefinita dalla classe di storage predefinita corrente e annotare la classe di storage supportata da Trident come predefinita per il cluster OpenShift.</block>
  <block id="9b1c6f527a1a481b925397807f319e71" category="list-text">Modificare l'operatore di imageregistry immettendo i seguenti parametri di storage in<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> sezione.</block>
  <block id="9ef71cd5ccaeb28206cd64b1d184019c" category="list-text">Inserire i seguenti parametri in<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> Sezione per la creazione di un percorso OpenShift con un nome host personalizzato. Salvare e uscire.</block>
  <block id="e0b23bc469102cf89472e5734da92a23" category="admonition">La suddetta configurazione del percorso viene utilizzata quando si desidera un nome host personalizzato per il percorso. Se si desidera che OpenShift crei un percorso con un nome host predefinito, è possibile aggiungere i seguenti parametri a<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> sezione:<block ref="b09e8357c45c55a2c3ca685c9742fa6e" prefix=" " category="inline-code"></block>.</block>
  <block id="625bd6ae5e3ac822b187b90d50edb553" category="sidebar-title">Certificati TLS personalizzati</block>
  <block id="08e414328e39f86009287c06a5f23d23" category="paragraph">Quando si utilizza un nome host personalizzato per il percorso, per impostazione predefinita, utilizza la configurazione TLS predefinita dell'operatore OpenShift Ingress. Tuttavia, è possibile aggiungere una configurazione TLS personalizzata al percorso. A tale scopo, attenersi alla seguente procedura.</block>
  <block id="60d14675c3111738a4ed19528764a7b1" category="list-text">Creare un segreto con i certificati TLS e la chiave del percorso.</block>
  <block id="47f7f890b5c1bcb52ae163771dbf35b0" category="list-text">Modificare l'operatore di imageregistry e aggiungere i seguenti parametri a<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> sezione.</block>
  <block id="9199ff34349c38138ad0275e447e6588" category="list-text">Modificare nuovamente l'operatore di imageregistry e modificare lo stato di gestione dell'operatore in<block ref="80c202b1c3fd395a7bfe4d846c914bc3" prefix=" " category="inline-code"></block> stato. Salvare e uscire.</block>
  <block id="2bc42a1a9a963d9a3ff2118466e5db07" category="list-text">Se tutti i prerequisiti sono soddisfatti, PVC, POD e servizi vengono creati per il registro delle immagini private. In pochi minuti, il registro dovrebbe essere attivo.</block>
  <block id="1f3713e339193dd15865ca74785eaa2c" category="list-text">Se si utilizzano i certificati TLS predefiniti per il percorso del Registro di sistema OpenShift dell'operatore di ingresso, è possibile recuperare i certificati TLS utilizzando il seguente comando.</block>
  <block id="295132dd97e1047a7c09e6a48054c469" category="list-text">Per consentire ai nodi OpenShift di accedere e estrarre le immagini dal Registro di sistema, aggiungere i certificati al client del docker sui nodi OpenShift. Creare una mappa di configurazione in<block ref="34dd8d8a3478a983eb249305316984b0" prefix=" " category="inline-code"></block> Namespace che utilizza i certificati TLS e lo patch alla configurazione dell'immagine del cluster per rendere attendibile il certificato.</block>
  <block id="98f3e484001465a59149c551e8d88cf0" category="list-text">Il registro interno di OpenShift è controllato dall'autenticazione. Tutti gli utenti di OpenShift possono accedere al registro di OpenShift, ma le operazioni che l'utente connesso può eseguire dipendono dalle autorizzazioni dell'utente.</block>
  <block id="561d4c8140016564eee98ecbc20f9add" category="list-text">Per consentire a un utente o a un gruppo di utenti di estrarre immagini dal registro, agli utenti deve essere assegnato il ruolo di visualizzatore del registro.</block>
  <block id="88167e36ea0f872788407d0e01fc1382" category="list-text">Per consentire a un utente o a un gruppo di utenti di scrivere o inviare immagini, agli utenti deve essere assegnato il ruolo di editor del Registro di sistema.</block>
  <block id="5ba9e8f3c64be4c82249856cac87a071" category="list-text">Per consentire ai nodi OpenShift di accedere al Registro di sistema e di eseguire il push o il pull delle immagini, è necessario configurare un pull secret.</block>
  <block id="86e93d266c168d718105c402f43fc91e" category="list-text">Questo segreto pull può quindi essere patchato agli account di servizio o può essere referenziato nella definizione del pod corrispondente.</block>
  <block id="fe2033a9e377624583baa802ffd9ce6d" category="list-text">Per applicare la patch agli account di servizio, eseguire il seguente comando.</block>
  <block id="59bd1dbdd3278e23e67bcabffbc4d55a" category="list-text">Per fare riferimento al segreto pull nella definizione del pod, aggiungere il seguente parametro a<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> sezione.</block>
  <block id="c0c3b4069e9a2e249507f67a6a2a3b07" category="list-text">Per trasferire o estrarre un'immagine dalle workstation a parte il nodo OpenShift, attenersi alla seguente procedura.</block>
  <block id="18f8bf05a7a278e63d921de74d2a5966" category="list-text">Aggiungere i certificati TLS al client docker.</block>
  <block id="312eaa3acf94b813cfe857f63a602724" category="list-text">Accedere a OpenShift usando il comando oc login.</block>
  <block id="cb4744e00672fbf6eba33b1b86d23ae0" category="list-text">Accedere al registro utilizzando le credenziali utente di OpenShift con il comando podman/docker.</block>
  <block id="abe31bcfb59f2265c2fb97dde407366c" category="open-title">podman</block>
  <block id="53557215e4d209eda16495dbe5f7c505" category="paragraph">+ NOTA: Se si utilizza<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> per accedere al registro di sistema privato, quindi utilizzare il token invece della password.</block>
  <block id="05b6053c41a2130afd6fc3b158bda4e6" category="open-title">docker</block>
  <block id="aa20d170f1ff336ec9079cf6dd1ccee3" category="list-text">Premere o tirare le immagini.</block>
  <block id="4b6826f4f20a8e7e7a3b42ccb81d514f" category="section-title">Cloning delle macchine virtuali</block>
  <block id="4a56de086437c8a56c22bccd4e7ed9ba" category="paragraph">Il cloning di una macchina virtuale esistente in OpenShift viene ottenuto con il supporto della funzionalità di cloning di Volume CSI di Astra Trident. Il cloning del volume CSI consente la creazione di un nuovo PVC utilizzando un PVC esistente come origine dati duplicando il suo PV. Dopo la creazione del nuovo PVC, funziona come entità separata e senza alcun collegamento o dipendenza dal PVC di origine.</block>
  <block id="0ea820e58acf3d0c3acac3f64518c517" category="image-alt">Architettura di VM Cloning</block>
  <block id="a1dbf280b3b5da141010127710d68ba7" category="paragraph">La clonazione dei volumi CSI è soggetta a determinate restrizioni:</block>
  <block id="7f8cb9ac957166d3d134bf9df8861f5b" category="list-text">Il PVC di origine e il PVC di destinazione devono trovarsi nello stesso progetto.</block>
  <block id="058d8141e417cb514573ba1a70e2e0cd" category="list-text">La clonazione è supportata all'interno della stessa classe di storage.</block>
  <block id="611b1b227968093cc5c73e69f7ac0fda" category="list-text">La clonazione può essere eseguita solo quando i volumi di origine e di destinazione utilizzano la stessa impostazione VolumeMode; ad esempio, un volume di blocco può essere clonato solo su un altro volume di blocco.</block>
  <block id="557d036c1a69ab0889c0820deb1e88de" category="paragraph">Le VM in un cluster OpenShift possono essere clonate in due modi:</block>
  <block id="e1230e5b1f51d793ea14fb31df500399" category="list-text">Spegnendo la VM di origine</block>
  <block id="29ec5d7b455e19c4f8141df877a9af0a" category="list-text">Mantenendo attiva la VM di origine</block>
  <block id="84d19f7437a8329c49099517eccd37dc" category="section-title">Spegnendo la VM di origine</block>
  <block id="9057e692817874e4c563dec1fa8c1700" category="paragraph">Clonare una macchina virtuale esistente spegnendo la macchina virtuale è una funzionalità OpenShift nativa implementata con il supporto di Astra Trident. Per clonare una macchina virtuale, attenersi alla seguente procedura.</block>
  <block id="ea1abad541ee7994705555d53c0281c3" category="list-text">Accedere a workload &gt; Virtualization &gt; Virtual Machines (carichi di lavoro &gt; virtualizzazione &gt; macchine virtuali) e fare clic sui puntini di sospensione accanto alla macchina virtuale che si desidera clonare.</block>
  <block id="375000776ee4694734b1d066c46e7096" category="list-text">Fare clic su Clone Virtual Machine (Clona macchina virtuale) e fornire i dettagli della nuova macchina virtuale.</block>
  <block id="b22c43b0906ef8ba78f3fbb7d5b1ff20" category="image-alt">clonare la macchina virtuale</block>
  <block id="cf702a835a3fd4b019603d29ec402106" category="list-text">Fare clic su Clone Virtual Machine (Clona macchina virtuale) per chiudere la macchina virtuale di origine e avviare la creazione della macchina virtuale clone.</block>
  <block id="82cfb538b52ee01d4a9901d4d2cfad4d" category="list-text">Al termine di questa fase, è possibile accedere e verificare il contenuto della VM clonata.</block>
  <block id="3c7aa222cd4c9ee079b31567a347c05f" category="paragraph">Una macchina virtuale esistente può anche essere clonata clonando il PVC esistente della macchina virtuale di origine e quindi creando una nuova macchina virtuale utilizzando il PVC clonato. Questo metodo non richiede l'arresto della VM di origine. Per clonare una macchina virtuale senza spegnerla, attenersi alla procedura riportata di seguito.</block>
  <block id="81ab8abf2317781c0eb6f4deeaeea5a5" category="list-text">Accedere a Storage &gt; PersistentVolumeClaims (Storage &gt; PersistentVolumeClaims) e fare clic sui puntini di sospensione accanto al PVC collegato alla VM di origine.</block>
  <block id="545ce69617c1c157be6073dcc63bfbae" category="list-text">Fare clic su Clone PVC e fornire i dettagli del nuovo PVC.</block>
  <block id="e659422cf737778a2fb1cdd50cc8003e" category="image-alt">clonare il pvc</block>
  <block id="07c24ffdbaf9583216cca9f030058c11" category="list-text">Quindi fare clic su Clone (Clona). In questo modo si crea un PVC per la nuova macchina virtuale.</block>
  <block id="5ba8ff3c009683ee423b0884c25360d0" category="list-text">Accedere a workload &gt; virtualizzazione &gt; macchine virtuali e fare clic su Create &gt; with YAML (Crea &gt; con YAML).</block>
  <block id="cd32f6b0aebb29494cbc9cc21a10c926" category="list-text">Nella sezione spec &gt; template &gt; spec &gt; Volumes (specifiche &gt; modello &gt; specifiche &gt; volumi), collegare il PVC clonato invece del disco container. Fornire tutti gli altri dettagli della nuova macchina virtuale in base alle proprie esigenze.</block>
  <block id="75b0d3500d81c7799a5b84eca57d6d04" category="list-text">Fare clic su Create (Crea) per creare la nuova macchina virtuale.</block>
  <block id="19e005e0709674157e554800d5ea7ef9" category="list-text">Una volta creata correttamente la macchina virtuale, accedere e verificare che la nuova macchina sia un clone della macchina virtuale di origine.</block>
  <block id="fdbfc131399a8776fecd30fa821de4d0" category="inline-link-macro">Segue: Workflow: Creazione di macchine virtuali da un'istantanea.</block>
  <block id="c5c4205f35e83d4dc33cfa7821ceb5a7" category="paragraph"><block ref="c5c4205f35e83d4dc33cfa7821ceb5a7" category="inline-link-macro-rx"></block></block>
  <block id="8b14fb34f5313442bf2fdc4d80edc389" category="summary">Questa sezione è dedicata all'analisi delle opzioni di bilanciamento del carico per gli utenti che desiderano personalizzare Red Hat OpenShift con l'implementazione NetApp.</block>
  <block id="87beaa6eff6159cd7270b2a4e71c10a4" category="doc">Analisi delle opzioni di bilanciamento del carico: Red Hat OpenShift con NetApp</block>
  <block id="a802e9436bb9bcbfa2b88bb549e28503" category="paragraph">Nella maggior parte dei casi, Red Hat OpenShift rende le applicazioni disponibili al mondo esterno attraverso i percorsi. Un servizio viene esposto assegnandogli un nome host raggiungibile esternamente. Il percorso definito e gli endpoint identificati dal servizio possono essere utilizzati da un router OpenShift per fornire questa connettività denominata ai client esterni.</block>
  <block id="0aa971b4d33bdc82c500a35166e588c8" category="paragraph">Tuttavia, in alcuni casi, le applicazioni richiedono l'implementazione e la configurazione di bilanciatori di carico personalizzati per esporre i servizi appropriati. Un esempio è NetApp Astra Control Center. Per soddisfare questa esigenza, abbiamo valutato diverse opzioni di bilanciamento del carico personalizzate. L'installazione e la configurazione sono descritte in questa sezione.</block>
  <block id="6914d9014ff3e2cb99cabff26b55a0bc" category="paragraph">Le seguenti pagine contengono informazioni aggiuntive sulle opzioni di bilanciamento del carico validate nella soluzione Red Hat OpenShift con NetApp:</block>
  <block id="2b545f7c547a71eaeda9dcb451aea0c5" category="inline-link-macro">MetalLB</block>
  <block id="eaefba36e93c0d0177c3de1143bd08dd" category="list-text"><block ref="eaefba36e93c0d0177c3de1143bd08dd" category="inline-link-macro-rx"></block></block>
  <block id="10a93051f49f4080568cecc5ec30cd99" category="inline-link-macro">F5 BIG-IP</block>
  <block id="886218e92c071e06819887a13189b4e6" category="list-text"><block ref="886218e92c071e06819887a13189b4e6" category="inline-link-macro-rx"></block></block>
  <block id="eed1ab12478f3384bfca66e2b382aefc" category="doc">Implementa la virtualizzazione di Red Hat OpenShift con NetApp ONTAP</block>
  <block id="7dc3a10e876dbab2b177f35c0b436f3a" category="list-text">Un cluster Red Hat OpenShift (successivo alla versione 4.6) installato su un'infrastruttura bare-metal con nodi di lavoro RHCOS</block>
  <block id="b5762731ee8c7a3d9a7ce9abe3804cf0" category="list-text">Il cluster OpenShift deve essere installato tramite l'infrastruttura di provisioning del programma di installazione (IPI)</block>
  <block id="7ed0bc09bfa62b64806b6b5c2f4378c7" category="list-text">Implementare i controlli dello stato delle macchine per mantenere l'ha per le macchine virtuali</block>
  <block id="43b1ab0e04b8f87e603cc790967d2886" category="list-text">Un cluster NetApp ONTAP</block>
  <block id="dc7ec0964c3d39892e26bbe1593a79e2" category="list-text">Astra Trident installato sul cluster OpenShift</block>
  <block id="d4c321b9edd8d817bdc7ca442e71e3af" category="list-text">Un backend Trident configurato con una SVM sul cluster ONTAP</block>
  <block id="e909486a42368b2659780687c3b4a31b" category="list-text">StorageClass configurato sul cluster OpenShift con Astra Trident come provisioner</block>
  <block id="cfcf3a62902e36f3d966271cc090b65c" category="list-text">Accesso cluster-admin al cluster Red Hat OpenShift</block>
  <block id="af91af16b4791d61bb2e9206807a658d" category="list-text">Accesso amministrativo al cluster NetApp ONTAP</block>
  <block id="e281839ef9ef6cb1eadcc2aa7d6d63be" category="list-text">Una workstation di amministrazione con tridentctl e oc tools installati e aggiunti al percorso dei dollari</block>
  <block id="314f04ff1024e623d43e0cda9a9df410" category="paragraph">Poiché la virtualizzazione OpenShift è gestita da un operatore installato sul cluster OpenShift, impone un overhead aggiuntivo su memoria, CPU e storage, che deve essere tenuto in considerazione durante la pianificazione dei requisiti hardware per il cluster. Consultare la documentazione<block ref="f9421eaa4175c3e9f421a9acaf6f00d6" category="inline-link-rx"></block> per ulteriori dettagli.</block>
  <block id="be51a7d8687b0a6254a274c1e0100052" category="paragraph">In alternativa, è possibile specificare un sottoinsieme dei nodi del cluster OpenShift per ospitare gli operatori, i controller e le macchine virtuali della virtualizzazione OpenShift configurando le regole di posizionamento dei nodi. Per configurare le regole di posizionamento dei nodi per la virtualizzazione OpenShift, seguire la documentazione<block ref="325820076f9012df5bb7261c397a527f" category="inline-link-rx"></block>.</block>
  <block id="a805b74dbb589c916a1ebf0e08601665" category="paragraph">Per il supporto dello storage OpenShift Virtualization, NetApp consiglia di disporre di un StorageClass dedicato che richieda storage da un particolare backend Trident, a sua volta supportato da una SVM dedicata. In questo modo si mantiene un livello di multi-tenancy in relazione ai dati serviti per i carichi di lavoro basati su macchine virtuali sul cluster OpenShift.</block>
  <block id="adb787dc1bae0d1c8dee5bd61d49c235" category="inline-link-macro">Avanti: Implementazione tramite operatore.</block>
  <block id="6166597c75dc82b2cc8c50a0d5d74400" category="paragraph"><block ref="6166597c75dc82b2cc8c50a0d5d74400" category="inline-link-macro-rx"></block></block>
  <block id="86c2cc4630e619e2c08c32f54e844297" category="section-title">Creare risorse su più cluster</block>
  <block id="bc2397695676d1a63e489d4c80c8cd91" category="paragraph">Advanced Cluster Management per Kubernetes consente agli utenti di creare risorse su uno o più cluster gestiti contemporaneamente dalla console. Ad esempio, se si dispone di cluster OpenShift in siti diversi supportati da diversi cluster NetApp ONTAP e si desidera eseguire il provisioning dei PVC in entrambi i siti, è possibile fare clic sul segno (+) nella barra superiore. Quindi selezionare i cluster in cui si desidera creare il PVC, incollare la risorsa YAML e fare clic su Create (Crea).</block>
  <block id="24800112d59462f8ea9ff03f5dd456a7" category="image-alt">Creare risorse</block>
  <block id="31fd0c2c8d388a4cd2c6459234743476" category="section-title">Osservabilità</block>
  <block id="e98511d60f9850de86f096614f447322" category="paragraph">La gestione avanzata dei cluster per Kubernetes consente di monitorare nodi, pod, applicazioni e carichi di lavoro in tutti i cluster.</block>
  <block id="36aff44ed429ca86d182dc7ee3dfdbb1" category="list-text">Accedere a osservare gli ambienti &gt; Panoramica.</block>
  <block id="7a6ccefec75a946583cffdd0a8a47e09" category="image-alt">Pagina iniziale dell'osservabilità</block>
  <block id="c9904a9276a489fc238c999d2ddd633f" category="list-text">Tutti i pod e i carichi di lavoro di tutti i cluster vengono monitorati e ordinati in base a una varietà di filtri. Fare clic su Pod per visualizzare i dati corrispondenti.</block>
  <block id="4a973ae1a908770e354f949d3c0592f8" category="image-alt">Osservare i pod</block>
  <block id="7cd1c61051d3647bc47d839e0efee222" category="list-text">Tutti i nodi dei cluster vengono monitorati e analizzati in base a una varietà di punti dati. Fare clic su Nodes (nodi) per ulteriori informazioni sui dettagli corrispondenti.</block>
  <block id="8a373f777de729c082b5be2d80b7eca6" category="image-alt">Osservare i nodi</block>
  <block id="4e7f54a0ebc5cd69209a17181d477e4c" category="list-text">Tutti i cluster vengono monitorati e organizzati in base a diverse risorse e parametri del cluster. Fare clic su Clusters (Clusters) per visualizzare i dettagli del cluster.</block>
  <block id="2ececa2c251a851a85e976daae558c81" category="image-alt">Osservare i Clusters</block>
  <block id="a883982d5f8961021329c238318d4e2b" category="inline-link-macro">Avanti: Funzionalità - Crea risorse.</block>
  <block id="5ca146f2101c14a961df161060f86cb9" category="paragraph"><block ref="5ca146f2101c14a961df161060f86cb9" category="inline-link-macro-rx"></block></block>
  <block id="bc42bbaf219349a2ba37dfd4709b2003" category="doc">Sfrutta NetApp Astra Control per eseguire l'analisi post-mortem e ripristinare l'applicazione</block>
  <block id="c48db988cd283c11f89d4dd85803ec0a" category="doc">Configurazione della multi-tenancy su Red Hat OpenShift con NetApp</block>
  <block id="6d72da55d82cdd434045ba5df1a959b6" category="paragraph">Molte organizzazioni che eseguono più applicazioni o carichi di lavoro su container tendono a implementare un cluster Red Hat OpenShift per applicazione o carico di lavoro. Ciò consente loro di implementare un rigoroso isolamento per l'applicazione o il carico di lavoro, ottimizzare le performance e ridurre le vulnerabilità della sicurezza. Tuttavia, l'implementazione di un cluster Red Hat OpenShift separato per ciascuna applicazione pone un proprio insieme di problemi. Aumenta l'overhead operativo dovendo monitorare e gestire ciascun cluster da solo, aumenta i costi grazie alle risorse dedicate per le diverse applicazioni e ostacola l'efficienza della scalabilità.</block>
  <block id="332dcd535fa9ce865f462efb80829a35" category="paragraph">Per risolvere questi problemi, si può prendere in considerazione l'esecuzione di tutte le applicazioni o i carichi di lavoro in un singolo cluster Red Hat OpenShift. Tuttavia, in un'architettura di questo tipo, le vulnerabilità legate all'isolamento delle risorse e alla sicurezza delle applicazioni sono una delle sfide principali. Qualsiasi vulnerabilità di sicurezza in un workload potrebbe naturalmente ricadersi in un altro workload, aumentando così la zona di impatto. Inoltre, qualsiasi utilizzo improvviso e non controllato delle risorse da parte di un'applicazione può influire sulle prestazioni di un'altra applicazione, poiché non esiste un criterio di allocazione delle risorse per impostazione predefinita.</block>
  <block id="14a9bacc4b197037f54eb0c4c7e1970c" category="paragraph">Pertanto, le organizzazioni cercano soluzioni in grado di ottenere il meglio in entrambi i mondi, ad esempio, consentendo loro di eseguire tutti i propri carichi di lavoro in un singolo cluster e offrendo al contempo i vantaggi di un cluster dedicato per ogni carico di lavoro.</block>
  <block id="73c1b26ace2fc5fca6e6e78c00a61837" category="paragraph">Una di queste soluzioni efficaci consiste nel configurare la multi-tenancy su Red Hat OpenShift. La multi-tenancy è un'architettura che consente a più tenant di coesistere sullo stesso cluster con un corretto isolamento delle risorse, della sicurezza e così via. In questo contesto, un tenant può essere visualizzato come un sottoinsieme delle risorse del cluster configurate per essere utilizzate da un particolare gruppo di utenti a scopo esclusivo. La configurazione della multi-tenancy su un cluster Red Hat OpenShift offre i seguenti vantaggi:</block>
  <block id="cde9f9f8fcae0cdc6624895868803d60" category="list-text">Riduzione di CapEx e OpEx grazie alla condivisione delle risorse del cluster</block>
  <block id="943a49720e6c85fa9692af2a5ebd8829" category="list-text">Riduzione dell'overhead operativo e di gestione</block>
  <block id="f51a58b3ab19c778652fcff9dd39ca55" category="list-text">Proteggere i carichi di lavoro dalla contaminazione incrociata delle violazioni della sicurezza</block>
  <block id="181cfddfdb055879df4d55323a14c473" category="list-text">Protezione dei carichi di lavoro da un peggioramento inatteso delle performance dovuto a conflitti di risorse</block>
  <block id="f3ff3f5b3c67fb47bb8ec0f2f688b97d" category="paragraph">Per un cluster OpenShift multitenant completamente realizzato, è necessario configurare le quote e le restrizioni per le risorse cluster appartenenti a diversi bucket di risorse: Calcolo, storage, networking, sicurezza e così via. Anche se vengono trattati alcuni aspetti di tutti i bucket di risorse di questa soluzione, Ci concentriamo sulle Best practice per isolare e proteggere i dati serviti o consumati da più carichi di lavoro sullo stesso cluster Red Hat OpenShift configurando la multi-tenancy sulle risorse storage allocate dinamicamente da Astra Trident con il supporto di NetApp ONTAP.</block>
  <block id="d463f48696e58e286e9c0d594169b395" category="inline-link-macro">Avanti: Architettura.</block>
  <block id="4fbbd2f5b2a8e82447aa1b841b2a70d0" category="paragraph"><block ref="4fbbd2f5b2a8e82447aa1b841b2a70d0" category="inline-link-macro-rx"></block></block>
  <block id="482f4dddd14a12f4ece48aef54de313c" category="summary">Red Hat OpenShift Container Platform unisce le operazioni IT e di sviluppo su un'unica piattaforma per creare, implementare e gestire le applicazioni in modo coerente tra infrastrutture cloud ibride e on-premise. Red Hat OpenShift si basa su innovazioni open-source e standard di settore, tra cui Kubernetes e Red Hat Enterprise Linux CoreOS, la distribuzione Linux aziendale leader a livello mondiale progettata per carichi di lavoro basati su container.</block>
  <block id="f122078c68f20c36897fec8a7c4a23e8" category="doc">Panoramica di OpenShift</block>
  <block id="e68e90b5707502c9f2fc1361ac071b3d" category="paragraph">Red Hat OpenShift Container Platform unisce le operazioni IT e di sviluppo su un'unica piattaforma per creare, implementare e gestire le applicazioni in modo coerente tra infrastrutture cloud ibride e on-premise. Red Hat OpenShift si basa su innovazioni open-source e standard di settore, tra cui Kubernetes e Red Hat Enterprise Linux CoreOS, la distribuzione Linux aziendale leader a livello mondiale progettata per carichi di lavoro basati su container. OpenShift fa parte del programma Cloud Native Computing Foundation (CNCF) Certified Kubernetes, che offre portabilità e interoperabilità dei carichi di lavoro dei container.</block>
  <block id="b2b7104a419a54dcb2763bddc6a0a47c" category="section-title">Red Hat OpenShift offre le seguenti funzionalità:</block>
  <block id="d383250f88949df87bac7768b697ccb6" category="list-text">*Provisioning self-service.* gli sviluppatori possono creare applicazioni on-demand in modo rapido e semplice dai tool che utilizzano di più, mentre le operazioni mantengono il pieno controllo sull'intero ambiente.</block>
  <block id="df45d857ed72e8e5ed370c6fdfd1e305" category="list-text">*Storage persistente.* grazie al supporto per lo storage persistente, OpenShift Container Platform consente di eseguire applicazioni stateful e stateless native nel cloud.</block>
  <block id="29ee9790b817110f2303080d5b295946" category="list-text">*Integrazione continua e sviluppo continuo (ci/CD).* questa piattaforma con codice sorgente gestisce immagini di build e implementazione su larga scala.</block>
  <block id="a0f0997dded25d9aa9c767f29c17c249" category="list-text">*Standard open-source.* questi standard incorporano l'Open Container Initiative (OCI) e Kubernetes per l'orchestrazione di container, oltre ad altre tecnologie open-source. Non ti limiterai alla tecnologia o alla roadmap di business di un vendor specifico.</block>
  <block id="7dc3d12ecda66373091607ba18ef4434" category="list-text">*Ci/CD pipeline.* OpenShift fornisce supporto immediato per le pipeline ci/CD, in modo che i team di sviluppo possano automatizzare ogni fase del processo di delivery delle applicazioni e assicurarsi che venga eseguito in ogni modifica apportata al codice o alla configurazione dell'applicazione.</block>
  <block id="95e4c6a8e27cc92068d97ef795477714" category="list-text">*RBAC (Role-Based Access Control).* questa funzione consente di monitorare team e utenti per organizzare un gruppo di sviluppatori di grandi dimensioni.</block>
  <block id="d565eddf8e07af916519ec07f8712204" category="list-text">*Automated Build and Deploy.* OpenShift offre agli sviluppatori la possibilità di creare le proprie applicazioni containerizzate o di fare in modo che la piattaforma crei i container dal codice sorgente dell'applicazione o persino dai binari. La piattaforma automatizza quindi l'implementazione di queste applicazioni nell'infrastruttura in base alle caratteristiche definite per le applicazioni. Ad esempio, la quantità di risorse da allocare e la posizione dell'infrastruttura da implementare per garantire la conformità con le licenze di terze parti.</block>
  <block id="4fe0bdfd5a2ae34ba1a93860fd91d2fd" category="list-text">*Ambienti coerenti.* OpenShift garantisce che l'ambiente fornito per gli sviluppatori e per tutto il ciclo di vita dell'applicazione sia coerente dal sistema operativo alle librerie, alla versione runtime (ad esempio, Java runtime), e persino il runtime dell'applicazione in uso (ad esempio, tomcat) per rimuovere i rischi derivanti da ambienti incoerenti.</block>
  <block id="64f8957eb1a3bb6a1e9ebd391e76925a" category="list-text">*Gestione della configurazione.* la configurazione e la gestione dei dati sensibili sono integrate nella piattaforma per garantire che all'applicazione venga fornita una configurazione coerente e indipendente dall'ambiente, indipendentemente dalle tecnologie utilizzate per creare l'applicazione o dall'ambiente in cui viene implementata.</block>
  <block id="5efb308bdb8052c1aa3fe8333f459fe5" category="list-text">*Registri e metriche delle applicazioni.* un feedback rapido è un aspetto importante dello sviluppo delle applicazioni. Il monitoraggio integrato e la gestione dei log di OpenShift forniscono agli sviluppatori metriche immediate per studiare il comportamento dell'applicazione tra le modifiche e per risolvere i problemi il prima possibile nel ciclo di vita dell'applicazione.</block>
  <block id="8c2b388bd42b0b6bae19890633c98a8d" category="list-text">*Sicurezza e catalogo di container.* OpenShift offre la multi-tenancy e protegge l'utente dall'esecuzione di codice dannoso utilizzando la sicurezza stabilita con Security-Enhanced Linux (SELinux), CGroups e Secure Computing Mode (seccomp) per isolare e proteggere i container. Fornisce inoltre la crittografia tramite certificati TLS per i vari sottosistemi e l'accesso ai container certificati Red Hat (access.redhat.com/containers) sottoposti a scansione e classificati con un'enfasi specifica sulla sicurezza per fornire container applicativi certificati, affidabili e sicuri agli utenti finali.</block>
  <block id="16c321ec2744799f0acef92ce84d06ca" category="paragraph"><block ref="16c321ec2744799f0acef92ce84d06ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe8c2f8039053e077a0ca678496b72aa" category="section-title">Metodi di implementazione per Red Hat OpenShift</block>
  <block id="9c2dd02f13d452b4422ac6c864933f01" category="paragraph">A partire da Red Hat OpenShift 4, i metodi di implementazione di OpenShift includono implementazioni manuali che utilizzano l'infrastruttura con provisioning utente (UPI) per implementazioni altamente personalizzate o implementazioni completamente automatizzate che utilizzano l'infrastruttura con provisioning dell'installatore (IPI).</block>
  <block id="68dc46cb39cdfc93e4593bbdd5c218cf" category="paragraph">Il metodo di installazione IPI è il metodo preferito nella maggior parte dei casi perché consente la rapida implementazione dei cluster OCP per gli ambienti di sviluppo, test e produzione.</block>
  <block id="ec55e5ffb2376dada4b2eb066c1fd9fd" category="section-title">Installazione IPI di Red Hat OpenShift</block>
  <block id="a91a379e59fea6610134af1efa3dfe87" category="paragraph">La distribuzione dell'infrastruttura IPI (Installer Provised Infrastructure) di OpenShift prevede questi passaggi di alto livello:</block>
  <block id="d1befa03c79ca0b84ecc488dea96bc68" category="inline-link">sito web</block>
  <block id="a07879007b1202a533ff3ef18bc0d197" category="list-text">Visita Red Hat OpenShift<block ref="36af4d1b80928d398e137421c95a1013" category="inline-link-rx"></block> E accedi con le tue credenziali SSO.</block>
  <block id="66f8ff89bd2c9146cb3273d416c60fd2" category="list-text">Seleziona l'ambiente in cui desideri implementare Red Hat OpenShift.</block>
  <block id="cc66c30273a9be504b88d3239e65516b" category="paragraph"><block ref="cc66c30273a9be504b88d3239e65516b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5806bcee67fc8f13f0255068a186e42" category="list-text">Nella schermata successiva, scaricare il programma di installazione, l'esclusivo segreto pull e gli strumenti CLI per la gestione.</block>
  <block id="86b43786316d35748685c4f7abc4145b" category="paragraph"><block ref="86b43786316d35748685c4f7abc4145b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">istruzioni per l'installazione</block>
  <block id="c9a2aa5906b4dad4a982c3a9c51d31f3" category="list-text">Seguire la<block ref="04512308a1627dc41acfeed51ef16ba3" category="inline-link-rx"></block> Fornito da Red Hat per l'implementazione nel vostro ambiente preferito.</block>
  <block id="220887aee59c37fa79fc366cba7dad4e" category="section-title">Implementazioni OpenShift validate da NetApp</block>
  <block id="d711fd24836980dd490f3c01dd3ee8de" category="paragraph">NetApp ha testato e validato l'implementazione di Red Hat OpenShift nei propri laboratori utilizzando il metodo di implementazione IPI (Installer Provised Infrastructure) in ciascuno dei seguenti ambienti di data center:</block>
  <block id="aa9095c5ba77e3549672e5c4fae1fedc" category="inline-link-macro">OpenShift su bare metal</block>
  <block id="fecab6277bc7322982f127ce83dee308" category="list-text"><block ref="fecab6277bc7322982f127ce83dee308" category="inline-link-macro-rx"></block></block>
  <block id="5f6a8f3661e7319797d4eab6792350e6" category="inline-link-macro">OpenShift sulla piattaforma Red Hat OpenStack</block>
  <block id="ff3de63c4917b45d20525986d5b29962" category="list-text"><block ref="ff3de63c4917b45d20525986d5b29962" category="inline-link-macro-rx"></block></block>
  <block id="92fb5c16a9f212d49c0c5fb48ebc9144" category="list-text"><block ref="92fb5c16a9f212d49c0c5fb48ebc9144" category="inline-link-macro-rx"></block></block>
  <block id="83fc4dbe543f82a9e50bc1bd4c74fb70" category="list-text"><block ref="83fc4dbe543f82a9e50bc1bd4c74fb70" category="inline-link-macro-rx"></block></block>
  <block id="254f642527b45bc260048e30704edb39" category="doc">Configurazione</block>
  <block id="44b1200b793638d4a3aebd1bee591e12" category="paragraph">Per qualsiasi soluzione multi-tenant, nessun utente può avere accesso a più risorse di cluster di quelle richieste. Pertanto, l'intero insieme di risorse da configurare come parte della configurazione multi-tenancy è diviso tra cluster-admin, storage-admin e sviluppatori che lavorano su ciascun progetto.</block>
  <block id="1ceba10f8902735a18e8c3bb3e8a3052" category="paragraph">La seguente tabella descrive le diverse attività che devono essere eseguite da diversi utenti:</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">Ruolo</block>
  <block id="ef615563c8e8ea902c7fcac3cd2c4246" category="cell">Attività</block>
  <block id="064dceba374668ef0734be5f9e182682" category="cell">*Cluster-admin*</block>
  <block id="445b72f2cbecd97022bb6636eda3cbc7" category="cell">Crea progetti per applicazioni o carichi di lavoro diversi</block>
  <block id="e033ab3bea3b8a20afb5852070df0203" category="cell">Creare ClusterRoles e RoleBinding per l'amministrazione dello storage</block>
  <block id="293d08622718634a8518b6fcc6376617" category="cell">Creazione di ruoli e associazioni per gli sviluppatori che assegnano l'accesso a progetti specifici</block>
  <block id="3e97e469255cd3686174c371f50961f9" category="cell">[Facoltativo] configurare i progetti per pianificare i pod su nodi specifici</block>
  <block id="93ffd2b1215bc47cc78b020f89e922ef" category="cell">*Storage-admin*</block>
  <block id="043ab42cdcbdacc4691c26ee52ed8ccd" category="cell">Creare SVM su NetApp ONTAP</block>
  <block id="be09a24f118a66330a40633e9d5ebfca" category="cell">Creare backend Trident</block>
  <block id="55995e8c220e05b3e75252cccf5752be" category="cell">Creare StorageClasses</block>
  <block id="2a5eb41b2d7fd04d01836f89ab790852" category="cell">Creare ResourceQuotas di storage</block>
  <block id="4e00898ecc4e6640083ccff8d85fbe87" category="cell">*Sviluppatori*</block>
  <block id="bfc5fb8ef5464441bc8b3ca7eda2892d" category="cell">Convalidare l'accesso per creare o applicare patch a PVC o pod nel progetto assegnato</block>
  <block id="9e95c94350b2b7b51176ad958deb1388" category="cell">Convalida l'accesso per creare o applicare patch a PVC o pod in un altro progetto</block>
  <block id="8c0b7954d326b4bcf2f42a57ef00eead" category="cell">Convalida l'accesso per visualizzare o modificare progetti, ResourceQuotas e StorageClasses</block>
  <block id="4edd9914739183e9cb724a222261a01f" category="inline-link-macro">Avanti: Prerequisiti.</block>
  <block id="8013a47a037d25fa6d9671120cfc1ee5" category="paragraph"><block ref="8013a47a037d25fa6d9671120cfc1ee5" category="inline-link-macro-rx"></block></block>
  <block id="b1a934cbded2602c4186fb43d7c8a986" category="paragraph">A seconda del caso di utilizzo specifico, sia i container che le macchine virtuali (VM) possono fungere da piattaforme ottimali per diversi tipi di applicazioni. Pertanto, molte organizzazioni eseguono alcuni dei propri carichi di lavoro su container e alcune su macchine virtuali. Spesso, questo porta le organizzazioni ad affrontare ulteriori sfide dovendo gestire piattaforme separate: Un hypervisor per le macchine virtuali e un container orchestrator per le applicazioni.</block>
  <block id="7652dcfa1608f7891f4e5c9b462354be" category="paragraph">Per affrontare questa sfida, Red Hat ha introdotto la virtualizzazione OpenShift (precedentemente nota come virtualizzazione nativa container) a partire dalla versione 4.6 di OpenShift. La funzionalità di virtualizzazione di OpenShift consente di eseguire e gestire macchine virtuali insieme ai container nella stessa installazione di OpenShift Container Platform, offrendo una funzionalità di gestione ibrida per automatizzare l'implementazione e la gestione delle macchine virtuali attraverso gli operatori. Oltre a creare macchine virtuali in OpenShift, con la virtualizzazione OpenShift, Red Hat supporta anche l'importazione di macchine virtuali da VMware vSphere, Red Hat Virtualization e Red Hat OpenStack Platform.</block>
  <block id="269bac1ed5128eacc45c06318333642a" category="image-alt">Virtualizzazione OpenShift</block>
  <block id="bf4e72937ad57bd2f780561c81d25d53" category="paragraph">Alcune funzionalità come la migrazione live delle macchine virtuali, la clonazione dei dischi delle macchine virtuali, le snapshot delle macchine virtuali e così via sono supportate dalla virtualizzazione OpenShift con l'assistenza di Astra Trident, se supportata da NetApp ONTAP. Esempi di ciascuno di questi flussi di lavoro sono discussi più avanti in questo documento nelle rispettive sezioni.</block>
  <block id="8a5bcb32f7cb878beee68d6f84b3ada7" category="paragraph">Per ulteriori informazioni sulla virtualizzazione di Red Hat OpenShift, consulta la documentazione<block ref="3339eb5909b80aa35681f9f3f9478c17" category="inline-link-rx"></block>.</block>
  <block id="2bd77ae4e72f37c837a2da8cfa83e210" category="inline-link-macro">Avanti: Prerequisiti per l'implementazione.</block>
  <block id="3a86ddb85761278fa813d15edecbc2b1" category="paragraph"><block ref="3a86ddb85761278fa813d15edecbc2b1" category="inline-link-macro-rx"></block></block>
  <block id="472d13eb415cd6107aeef3a1ae6cd705" category="summary">NetApp offre una serie di prodotti che assistono i nostri clienti nell'orchestrazione e nella gestione dei dati persistenti in ambienti basati su container, come Red Hat OpenShift.</block>
  <block id="2515fbef39d57544723402c683215c64" category="doc">Panoramica sull'integrazione dello storage NetApp</block>
  <block id="689ca76b61ed9331405d36eb5ded709d" category="paragraph">NetApp offre una serie di prodotti per aiutarvi nell'orchestrazione e nella gestione dei dati persistenti in ambienti basati su container, come Red Hat OpenShift.</block>
  <block id="ebfc0e639726a366f8eb5ac86bb7cc43" category="paragraph"><block ref="ebfc0e639726a366f8eb5ac86bb7cc43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c3fd18fbca2ec11aa1ef250cf79f2e5" category="paragraph">NetApp Astra Control offre un set completo di servizi di gestione dei dati application-aware e storage per carichi di lavoro Kubernetes stateful, basati sulla tecnologia di protezione dei dati di NetApp. Astra Control Service è disponibile per supportare carichi di lavoro stateful nelle implementazioni Kubernetes native nel cloud. Astra Control Center è disponibile per supportare carichi di lavoro stateful in implementazioni on-premise, come Red Hat OpenShift. Per ulteriori informazioni, visita il sito Web di NetApp Astra Control<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="d656f81a685df3697a812158d0bd2f21" category="paragraph">NetApp Astra Trident è un orchestrator di storage open-source e completamente supportato per container e distribuzioni Kubernetes, tra cui Red Hat OpenShift. Per ulteriori informazioni, visita il sito web di Astra Trident<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="cd351007d4a671a321b6881f730d0dc3" category="paragraph">Le pagine seguenti contengono informazioni aggiuntive sui prodotti NetApp validati per la gestione delle applicazioni e dello storage persistente nella soluzione Red Hat OpenShift con NetApp:</block>
  <block id="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="list-text"><block ref="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="inline-link-macro-rx"></block></block>
  <block id="ea1c9e7b76d8b7cc203b9f6a9633e241" category="list-text"><block ref="ea1c9e7b76d8b7cc203b9f6a9633e241" category="inline-link-macro-rx"></block></block>
  <block id="afa49872fb8ae001174e4c8f2cc47208" category="inline-link-macro">Pagina successiva: Panoramica di NetApp Astra Control Center</block>
  <block id="22fd530ae76b4bbe50669b9a4d5b72d7" category="paragraph"><block ref="22fd530ae76b4bbe50669b9a4d5b72d7" category="inline-link-macro-rx"></block></block>
  <block id="d46a5e1e10f8a4a33306d0696cef14f5" category="summary">Questo documento di riferimento fornisce la convalida dell'implementazione della soluzione anthos con NetApp, implementata in più ambienti di data center, convalidata da NetApp e dai nostri partner di progettazione.</block>
  <block id="9d171bf7d3d65afb2e7e56d43b4b9ed5" category="doc">NVA-1165: Anthos con NetApp</block>
  <block id="dbadbc59fa29afd33e371d5285fde4cf" category="paragraph">Banu Sundhar e Suresh Thoppay, NetApp</block>
  <block id="28eb5fe5f641c3ffa32f2488fa166a36" category="paragraph">Questo documento di riferimento fornisce la convalida dell'implementazione della soluzione anthos con NetApp da parte di NetApp e dei nostri partner tecnici quando viene implementata in più ambienti di data center. Inoltre, illustra in dettaglio l'integrazione dello storage con i sistemi di storage NetApp utilizzando Astra Trident Storage orchestrator per la gestione dello storage persistente. Infine, esploriamo e documentiamo una serie di validazioni delle soluzioni e casi di utilizzo reali.</block>
  <block id="9b3053daf2ec8e22b4a577982f08f107" category="paragraph">La soluzione anthos con NetApp è progettata per offrire un valore eccezionale ai clienti con i seguenti casi di utilizzo:</block>
  <block id="0d3aabd1c9ad032e07b543d0aff99cb1" category="list-text">Facile da implementare e gestire l'ambiente anthos implementato utilizzando il fornito<block ref="f9d1b8d1854865b695167e2c5829f633" prefix=" " category="inline-code"></block> su metallo nudo o su<block ref="fb87177c7509d5723aa1bbc241ec2f7b" prefix=" " category="inline-code"></block> Su VMware vSphere.</block>
  <block id="cbc828fed325d3834b2bf3b1f2b5e639" category="inline-link">kubivirt</block>
  <block id="341508ebeee3f32bbf4f6fee6cb456a0" category="list-text">Potenza combinata di container Enterprise e carichi di lavoro virtualizzati con anthos implementato virtualmente su vSphere o su bare metal con<block ref="3149dc0a8051bd1d167afbb1fe9775d9" category="inline-link-rx"></block>.</block>
  <block id="de800fedc3b1bf6c4cf497db01ca193d" category="list-text">Configurazione e casi di utilizzo reali che evidenziano le funzionalità di anthos quando utilizzate con lo storage NetApp e Astra Trident, l'orchestrator dello storage open-source per Kubernetes.</block>
  <block id="c67346d734cf1873532bdc9f9a1421da" category="list-text">Possibilità di eseguire workload virtualizzati e containerizzati contemporaneamente</block>
  <block id="71d00a17a6d603b0b4ebb168354950db" category="list-text">Possibilità di scalare l'infrastruttura in modo indipendente in base alle esigenze dei carichi di lavoro</block>
  <block id="ee1ef628edbfb6bb102163064fbd3d8e" category="paragraph">La soluzione anthos con NetApp riconosce queste sfide e presenta una soluzione che aiuta a risolvere ogni problema implementando l'implementazione completamente automatica di anthos in maniera prematura nell'ambiente di data center scelto dal cliente.</block>
  <block id="22acab0d08b6253aa6c7d6be2fd3f4d3" category="paragraph">La soluzione anthos con NetApp comprende i seguenti componenti principali:</block>
  <block id="c6e52ea38355d1c4527e874a4c673b5b" category="section-title">Anthos on Prem</block>
  <block id="385c65f480dfcbc7cb530a2c6c807ae9" category="paragraph">Anthos on Prem è una piattaforma Kubernetes aziendale completamente supportata che può essere implementata nell'hypervisor VMware vSphere o su un'infrastruttura bare metal di tua scelta.</block>
  <block id="001a38f118eab6df015a51079735d9c9" category="paragraph">Per ulteriori informazioni su anthos, visitare il sito Web di anthos all'indirizzo<block ref="984918f1ee4e70aa6181e0564d0768e7" category="inline-link-rx"></block>.</block>
  <block id="94806f6a6daed15d3a6ea4f0146cf8ee" category="paragraph">NetApp dispone di diversi sistemi storage perfetti per data center aziendali e implementazioni di cloud ibrido. Il portfolio NetApp include NetApp ONTAP, Cloud Volumes ONTAP, Cloud Volumes Service, Azure NetApp Files, FSxN per i sistemi storage NetApp ONTAP, tutti in grado di fornire storage persistente per le applicazioni containerizzate.</block>
  <block id="b73ed4ba665437210c3da7d43d6618bf" category="paragraph">Astra Trident è un orchestrator di storage open-source e completamente supportato per container e distribuzioni Kubernetes, incluso Anthos.</block>
  <block id="57f64c5c85667657a2c67b472c545e5a" category="paragraph">Vedere<block ref="0c665fc00d0d39d9ca9d157ca926b271" category="inline-link-rx"></block> per la matrice di supporto per le release validate.</block>
  <block id="ff870d33a6cd8a05e92781267ae2d76c" category="inline-link-macro">Avanti: Panoramica di anthos.</block>
  <block id="c3d162eb5f173883de1167105528ba0b" category="paragraph"><block ref="c3d162eb5f173883de1167105528ba0b" category="inline-link-macro-rx"></block></block>
  <block id="306235ad6a87783a223e0ba03145dc12" category="doc">Creazione di registri di immagini privati</block>
  <block id="56a0195518edf56f84e2b789302cf485" category="paragraph">Questa procedura documenta la creazione di un registro di immagine privato supportato da un volume persistente fornito da Astra Trident e NetApp ONTAP.</block>
  <block id="13bb7c6596c212587d7a35708de351f2" category="admonition">Astra Control Center richiede un registro per ospitare le immagini richieste dai container Astra. La sezione seguente descrive i passaggi per configurare un registro privato su un cluster Red Hat OpenShift e per inviare le immagini necessarie per supportare l'installazione di Astra Control Center.</block>
  <block id="83806e2d09a78bbe33b3e817a88df12b" category="list-text">Se si utilizzano i certificati TLS predefiniti per il percorso del Registro di sistema OpenShift dell'operatore di ingresso, è possibile recuperare i certificati TLS utilizzando il seguente comando:</block>
  <block id="6714b6fa43a8d03bcbfeb657bd27788d" category="list-text">Il registro interno di OpenShift è controllato dall'autenticazione. Tutti gli utenti di OpenShift possono accedere al registro di OpenShift, ma le operazioni che l'utente connesso può eseguire dipendono dalle autorizzazioni dell'utente.</block>
  <block id="489c81c1a0ec76cf6ab9a12890120550" category="list-text">Per applicare la patch agli account di servizio, eseguire il seguente comando:</block>
  <block id="ec0c98e5e0be835a1df04b40b6c8e96c" category="list-text">Per trasferire o estrarre un'immagine dalle workstation a parte il nodo OpenShift, attenersi alla seguente procedura:</block>
  <block id="ffedc012b4decbb02d6a5ca1791f3d60" category="admonition">Se si utilizza<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> per accedere al registro privato, quindi utilizzare un token invece di una password.</block>
  <block id="abd6754aa5a185ca83b3f00c5da68534" category="inline-link-macro">Successivo: Convalida della soluzione/casi d'utilizzo.</block>
  <block id="8bfe62be82a77570753936203ee020ca" category="paragraph"><block ref="8bfe62be82a77570753936203ee020ca" category="inline-link-macro-rx"></block></block>
  <block id="8e0bd613649f232fe1f718134898ea21" category="summary">Per consentire l'integrazione di Trident con il sistema storage NetApp ONTAP, è necessario creare un backend che consenta la comunicazione con il sistema storage.</block>
  <block id="60423d24e49c8db4836be0abd09fb78d" category="doc">Configurazione iSCSI di NetApp ONTAP</block>
  <block id="3ca99f0e09d3b1ea097a113dd72c9317" category="list-text">Nell'archivio di installazione scaricato in sono disponibili file backend di esempio<block ref="75e4a0ceb294a9d74374c938e4e8ddc8" prefix=" " category="inline-code"></block> gerarchia di cartelle. Per i sistemi NetApp ONTAP che utilizzano iSCSI, copiare il<block ref="684351d8ace6c8daa15d6a5ec881647e" prefix=" " category="inline-code"></block> nella directory di lavoro e modificare il file.</block>
  <block id="fa346018b8222fdc195d0b73016cf5a0" category="list-text">Modificare i valori di gestione LIF, dataLIF, svm, nome utente e password in questo file.</block>
  <block id="38ace6c607c7db13cd4cc319f9b0225b" category="list-text">Una volta creato questo file di back-end, eseguire il comando seguente per creare il primo backend.</block>
  <block id="da0289d58f35e36d18325d6e8038b226" category="admonition">Esiste un campo opzionale chiamato<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> definito in questo file. Nei backend iSCSI, questo valore può essere impostato su un tipo di file system Linux specifico (XFS, ext4 e così via), oppure può essere cancellato per consentire al sistema operativo del nodo di lavoro di decidere quale file system utilizzare.</block>
  <block id="00d32067724b7191cb5b0ffaf99cc3fe" category="list-text">Eseguire<block ref="0f12ee5c9f1dd90158580f1c292b0d37" prefix=" " category="inline-code"></block> per creare la classe di storage.</block>
  <block id="36a95a56c85c06906ce9ed37f6c88bbe" category="list-text">Creare il PVC emettendo il<block ref="0f12ee5c9f1dd90158580f1c292b0d37" prefix=" " category="inline-code"></block> comando. La creazione può richiedere del tempo a seconda delle dimensioni del volume di backup da creare, in modo da poter guardare il processo mentre viene completato.</block>
  <block id="7f35d44665a62879611c82424828f0fd" category="inline-link-macro">Avanti: Opzioni di configurazione avanzate per anthos.</block>
  <block id="bff5cad56bec414a2d44f250d8a8ad3d" category="paragraph"><block ref="bff5cad56bec414a2d44f250d8a8ad3d" category="inline-link-macro-rx"></block></block>
  <block id="967a8ba34c500bbb53dbf69cee7587d9" category="doc">Registra i tuoi cluster Red Hat OpenShift con Astra Control Center</block>
  <block id="d2b3fd1f3d8ac38be89cec192a9d1558" category="list-text">Il primo passo consiste nell'aggiungere i cluster OpenShift all'Astra Control Center e gestirli. Accedere a Clusters, fare clic su Add a Cluster (Aggiungi cluster) e caricare<block ref="deabc6332aa53495b56c51d2e3eca54f" prefix=" " category="inline-code"></block> Per il cluster OpenShift, quindi fare clic su Select Storage (Seleziona storage).</block>
  <block id="0fafca9f5d93d0accfd1e6ed440a772b" category="list-text">Per il backup e il ripristino tra cluster OpenShift utilizzando Astra Control Center, è necessario eseguire il provisioning di un bucket di storage a oggetti che supporti il protocollo S3. Le opzioni attualmente supportate sono ONTAP S3, StorageGRID e AWS S3. Ai fini di questa installazione, configureremo un bucket AWS S3. Accedere a Bucket, fare clic su Add bucket (Aggiungi bucket) e selezionare Generic S3. Inserisci i dettagli sul bucket S3 e le credenziali per accedervi, fai clic sulla casella di controllo Rendi questo bucket il bucket predefinito per il cloud, quindi fai clic su Aggiungi.</block>
  <block id="048fd5f2b27a172a00e3a014fbc0161b" category="inline-link-macro">Avanti: Scegliere le applicazioni da proteggere.</block>
  <block id="6178a48a7c4c2e616e1caf9190bf41e6" category="paragraph"><block ref="6178a48a7c4c2e616e1caf9190bf41e6" category="inline-link-macro-rx"></block></block>
  <block id="90f687894749dad073416489141eb43f" category="list-text">Documentazione di NetApp Astra Trident</block>
  <block id="7cfc9495aac39bbaa5defc76b7f4e8db" category="list-text">Documentazione di Anthos Clusters su VMware</block>
  <block id="3001330ca359a25f2bb0fb3a80b81f98" category="inline-link"><block ref="3001330ca359a25f2bb0fb3a80b81f98" category="inline-link-rx"></block></block>
  <block id="ce31d50048cf83e159c11cdf9571f300" category="paragraph"><block ref="ce31d50048cf83e159c11cdf9571f300" category="inline-link-rx"></block></block>
  <block id="9ee8ef3c59727b8b17070caf87743214" category="list-text">Anthos sulla documentazione bare metal</block>
  <block id="bc10096da41c680de98ecf3f1def7d17" category="inline-link"><block ref="bc10096da41c680de98ecf3f1def7d17" category="inline-link-rx"></block></block>
  <block id="d642746f7d7a37b7cb340d9a62d751a5" category="paragraph"><block ref="d642746f7d7a37b7cb340d9a62d751a5" category="inline-link-rx"></block></block>
  <block id="a8fba1abc3fbaa027d18daed3f6e170d" category="doc">Installazione dei bilanciatori di carico MetalLB</block>
  <block id="48501496ee9b06b63701de94b6ffc3a5" category="paragraph">Questa pagina elenca le istruzioni di installazione e configurazione per il bilanciamento del carico gestito da MetalLB.</block>
  <block id="ccd779a5e754b22c1589256334866c0a" category="paragraph">Il bilanciamento del carico MetalLB è completamente integrato con i cluster anthos su VMware e ha eseguito l'implementazione automatica come parte delle configurazioni dei cluster Admin e User a partire dalla release 1.11. Vi sono blocchi di testo nei rispettivi<block ref="c6ce65430f0e0c334f6b50da737f2e9b" prefix=" " category="inline-code"></block> file di configurazione che è necessario modificare per fornire informazioni sul bilanciamento del carico. Viene eseguito in hosting automatico sul cluster anthos invece di richiedere l'implementazione di risorse esterne come le altre soluzioni di bilanciamento del carico supportate. Consente inoltre di creare un pool ip che assegna automaticamente gli indirizzi con la creazione di servizi Kubernetes di tipo bilanciamento del carico in cluster che non vengono eseguiti su un provider cloud.</block>
  <block id="616e4c989df3c842830310568b54cee6" category="section-title">Integrazione con anthos</block>
  <block id="b938ac6243408826bd53c58d2a6a6f1f" category="paragraph">Quando si attiva il bilanciamento del carico di MetalLB per l'amministratore di anthos, è necessario modificare alcune righe in<block ref="d4b71de62fea2275aed3155c187cb766" prefix=" " category="inline-code"></block> che esiste in<block ref="b58bb01ef49e2b97a31ca0536ef027fd" prefix=" " category="inline-code"></block> file. Gli unici valori che è necessario modificare sono l'impostazione di<block ref="0256ba7412d85da2acbcf1930256c21b" prefix=" " category="inline-code"></block> quindi impostare<block ref="c4b58542f9e0392c2110da5afb7437af" prefix=" " category="inline-code"></block> Come MetalLB. Vedere il seguente frammento di codice per un esempio:</block>
  <block id="79fdf71abab382ca3fbab93d863f835c" category="paragraph">Quando si abilita il bilanciamento del carico MetalLB per i cluster di utenti anthos, vi sono due aree in ciascuna<block ref="aba03e96a3a4305fd83dc510e1607415" prefix=" " category="inline-code"></block> file da aggiornare. In primo luogo, in modo simile a.<block ref="b58bb01ef49e2b97a31ca0536ef027fd" prefix=" " category="inline-code"></block> modificare il<block ref="0256ba7412d85da2acbcf1930256c21b" prefix=" " category="inline-code"></block>,<block ref="4fa041ebf362f3965af3570da03ef0fe" prefix=" " category="inline-code"></block>, e.<block ref="c4b58542f9e0392c2110da5afb7437af" prefix=" " category="inline-code"></block> valori in<block ref="d4b71de62fea2275aed3155c187cb766" prefix=" " category="inline-code"></block> sezione. Vedere il seguente frammento di codice per un esempio:</block>
  <block id="c173f58ae6718fb7dc80d6ddb9b392e5" category="admonition">L'indirizzo IP entressVIP deve trovarsi all'interno del pool di indirizzi IP assegnati al bilanciamento del carico MetalLB in un secondo momento della configurazione.</block>
  <block id="77960f17a334c28c4bacd9515ac55817" category="paragraph">Quindi, accedere a<block ref="0ea77e636e8d12d9ce07b2dab6268822" prefix=" " category="inline-code"></block> sottosezione e modificare<block ref="045d68a12437e8212f812d2bf506dbc0" prefix=" " category="inline-code"></block> assegnando un nome al pool in<block ref="146d8d83713f4abd99cafc739779598c" prefix=" " category="inline-code"></block> variabile. È inoltre necessario creare un pool di indirizzi ip che MetalLB può assegnare ai servizi di tipo LoadBalancer fornendo un intervallo a<block ref="336f9e008319434aa314ef3c1b8a682f" prefix=" " category="inline-code"></block> variabile.</block>
  <block id="8dfd015968f24ba6c3e2d8386cd40cbe" category="admonition">Il pool di indirizzi può essere fornito come un intervallo come nell'esempio, limitandolo a un numero di indirizzi in una particolare subnet, oppure può essere fornito come notazione CIDR se l'intera subnet è resa disponibile.</block>
  <block id="ea4a20324a094d5f515252d5669a60ca" category="list-text">Quando vengono creati servizi Kubernetes di tipo LoadBalancer, MetalLB assegna automaticamente un IP esterno ai servizi e annuncia l'indirizzo IP rispondendo alle richieste ARP.</block>
  <block id="f1d1e6ba9a2b7db0fa9da49e0e72d8e2" category="inline-link-macro">Avanti: Installazione dei bilanciatori di carico seesaw.</block>
  <block id="bbceb5257bbc998fe84b078ef4d5062b" category="paragraph"><block ref="bbceb5257bbc998fe84b078ef4d5062b" category="inline-link-macro-rx"></block></block>
  <block id="cbaa3aa588b8aa5c85dca443c15a0195" category="doc">Configurazione NFS di NetApp ONTAP</block>
  <block id="89441fb0b16307f49090afa2b479b9fa" category="list-text">Nell'archivio di installazione scaricato in sono disponibili file backend di esempio<block ref="75e4a0ceb294a9d74374c938e4e8ddc8" prefix=" " category="inline-code"></block> gerarchia di cartelle. Per i sistemi NetApp ONTAP che servono NFS, copiare il<block ref="d897e4d05156cbf9998e98200d6190aa" prefix=" " category="inline-code"></block> nella directory di lavoro e modificare il file.</block>
  <block id="87f6ff6bf74013e1dfe6df49a1cf1986" category="list-text">Modificare il backendName, managementLIF, dataLIF, svm, nome utente, e password in questo file.</block>
  <block id="f897eefba2c59919d6493db4825e2db2" category="admonition">È consigliabile definire il valore backendName personalizzato come combinazione di storageDriverName e dataLIF che fornisce NFS per una facile identificazione.</block>
  <block id="00d6947fd6a153943286b857dcd0f339" category="admonition">Esiste un campo opzionale chiamato<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> definito in questo file. Questa riga può essere eliminata nei backend NFS.</block>
  <block id="d0ee5cd6f53ec708670800837b7502b7" category="inline-link-macro">Avanti: ISCSI NetApp ONTAP.</block>
  <block id="884a92818052da7764b1c5b7589bd458" category="paragraph"><block ref="884a92818052da7764b1c5b7589bd458" category="inline-link-macro-rx"></block></block>
  <block id="2f0792348007b672e999da06f311bd6f" category="summary">Astra Trident è un orchestrator di storage open-source completamente supportato per container e distribuzioni Kubernetes, incluso Anthos.</block>
  <block id="8986a7e5e5d0b79b5251a648f9f67ef6" category="paragraph">Astra Trident è un orchestrator di storage open-source completamente supportato per container e distribuzioni Kubernetes, incluso Anthos. Trident lavora con l'intero portfolio di storage NetApp, incluso NetApp ONTAP, e supporta anche connessioni NFS e iSCSI. Trident accelera il workflow DevOps consentendo agli utenti finali di eseguire il provisioning e gestire lo storage dai sistemi storage NetApp senza richiedere l'intervento di un amministratore dello storage.</block>
  <block id="e16f8b7c3b79f3d80b3d5b5862b4481a" category="paragraph">Un amministratore può configurare una serie di backend di storage in base alle esigenze di progetto e ai modelli di sistemi di storage che consentono funzionalità di storage avanzate, tra cui compressione, tipi di dischi specifici e livelli di QoS che garantiscono un certo livello di performance. Una volta definiti, questi backend possono essere utilizzati dagli sviluppatori nei loro progetti per creare dichiarazioni di volume persistenti (PVC) e per collegare storage persistente ai propri container on-demand.</block>
  <block id="5be08e29583206baf8c89778e711c743" category="paragraph"><block ref="5be08e29583206baf8c89778e711c743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82c67e38528d52fd46de6b6ba7370337" category="paragraph">Astra Trident ha un rapido ciclo di sviluppo e, come Kubernetes, viene rilasciato quattro volte all'anno.</block>
  <block id="e79464fd5ecc0abac7a7f768780ea0f4" category="paragraph">È possibile trovare la documentazione relativa all'ultima versione di Astra Trident<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>. Matrice di supporto per quale versione di Trident è stata testata con la quale è possibile trovare la distribuzione Kubernetes<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>.</block>
  <block id="1efa4d2f8950cdd5154a6c130953c9f2" category="paragraph">Con la versione 22.04, è stato reso disponibile un grafico Helm per facilitare l'installazione dell'operatore Trident.</block>
  <block id="dee50dd9c6fd0b4d11789e8a074455c0" category="paragraph">Per informazioni dettagliate sull'installazione di Astra Trident, vedere<block ref="df28848dc0c60e349970187bfd75a0df" category="inline-link-rx"></block>.</block>
  <block id="6cfca408e9e3b476e6440302dbe3a550" category="section-title">Creare un backend di sistema storage</block>
  <block id="6d82ca16bfbce249e1f9ea541bff13ff" category="inline-link-macro">Creare un backend.</block>
  <block id="1e449644660ede384d0f8370105c8852" category="paragraph">Dopo aver completato l'installazione di Astra Trident Operator, è necessario configurare il backend per la piattaforma di storage NetApp specifica in uso. Seguire il link riportato di seguito per continuare l'installazione e la configurazione di Astra Trident.<block ref="0510ad325b52db9e306380d77ace3c72" category="inline-link-macro-rx"></block></block>
  <block id="14f4c7abe09c4481722f1fa6563f2604" category="section-title">Creare una classe di storage</block>
  <block id="69dd4ff02a34defa6f31ed5f8bb209f6" category="paragraph">Dopo aver creato il backend, è necessario creare una classe di storage che gli utenti Kubernetes specificheranno quando desiderano un volume. Kubernetes consente agli utenti di eseguire il provisioning dei volumi utilizzando le dichiarazioni di volumi persistenti (PVC) che specificano una classe di storage in base al nome. Fare clic sul collegamento riportato di seguito per creare una classe di storage.<block ref="034759ff187a64d8fb38f587d14777c0" category="inline-link-macro-rx"></block></block>
  <block id="50cbd0d28725f746b370915ee052232c" category="section-title">Eseguire il provisioning dinamico di un volume</block>
  <block id="72407fd74e9ce26b706ed85bc90bd124" category="inline-link-macro">Creare un PVC</block>
  <block id="35a0b000c0ba5920cef3268fee2323b4" category="paragraph">È necessario creare un oggetto Kubernetes Persistent Volume claim (PVC) utilizzando la classe storage per eseguire il provisioning dinamico di un volume. Fare clic sul collegamento riportato di seguito per creare un oggetto PVC.<block ref="0af94896212bb2843496226f6871904c" category="inline-link-macro-rx"></block></block>
  <block id="279865aaa331ec925a99c3272eb45478" category="section-title">Utilizzare il volume</block>
  <block id="fed9c63a200801110024280f08877e16" category="inline-link-macro">Montare il volume in un pod</block>
  <block id="d822bbb4d6960be49b781e594679db64" category="paragraph">Il volume fornito nella fase precedente può essere utilizzato da un'applicazione montando il volume nel pod.il link seguente mostra un esempio.<block ref="48fadb04c46cf19aa1b5e274dd9b5da9" category="inline-link-macro-rx"></block></block>
  <block id="7a11d367cfedc152ce1db261fb8f21fd" category="inline-link-macro">Pagina successiva: Opzioni di configurazione avanzate per anthos.</block>
  <block id="fca5cd0af87c3fa0c3d74ee21a3d346f" category="paragraph"><block ref="fca5cd0af87c3fa0c3d74ee21a3d346f" category="inline-link-macro-rx"></block></block>
  <block id="f9d11737e933d637293dde1af50cc17c" category="inline-link-macro">questo documento</block>
  <block id="8e6bdc78726b4f56217f2db215176c4c" category="paragraph">Per l'installazione e la configurazione di Astra Trident per il supporto di Astra Control Center, vedere <block ref="a26f48e8d5c30c46f5b177e7942c3e6b" category="inline-link-macro-rx"></block>.</block>
  <block id="5a45cefd7ffdd292bbc23212059fae63" category="paragraph">In un ambiente connesso al cloud, il centro di controllo Astra utilizza Cloud Insights per fornire monitoraggio avanzato e telemetria. In assenza di una connessione Cloud Insights, sono disponibili funzioni limitate di monitoraggio e telemetria (7 giorni di metriche) ed esportate negli strumenti di monitoraggio nativi di Kubernetes (Prometheus e Grafana) attraverso endpoint di metriche aperte.</block>
  <block id="b5348ca8ff6fec2e5b760e7176813e60" category="paragraph">Oltre alla versione a pagamento di Astra Control Center, è disponibile una licenza di valutazione di 90 giorni. La versione di valutazione è supportata tramite e-mail e il canale slack della community. I clienti hanno accesso a queste risorse, ad altri articoli della Knowledge base e alla documentazione disponibile nella dashboard di supporto dei prodotti.</block>
  <block id="f7606168abf643ab18d0fa39eaf87445" category="admonition">Per ogni installazione di OpenShift in un sito è consigliabile disporre di una SVM dedicata per lo storage persistente. Le implementazioni multi-sito richiedono sistemi storage aggiuntivi.</block>
  <block id="cdcf8f111b01a0c0037e638c481f80b0" category="admonition">Le installazioni di Docker devono avere una versione di Docker superiore alla 20.10 e le installazioni di Podman devono avere una versione di podman superiore alla 3.0.</block>
  <block id="22a3cd730895fa6285f7ee2b7838bc34" category="list-text">Creare o ottenere il file kubeconfig con accesso amministratore al cluster {k8s_usercluster_name} su cui deve essere installato Astra Control Center.</block>
  <block id="bcd2576f09ac9988bca57ac067028342" category="section-title">Fasi successive all'installazione</block>
  <block id="f1712afd3ab64493ad6802bfa9e5be87" category="list-text">Controllare<block ref="83f93b05da174976bd534cc67ad9f7b4" prefix=" " category="inline-code"></block> registri per verificare che l'installazione sia stata completata.</block>
  <block id="da44b5941c7cfd27a6f5686a3168f332" category="list-text">Quando si accede all'interfaccia grafica di Astra Control Center per la prima volta utilizzando l'indirizzo email admin fornito in CRD, è necessario modificare la password.</block>
  <block id="dc89b61e16e84216193885f3a7c62fb9" category="inline-link-macro">Avanti: Registra i tuoi Red Hat OpenShift Clusters.</block>
  <block id="13d5bf8d97a187ca5d13b7429c268342" category="paragraph"><block ref="13d5bf8d97a187ca5d13b7429c268342" category="inline-link-macro-rx"></block></block>
  <block id="872c01365a01300e2a8a772cd65e51b1" category="summary">In questa pagina sono riportate le istruzioni di installazione e configurazione per il bilanciamento del carico del carico di scarico.</block>
  <block id="b0215348c4b61c9ef3af7e95c45db79b" category="doc">Installazione di bilanciatori di carico seesaw</block>
  <block id="1ffbf83c6ff924ed568f0f88c922ac88" category="paragraph">Questa pagina elenca le istruzioni di installazione e configurazione per il bilanciamento del carico gestito da seesaw.</block>
  <block id="2498fd03c323b46a1d209aa07977fa55" category="paragraph">Seesaw è il bilanciamento del carico di rete gestito predefinito installato in un cluster anthos su ambiente VMware dalle versioni 1.6 alla 1.10.</block>
  <block id="1de0bfc08643a28f36a8fcd5662e17f0" category="section-title">Installazione del bilanciamento del carico di scarico</block>
  <block id="7e83a37698e612c5150b6c3a383cf59b" category="paragraph">Il bilanciamento del carico seesaw è completamente integrato con i cluster anthos su VMware e ha eseguito l'implementazione automatica come parte delle configurazioni dei cluster Admin e User. Sono presenti blocchi di testo in<block ref="c6ce65430f0e0c334f6b50da737f2e9b" prefix=" " category="inline-code"></block> i file di configurazione che devono essere modificati per fornire informazioni sul bilanciamento del carico, quindi prima dell'implementazione del cluster è necessario eseguire un ulteriore passaggio per implementare il bilanciamento del carico utilizzando il sistema integrato<block ref="fb87177c7509d5723aa1bbc241ec2f7b" prefix=" " category="inline-code"></block> tool.</block>
  <block id="3d4d180e7186ad7195269636446a1c4c" category="admonition">I bilanciatori di carico Seesaw possono essere implementati in modalità ha o non ha. Ai fini di questa convalida, il bilanciamento del carico di sewaw è stato implementato in modalità non ha, che è l'impostazione predefinita. Per scopi di produzione, NetApp consiglia di implementare seesaw in una configurazione ha per garantire tolleranza agli errori e affidabilità.</block>
  <block id="613f73d2545e2e4434e09e47400d96a6" category="paragraph">Ogni file di configurazione contiene una sezione, rispettivamente per il cluster di amministrazione e per ogni cluster di utenti che si sceglie di implementare, per configurare il bilanciamento del carico in modo che venga gestito da anthos on-Prem.</block>
  <block id="aa2bdb165616b7814c712fd55ecd1ce8" category="paragraph">Il testo seguente è un esempio della configurazione della partizione per il cluster GKE-Admin. I valori che devono essere non commentati e modificati vengono inseriti in grassetto di seguito:</block>
  <block id="71f92aabf82706f3d2a00af1b3a34f95" category="paragraph">Anche il bilanciamento del carico di sequilazione ha un'unità statica separata<block ref="d218bc0ba36a7fb2d7aea32df7659206" prefix=" " category="inline-code"></block> file che è necessario fornire per ogni implementazione del cluster. Questo file deve trovarsi nella stessa directory relativa a.<block ref="c6ce65430f0e0c334f6b50da737f2e9b" prefix=" " category="inline-code"></block> il file di implementazione o il percorso completo devono essere specificati nella sezione precedente.</block>
  <block id="cda0b5b1eab2f931076d0edc39a6920a" category="paragraph">Un esempio di<block ref="1db10b36979626249cbedcd8e8818146" prefix=" " category="inline-code"></block> il file è simile al seguente script:</block>
  <block id="b7e1a8e2925f8cb0b4f88b8532edd6d7" category="admonition">Questo file fornisce il gateway e la netmask per la rete che il bilanciamento del carico fornisce al cluster sottostante, nonché l'IP di gestione e il nome host per la macchina virtuale che viene implementata per eseguire il bilanciamento del carico.</block>
  <block id="4f8cee548fdf2c886e16bf694eb06522" category="paragraph"><block ref="4f8cee548fdf2c886e16bf694eb06522" category="inline-link-macro-rx"></block></block>
  <block id="fdd1d4ba64f526087e6e49e35a884fbd" category="summary">Questa sezione è dedicata alle personalizzazioni che gli utenti del mondo reale dovrebbero eseguire durante l'implementazione di questa soluzione in produzione, ad esempio l'implementazione di istanze personalizzate di bilanciamento del carico.</block>
  <block id="b432301f7ba469598e6ea2eb86e4859a" category="paragraph">In genere, la soluzione più semplice da implementare è la migliore, ma in alcuni casi sono necessarie personalizzazioni avanzate per soddisfare i requisiti o le specifiche di un'applicazione specifica o dell'ambiente in cui la soluzione viene implementata. A tal fine, la soluzione Red Hat OpenShift con NetApp consente le seguenti personalizzazioni per soddisfare queste esigenze.</block>
  <block id="2642cf401e87de575eae139953f87134" category="admonition">In questa sezione sono state documentate alcune opzioni di configurazione avanzate, come l'utilizzo di bilanciatori di carico di terze parti o la creazione di un registro privato per l'hosting di immagini container personalizzate, entrambi prerequisiti per l'installazione di NetApp Astra Control Center.</block>
  <block id="02b655f637212514780af2795fd74fc4" category="paragraph">Le pagine seguenti contengono informazioni aggiuntive sulle opzioni di configurazione avanzate validate nella soluzione Red Hat OpenShift con NetApp:</block>
  <block id="5aad41fe64600c5795950512637ebae3" category="inline-link-macro">Avanti: Analisi delle opzioni di bilanciamento del carico.</block>
  <block id="0b44acd6b2e7596e640212aa28de05c5" category="paragraph"><block ref="0b44acd6b2e7596e640212aa28de05c5" category="inline-link-macro-rx"></block></block>
  <block id="ee1514b17e642c9cd1384a20cec220e3" category="summary">Il video a cui si accede da questa pagina mostra alcune delle funzionalità documentate in questo documento.</block>
  <block id="17c3771ed0b6c1ae15740eff715e9922" category="doc">Video e demo</block>
  <block id="9ea2cbade31de8af1dca89093e681575" category="paragraph">Il seguente video mostra alcune delle funzionalità descritte in questo documento:</block>
  <block id="f1633856fe511230f9c635e7a1c53316" category="inline-link-macro">Video: Implementazione di Trident sul cluster anthos 1.14</block>
  <block id="cf1f8100313c03361151f9caa6715bac" category="paragraph"><block ref="cf1f8100313c03361151f9caa6715bac" category="inline-link-macro-rx"></block></block>
  <block id="eec34a14279b64231b91793978a204da" category="paragraph"><block ref="eec34a14279b64231b91793978a204da" category="inline-link-macro-rx"></block></block>
  <block id="bbdfa4f0841eb6d317a11ae76992b8b8" category="summary">Questa sezione è dedicata all'analisi delle opzioni di bilanciamento del carico per gli utenti che desiderano personalizzare la propria anthos con l'implementazione NetApp.</block>
  <block id="288c554e356764c1144e77f0d78f97bf" category="doc">Analisi delle opzioni di bilanciamento del carico</block>
  <block id="807a04fd6be3315608f66b00ab708987" category="paragraph">Un'applicazione implementata in anthos è esposta al mondo da un servizio fornito da un bilanciamento del carico implementato nell'ambiente anthos on-premise.</block>
  <block id="b935e49429349d1edf159cd09a0b8ff5" category="paragraph">Le seguenti pagine contengono informazioni aggiuntive sulle opzioni di bilanciamento del carico validate nella soluzione anthos con NetApp:</block>
  <block id="abb33c60fb7710d77680621bb6bb0433" category="inline-link-macro">Installazione di F5 BIG-IP load balancer</block>
  <block id="bf19992eca1061913e185b60f91a8344" category="list-text"><block ref="bf19992eca1061913e185b60f91a8344" category="inline-link-macro-rx"></block></block>
  <block id="297afb95cdd3600afb3f67c77b24215f" category="list-text"><block ref="297afb95cdd3600afb3f67c77b24215f" category="inline-link-macro-rx"></block></block>
  <block id="0395f03c04f82443f0fc31b418d2ded6" category="list-text"><block ref="0395f03c04f82443f0fc31b418d2ded6" category="inline-link-macro-rx"></block></block>
  <block id="6f838db94915ec121c6b32b1df99a983" category="inline-link-macro">Avanti: Installazione di F5 BIG-IP Load Balancer.</block>
  <block id="ecdb02c5420667abdb9a61d02af359c2" category="paragraph"><block ref="ecdb02c5420667abdb9a61d02af359c2" category="inline-link-macro-rx"></block></block>
  <block id="87f76f310cf20e85a098d49fa77367e5" category="doc">Anthos Clusters su VMware</block>
  <block id="206188ac4e8ec83453b82a36311f1a25" category="paragraph">Anthos Clusters su VMware è un'estensione di Google Kubernetes Engine implementata nel data center privato di un utente finale. Un'organizzazione può implementare le stesse applicazioni progettate per essere eseguite in container in Google Cloud nei cluster Kubernetes on-premise. I cluster Anthos su VMware possono essere implementati in un ambiente VMware vSphere esistente nel data center, risparmiando sulle spese di capitale e consentendo operazioni di implementazione e scalabilità più rapide.</block>
  <block id="b107e7085d2931bbe4118d8c5eed9643" category="paragraph">L'implementazione dei cluster anthos su VMware include i seguenti componenti:</block>
  <block id="305e92355c5c05eac28d2fbad20eaa5c" category="list-text">*Anthos admin workstation.* un host di implementazione da cui<block ref="fb87177c7509d5723aa1bbc241ec2f7b" prefix=" " category="inline-code"></block> e.<block ref="0f12ee5c9f1dd90158580f1c292b0d37" prefix=" " category="inline-code"></block> I comandi possono essere eseguiti per implementare e interagire con le implementazioni di anthos.</block>
  <block id="3cd74a54f5924b896bf9cb97397e8b35" category="list-text">*Admin cluster.* il cluster iniziale implementato durante la configurazione dei cluster anthos su VMware. Questo cluster gestisce tutte le azioni del cluster utente subordinate, incluse l'implementazione, la scalabilità e l'aggiornamento.</block>
  <block id="11b774f9c0d1531100a341b6da7d98fa" category="list-text">*Cluster utente.* ogni cluster utente viene implementato con la propria istanza o partizione di bilanciamento del carico, consentendo di agire come cluster Kubernetes standalone per singoli utenti o gruppi, contribuendo a ottenere una multi-tenancy completa.</block>
  <block id="b4dfd3f706cb0162d524cf7c36093e7c" category="paragraph">La seguente figura mostra una descrizione di un'implementazione di anthos-Clusters-on-VMware.</block>
  <block id="1780877562a197bb240c255e7ebc64a6" category="paragraph"><block ref="1780877562a197bb240c255e7ebc64a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="section-title">Benefici</block>
  <block id="348ed6380fe1c4753877d1f13d95d39a" category="paragraph">I cluster Anthos su VMware offrono i seguenti vantaggi:</block>
  <block id="cf97925041bebbd35543bc4fc24fa499" category="list-text">*Multi-tenancy avanzata.* a ciascun utente finale può essere assegnato il proprio cluster utente, implementato con le risorse virtuali necessarie per il proprio ambiente di sviluppo.</block>
  <block id="f34111b15d3f3387462dd512dde1392f" category="list-text">*Risparmi sui costi.* gli utenti finali possono ottenere risparmi significativi sui costi implementando più cluster di utenti nello stesso ambiente fisico e utilizzando le proprie risorse fisiche per le implementazioni delle applicazioni invece di fornire risorse nel proprio ambiente Google Cloud o su grandi cluster bare-metal.</block>
  <block id="a6c34625dcf8367e84732b5219f81cb7" category="list-text">*Sviluppare e pubblicare.* le implementazioni on-premise possono essere utilizzate mentre le applicazioni sono in fase di sviluppo, il che consente di testare le applicazioni nella privacy di un data center locale prima di essere rese pubblicamente disponibili nel cloud.</block>
  <block id="844236b21d302f8c93eda00636abfff8" category="list-text">*Requisiti di sicurezza.* i clienti con maggiori problemi di sicurezza o set di dati sensibili che non possono essere memorizzati nel cloud pubblico sono in grado di eseguire le proprie applicazioni dalla sicurezza dei propri data center, soddisfacendo così i requisiti organizzativi.</block>
  <block id="f89d1a459fed3d81a3b4a7360d0e85fc" category="list-text">*VMware vSphere vMotion.* VMware vCenter consente di eseguire la migrazione a caldo delle macchine virtuali tra i nodi del cluster, su richiesta e senza interruzioni.</block>
  <block id="4418ae814387892bd88d45091a182234" category="list-text">*VSphere High Availability.* per evitare interruzioni in caso di guasti agli host, VMware vSphere consente di eseguire il clustering e la configurazione degli host in base all'alta disponibilità. Le macchine virtuali che vengono interrompite da un guasto dell'host vengono riavviati a breve su altri host del cluster, ripristinando i servizi.</block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">Requisiti hardware</block>
  <block id="a623a8d0366bf079411aa30be45b2d10" category="section-title">Calcolo</block>
  <block id="2c912ca37607e38556f15eebae425241" category="paragraph">Google Cloud richiede periodicamente la convalida aggiornata delle piattaforme server dei partner con le nuove release di anthos attraverso il programma per partner della piattaforma anthos Ready. È possibile trovare un elenco delle piattaforme server attualmente validate e delle versioni di anthos supportate<block ref="3b2369e07f297fb9367d6c18ca70e2ac" category="inline-link-rx"></block>.</block>
  <block id="696c660ff8d9323e55146a6dbd4e4088" category="section-title">Sistema operativo</block>
  <block id="69da39b403ff0537d2282cb291d4397c" category="paragraph">I cluster Anthos su VMware possono essere implementati in ambienti vSphere 6 e 7, in base alla scelta del cliente, in modo da soddisfare le esigenze della propria infrastruttura di data center corrente.</block>
  <block id="e7a811d106a4076d6c6992a7b97734a0" category="paragraph">La seguente tabella contiene un elenco delle versioni di vSphere utilizzate da NetApp e dai partner per la convalida della soluzione.</block>
  <block id="64d354dc5879cf570ce7b4ef676e75bd" category="cell">Sistema operativo</block>
  <block id="b8e7b465df7c5979dc731d06e84ce2cf" category="cell">Rilasciare</block>
  <block id="97f1ca2cfbf4529686b9719bf26e07c0" category="cell">Versioni anthos</block>
  <block id="23d300c91b3d48f94c1e7f5953ad3e5e" category="cell">7.0U3</block>
  <block id="9f281f23fa0eaa9fab3de640f4c4ed29" category="cell">1.14</block>
  <block id="26181b11798a17989dc697461dc3e9d0" category="section-title">Hardware aggiuntivo</block>
  <block id="89f7e5d7117ac9eb1ece116273f5f012" category="paragraph">Per completare l'implementazione di anthos con NetApp come soluzione completamente validata, NetApp e i nostri partner hanno testato altri componenti del data center per il networking e lo storage.</block>
  <block id="9e5fa7e53550abb6c768c926e7888df7" category="paragraph">La tabella seguente contiene informazioni su questi componenti dell'infrastruttura aggiuntivi.</block>
  <block id="c0bd7654d5b278e65f21cf4e9153fdb4" category="cell">Produttore</block>
  <block id="b2311a2cf7a04db2bfe860c3fa17635c" category="cell">Componente hardware</block>
  <block id="fe02a8fc8838381700e175498b8e1db0" category="cell">Mellanox</block>
  <block id="7b42b4827c459034b51ee8ce9f497ca3" category="cell">switch (rete dati)</block>
  <block id="7b1d1185b835814de783483f686e9825" category="cell">Cisco</block>
  <block id="d5cbf018e46e897c3774dc4576d35dbe" category="cell">switch (rete di gestione)</block>
  <block id="cfaa375bf6c7f9fcc1bc04d4f30c9154" category="cell">NetApp</block>
  <block id="4c6ba3c2ecfdab7b2b5151a4715c51c0" category="cell">Sistema storage AFF</block>
  <block id="8bb152d8bbc90b878b63c05b6b953334" category="section-title">Software aggiuntivo</block>
  <block id="dd4a9a41d8672c9659041812469e1df2" category="paragraph">La seguente tabella include un elenco delle versioni software implementate nell'ambiente di convalida.</block>
  <block id="da0d53141f6343167596fe8598964773" category="cell">Software Name (Nome software)</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="eba1f3287bdc33dfa25c084b5e15a4c5" category="cell">9.12.1</block>
  <block id="8dfda84fc7f59655e20a770603bf9231" category="cell">23.01</block>
  <block id="a6eee2bc9df13513ff08680b88b5140c" category="paragraph">Durante la convalida della piattaforma anthos Ready eseguita da NetApp, l'ambiente di laboratorio è stato costruito sulla base del seguente diagramma, che ci ha consentito di testare diversi scenari utilizzando diversi backend di storage NetApp ONTAP.</block>
  <block id="ba18949144254244b0c22a4dda957809" category="paragraph"><block ref="ba18949144254244b0c22a4dda957809" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13d18f8604b3585f7ab88b87766a8d38" category="paragraph">Prima dell'implementazione di anthos, è necessario disporre della seguente infrastruttura:</block>
  <block id="92b7a761f185f74bf3bf9d2229c67a28" category="list-text">Un server DHCP disponibile per fornire locazioni di indirizzi di rete on-demand, nel caso in cui i cluster debbano scalare dinamicamente.</block>
  <block id="8256d4d5c73a64213343972bedd38f45" category="section-title">Implementare anthos in un cluster ESXi di almeno tre nodi</block>
  <block id="0dc619d5fd0af9a7a1c5ddea5b3e05a4" category="paragraph">Sebbene sia possibile installare anthos in un cluster vSphere di meno di tre nodi a scopo dimostrativo o di valutazione, questa operazione non è consigliata per i carichi di lavoro di produzione. Anche se due nodi consentono la tolleranza di base ha e fault tolerance, una configurazione del cluster anthos deve essere modificata per disattivare l'affinità host predefinita e questo metodo di implementazione non è supportato da Google Cloud.</block>
  <block id="150754dbd257c09eef8557a399e5ebc2" category="paragraph">La distribuzione dei nodi cluster anthos su più nodi hypervisor può essere ottenuta abilitando l'affinità di macchine virtuali e host.</block>
  <block id="659aed3f7f249a658860ff0d51cdef11" category="paragraph">Per configurare i gruppi di affinità, fare riferimento al collegamento appropriato riportato di seguito per la versione di VMware vSphere in uso.</block>
  <block id="bfe724d354657c9ac5cef22bd231f66f" category="inline-link">Documentazione vSphere 7.0: Utilizzo delle regole di affinità DRS</block>
  <block id="10c2b11d36730909ac14bcf903f9c456" category="paragraph"><block ref="0817a5be4b4f4733045646ef5cffc66c" category="inline-link-rx"></block>.<block ref="211975e132e07e8f3a0d0d18ff3759e5" category="inline-link-rx"></block>.</block>
  <block id="67243afe565a819d977d538c55049340" category="admonition">Anthos dispone di un'opzione di configurazione in ogni singolo utente<block ref="c6ce65430f0e0c334f6b50da737f2e9b" prefix=" " category="inline-code"></block> File per creare automaticamente regole di affinità dei nodi che possono essere attivate o disattivate in base al numero di host ESXi nell'ambiente.</block>
  <block id="748635e1daf718400c0f3bdeb448cf73" category="inline-link-macro">Avanti: Anthos su bare metal.</block>
  <block id="3f3ed1875910e0d28d2c97b78338cc3d" category="paragraph"><block ref="3f3ed1875910e0d28d2c97b78338cc3d" category="inline-link-macro-rx"></block></block>
  <block id="13a74472f5a5018f40319d30a728d03e" category="paragraph">NetApp ONTAP è un potente tool software per lo storage con funzionalità come GUI intuitiva, API REST con integrazione dell'automazione, analisi predittive e azioni correttive informate dell'ai, aggiornamenti hardware senza interruzioni e importazione di storage incrociato.</block>
  <block id="f1bcd982a417f561201a3262b52a84d7" category="list-text">*NetApp SnapLock.* Amministrazione efficiente dei dati non riscrivibili, scrivendo su volumi speciali che non possono essere sovrascritti o cancellati per un determinato periodo.</block>
  <block id="96f474208f638efbbd85fac3a46a2ed4" category="paragraph">Per ulteriori informazioni su ONTAP, consultare<block ref="eb1214e3900207403ada8715d3d4c764" category="inline-link-rx"></block>.</block>
  <block id="697ac904ffe5f281c2b20466e99a46ec" category="paragraph"><block ref="697ac904ffe5f281c2b20466e99a46ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="678cbe37bb872d145128736b4650ef68" category="paragraph">NetApp offre solide piattaforme di storage all-flash (AFF) e ibride scale-out (FAS), realizzate su misura con performance a bassa latenza, protezione integrata dei dati e supporto multiprotocollo.</block>
  <block id="a150469d40f75f1df1e87a9558f50769" category="paragraph">Entrambi i sistemi sono basati sul software per la gestione dei dati NetApp ONTAP, il software per la gestione dei dati più avanzato del settore per una gestione dello storage semplificata, integrata nel cloud e altamente disponibile, in grado di offrire la velocità, l'efficienza e la sicurezza di livello Enterprise di cui ha bisogno il data fabric.</block>
  <block id="a9b90f3200d3b94ea47e85db3a435816" category="paragraph">Per ulteriori informazioni sulle piattaforme NETAPP AFF e FAS, fare clic su<block ref="629508ef5a91b5835f70894f34eed424" category="inline-link-rx"></block>.</block>
  <block id="28bbba0205a8bfd9f8f2da8b73522dc7" category="inline-link-macro">Pagina successiva: Panoramica delle integrazioni di storage NetApp.</block>
  <block id="941b2b9e397e77b597402b51e7ef131d" category="paragraph"><block ref="941b2b9e397e77b597402b51e7ef131d" category="inline-link-macro-rx"></block></block>
  <block id="858674153e1f55409f3ea08cdc502f53" category="inline-link-macro">Pagina successiva: Opzioni di configurazione avanzate.</block>
  <block id="9bb9f32bf0692d68fe53042de73b0c6a" category="paragraph"><block ref="9bb9f32bf0692d68fe53042de73b0c6a" category="inline-link-macro-rx"></block></block>
  <block id="7768400c23564e6141f156e229944614" category="summary">Anthos unisce le operazioni di sviluppo e IT su un'unica piattaforma per creare, implementare e gestire le applicazioni in modo coerente tra infrastrutture di cloud ibrido e on-premise. Anthos porta i cluster GKE Kubernetes direttamente nel tuo ambiente di data center, in formati virtuali o bare metal.</block>
  <block id="346f4310b75e0cc51fdf8a1db6149978" category="doc">Panoramica di anthos</block>
  <block id="89ef90a5be38c2b656627392eee1a2a9" category="paragraph">Anthos con NetApp è un'architettura di cloud ibrido verificata e basata su Best practice per l'implementazione on-premise di un ambiente Google Kubernetes Engine (GKE) in modo affidabile e affidabile. Questo documento di riferimento sull'architettura verificata di NetApp funge sia da guida di progettazione che da convalida dell'implementazione della soluzione anthos con NetApp implementata in ambienti virtuali e bare metal. L'architettura descritta in questo documento è stata convalidata da esperti in materia presso NetApp e Google Cloud per offrire i vantaggi dell'esecuzione di anthos nel tuo ambiente di data center aziendale.</block>
  <block id="72efb373513d77a08aa5dd7e375a418f" category="section-title">Anthos</block>
  <block id="5b1a0b45a2d6518143a0c9b299e736b4" category="paragraph">Anthos è una soluzione per data center di Kubernetes con cloud ibrido che consente alle organizzazioni di costruire e gestire moderne infrastrutture di cloud ibrido adottando al contempo flussi di lavoro agili incentrati sullo sviluppo delle applicazioni. Anthos su VMware, una soluzione basata su tecnologie open-source, viene eseguita on-premise in un'infrastruttura basata su VMware vSphere, in grado di connettersi e interagire con Anthos GKE in Google Cloud. L'adozione di container, service mesh e altre tecnologie trasformative consente alle organizzazioni di sperimentare cicli di sviluppo delle applicazioni coerenti e carichi di lavoro pronti per la produzione in ambienti locali e basati sul cloud. La seguente figura illustra la soluzione anthos e il modo in cui un'implementazione in un data center on-premise si interconnette con l'infrastruttura nel cloud.</block>
  <block id="ea2625d89edeb5ba9cb41ca58df54e93" category="paragraph">Anthos offre le seguenti funzionalità:</block>
  <block id="c10e0a21a04a29dfca9609b3ec4bab76" category="list-text">*Anthos Configuration management.* automatizza le policy e la sicurezza delle implementazioni ibride di Kubernetes.</block>
  <block id="e8c4d5cbaf3932ffa3fa7a097bff923e" category="list-text">*Anthos Service Mesh.* migliora l'osservabilità, la sicurezza e il controllo delle applicazioni con una mesh di servizi basata su Istio.</block>
  <block id="ed4b514e0a9558c7acbec81ecc5fe0e1" category="list-text">*Google Cloud Marketplace for Kubernetes Applications.* un catalogo di applicazioni container curate disponibili per una facile implementazione.</block>
  <block id="b2f70465e1ea6dcdc0843dc8ed3b7f55" category="list-text">*Migrazione per anthos.* migrazione automatica di servizi fisici e macchine virtuali da on-premise al cloud.</block>
  <block id="52bc26b321a0b4cd1f91f7961a0783c8" category="list-text">*Stackdriver.* Servizio di gestione offerto da Google per la registrazione e il monitoraggio delle istanze cloud.</block>
  <block id="9d1fde4a5ff757f9279ca3b948ce8cb2" category="paragraph"><block ref="9d1fde4a5ff757f9279ca3b948ce8cb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a4777b2291cea091fd5877d9051ff1a3" category="section-title">Metodi di implementazione per anthos</block>
  <block id="0b7914a951055f790f36ed2e8e90bf01" category="section-title">Anthos su VMware</block>
  <block id="1702288bedca391f972e58fc0561e9ed" category="paragraph">I cluster Anthos implementati negli ambienti VMware vSphere sono facili da implementare, gestire e scalare rapidamente per la maggior parte dei carichi di lavoro Kubernetes dell'utente finale.</block>
  <block id="6f2ed4f8e4ebad80d7a306a0dc285156" category="paragraph">Per ulteriori informazioni sui cluster anthos su VMware, implementati con NetApp, visita la pagina <block ref="2f8f1280f6424b00276dc85d82fdb14f" category="inline-link-macro-rx"></block>.</block>
  <block id="aa69ca65720dd2e4eef99ebfb7816268" category="section-title">Anthos su bare metal</block>
  <block id="45a6d5427a773bd692ba6faf09ae9200" category="paragraph">I cluster anthos implementati su server bare metal sono indipendenti dall'hardware e consentono di selezionare una piattaforma di calcolo ottimizzata per il tuo caso d'utilizzo personalizzato.</block>
  <block id="18d4f7e36efb77494db296ea83bc4753" category="paragraph">Per ulteriori informazioni su anthos sui cluster bare metal implementati con NetApp, visitare il sito <block ref="eb911f2bc48f3132c014132a2870169f" category="inline-link-macro-rx"></block>.</block>
  <block id="d6c97ba6a05169248582981cf5627522" category="inline-link-macro">Avanti: Anthos Clusters su VMware.</block>
  <block id="9954fadf8d7c9568ecdb434ffa0a15c1" category="paragraph"><block ref="9954fadf8d7c9568ecdb434ffa0a15c1" category="inline-link-macro-rx"></block></block>
  <block id="58c0d00b6ee4c263f1fbe431b41eebf4" category="summary">Una volta gestiti i carichi di lavoro delle applicazioni da Astra Control Center, è possibile configurare le impostazioni di protezione per tali carichi di lavoro.</block>
  <block id="16dcf1808fc3c9a6f8342f97305d2ad6" category="doc">Proteggi le tue applicazioni</block>
  <block id="59af79c7ab060b4cca322301a4729f0c" category="section-title">Creazione di un'istantanea dell'applicazione</block>
  <block id="c0cf3c0162d106c6ee24b7afa9b79575" category="paragraph">Un'istantanea di un'applicazione crea una copia Snapshot di ONTAP che può essere utilizzata per ripristinare o clonare l'applicazione in un momento specifico in base a tale copia Snapshot.</block>
  <block id="9101281f33d55e682b1a47a44251fa0e" category="list-text">Per creare un'istantanea dell'applicazione, accedere alla scheda applicazioni &gt; gestite e fare clic sull'applicazione di cui si desidera creare una copia Snapshot. Fare clic sul menu a discesa accanto al nome dell'applicazione e fare clic su Snapshot.</block>
  <block id="c01290a8a623e36f9bcae85b910a3410" category="inline-image-macro">Pulsante Astra Control Center snapshot</block>
  <block id="b09383080793dfb527084933760af6ed" category="paragraph"><block ref="b09383080793dfb527084933760af6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f372cf1de9e60f6875a0b24a5c28b07" category="list-text">Inserire i dettagli dell'istantanea, fare clic su Next (Avanti), quindi su Snapshot (istantanea). La creazione dello snapshot richiede circa un minuto e lo stato diventa disponibile dopo la creazione dello snapshot.</block>
  <block id="f40e241f10f15eb6887acbc81fec81b0" category="inline-image-macro">Astra Control Center crea snapshot</block>
  <block id="42dd75b4fbc849903d5d179a8e68d570" category="paragraph"><block ref="42dd75b4fbc849903d5d179a8e68d570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1853746a915bea325b8b576237c24427" category="section-title">Creazione di un backup dell'applicazione</block>
  <block id="c09bdf0c852b6f771b10fb71482778db" category="paragraph">Un backup di un'applicazione acquisisce lo stato attivo dell'applicazione e la configurazione delle risorse, le taglia in file e le memorizza in un bucket di storage a oggetti remoto.</block>
  <block id="72e328bb06195897c7a644970c61d3a2" category="paragraph">Per il backup e il ripristino delle applicazioni gestite nel centro di controllo Astra, è necessario configurare le impostazioni del superutente per i sistemi ONTAP di backup come prerequisito. A tale scopo, immettere i seguenti comandi.</block>
  <block id="3805fe09ab2fab11e5a88285db1ba4f1" category="paragraph">Per creare un backup dell'applicazione, attenersi alla seguente procedura:</block>
  <block id="17937980068cd45516e074151c756bab" category="list-text">Per creare un backup dell'applicazione gestita in Astra Control Center, accedere a Apps &gt; Managed (applicazioni &gt; gestite) e fare clic sull'applicazione di cui si desidera eseguire il backup. Fare clic sul menu a discesa accanto al nome dell'applicazione e fare clic su Backup.</block>
  <block id="bc230776554b8a63af328cf9f01124e1" category="inline-image-macro">Pulsante di backup di Astra Control Center</block>
  <block id="0929177ba68c50d4dd73a2a3311ac885" category="paragraph"><block ref="0929177ba68c50d4dd73a2a3311ac885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7bfa2a7b059f09c3a772620888e93ef4" category="list-text">Inserire i dettagli del backup, selezionare il bucket di storage a oggetti in cui memorizzare i file di backup e fare clic su Next (Avanti). Dopo aver esaminato i dettagli, fare clic su Backup. A seconda delle dimensioni dell'applicazione e dei dati, il backup può richiedere alcuni minuti. Lo stato del backup diventa disponibile una volta completato il backup.</block>
  <block id="e10781941ccd98298d2856b437b3fb4b" category="inline-image-macro">Astra Control Center crea backup</block>
  <block id="4ba6af660a8dd39dc1d12fb6ee80ba81" category="paragraph"><block ref="4ba6af660a8dd39dc1d12fb6ee80ba81" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b1fda3b0f36b6fd708a9871e1c19c50" category="section-title">Ripristino di un'applicazione</block>
  <block id="344aed2ab37311beed01bbd40d93caed" category="paragraph">Con la semplice pressione di un pulsante, è possibile ripristinare un'applicazione nello spazio dei nomi di origine nello stesso cluster o in un cluster remoto per la protezione delle applicazioni e il disaster recovery.</block>
  <block id="d587342349a123dddff71bef9eb7b6e6" category="paragraph">Per ripristinare un'applicazione, attenersi alla seguente procedura:</block>
  <block id="804e8c9205cc0caea9e5cb6645febba7" category="list-text">Accedere alla scheda applicazioni &gt; gestite e fare clic sull'applicazione in questione. Fare clic sul menu a discesa accanto al nome dell'applicazione e fare clic su Restore (Ripristina).</block>
  <block id="92955527b375720b2a586155a776c0ac" category="inline-image-macro">Pulsante clone di Astra Control Center</block>
  <block id="84eb14028ce6ae6f2bf17b71ebe50c69" category="paragraph"><block ref="84eb14028ce6ae6f2bf17b71ebe50c69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b33d7fda666bdb32a2be1f3783106a3c" category="list-text">Immettere il nome dello spazio dei nomi di ripristino, selezionare il cluster in cui si desidera ripristinarlo e scegliere se si desidera ripristinarlo da uno snapshot esistente o da un backup dell'applicazione. Fare clic su Avanti.</block>
  <block id="c4293ef1955d52694e7d2288b637df1a" category="inline-image-macro">Ripristino di Astra Control Center</block>
  <block id="7bbb08271e6b60bc55d6817c7e100528" category="paragraph"><block ref="7bbb08271e6b60bc55d6817c7e100528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9242e3e5428d2ddbd81dece3073767a" category="list-text">Nel riquadro di revisione, immettere<block ref="bb2ac0b8da1f64a3498af147ba43fc10" prefix=" " category="inline-code"></block> E fare clic su Restore (Ripristina) dopo aver esaminato i dettagli.</block>
  <block id="7d6d73878ae09dbfd1e5ee7a0ecab66c" category="inline-image-macro">Revisione del ripristino di Astra Control Center</block>
  <block id="b862f033546ae8bdc1bb091ad8b57023" category="paragraph"><block ref="b862f033546ae8bdc1bb091ad8b57023" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1b86c631d7b3beb0163beee546245df6" category="paragraph">La nuova applicazione passa allo stato di ripristino mentre Astra Control Center ripristina l'applicazione sul cluster selezionato. Una volta installate e rilevate tutte le risorse dell'applicazione da Astra, l'applicazione passa allo stato Available (disponibile).</block>
  <block id="9ff3c5458e4a8facc6e7c25656a3baf7" category="inline-image-macro">Scoperta della nuova app di Astra Control Center</block>
  <block id="81d066be6d2211bf186bc1960361d8e3" category="paragraph"><block ref="81d066be6d2211bf186bc1960361d8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4600d44abb914105737c3d4a802b87c" category="section-title">Clonare un'applicazione</block>
  <block id="5394f3451a07ae7dbe101ceb0725a004" category="paragraph">È possibile clonare un'applicazione nel cluster di origine o in un cluster remoto per scopi di sviluppo/test o protezione dell'applicazione e disaster recovery. La clonazione di un'applicazione all'interno dello stesso cluster sullo stesso backend di storage utilizza la tecnologia NetApp FlexClone, che clona i PVC all'istante e consente di risparmiare spazio di storage.</block>
  <block id="bf6a757407fc5616f49930e56f86f233" category="list-text">Per clonare un'applicazione, accedere alla scheda applicazioni &gt; gestite e fare clic sull'applicazione in questione. Fare clic sul menu a discesa accanto al nome dell'applicazione e fare clic su Clone (Clona).</block>
  <block id="1cfafd65804d582aac709fefcd3e60cd" category="paragraph"><block ref="1cfafd65804d582aac709fefcd3e60cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0ff29eefb84e5d7a2cdae616ae42213" category="list-text">Immettere i dettagli del nuovo spazio dei nomi, selezionare il cluster in cui si desidera clonarlo e scegliere se clonarlo da uno snapshot esistente, da un backup o dallo stato corrente dell'applicazione. Fare clic su Next (Avanti), quindi su Clone (Clona) nel Review pane (pannello di revisione) dopo aver esaminato i dettagli.</block>
  <block id="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="paragraph"><block ref="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c0e19abe22935505e774d4d3b2e8449" category="list-text">La nuova applicazione entra nello stato di rilevamento mentre Astra Control Center crea l'applicazione sul cluster selezionato. Una volta installate e rilevate tutte le risorse dell'applicazione da Astra, l'applicazione entra nello stato Available (disponibile).</block>
  <block id="60bae26bb7c1e8711f1e39a45fc7b6c7" category="paragraph"><block ref="60bae26bb7c1e8711f1e39a45fc7b6c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="957478b81604fc0a340d863f3b89a2da" category="summary">NetApp dispone di diverse piattaforme storage qualificate con il nostro Trident Storage Orchestrator per il provisioning dello storage per le applicazioni implementate su anthos.</block>
  <block id="77caa49b32b4fc8ce3276158f57f9229" category="doc">Panoramica dello storage NetApp</block>
  <block id="e961adb60321df286b916effec21c9d5" category="paragraph">NetApp dispone di diverse piattaforme di storage qualificate con Astra Trident Storage Orchestrator per il provisioning dello storage per le applicazioni implementate come container.</block>
  <block id="0c5e049b7be7649501696f84472d6820" category="paragraph"><block ref="0c5e049b7be7649501696f84472d6820" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82dc86caf99045e3dfd059ffe973d587" category="list-text">NetApp Cloud Volumes Service (GCP) e Azure NetApp Files offrono storage basato su file nel cloud.</block>
  <block id="e0219edd422866b0cdb0aaa5f2b9352e" category="list-text">Amazon FSX per NetApp ONTAP è un servizio completamente gestito su AWS che fornisce storage per casi di utilizzo basati su file.</block>
  <block id="7cdcf7845d98f304186a5184cd2161ac" category="inline-link-macro">Pagina successiva: NetApp ONTAP.</block>
  <block id="1a4c8966068ddb4b2fda6d5bc54054c3" category="paragraph"><block ref="1a4c8966068ddb4b2fda6d5bc54054c3" category="inline-link-macro-rx"></block></block>
  <block id="c0018d5f0e0d9decd39a8059cc2bc473" category="summary">Gli esempi forniti in questa pagina sono validazioni di soluzioni e casi di utilizzo per anthos con NetApp.</block>
  <block id="d48e549b4fdcc889e0243c53bbb4dda0" category="doc">Convalida della soluzione e casi di utilizzo</block>
  <block id="fc31dc82d7754f65126c60eab5625947" category="inline-link-macro">Installare un'applicazione utilizzando Google Cloud Console</block>
  <block id="627662d598c35dc9438ec1747d7766dc" category="paragraph"><block ref="627662d598c35dc9438ec1747d7766dc" category="inline-link-macro-rx"></block></block>
  <block id="f498970d77b95b37672534275d7e8b40" category="paragraph"><block ref="f498970d77b95b37672534275d7e8b40" category="inline-link-macro-rx"></block></block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">Astratto</block>
  <block id="6fd40b989d7667b2025880aec23fdf21" category="paragraph">Questo documento di riferimento fornisce la convalida dell'implementazione di Google Cloud anthos in diversi ambienti di data center convalidati da NetApp. Descrive inoltre l'integrazione dello storage con i sistemi di storage NetApp utilizzando Astra Trident Storage orchestrator per la gestione dello storage persistente e NetApp Astra Control Center per la gestione e la protezione delle applicazioni stateful. Infine, vengono analizzate e documentate una serie di validazioni delle soluzioni e casi di utilizzo reali.</block>
  <block id="9b6757a6af2937cac7096646ee8dedb8" category="summary">F5 BIG-IP è un Application Delivery Controller (ADC) che offre un'ampia gamma di servizi avanzati di gestione del traffico e di sicurezza di livello produttivo come il bilanciamento del carico L4-L7, l'offload SSL/TLS, DNS, firewall e molto altro ancora. Questi servizi aumentano drasticamente la disponibilità, la sicurezza e le performance delle applicazioni.</block>
  <block id="4f3422718812b2a40b70340da35b565c" category="paragraph">F5 BIG-IP è un Application Delivery Controller (ADC) che offre un'ampia gamma di servizi avanzati di gestione del traffico e di sicurezza di livello produttivo come il bilanciamento del carico L4-L7, l'offload SSL/TLS, DNS, firewall e altro ancora. Questi servizi aumentano notevolmente la disponibilità, la sicurezza e le performance delle applicazioni.</block>
  <block id="81d91349803cba0e1b0d0f84948ff37c" category="paragraph">F5 BIG-IP può essere implementato e utilizzato in vari modi, tra cui su hardware dedicato, nel cloud o come appliance virtuale on-premise. Fare riferimento alla documentazione qui per esplorare e implementare F5 BIG-IP.</block>
  <block id="402c558f65f9d58557e4d79511d71f01" category="paragraph">F5 BIG-IP è stata la prima delle soluzioni di bilanciamento del carico in bundle disponibili con anthos on-Prem ed è stata utilizzata in una serie delle prime validazioni dei partner anthos Ready per la soluzione anthos con NetApp.</block>
  <block id="cb9f661ea2c5b0b25cb936398de81286" category="admonition">F5 BIG-IP può essere implementato in modalità standalone o cluster. Ai fini di questa convalida, F5 BIG-IP è stato implementato in modalità standalone. Tuttavia, per scopi di produzione, NetApp consiglia di creare un cluster di istanze BIG-IP per evitare un singolo punto di errore.</block>
  <block id="0d3e8be481c0c23fd0a68da9a9340ef7" category="admonition">Un sistema F5 BIG-IP può essere implementato su hardware dedicato, nel cloud o come appliance virtuale on-premise con versioni superiori alla 12.x per l'integrazione con F5 CIS. Ai fini di questo documento, il sistema F5 BIG-IP è stato validato come appliance virtuale, ad esempio utilizzando L'edizione BIG-IP VE.</block>
  <block id="39bc153685f2a0c6d56db4227295a3b0" category="section-title">Release validate</block>
  <block id="b662a8c121a377d9111fe64265c8d819" category="paragraph">Questa soluzione utilizza l'appliance virtuale implementata in VMware vSphere. Il networking per l'appliance virtuale F5 Big-IP può essere configurato in una configurazione a due o tre armi in base all'ambiente di rete. L'implementazione di questo documento si basa sulla configurazione a due armi. Ulteriori informazioni sulla configurazione dell'appliance virtuale per l'utilizzo con anthos sono disponibili<block ref="f18a28d0c935319437c4d1b1e33e5728" category="inline-link-rx"></block>.</block>
  <block id="9c62eb7c12e4e6a75fc74fffecb2db09" category="paragraph">Il Solutions Engineering Team di NetApp ha convalidato le release riportate nella seguente tabella del nostro laboratorio per lavorare con le implementazioni di anthos on-Prem:</block>
  <block id="529a05ca6c1263aab080ec4f20754411" category="cell">Fare</block>
  <block id="a1fa27779242b4902f7ae3bdd5c6d508" category="cell">Tipo</block>
  <block id="37f438df6a6d5ba4c17ef8ca58562f00" category="cell">F5</block>
  <block id="90524e294c6b7accf9b320977f3f5baa" category="cell">VE. BIG-IP</block>
  <block id="bc75f10c94df92e80198364d879456ab" category="cell">15.0.1-0.0.11</block>
  <block id="c2c889e06ea18c0e72996bc4b43c8115" category="cell">16.1.0-0.0.19</block>
  <block id="7cd8fb6e31cc946c078d2740c76a9899" category="section-title">Installazione</block>
  <block id="674751c31a2db2596bf7788e2953b80f" category="paragraph">Per installare F5 BIG-IP, attenersi alla seguente procedura:</block>
  <block id="ee5cd6f83412e93266bf30ff048db6ff" category="list-text">Scaricare il file dell'applicazione virtuale Open Virtual Appliance (OVA) da F5<block ref="cafae381bde5e2381c6df42a3aa937c6" category="inline-link-rx"></block>.</block>
  <block id="fff9995f30a825c5d3e5709e7b78117a" category="admonition">Per scaricare l'appliance, l'utente deve registrarsi con F5. Forniscono una licenza demo di 30 giorni per Big-IP Virtual Edition Load Balancer. NetApp consiglia una licenza permanente da 10 Gbps per l'implementazione in produzione di un'appliance.</block>
  <block id="1a104d04970b6b80d8cf31f554404f4d" category="list-text">Fare clic con il pulsante destro del mouse su Infrastructure Resource Pool e selezionare Deploy OVF Template (implementa modello OVF Viene avviata una procedura guidata che consente di selezionare il file OVA appena scaricato nella fase 1. Fare clic su Avanti.</block>
  <block id="fdf7304b13d736c791bc745a330e7309" category="inline-image-macro">Implementazione di appliance Big-IP</block>
  <block id="930835cee46ee894bb92b5627c286380" category="paragraph"><block ref="930835cee46ee894bb92b5627c286380" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6762efea56447c717fea204b2676851" category="list-text">Fare clic su Next (Avanti) per continuare con ogni passaggio e accettare i valori predefiniti per ciascuna schermata visualizzata fino a quando non viene visualizzata la schermata di selezione della memoria. Selezionare il VM_Datastore in cui si desidera implementare la macchina virtuale, quindi fare clic su Avanti.</block>
  <block id="fbd07b7802c1a124a9359b27b9f46968" category="list-text">La schermata successiva presentata dalla procedura guidata consente di personalizzare le reti virtuali per l'utilizzo nell'ambiente. Selezionare VM_Network per il campo External (esterno) e Management_Network per il campo Management (Gestione). Interni e ha vengono utilizzati per le configurazioni avanzate dell'appliance F5 Big-IP e non sono configurati. Questi parametri possono essere lasciati soli oppure possono essere configurati per connettersi a gruppi di porte distribuiti non infrastrutturali. Fare clic su Avanti.</block>
  <block id="5869793ca55f5fc50960cbd965138c70" category="inline-image-macro">Implementazione dell'appliance Big_IP, parte 2</block>
  <block id="b395903460348cc88bfae6fcad255f21" category="paragraph"><block ref="b395903460348cc88bfae6fcad255f21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93353313944577e80d34c3d9491db6ce" category="list-text">Esaminare la schermata di riepilogo dell'appliance e, se tutte le informazioni sono corrette, fare clic su fine per avviare l'implementazione.</block>
  <block id="68b984a73f20c874fb80feeaa4621109" category="list-text">Una volta implementata l'appliance virtuale, fare clic con il pulsante destro del mouse e accenderla. Dovrebbe ricevere un indirizzo DHCP sulla rete di gestione. L'appliance è basata su Linux e dispone di VMware Tools, in modo da poter visualizzare l'indirizzo DHCP ricevuto nel client vSphere.</block>
  <block id="ca9eda681850d46169f2940362b1548f" category="inline-image-macro">Implementazione dell'appliance Big-IP, parte 3</block>
  <block id="9c7b1162de6217dfe316b9d57d67b16f" category="paragraph"><block ref="9c7b1162de6217dfe316b9d57d67b16f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d92e443c00989a23096c72b760af7de8" category="list-text">Aprire un browser Web e connettersi all'appliance utilizzando l'indirizzo IP indicato nella fase precedente. L'accesso predefinito è admin/admin e, dopo il primo accesso, l'appliance richiede immediatamente di modificare la password admin. Viene quindi visualizzata una schermata in cui è necessario accedere con le nuove credenziali.</block>
  <block id="dbe135d0d5ae1eb2c137c81f0ce0bdfb" category="inline-image-macro">Configurazione Big-IP</block>
  <block id="372bcca75330a5dc5675a722489ff49b" category="paragraph"><block ref="372bcca75330a5dc5675a722489ff49b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bdb0e3e1ff63b6d5f08545e207448035" category="list-text">La prima schermata richiede all'utente di completare l'utilità di configurazione. Avviare l'utility facendo clic su Next (Avanti).</block>
  <block id="6e7de45031877e6ff00d3069664fbcaf" category="inline-image-macro">Configurazione Big-IP, parte 2</block>
  <block id="cee8fbb1e19d03d10bbd1e01e76cf77b" category="paragraph"><block ref="cee8fbb1e19d03d10bbd1e01e76cf77b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8523c09995ae3cfb4593cd6c4e09029f" category="list-text">La schermata successiva richiede l'attivazione della licenza per l'appliance. Fare clic su Activate (attiva) per iniziare. Quando richiesto nella pagina successiva, incollare la chiave di licenza di valutazione di 30 giorni ricevuta al momento della registrazione per il download o la licenza permanente acquistata al momento dell'acquisto dell'appliance. Fare clic su Avanti.</block>
  <block id="b648434aacde9879c494bb807f510d0a" category="inline-image-macro">Configurazione Big-IP, parte 3</block>
  <block id="abc7fe3f8ac78f7eef2f5ca730be051c" category="paragraph"><block ref="abc7fe3f8ac78f7eef2f5ca730be051c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="38d2bfb14ed98f122ce9d9b9cdb2a127" category="admonition">Affinché il dispositivo esegua l'attivazione, la rete definita nell'interfaccia di gestione deve essere in grado di raggiungere Internet.</block>
  <block id="6ba845d7cd0e966d0a2a21209623a5b4" category="list-text">Nella schermata successiva, viene visualizzato il Contratto di licenza con l'utente finale (EULA). Se i termini della licenza sono accettabili, fare clic su Accept (Accetta).</block>
  <block id="c14be37e927625fe613c8c559de70df1" category="list-text">La schermata successiva conta il tempo trascorso durante la verifica delle modifiche di configurazione apportate finora. Fare clic su Continue (continua) per riprendere la configurazione iniziale.</block>
  <block id="48f2578529c2f8c811567604f610cb5f" category="inline-image-macro">Configurazione Big-IP, parte 4</block>
  <block id="7032ef2cca6e17b4d3590ecbbce7ff16" category="paragraph"><block ref="7032ef2cca6e17b4d3590ecbbce7ff16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c3d807fce3ffcb905b00324d2f7e2b9" category="list-text">La finestra Modifica configurazione si chiude e l'Utilità di configurazione visualizza il menu Provisioning risorse. Questa finestra elenca le funzionalità attualmente concesse in licenza e le allocazioni delle risorse correnti per l'appliance virtuale e ciascun servizio in esecuzione.</block>
  <block id="117c183bcbd703e6b0520f843e971c9b" category="list-text">Facendo clic sull'opzione di menu Platform (piattaforma) a sinistra è possibile apportare ulteriori modifiche alla piattaforma. Le modifiche includono l'impostazione dell'indirizzo IP di gestione configurato con DHCP, l'impostazione del nome host e del fuso orario in cui è installato l'appliance e la protezione dell'appliance dall'accessibilità SSH.</block>
  <block id="c9fd499e062b35d18ef68efd381c6c09" category="inline-image-macro">Configurazione Big-IP, parte 6</block>
  <block id="78df99aca47bd680a19574eebccf4249" category="paragraph"><block ref="78df99aca47bd680a19574eebccf4249" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fad130ca7ff2a3734a8b7547b3ebc404" category="list-text">Fare clic sul menu Network (rete), che consente di configurare le funzioni di rete standard. Fare clic su Next (Avanti) per avviare la Configurazione di rete standard.</block>
  <block id="f4e4f5e5f31a0b8312fb2338d9015dd0" category="inline-image-macro">Configurazione Big-IP, parte 7</block>
  <block id="72cb9d54a4958e24c358ee0871b24454" category="paragraph"><block ref="72cb9d54a4958e24c358ee0871b24454" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c574654bbbf1cf9927e54a1cf4152c71" category="list-text">La prima pagina della procedura guidata configura la ridondanza; lasciare le impostazioni predefinite e fare clic su Avanti. La pagina successiva consente di configurare un'interfaccia interna sul bilanciamento del carico. L'interfaccia 1.1 viene mappata alla VMNIC etichettata Internal nella procedura guidata di implementazione di OVF.</block>
  <block id="19ee7bbff17fca60aeffed9079a87c6b" category="inline-image-macro">Configurazione Big-IP, parte 8</block>
  <block id="1781760e35ea460b2019eb0440baf384" category="paragraph"><block ref="1781760e35ea460b2019eb0440baf384" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37f1b31abf7679b5f5e495d8796a48a7" category="admonition">Gli spazi in questa pagina per l'indirizzo IP automatico, la netmask e l'indirizzo IP mobile possono essere riempiti con un indirizzo IP non instradabile da utilizzare come segnaposto. È inoltre possibile utilizzare una rete interna configurata come gruppo di porte distribuito per i guest virtuali se si sta implementando la configurazione a tre armi. Per continuare con la procedura guidata, è necessario completarli.</block>
  <block id="93e0638cb95146eb8773223a90aa6d86" category="list-text">La pagina successiva consente di configurare una rete esterna utilizzata per mappare i servizi ai pod implementati in Kubernetes. Selezionare un IP statico dall'intervallo VM_Network, la subnet mask appropriata e un IP mobile dello stesso intervallo. L'interfaccia 1.2 viene mappata alla VMNIC etichettata External nella procedura guidata di implementazione di OVF.</block>
  <block id="803c8b846cb5b5c6c8d5a2b0b07f4dba" category="inline-image-macro">Configurazione Big-IP, parte 9</block>
  <block id="6909280d84c97f4c2d6301b2d570e37a" category="paragraph"><block ref="6909280d84c97f4c2d6301b2d570e37a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3966f18c8da763e8d9f315b3e44811e" category="list-text">Nella pagina successiva, è possibile configurare una rete ha interna se si stanno implementando più appliance virtuali nell'ambiente. Per procedere, è necessario compilare i campi Self-IP Address (Indirizzo IP automatico) e Netmask (maschera di rete) e selezionare Interface 1.3 (interfaccia VLAN), che viene mappata alla rete ha definita dalla creazione guidata dei modelli OVF.</block>
  <block id="9cd42351da162e75b1a0178bdd0ded20" category="inline-image-macro">Configurazione Big-IP, parte 10</block>
  <block id="ca2835359be5e4e2e79ed5b6fd777515" category="paragraph"><block ref="ca2835359be5e4e2e79ed5b6fd777515" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d469ac29aab926968093104ad6265df" category="list-text">La pagina successiva consente di configurare i server NTP. Fare clic su Next (Avanti) per continuare con la configurazione del DNS. I server DNS e l'elenco di ricerca dei domini devono essere già popolati dal server DHCP. Fare clic su Next (Avanti) per accettare le impostazioni predefinite e continuare.</block>
  <block id="97a60c27b370d45c17075cff06f473a3" category="list-text">Per il resto della procedura guidata, fare clic su Next (Avanti) per continuare con la configurazione avanzata del peering, la cui configurazione non rientra nell'ambito di questo documento. Quindi fare clic su fine per uscire dalla procedura guidata.</block>
  <block id="0953ce81fac634b21f33efe8dee24c28" category="list-text">Creare singole partizioni per il cluster di amministrazione anthos e per ciascun cluster utente implementato nell'ambiente. Fare clic su System (sistema) nel menu a sinistra, selezionare Users (utenti) e fare clic su Partition List (elenco partizioni).</block>
  <block id="ad99125325ea694a08a4db92eabb18a1" category="inline-image-macro">Configurazione Big-IP, parte 11</block>
  <block id="d71ac8787685cb0f3b8f800520d684b1" category="paragraph"><block ref="d71ac8787685cb0f3b8f800520d684b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99a0344c261b0475e6caf01bb585530f" category="list-text">La schermata visualizzata mostra solo la partizione comune corrente. Fare clic su Create (Crea) a destra per creare la prima partizione aggiuntiva e assegnarle un nome<block ref="7b8bd901f7c351d00688bb6fecf79a3c" prefix=" " category="inline-code"></block>. Quindi fare clic su Repeat (Ripeti) e assegnare un nome alla partizione<block ref="b328b4839c0f0e2bfc22ab6fca60065e" prefix=" " category="inline-code"></block>. Fare nuovamente clic sul pulsante Repeat (Ripeti) per assegnare un nome alla partizione successiva<block ref="916e48fa5c2bc8c7765c99a8f011dccb" prefix=" " category="inline-code"></block>. Infine, fare clic su fine per completare la procedura guidata. Viene visualizzata nuovamente la schermata elenco partizioni con tutte le partizioni elencate.</block>
  <block id="938c47fe40c045ae4bc242bf2339ab01" category="inline-image-macro">Configurazione Big-IP, parte 12</block>
  <block id="598f9d349e1cb4c318e78a0d182dd743" category="paragraph"><block ref="598f9d349e1cb4c318e78a0d182dd743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dc19630e1d9c7f2a85a541796c5ec51" category="paragraph">Ogni file di configurazione contiene una sezione, rispettivamente per il cluster di amministrazione e per ogni cluster di utenti che si sceglie di implementare per configurare il bilanciamento del carico in modo che venga gestito da anthos su Prem.</block>
  <block id="38779167fbee63015f17c4c1b453dd32" category="paragraph">Il seguente script è un esempio della configurazione della partizione per il cluster GKE-Admin. I valori che devono essere non commentati e modificati vengono inseriti in grassetto di seguito:</block>
  <block id="441be298f9b7d68522f3e6df5d9629e2" category="inline-link-macro">Avanti: Installazione dei bilanciatori di carico MetalLB.</block>
  <block id="9c79b190423dda0c207aac371557f50a" category="paragraph"><block ref="9c79b190423dda0c207aac371557f50a" category="inline-link-macro-rx"></block></block>
  <block id="e66e12138810859d8abf5fa2081fb491" category="summary">Come implementare un'applicazione sul cluster Anthos GKE in maniera preesistente, utilizzando Google Cloud Console.</block>
  <block id="0fedf382c8cab1bb4bd4137b2edd4ddf" category="doc">Implementare un'applicazione da Google Cloud Console Marketplace</block>
  <block id="db974f321885ec32e283b3ba19624bf5" category="list-text">Un cluster anthos implementato on-premise e registrato con Google Cloud Console</block>
  <block id="86baa7935f2da05d24c2736b997d56af" category="list-text">Bilanciamento del carico MetalLB configurato nel cluster anthos</block>
  <block id="0e4a5cc43eded7fb6f9688b4db42749c" category="list-text">Un account con autorizzazioni per implementare le applicazioni nel cluster</block>
  <block id="0abcad93e8aa42fe77227a82e7bfac88" category="list-text">Un account di fatturazione con Google Cloud se scegli un'applicazione con costi associati (opzionale)</block>
  <block id="241b7771ea8f8a56aa7c79c94ea05b45" category="section-title">Implementazione di un'applicazione</block>
  <block id="7519665b833135b7a83098238355d197" category="paragraph">Per questo caso di utilizzo, implementiamo una semplice applicazione WordPress su uno dei nostri cluster Anthos utilizzando Google Cloud Console. L'implementazione utilizza lo storage persistente fornito da NetApp ONTAP in uno storage predefinito. Vengono quindi illustrati due diversi metodi per modificare il servizio predefinito delle applicazioni in modo che il bilanciamento del carico MetalLB fornisca un indirizzo IP e lo esprima al mondo.</block>
  <block id="0f46ecb3b1113d47388dd5a45b007f77" category="paragraph">Per implementare un'applicazione in questo modo, attenersi alla seguente procedura:</block>
  <block id="284e9ebcc65faa3412015e1aef0b212f" category="list-text">Verificare che il cluster a cui si desidera eseguire l'implementazione sia accessibile in Google Cloud Console.</block>
  <block id="c5ae9e1da0751273beff7dba35e9f3a0" category="inline-image-macro">Cluster registrati</block>
  <block id="113157b1187558580348ca8d41e0e09d" category="paragraph"><block ref="113157b1187558580348ca8d41e0e09d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ffca2e9c9a134c6025fcd79da7b2c759" category="list-text">Selezionare applicazioni dal menu a sinistra, selezionare il menu delle opzioni a tre punti in alto e scegliere Deploy from Marketplace, che apre una nuova finestra dalla quale selezionare un'applicazione da Google Cloud Marketplace.</block>
  <block id="0684d335d9a7c1f72f6bfcd5a3f89e00" category="inline-image-macro">Application Marketplace</block>
  <block id="c2c2bcc598caddf4725c028c7db228b2" category="paragraph"><block ref="c2c2bcc598caddf4725c028c7db228b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1116a3fdba8715414e3ef4e4f99912" category="list-text">Cercare l'applicazione che si desidera installare, in questo caso WordPress.</block>
  <block id="822f5bce2ee65cbb4bdffaba2710ba34" category="inline-image-macro">Cerca in WordPress</block>
  <block id="660eb3f5a04738d18f35a59427836264" category="paragraph"><block ref="660eb3f5a04738d18f35a59427836264" category="inline-image-macro-rx" type="image"></block></block>
  <block id="510d39751378d8f38e07c02ea0fc6be6" category="list-text">Dopo aver selezionato l'applicazione WordPress, viene visualizzata una schermata di panoramica. Fare clic sul pulsante Configure (Configura).</block>
  <block id="10caa5e50634911a226bf4aadc5a0c7a" category="inline-image-macro">Schermata Panoramica di WordPress</block>
  <block id="096a5432cb51a4b959599922c18c06c1" category="paragraph"><block ref="096a5432cb51a4b959599922c18c06c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6ef5c869d6fe64bd1b351a45360b963" category="list-text">Nella pagina successiva è necessario selezionare il cluster in cui eseguire l'implementazione, nel nostro caso Demo-Cluster. Selezionare o creare un nuovo namespace e un nuovo nome di istanza dell'applicazione, quindi selezionare le classi di storage e le dimensioni dei volumi persistenti necessarie per l'applicazione WordPress e il relativo database MariaDB di supporto. In entrambi i casi, abbiamo scelto la classe di storage ONTAP-NAS-CSI.</block>
  <block id="355246a53a979cfb1041a2b1940f6879" category="inline-image-macro">Configurazione di WordPress</block>
  <block id="d888949dd50bbca6d60ecc23eaef49f9" category="paragraph"><block ref="d888949dd50bbca6d60ecc23eaef49f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45d655c70f06a3434e67cbfc80248a9a" category="admonition">Non selezionare Enable public IP Access (attiva accesso IP pubblico). In questo modo viene creato un servizio di tipo NodePort non accessibile da un'implementazione anthos on-premise.</block>
  <block id="afab588b2fdc93623ccf8cb877caf4da" category="list-text">Dopo aver fatto clic sul pulsante Deploy (implementa), viene visualizzata una pagina contenente i dettagli dell'applicazione. È possibile aggiornare questa pagina o accedere al cluster utilizzando la CLI per controllare lo stato dell'implementazione.</block>
  <block id="31e41095bfaa14799239e8d9ba7ad438" category="inline-image-macro">Dettagli dell'applicazione</block>
  <block id="d0354e2068a16698befdae7925d598c8" category="paragraph"><block ref="d0354e2068a16698befdae7925d598c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="182bdd798d19f66a7142e53dc7ba7d03" category="list-text">La CLI può essere utilizzata per controllare lo stato dell'applicazione durante la distribuzione eseguendo il comando per recuperare le informazioni sul pod nello spazio dei nomi dell'applicazione:<block ref="f33e7514e1b666008863c58a5b3b8fc3" prefix=" " category="inline-code"></block>.</block>
  <block id="4fdb8b8bf983b608be34dc4a03f63bae" category="inline-image-macro">Kubectl ottiene i pod</block>
  <block id="5d15d1dcdf1862334a130d3d7fe69ccc" category="paragraph"><block ref="5d15d1dcdf1862334a130d3d7fe69ccc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e9914dac3fe74f2b341b37fde931ccc8" category="admonition">Notare in questa schermata che esiste un pod deployer in uno stato di errore. Questo è normale. Questo pod è un pod di supporto utilizzato da Google Cloud Console per implementare l'applicazione che termina automaticamente dopo che gli altri pod hanno iniziato il processo di inizializzazione.</block>
  <block id="9d8881c161170e208f09b8b2a142a66f" category="list-text">Dopo alcuni istanti, verificare che l'applicazione sia in esecuzione.</block>
  <block id="ce0590d3b5f26b188a077af82f7344a2" category="inline-image-macro">Applicazione in esecuzione</block>
  <block id="011a851bc4637452cc423fc951144521" category="paragraph"><block ref="011a851bc4637452cc423fc951144521" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad3acabe74bca98e10c24bed74bda730" category="section-title">Esposizione dell'applicazione</block>
  <block id="76ce15c259c30934261379d5c782fb7a" category="paragraph">Una volta implementata l'applicazione, è possibile assegnarla a un IP raggiungibile in tutto il mondo in due modi.</block>
  <block id="636274e5bcac1260da12a33d8dae0b1e" category="section-title">Utilizzando Google Cloud Console</block>
  <block id="affe13ca759d7abbd8dd52510dcccb9d" category="paragraph">È possibile esporre l'applicazione utilizzando Google Cloud Console e modificando l'output YAML dei servizi in un browser per impostare un IP raggiungibile pubblicamente. A tale scopo, attenersi alla seguente procedura:</block>
  <block id="e14de37e4860e0a27178cce381f79223" category="list-text">In Google Cloud Console, fare clic su Services and Ingress (servizi e ingresso) nel menu a sinistra.</block>
  <block id="7888520f99ee2ce14da11b431d5ae318" category="inline-image-macro">Services e Ingress</block>
  <block id="a30c95bc1250f0f260b3859484a79e52" category="paragraph"><block ref="a30c95bc1250f0f260b3859484a79e52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6187f833f4cb9c4f7b8ee4db49498f1b" category="list-text">Fare clic su<block ref="038c7925bdf387b6bedcaa4b32ec3a83" prefix=" " category="inline-code"></block> servizio. Viene visualizzata la schermata Dettagli servizio. Fare clic sul pulsante Edit (Modifica) nella parte superiore.</block>
  <block id="d203ca99d4a0afdab1bcfe540a547944" category="inline-image-macro">Modificare i dettagli del servizio</block>
  <block id="572acf06c07873db504c906b27cd9089" category="paragraph"><block ref="572acf06c07873db504c906b27cd9089" category="inline-image-macro-rx" type="image"></block></block>
  <block id="668b0ecfd7e72dc665e312c2993930b3" category="list-text">Viene visualizzata la pagina editing Service Details contenente le informazioni YAML relative al servizio. Scorrere verso il basso fino a visualizzare<block ref="084d5d41838f6b2d8b0c1f1176d66d01" prefix=" " category="inline-code"></block> e il<block ref="3190100143eef75fa97ee36e98fa3f8b" prefix=" " category="inline-code"></block> valore, impostato su<block ref="8fa769eb2083a1e8b123c7328287e112" prefix=" " category="inline-code"></block>. Impostare questo valore su<block ref="a38b02b14f77fc6ad85cfb7df9d27b2e" prefix=" " category="inline-code"></block> E fare clic sul pulsante Save (Salva).</block>
  <block id="d6b6ff61b6af359d37d3635e95073c9d" category="inline-image-macro">Digitare ClusterIP value (valore IP cluster)</block>
  <block id="198f2e2e4e51b005096e30bd1dc74de8" category="paragraph"><block ref="198f2e2e4e51b005096e30bd1dc74de8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5f9f0194a478fbc7f5f93f46c2953de" category="inline-image-macro">Digitare LoadBalancer value</block>
  <block id="51301646eb8394e4ac0765ad84f0d777" category="paragraph"><block ref="51301646eb8394e4ac0765ad84f0d777" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7331da14461f4638eebbff81857db51" category="list-text">Quando si torna alla pagina Service Details (Dettagli servizio), il<block ref="e659b52eba1f0299b2d8ca3483919e72" prefix=" " category="inline-code"></block> ora gli elenchi<block ref="a38b02b14f77fc6ad85cfb7df9d27b2e" prefix=" " category="inline-code"></block> e a.<block ref="918d33b6c8dd822ec40bbef2e2f58f3e" prefix=" " category="inline-code"></block> Il campo elenca un indirizzo IP assegnato dal pool di MetalLB e la porta attraverso la quale l'applicazione è accessibile.</block>
  <block id="3ec7f6e26f5dfb369960a71540f97a1f" category="inline-image-macro">Dettagli del servizio finali</block>
  <block id="e5b2b641e4db64d79ddda6476267c442" category="paragraph"><block ref="e5b2b641e4db64d79ddda6476267c442" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74e17d078471c59b2bf53ed27db0fb1f" category="section-title">Applicazione di patch al servizio con Kubectl</block>
  <block id="f022ee3e39dabcf83208cc99a6eb4a8b" category="paragraph">È possibile esporre l'applicazione utilizzando CLI e<block ref="b40dfaf71508ce779421b1c4dde5f99f" prefix=" " category="inline-code"></block> Comando per modificare l'implementazione e impostare un indirizzo IP pubblicamente raggiungibile. A tale scopo, attenersi alla seguente procedura:</block>
  <block id="7d217d270c695202071f85ac46866514" category="list-text">Elencare i servizi associati ai pod nello spazio dei nomi con<block ref="3841f6ce7a9f7be216fe99eef26477f6" prefix=" " category="inline-code"></block> comando.</block>
  <block id="fe7c7c8f844859020a7db7a331ade810" category="inline-image-macro">List Services (servizi elenco)</block>
  <block id="45c0563dbcc7191f2f4360b2e8740e4a" category="paragraph"><block ref="45c0563dbcc7191f2f4360b2e8740e4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6969be1fd50af4592e0d142a1d8d70cd" category="list-text">Modificare il tipo di servizio da<block ref="8fa769eb2083a1e8b123c7328287e112" prefix=" " category="inline-code"></block> per digitare<block ref="5c89f521cbb8685d397906bd6ce0efa1" prefix=" " category="inline-code"></block> utilizzando il seguente comando:</block>
  <block id="ee64374fc07de409e3af533d716265a7" category="paragraph">A questo nuovo tipo di servizio viene assegnato automaticamente un indirizzo IP disponibile dal pool di MetalLB.</block>
  <block id="c2a179dcfc744c6d0e1f8e669f780a31" category="inline-image-macro">Servizio di patch per il bilanciamento del carico di lavoro</block>
  <block id="ee6e2870bddeced39fa0bbc481e1cd21" category="paragraph"><block ref="ee6e2870bddeced39fa0bbc481e1cd21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="515ddbc3d2b92a28024949cdc11effe0" category="section-title">Visitare l'applicazione sull'IP esterno esposto</block>
  <block id="9f32f710fb943684fe7ac71944e06000" category="paragraph">Ora che l'applicazione è esposta con un indirizzo IP pubblicamente raggiungibile, è possibile visitare la propria istanza di WordPress utilizzando un browser.</block>
  <block id="3922853243ef47d8d33c4ed74259c64a" category="inline-image-macro">Wordpress nel browser</block>
  <block id="d989de00c947c6c543a0711c796da0b3" category="paragraph"><block ref="d989de00c947c6c543a0711c796da0b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8921c6e9843ba7487c77f4dce1467111" category="summary">Il software NetApp Element offre performance modulari e scalabili, con ogni nodo di storage che offre capacità e throughput garantiti all'ambiente. I sistemi NetApp Element possono scalare da 4 a 100 nodi in un singolo cluster e offrire una serie di funzionalità avanzate di gestione dello storage.</block>
  <block id="53c583e55a36ad49234df678a2dbcf45" category="paragraph">Il software NetApp Element offre performance modulari e scalabili, con ogni nodo di storage che offre capacità e throughput garantiti all'ambiente. I sistemi NetApp Element possono scalare da 4 a 100 nodi in un singolo cluster e offrire una serie di funzionalità avanzate di gestione dello storage.</block>
  <block id="10a641cf7647f6970bad748b52bb253b" category="paragraph"><block ref="10a641cf7647f6970bad748b52bb253b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27765508a97a89684590658c3465fb70" category="inline-link">Sito Web di NetApp SolidFire</block>
  <block id="d37eaafbb6dfb29673d63ff988ff4f41" category="paragraph">Per ulteriori informazioni sui sistemi di storage NetApp Element, visitare il sito<block ref="0d1d77e6774527457304fa15f73899a1" category="inline-link-rx"></block>.</block>
  <block id="bd4ffcaabbe4a4f83fbfaaa2e34dc8a3" category="section-title">Reindirizzamento dell'accesso iSCSI e funzionalità di riparazione automatica</block>
  <block id="dbafa7c074ef7efc3c778b69c0ad31b5" category="paragraph">Il software NetApp Element sfrutta il protocollo di storage iSCSI, un metodo standard per incapsulare i comandi SCSI su una rete TCP/IP tradizionale. Quando gli standard SCSI cambiano o quando le performance delle reti Ethernet migliorano, il protocollo di storage iSCSI beneficia senza la necessità di modifiche.</block>
  <block id="23e6b910b28346537f5696478fffe779" category="paragraph">Sebbene tutti i nodi storage dispongano di un IP di gestione e di un IP di storage, il software NetApp Element annuncia un singolo indirizzo IP virtuale di storage (indirizzo SVIP) per tutto il traffico di storage nel cluster. Come parte del processo di accesso iSCSI, lo storage può rispondere che il volume di destinazione è stato spostato in un indirizzo diverso e quindi non può procedere con il processo di negoziazione. L'host quindi invia nuovamente la richiesta di accesso al nuovo indirizzo in un processo che non richiede alcuna riconfigurazione sul lato host. Questo processo è noto come reindirizzamento dell'accesso iSCSI.</block>
  <block id="b8603f3d585261d0005c7c5e51108d19" category="paragraph">Il reindirizzamento dell'accesso iSCSI è una parte chiave del cluster software NetApp Element. Quando viene ricevuta una richiesta di accesso all'host, il nodo decide quale membro del cluster deve gestire il traffico in base agli IOPS e ai requisiti di capacità per il volume. I volumi vengono distribuiti nel cluster software NetApp Element e ridistribuiti se un singolo nodo gestisce un volume eccessivo di traffico per i volumi o se viene aggiunto un nuovo nodo. Più copie di un determinato volume vengono allocate nell'array.</block>
  <block id="7f640668ae5a8fc28f807fe0d6b9128b" category="paragraph">In questo modo, se un guasto di un nodo è seguito da una ridistribuzione del volume, non vi è alcun effetto sulla connettività dell'host oltre a una disconnessione e all'accesso con reindirizzamento alla nuova posizione. Con il reindirizzamento dell'accesso iSCSI, un cluster software NetApp Element è un'architettura scale-out con riparazione automatica in grado di eseguire operazioni e aggiornamenti senza interruzioni.</block>
  <block id="5c8e89de2b8e6e2f103d858b59e5aca0" category="section-title">QoS del cluster software NetApp Element</block>
  <block id="16600c3602f9acbaa2286f34135f6bb8" category="paragraph">Un cluster software NetApp Element consente di configurare dinamicamente la qualità del servizio in base al volume. È possibile utilizzare le impostazioni QoS per volume per controllare le performance dello storage in base agli SLA definiti dall'utente. I seguenti tre parametri configurabili definiscono la QoS:</block>
  <block id="d91a826908d0c27cf5d21d2152292ab0" category="list-text">*IOPS minimi.* il numero minimo di IOPS sostenuti che il cluster software NetApp Element fornisce a un volume. Il livello minimo di IOPS configurato per un volume è il livello garantito di performance per un volume. Le performance per volume non scendono al di sotto di questo livello.</block>
  <block id="f8cd3dfe225577e230dc2699ebbbfe34" category="list-text">*IOPS massimo.* numero massimo di IOPS sostenuti che il cluster software NetApp Element fornisce a un determinato volume.</block>
  <block id="827b5871d6ce8f2203a567ef3024f072" category="list-text">*IOPS burst.* numero massimo di IOPS consentito in uno scenario a burst breve. L'impostazione della durata del burst è configurabile, con un valore predefinito di 1 minuto. Se un volume è stato eseguito al di sotto del livello IOPS massimo, vengono accumulati i crediti burst. Quando i livelli di performance diventano molto elevati e vengono spinti, sul volume sono consentiti brevi burst di IOPS oltre i massimi IOPS.</block>
  <block id="e95bb6f1e85d1ffe0eb983fd5e0fbde8" category="section-title">Multi-tenancy</block>
  <block id="086d1eacd91102f734387f0266326344" category="paragraph">La multi-tenancy sicura si ottiene con le seguenti funzionalità:</block>
  <block id="97bee3e8d0db89b2cd19eba861763e7a" category="list-text">*Autenticazione sicura.* il protocollo CHAP (Challenge-Handshake Authentication Protocol) viene utilizzato per l'accesso sicuro ai volumi. Il protocollo LDAP (Lightweight Directory Access Protocol) viene utilizzato per l'accesso sicuro al cluster per la gestione e la creazione di report.</block>
  <block id="3918507b16aa3cc38274c29da446d90f" category="list-text">*Volume Access Group (VAG).* facoltativamente, i VAG possono essere utilizzati al posto dell'autenticazione, mappando qualsiasi numero di iSCSI Initiator-Specific iSCSI Qualified Name (IQN) in uno o più volumi. Per accedere a un volume in un VAG, l'IQN dell'iniziatore deve essere nell'elenco IQN consentito per il gruppo di volumi.</block>
  <block id="28328e0db9c18c9ada207997f806124f" category="list-text">*LAN virtuali tenant (VLAN).* a livello di rete, la sicurezza di rete end-to-end tra gli iniziatori iSCSI e il cluster software NetApp Element è facilitata dall'utilizzo di VLAN. Per qualsiasi VLAN creata per isolare un carico di lavoro o un tenant, il software NetApp Element crea un indirizzo SVIP di destinazione iSCSI separato accessibile solo attraverso la VLAN specifica.</block>
  <block id="5fec85270e969240cc769f429b9c8cdc" category="list-text">*VLAN abilitate per VRF.* per supportare ulteriormente la sicurezza e la scalabilità nel data center, il software NetApp Element consente di abilitare qualsiasi VLAN tenant per funzionalità simili a VRF. Questa funzionalità aggiunge queste due funzionalità chiave:</block>
  <block id="fca8436836d48525b8d98babbfd68518" category="list-text">Routing *L3 a un indirizzo SVIP tenant.* questa funzione consente di posizionare gli iniziatori iSCSI su una rete o VLAN separata da quella del cluster software NetApp Element.</block>
  <block id="eaea554ececf5b64515f0833c56b3de4" category="list-text">*Subnet IP sovrapposte o duplicate.* questa funzione consente di aggiungere un modello agli ambienti tenant, consentendo a ciascuna VLAN tenant di essere assegnata a indirizzi IP della stessa subnet IP. Questa funzionalità può essere utile per gli ambienti dei provider di servizi in cui la scalabilità e la conservazione di IPSpace sono importanti.</block>
  <block id="c08531651ee4977d5020da1b84003631" category="section-title">Efficienze dello storage aziendale</block>
  <block id="78712bd6b2d8e5531e122b5e849fb842" category="paragraph">Il cluster software NetApp Element aumenta l'efficienza e le performance generali dello storage. Le seguenti funzioni vengono eseguite inline, sono sempre attive e non richiedono alcuna configurazione manuale da parte dell'utente:</block>
  <block id="6893566c26b28e197cebdefdcc6af3ae" category="list-text">*Deduplica.* il sistema memorizza solo blocchi 4K univoci. Tutti i blocchi 4K duplicati vengono automaticamente associati a una versione dei dati già memorizzata. I dati si trovano su dischi a blocchi e vengono mirrorati utilizzando la protezione dei dati del software NetApp Element Helix. Questo sistema riduce significativamente il consumo di capacità e le operazioni di scrittura all'interno del sistema.</block>
  <block id="2e5dd3a69ccb3f04d7814fc742318204" category="list-text">*Compressione.* la compressione viene eseguita inline prima che i dati vengano scritti nella NVRAM. I dati vengono compressi, memorizzati in blocchi 4K e rimangono compressi nel sistema. Questa compressione riduce significativamente il consumo di capacità, le operazioni di scrittura e il consumo di larghezza di banda nel cluster.</block>
  <block id="215de8162cb5ac909005881f92812fb0" category="list-text">*Thin-provisioning.* questa funzionalità fornisce la giusta quantità di storage al momento necessario, eliminando il consumo di capacità causato da volumi con overprovisioning o volumi sottoutilizzati.</block>
  <block id="95f1b89c8e9c330fcfdc8ec84633bfe6" category="list-text">*Helix.* i metadati di un singolo volume vengono memorizzati su un'unità di metadati e replicati su un'unità di metadati secondaria per la ridondanza.</block>
  <block id="da9c9b2b4164632e569069fe1e7c53ee" category="admonition">Element è stato progettato per l'automazione. Tutte le funzionalità di storage sono disponibili tramite API. Queste API sono l'unico metodo utilizzato dall'interfaccia utente per controllare il sistema.</block>
  <block id="de3b8bd79707b5ac064727a07d81d808" category="summary">Le funzionalità indipendenti dall'hardware di anthos on bare metal ti consentono di scegliere una piattaforma di calcolo ottimizzata per il tuo caso d'utilizzo personalizzato e di offrire molti vantaggi aggiuntivi.</block>
  <block id="a5fcf88905522eca0a7500198fc13ea9" category="paragraph">Alcuni esempi includono:</block>
  <block id="b872ec62b57abae84b75461c58e0a0a7" category="list-text">*Porta il tuo server.* puoi utilizzare server che corrispondono alla tua infrastruttura esistente per ridurre le spese di capitale e i costi di gestione.</block>
  <block id="231a9d200c75839cf9b4ffeecde45821" category="list-text">*Porta il tuo sistema operativo Linux.* scegliendo il sistema operativo Linux al quale desideri implementare l'ambiente anthos-on-bare-metal, puoi assicurarti che l'ambiente anthos si adatti perfettamente all'infrastruttura e agli schemi di gestione esistenti.</block>
  <block id="8f3c025cf8c4fb1a7841163ea4213611" category="list-text">*Prestazioni migliorate e costi ridotti.* senza la necessità di un hypervisor, i cluster anthos-on-bare-metal richiedono l'accesso diretto alle risorse hardware del server, inclusi i dispositivi hardware ottimizzati per le performance come le GPU.</block>
  <block id="5c96e444541cebd597916a4a84177f6b" category="list-text">*Prestazioni di rete migliorate e latenza ridotta.* poiché i nodi server anthos-on-bare-metal sono collegati direttamente alla rete senza un livello di astrazione virtualizzato, possono essere ottimizzati per bassa latenza e performance.</block>
  <block id="6a655d9810c4c5ea4ab7a5520d43ca6f" category="paragraph">La seguente tabella contiene le piattaforme server testate dai partner engineer NetApp e NetApp per la convalida di anthos sulle implementazioni bare metal.</block>
  <block id="21f20abdc637c3f2ef02355079dac15d" category="cell">UCS</block>
  <block id="8746d13b8a20e92a40041de84ef0df6f" category="cell">B200 M5</block>
  <block id="3cd9b23ed31110b2ebcbcc8c9a1dc8c0" category="cell">HPE</block>
  <block id="dcaa84314614529edc3d258cff7f565a" category="cell">ProLiant</block>
  <block id="76cca00a6b1e58467cea8165c904fe4f" category="cell">DL360</block>
  <block id="08c2b93847522285403aa57a50c67356" category="paragraph">I nodi anthos-on-bare-metal possono essere configurati con diverse distribuzioni Linux scelte dal cliente per adattarsi all'attuale infrastruttura del data center.</block>
  <block id="c5c8661ff74179fd251af29468f2ee7d" category="paragraph">La seguente tabella contiene un elenco dei sistemi operativi Linux utilizzati da NetApp e dai partner per la convalida della soluzione.</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">CentOS</block>
  <block id="6762f053abca7510f6648c71492724a7" category="cell">8.4</block>
  <block id="cb9cc8981898224a2fe45ac6ff7d4244" category="cell">1.11</block>
  <block id="c73bbd3786350b0a8d3577d82afdf489" category="cell">Red Hat Enterprise Linux</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">Ubuntu</block>
  <block id="629f0a0ce45378aa8d3f93d405eb19cc" category="paragraph">Per completare l'implementazione di anthos su bare metal come soluzione completamente validata, NetApp e i nostri partner hanno testato componenti aggiuntivi per il data center per il networking e lo storage.</block>
  <block id="b763f3ad097c7d9beb9849be170a627a" category="cell">Nome hardware</block>
  <block id="8c692721fdfc559bf4689567aa48fb47" category="cell">Nexus</block>
  <block id="5cb4ead83aaa15a241ef0e8c36f0678c" category="cell">C9336C-FX2</block>
  <block id="969f1705e87aebac2415f45faaf8ef89" category="cell">A250, A220</block>
  <block id="effae9170216f08fb6cb3265a4cae9cc" category="paragraph">La seguente tabella include un elenco delle versioni software aggiuntive implementate nell'ambiente di convalida.</block>
  <block id="91c8cbe28b4928f6ea19ea8d1894623a" category="cell">Nome del software</block>
  <block id="604081aa29d106416ce93ba7c42a41e3" category="cell">NXOS</block>
  <block id="55e62f54b487de5f2a89d645f80d77b4" category="cell">9.3(5)</block>
  <block id="e764fe6b8f8825a307a87cedbef45678" category="cell">22.04</block>
  <block id="e0f2ed66fa5adfb40b7738ba72a899c9" category="paragraph">Durante la convalida della piattaforma anthos Ready eseguita da NetApp e dal nostro team di partner di World Wide Technology (WWT), l'ambiente di laboratorio è stato costruito sulla base del seguente diagramma, che ci ha consentito di testare la funzionalità di ogni tipo di server, sistema operativo, dispositivi di rete, e sistemi storage implementati nella soluzione.</block>
  <block id="9401797270b98418222b9be6674161bc" category="admonition">Questo ambiente multi-OS mostra l'interoperabilità con le versioni dei sistemi operativi supportate per la soluzione anthos-on-bare-metal. Prevediamo che i clienti si standardizzeranno su uno o un sottoinsieme di sistemi operativi per la loro implementazione.</block>
  <block id="c7a2b443f8714e7071c1d55a3bd2715f" category="section-title">Risorse di supporto dell'infrastruttura</block>
  <block id="f8f0e385abfb7fc517b1b9b4e9e8d19e" category="paragraph">Prima dell'implementazione di anthos su bare metal, deve essere implementata la seguente infrastruttura:</block>
  <block id="3a6810b280d17ed872c226f7c95dac46" category="list-text">Almeno un server DNS che fornisce una risoluzione completa del nome host accessibile dalla rete di gestione.</block>
  <block id="14de5275438fed7bf294f7d1ef6ebfce" category="list-text">Almeno un server NTP accessibile dalla rete di gestione.</block>
  <block id="ab851d2f29c7c89b9bc55851dd1002d2" category="list-text">(Opzionale) connettività Internet in uscita per la rete di gestione in banda.</block>
  <block id="82d4df3a9be244e5548f2913b75e403c" category="admonition">Nella sezione Video e demo di questo documento è disponibile un video dimostrativo su un'implementazione di anthos su bare metal.</block>
  <block id="137a72e2db1a693e6a6d286f154ddc67" category="inline-link-macro">Pagina successiva: Panoramica dei sistemi storage NetApp.</block>
  <block id="8a31087c2de67e51ba9270956af09594" category="paragraph"><block ref="8a31087c2de67e51ba9270956af09594" category="inline-link-macro-rx"></block></block>
  <block id="21e8ffc6f822b183559b39b43061c1d2" category="summary">NetApp offre una serie di prodotti che assistono i nostri clienti nell'orchestrazione e nella gestione dei dati persistenti in ambienti basati su container come anthos.</block>
  <block id="5b9abd64aa4865a31820ebec932e54f2" category="section-title">Programma per partner di storage anthos Ready.</block>
  <block id="7a8b9d74335d44fbaaf7f5d5aebf0cfd" category="paragraph">Google Cloud richiede periodicamente la convalida aggiornata delle integrazioni di storage dei partner con le nuove release di anthos attraverso il programma per partner di storage anthos Ready. È possibile trovare un elenco delle soluzioni storage attualmente validate, dei driver CSI, delle funzionalità disponibili e delle versioni di anthos supportate<block ref="0ccc93736ba595a77f031ff105798de0" category="inline-link-rx"></block>.</block>
  <block id="8490bfef5919608f9d8461a6bb270666" category="paragraph">NetApp ha mantenuto una conformità regolare su base trimestrale con le richieste di validare il nostro orchestrator di storage conforme a Astra Trident CSI e il nostro sistema di storage ONTAP con le versioni di anthos.</block>
  <block id="d9c9cc94777c7797db966b663b32ce4d" category="paragraph">La tabella seguente contiene le versioni anthos testate dai tecnici dei partner NetApp e NetApp per la convalida dei driver e delle funzionalità di NetApp Astra Trident CSI nell'ambito del programma per partner di storage anthos Ready:</block>
  <block id="02046ad0e82ff27f6e1774aa588fd853" category="cell">Tipo di implementazione</block>
  <block id="1552eec8291d257c4b855dcfa425d802" category="cell">Sistema storage</block>
  <block id="6a5025e8000765df098a91023b66544a" category="cell">Versione di Astra Trident</block>
  <block id="888a77f5ac0748b6c8001822417df8b6" category="cell">Protocollo</block>
  <block id="56079badd056a19303cc26e6a4fcc7e0" category="cell">VMware</block>
  <block id="c07ee5debf5f3a3fef16c1ee5e8e4942" category="cell">NAS</block>
  <block id="7f7813d8ff1a7fae9bca0ef452fb1346" category="cell">Multiwriter, espansione dei volumi, snapshot, PVCDataSource</block>
  <block id="62a0282d39568be094470486eaf70c4f" category="cell">SAN</block>
  <block id="8c56d327dfefc3dfd3c4c4fbe25a8bd1" category="cell">Blocco raw, espansione dei volumi, snapshot, PVCDataSource</block>
  <block id="9fe6d7d50b2c6958117a19834e038c82" category="cell">1.13</block>
  <block id="775d4bb28d257a6aa23992563a82c458" category="cell">22.10</block>
  <block id="74eb178224c5fa701fbcd96998feaafe" category="cell">ONTAP 9.9.1</block>
  <block id="e5db66c80967b6fa50a1eede0ce50e2f" category="cell">Multivriter, Volume Expansion, snapshot</block>
  <block id="4c606f506efd3b3bef3499e3342b5933" category="cell">Blocco raw, espansione del volume, snapshot</block>
  <block id="e0076fd5294e757abc41b2328ed8c57d" category="cell">Elemento 12.3</block>
  <block id="a2da3c930443e5d1421caec9ee18a376" category="cell">metallo nudo</block>
  <block id="bdca6efb043178ef172612dd1e173dde" category="cell">1.10</block>
  <block id="955ddf0f7e289ee80cdea4b5324b620d" category="cell">22.01</block>
  <block id="84aafd4e962655f32c5bdea750278fba" category="paragraph">NetApp offre una serie di prodotti che consentono di orchestrare e gestire i dati persistenti in ambienti basati su container come Anthos.</block>
  <block id="55713395841bbe573d35c776279d08cc" category="paragraph">NetApp Astra Trident è un orchestrator di storage open-source e completamente supportato per container e distribuzioni Kubernetes, incluso Anthos. Per ulteriori informazioni, visita il sito web di Astra Trident<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="ea3f2894c4df21a157c45dcbcf989bda" category="paragraph">Le pagine seguenti contengono informazioni aggiuntive sui prodotti NetApp validati per la gestione delle applicazioni e dello storage persistente nella soluzione anthos con NetApp.</block>
  <block id="7b83f653c093c1509ca751b06a9ba82f" category="inline-link-macro">Pagina successiva: Panoramica di NetApp Astra Trident.</block>
  <block id="ee33055a07370e6d1e33ad7480a57a7b" category="paragraph"><block ref="ee33055a07370e6d1e33ad7480a57a7b" category="inline-link-macro-rx"></block></block>
  <block id="29fc4f6574f437e623e4eb9d47136931" category="list-text">Prima di iniziare l'installazione, trasferire le immagini di Astra Control Center in un registro di immagini.</block>
  <block id="25b4e951c048e2ae39554f36af8824b9" category="admonition">Puoi scegliere di farlo con Docker o Podman; in questo passaggio sono fornite le istruzioni per entrambi.</block>
  <block id="ad3318a786149147666e961c291c6875" category="admonition">Se si utilizzano certificati non attendibili per il Registro di sistema, modificare lo script della shell e utilizzare<block ref="0f5007fcae9fe13c2bbe7c6669b72178" prefix=" " category="inline-code"></block> per il comando podman push<block ref="0860f2134645f92280f543681a4900f8" prefix=" " category="inline-code"></block>.</block>
  <block id="a272bae97494286f198c532bb9579161" category="list-text">Quindi, caricare i certificati TLS del Registro di sistema delle immagini nei nodi OpenShift. A tale scopo, creare una mappa di configurazione in<block ref="34dd8d8a3478a983eb249305316984b0" prefix=" " category="inline-code"></block> Namespace che utilizza i certificati TLS e lo patch alla configurazione dell'immagine del cluster per rendere attendibile il certificato.</block>
  <block id="6589da0279dd02b9b1d177e0ff5f457b" category="list-text">Creare uno spazio dei nomi<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> Per l'installazione dell'operatore del centro di controllo Astra.</block>
  <block id="4324c8f0a70a221bdde33868774e5a76" category="list-text">Modificare Astra Control Center Operator CR<block ref="29815934e812e1cfba6cc38eff0d17d3" prefix=" " category="inline-code"></block>, Che è un insieme di tutte le risorse distribuite da Astra Control Center. Nel CR operatore, individuare la definizione di implementazione per<block ref="83f93b05da174976bd534cc67ad9f7b4" prefix=" " category="inline-code"></block> E inserire l'FQDN del registro insieme al nome dell'organizzazione fornito durante l'invio delle immagini al registro (in questo esempio,<block ref="6bde403d563a0c848b35e178652a7a84" prefix=" " category="inline-code"></block>) sostituendo il testo<block ref="e7fbb61ffc587682a801796b46db408a" prefix=" " category="inline-code"></block> e fornisci il nome del segreto in cui abbiamo appena creato<block ref="0d9b54b29da54379cca6b8782b9faae5" prefix=" " category="inline-code"></block> sezione. Verificare altri dettagli dell'operatore, salvare e chiudere.</block>
  <block id="a27cc132b2f3001f3e9df9c40dad4bfb" category="list-text">Creare l'operatore eseguendo il seguente comando.</block>
  <block id="685fe82295261a8902e709081b6c9599" category="list-text">Creare uno spazio dei nomi dedicato per l'installazione di tutte le risorse di Astra Control Center.</block>
  <block id="6d71c41a686bcfc0b0866044afd43f2b" category="list-text">Creare il segreto per accedere al registro delle immagini nello spazio dei nomi.</block>
  <block id="25eb68598d15a49d385089020950412c" category="list-text">Modificare il file CRD di Astra Control Center<block ref="14eaa229cb5cb8abd16cee04a7cdc20c" prefix=" " category="inline-code"></block> E inserire l'FQDN, i dettagli del registro immagini, l'indirizzo e-mail dell'amministratore e altri dettagli.</block>
  <block id="d689979a6af0f5660231db187d212950" category="list-text">Creare il CRD di Astra Control Center nello spazio dei nomi creato per esso.</block>
  <block id="42b9bde28896d6478a324770641ac301" category="admonition">Il file precedente<block ref="14eaa229cb5cb8abd16cee04a7cdc20c" prefix=" " category="inline-code"></block> È la versione minima del CRD di Astra Control Center. Se si desidera creare il CRD con un maggiore controllo, ad esempio la definizione di uno storageclass diverso da quello predefinito per la creazione di PVC o la fornitura di dettagli SMTP per le notifiche di posta, è possibile modificare il file<block ref="70b058e54d2bda749060070a7f9c4e5c" prefix=" " category="inline-code"></block>, Inserire i dettagli necessari e utilizzarli per creare il CRD.</block>
  <block id="a003986254b5a6c136733113505348da" category="doc">Installazione di F5 BIG-IP Load Balancer</block>
  <block id="048600e045fd4c5afe58ec9d65aa4b19" category="paragraph">F5 BIG-IP è un Application Delivery Controller (ADC) che offre un'ampia gamma di servizi avanzati di gestione del traffico e sicurezza di livello produttivo come il bilanciamento del carico L4-L7, l'offload SSL/TLS, DNS, firewall e molto altro ancora. Questi servizi aumentano drasticamente la disponibilità, la sicurezza e le performance delle tue applicazioni.</block>
  <block id="5c47e8322efb7f77c0aa515fec29477e" category="paragraph">F5 BIG-IP può essere implementato e utilizzato in vari modi, su hardware dedicato, nel cloud o come appliance virtuale on-premise. Fare riferimento alla documentazione qui per esplorare e implementare F5 BIG-IP in base ai requisiti.</block>
  <block id="16a275a8b38f9c5211732c331edb7135" category="paragraph">Per un'integrazione efficiente dei servizi Big-IP di F5 con Red Hat OpenShift, F5 offre IL BIG-IP Container Ingress Service (CIS). CIS viene installato come controller pod che controlla l'API OpenShift per alcune definizioni di risorse personalizzate (CRD) e gestisce la configurazione del sistema F5 BIG-IP. F5 BIG-IP CIS può essere configurato per controllare i tipi di servizio LoadBalancer e route in OpenShift.</block>
  <block id="e3ce824a7aff01576faaac58df9e0b18" category="paragraph">Inoltre, per l'allocazione automatica dell'indirizzo IP al servizio del tipo LoadBalancer, è possibile utilizzare il controller F5 IPAM. Il controller F5 IPAM viene installato come controller pod che controlla i servizi di OpenShift API per LoadBalancer con un'annotazione ipamLabel per allocare l'indirizzo IP da un pool preconfigurato.</block>
  <block id="3b08b142099d42d5280d7b493288bf63" category="paragraph">Questa pagina elenca le istruzioni di installazione e configurazione per i controller F5 BIG-IP CIS e IPAM. Come prerequisito, è necessario disporre di un sistema F5 BIG-IP distribuito e concesso in licenza. Deve inoltre essere concesso in licenza per i servizi SDN, inclusi per impostazione predefinita con LA licenza base BIG-IP VE.</block>
  <block id="5fb7b483d0c9fa099945579d826691b8" category="admonition">F5 BIG-IP può essere implementato in modalità standalone o cluster. Ai fini di questa convalida, F5 BIG-IP è stato implementato in modalità standalone, ma per scopi di produzione, è preferibile disporre di un cluster di big-IP per evitare un singolo punto di errore.</block>
  <block id="2454407b9991c6c5f417a2feb8ea7970" category="cell">4.6 EUS, 4.7</block>
  <block id="00d0a06cc7c922b3bc62b22524723ff8" category="cell">F5 BIG-IP VE EDITION</block>
  <block id="5bd03f916d1e7b0410d0d3b2d12c6366" category="cell">16.1.0</block>
  <block id="c6f7874f49f685ffdf1b5a8aad8875c4" category="cell">F5 Container Ingress Service</block>
  <block id="21f47a5b35d016c2f0f8f57704079407" category="cell">2.5.1</block>
  <block id="9635118f932e26e24f0ca315d3843379" category="cell">F5 Controller IPAM</block>
  <block id="5256eb2d6e3cf80e003a290e63843800" category="cell">0.1.4</block>
  <block id="088afeececf092d5a406e0f5022a9638" category="cell">F5 AS3</block>
  <block id="425b0ca2d1d9d5c75555116fcd1614bf" category="cell">3.30.0</block>
  <block id="b9a4064fa117596b59fb18df84df74df" category="inline-link">F5 repository AS3 GitHub</block>
  <block id="6463cf716c052865ec9f4716ff0b5d3f" category="list-text">Installare l'estensione F5 Application Services 3 per consentire ai sistemi BIG-IP di accettare configurazioni in JSON invece di comandi imperativi. Passare a.<block ref="0d4e47593b830323684cdec40cb60c71" category="inline-link-rx"></block>E scaricare il file RPM più recente.</block>
  <block id="4c0802ebd79a8c6e5ea4aed829f023c9" category="list-text">Accedere al sistema F5 BIG-IP, accedere a iApps &gt; Package Management LX e fare clic su Import (Importa).</block>
  <block id="3536ed517a711f49cfe64071db031cf5" category="list-text">Fare clic su Choose file (Scegli file) e selezionare il file RPM AS3 scaricato, fare clic su OK, quindi su Upload (carica).</block>
  <block id="2a90f793207a5a0c028d8ccc45e943fd" category="inline-image-macro">Caricamento di iApp</block>
  <block id="7a3eaac0605c201c339e116a475c0bf6" category="paragraph"><block ref="7a3eaac0605c201c339e116a475c0bf6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="caedd771b59d267eda8f88d329e8784f" category="list-text">Verificare che l'estensione AS3 sia installata correttamente.</block>
  <block id="c434efeb83b6dc500ea7893f1ad4236b" category="inline-image-macro">Convalida dell'installazione di AS3</block>
  <block id="eb52ccb2be126d28d17e4383ae6ea6cf" category="paragraph"><block ref="eb52ccb2be126d28d17e4383ae6ea6cf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97e9e05bfde432cfa7291b1e55a52ba7" category="list-text">Quindi, configurare le risorse necessarie per la comunicazione tra OpenShift e I sistemi BIG-IP. Creare innanzitutto un tunnel tra OpenShift e IL SERVER BIG-IP creando un'interfaccia di tunnel VXLAN sul sistema BIG-IP per OpenShift SDN. Accedere a Network &gt; Tunnels &gt; Profiles (rete &gt; tunnel &gt; profili), fare clic su Create (Crea) e impostare il profilo principale su vxlan e il tipo di flooding su Multicast. Inserire un nome per il profilo e fare clic su fine.</block>
  <block id="faaca798da0468a250bf3c3bffc26681" category="inline-image-macro">Creare un profilo VXLAN</block>
  <block id="bddf6bed69a1a2234f15cefc27853c50" category="paragraph"><block ref="bddf6bed69a1a2234f15cefc27853c50" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45ae0c96657fdc5a20e83839c2386c1e" category="list-text">Accedere a Network (rete) &gt; Tunnels (tunnel) &gt; Tunnel List (elenco tunnel), fare clic su Create (Crea) e immettere il nome e l'indirizzo IP locale per il tunnel. Selezionare il profilo di tunnel creato nel passaggio precedente e fare clic su fine.</block>
  <block id="1497a4f92d416d6c80392ec3467ff140" category="inline-image-macro">Creare un tunnel VXLAN</block>
  <block id="53ce9cdf8cf7f6cb09991e817df94959" category="paragraph"><block ref="53ce9cdf8cf7f6cb09991e817df94959" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc5e5bc480b39177b8cb8c9c3a2266ae" category="list-text">Accedi al cluster Red Hat OpenShift con privilegi di amministratore del cluster.</block>
  <block id="986e63a308b4bebd3f531e38fa5a06c7" category="list-text">Creare una subnet host su OpenShift per il server F5 BIG-IP, che estende la subnet dal cluster OpenShift al server F5 BIG-IP. Scaricare la definizione YAML della subnet host.</block>
  <block id="fd4475e12938f5f51ba3f312b42cdd39" category="list-text">Modificare il file di sottorete host e aggiungere l'IP BIG-IP VTEP (tunnel VXLAN) per OpenShift SDN.</block>
  <block id="2e6d8a8db3c4d4a2227ffa0571be2a86" category="admonition">Modificare l'indirizzo e altri dettagli in base all'ambiente in uso.</block>
  <block id="7f9916ee1bc520d892dfbbb1e06e2732" category="list-text">Creare la risorsa HostSubnet.</block>
  <block id="7a46b2d02d466dda0cc67b215cb80bff" category="list-text">Ottenere l'intervallo di subnet IP del cluster per la subnet host creata per il server Big-IP F5.</block>
  <block id="4f6c1fea3654c07f1606c0c76509d0b0" category="list-text">Creare un IP self su OpenShift VXLAN con un IP nell'intervallo di subnet host di OpenShift corrispondente al server F5 BIG-IP. Accedere al sistema F5 BIG-IP, selezionare Network &gt; Self IPs (rete &gt; IP automatici) e fare clic su Create (Crea). Inserire un IP dalla subnet IP del cluster creata per la subnet host F5 BIG-IP, selezionare il tunnel VXLAN e immettere gli altri dettagli. Quindi fare clic su fine.</block>
  <block id="5c241806c0dd5ebb7030904151cb78ef" category="inline-image-macro">Crea IP automatico per VXLAN</block>
  <block id="ffad9e123d8b7013e7d4553570644879" category="paragraph"><block ref="ffad9e123d8b7013e7d4553570644879" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d094b7d82871afb601d2f30d416ba8d" category="list-text">Creare una partizione nel sistema F5 BIG-IP da configurare e utilizzare con CIS. Accedere a sistema &gt; utenti &gt; elenco partizioni, fare clic su Crea e immettere i dettagli. Quindi fare clic su fine.</block>
  <block id="4d81871723233ec21ed69ab80e638779" category="inline-image-macro">Creare UNA partizione BIG-IP</block>
  <block id="b83428617c6ed29213f89e68f142bd18" category="paragraph"><block ref="b83428617c6ed29213f89e68f142bd18" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37397397fa66431e2fa681b97126c399" category="admonition">F5 consiglia di non eseguire alcuna configurazione manuale sulla partizione gestita da CIS.</block>
  <block id="81e4a49e9dbe0b55256fe5abf1b94fa4" category="list-text">Installare F5 BIG-IP CIS utilizzando l'operatore di OperatorHub. Accedi al cluster Red Hat OpenShift con privilegi di amministrazione del cluster e crea un segreto con le credenziali di accesso del sistema F5 BIG-IP, un prerequisito per l'operatore.</block>
  <block id="5de4ac005898cabf55523098c40c549b" category="list-text">Installare F5 CIS CRD.</block>
  <block id="0eddace1b16ed738fe1be181481c71b6" category="list-text">Accedere a Operator &gt; OperatorHub, cercare la parola chiave F5 e fare clic sul riquadro F5 Container Ingress Service.</block>
  <block id="07543409cb05595e273df71050b9a9c0" category="inline-image-macro">F5 CIS in OperatorHub</block>
  <block id="334a7bbf4711d93b48b93c2b81d84a71" category="paragraph"><block ref="334a7bbf4711d93b48b93c2b81d84a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c25b2a3d320d6d02584fde4190d05d91" category="list-text">Leggere le informazioni dell'operatore e fare clic su Install (Installa).</block>
  <block id="60d3353ed1910ad5c7bd352d0c1bea85" category="inline-image-macro">F5 riquadro CIS Info in OperatorHub</block>
  <block id="1aa79507d413f19135716c8006afa423" category="paragraph"><block ref="1aa79507d413f19135716c8006afa423" category="inline-image-macro-rx" type="image"></block></block>
  <block id="637a1bc658defc200d903b27828aa8fb" category="list-text">Nella schermata Install operator (Installa operatore), lasciare tutti i parametri predefiniti e fare clic su Install (Installa).</block>
  <block id="ccf254d7c8b666c9c127ec12fe14804b" category="inline-image-macro">Installare l'operatore F5 CIS</block>
  <block id="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="paragraph"><block ref="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="636d8318702bc67a1613ceadf7ce9d00" category="list-text">L'installazione dell'operatore richiede un po' di tempo.</block>
  <block id="dffa3077bcff43536afd75bd61b11c0c" category="inline-image-macro">F5 avanzamento installazione operatore CIS</block>
  <block id="b1be0ed9469d2ced1f6283b49735f5c1" category="paragraph"><block ref="b1be0ed9469d2ced1f6283b49735f5c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="197a0a4cc4a45ec9a62fe2b7335d8dfc" category="list-text">Una volta installato l'operatore, viene visualizzato il messaggio Installazione completata.</block>
  <block id="5bf83e99bfa132430d0b690181334933" category="list-text">Accedere a Operators &gt; Installed Operators (operatori &gt; operatori installati), fare clic su F5 Container Ingress Service (F5 Container Ingress Service), quindi fare clic su Create Instance (Crea istanza) nella sezione F5BigIpCtlr.</block>
  <block id="a5f584f06c59c2cf4a4a4e8b42d495a2" category="inline-image-macro">Crea F5BigIpCtlr</block>
  <block id="a2574a02e64888de32a5a277ed05f668" category="paragraph"><block ref="a2574a02e64888de32a5a277ed05f668" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5ce9a4ef68c16a3ab5d0dd555305872" category="list-text">Fare clic su YAML View (Visualizza YAML) e incollare il seguente contenuto dopo aver aggiornato i parametri necessari.</block>
  <block id="2e2beb899f89156ed06287fe6f78e6cf" category="admonition">Aggiornare i parametri<block ref="9117e80b6a6843f23b631387abeed925" prefix=" " category="inline-code"></block>, ` openshift_sdn_name`,<block ref="957c32cdfcd5fb9c99f7a4e3311e7768" prefix=" " category="inline-code"></block> e.<block ref="1155b6812ea5125b3144173aaaad6205" prefix=" " category="inline-code"></block> di seguito per riflettere i valori per la configurazione prima di copiare il contenuto.</block>
  <block id="50a17348dc3f981a95001edcc80a428f" category="list-text">Dopo aver incollato questo contenuto, fare clic su Create (Crea). In questo modo vengono installati i pod CIS nello spazio dei nomi del sistema kube.</block>
  <block id="72003ce6faa67d172e943ddd74fab63b" category="inline-image-macro">Validare i pod F5 CIS</block>
  <block id="ef76b6b9f85ff0ec00e48f565e13eff9" category="paragraph"><block ref="ef76b6b9f85ff0ec00e48f565e13eff9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc8632c05e82ccafb395157ccae4f5c3" category="admonition">Red Hat OpenShift, per impostazione predefinita, fornisce un modo per esporre i servizi tramite route per il bilanciamento del carico L7. Un router OpenShift integrato è responsabile della pubblicità e della gestione del traffico per questi percorsi. Tuttavia, è anche possibile configurare F5 CIS per supportare i percorsi attraverso un sistema esterno F5 BIG-IP, che può essere eseguito come router ausiliario o come sostituto del router OpenShift self-hosting. CIS crea un server virtuale nel sistema BIG-IP che funge da router per i route OpenShift, mentre BIG-IP gestisce il routing degli annunci pubblicitari e del traffico. Fare riferimento alla documentazione qui per informazioni sui parametri per attivare questa funzione. Si noti che questi parametri sono definiti per la risorsa di implementazione OpenShift nell'API apps/v1. Pertanto, quando si utilizzano questi dati con l'API cis.f5.com/v1 della risorsa F5BigIpCtlr, sostituire i trattini (-) con i trattini (_) per i nomi dei parametri.</block>
  <block id="a6e55fc1fe932b26a294a0f2880478aa" category="list-text">Gli argomenti passati alla creazione delle risorse CIS includono<block ref="49dcf57b3a065d02c9969c595e32ea50" prefix=" " category="inline-code"></block> e.<block ref="5d0d2663dc7f08b0183abaddf17f8307" prefix=" " category="inline-code"></block>. Questi parametri sono necessari per abilitare l'integrazione CIS con un controller IPAM. Verificare che il CIS abbia attivato l'integrazione IPAM creando la risorsa F5 IPAM.</block>
  <block id="84ac0b78989fa6595723d5541b8ec470" category="list-text">Creare l'account del servizio, il ruolo e il rolebinding richiesti per il controller F5 IPAM. Creare un file YAML e incollare il seguente contenuto.</block>
  <block id="670c1074ae74616731a63f6b9462b94e" category="list-text">Creare le risorse.</block>
  <block id="b7802bea6dc04d06b63232b6301621bb" category="list-text">Creare un file YAML e incollare la definizione di implementazione F5 IPAM fornita di seguito.</block>
  <block id="6a1491ddca525bea3293eca6ea8019d0" category="admonition">Aggiornare il parametro ip-range in spec.template.spec.containers[0].args di seguito per riflettere gli intervalli di indirizzi IP e ipamLabels corrispondenti alla configurazione.</block>
  <block id="642252b62fe47e95caa77e3b06a7dbaf" category="admonition">IpamLabels <block ref="4795fc86aa645b109548974bcffefe07" prefix="[" category="inline-code"></block> e.<block ref="0ce75607b46ab2a9cc08eab9ade2a24d" prefix=" " category="inline-code"></block> Nell'esempio seguente] devono essere annotati per i servizi di tipo LoadBalancer affinché il controller IPAM rilevi e assegni un indirizzo IP dall'intervallo definito.</block>
  <block id="8f253132259909c28624117b3476a672" category="list-text">Creare l'implementazione del controller F5 IPAM.</block>
  <block id="43946dccec13f46420eb559911e4c526" category="list-text">Verificare che i controller pod F5 IPAM siano in esecuzione.</block>
  <block id="1362b3e7985b4f24d6c2ef4438ee1f0e" category="list-text">Creare lo schema F5 IPAM.</block>
  <block id="52b8ffce119fe77b28034f2fdd35eb5f" category="section-title">Verifica</block>
  <block id="32172ccfad6e7060b8f5e091e296f09c" category="list-text">Creare un servizio di tipo LoadBalancer</block>
  <block id="0847be44e618094bc81c848c7d131399" category="list-text">Controllare se il controller IPAM assegna un indirizzo IP esterno.</block>
  <block id="0e51a0606ba7833099aa57bd61c62ba6" category="list-text">Creare un'implementazione e utilizzare il servizio LoadBalancer creato.</block>
  <block id="5f905cb56a4d1b364cab7fc57f4de4e5" category="list-text">Verificare che i pod siano in funzione.</block>
  <block id="51b4d723f0434284233dab97982b185d" category="list-text">Controllare se il server virtuale corrispondente viene creato nel sistema BIG-IP per il servizio di tipo LoadBalancer in OpenShift. Accedere a traffico locale &gt; Server virtuali &gt; elenco server virtuali.</block>
  <block id="91193cea3335c4666b7dc31ca767030c" category="inline-image-macro">Convalidare la creazione di server virtuali BIG-IP per il tipo di servizio corrispondente LoadBalancer</block>
  <block id="879dfaa1de924ed5e9ccb98da9ac95cd" category="paragraph"><block ref="879dfaa1de924ed5e9ccb98da9ac95cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="92637d8d513510f7c1f5bfac6e1cce9b" category="summary">Per consentire l'integrazione di Trident con il sistema storage NetApp ONTAP, è necessario creare un backend che consenta la comunicazione con il sistema storage.</block>
  <block id="5d77fe4a6bb4c5e88c5c18510b3c4749" category="doc">NetApp Element: Red Hat OpenShift con NetApp</block>
  <block id="22f48c519a73ce4759edffb196331422" category="paragraph"><block ref="22f48c519a73ce4759edffb196331422" category="inline-image-macro-rx" type="image"></block></block>
  <block id="772db62cf9ecb837ed4f0a91a5963492" category="paragraph">In questo modo, se un guasto di un nodo è seguito da una ridistribuzione del volume, non vi è alcun effetto sulla connettività dell'host oltre a una disconnessione e all'accesso con reindirizzamento alla nuova posizione. Con il reindirizzamento dell'accesso iSCSI, un cluster software NetApp Element è un'architettura scale-out con riparazione automatica in grado di eseguire operazioni e aggiornamenti senza interruzioni.</block>
  <block id="d61c98dcb4bec6f3e1213776ebb1e6c3" category="paragraph"><block ref="d61c98dcb4bec6f3e1213776ebb1e6c3" category="inline-link-macro-rx"></block></block>
  <block id="2c65eb4e4300c763b9d8ffcdc45660fc" category="paragraph">Per installare OpenShift Virtualization, attenersi alla seguente procedura:</block>
  <block id="bb761e1ed8ef4412cddb399e81488f83" category="list-text">Accedi al cluster bare-metal Red Hat OpenShift con accesso cluster-admin.</block>
  <block id="bbb49986c10d9b599ce8b72ea09d5261" category="list-text">Accedere a Operator &gt; OperatorHub e cercare OpenShift Virtualization.</block>
  <block id="016a229c1180d24870be44f7391c5678" category="list-text">Selezionare il riquadro OpenShift Virtualization (virtualizzazione OpenShift) e fare clic su Install (Installa)</block>
  <block id="fe87c9ebb6d1db5af643c2101dd83c2d" category="image-alt">Riquadro OpenShift Virtualization Operator</block>
  <block id="d2770f20a312c7d906cf3d8a97d335a2" category="list-text">Nella schermata Install Operator (Installa operatore), lasciare tutti i parametri predefiniti e fare clic su Install (Installa).</block>
  <block id="66b5ae84d6c0a470bb131b7aeb63f734" category="image-alt">OpenShift Virtualization Operator Details (Dettagli operatore di virtualizzazione</block>
  <block id="5f27d84a5a158e75ab7ac4543ca7c1be" category="image-alt">Installazione di OpenShift Virtualization Operator</block>
  <block id="49598c5badb95e31a9894d5dc277f301" category="list-text">Una volta installato l'operatore, fare clic su Create HyperConverged (Crea HyperConverged).</block>
  <block id="f63ea68253a91a92e8afb2e42bf0fb36" category="image-alt">OpenShift Virtualization Operator - Crea hyperconverged</block>
  <block id="0e4308133099865567bc6a19f0abcb88" category="list-text">Nella schermata Create HyperConverged (Crea HyperConverged), fare clic su Create (Crea), accettando tutti i parametri predefiniti. Questa fase avvia l'installazione di OpenShift Virtualization.</block>
  <block id="c57b56755457ec355801b1e17915fc47" category="image-alt">OpenShift Virtualization Operator - Dettagli di Hyperconverged</block>
  <block id="ee0ffac6ee8f4e224a044d95e68aa30d" category="list-text">Dopo che tutti i pod sono stati spostati nello stato di esecuzione nello spazio dei nomi openshift-cnv e l'operatore di virtualizzazione OpenShift è in stato di successo, l'operatore è pronto per l'uso. È ora possibile creare macchine virtuali sul cluster OpenShift.</block>
  <block id="423e88e20ace3dbca3f9d5bd3b109cef" category="image-alt">Installazione di OpenShift Virtualization Operator completata</block>
  <block id="46af5002087f682df1feb9b3339d1f68" category="inline-link-macro">Segue: Workflow: Creare una macchina virtuale.</block>
  <block id="066b9e10038ca1d47643166f151f910c" category="paragraph"><block ref="066b9e10038ca1d47643166f151f910c" category="inline-link-macro-rx"></block></block>
  <block id="d008c60ddb28c0bbad1dfabdd77327fc" category="doc">Configurazione: Attività di amministrazione dello storage</block>
  <block id="6c0ed744c737f30af364d229639c8288" category="paragraph">Le seguenti risorse devono essere configurate da un amministratore dello storage:</block>
  <block id="64244866ddff81ded5e6aaa49055c6aa" category="list-text">Accedere al cluster NetApp ONTAP come amministratore.</block>
  <block id="85ca996063b5ec233e56a20ba93c5f44" category="list-text">Accedere a Storage &gt; Storage VM (Storage &gt; Storage VM) e fare clic su Add (Aggiungi). Creare due SVM, una per il progetto 1 e l'altra per il progetto 2, fornendo i dettagli richiesti. Inoltre, creare un account vsadmin per gestire SVM e le relative risorse.</block>
  <block id="3f8bc17bf8dd138aa2915235f0a9c0d3" category="image-alt">Creazione di SVM su ONTAP</block>
  <block id="b436e7799d01413277e05983e509574a" category="list-text">Accedere al cluster Red Hat OpenShift come amministratore dello storage.</block>
  <block id="c9bd46366e9fb78552566f1e7a13633a" category="list-text">Creare il backend per il progetto 1 e mapparlo sulla SVM dedicata al progetto. NetApp consiglia di utilizzare l'account vsadmin di SVM per connettere il backend a SVM invece di utilizzare l'amministratore del cluster ONTAP.</block>
  <block id="f934b433773b966e5ebe0c7172decda4" category="admonition">Per questo esempio, viene utilizzato il driver ontap-nas. Utilizzare il driver appropriato per creare il backend in base al caso d'utilizzo.</block>
  <block id="4a6c648106c1ff38316705bf986de601" category="list-text">Analogamente, creare il backend Trident per il progetto 2 e mapparlo sulla SVM dedicata al progetto 2.</block>
  <block id="9a45d41277a2e8ce29709826a31fb482" category="list-text">Quindi, creare le classi di storage. Creare la classe di storage per il project-1 e configurarla per utilizzare i pool di storage dal backend dedicato al project-1 impostando il parametro storagePools.</block>
  <block id="4350d40426f8c94f6ca046609969adb2" category="list-text">Allo stesso modo, creare una classe di storage per il progetto 2 e configurarla per utilizzare i pool di storage dal back-end dedicato al progetto 2.</block>
  <block id="2ee847ebe129ae778860d6dd2da21cf6" category="list-text">Creare un ResourceQuota per limitare le risorse nel progetto 1, richiedendo storage da storageclasses dedicati ad altri progetti.</block>
  <block id="c689ae18a0f5e47541dcec4afb6e187a" category="list-text">Allo stesso modo, creare un ResourceQuota per limitare le risorse nel progetto 2, richiedendo lo storage da storageclasses dedicati ad altri progetti.</block>
  <block id="7f9ddc8224f28e1481299160807c876d" category="inline-link-macro">Successivo: Convalida.</block>
  <block id="93a1440c4dcba82f234a9305a9445144" category="paragraph"><block ref="93a1440c4dcba82f234a9305a9445144" category="inline-link-macro-rx"></block></block>
  <block id="fe70522102670f75ed2fff361701d056" category="paragraph">Questo documento di riferimento fornisce la convalida dell'implementazione della soluzione Red Hat OpenShift, implementata tramite l'infrastruttura IPI (Installer Provised Infrastructure) in diversi ambienti di data center come validati da NetApp. Descrive inoltre l'integrazione dello storage con i sistemi di storage NetApp utilizzando Astra Trident Storage orchestrator per la gestione dello storage persistente e NetApp Astra Control Center per la gestione e la protezione delle applicazioni stateful. Infine, vengono analizzate e documentate una serie di validazioni delle soluzioni e casi di utilizzo reali.</block>
  <block id="0d1d64b47559f0c28c883e7e790b8363" category="summary">Questa sezione è dedicata alle personalizzazioni che gli utenti reali dovrebbero eseguire durante l'implementazione di questa soluzione in produzione, ad esempio la creazione di un registro di immagini dedicato o l'implementazione di istanze personalizzate di bilanciamento del carico.</block>
  <block id="becc5334b7f3d2f4f57fc42cd287fd54" category="inline-link-macro">Esplorazione delle opzioni di bilanciamento del carico</block>
  <block id="22651dd64b4cd4c6d2742d1f8b126ae6" category="list-text"><block ref="22651dd64b4cd4c6d2742d1f8b126ae6" category="inline-link-macro-rx"></block></block>
  <block id="261bdcc1d2c24d15c43c5947e69ea9e6" category="inline-link-macro">Configurazione dei registri di immagini private</block>
  <block id="c8db11b008075455562a8b598b31753c" category="list-text"><block ref="c8db11b008075455562a8b598b31753c" category="inline-link-macro-rx"></block></block>
  <block id="06fdae3f02fee5cbe172f1574564c925" category="doc">Gestione avanzata dei cluster per Kubernetes: Red Hat OpenShift con NetApp</block>
  <block id="30c15b5a84f4fb26cd25b38dc787b22d" category="paragraph">Poiché un'applicazione containerizzata passa dallo sviluppo alla produzione, molte organizzazioni richiedono più cluster Red Hat OpenShift per supportare il test e l'implementazione di tale applicazione. In combinazione con questo, le organizzazioni generalmente ospitano più applicazioni o carichi di lavoro su cluster OpenShift. Pertanto, ogni organizzazione finisce per gestire un insieme di cluster e gli amministratori di OpenShift devono quindi affrontare la sfida aggiunta di gestire e mantenere più cluster in una gamma di ambienti che si estendono a più data center on-premise e cloud pubblici. Per affrontare queste sfide, Red Hat ha introdotto la gestione avanzata dei cluster per Kubernetes.</block>
  <block id="1cf7b9db4d7fe091bd1bbb685e5beea8" category="paragraph">Red Hat Advanced Cluster Management per Kubernetes consente di eseguire le seguenti operazioni:</block>
  <block id="808c579683377aa7bd89b8e4d76ba220" category="list-text">Crea, importa e gestisci più cluster tra data center e cloud pubblici</block>
  <block id="7fe0555145a586e3fb769f86902ccc72" category="list-text">Implementa e gestisci applicazioni o carichi di lavoro su più cluster da una singola console</block>
  <block id="416434625b0f2158d99a4af37f233805" category="list-text">Monitorare e analizzare lo stato e lo stato delle diverse risorse del cluster</block>
  <block id="fed6fdd49a1e6adda0ea12a93e74ea2d" category="list-text">Monitorare e applicare la conformità alla sicurezza in più cluster</block>
  <block id="a7516c278242a08b85090e24cbf67218" category="paragraph">Red Hat Advanced Cluster Management per Kubernetes viene installato come add-on in un cluster Red Hat OpenShift e utilizza questo cluster come controller centrale per tutte le operazioni. Questo cluster è noto come cluster di hub ed espone un piano di gestione per consentire agli utenti di connettersi a Advanced Cluster Management. Tutti gli altri cluster OpenShift importati o creati tramite la console Advanced Cluster Management sono gestiti dal cluster hub e sono denominati cluster gestiti. Installa un agente chiamato Klusterlet sui cluster gestiti per connetterli al cluster hub e soddisfare le richieste di attività diverse correlate alla gestione del ciclo di vita del cluster, alla gestione del ciclo di vita delle applicazioni, all'osservabilità e alla conformità alla sicurezza.</block>
  <block id="b1000f23e43dfac19b53c74d7ebe66c8" category="image-alt">Architettura ACM</block>
  <block id="a376445fd812a7fa27714e6b11bc6163" category="paragraph">Per ulteriori informazioni, consultare la documentazione<block ref="50c0dc50e188cf3a7847d9a813fd829e" category="inline-link-rx"></block>.</block>
  <block id="a99137a02f570225903b02b175e289a4" category="paragraph"><block ref="a99137a02f570225903b02b175e289a4" category="inline-link-macro-rx"></block></block>
  <block id="55c7e45b50d0b012faf4bce31b6ad05d" category="section-title">Creare una macchina virtuale da un'istantanea</block>
  <block id="9e5a59ca9aef030e74a725dab3fb6dcf" category="paragraph">Con Astra Trident e Red Hat OpenShift, gli utenti possono creare un'istantanea di un volume persistente su classi di storage fornite dall'IT. Con questa funzione, gli utenti possono eseguire una copia point-in-time di un volume e utilizzarlo per creare un nuovo volume o ripristinare lo stato precedente dello stesso volume. Ciò consente o supporta una varietà di casi di utilizzo, dal rollback ai cloni al ripristino dei dati.</block>
  <block id="f991e1a54e399d272c7d968dcdfdb690" category="paragraph">Per le operazioni Snapshot in OpenShift, è necessario definire le risorse VolumeSnapshotClass, VolumeSnapshot e VolumeSnapshotContent.</block>
  <block id="0e2d1628ef03c4400cd293c3143cabb3" category="list-text">Un VolumeSnapshotContent è lo snapshot effettivo preso da un volume nel cluster. Si tratta di una risorsa a livello di cluster analoga a PersistentVolume per lo storage.</block>
  <block id="8ca4876558d3675f7a3e2c452c62a215" category="list-text">VolumeSnapshot è una richiesta per la creazione dello snapshot di un volume. È analogo a un PersistentVolumeClaim.</block>
  <block id="7f9fbed02a61699d31f7d9a0eb11bc81" category="list-text">VolumeSnapshotClass consente all'amministratore di specificare attributi diversi per un'istantanea VolumeSnapshot. Consente di avere attributi diversi per diversi snapshot acquisiti dallo stesso volume.</block>
  <block id="7f7858938c48bb9f08341c0e41c9162d" category="image-alt">VM dall'architettura Snapshot</block>
  <block id="99bf6e1ad41f7875d5b7ec9f857c4f0f" category="paragraph">Per creare un'istantanea di una macchina virtuale, attenersi alla seguente procedura:</block>
  <block id="5dc14d36063086387d2eb7cf012544aa" category="list-text">Creare una classe VolumeSnapshotClass da utilizzare per creare un'istantanea VolumeSnapshot. Accedere a Storage &gt; VolumeSnapshotClasses e fare clic su Create VolumeSnapshotClass (Crea VolumeSnapshotClass).</block>
  <block id="52f0977d1e65469f01e2f290e637a8f1" category="list-text">Immettere il nome della classe Snapshot, immettere csi.trident.netapp.io per il driver e fare clic su Create (Crea).</block>
  <block id="508073b07367d898823f1841627451d4" category="image-alt">Creare la classe Snapshot</block>
  <block id="2bde7e02152796551174ea391bda0b60" category="list-text">Identificare il PVC collegato alla VM di origine e creare un'istantanea del PVC. Selezionare<block ref="fbbf264c8665570001a09df2b42a9873" prefix=" " category="inline-code"></block> E fare clic su Create VolumeSnapshots (Crea snapshot Volume).</block>
  <block id="b9513caba1fba7b4291a9e22bc512de5" category="list-text">Selezionare il PVC per il quale si desidera creare l'istantanea, immettere il nome dell'istantanea o accettare il valore predefinito, quindi selezionare la VolumeSnapshotClass appropriata. Quindi fare clic su Create (Crea).</block>
  <block id="a7a384e6f13cae2ef877b4dd78fd48ad" category="image-alt">Crea snapshot</block>
  <block id="d8ae3e40f0f0dba0b7c7ba5b8eea845a" category="list-text">In questo modo viene creata l'istantanea del PVC in quel momento.</block>
  <block id="e9b3b34ca8f917d1968a106e682f1a97" category="section-title">Creare una nuova macchina virtuale dall'istantanea</block>
  <block id="3ffbaa72c8e63f0ec3ced08d8ebf9f72" category="list-text">Innanzitutto, ripristinare l'istantanea in un nuovo PVC. Accedere a Storage &gt; VolumeSnapshots (Storage &gt; VolumeSnapshots), fare clic sui puntini di sospensione accanto all'istantanea che si desidera ripristinare e fare clic su Restore as new PVC (Ripristina come nuovo PVC).</block>
  <block id="5160cd070df38f982551c5fea6f1c844" category="list-text">Inserire i dettagli del nuovo PVC e fare clic su Restore (Ripristina). In questo modo si crea un nuovo PVC.</block>
  <block id="0d695454ca10516a832452b6123c5bb5" category="image-alt">Ripristinare Snapshot su un nuovo PVC</block>
  <block id="8a4d1acf8df9931b5c42b3253f943d79" category="list-text">Quindi, creare una nuova macchina virtuale da questo PVC. Accedere a workload &gt; virtualizzazione &gt; macchine virtuali e fare clic su Create &gt; with YAML (Crea &gt; con YAML).</block>
  <block id="91b9a57ab88a6942f692f9f393549f6e" category="list-text">Nella sezione spec &gt; template &gt; spec &gt; Volumes (specifiche &gt; modello &gt; specifiche &gt; volumi), specificare il nuovo PVC creato da Snapshot anziché dal disco container. Fornire tutti gli altri dettagli della nuova macchina virtuale in base alle proprie esigenze.</block>
  <block id="57dc3c96f32e4895e89eab4a248088f5" category="list-text">Una volta creata correttamente la macchina virtuale, accedere e verificare che la nuova macchina virtuale abbia lo stesso stato della macchina virtuale il cui PVC è stato utilizzato per creare lo snapshot al momento della creazione dello snapshot.</block>
  <block id="91796648d42dbd448c6cbb2044cb92ba" category="paragraph">Un backup di un'applicazione acquisisce lo stato attivo dell'applicazione e la configurazione delle risorse IT, le taglia in file e le memorizza in un bucket di storage a oggetti remoto.</block>
  <block id="6db82a24b17137378420e9fc7961d961" category="list-text">Per creare un backup dell'applicazione gestita in Astra Control Center, accedere alla scheda Apps (applicazioni) &gt; Managed (gestite) e fare clic sull'applicazione di cui si desidera eseguire il backup. Fare clic sul menu a discesa accanto al nome dell'applicazione e fare clic su Backup.</block>
  <block id="f789c3d3aacfbd2d2f99ba395ddb8bc5" category="list-text">Inserire i dettagli del backup, selezionare il bucket di storage a oggetti in cui memorizzare i file di backup, fare clic su Next (Avanti) e, dopo aver esaminato i dettagli, fare clic su Backup (Backup). A seconda delle dimensioni dell'applicazione e dei dati, il backup può richiedere alcuni minuti e lo stato del backup diventa disponibile una volta completato correttamente il backup.</block>
  <block id="8ac352fe46a0c45e744688191b7df581" category="list-text">Per ripristinare un'applicazione, selezionare Apps (applicazioni) &gt; Managed Tab (scheda gestita) e fare clic sull'applicazione in questione. Fare clic sul menu a discesa accanto al nome dell'applicazione e fare clic su<block ref="2bd339d85ee3b33e513359ce781b60cc" prefix=" " category="inline-code"></block>.</block>
  <block id="04783413cee5e3c613efc7939cea3560" category="list-text">Per clonare un'applicazione, accedere alla scheda applicazioni &gt; gestite e fare clic sull'applicazione in questione. Fare clic sul menu a discesa accanto al nome dell'applicazione e fare clic su Clone (Clona).</block>
  <block id="654c7a62842024ed8e405ed0ac9c4377" category="list-text">Immettere i dettagli del nuovo spazio dei nomi, selezionare il cluster in cui si desidera clonarlo e scegliere se clonarlo da uno snapshot esistente o da un backup o dallo stato corrente dell'applicazione. Quindi, fare clic su Next (Avanti) e su Clone on review pane (Clona sul pannello di revisione) dopo aver esaminato i dettagli.</block>
  <block id="c501040965cb5ca97cc675347e9ebfdf" category="list-text">La nuova applicazione passa allo stato di rilevamento mentre Astra Control Center crea l'applicazione sul cluster selezionato. Una volta installate e rilevate tutte le risorse dell'applicazione da Astra, l'applicazione passa allo stato Available (disponibile).</block>
  <block id="a5369d9ec76321542413da21642ecc74" category="inline-link-macro">Pagina successiva: Panoramica delle integrazioni di storage NetApp</block>
  <block id="1a9b0bf11ebe49684776b9ffad6b4022" category="paragraph"><block ref="1a9b0bf11ebe49684776b9ffad6b4022" category="inline-link-macro-rx"></block></block>
  <block id="b2f35a84b813ef160b585d350d2fcd58" category="summary">Le funzionalità indipendenti dall'hardware di anthos on bare metal ti consentono di scegliere una piattaforma di calcolo ottimizzata per il tuo caso d'utilizzo. Pertanto, il può corrispondere all'infrastruttura esistente e ridurre le spese di capitale.</block>
  <block id="5f95fbda20eeb9ce0859afe2ac6f42fa" category="doc">Requisiti della soluzione</block>
  <block id="7d4009b9254a61f6afd71a2656a3a78f" category="section-title">Calcolo: Porta il tuo server</block>
  <block id="3752e68cccc911651920465532b3d6b4" category="paragraph">Le funzionalità indipendenti dall'hardware di anthos on bare metal ti consentono di scegliere una piattaforma di calcolo ottimizzata per il tuo caso d'utilizzo. Pertanto, il può corrispondere all'infrastruttura esistente e ridurre le spese di capitale.</block>
  <block id="dee41946d9d6ca32131352cb4374f12b" category="paragraph">La seguente tabella elenca il numero minimo di componenti hardware di calcolo necessari per implementare questa soluzione, anche se i modelli hardware utilizzati possono variare in base ai requisiti del cliente.</block>
  <block id="c64518704ce0c0d5501a45763f464276" category="cell">Utilizzo</block>
  <block id="602f72fff77475a16eff159759656261" category="cell">Hardware e modello</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">Quantità</block>
  <block id="06e9950a2c1bb489cf54d03d4547e913" category="cell">Nodi di amministrazione</block>
  <block id="b349dcffed4594674c8ce6c91e72e42f" category="cell">Cisco UCS B200</block>
  <block id="fcb81a84511da525a1581c4ccc00d0fb" category="cell">Nodi di lavoro</block>
  <block id="4867cc2ab4385d91c3a36d6ace67a984" category="cell">HP ProLiant DL360</block>
  <block id="2c0b20f0fbc047d58ca10a50c6a32bc7" category="section-title">Storage: NetApp ONTAP</block>
  <block id="fb5205026c598f136a15ad6c49fc1826" category="paragraph">La seguente tabella elenca il numero minimo di componenti storage-hardware necessari per implementare la soluzione, anche se i modelli hardware utilizzati possono variare in base ai requisiti del cliente.</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="cell">Hardware</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="cell">NetApp AFF</block>
  <block id="eb8440af98c502b8095408e970297e6b" category="cell">NetApp AFF A300</block>
  <block id="e8d610d6c2d243856beaade33b5aa123" category="cell">2 (1 coppia ha)</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">Requisiti software</block>
  <block id="b6ce11f078022a4ab598b8016db52a13" category="paragraph">Le versioni software identificate nella seguente tabella sono state utilizzate da NetApp e dai nostri partner per validare la soluzione con NetApp, anche se i componenti software utilizzati possono variare in base ai requisiti del cliente.</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">Software</block>
  <block id="128b9c7509f09d8ff4b08e87def0ac74" category="cell">Sistema operativo su 3 amministratori</block>
  <block id="7cd95c816f8a04ff858a857e3e5a484d" category="cell">20.04</block>
  <block id="836a05a21ac6df3b6bcf9838895b017e" category="cell">Sistema operativo su Worker4</block>
  <block id="bbd243e896202aa0eb00ce19d8a7fea8" category="cell">Sistema operativo su Worker3</block>
  <block id="4077fabc9a8b0e761cfd9bf752e03c8a" category="cell">18.04</block>
  <block id="aaad0494526f271ca02ebd06a79e7382" category="cell">Sistema operativo su Worker2</block>
  <block id="2a568439f8e6ff92daa9925ce8a03adf" category="cell">8.2</block>
  <block id="7ac53708026d8515ce15cc154e95f46b" category="cell">Sistema operativo su Worker1</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8.1</block>
  <block id="7cf4fea896dee61293d729d9985621d7" category="cell">Orchestrazione di container</block>
  <block id="ca9f0d77f73d954e88e6ab43539ac7cb" category="cell">1.6.0</block>
  <block id="ea704238343d48baa3a08f039015185f" category="cell">Sistema operativo per lo storage</block>
  <block id="f33749dd101d316dcf2e6953732629f9" category="cell">9.7P8</block>
  <block id="8fe1ffd8f7dcf339dd4f34aabb6e1c99" category="cell">Gestione dello storage container</block>
  <block id="a84024ce06ef98519b3b51300b2c8fbf" category="cell">20.10</block>
  <block id="0e98dfa85df93b279e4fd456b30409cf" category="admonition">Questo ambiente multi-OS mostra l'interoperabilità con le versioni del sistema operativo supportate della soluzione anthos on bare metal. Prevediamo che i clienti si standardizzeranno su uno o un sottoinsieme di sistemi operativi per l'implementazione.</block>
  <block id="d94e09dc1956d9513e690f8d24852f05" category="inline-link">Anthos sulla documentazione bare metal</block>
  <block id="8319a8c7a5b0b686057dbf3e7b4068f2" category="paragraph">Per i requisiti hardware e software di anthos on bare metal, consultare<block ref="ee9c468e431b4e6c834acacee08b5282" category="inline-link-rx"></block> pagina.</block>
  <block id="71196ec10a92c76a666a93f55523b96e" category="inline-link-macro">Avanti: Riepilogo dell'implementazione.</block>
  <block id="1b8d67e147d4d9c532832778cca5fee8" category="paragraph"><block ref="1b8d67e147d4d9c532832778cca5fee8" category="inline-link-macro-rx"></block></block>
  <block id="5cb451e1c66a533348d9c913d8c630e3" category="inline-link-macro">Pagina successiva: Panoramica della soluzione.</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="doc">Panoramica della soluzione</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="inline-link">Trident</block>
  <block id="9fc7e91d0cfa196bee652e5b3ab8991b" category="doc">Convalida della soluzione</block>
  <block id="4b774a4819b60036fd16dae7b1618fe7" category="inline-link-macro">Prossimo: Conclusione.</block>
  <block id="06dc93ff20817f0d5fb8a07f8e43d6cb" category="doc">Riepilogo dell'implementazione</block>
  <block id="f913f3c8b073438c23eb36c9cf8237ac" category="section-title">Creare una macchina virtuale</block>
  <block id="71dd19ec5a595517b0b57750ad1a6568" category="paragraph">Le VM sono implementazioni stateful che richiedono volumi per ospitare il sistema operativo e i dati. Con CNV, poiché le macchine virtuali vengono eseguite come pod, le macchine virtuali vengono supportate da PVS ospitati su NetApp ONTAP tramite Trident. Questi volumi sono collegati come dischi e memorizzano l'intero file system, inclusa l'origine di boot della macchina virtuale.</block>
  <block id="e01cb9126428f7417091e42362dcb6cb" category="image-alt">Creare un'architettura VM</block>
  <block id="51f24796fdd958a7a4ab9fb9a1086c9a" category="paragraph">Per creare una macchina virtuale sul cluster OpenShift, attenersi alla seguente procedura:</block>
  <block id="eaeef52618dbbd29ca52633c93abcbb4" category="list-text">Selezionare il sistema operativo desiderato e fare clic su Next (Avanti).</block>
  <block id="6befc3ce0d5cbd575434f0d5e1ec1125" category="list-text">Se nel sistema operativo selezionato non è configurata alcuna origine di avvio, è necessario configurarla. Per Boot Source (origine di avvio), selezionare se si desidera importare l'immagine del sistema operativo da un URL o da un registro e fornire i dettagli corrispondenti. Espandere Advanced (Avanzate) e selezionare Trident-Backed StorageClass (StorageClass supportato da Trident). Quindi fare clic su Next (Avanti).</block>
  <block id="9b992d4161d9af3e77a9c4e35f9d7652" category="image-alt">Creare l'origine di boot per la macchina virtuale</block>
  <block id="fe46fcd3bb2eadd55896f6a4e9af5b05" category="list-text">Se il sistema operativo selezionato ha già una sorgente di avvio configurata, il passaggio precedente può essere ignorato.</block>
  <block id="c119644bb97e69cc47555d48ff5ead07" category="list-text">Se si desidera personalizzare la macchina virtuale, fare clic su Customize Virtual Machine (Personalizza macchina virtuale) e modificare i parametri richiesti.</block>
  <block id="8b2c60e63de0927cca5bd9401cdd4647" category="list-text">Fare clic su Create Virtual Machine (Crea macchina virtuale) per creare la macchina virtuale; in questo modo viene fatto rotare in background un pod corrispondente.</block>
  <block id="ba7734e1db4ae3c0a25330f01ced054d" category="paragraph">Quando un'origine di avvio viene configurata per un modello o un sistema operativo da un URL o da un registro, crea un PVC in<block ref="1f9b99deb0fa755d5d42404160cfd87f" prefix=" " category="inline-code"></block> Proiettare e scaricare l'immagine guest KVM sul PVC. È necessario assicurarsi che i PVC modello dispongano di spazio di provisioning sufficiente per ospitare l'immagine guest KVM per il sistema operativo corrispondente. Questi PVC vengono quindi clonati e collegati come rootdisk alle macchine virtuali quando vengono creati utilizzando i rispettivi modelli in qualsiasi progetto.</block>
  <block id="2188a3011c4ccaa5490bcaca14a05579" category="inline-link-macro">Segue: Flussi di lavoro: VM Live Migration.</block>
  <block id="a997d50e238a53b066824f32046c10ab" category="paragraph"><block ref="a997d50e238a53b066824f32046c10ab" category="inline-link-macro-rx"></block></block>
  <block id="35be109b995061abd3392d1b01fd0e9a" category="summary">La piattaforma Red Hat OpenStack offre una base integrata per creare, implementare e scalare un cloud privato OpenStack sicuro e affidabile.</block>
  <block id="639813d9aa126816c3f9e9de2a45ce17" category="paragraph">OSP è un cloud Infrastructure-as-a-service (IaaS) implementato da una raccolta di servizi di controllo che gestiscono risorse di calcolo, storage e networking. L'ambiente viene gestito tramite un'interfaccia basata su web che consente ad amministratori e utenti di controllare, eseguire il provisioning e automatizzare le risorse di OpenStack. Inoltre, l'infrastruttura OpenStack è facilitata da un'ampia interfaccia a riga di comando e API che consentono funzionalità di automazione complete per amministratori e utenti finali.</block>
  <block id="dc34aa9761794ceabad79dc29944976e" category="paragraph">Il progetto OpenStack è un progetto della community sviluppato rapidamente che fornisce release aggiornate ogni sei mesi. Inizialmente Red Hat OpenStack Platform ha mantenuto il passo con questo ciclo di release pubblicando una nuova release insieme a ogni release upstream e fornendo supporto a lungo termine per ogni terza release. Di recente, con la release di OSP 16.0 (basata su OpenStack Train), Red Hat ha scelto di non tenere il passo con i numeri di release, ma ha invece trasferito le nuove funzionalità nelle subrelease. La versione più recente è Red Hat OpenStack Platform 16.1, che include funzionalità avanzate con backport delle release Usuri e Victoria in upstream.</block>
  <block id="737c38dd225185612ac8fa148ae9583e" category="inline-link">Sito Web della piattaforma Red Hat OpenStack</block>
  <block id="19fb2090425be8f78441166e8f1d8d6f" category="paragraph">Per ulteriori informazioni su OSP, vedere<block ref="9c79780f89511512bd5bf54ce21d04de" category="inline-link-rx"></block>.</block>
  <block id="e2ab8aafc6151adfa655ffd5d2425e7d" category="section-title">Servizi OpenStack</block>
  <block id="ffd7a6889e6ea6965969472250235082" category="paragraph">I servizi della piattaforma OpenStack vengono implementati come container, isolando i servizi l'uno dall'altro e consentendo facili aggiornamenti. La piattaforma OpenStack utilizza un set di container creati e gestiti con Kolla. L'implementazione dei servizi viene eseguita estraendo le immagini container dal Red Hat Custom Portal. Questi container di servizio vengono gestiti utilizzando il comando Podman e vengono implementati, configurati e gestiti con Red Hat OpenStack Director.</block>
  <block id="f5fdcf6d68d437c59942a35d79b8c7b1" category="paragraph"><block ref="f5fdcf6d68d437c59942a35d79b8c7b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2ba7e785c49050f48da9aacc45c2b85" category="cell">Servizio</block>
  <block id="7adea0d9c77aabccd8bb67ae0a832d59" category="cell">Nome del progetto</block>
  <block id="2938c7f7e560ed972f8a4f68e80ff834" category="cell">Dashboard</block>
  <block id="85fb7708d989f936cb51ef53a8af080f" category="cell">Orizzonte</block>
  <block id="d5a9efab6df20a9e132b774795775dde" category="cell">Dashboard basato su browser Web che consente di gestire i servizi OpenStack.</block>
  <block id="c9c5c65fb4af9cf90eb99b3b84424189" category="cell">Identità</block>
  <block id="1ce2096c300f78bbb8389ca2603e6dd9" category="cell">Keystone</block>
  <block id="91c68681aadba9c0e8308f7d0b3cc416" category="cell">Servizio centralizzato per l'autenticazione e l'autorizzazione dei servizi OpenStack e per la gestione di utenti, progetti e ruoli.</block>
  <block id="e7a39f4cb0dd0ffaaffe8fb0319dec67" category="cell">Networking OpenStack</block>
  <block id="88fac409baf592beb25e285d8663edcb" category="cell">Neutroni</block>
  <block id="0283e46fd80198d441eb742b88cf96f1" category="cell">Fornisce connettività tra le interfacce dei servizi OpenStack.</block>
  <block id="4f0550f066ae72bb8c24fc3f59c323bf" category="cell">Storage a blocchi</block>
  <block id="a7173cc5cdd0e31df00cd34f058b1d33" category="cell">Cinder</block>
  <block id="597dab3a2b3c74e3c266b2f65ec28619" category="cell">Gestisce volumi di storage a blocchi persistenti per macchine virtuali (VM).</block>
  <block id="6e747c4965495f2e26bf17e647aa0083" category="cell">Nova</block>
  <block id="f13c04e9c49274cd31bd8092c8f50304" category="cell">Gestisce ed esegue il provisioning delle macchine virtuali in esecuzione sui nodi di calcolo.</block>
  <block id="be53a0541a6d36f6ecb879fa2c584b08" category="cell">Immagine</block>
  <block id="10ec3a0506fab7073649337ca7be7979" category="cell">Panoramica</block>
  <block id="d9ff71ddcb6bbbe8ad48ae8b678369d4" category="cell">Servizio di registro utilizzato per memorizzare risorse come immagini di macchine virtuali e snapshot di volumi.</block>
  <block id="670aaecb1a526fbed439dad3ec353a96" category="cell">Storage a oggetti</block>
  <block id="ae832e9b5bda2699db45f3fa6aa8c556" category="cell">Rapido</block>
  <block id="41c380458dfcdc118ef573a2d98c6acb" category="cell">Consente agli utenti di memorizzare e recuperare file e dati arbitrari.</block>
  <block id="aa96a21412def0d916f43b639424f8e4" category="cell">Telemetria</block>
  <block id="8fb4b5e28f192236eaa9e4972f810dbd" category="cell">Ceilometro</block>
  <block id="ed622b9c64858cc66a01c58893b5d39d" category="cell">Fornisce misurazioni dell'utilizzo delle risorse cloud.</block>
  <block id="7d486371bb65b0633535ceba4189d8ed" category="cell">Calore</block>
  <block id="abaa6ebae60b74638c54a43f3341db8e" category="cell">Motore di orchestrazione basato su modelli che supporta la creazione automatica di stack di risorse.</block>
  <block id="5ddbd3cec63b14995bf6a5823b692de7" category="paragraph">La soluzione Red Hat OpenShift con NetApp utilizza due switch dati per fornire connettività dati primaria a 25 Gbps. Utilizza inoltre due switch di gestione aggiuntivi che forniscono connettività a 1 Gbps per la gestione in-band dei nodi di storage e gestione out-of-band per la funzionalità IPMI.</block>
  <block id="b81a67bf2ab52e16a62a9c71454c90ee" category="paragraph">Red Hat OpenStack Director richiede la funzionalità IPMI per implementare la piattaforma Red Hat OpenStack utilizzando il servizio di provisioning bare-metal ironico.</block>
  <block id="c546b983b02d8654c5b245147d99dcf0" category="paragraph">Red Hat OpenShift con NetApp è progettato per separare logicamente il traffico di rete per scopi diversi utilizzando Virtual Local Area Network (VLAN). Questa configurazione può essere scalata per soddisfare le esigenze dei clienti o per fornire un ulteriore isolamento per servizi di rete specifici. La seguente tabella elenca le VLAN necessarie per implementare la soluzione durante la convalida della soluzione in NetApp.</block>
  <block id="414b4843c124e72b43bccf2948a53a41" category="cell">Rete utilizzata per la gestione dei nodi fisici e servizio IPMI per ironico.</block>
  <block id="567f5ee3e60ecdd5338b39cab0006510" category="cell">Infrastruttura storage</block>
  <block id="e8cbca2d71bd2aeff622a07b4ffad6c2" category="cell">Rete utilizzata per i nodi controller per mappare i volumi direttamente per supportare servizi di infrastruttura come Swift.</block>
  <block id="757b505cfd34c64c85ca5b5690ee5293" category="cell">201</block>
  <block id="e103375dfc18f23e4fc072903e894fe9" category="cell">Storage Cinder</block>
  <block id="0bdfa6389eb47674a02f6049f342785d" category="cell">Rete utilizzata per mappare e collegare i volumi a blocchi direttamente alle istanze virtuali implementate nell'ambiente.</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202</block>
  <block id="772d9a23b79ccb504fa0590644934c3b" category="cell">API interna</block>
  <block id="e44f5f63400b0975b884dc2980ee3a61" category="cell">Rete utilizzata per la comunicazione tra i servizi OpenStack utilizzando la comunicazione API, i messaggi RPC e la comunicazione con il database.</block>
  <block id="34ed066df378efacc9b924ec161e7639" category="cell">301</block>
  <block id="6252d0571760e3d285e2e41a2b1e7743" category="cell">Tenant</block>
  <block id="ea414c629935302b115bf3dabf5f827c" category="cell">Neutron fornisce a ciascun tenant le proprie reti tramite il tunneling tramite VXLAN. Il traffico di rete viene isolato all'interno di ciascuna rete tenant. A ciascuna rete tenant è associata una subnet IP e gli spazi dei nomi di rete indicano che più reti tenant possono utilizzare lo stesso intervallo di indirizzi senza causare conflitti.</block>
  <block id="577bcc914f9e55d5e4e4f82f9f00e7d4" category="cell">302</block>
  <block id="bfd15aa26ba0ced782240c4a8b7e517e" category="cell">Gestione dello storage</block>
  <block id="cdc529b5e11a981e4597195c5f1c53b5" category="cell">OpenStack Object Storage (Swift) utilizza questa rete per sincronizzare gli oggetti dati tra i nodi di replica partecipanti. Il servizio proxy funge da interfaccia intermedia tra le richieste degli utenti e il livello di storage sottostante. Il proxy riceve le richieste in entrata e individua la replica necessaria per recuperare i dati richiesti.</block>
  <block id="11b9842e0a271ff252c1903e7132cd68" category="cell">303</block>
  <block id="5214f1e2490f3878e307fd6f81f9f77f" category="cell">PXE</block>
  <block id="16d856c79e739181f35adfe5b791c650" category="cell">OpenStack Director offre l'avvio PXE come parte dell'ironico servizio di provisioning bare metal per orchestrare l'installazione di OSP Overcloud.</block>
  <block id="966b6dfb6b0819cc10644bea3115cf20" category="cell">3484</block>
  <block id="b206a1b4ea1097761f78e8876f6da779" category="cell">Esterno</block>
  <block id="f2feccaa3f5d086f0b16010ff463e369" category="cell">Rete pubblicamente disponibile che ospita OpenStack Dashboard (Horizon) per la gestione grafica e consente alle chiamate API pubbliche di gestire i servizi OpenStack.</block>
  <block id="dfeb9598fbfb97cc6bbcc0aff2c785d6" category="cell">3485</block>
  <block id="32223320445c4cf46444e40ebde18b7e" category="cell">Fornisce l'accesso a funzioni di amministrazione del sistema come accesso SSH, traffico DNS e traffico NTP (Network Time Protocol). Questa rete funge anche da gateway per i nodi non controller.</block>
  <block id="ab4f2b5fd96ca65349119909c1eada2d" category="cell">3486</block>
  <block id="f2260a90424f1d412334d1b3467abd22" category="list-text">Almeno un server DNS che fornisce una risoluzione completa del nome host.</block>
  <block id="d70672769aa84f2a999291a645e67355" category="list-text">Almeno tre server NTP in grado di mantenere sincronizzato il tempo per i server della soluzione.</block>
  <block id="478a3526bd6097c6b7a330fd6aae410e" category="list-text">(Opzionale) connettività Internet in uscita per l'ambiente OpenShift.</block>
  <block id="9a14258452ea5da50d562e08e5b9291c" category="section-title">Implementa OpenShift su un cloud privato OSP con almeno tre nodi di calcolo</block>
  <block id="493fd05bc58266bcd8394072cbe81748" category="paragraph">L'architettura verificata descritta in questo documento presenta l'implementazione hardware minima adatta per le operazioni ha implementando tre nodi controller OSP e due nodi di calcolo OSP. Questa architettura garantisce una configurazione a tolleranza di errore in cui entrambi i nodi di calcolo possono lanciare istanze virtuali e le macchine virtuali implementate possono migrare tra i due hypervisor.</block>
  <block id="ebe803a768c48af52bca59e6ab7df9bf" category="paragraph">Poiché Red Hat OpenShift inizialmente viene implementato con tre nodi master, una configurazione a due nodi potrebbe causare l'occupazione di almeno due master nello stesso nodo, il che può causare un'interruzione di OpenShift se tale nodo specifico non è disponibile. Pertanto, è una Best practice di Red Hat implementare almeno tre nodi di calcolo OSP in modo che i master OpenShift possano essere distribuiti in modo uniforme e la soluzione riceva un ulteriore livello di tolleranza agli errori.</block>
  <block id="bbfdc160550acbcdb4791a961a165d5d" category="paragraph">La distribuzione dei master OpenShift tra più nodi hypervisor può essere ottenuta abilitando l'affinità VM/host.</block>
  <block id="cb346122cae28dfb1fcf0811f46296a2" category="paragraph">Affinity è un modo per definire le regole per un insieme di macchine virtuali e/o host che determinano se le macchine virtuali vengono eseguite insieme sullo stesso host o su host del gruppo o su host diversi. Viene applicato alle macchine virtuali creando gruppi di affinità costituiti da macchine virtuali e/o host con un insieme di parametri e condizioni identici. A seconda che le macchine virtuali di un gruppo di affinità vengano eseguite sullo stesso host o su host del gruppo o separatamente su host diversi, i parametri del gruppo di affinità possono definire affinità positiva o affinità negativa. Nella piattaforma Red Hat OpenStack, è possibile creare e applicare le regole di affinità e anti-affinità degli host creando gruppi di server e configurando i filtri in modo che le istanze distribuite da Nova in un gruppo di server vengano distribuite su nodi di calcolo diversi.</block>
  <block id="9c0af999b760fac2aa82d9d105fa7a7e" category="paragraph">Un gruppo di server dispone di un massimo predefinito di 10 istanze virtuali per le quali può gestire il posizionamento. È possibile modificare questa impostazione aggiornando le quote predefinite per Nova.</block>
  <block id="de5bd213c3df23736df75636241f96de" category="admonition">Esiste un limite specifico di affinità/anti-affinità per i gruppi di server OSP; se non sono disponibili risorse sufficienti per l'implementazione su nodi separati o se non sono disponibili risorse sufficienti per consentire la condivisione dei nodi, la macchina virtuale non viene avviata.</block>
  <block id="8aea038e418642b1735131358c24a866" category="inline-link">Come si configurano affinità e anti-affinità per le istanze di OpenStack?</block>
  <block id="d90e13a49726d9175649113d81f4caa7" category="paragraph">Per configurare i gruppi di affinità, vedere<block ref="f5b5be16184c5362a1ca218025e91581" category="inline-link-rx"></block>.</block>
  <block id="47a822101acb11c74a4877a3d0b77093" category="inline-link">Red Hat OpenShift Installazione di un cluster su OpenStack con personalizzazioni</block>
  <block id="42bb5e38e5b1c611bdce679410b24d67" category="paragraph">In questi casi, è possibile eseguire ed eseguire le procedure guidate senza implementare immediatamente un cluster; al contrario, viene creato un file di configurazione da cui il cluster può essere distribuito in un secondo momento. Questa funzione è molto utile se si desidera modificare le impostazioni predefinite dell'IPI o se si desidera implementare più cluster identici nell'ambiente per altri utilizzi, ad esempio la multi-tenancy. Per ulteriori informazioni sulla creazione di una configurazione di installazione personalizzata per OpenShift, vedere<block ref="05810b34cd92ddfe8fd049160cb24f72" category="inline-link-rx"></block>.</block>
  <block id="4e92dab2ab2bbe684f09a2aca58c9e44" category="list-text">Cluster NetApp ONTAP</block>
  <block id="f675b3d5e1e137870f481a742a3ec0af" category="list-text">Trident installato sul cluster</block>
  <block id="1db1a9d97c708824712706fc4267ec25" category="list-text">Workstation di amministrazione con tool tridentctl e oc installati e aggiunti al percorso dei dollari</block>
  <block id="7cf4175762acfbabf9178d34f2504b28" category="list-text">Accesso amministratore a ONTAP</block>
  <block id="10a540d0ed57154e8676c5725af53935" category="list-text">Accesso cluster-admin al cluster OpenShift</block>
  <block id="6340f6ab1111f349228595ebceb8f6db" category="list-text">Il cluster è integrato con il provider di identità</block>
  <block id="9e110c19bb79322a0b76199795550dea" category="list-text">Il provider di identità è configurato in modo da distinguere in modo efficiente tra gli utenti di diversi team</block>
  <block id="b917a2bfe0dd0160c3ad88751f355f5d" category="inline-link-macro">Avanti: Attività dell'amministratore del cluster.</block>
  <block id="7a9f102fda0e3438bff54da4acdbccbb" category="paragraph"><block ref="7a9f102fda0e3438bff54da4acdbccbb" category="inline-link-macro-rx"></block></block>
  <block id="a62e902f0d244d960eddf2f14d3afa6f" category="paragraph">OpenShift su bare metal offre un'implementazione automatica della piattaforma container OpenShift sui server commodity.</block>
  <block id="0e05c6235b67ae8e5b743c9ca77358fa" category="paragraph">OpenShift su bare metal è simile alle implementazioni virtuali di OpenShift, che offrono facilità di implementazione, provisioning rapido e scalabilità dei cluster OpenShift, supportando al contempo i carichi di lavoro virtualizzati per le applicazioni non pronte per essere containerizzate. L'implementazione su bare metal non richiede l'overhead aggiuntivo necessario per gestire l'ambiente dell'hypervisor host oltre all'ambiente OpenShift. Implementando direttamente sui server bare metal, è possibile ridurre anche i limiti di overhead fisico dovuti alla condivisione delle risorse tra l'host e l'ambiente OpenShift.</block>
  <block id="67a3852a946bc539243cc1e5f8982d03" category="section-title">OpenShift su bare metal offre le seguenti funzionalità:</block>
  <block id="9a3c3034787ddbd4af974d73f795c75a" category="list-text">*IPI o installazione assistita.* con un cluster OpenShift implementato da Installer Provised Infrastructure (IPI) su server bare metal, i clienti possono implementare un ambiente OpenShift altamente versatile e facilmente scalabile direttamente sui commodity server, senza la necessità di gestire un layer hypervisor.</block>
  <block id="bf995f5252e568d22b265ec62c16914c" category="list-text">*Progettazione di cluster compatti.* per ridurre al minimo i requisiti hardware, OpenShift on bare metal consente agli utenti di implementare cluster di soli 3 nodi, consentendo ai nodi del piano di controllo OpenShift di agire anche come nodi di lavoro e container host.</block>
  <block id="13442dfd439ae0a377b0a2d2d9df1709" category="list-text">*Virtualizzazione OpenShift.* OpenShift può eseguire macchine virtuali all'interno di container utilizzando la virtualizzazione OpenShift. Questa virtualizzazione nativa per container esegue l'hypervisor KVM all'interno di un container e collega volumi persistenti per lo storage delle macchine virtuali.</block>
  <block id="6e6a5272d3c6f8eceb96e3c19f0faaf6" category="list-text">*Infrastruttura ottimizzata per ai/ML.* implementa applicazioni come Kubeflow per applicazioni di machine learning incorporando nodi di lavoro basati su GPU nel tuo ambiente OpenShift e sfruttando OpenShift Advanced Scheduling.</block>
  <block id="6bc136fcf409560a1029f6f323619bbf" category="paragraph">La soluzione Red Hat OpenShift su NetApp utilizza due switch dati per fornire connettività dati primaria a 25 Gbps. Utilizza inoltre due switch di gestione che forniscono connettività a 1 Gbps per la gestione in-band dei nodi di storage e gestione out-of-band per la funzionalità IPMI.</block>
  <block id="17fea9675576fc9c72deb9501a5fd16a" category="paragraph">Per l'implementazione di OpenShift Bare-Metal IPI, è necessario creare un nodo di provisioning, una macchina Red Hat Enterprise Linux 8 che deve avere interfacce di rete collegate a reti separate.</block>
  <block id="2f42f99315e0171a6e5c61957ae4689c" category="list-text">*Provisioning network.* questa rete viene utilizzata per avviare i nodi bare-metal e installare le immagini e i pacchetti necessari per implementare il cluster OpenShift.</block>
  <block id="aba727a2dc3dd836a33a2022bb2a9c3f" category="list-text">*Rete bare-metal.* questa rete viene utilizzata per la comunicazione pubblica del cluster dopo l'implementazione.</block>
  <block id="7633522f66aaba6bc4bb2c25d299d287" category="paragraph">Per la configurazione del nodo di provisioning, il cliente crea interfacce di bridge che consentono al traffico di instradare correttamente sul nodo stesso e sulla macchina virtuale Bootstrap fornita a scopo di implementazione. Una volta implementato il cluster, l'API e gli indirizzi VIP di ingresso vengono migrati dal nodo di boot strap al cluster appena implementato.</block>
  <block id="963d7d04e1f1692a7fc49ae899123dbd" category="paragraph">Le immagini seguenti illustrano l'ambiente sia durante l'implementazione IPI che al termine dell'implementazione.</block>
  <block id="096e71732ebcd1f43544a7159596cb17" category="paragraph"><block ref="096e71732ebcd1f43544a7159596cb17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb18861dc375756df1a31b7ed3c03f38" category="paragraph"><block ref="bb18861dc375756df1a31b7ed3c03f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5a0639a1bbc3695e0ebaf4c3affe363" category="paragraph">La soluzione Red Hat OpenShift con NetApp è progettata per separare logicamente il traffico di rete per scopi diversi utilizzando Virtual Local Area Network (VLAN).</block>
  <block id="3d9073c9e531118eb3aff0f20647c86f" category="cell">Gestione per nodi bare metal e IPMI</block>
  <block id="f53272342c85041784b2d5136e6eaa7d" category="cell">Rete bare-metal</block>
  <block id="44a94f76baabd05ab407f76c946326c8" category="cell">Rete per i servizi OpenShift una volta che il cluster è disponibile</block>
  <block id="11405696f0e53417a3847f430a7b8ed0" category="cell">Rete di provisioning</block>
  <block id="846325c36d78e7582d8bfcab277ca67a" category="cell">Rete per l'avvio PXE e l'installazione di nodi bare metal tramite IPI</block>
  <block id="eb5f501445f81cb1f7f4cf290565f9c8" category="admonition">Sebbene ciascuna di queste reti sia virtualmente separata da VLAN, ciascuna porta fisica deve essere impostata in modalità di accesso con la VLAN primaria assegnata, poiché non esiste alcun modo di passare un tag VLAN durante una sequenza di avvio PXE.</block>
  <block id="3ab0ae61b5256f874297403903fd5afc" category="paragraph">Prima dell'implementazione della piattaforma container OpenShift, è necessario installare la seguente infrastruttura:</block>
  <block id="06a9d12a76441fd395abeba7bf0d7b91" category="list-text">Almeno un server DNS che fornisce una risoluzione completa del nome host accessibile dalla rete di gestione in-band e dalla rete VM.</block>
  <block id="943dbb8750d636d9918af903ac016c0e" category="summary">NetApp dispone di diverse piattaforme storage qualificate con il nostro Trident Storage Orchestrator per il provisioning dello storage per le applicazioni implementate su Red Hat OpenShift.</block>
  <block id="3dbb1adfd571e8b44af1259f287d723f" category="paragraph">NetApp dispone di diverse piattaforme di storage qualificate con Astra Trident Storage Orchestrator per il provisioning dello storage per le applicazioni implementate su Red Hat OpenShift.</block>
  <block id="85a240011ba49404bf70606e37c41c96" category="paragraph">Le pagine seguenti contengono informazioni aggiuntive sui sistemi di storage NetApp validati nella soluzione Red Hat OpenShift con NetApp:</block>
  <block id="3a374bfcdd912b5071f863e2b9f0eefa" category="list-text"><block ref="3a374bfcdd912b5071f863e2b9f0eefa" category="inline-link-macro-rx"></block></block>
  <block id="70b44fe3d3567f3f2a5ccd67ff8ac852" category="list-text"><block ref="70b44fe3d3567f3f2a5ccd67ff8ac852" category="inline-link-macro-rx"></block></block>
  <block id="7c613b296892d4712b9041d3081282f8" category="summary">Gestione avanzata dei cluster per Kubernetes su Red Hat OpenShift con NetApp.</block>
  <block id="78e1aefe2bbb2518f1156636e761e479" category="paragraph">Per installare Advanced Cluster Management per Kubernetes su un cluster OpenShift, attenersi alla seguente procedura:</block>
  <block id="b17056cdbd9ec695d4348e1ad799ace4" category="list-text">Scegliere un cluster OpenShift come cluster hub e accedervi con privilegi di amministratore del cluster.</block>
  <block id="bc2ab7a7550cebeb52a08cf830b5ecf6" category="list-text">Accedere a Operators &gt; Operators Hub e cercare Advanced Cluster Management for Kubernetes.</block>
  <block id="2e5d3941e033e96d5317cc2bbd1da914" category="image-alt">Riquadro ACM</block>
  <block id="c4ab802b80978ba1c5de3922d546bdb7" category="list-text">Selezionare Advanced Cluster Management for Kubernetes (Gestione avanzata cluster per Kubernetes) e fare clic su Install (Installa).</block>
  <block id="cc5a9dd5971b8369354db684e5dbfe2b" category="image-alt">Dettagli del riquadro ACM</block>
  <block id="c972585d6241c4f2ed2604bcc8706358" category="list-text">Nella schermata Install Operator (operatore di installazione), fornire i dettagli necessari (NetApp consiglia di conservare i parametri predefiniti) e fare clic su Install (Installa).</block>
  <block id="72b342ddabad6a9ec11df82389c40b88" category="image-alt">Installare la tessera ACM Operator</block>
  <block id="64524f91c2fdfcd54b4bbcab35392908" category="image-alt">Installazione dell'operatore ACM in corso</block>
  <block id="7bf3d0678c48be5730f20005e6f88aa1" category="list-text">Una volta installato l'operatore, fare clic su Create MultiClusterHub (Crea MultiClusterHub).</block>
  <block id="e0d84ec6a5b8f92909a7a3bef11455c1" category="image-alt">Operatore ACM Multiplexerhub</block>
  <block id="95f29f27e373a9759cf065e1fde23e28" category="list-text">Nella schermata Create MultiClusterHub (Crea MultiClusterHub), fare clic su Create (Crea) dopo aver inserito i dettagli. In questo modo viene avviata l'installazione di un hub multi-cluster.</block>
  <block id="344f0cb43d1b2e7a719bea808fe7c5bf" category="image-alt">Schermata Create Multiploud hub</block>
  <block id="a50aa5e8249109d6f4902945e968ad7d" category="list-text">Dopo che tutti i pod sono stati spostati nello stato in esecuzione nello spazio dei nomi di gestione del cluster aperto e l'operatore passa allo stato riuscito, viene installata la funzione Advanced Cluster Management per Kubernetes.</block>
  <block id="851548d1ad843a23609f325e8b54e72d" category="image-alt">Operatore ACM installato</block>
  <block id="391dd52c88201d377f1572062e22c43e" category="list-text">Il completamento dell'installazione dell'hub richiede un po' di tempo e, una volta completata, l'hub MultiCluster passa allo stato di esecuzione.</block>
  <block id="c7aa79f0c31ac15d728ee47c7e6eaee2" category="image-alt">Hub multigruppo pronto</block>
  <block id="eef36825efd5d2d40e4f833635cd19da" category="list-text">Crea un percorso nello spazio dei nomi di gestione del cluster aperto. Connettersi all'URL nel percorso per accedere alla console Advanced Cluster Management.</block>
  <block id="f761fad3f1c25e94d5f46ebd9e23a901" category="image-alt">Percorso della console ACM</block>
  <block id="4488e277b96ae08def5eb77c2d8c6e74" category="inline-link-macro">Avanti: Funzionalità - Gestione del ciclo di vita del cluster.</block>
  <block id="8a4d50965d8a3c708bdb16a716d64246" category="paragraph"><block ref="8a4d50965d8a3c708bdb16a716d64246" category="inline-link-macro-rx"></block></block>
  <block id="7715f0efda43c06909ce1afad9f650b6" category="inline-link-macro">Pagina successiva: Ulteriori informazioni: DevOps con NetApp Astra.</block>
  <block id="5d74a508c84dc62d2e7a448ba2c651fa" category="paragraph"><block ref="5d74a508c84dc62d2e7a448ba2c651fa" category="inline-link-macro-rx"></block></block>
  <block id="943b2a1ab5485e1a2db3098051987614" category="summary">Utilizzo della tecnologia FlexClone per una rapida implementazione</block>
  <block id="065cb44483a670695f374bc25a1f01b4" category="doc">Validazione dei casi d'utilizzo: DevOps con NetApp Astra</block>
  <block id="438d983a4a02b97c1363407ba1bb3dbd" category="paragraph">I seguenti casi di utilizzo sono stati validati per DevOps con NetApp Astra:</block>
  <block id="47d55e9f9b259c93da777f74a5e832ee" category="inline-link-macro">Integra la protezione nelle pipeline ci/CD con NetApp Astra Control</block>
  <block id="86ebb4e5f51da406d6b6170528e02c8c" category="list-text"><block ref="86ebb4e5f51da406d6b6170528e02c8c" category="inline-link-macro-rx"></block></block>
  <block id="a9e51e0a4f30c204f900ee62c24b54e8" category="inline-link-macro">Sfrutta Astra Control per facilitare l'analisi post-mortem e ripristinare l'applicazione</block>
  <block id="5ea6f0d962656bf6d901dedc10e9da49" category="list-text"><block ref="5ea6f0d962656bf6d901dedc10e9da49" category="inline-link-macro-rx"></block></block>
  <block id="6c9a3a62fc54ba1feccaee9df9c39f88" category="inline-link-macro">Accelerazione dello sviluppo software con NetApp FlexClones</block>
  <block id="001bc4e878f5da889174d53f10bc3a58" category="list-text"><block ref="001bc4e878f5da889174d53f10bc3a58" category="inline-link-macro-rx"></block></block>
  <block id="69955eeaaa4d02c4d90d3119741235a0" category="inline-link-macro">Pagina successiva: Video e demo - DevOps con NetApp Astra.</block>
  <block id="d2ed0f238fb1fa6e7a14606baf24c2ab" category="paragraph"><block ref="d2ed0f238fb1fa6e7a14606baf24c2ab" category="inline-link-macro-rx"></block></block>
  <block id="72a943bda30daac28d5a7097897df424" category="summary">NetApp offre una serie di prodotti che assistono i nostri clienti nell'orchestrazione e nella gestione dei dati persistenti in ambienti basati su container.</block>
  <block id="87517df6852cb879fffc1e5811e773eb" category="paragraph">NetApp offre una serie di prodotti che consentono di orchestrare, gestire, proteggere e migrare le applicazioni stateful containerizzate e i relativi dati.</block>
  <block id="c60042e38b748289146bd910731af5f0" category="paragraph">NetApp Astra Control offre un set completo di servizi di gestione dei dati application-aware e storage per carichi di lavoro Kubernetes stateful basati sulla tecnologia di protezione dei dati di NetApp. Astra Control Service è disponibile per supportare carichi di lavoro stateful nelle implementazioni Kubernetes native nel cloud. Astra Control Center è disponibile per supportare carichi di lavoro stateful in implementazioni on-premise di piattaforme Enterprise Kubernetes come {k8s_distribution_name}. Per ulteriori informazioni, visita il sito Web di NetApp Astra Control<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="d9ac8f9dec3643254ee6240ba67244f5" category="list-text"><block ref="d9ac8f9dec3643254ee6240ba67244f5" category="inline-link-macro-rx"></block></block>
  <block id="dd2387c2fbbd7ec35d40da2a116c5349" category="list-text"><block ref="dd2387c2fbbd7ec35d40da2a116c5349" category="inline-link-macro-rx"></block></block>
  <block id="0218e43406cb3e0a01af575972d39479" category="inline-link-macro">Pagina successiva: Validazioni dei casi d'utilizzo: DevOps con NetApp Astra.</block>
  <block id="138b9ec9c8120fa5dbf98537df5269d4" category="paragraph"><block ref="138b9ec9c8120fa5dbf98537df5269d4" category="inline-link-macro-rx"></block></block>
  <block id="8bd43c9f55116966ac61fd08aa3cd4bf" category="list-text">Integrazione perfetta con un cloud pubblico per tiering e protezione dei dati. ONTAP offre inoltre solide funzionalità di protezione dei dati che lo differenziano in qualsiasi ambiente:</block>
  <block id="a95908309fdc4765216365a8dc7d2561" category="paragraph">Entrambi i sistemi sono basati sul software per la gestione dei dati NetApp ONTAP, il software per la gestione dei dati più avanzato del settore per una gestione dello storage semplificata, altamente disponibile e integrata nel cloud, per offrire velocità, efficienza e sicurezza di livello Enterprise per le tue esigenze di data fabric.</block>
  <block id="158de41b0c768154e1c26d384097971b" category="paragraph">ONTAP Select è un'implementazione software-defined di NetApp ONTAP che può essere implementata su un hypervisor nel tuo ambiente. Può essere installato su VMware vSphere o su KVM e offre tutte le funzionalità e l'esperienza di un sistema ONTAP basato su hardware.</block>
  <block id="9c38b2d834f16a22a033cc493828d911" category="paragraph">NetApp Cloud Volumes ONTAP è una versione di NetApp ONTAP implementata nel cloud che può essere implementata in diversi cloud pubblici, tra cui Amazon AWS, Microsoft Azure e Google Cloud.</block>
  <block id="96bef5489c133651bd324f8029d14586" category="paragraph"><block ref="96bef5489c133651bd324f8029d14586" category="inline-link-macro-rx"></block></block>
  <block id="847338f2bbcf0d01da4eec4011f6ad14" category="summary">Questo report tecnico illustra in che modo NetApp rende i casi d'utilizzo DevOps semplici ed efficienti su più fronti, quando si utilizzano applicazioni containerizzate. Inizia descrivendo in dettaglio i sistemi storage NetApp e la loro integrazione con le piattaforme Kubernetes utilizzando il portfolio Astra. Infine, vengono analizzate e documentate una serie di validazioni delle soluzioni e casi di utilizzo reali.</block>
  <block id="322f410c2f08f93c29982d4bf9cabcc0" category="doc">TR-4919: DevOps con NetApp Astra</block>
  <block id="ede7528f12f050f41a167a0f19204ecb" category="paragraph">La soluzione DevOps con NetApp Astra è progettata per offrire un valore eccezionale ai clienti con i seguenti casi di utilizzo:</block>
  <block id="2dcb73ff09329212051362094e88c1a7" category="list-text">Facile da implementare e gestire applicazioni e ambienti di sviluppo implementati su distribuzioni Kubernetes supportate.</block>
  <block id="c267f4560fe6c3f4bee2d0420cdd7977" category="list-text">Discussione di casi di utilizzo reali per i flussi di lavoro DevOps ed esempi di strumenti e metodi che NetApp può fornire per semplificare l'adozione e l'utilizzo di questi metodi.</block>
  <block id="52d3258544cd838f0c52461847e6943b" category="list-text">Esplorazione di come è possibile utilizzare snapshot, backup e cloni coerenti con l'applicazione per migliorare l'esperienza DevOps.</block>
  <block id="6071498e95e7692ffc4f3f66e80e1fe2" category="list-text">Alta disponibilità a tutti i livelli dello stack, in modo che i flussi di lavoro non vengano mai interrotti.</block>
  <block id="0fd2f931dbf65015445450e54266b6dd" category="list-text">Facilità di implementazione e procedure di gestione per l'utente finale.</block>
  <block id="683aa4d78ced60b9236f9cc2f4eaf1eb" category="list-text">Infrastruttura programmabile e basata su API per restare al passo con i microservizi e l'agilità dello sviluppatore.</block>
  <block id="440bd390f196ecee0d5c1bbc242f74c1" category="list-text">Possibilità di scalare l'infrastruttura in modo indipendente e automatizzato, in base alle esigenze dei carichi di lavoro.</block>
  <block id="e1151e572983d1f8759759f2765ccd80" category="list-text">La protezione delle applicazioni insieme ai set di dati persistenti di supporto per i flussi di lavoro DevOps accelera il time-to-market senza dover fare affidamento sulle ridistribuizioni o sulla copia manuale dei dati.</block>
  <block id="556e90029d54aba834e233882cb7bdb5" category="paragraph">Riconoscendo queste funzionalità e queste sfide, questo report tecnico illustra il processo di miglioramento e semplificazione dei casi di utilizzo DevOps per le applicazioni containerizzate utilizzando l'ampio portfolio di prodotti NetApp.</block>
  <block id="3c4a3a2e21fd3a1caee264afd78ccaa4" category="paragraph">La soluzione DevOps con NetApp contiene i seguenti componenti principali:</block>
  <block id="26ebb4a3d87e964eeae59f74f1cf7565" category="section-title">Procedure DevOps</block>
  <block id="d113ef32a81ded7eb94b33e9a12344d3" category="paragraph">Le pratiche DevOps si concentrano su operazioni automatizzate, ripetibili e facilmente gestibili che migliorano il flusso di lavoro di sviluppo consentendo all'utente finale di controllare l'ambiente in cui sta sviluppando il proprio codice. Questa soluzione fornisce diversi esempi e casi di utilizzo in cui la tecnologia NetApp può essere di maggior beneficio per tali operazioni.</block>
  <block id="301a5e3f98e4b9ad41275bc224cd61ec" category="paragraph">Attualmente sono in uso numerose piattaforme di orchestrazione dei container. Anche se la maggior parte di queste piattaforme si basa su Kubernetes, ognuna ha pro e contro. Pertanto, è importante comprendere i set di funzionalità e le integrazioni quando si seleziona una piattaforma di orchestrazione container per i flussi di lavoro DevOps. Con la suite di prodotti NetApp Astra, supportiamo le seguenti piattaforme per casi di utilizzo DevOps completi:</block>
  <block id="6c00bd8314a0e887501377d7e80e84a0" category="list-text"><block ref="41493d18eda2456ccaff840381cd2ba9" category="inline-link-rx"></block> 4.6.8+</block>
  <block id="82033d4b30c6027097326898ed36b593" category="inline-link">Rancher</block>
  <block id="30fad75d887172c8bd19dcc5febd9364" category="list-text"><block ref="f47c99eede6f9eae831133d1e9b5034b" category="inline-link-rx"></block> 2.5+</block>
  <block id="30136395f01879792198317c11831ea4" category="inline-link">Kubernetes</block>
  <block id="22bd2466d697a7c77e319d9a31c2166f" category="list-text"><block ref="fe8d70118059c4a67994e27a008bb3e0" category="inline-link-rx"></block> 1.20+</block>
  <block id="a56837df79ae6671b6b511c330431135" category="inline-link">Griglia VMware Tanzu Kubernetes</block>
  <block id="b2bc0f20995d2c98d2f854eb51c195c7" category="list-text"><block ref="3f98585591c50cc93953cd157cf0939c" category="inline-link-rx"></block> 1.4+</block>
  <block id="a1c1bb4994628000cfe61563bf4ff4f5" category="inline-link">VMware Tanzu Kubernetes Grid Integrated Edition</block>
  <block id="a75ee0eed3c5f01371e94695f023b820" category="list-text"><block ref="948fe538658bc79d22a37c7852e43c83" category="inline-link-rx"></block> 1.12.2+</block>
  <block id="f582083d849d313b57029bcb7e14f0b5" category="paragraph">Per ulteriori informazioni, visitare il sito Web di NetApp<block ref="95da63d781dead5af723667a3f69096a" category="inline-link-rx"></block>.</block>
  <block id="8fe0ec287a8d48a38a4f1454d62282f5" category="paragraph">NetApp Astra Control Center offre un'ampia gamma di servizi di gestione dei dati application-aware e storage per carichi di lavoro Kubernetes stateful implementati in un ambiente on-premise e basati sulla tecnologia di protezione dei dati NetApp.</block>
  <block id="fba78f40ce7eabf1a8bf79ee5c44bd8e" category="inline-link-macro">Avanti: Panoramica su DevOps.</block>
  <block id="a9d268e4b26cd47b2d7a0aa5a816a1c8" category="paragraph"><block ref="a9d268e4b26cd47b2d7a0aa5a816a1c8" category="inline-link-macro-rx"></block></block>
  <block id="70806b7246c09c2ec58c7947d781ebdf" category="doc">Panoramica di NetApp Astra Control</block>
  <block id="c46717c86eab6ada72e202311e47bf46" category="paragraph">In un ambiente connesso al cloud, il centro di controllo Astra utilizza Cloud Insights per fornire monitoraggio avanzato e telemetria. In assenza di una connessione Cloud Insights, sono disponibili funzioni limitate di monitoraggio e telemetria (per un valore di sette giorni di metriche) ed esportate negli strumenti di monitoraggio nativi di Kubernetes (Prometheus e Grafana) attraverso endpoint di metriche aperte.</block>
  <block id="f04c9d184475a1c831571242df5998ca" category="paragraph">Oltre alla versione a pagamento di Astra Control Center, è disponibile anche una licenza di valutazione di 90 giorni. La versione di valutazione è supportata tramite e-mail e il canale slack della community. I clienti hanno accesso a queste risorse, ad altri articoli della Knowledge base e alla documentazione disponibile nella dashboard di supporto dei prodotti.</block>
  <block id="3d4bc8fb320a39f7369e26aa8dd43ff9" category="paragraph">Per una guida dettagliata all'installazione e alle operazioni su Astra Control Center, seguire la documentazione <block ref="30c5ae998902105fcf03dc0b9654af4c" category="inline-link-macro-rx"></block>.</block>
  <block id="778aa9cc77239e29447d4ec0991d37ed" category="section-title">Automazione di Astra Control Center</block>
  <block id="1c3dabdc1df77100ef6e17757091285e" category="paragraph">Astra Control Center dispone di un'API REST completamente funzionale per l'accesso programmatico. Gli utenti possono utilizzare qualsiasi linguaggio di programmazione o utility per interagire con gli endpoint API REST di Astra Control. Per ulteriori informazioni su questa API, consultare la documentazione <block ref="bb2ca4e10b1254bc49d4388c68f9edb7" category="inline-link-macro-rx"></block>.</block>
  <block id="5d9f4b40183d98a25c3ab751a2c22032" category="paragraph">Se stai cercando un toolkit di sviluppo software pronto per interagire con le API REST di Astra Control, NetApp offre un toolkit con Astra Control Python SDK, che puoi scaricare <block ref="ccffe56769527505ab07c82206690bfe" category="inline-link-macro-rx"></block>.</block>
  <block id="22082fb9e9a42ddec66d9e75b3a3e61f" category="paragraph">Se la programmazione non è adatta alla tua situazione e desideri utilizzare uno strumento di gestione della configurazione, puoi clonare ed eseguire i playbook Ansible pubblicati da NetApp <block ref="8c91b346fb645d82eb54fe01a7c0cd36" category="inline-link-macro-rx"></block>.</block>
  <block id="d10e08b0a3edeee9dca36ed4d8843516" category="inline-link-macro">Pagina successiva: Validazioni dei casi d'utilizzo: DevOps con NetApp Astra</block>
  <block id="05caddd89629dc542b78549ec8132f7e" category="paragraph"><block ref="05caddd89629dc542b78549ec8132f7e" category="inline-link-macro-rx"></block></block>
  <block id="d0f564d49f74b4698141e88cbce5ad41" category="summary">NetApp dispone di diverse piattaforme di storage qualificate con Astra Trident e Astra Control per il provisioning, la protezione e la gestione dei dati per le applicazioni containerizzate, contribuendo così a definire e massimizzare il throughput DevOps.</block>
  <block id="b43c4021858544ebd3a492d082a7f349" category="doc">Panoramica dei sistemi storage NetApp</block>
  <block id="8f98c507505a202b216bb930f143954d" category="paragraph">NetApp dispone di diverse piattaforme storage qualificate con Astra Trident e Astra Control per il provisioning, la protezione e la gestione dei dati per le applicazioni containerizzate.</block>
  <block id="c64f419c58469b610f6840042d2d188c" category="admonition">Ogni sistema storage del portfolio NetApp può semplificare la gestione dei dati e lo spostamento tra i siti on-premise e il cloud, in modo che i dati si trovino dove si trovano le applicazioni.</block>
  <block id="e3775ded02e90946eb22f7f559238e62" category="list-text"><block ref="e3775ded02e90946eb22f7f559238e62" category="inline-link-macro-rx"></block></block>
  <block id="9111d84a5d538f39612bb42cb2a729aa" category="inline-link-macro">Pagina successiva: Panoramica delle integrazioni dello storage NetApp.</block>
  <block id="1139e8039447d6c6f83fa4a35ea79999" category="paragraph"><block ref="1139e8039447d6c6f83fa4a35ea79999" category="inline-link-macro-rx"></block></block>
  <block id="b75bc3343d170f8dd97d55a434b978ed" category="doc">Utilizza Astra Control per facilitare l'analisi post-mortem e ripristinare l'applicazione</block>
  <block id="3bbc946d425216e518cab3d8bcac2d2e" category="inline-link-macro">primo caso di utilizzo</block>
  <block id="3693bda9c9f6c60fbcfaa68a3c84d1c0" category="paragraph">In <block ref="378d294ca149bdd5226353f2fb623f62" category="inline-link-macro-rx"></block>, Abbiamo dimostrato come utilizzare NetApp Astra Control Center per proteggere le tue applicazioni in Kubernetes. In questa sezione viene descritto come integrare i backup delle applicazioni tramite Astra Control direttamente nel flusso di lavoro di sviluppo utilizzando l'SDK Python del toolkit NetApp Astra. Questo approccio consente la protezione degli ambienti di sviluppo e produzione automatizzando i backup on-demand durante il processo di integrazione continua e implementazione continua (ci/CD). Con questo ulteriore livello di protezione dei dati coerente con le applicazioni aggiunto alla pipeline ci/CD e alle applicazioni di produzione, i processi di sviluppo sono sicuri se qualcosa va storto nel processo, il che promuove buone pratiche di business-continuity.</block>
  <block id="93cf0eac312e112dec7819cf9726e08d" category="paragraph">In un workflow tradizionale, dopo aver riscontrato un errore quando l'applicazione viene aggiornata a una nuova versione, il team di sviluppo tentava di risolvere il problema in tempo reale in base ai report di bug forniti dai clienti. In alternativa, al primo segnale di problemi, il team potrebbe tentare di ridistribuire l'applicazione in un ambiente di debug parallelo per portare il processo offline. Potevano ridistribuire una base di codice precedente da una versione precedente in produzione, ripristinando l'applicazione in ordine di lavoro.</block>
  <block id="63cbc205a471137f16d61f24cd16531d" category="image-alt">Workflow tradizionale</block>
  <block id="cd78d769508976f182829ab0d59eb537" category="paragraph">Anche se questo approccio funziona, il team dovrebbe assicurarsi che lo stato dell'applicazione di produzione guasta corrisponda a quello della versione vista in produzione quando si sono verificati i problemi. Inoltre, dovrebbero dedicare del tempo alla promozione della build sicuramente funzionante in produzione, recuperando il codice dal repository e ridistribuendo le immagini della macchina per ripristinare l'applicazione a un buon stato di esecuzione. Inoltre, in questo scenario, non abbiamo considerato se il database di produzione stesso fosse corrotto dal codice difettoso. Idealmente, esistono processi di backup separati per i dati del database, ma dobbiamo presumere che siano coerenti con lo stato dell'applicazione così come è stata pubblicata? È qui che i benefici di backup, ripristini e cloni stateful e coerenti con l'applicazione con Astra Control dimostrano davvero il loro valore.</block>
  <block id="8b8ad5ef011a096e139bfa3245f80536" category="paragraph">Innanzitutto, possiamo utilizzare Astra Control per facilitare l'analisi post-mortem sullo stato dell'applicazione. Per farlo, cloniamo la versione di produzione buggy in un ambiente di test parallelo in modo coerente con l'applicazione. La messa da parte di questo ambiente nello stato di bug-ridden ci consente di risolvere il problema in tempo reale.</block>
  <block id="f94a2c6cdc2965b0f258d8215d1d28e0" category="paragraph">Inoltre, Astra Control supporta la funzionalità di ripristino in-place che consente di ripristinare l'applicazione di produzione a un ultimo backup accettabile (che ha preceduto la versione del codice interessata). La versione ripristinata assume la posizione dell'applicazione di produzione precedente, in modo coerente e stateful con l'applicazione, incluso l'IP di ingresso precedentemente assegnato. Di conseguenza, i clienti che accedono al front-end non sarebbero a conoscenza della transizione alla versione di backup.</block>
  <block id="1b0d7d8dcdf6d93ab2d330cc2396dfbc" category="image-alt">Workflow post-mortem</block>
  <block id="204890df83c01d375e4f4b6a724cc278" category="section-title">Prerequisiti per la convalida del caso d'utilizzo</block>
  <block id="93323e0f22b5aab17967ba48325ffbfa" category="paragraph">I seguenti strumenti o piattaforme sono stati implementati e configurati come prerequisiti:</block>
  <block id="f4f24690df38094196eebb86cb8ae057" category="list-text">Red Hat OpenShift Container Platform.</block>
  <block id="727324215fe79d6ac06ad699c15bc8b6" category="list-text">NetApp Astra Trident installato su OpenShift con un backend configurato su un sistema NetApp ONTAP.</block>
  <block id="229afb3c2926b78c5616a952d849e68c" category="list-text">Uno storageclass predefinito configurato, che punta a un backend NetApp ONTAP.</block>
  <block id="ba5452097a4c1be15b1efd3a6b26349f" category="list-text">NetApp Astra Control Center installato su un cluster OpenShift.</block>
  <block id="81c0c009a723f32f259a76657c0df955" category="list-text">Cluster OpenShift aggiunto come cluster gestito ad Astra Control Center.</block>
  <block id="6500a898faeb0dbf12368cd5d4c62b66" category="list-text">Jenkins installato su un cluster OpenShift.</block>
  <block id="76046924ab57dbfe48ac94a0d7cd184f" category="list-text">Applicazione Magento installata nell'ambiente di produzione. In questo caso di utilizzo, l'ambiente di produzione è uno spazio dei nomi chiamato "lento-prod" in un cluster Red Hat OpenShift.</block>
  <block id="7e5531e0bbdbf2a1b4736169f5261238" category="list-text">Applicazione di produzione gestita da Astra Control Center.</block>
  <block id="be3750e953403822ff53f62de7d378c9" category="list-text">Backup sicuramente funzionanti dell'applicazione di produzione acquisita con Astra Control.</block>
  <block id="a571d6a950aa43dc09919def5e2f001a" category="section-title">Clonare e ripristinare la pipeline</block>
  <block id="c04ae281a30f44b5bfe0091b23da26f7" category="paragraph">Considerando che l'applicazione è stata aggiornata a una nuova versione, l'applicazione nell'ambiente di produzione <block ref="5c755bccc6412e6f8ba1155b31007bd1" prefix="(" category="inline-code"></block>) non si comporta come previsto dopo l'aggiornamento. Supponiamo che i dati restituiti dalle query front-end non corrispondano alla richiesta o che il database sia stato effettivamente danneggiato. Per clonare e ripristinare la pipeline, attenersi alla seguente procedura:</block>
  <block id="8c2af21e6b34f2b1071040d4d1cfcb1c" category="image-alt">App non riuscita</block>
  <block id="6b1006b72a3e1550c386243b3965f2dc" category="list-text">Accedere a Jenkins e creare una pipeline facendo clic su New Item (nuovo elemento), quindi su Pipeline (pipeline).</block>
  <block id="42c6ce7c0a0da42cf240660b7916b661" category="list-text">Copiare la pipeline dal file Jenkinsfile<block ref="8676dd4f33dff00c4bf2944921591642" category="inline-link-rx"></block>.</block>
  <block id="64b46adfefce359622cb0f4882c6c1bd" category="list-text">Incollare la pipeline nella sezione della pipeline Jenkins, quindi fare clic su Save (Salva).</block>
  <block id="68d9707b516a968ed4c0757cbe9d5a9f" category="list-text">Compilare i parametri della pipeline Jenkins con i relativi dettagli, come la versione corrente dell'applicazione Magento in produzione, l'FQDN di Astra Control Center, il token API, l'ID dell'istanza e il nome dell'applicazione o lo spazio dei nomi degli ambienti di produzione e debug, nonché i nomi dei cluster di origine e destinazione. Ai fini di questo caso d'utilizzo, l'ambiente di produzione è uno spazio dei nomi chiamato 'lento-prod' e l'ambiente di debug è uno spazio dei nomi chiamato 'lento-debug' configurato su un cluster Red Hat OpenShift.</block>
  <block id="0aada8c0ec6d36d56210caa3cac9e025" category="list-text">Fare clic su Crea ora. La pipeline inizia a essere eseguita e procede attraverso le fasi. L'applicazione viene prima clonata nello stato corrente in un ambiente di debug e quindi ripristinata al backup funzionante.</block>
  <block id="4413dc875e85526bf92964b740f23064" category="image-alt">Pipeline post-mortem</block>
  <block id="4abbf0b75dc539f2afebf5014fbe6ea8" category="list-text">Verificare che l'applicazione clonata sia la versione contenente bug.</block>
  <block id="cbcf57aecdb6a6d216d8239a690bc2f6" category="image-alt">Applicazione clonata non riuscita</block>
  <block id="e73e23a9c5f896c3c98ea35a77116dfe" category="list-text">Verificare che l'ambiente di produzione sia ripristinato a un backup funzionante e che l'applicazione in produzione funzioni come previsto.</block>
  <block id="b24fb6cbfbfd8a2620eab1cb8f9d1563" category="image-alt">Ripristinata l'app Prod</block>
  <block id="cbd612409ffde58db700aacbf7ea15ca" category="paragraph">Queste due operazioni in tandem accelerano il ritorno alle normali operazioni di business. Per vedere questo caso d'utilizzo in azione, guarda il video <block ref="f5eb99e953852b5d0acfc08abd7c4f00" category="inline-link-macro-rx"></block>.</block>
  <block id="dc51ad14ee45a258aa1e6606251cf967" category="doc">Video e demo: DevOps con NetApp Astra</block>
  <block id="cd70acb1d118792e37e49b5dc15142ad" category="paragraph">I seguenti video mostrano alcune delle funzionalità descritte in questo documento:</block>
  <block id="5df9589990c71ed42c69a8bcc053d0d4" category="inline-link-macro">Video: Sfrutta NetApp Astra Control per eseguire l'analisi post-mortem e ripristinare l'applicazione</block>
  <block id="9fe0dbff6457627765d03955bd1659be" category="inline-link-macro">Video: Accelera lo sviluppo software con Astra Control e la tecnologia NetApp FlexClone</block>
  <block id="2f1df67ff878abb3db18e3010bcc2920" category="paragraph">Uno degli utilizzi più comuni dei flussi di lavoro DevOps è l'integrazione continua e le pipeline di implementazione continua (ci/CD) che creano, integrano ed eseguono suite di test automatizzate sulle applicazioni man mano che gli sviluppatori commettono nuovo codice. Gli ingegneri DevOps e gli SREs (Site-Reliability Engineer) dispongono di pipeline dedicate ai vari flussi di lavoro per lo sviluppo di nuove funzionalità, il test di regressione, la correzione di bug, la progettazione della qualità e altre funzioni del processo di sviluppo.</block>
  <block id="1413f73ce604910297e839d41a24e9f9" category="paragraph">Man mano che i team aumentano il loro livello di automazione, il ritmo del cambiamento per le applicazioni in-produzione può sembrare schiacciante. Pertanto, alcuni team preferiscono proteggere le applicazioni o i servizi in-produzione. Oltre a proteggere il codice e le immagini dei container, desiderano proteggere lo stato dell'applicazione, i dati di configurazione (come gli oggetti Kubernetes e le risorse associate all'applicazione) e i dati persistenti di un'applicazione.</block>
  <block id="8322f060ae0335cf0232ac3b55da6556" category="paragraph">In questo caso di utilizzo, analizziamo più da vicino una pipeline di promozione-produzione che implementa una nuova versione di un'applicazione: Prima in un ambiente di staging e poi in un ambiente di produzione. Questo esempio si applica allo stesso modo ai principali cloud pubblici e anche a un ambiente on-premise. Anche se mostriamo l'implementazione di una versione dell'applicazione, la pipeline può essere utilizzata anche con altre strategie, come l'implementazione blu/verde o canary. Come parte della pipeline ci/CD, proteggeremo l'applicazione creando un backup completo dell'applicazione. Un backup applicativo-aware dell'applicazione in-production e dei relativi dati, stato e configurazione può essere utile per numerosi flussi di lavoro DevOps.</block>
  <block id="13c258a59936aa47a4215b1c02921c7d" category="image-alt">Architettura DevOps con NetApp Astra Use Case 1</block>
  <block id="fcd7f001e9274fdefb14bff91c799306" category="inline-link">Magento</block>
  <block id="0e8625d3981b9d26e0866da357d318c8" category="inline-link">SDK NetApp Astra Control Python</block>
  <block id="2e54334c0a5ce2e3e5a5845df3ab3ada" category="inline-link">Jenkins</block>
  <block id="e5c0235557a0821c530e70a6ac76e817" category="paragraph">L'applicazione utilizzata per la convalida di questo caso di utilizzo è stata<block ref="ca8bdc27f15f815590190c112abb55a0" category="inline-link-rx"></block>, Una soluzione di e-commerce con front-end basato su web; un'istanza di Elasticsearch per le funzionalità di ricerca e analisi; e un database MariaDB che tiene traccia di tutti i dettagli dell'inventario di acquisto e delle transazioni. Questa applicazione containerizzata è stata installata in un cluster Red Hat OpenShift. Ogni pod dell'applicazione utilizzava volumi persistenti per memorizzare i dati. I volumi persistenti sono stati creati automaticamente da NetApp Astra Trident, lo storage orchestrator per Kubernetes conforme a Container Storage Interface, che consente il provisioning dello storage sui sistemi storage NetApp. Inoltre, per utilizzare le funzionalità di protezione delle applicazioni di Astra Control Center, l'applicazione in questione è stata gestita da Astra Control, che è stata utilizzata per attivare i backup delle applicazioni che memorizzavano lo stato dell'applicazione insieme ai dati contenuti nei volumi persistenti. Abbiamo utilizzato<block ref="d0b4b6e44937c3a38c218d58868f48cf" category="inline-link-rx"></block> Per automatizzare il processo di attivazione dei backup delle applicazioni, che è stato poi introdotto in una pipeline ci/CD. Questa pipeline è stata creata ed eseguita utilizzando un popolare tool ci/CD chiamato <block ref="2362760839a75356cff2ce591e8175c5" category="inline-link-rx"></block>] per automatizzare il flusso di creazione, protezione e implementazione dell'applicazione.</block>
  <block id="be6d35c56a8d9c9eda054648f5aaf778" category="paragraph">Analizziamo i prerequisiti e la procedura per introdurre la protezione in una pipeline ci/CD.</block>
  <block id="019b3399490601533f0c22df26617506" category="list-text">NetApp Astra Trident installato su OpenShift con un sistema ONTAP di back-end configurato</block>
  <block id="32714d2e851023befd52d2dafcb3df12" category="list-text">Uno storageclass predefinito configurato, che punta a un backend NetApp ONTAP</block>
  <block id="4feccdee8cd5d15c137a63228c1e8035" category="list-text">NetApp Astra Control Center installato su un cluster OpenShift</block>
  <block id="89a7002b85e3c07334367a744cb41016" category="list-text">Cluster OpenShift aggiunto come cluster gestito ad Astra Control Center</block>
  <block id="f485827022df06c2991a88b97eeb4e48" category="list-text">Jenkins è stato installato su un cluster OpenShift e configurato con un nodo Agent su cui è installato un motore Docker</block>
  <block id="e6b72ced375884adc1f139800a859ef1" category="section-title">Installazione dell'applicazione</block>
  <block id="cd03481692ef65344c4dd7bf363bc056" category="paragraph">Iniziamo con l'installazione iniziale dell'applicazione negli ambienti di staging e produzione. Ai fini di questo caso d'utilizzo, questo passaggio è un prerequisito, quindi viene eseguito manualmente. La pipeline ci/CD viene utilizzata per i flussi di lavoro di creazione e implementazione successivi come risultato delle nuove versioni dell'applicazione.</block>
  <block id="2ee68ca17059fe4d4ab06d0230bed0c3" category="paragraph">L'ambiente di produzione in questo caso di utilizzo è uno spazio dei nomi chiamato<block ref="5c755bccc6412e6f8ba1155b31007bd1" prefix=" " category="inline-code"></block>e il corrispondente ambiente di staging è uno spazio dei nomi chiamato<block ref="b6e78b61f8d1e4d47cc09b947a8d4fb2" prefix=" " category="inline-code"></block> Configurato sul cluster Red Hat OpenShift. Per installare l'applicazione, attenersi alla seguente procedura:</block>
  <block id="05586ccfd2c7dbe7b3226b21240add7c" category="list-text">Installare l'applicazione Magento utilizzando bitnami Helm Chart nell'ambiente di produzione. Utilizziamo RWX PVS per i pod Magento e MariaDB.</block>
  <block id="14224ce39d8587f380c4b992c668c24d" category="admonition">Magento bitnami Helm Chart richiede un servizio LoadBalancer per esporre il servizio Magento GUI. Abbiamo utilizzato <block ref="6beef47e42ff9b3760535f361acb6931" category="inline-link-macro-rx"></block> per fornire un servizio di bilanciamento del carico on-premise in questo esempio.</block>
  <block id="4750ba228d6f73ce1e9d9e27f0cd2ca5" category="list-text">Dopo alcuni minuti, verificare che tutti i pod e i servizi siano in esecuzione.</block>
  <block id="3a0715e577e143188e1e748efe2fca27" category="list-text">Ripetere la stessa procedura per l'ambiente di staging.</block>
  <block id="e684201cc94f2e04edf2353711b58fe5" category="section-title">Gestire l'applicazione Magento in Astra Control Center</block>
  <block id="e9758d5e82771fcca93395ce3a7c1d40" category="list-text">Accedere ad applicazioni e selezionare la scheda applicazioni rilevate.</block>
  <block id="082833c45c4a99b63cbf53365495e0d2" category="list-text">Fare clic sui puntini di sospensione dell'applicazione Magento nell'ambiente di produzione <block ref="5c755bccc6412e6f8ba1155b31007bd1" prefix="(" category="inline-code"></block>), quindi fare clic su Manage (Gestisci).</block>
  <block id="28a12dc4e9b29cb97bfaf36914e9983a" category="list-text">L'applicazione Magento è ora gestita da Astra Control Center. Tutte le operazioni supportate da Astra Control possono essere eseguite sull'applicazione. Prendere nota anche della versione dell'applicazione.</block>
  <block id="4ef629c07108e88861fc4036780e9a1f" category="image-alt">Verifica della versione di Magento prima dell'aggiornamento</block>
  <block id="c03f75891d5e0356b60d3752df0f0444" category="list-text">Ripetere i passaggi per la gestione dell'applicazione Magento nell'ambiente di staging <block ref="b6e78b61f8d1e4d47cc09b947a8d4fb2" prefix="(" category="inline-code"></block>).</block>
  <block id="881e2f21543c210893e098f6383f4199" category="section-title">Pipeline ci/CD con protezione integrata</block>
  <block id="841e01ce1d424839fd87eed89e1ce154" category="paragraph">Quando lavoriamo con le nuove versioni delle applicazioni, utilizziamo una pipeline ci/CD per creare l'immagine container, eseguire backup degli ambienti di staging e produzione, implementare la nuova versione dell'applicazione nell'ambiente di staging, attendere l'approvazione per la promozione in produzione, quindi, implementare la nuova versione dell'applicazione nell'ambiente di produzione. Per utilizzare una pipeline ci/CD, attenersi alla seguente procedura:</block>
  <block id="88ba71f9d62d24eeb2decfe9cd30cfb1" category="list-text">Accedi a Jenkins e crea le credenziali richieste: Una per Magento creds, una per MariaDB admin creds e la terza per MariaDB root creds.</block>
  <block id="9743ff34b00bc2d03fdc0b6ee11b0781" category="list-text">Accedere a Manage Jenkins &gt; Manage Credentials (Gestisci Jenkins &gt; Gestisci credenziali) e fare clic sul dominio appropriato.</block>
  <block id="5efc31d04501ec1bfbc5b2e785ac7cc2" category="list-text">Fare clic su Add Credentials (Aggiungi credenziali) e impostare il tipo su Username (Nome utente) con password e ambito impostati su Global (Globale). Immettere il nome utente, la password e un ID per le credenziali, quindi fare clic su OK.</block>
  <block id="5ff08be42358b0ed5a5235096ccfa397" category="image-alt">Crea credenziali</block>
  <block id="ef7b482a4875dec8ec53a6a7ecea081b" category="list-text">Ripetere la stessa procedura per le altre due credenziali.</block>
  <block id="955b68bae8db1bc3b2abbf6ada3710be" category="list-text">Tornare alla dashboard, creare una pipeline facendo clic su New Item (nuovo elemento), quindi fare clic su Pipeline (pipeline).</block>
  <block id="027f0bd54326a6b14e6c7daf65d07f5c" category="list-text">Copiare la pipeline dal file Jenkinsfile<block ref="94d69998dfd97a76d20ae02a64c629ae" category="inline-link-rx"></block>.</block>
  <block id="843730ff8981a034040c0f42fdaa48ce" category="list-text">Compilare i parametri della pipeline Jenkins con i relativi dettagli, tra cui la versione del grafico Helm, la versione dell'applicazione Magento a cui si desidera eseguire l'aggiornamento, la versione del toolkit Astra, l'FQDN di Astra Control Center, il token API e il relativo ID istanza. Specificare il registro del docker, lo spazio dei nomi e l'IP Magento degli ambienti di produzione e di staging e specificare anche gli ID delle credenziali create.</block>
  <block id="3f52d6cbc878f43533503f2bd5a61952" category="list-text">Fare clic su Crea ora. La pipeline inizia a essere eseguita e procede attraverso le fasi. L'immagine dell'applicazione viene creata e caricata nel registro del container.</block>
  <block id="059d6fb9b965d0897c20fb2482659279" category="image-alt">Avanzamento della pipeline</block>
  <block id="ed2c1f4dfcf187d5140cf31e58801b4f" category="list-text">I backup dell'applicazione vengono avviati tramite Astra Control.</block>
  <block id="633d66eb7984b86ee4487b6a10ffc34a" category="image-alt">Backup avviato</block>
  <block id="75b0ba1236c133f891fdd36b2e3913f3" category="list-text">Una volta completate le fasi di backup, verificare i backup da Astra Control Center.</block>
  <block id="2b3a33094c5c31ac6cc6be770417a07c" category="image-alt">Backup riuscito</block>
  <block id="fec272abe380f3502ef64cbc2cc652bf" category="list-text">La nuova versione dell'applicazione viene quindi distribuita nell'ambiente di staging.</block>
  <block id="4576032c05f55b22a040f067151cde6f" category="image-alt">Implementazione dello staging avviata</block>
  <block id="4d4659ee9b2600243399d4aceca7c670" category="list-text">Al termine di questa fase, il programma attende che l'utente approvi la distribuzione in produzione. In questa fase, supponiamo che il team di QA esegua alcuni test manuali e approvi la produzione. Fare clic su Approve (approva) per distribuire la nuova versione dell'applicazione nell'ambiente di produzione.</block>
  <block id="e30db45e8514d0d8f662187e28b8b5ec" category="image-alt">In attesa di promozione</block>
  <block id="3a7b15850615e9fd306b379f77e0e016" category="list-text">Verificare che anche l'applicazione di produzione sia aggiornata alla versione desiderata.</block>
  <block id="f11253856e2b859c46731353f46b732e" category="image-alt">App PROD aggiornata</block>
  <block id="70817285f3f68722fd851dde7464feb2" category="paragraph">Come parte della pipeline ci/CD, abbiamo dimostrato la capacità di proteggere l'applicazione creando un backup completo e integrato con l'applicazione. Poiché il backup dell'intera applicazione è stato eseguito nell'ambito della pipeline di promozione-produzione, puoi sentirti più sicuro delle implementazioni altamente automatizzate delle applicazioni. Questo backup integrato con l'applicazione contenente i dati, lo stato e la configurazione dell'applicazione può essere utile per numerosi flussi di lavoro DevOps. Un importante flusso di lavoro potrebbe essere il ripristino della versione precedente dell'applicazione in caso di problemi imprevisti.</block>
  <block id="94ec4ad32f9ba408876eabf1a42f6901" category="paragraph">Anche se abbiamo dimostrato un workflow ci/CD attraverso lo strumento Jenkins, il concetto può essere estrapolato in modo semplice ed efficiente a diversi strumenti e strategie. Per vedere questo caso d'utilizzo in azione, guarda il video <block ref="2eda593691b1da530fed5bfcba32a663" category="inline-link-macro-rx"></block>.</block>
  <block id="44a18520ed05f9b0b2e06135a4ff7518" category="summary">Una panoramica di devops e dei potenziali casi di utilizzo in questo report tecnico.</block>
  <block id="74b9fd8d0b2ef1c2b396580a2afd59ae" category="doc">Panoramica di DevOps</block>
  <block id="d5df4eecbaafa5d83d7698ba92c7cecd" category="paragraph">Negli ultimi anni, le organizzazioni che creano software hanno adottato i concetti di DevOps. Le pratiche DevOps abbattono le barriere organizzative, avvicinando i team di sviluppo e operativi. Le pratiche DevOps consentono inoltre ai team di accelerare l'erogazione, aumentare la disponibilità e rendere più stabili servizi e applicazioni, migliorando così la produttività del team. Inoltre, l'adozione di un framework di automazione è anche un elemento chiave del successo, dalla creazione, test e gestione di applicazioni su larga scala o dalla gestione di una piattaforma o stack di infrastruttura completamente automatizzati. Di seguito vengono illustrati alcuni casi di utilizzo principali per DevOps in cui è possibile implementare le soluzioni NetApp per migliorare le esperienze che i professionisti DevOps incontrano durante le loro pratiche quotidiane.</block>
  <block id="e7ccc944261680ee4a52d724dd1ca1c5" category="section-title">Casi di utilizzo DevOps</block>
  <block id="e4fd3fc8a04e3e1d2e788cd1b017e1f2" category="paragraph">Sebbene DevOps non disponga di una singola definizione universalmente accettata, le soluzioni per i professionisti DevOps contengono in genere costrutti o ideologie simili che consentono un'implementazione, una ripetizione e una gestione semplici su larga scala. Le sezioni seguenti descrivono i potenziali casi di utilizzo per i flussi di lavoro DevOps abilitati dalle soluzioni NetApp.</block>
  <block id="020a9588f0f051f7f9ff59fabaffa365" category="section-title">Integrazione continua, erogazione continua e implementazione continua (ci/CD)</block>
  <block id="b1a2676c9ceea5e6ef4c514562097e9a" category="paragraph">Continuous Integration, Continuous Delivery e Continuous Deployment (ci/CD) è una filosofia di codifica che incoraggia gli sviluppatori a implementare e trasformare le proprie pratiche di codifica stabilendo un metodo per aggiornare, testare e implementare il proprio codice in modo automatizzato. Il metodo più diffuso con cui ci/CD viene implementato nella maggior parte dei flussi di lavoro DevOps è quello della pipeline ci/CD, e esistono diverse applicazioni software di terze parti che possono contribuire a ottenere questo risultato.</block>
  <block id="3ff91355eb24188940a49b15da87cb74" category="image-alt">Immagine ci/CD</block>
  <block id="64d92cb8c4c053363095cf796a7b89ba" category="paragraph">Di seguito sono riportati alcuni esempi di applicazioni comuni che possono essere di aiuto con i flussi di lavoro ci/CD-type:</block>
  <block id="418f66e40d28aac0fa315742070e645f" category="inline-link">ArgoCD</block>
  <block id="e1500a23f27fb897c6cdf5caab04195d" category="inline-link">Tekton</block>
  <block id="4d094d290ed5b2a855427290709addea" category="paragraph"><block ref="ff7d5093e53bbd8006cbcaaeb044f69a" category="inline-link-rx"></block>
<block ref="0d8e72f4ae085bb6c45eba7c3f144090" category="inline-link-rx"></block>
<block ref="313a601d85cff2a8e7d85ce0f552cc73" category="inline-link-rx"></block></block>
  <block id="2c14caaf080b9d4ff53b1e0d7364a348" category="paragraph">Alcuni dei casi di utilizzo inclusi più avanti in questo report tecnico sono stati dimostrati in Jenkins, ma i principi ci/CD principali possono essere applicati a qualsiasi strumento implementato da un'organizzazione nelle proprie pratiche.</block>
  <block id="af41549605744cf23f27cbc14458bf82" category="section-title">Infrastruttura come codice</block>
  <block id="3e9f73de1e8a89473ea5df8ed9ad7651" category="paragraph">L'infrastruttura come codice aiuta a fornire e gestire le risorse IT attraverso comandi automatizzati, API e kit di sviluppo software (SDK). Questo concetto migliora notevolmente l'esperienza DevOps eliminando i limiti fisici del data center o delle risorse che potrebbero impedire agli sviluppatori di raggiungere i propri obiettivi.</block>
  <block id="9b2cf15c50955773c7604b77322b057e" category="image-alt">Infrastruttura come immagine di codice</block>
  <block id="a7f5f35426b927411fc9231b56382173" category="inline-link">Python</block>
  <block id="d51d5ee15f404c2f4f7863bebcde1fac" category="inline-link">Ansible</block>
  <block id="14590850b4107a6f92feb1af739b82eb" category="inline-link">Marionetta</block>
  <block id="10feac82bf81358ba2b3681989464290" category="paragraph">Gli utenti finali spesso utilizzano linguaggi di programmazione come<block ref="11022d613ff738bd6763caad4acd7f7e" category="inline-link-rx"></block> o strumenti di automazione come<block ref="9790ec336069075a6bee003fe52e73bb" category="inline-link-rx"></block> oppure<block ref="82158671408fe4876cefcfa78b9fd777" category="inline-link-rx"></block> per creare azioni di scalabilità dell'infrastruttura automatizzate e ripetibili che possono essere chiamate dagli sviluppatori quando necessario.</block>
  <block id="25d4b1e166882d63d2b4f8c8919a7513" category="paragraph">Sia NetApp ONTAP che Astra Control contengono API pubbliche e moduli ansible o toolkit di sviluppo software che rendono le operazioni di automazione molto semplici da adottare e integrare nei processi DevOps.</block>
  <block id="436a9385e01c8134ffa76de0039b69e9" category="paragraph"><block ref="436a9385e01c8134ffa76de0039b69e9" category="inline-link-macro-rx"></block></block>
  <block id="c6b924f851b08c850fe2e53f34ada256" category="doc">Accelerazione dello sviluppo software con la tecnologia FlexClone di NetApp</block>
  <block id="e071982902994eb194aeef35d4e7d131" category="paragraph">La clonazione di un'applicazione distribuita in un cluster Kubernetes è uno strumento molto utile per gli sviluppatori che desiderano accelerare i propri flussi di lavoro condividendo ambienti con i partner o testando nuove versioni di codice in un ambiente di sviluppo senza interferire con la versione su cui stanno attualmente lavorando. La clonazione stateful e coerente con l'applicazione di un'applicazione Kubernetes è una delle funzionalità principali incluse in NetApp Astra Control, insieme al backup e ripristino delle applicazioni. Come bonus, se un'applicazione viene clonata all'interno dello stesso cluster Kubernetes utilizzando lo stesso backend di storage, Astra Control utilizza per impostazione predefinita la tecnologia NetApp FlexClone per la duplicazione di volumi di dati persistenti, accelerando notevolmente il processo. Accelerando questo processo, l'ambiente clonato viene fornito e disponibile per l'utilizzo in pochi istanti, consentendo agli sviluppatori di riprendere il proprio lavoro con una breve pausa rispetto alla ridistribuzione dell'ambiente di test o sviluppo. Come ulteriore comodità, tutte le funzioni disponibili in NetApp Astra Control possono essere chiamate con un'API, che consente una facile integrazione in framework di automazione come Ansible. Pertanto, gli ambienti possono essere gestiti in tempi ancora più rapidi, perché sono necessarie solo modifiche di lieve entità in un manuale o in un ruolo per iniziare la procedura di cloning.</block>
  <block id="130a289acaa6c63f08a152e232264781" category="section-title">Che cos'è la tecnologia FlexClone di NetApp?</block>
  <block id="de7fc3e1378f3d66008013e37abfc654" category="paragraph">La tecnologia NetApp FlexClone è una copia scrivibile e point-in-time basata su snapshot di un NetApp FlexVol. Vengono forniti quasi istantaneamente, contengono tutti i dati del volume di origine e non consumano spazio di storage aggiuntivo fino a quando i dati nel nuovo volume non iniziano a divergere dall'origine. Vengono spesso utilizzati in ambienti basati su modelli o di sviluppo quando più copie di dati sono utili per scopi di staging e i sistemi storage dispongono di risorse limitate per il provisioning di questi volumi. Rispetto a un sistema storage tradizionale in cui i dati devono essere copiati più volte, con un conseguente consumo di tempo e spazio di storage significativo, la tecnologia NetApp FlexClone accelera le attività dipendenti dallo storage.</block>
  <block id="66b43b8d36a821005edbb505f73e703f" category="image-alt">Immagine FlexClone</block>
  <block id="b9ca5ba97cf75d3dafb51f78e073770a" category="inline-link">Documenti NetApp</block>
  <block id="b9c059adc88329f807d19beff36c402c" category="paragraph">Per ulteriori informazioni sulla tecnologia FlexClone di NetApp, visita la pagina all'indirizzo<block ref="26a4454b15f9e59c91953aae4d5cca61" category="inline-link-rx"></block>.</block>
  <block id="c2bdd689dbc313e32552cbc9e519673e" category="list-text">Una distribuzione Kubernetes supportata, come Red Hat OpenShift 4.6.8+, Rancher 2.5+ o Kubernetes 1.19+.</block>
  <block id="17909bff47021a48534aa137533988cb" category="list-text">NetApp Astra Control Center 21.12+.</block>
  <block id="f6e864ce20ae64f2d8e8d9788960ddcb" category="list-text">Un sistema NetApp ONTAP con un backend di storage configurato tramite NetApp Astra Trident.</block>
  <block id="02de8f49568cea93a498f8b7b321a4e4" category="list-text">Ansible 2.9+.</block>
  <block id="0f466e306fc4825f1141ddc130ca599a" category="list-text">Modelli per gli ambienti che si desidera clonare come applicazioni gestite in NetApp Astra Control.</block>
  <block id="3e36385ca501623e48219eaf55547185" category="section-title">Introduzione al caso d'utilizzo</block>
  <block id="c7af167d0f4082e772505e76bb547621" category="paragraph">In questo caso di utilizzo, viene visualizzato un aspetto simile al seguente flusso di lavoro:</block>
  <block id="fc1fa3a113fd483da9a2a706cef62740" category="image-alt">Immagine del workflow</block>
  <block id="3056a7af3144c13993f45fa84e78699e" category="list-text">Un utente esegue il playbook ansible per creare un nuovo ambiente di staging.</block>
  <block id="c48538a3317fc98bc2fa8cf73553ca0b" category="list-text">Ansible utilizza il modulo URI-API per richiamare Astra Control per eseguire l'operazione di cloning.</block>
  <block id="af27beb3ef227700c87619b941ef922d" category="list-text">Astra Control esegue un'operazione di cloning su un ambiente modello con provisioning anticipato, creando così una nuova applicazione gestita.</block>
  <block id="afec891492c1e0c4d92776aa8fbb7a37" category="admonition">Questo ambiente può essere una singola applicazione standalone in fase di sviluppo o un intero ambiente di sviluppo come una pipeline Jenkins ci/CD.</block>
  <block id="b120622a84d96b41ece4bf14a2afc42c" category="list-text">L'utente quindi estrae una versione del proprio codice nell'ambiente di sviluppo clonato da un repository online come Gitea.</block>
  <block id="58b9c8dff15389cfc89079bed15b0353" category="list-text">La nuova versione dell'applicazione viene implementata e gestita da NetApp Astra Control.</block>
  <block id="512473ae00b91f234459da9d54a73d63" category="admonition">Entrambi questi processi possono essere automatizzati.</block>
  <block id="45469e0108aa4b426d8e379bf3e01032" category="list-text">L'utente può sviluppare nuovo codice in questo ambiente clonato.</block>
  <block id="290324e3d59e2f7053c0f9e9e6e0efa3" category="list-text">Quando l'utente è soddisfatto dei propri sforzi di sviluppo, può reinviare il codice al repository ospitato.</block>
  <block id="30d4a5dfd238538be60a29a62c199938" category="paragraph">Il caso d'utilizzo qui presentato dipende dall'esistenza di modelli Golden per gli ambienti o le applicazioni che si desidera clonare. Nel nostro ambiente abbiamo creato tre modelli di questo tipo, uno per un'implementazione di WordPress, uno per un'implementazione di Magento e uno per un ambiente ci/CD di Jenkins con Gitea che abbiamo chiamato DevTools.</block>
  <block id="c30f4e03a21fface6aa43659a4078d71" category="image-alt">Immagine dei modelli</block>
  <block id="1107495525479f3871a68bae36a3f17b" category="paragraph">Ciascuno di questi ambienti è gestito da NetApp Astra Control, con volumi persistenti attualmente memorizzati su un sistema di storage NetApp ONTAP con un backend NFS fornito da NetApp Astra Trident.</block>
  <block id="2ba3749d66f6540154024e19b4d99cc9" category="section-title">Validazione del caso d'utilizzo</block>
  <block id="7a73c2eecaec86daa9aee3eff521b699" category="list-text">Clonare il toolkit ansible fornito dal team NetApp Solutions Engineering, che include il ruolo di cloning e il manuale di aggiornamento dell'applicazione.</block>
  <block id="6264ab91acf969dcae78c1602bca2059" category="list-text">Modifica<block ref="c4fe4210b1a8cc125caf1d344db07732" prefix=" " category="inline-code"></block> E compila i valori globali che si adattano al tuo ambiente Astra Control.</block>
  <block id="240e34a15ccbba0aea72efc21aaab86d" category="admonition">I valori dell'ambiente globale da compilare sono disponibili sotto l'icona del profilo utente in NetApp Astra Control nel menu API Access.</block>
  <block id="f35821a1d6caaf6d90163620f4ea7458" category="image-alt">API Access Image (immagine accesso API)</block>
  <block id="25037aa69bc75f53a1077e99016fcb35" category="list-text">Una volta completate le variabili globali, è possibile scegliere i valori per l'applicazione specifica che si desidera clonare. Per clonare l'ambiente devtools in un ambiente personale chiamato<block ref="2ab4557e919d8388e34d63b073eb0704" prefix=" " category="inline-code"></block>, eseguire le seguenti operazioni:</block>
  <block id="3c88bcd7ff9904c39c203d75df0f43aa" category="admonition">Per sfruttare la tecnologia FlexClone di NetApp nel processo di cloning,<block ref="4235aba0b7240b55d6c0b4e16f2b0c9a" prefix=" " category="inline-code"></block> e.<block ref="57d3fb1ffc6c61e8386a14142cad2cfe" prefix=" " category="inline-code"></block> deve essere lo stesso.</block>
  <block id="7701b76fd4e9f02523bba989b59e089f" category="list-text">È ora possibile eseguire il manuale per clonare l'applicazione.</block>
  <block id="b843fd904e687b09c9fea5652dd26835" category="admonition">Il playbook così come è stato scritto deve essere eseguito dall'utente root o da un utente che può eseguire l'escalation attraverso il processo sudo passando l'argomento "-K".</block>
  <block id="47261a281b6d461c0e208fcdd564b6ef" category="list-text">Quando il playbook completa la sua esecuzione, l'applicazione clonata viene visualizzata come disponibile nella console di Astra Control Center.</block>
  <block id="4ebfaaa8ab1aa4f1a8e1f0e4c080a066" category="image-alt">Immagine dell'applicazione clonata</block>
  <block id="d7d808da7950a8d4bece269105013664" category="list-text">Un utente può quindi accedere all'ambiente Kubernetes in cui è stata implementata l'applicazione, verificare che l'applicazione sia esposta con un nuovo indirizzo IP e iniziare il lavoro di sviluppo.</block>
  <block id="ba87075b7677acd5c3798c45d5899095" category="paragraph">Per una dimostrazione di questo caso di utilizzo e un esempio di aggiornamento di un'applicazione, vedere <block ref="c3446aeb84c085acd211fbde68c1be91" category="inline-link-macro-rx"></block>.</block>
  <block id="97e84aad4ef505e4cda6422dc1c95990" category="doc">Ulteriori informazioni: DevOps con NetApp Astra</block>
  <block id="0221d1074d249c254f0679e761454a05" category="inline-link"><block ref="0221d1074d249c254f0679e761454a05" category="inline-link-rx"></block></block>
  <block id="40454fb96e27a719bd7a751c4ec47d16" category="paragraph"><block ref="40454fb96e27a719bd7a751c4ec47d16" category="inline-link-rx"></block></block>
  <block id="5eae6f5974c9d4195ebe0cf8b607647e" category="list-text">Documentazione Ansible</block>
  <block id="015674032a5c43c779a74ee9e3dbfc94" category="inline-link"><block ref="015674032a5c43c779a74ee9e3dbfc94" category="inline-link-rx"></block></block>
  <block id="f13ae695d1de0b91201bca0cd4e87c69" category="paragraph"><block ref="f13ae695d1de0b91201bca0cd4e87c69" category="inline-link-rx"></block></block>
  <block id="f89c93af274397315016bac75d215351" category="inline-link"><block ref="f89c93af274397315016bac75d215351" category="inline-link-rx"></block></block>
  <block id="9e4287aba38224954e73e528ce96bb47" category="paragraph"><block ref="9e4287aba38224954e73e528ce96bb47" category="inline-link-rx"></block></block>
  <block id="7a42c46751036b34f81738e60f1b7e97" category="list-text">Documentazione del rancher</block>
  <block id="6483799d4ba7ad61fe06633600d8824a" category="inline-link"><block ref="6483799d4ba7ad61fe06633600d8824a" category="inline-link-rx"></block></block>
  <block id="b8e7a2183995014079b38a90770a02ea" category="paragraph"><block ref="b8e7a2183995014079b38a90770a02ea" category="inline-link-rx"></block></block>
  <block id="d7c98030ea1f0ace5cb1fc0a5954a87c" category="list-text">Documentazione Kubernetes</block>
  <block id="9b4643ea7f05b216a0cf56ceddb43241" category="inline-link"><block ref="9b4643ea7f05b216a0cf56ceddb43241" category="inline-link-rx"></block></block>
  <block id="6bd14be39aedfe96ceacec2caaac0532" category="paragraph"><block ref="6bd14be39aedfe96ceacec2caaac0532" category="inline-link-rx"></block></block>
  <block id="c48c25afacd7dddac49ab104ad056df0" category="paragraph">Astra Trident è uno storage orchestrator open-source completamente supportato per container e distribuzioni Kubernetes come {k8s_distribution_name}. Trident lavora con l'intero portfolio di storage NetApp, inclusi i sistemi storage NetApp ONTAP ed Element, e supporta anche connessioni NFS e iSCSI. Trident accelera il workflow DevOps consentendo agli utenti finali di eseguire il provisioning e gestire lo storage dai sistemi storage NetApp senza richiedere l'intervento di un amministratore dello storage.</block>
  <block id="ed42e52f359216f47260ed1d21ef331c" category="paragraph">A partire dalla versione 20.04, l'impostazione di Trident viene eseguita dall'operatore Trident. L'operatore semplifica le implementazioni su larga scala e fornisce supporto aggiuntivo, inclusa la riparazione automatica dei pod implementati nell'installazione di Trident.</block>
  <block id="ae5d1fe148e47e375a2109cb3f29045a" category="paragraph">Consultare la documentazione <block ref="a57add0d538360cd0adbee43a89f028d" category="inline-link-macro-rx"></block> Per installare e utilizzare Astra Trident.</block>
  <block id="3ae96676432caea17595a22525bd9660" category="admonition">Esiste un campo opzionale chiamato<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> definito in questo file. Nei backend iSCSI, questo valore può essere impostato su un tipo di filesystem Linux specifico (XFS, ext4, ecc.) o può essere cancellato per consentire a OpenShift di decidere quale filesystem usare.</block>
  <block id="4d4480c77d84881f85763c51fb0a0ebb" category="doc">Video e demo: Red Hat OpenShift con NetApp</block>
  <block id="72feee9e055adc523c4c9ca3c1453409" category="inline-link-macro">Video: Protezione dei dati in pipeline ci/CD con Astra Control</block>
  <block id="6be5bc354916244292cf704d8a451541" category="inline-link-macro">Video: Migrazione dei workload con Astra Control Center - Red Hat OpenShift con NetApp</block>
  <block id="c0a8420c339dd9d57d40448c30a749df" category="inline-link-macro">Video: Migrazione dei workload con Astra Trident e SnapMirror - Red Hat OpenShift con NetApp</block>
  <block id="762a14964ee1713d320b8beefaf55b17" category="inline-link-macro">Video: Installazione della virtualizzazione OpenShift - Red Hat OpenShift con NetApp</block>
  <block id="aad993afc3c78a3a38ae471fa2ae1060" category="inline-link-macro">Video: Implementazione di una macchina virtuale con virtualizzazione OpenShift - Red Hat OpenShift con NetApp</block>
  <block id="71417a3dd01aa388d35bf54aa4c401fa" category="summary">Questa pagina contiene collegamenti a video che mostrano alcune delle funzionalità descritte in questo documento.</block>
  <block id="952be0b8dee874c73cd76a4d6a526b27" category="doc">Video e demo: VMware Tanzu con NetApp</block>
  <block id="bf6a387fea3d3444126eab19bcb4bbcd" category="inline-link-macro">Pagina successiva: Ulteriori informazioni: VMware Tanzu con NetApp.</block>
  <block id="df2a7ac55fe19fad5a5006603cfd8662" category="paragraph"><block ref="df2a7ac55fe19fad5a5006603cfd8662" category="inline-link-macro-rx"></block></block>
  <block id="aa7b3dace1453f21689852e3b066f673" category="summary">VMware Tanzu Kubernetes Grid Service (noto anche come vSphere con Tanzu) consente di creare e utilizzare i cluster Tanzu Kubernetes in modo nativo in vSphere e consente inoltre di eseguire alcuni carichi di lavoro più piccoli direttamente sugli host ESXi.</block>
  <block id="b71ad38bc3fd2c1a10efc2b09270e430" category="doc">Panoramica di VMware Tanzu Kubernetes Grid Service (TKGS)</block>
  <block id="9f0bacdd758242392df6d215d34d9b8e" category="paragraph">VMware Tanzu Kubernetes Grid Service (noto anche come vSphere con Tanzu) consente di creare e utilizzare i cluster Tanzu Kubernetes in modo nativo in vSphere e consente inoltre di eseguire alcuni carichi di lavoro più piccoli direttamente sugli host ESXi. Consente di trasformare vSphere in una piattaforma per l'esecuzione di workload containerizzati in modo nativo sul layer dell'hypervisor. Tanzu Kubernetes Grid Service implementa su vSphere un cluster di supervisore, se abilitato, che implementa e gestisce i cluster richiesti per i carichi di lavoro. È integrato in modo nativo con vSphere 7 e sfrutta molte funzionalità vSphere affidabili come vCenter SSO, Content Library, rete vSphere, storage vSphere, vSphere ha e DRS e sicurezza vSphere per un'esperienza più perfetta con Kubernetes.</block>
  <block id="6b25ac3e69375bd4a52dbffeb5c9cb14" category="paragraph">VSphere con Tanzu offre una singola piattaforma per ambienti applicativi ibridi, in cui è possibile eseguire i componenti delle applicazioni in container o in macchine virtuali, garantendo una migliore visibilità e facilità di gestione per sviluppatori, ingegneri DevOps e amministratori vSphere. VMware TKGS è supportato solo con gli ambienti vSphere 7 ed è l'unica offerta del portfolio di operazioni di Tanzu Kubernetes che consente di eseguire i pod direttamente sugli host ESXi.</block>
  <block id="0e1d3327747a52bdd78d80247d5b6500" category="image-alt">Servizio VMware Tanzu Kubernetes</block>
  <block id="6e1adc41159b779c5ef1a0c9c934a673" category="paragraph">Per ulteriori informazioni su Tanzu Kubernetes Grid Service, seguire la documentazione <block ref="0cdaad1423fdb034ad0ee788d57a7a82" category="inline-link-macro-rx"></block>.</block>
  <block id="2a304a1348456ccd2234cd71a81bd338" category="inline-link">collegamento</block>
  <block id="767b04965a47baa63782400d36a0c62e" category="paragraph">Esistono molte considerazioni architetturali relative a set di funzionalità, networking e così via. A seconda dell'architettura scelta, i prerequisiti e il processo di implementazione di Tanzu Kubernetes Grid Service differiscono. Per implementare e configurare il servizio Grid di Tanzu Kubernetes nel tuo ambiente, segui la guida <block ref="5e5ad4985bdb8ab17883db4008c7c4a2" category="inline-link-macro-rx"></block>. Inoltre, per accedere ai nodi del cluster Tanzu Kubernetes implementati tramite TKGS, seguire la procedura descritta in questo documento<block ref="7db41b551ba1165c4dfa4cf2d8a36e55" category="inline-link-rx"></block>.</block>
  <block id="46d890e88b951c5a84a444aad08079ae" category="paragraph">NetApp consiglia di implementare tutti gli ambienti di produzione in implementazioni master multiple per la fault tolerance, scegliendo la configurazione dei nodi di lavoro per soddisfare i requisiti dei carichi di lavoro previsti. Pertanto, una classe di macchine virtuali consigliata per un carico di lavoro altamente intensivo avrebbe almeno quattro vCPU e 12 GB di RAM.</block>
  <block id="e8a4d3a2e07c429150e133b7fedebd64" category="paragraph">Quando i cluster Tanzu Kubernetes vengono creati in uno spazio dei nomi, gli utenti con<block ref="72122ce96bfec66e2396d2e25225d70a" prefix=" " category="inline-code"></block> oppure<block ref="de95b43bceeb4b998aed4aed5cef1ae7" prefix=" " category="inline-code"></block> l'autorizzazione può creare pod direttamente in qualsiasi namespace utilizzando l'account utente. Questo perché gli utenti con<block ref="72122ce96bfec66e2396d2e25225d70a" prefix=" " category="inline-code"></block> oppure<block ref="de95b43bceeb4b998aed4aed5cef1ae7" prefix=" " category="inline-code"></block> l'autorizzazione viene assegnata al ruolo di amministratore del cluster. Tuttavia, quando si creano implementazioni, daemon set, stateful set o altri in qualsiasi namespace, è necessario assegnare un ruolo con le autorizzazioni richieste agli account di servizio corrispondenti. Ciò è necessario perché le implementazioni o i set di daemon utilizzano account di servizio per implementare i pod.</block>
  <block id="dc4ab077311e2aad5b5af968844fc5fe" category="paragraph">Vedere il seguente esempio di ClusterRoleBinding per assegnare il ruolo di amministratore del cluster a tutti gli account di servizio nel cluster:</block>
  <block id="74d32c3e98de18a4adf66bd3f05e6088" category="inline-link-macro">Pagina successiva: Panoramica dei sistemi storage NetApp.</block>
  <block id="86de08c652cda2ec18cd6f36a36cfcfa" category="paragraph"><block ref="86de08c652cda2ec18cd6f36a36cfcfa" category="inline-link-macro-rx"></block></block>
  <block id="fa6f7af807ffa3ac6e2efb5c31463a4f" category="paragraph">Per consentire l'integrazione di Trident con il sistema storage NetApp ONTAP tramite NFS, è necessario creare un backend che consenta la comunicazione con il sistema storage. In questa soluzione viene configurato un backend di base, ma se si cercano opzioni più personalizzate, consultare la documentazione <block ref="f72d871ae286e7b7cf7d9ea12426661a" category="inline-link-macro-rx"></block>.</block>
  <block id="aaa6c6e969e6e978f9a8bce54e31b5f7" category="section-title">Creare una SVM in ONTAP</block>
  <block id="b1c04b7e96694453a1307ecc81208ae5" category="list-text">Accedere a Gestore di sistema di ONTAP, selezionare Storage &gt; Storage VM e fare clic su Aggiungi.</block>
  <block id="f53bd08113ff367a9bcd470b70a036d8" category="list-text">Immettere un nome per SVM, attivare il protocollo NFS, selezionare la casella di controllo Allow NFS Client Access (Consenti accesso client NFS) e aggiungere le subnet su cui si trovano i nodi di lavoro nelle regole dei criteri di esportazione per consentire il montaggio dei volumi come PVS nei cluster di workload.</block>
  <block id="0cdb2a8f015b7a7d81ab5c3d73de88a5" category="image-alt">Creazione di SVM con NFS</block>
  <block id="e570ad3092406b5118fcd78a9374e048" category="admonition">Se si utilizza l'implementazione NAT dei cluster di utenti o dei cluster di workload con NSX-T, è necessario aggiungere la subnet Egress (nel caso di TKGS0 o la subnet IP mobile (nel caso di TKGI) alle regole dei criteri di esportazione.</block>
  <block id="8f254daa71e82320e11e55258b095b00" category="list-text">Fornire i dettagli relativi ai file LIF dei dati e all'account di amministrazione SVM, quindi fare clic su Save (Salva).</block>
  <block id="02ffb816541fbf18a204c877564fb92e" category="image-alt">Gestione di LIF dati SVM e SVM</block>
  <block id="491df82049a4ac2d8b8b2fe6b773d65d" category="list-text">Assegnare gli aggregati a una SVM. Accedere a Storage &gt; Storage VM (Storage VM), fare clic sui puntini di sospensione accanto alla SVM appena creata, quindi fare clic su Edit (Modifica). Selezionare la casella di controllo Limit Volume Creation to Preferred Local Tier (limita creazione volume a livelli locali preferiti) e allegarvi gli aggregati richiesti.</block>
  <block id="85c5adc69f6da0ebb2ebf365c4211508" category="image-alt">Allocazione aggregata SVM</block>
  <block id="95fdf7e31ffa1073f8c42359589c334e" category="list-text">In caso di implementazioni NAT di cluster di utenti o workload su cui deve essere installato Trident, la richiesta di montaggio dello storage potrebbe provenire da una porta non standard a causa di SNAT. Per impostazione predefinita, ONTAP consente le richieste di montaggio del volume solo quando originate dalla porta root. Quindi, accedere all'interfaccia utente di ONTAP e modificare l'impostazione per consentire le richieste di montaggio da porte non standard.</block>
  <block id="03c8ff4111bb9cfc032f786c9bd7c6e8" category="section-title">Creare backend e StorageClasses</block>
  <block id="e15177ebae9bfb9adab94a9ccf5f2e96" category="list-text">Per i sistemi NetApp ONTAP che utilizzano NFS, creare un file di configurazione back-end sul jumphost con backendName, managementLIF, dataLIF, svm, nome utente, password e altri dettagli.</block>
  <block id="c75cfbdcbbe9d48dc121fc816d4a2ccf" category="list-text">Creare il backend Trident eseguendo il seguente comando.</block>
  <block id="ad2008cda12d454189828df19b2f9742" category="list-text">Una volta creato il backend, è necessario creare una classe di storage. La seguente definizione di classe di storage di esempio evidenzia i campi obbligatori e di base. Il parametro<block ref="55b56fb238360663afa6230ad82e74a0" prefix=" " category="inline-code"></block> Dovrebbe riflettere il driver di storage del backend Trident appena creato.</block>
  <block id="0286d73690ed0ef54af06bd9175945cd" category="list-text">Creare la classe di storage eseguendo il comando kubectl.</block>
  <block id="8d8b689e86dbd34b31294b3f829db499" category="list-text">Una volta creata la classe di storage, è necessario creare la prima dichiarazione di volume persistente (PVC). Di seguito viene fornita una definizione di PVC di esempio. Assicurarsi che il<block ref="ee822781a3bd0ae0f8f6331dc4865d9c" prefix=" " category="inline-code"></block> il campo corrisponde al nome della classe di storage appena creata. La definizione del PVC può essere ulteriormente personalizzata in base alle esigenze, a seconda del carico di lavoro da fornire.</block>
  <block id="c764ff1d25a2f9241afec7161127f74d" category="list-text">Creare il PVC emettendo il comando kubectl. La creazione può richiedere del tempo a seconda delle dimensioni del volume di backup da creare, in modo da poter guardare il processo mentre viene completato.</block>
  <block id="fca47dd46473e4571bb1904fe2d5f3f5" category="inline-link-macro">Pagina successiva: Video e demo: VMware Tanzu con NetApp.</block>
  <block id="61a5a682a4430d961b9bc43c2f902e94" category="paragraph"><block ref="61a5a682a4430d961b9bc43c2f902e94" category="inline-link-macro-rx"></block></block>
  <block id="62772f599e4130a9b43b483c82338681" category="summary">VMware Tanzu è un portfolio di prodotti che consente alle aziende di modernizzare le proprie applicazioni e l'infrastruttura su cui vengono eseguite. Lo stack completo di funzionalità di VMware Tanzu unisce i team di sviluppo e delle operazioni IT su un'unica piattaforma per adottare la modernizzazione sia nelle applicazioni che nella loro infrastruttura in modo coerente in ambienti di cloud ibrido e on-premise per offrire continuamente software migliori alla produzione.</block>
  <block id="969f4a20d38cf3096e1659b96da1b729" category="doc">Panoramica di VMware Tanzu</block>
  <block id="c395793804bd9dfa82ff727781faf3c5" category="image-alt">Portfolio VMware Tanzu</block>
  <block id="3614585a8ed284306a5eadc9e31585b8" category="paragraph">Per ulteriori informazioni sulle diverse offerte e sulle relative funzionalità del portfolio Tanzu, consulta la documentazione <block ref="e9fed892b98a6bbccfc15bfe67c5aa96" category="inline-link-macro-rx"></block>.</block>
  <block id="3ff60e0bc78c13ace612734741c1e1da" category="paragraph">Per quanto riguarda il catalogo delle operazioni di Tanzu Kubernetes, VMware dispone di una vasta gamma di implementazioni per Tanzu Kubernetes Grid, che forniscono e gestiscono il ciclo di vita dei cluster di Tanzu Kubernetes su una vasta gamma di piattaforme. Un cluster Tanzu Kubernetes è una distribuzione Kubernetes completa creata e supportata da VMware.</block>
  <block id="caaf1eb22b79381e3d4a2b2b9a7d1698" category="paragraph">NetApp ha testato e validato l'implementazione e l'interoperabilità dei seguenti prodotti del portfolio VMware Tanzu nei propri laboratori:</block>
  <block id="5849f8d5cb1d66cb095da163e533dea7" category="inline-link-macro">Griglia VMware Tanzu Kubernetes (TKG)</block>
  <block id="0fe3792ebba34a6c12f05656d54ecb49" category="list-text"><block ref="0fe3792ebba34a6c12f05656d54ecb49" category="inline-link-macro-rx"></block></block>
  <block id="c840af216b38aff44cc5ba246da60e17" category="inline-link-macro">VMware Tanzu Kubernetes Grid Service (TKGS)</block>
  <block id="eac001284f9380ccf17ee4490dbe13e1" category="list-text"><block ref="eac001284f9380ccf17ee4490dbe13e1" category="inline-link-macro-rx"></block></block>
  <block id="d6a1da4b26eb2ae838f5db5e80c44aee" category="inline-link-macro">VMware Tanzu Kubernetes Grid Integrated (TKGI)</block>
  <block id="57729a0bf5ad457403cd6505bdfeb143" category="list-text"><block ref="57729a0bf5ad457403cd6505bdfeb143" category="inline-link-macro-rx"></block></block>
  <block id="516a32af5ad38dd3b9ca9c156da39add" category="inline-link-macro">VMware vSphere con Tanzu (vSphere Pod)</block>
  <block id="a6726486b20bc2510c7d0b189955e69c" category="list-text"><block ref="a6726486b20bc2510c7d0b189955e69c" category="inline-link-macro-rx"></block></block>
  <block id="9c5a4b54facfb25c9699e51ca3728574" category="summary">Dopo aver registrato i cluster VMware Tanzu Kubernetes, è possibile individuare le applicazioni implementate e gestirle tramite Astra Control Center.</block>
  <block id="ada6daf9261af1429947be91dd72757b" category="paragraph">Dopo aver registrato i cluster Tanzu Kubernetes, è possibile individuare le applicazioni implementate e gestirle tramite Astra Control Center.</block>
  <block id="48652ad0d003928f33825c84d5c8d950" category="list-text">Una volta registrati i cluster e i backend ONTAP di Tanzu Kubernetes con il centro di controllo Astra, il centro di controllo inizia automaticamente a rilevare le applicazioni in tutti gli spazi dei nomi che utilizzano lo storageclass configurato con il backend ONTAP specificato.</block>
  <block id="a013472d7ab7df6d0e423dbb7e238f7a" category="paragraph"><block ref="a013472d7ab7df6d0e423dbb7e238f7a" category="inline-link-macro-rx"></block></block>
  <block id="96b5419ab713b49685af4d923930ce22" category="summary">Per integrare il sistema di storage NetApp ONTAP con i cluster VMware Tanzu Kubernetes per volumi persistenti tramite iSCSI, il primo passo è preparare i nodi accedendo a ciascun nodo e configurando le utility o i pacchetti iSCSI per il montaggio dei volumi iSCSI.</block>
  <block id="da883967924519350a1c423bd85906dd" category="paragraph">Per integrare il sistema di storage NetApp ONTAP con i cluster VMware Tanzu Kubernetes per volumi persistenti tramite iSCSI, il primo passo è preparare i nodi accedendo a ciascun nodo e configurando le utility o i pacchetti iSCSI per il montaggio dei volumi iSCSI. A tale scopo, seguire la procedura descritta in questo documento <block ref="fb2092145032d18c9376d95ca453f9a7" category="inline-link-macro-rx"></block>.</block>
  <block id="50c35de69200a8b9e4be302372e74851" category="admonition">NetApp sconsiglia questa procedura per le implementazioni NAT dei cluster VMware Tanzu Kubernetes.</block>
  <block id="bfc5022105ee1678e96b6f9991116647" category="admonition">TKGI utilizza le macchine virtuali Bosh come nodi per i cluster Tanzu Kubernetes che eseguono immagini di configurazione immutabili e qualsiasi modifica manuale dei pacchetti iSCSI sulle macchine virtuali Bosh non rimane persistente durante i riavvii. Pertanto, NetApp consiglia di utilizzare volumi NFS per lo storage persistente per i cluster Tanzu Kubernetes implementati e gestiti da TKGI.</block>
  <block id="16e4431f428a4ec8abdfbee6ec2c2889" category="paragraph">Una volta preparati i nodi del cluster per i volumi iSCSI, è necessario creare un backend che consenta la comunicazione con il sistema storage. In questa soluzione è stato configurato un backend di base, ma per ulteriori opzioni personalizzate, consultare la documentazione <block ref="f151238ff3a8d488c82b6303d676eaa3" category="inline-link-macro-rx"></block>.</block>
  <block id="31cd969d7cf1970993d449ccccaeddfe" category="paragraph">Per creare una SVM in ONTAP, attenersi alla seguente procedura:</block>
  <block id="70d94c82da2765251783d499556773b7" category="list-text">Inserire un nome per la SVM, attivare il protocollo iSCSI, quindi fornire i dettagli per la LIF dei dati.</block>
  <block id="9305b9f7555d613129963713b0c214e6" category="image-alt">LIF di dati SVM iSCSI</block>
  <block id="f9edece6d4cf48c209a5fe7da61f0ecb" category="list-text">Inserire i dettagli dell'account di amministrazione SVM, quindi fare clic su Save (Salva).</block>
  <block id="2b44a7a64e9a3efc0b4e423d6339aaa7" category="image-alt">Amministrazione di iSCSI SVM</block>
  <block id="f61c0f70e825557a7be7fe0ac432bdf7" category="list-text">Per assegnare gli aggregati alla SVM, selezionare Storage &gt; Storage VM (Storage &gt; Storage VM), fare clic sui puntini di sospensione accanto alla SVM appena creata, quindi fare clic su Edit (Modifica). Selezionare la casella di controllo Limit Volume Creation to Preferred Local Tier (limita creazione volume a livelli locali preferiti) e allegarvi gli aggregati richiesti.</block>
  <block id="74ede5d2e56e369e9eda54f4095292f5" category="list-text">Dopo aver creato un backend, è necessario creare una classe di storage. La seguente definizione di classe di storage di esempio evidenzia i campi obbligatori e di base. Il parametro<block ref="55b56fb238360663afa6230ad82e74a0" prefix=" " category="inline-code"></block> Dovrebbe riflettere il driver di storage del backend Trident appena creato. Annotare anche il valore del campo nome, a cui si deve fare riferimento in un passaggio successivo.</block>
  <block id="cf2c5963ca8332d4f43e6c3a955da4da" category="admonition">Esiste un campo opzionale chiamato<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> definito in questo file. Nei backend iSCSI, questo valore può essere impostato su un tipo di file system Linux specifico (XFS, ext4 e così via) o può essere cancellato per consentire ai cluster Tanzu Kubernetes di decidere quale filesystem utilizzare.</block>
  <block id="84053bd81ac19b225e107ad3b65ca58d" category="paragraph"><block ref="84053bd81ac19b225e107ad3b65ca58d" category="inline-link-macro-rx"></block></block>
  <block id="5f87e8fbf603b28eb84592d8e64980c6" category="doc">Ulteriori informazioni: VMware Tanzu con NetApp</block>
  <block id="a6f4f5f0d313fa8894e4ad13a09339c0" category="list-text">Documentazione VMware Tanzu</block>
  <block id="57a35ee57ca4eb666386f668ebc74599" category="inline-link"><block ref="57a35ee57ca4eb666386f668ebc74599" category="inline-link-rx"></block></block>
  <block id="35d5768f9d0ee829a3e2cae0cba15216" category="paragraph"><block ref="35d5768f9d0ee829a3e2cae0cba15216" category="inline-link-rx"></block></block>
  <block id="2839dd9e9e31ca41ba6399c0a64d3333" category="list-text">Documentazione di VMware Tanzu Kubernetes Grid</block>
  <block id="94ecd750f91f6d1908b92ec42eb37398" category="inline-link"><block ref="94ecd750f91f6d1908b92ec42eb37398" category="inline-link-rx"></block></block>
  <block id="f0a59887fc9e8ee88512ff6312c13efa" category="paragraph"><block ref="f0a59887fc9e8ee88512ff6312c13efa" category="inline-link-rx"></block></block>
  <block id="9cf21c31f745a435ac892addf1fd1a3f" category="list-text">Documentazione del servizio Grid VMware Tanzu Kubernetes</block>
  <block id="98978b88e05533d45b79613d9ee6f26d" category="inline-link"><block ref="98978b88e05533d45b79613d9ee6f26d" category="inline-link-rx"></block></block>
  <block id="56c4cea9b33fd23cf082d00ca92d5a46" category="paragraph"><block ref="56c4cea9b33fd23cf082d00ca92d5a46" category="inline-link-rx"></block></block>
  <block id="c23715ed7437fed1084a24cebb89e63c" category="list-text">Documentazione di VMware Tanzu Kubernetes Grid Integrated Edition</block>
  <block id="fd2560680b89b39b1b988587bf383fb4" category="inline-link"><block ref="fd2560680b89b39b1b988587bf383fb4" category="inline-link-rx"></block></block>
  <block id="f4b2873e621660e86074a62e5a6c5eac" category="paragraph"><block ref="f4b2873e621660e86074a62e5a6c5eac" category="inline-link-rx"></block></block>
  <block id="5851271128193658704cec246f4fd21c" category="doc">Panoramica sull'integrazione dello storage NetApp</block>
  <block id="c21c42ee74a060038cdb9ea059b7702a" category="list-text"><block ref="c21c42ee74a060038cdb9ea059b7702a" category="inline-link-macro-rx"></block></block>
  <block id="bbf3919625853b65280d28c2d26004fd" category="list-text"><block ref="bbf3919625853b65280d28c2d26004fd" category="inline-link-macro-rx"></block></block>
  <block id="7c83f61ffb36cd4e6fa256ea9573bcff" category="inline-link-macro">Pagina successiva: Panoramica di NetApp Astra Control.</block>
  <block id="9fefc82351a3a2abfcae01d825253856" category="paragraph"><block ref="9fefc82351a3a2abfcae01d825253856" category="inline-link-macro-rx"></block></block>
  <block id="30a7219728f2665214ac7ae0458c27a8" category="list-text"><block ref="30a7219728f2665214ac7ae0458c27a8" category="inline-link-macro-rx"></block></block>
  <block id="de15ad9e760a3587b2effb60a58133b1" category="summary">Astra Trident è un orchestrator di storage open-source e completamente supportato per container e distribuzioni Kubernetes, tra cui VMware Tanzu.</block>
  <block id="143c9ea21ac76ba425aa94411fbba07b" category="doc">Panoramica di Astra Trident</block>
  <block id="ebe5598ec22d01fe25c02071b488309b" category="section-title">Implementare l'operatore Trident utilizzando Helm</block>
  <block id="a082551b03c5e35829be23792317ac16" category="list-text">Aggiungi il repository NetApp Astra Trident Helm.</block>
  <block id="836237f5ff429cb9283688cdfaa56c76" category="list-text">Aggiornare i repository Helm.</block>
  <block id="875c7439b686e253522033c63d909efe" category="list-text">Creare un nuovo namespace per l'installazione di Trident.</block>
  <block id="82b1cf842f022e618212caef5d3c942d" category="list-text">Crea un segreto con le credenziali DockerHub per scaricare le immagini di Astra Trident.</block>
  <block id="e5073fdda88ef7d6b18ac4f938abbece" category="list-text">Per i cluster di utenti o carichi di lavoro gestiti da TKGS (vSphere con Tanzu) o TKG con implementazioni di cluster di gestione, completare la seguente procedura per installare Astra Trident:</block>
  <block id="d409e9c69dd2082fd0ed8a86d87258e8" category="list-text">Assicurarsi che l'utente che ha effettuato l'accesso disponga delle autorizzazioni necessarie per creare account di servizio nello spazio dei nomi Trident e che gli account di servizio nello spazio dei nomi Trident dispongano delle autorizzazioni necessarie per creare pod.</block>
  <block id="397ae57f2a6cbd8444c419c896f19886" category="list-text">Eseguire il seguente comando helm per installare l'operatore Trident nello spazio dei nomi creato.</block>
  <block id="eef6352658410e2218bd7027ae8ff351" category="list-text">Per un cluster di utenti o workload gestito dalle implementazioni TKGI, eseguire il seguente comando helm per installare l'operatore Trident nello spazio dei nomi creato.</block>
  <block id="12d34565a0d56eff4f8d3f99b138e11a" category="list-text">Verificare che i pod Trident siano in funzione.</block>
  <block id="f48fa73c7f509e20ce14901e4639f13d" category="paragraph">Dopo aver completato l'installazione di Astra Trident Operator, è necessario configurare il backend per la piattaforma di storage NetApp specifica in uso. Seguire i collegamenti riportati di seguito per continuare l'installazione e la configurazione di Astra Trident.</block>
  <block id="c060cacb4d77409e1402a5dcab49bf8b" category="list-text"><block ref="c060cacb4d77409e1402a5dcab49bf8b" category="inline-link-macro-rx"></block></block>
  <block id="2280e7f4e3cc9a8caee65d058e1db860" category="list-text"><block ref="2280e7f4e3cc9a8caee65d058e1db860" category="inline-link-macro-rx"></block></block>
  <block id="07f15dfb0f84a062c67184adcee67a8b" category="summary">Questo documento di riferimento fornisce la convalida dell'implementazione di diversi tipi di soluzioni VMware Tanzu Kubernetes, implementate come tanzu Kubernetes Grid (TKG), tanzu Kubernetes Grid Service (TKGS) o tanzu Kubernetes Grid Integrated (TKGI) in diversi ambienti di data center validati da NetApp.</block>
  <block id="bec8bc9f783c7d01005b7e64d1ad1785" category="doc">NVA-1166: VMware Tanzu con NetApp</block>
  <block id="c837e955d75d674feb57af7e68b3d74c" category="paragraph">Questo documento di riferimento fornisce la convalida dell'implementazione di diversi tipi di soluzioni VMware Tanzu Kubernetes, implementate come tanzu Kubernetes Grid (TKG), tanzu Kubernetes Grid Service (TKGS) o tanzu Kubernetes Grid Integrated (TKGI) in diversi ambienti di data center validati da NetApp. Descrive inoltre l'integrazione dello storage con i sistemi di storage NetApp e Astra Trident Storage orchestrator per la gestione dello storage persistente e Astra Control Center per il backup e la clonazione delle applicazioni stateful che utilizzano tale storage persistente. Infine, il documento fornisce dimostrazioni video delle integrazioni e delle validazioni della soluzione.</block>
  <block id="c0a14f456cfcfac669f2cf374f60561b" category="paragraph">La soluzione VMware Tanzu con NetApp è progettata per offrire un valore eccezionale ai clienti con i seguenti casi di utilizzo:</block>
  <block id="8cc1d80dbdd5d6d142f0173d8c8f2261" category="list-text">Semplice implementazione e gestione delle offerte VMware Tanzu Kubernetes Grid implementate su VMware vSphere e integrate con i sistemi storage NetApp.</block>
  <block id="8796988ff3c4f065733c3b887d886609" category="list-text">La potenza combinata dei container aziendali e dei carichi di lavoro virtualizzati con le offerte di VMware Tanzu Kubernetes Grid.</block>
  <block id="d7071bc518e2fa9a30b1debdd8e721f1" category="list-text">Configurazione e casi di utilizzo reali che evidenziano le funzionalità di VMware Tanzu quando viene utilizzato con lo storage NetApp e la suite di prodotti NetApp Astra.</block>
  <block id="3d4565b89cb9591acc32839ce0d48627" category="list-text">Protezione o migrazione coerente con l'applicazione di workload containerizzati implementati su cluster VMware Tanzu Kubernetes Grid i cui dati risiedono su sistemi storage NetApp utilizzando Astra Control Center.</block>
  <block id="29375f7cc2c5eece7fdd9c99f40eb3f8" category="list-text">Possibilità di implementazione in un modello di cloud ibrido con container in esecuzione sia nei data center on-premise che nel cloud.</block>
  <block id="ddea0381617b5a4b43a0a98a440c6658" category="paragraph">VMware Tanzu con NetApp riconosce queste sfide e presenta una soluzione che aiuta a risolvere ogni problema implementando le offerte VMware Tanzu Kubernetes nell'ambiente di cloud ibrido scelto dal cliente.</block>
  <block id="c57f369df48137f738543c0e5012006c" category="paragraph">La soluzione VMware Tanzu con NetApp comprende i seguenti componenti principali:</block>
  <block id="67d7b0b61202e57bcae8cda82f02e2b3" category="section-title">Piattaforme VMware Tanzu Kubernetes</block>
  <block id="55ad4cb8f0feecb71e184ef92cff1f70" category="paragraph">VMware Tanzu è disponibile in una serie di varianti che il team di progettazione delle soluzioni di NetApp ha validato nei nostri laboratori. Ogni release di Tanzu si integra con successo con il portfolio di storage NetApp e ciascuna di esse può aiutare a soddisfare determinate esigenze infrastrutturali. I seguenti punti chiave puntati descrivono le funzionalità e le offerte di ciascuna versione di Tanzu descritte in questo documento.</block>
  <block id="f377bdd54f0f567b139a5913567466f1" category="paragraph">*VMware Tanzu Kubernetes Grid (TKG)*</block>
  <block id="45915535ce313f81567f3b3c41571fe9" category="list-text">Ambiente Kubernetes upstream standard implementato in un ambiente VMware vSphere.</block>
  <block id="32fcd5c42dc47b5cc021d74a489dee4f" category="list-text">Precedentemente noto come Essential PKS (da Heptio Acquisition, febbraio 2019).</block>
  <block id="16196833d09cc8d52a1ef3790b4e15d3" category="list-text">TKG viene implementato con un'istanza di cluster di gestione separata per il supporto su vSphere 6.7U3 in poi.</block>
  <block id="08f2ff1c0826ffc53a185010cce7dac7" category="list-text">Le implementazioni di TKG possono essere implementate nel cloud e con AWS o Azure.</block>
  <block id="15aa7eec2d32a1ba74b5cea8af5241ec" category="list-text">Consente l'utilizzo di nodi di lavoro Windows o Linux (Ubuntu/Photon).</block>
  <block id="89a8813ef0f3f2c1a9b0f20dab87e2a2" category="list-text">NSX-T, ha Proxy, rete AVI o bilanciamento del carico possono essere utilizzati per il piano di controllo.</block>
  <block id="2ad16c86af27df82ae725dfd15176212" category="list-text">TKG supporta MetalLB per il piano dati/applicazioni.</block>
  <block id="7bf259c507ef53db8da3607757164b2e" category="list-text">Può utilizzare vSphere CSI e CSI di terze parti come NetApp Astra Trident.</block>
  <block id="7a3368d887604b1812f8f796b668f0e7" category="paragraph">*VMware Tanzu Kubernetes Grid Service (TKGS)*</block>
  <block id="27077307fac1683851c72a97ba11c62e" category="list-text">TKGS implementato con cluster di supervisore e cluster di workload solo su vSphere 7.0U1 e versioni successive.</block>
  <block id="3ee27cde76894c76ad60736ecbca78da" category="list-text">TKGS supporta MetalLB per il piano dati/applicazioni.</block>
  <block id="443c9bd7eeb4bc3d39f67cc555b4aab2" category="list-text">Fornisce supporto per vSphere Pod con Tanzu, consentendo l'esecuzione diretta dei pod su host ESXi abilitati nell'ambiente.</block>
  <block id="8da30835717bc9e00a9ea2b89d75d943" category="paragraph">*VMware Tanzu Kubernetes Grid Integrated (TKGI)*</block>
  <block id="f4ef19f9ee886fa602632ef3f35019ad" category="list-text">Precedentemente noto come Enterprise PKS (da Heptio Acquisition, febbraio 2019).</block>
  <block id="28789df26df63aa440b3aded601e67a6" category="list-text">Può utilizzare NSX-T, ha Proxy o avi. È anche possibile fornire il proprio bilanciamento del carico.</block>
  <block id="2b681f710a75cd56332534e50fe625ff" category="list-text">Supportato da vSphere 6.7U3 in poi, oltre a AWS, Azure e GCP.</block>
  <block id="f09eefe449cf027cce033ceb064c2fae" category="list-text">Installazione tramite procedura guidata per semplificare l'implementazione.</block>
  <block id="78c9a89b579a1005676bf4b1a4b3aad7" category="list-text">Esegue tanzu in macchine virtuali controllate immutabili gestite da BOSH.</block>
  <block id="46c96f35ab6c6f57dd96776e1f115737" category="list-text">Può utilizzare vSphere CSI e CSI di terze parti come NetApp Astra Trident (sono applicabili alcune condizioni).</block>
  <block id="22bd1c4adfe1c3f7d3dc00763a7a8d40" category="paragraph">*VSphere con Tanzu (vSphere Pod)*</block>
  <block id="4f50bac068dbe84c04d257f75bb42142" category="list-text">I pod nativi di vSphere vengono eseguiti in un layer sottile e basato su fotoni con hardware virtuale prescritto per un isolamento completo.</block>
  <block id="c8cefb07aba3cc260670993281c9bef5" category="list-text">Richiede NSX-T, ma che consente il supporto di funzionalità aggiuntive come un registro di immagine Harbour.</block>
  <block id="b603aa094817eb0510887a841cc71df8" category="list-text">Implementato e gestito in vSphere 7.0U1 in poi utilizzando un cluster di Supervisor virtuale come TKGS. Esegue i pod direttamente sui nodi ESXi.</block>
  <block id="cf3b96589f75768a855cebe2679e5b8b" category="list-text">Completamente integrato con vSphere, massima visibilità e controllo grazie all'amministrazione di vSphere.</block>
  <block id="3b050b735b1eb713cc1b3816851e3060" category="list-text">Pod isolati basati su CRX per il massimo livello di sicurezza.</block>
  <block id="e7004adb0d2f74954305a1023249e642" category="list-text">Supporta solo vSphere CSI per lo storage persistente. Nessun orchestratore di storage di terze parti supportato.</block>
  <block id="b63d5ee355078976e86c94b5c978788e" category="paragraph">NetApp Astra Control Center offre un'ampia gamma di servizi di gestione dei dati application-aware e storage per carichi di lavoro Kubernetes stateful, implementati in un ambiente on-premise e basati sulla tecnologia di protezione dei dati NetApp.</block>
  <block id="90534ff553f8895d609b7e0cec5e7977" category="paragraph">Astra Trident è un orchestrator di storage open-source e completamente supportato per container e distribuzioni Kubernetes, tra cui VMware Tanzu.</block>
  <block id="67c6ecbcd91c613e8659b3f0c4b01510" category="cell">9.9.1</block>
  <block id="63355c54bd7e8ff73915da41610ec6f7" category="cell">22.04.0</block>
  <block id="a3e69dd4d9f892aab0dcbf0a5dd246e2" category="cell">1.4+</block>
  <block id="22053fd2d26d3a313aea03b09e9a776c" category="cell">Servizio griglia VMware Tanzu Kubernetes</block>
  <block id="c99c6e88d4de8db879b1b5ec64d1f7ed" category="cell">0.0.15 [vSphere Namespaces]</block>
  <block id="8eb1302ead60c09b6d757b2b7ab84040" category="cell">1.22.6 [Supervisor Cluster Kubernetes]</block>
  <block id="caf617dd6edf29fd289caff7469ea66b" category="cell">VMware Tanzu Kubernetes Grid integrato</block>
  <block id="1d5bc9367c9565bbe31cc00aa1f870a4" category="cell">1.13.3</block>
  <block id="5d9dd4ee62c5446f01e895cd118d98dd" category="cell">Data center VMware NSX-T.</block>
  <block id="7bc09c21b8fa1161768459982f0ec89e" category="cell">Networking e sicurezza</block>
  <block id="b1179856b0372cb8777975cb658548ac" category="cell">3.1.3</block>
  <block id="cc540661734771d2e0272e8b4ef5c228" category="cell">VMware NSX Advanced Load Balancer</block>
  <block id="50382c1137e78c7c038faabadb85d9fd" category="cell">Bilanciamento del carico</block>
  <block id="d08680d7e9b745c4d4b81a2d6df7a012" category="cell">20.1.3</block>
  <block id="743cb170909d5e6e5936fc4783a59de5" category="inline-link-macro">Pagina successiva: Panoramica di VMware Tanzu.</block>
  <block id="4b362af24230ce2d990680198c520d44" category="paragraph"><block ref="4b362af24230ce2d990680198c520d44" category="inline-link-macro-rx"></block></block>
  <block id="3ff1ba174bc4d7824738ba1a0c0b4035" category="summary">NetApp Astra Control Center offre un'ampia gamma di servizi di gestione dei dati application-aware e storage per carichi di lavoro Kubernetes stateful, implementati in un ambiente on-premise, basati su una tecnologia di protezione dei dati affidabile di NetApp.</block>
  <block id="678f429fd30f5d3718b72e260e17f5f0" category="paragraph">Se stai cercando un toolkit di sviluppo software pronto per interagire con le API REST di Astra Control, NetApp fornisce un toolkit con l'SDK di Astra Control Python che puoi scaricare <block ref="ccffe56769527505ab07c82206690bfe" category="inline-link-macro-rx"></block>.</block>
  <block id="6b24baf9bd0e230b887612f836d0fbd5" category="paragraph">Se la programmazione non è adatta alla situazione e si desidera utilizzare uno strumento di gestione della configurazione, è possibile clonare ed eseguire i playbook Ansible pubblicati da NetApp <block ref="8c91b346fb645d82eb54fe01a7c0cd36" category="inline-link-macro-rx"></block>.</block>
  <block id="c90524de7ee251d8a5128ac3f59847c6" category="paragraph">L'installazione di Astra Control Center richiede i seguenti prerequisiti:</block>
  <block id="9f2559e9a5f31fdb3d5489aa3367ae35" category="list-text">Uno o più cluster Tanzu Kubernetes, gestiti da un cluster di gestione o da TKGS o TKGI. Sono supportati i cluster di workload TKG 1.4+ e i cluster di utenti TKGI 1.12.2+.</block>
  <block id="c94e1287a80d82c490967572d336083d" category="list-text">Astra Trident deve essere già installato e configurato su ciascuno dei cluster Tanzu Kubernetes.</block>
  <block id="ba1c516a3e7a998469a5ac73695127ce" category="admonition">È consigliabile che ogni Tanzu Kubernetes installato in un sito disponga di una SVM dedicata per lo storage persistente. Le implementazioni multi-sito richiedono sistemi storage aggiuntivi.</block>
  <block id="c756010e6a027d7d6ae199c033f4b1db" category="list-text">È necessario configurare un backend di storage Trident su ogni cluster Tanzu Kubernetes con una SVM supportata da un cluster ONTAP.</block>
  <block id="dd7ed1e31baf27a40282a08242cf6efc" category="list-text">Un StorageClass predefinito configurato su ciascun cluster Tanzu Kubernetes con Astra Trident come provisioning dello storage.</block>
  <block id="e8ed7f9c94a716f73364706e6db9c1c6" category="list-text">È necessario installare e configurare un bilanciamento del carico su ciascun cluster Tanzu Kubernetes per il bilanciamento del carico e l'esposizione di Astra Control Center se si utilizza ingressType<block ref="0a3e1793e4eaf6bd67bdf43d1bca1c74" prefix=" " category="inline-code"></block>.</block>
  <block id="6b769b6cd8bf0a312e04e05973e13018" category="list-text">È necessario installare e configurare un controller di ingresso su ciascun cluster Tanzu Kubernetes per esporre Astra Control Center se si utilizza ingressType<block ref="8045a0a6c688b0635e3caccc408a1446" prefix=" " category="inline-code"></block>.</block>
  <block id="0e6886020b4adf5871ebc7346b63c3a0" category="list-text">È necessario disporre dell'accesso Cluster Admin al cluster Tanzu Kubernetes in cui viene installato Astra Control Center.</block>
  <block id="8bd3433e327d75f3a3c33d9998840fce" category="list-text">Una workstation di amministrazione RHEL o Ubuntu.</block>
  <block id="ed060d0439d2eda03baa2005199d9bc1" category="paragraph">Questa soluzione descrive una procedura automatica per l'installazione di Astra Control Center utilizzando i playbook Ansible. Se si sta cercando una procedura manuale per installare Astra Control Center, seguire la guida dettagliata all'installazione e alle operazioni <block ref="30c5ae998902105fcf03dc0b9654af4c" category="inline-link-macro-rx"></block>.</block>
  <block id="a7fb28a136e66b85611d0ab47d44e747" category="list-text">Per utilizzare i playbook Ansible che implementano Astra Control Center, è necessario disporre di una macchina Ubuntu/RHEL con Ansible installato. Seguire le procedure<block ref="33c646d34972887e04f4f11763cd42b6" category="inline-link-rx"></block> Per Ubuntu e RHEL.</block>
  <block id="5ed95667cae604c0ddee2dbf04f423fe" category="list-text">Accedere al NetApp Support Site e scaricare l'ultima versione di NetApp Astra Control Center. Per farlo, è necessaria una licenza allegata al tuo account NetApp. Dopo aver scaricato il tarball, trasferirlo sulla workstation.</block>
  <block id="df57d245f4173d8ac23df756917bb6ae" category="list-text">Creare o ottenere il file kubeconfig con accesso amministratore all'utente o al cluster del carico di lavoro Tanzu Kubernetes su cui deve essere installato Astra Control Center.</block>
  <block id="b2d9440273952d4b05aed1b36c66494d" category="list-text">Modificare la directory in<block ref="01199d5fee9fe01be523a2944ceef91d" prefix=" " category="inline-code"></block>.</block>
  <block id="7489123185b81a6e11b42218fabb4c3b" category="list-text">Modificare il<block ref="014d194d817c312b5ce910e74b4d3836" prefix=" " category="inline-code"></block> archiviare e compilare le variabili con le informazioni richieste.</block>
  <block id="2b6b49be82749b9e141c2f0a23c8d11f" category="paragraph">Eseguire il seguente comando per eseguire il playbook se l'utente che esegue il playbook è root o ha configurato sudo senza password.</block>
  <block id="6b682acdf6e246de63c54d6f90044faa" category="paragraph">Se l'utente ha configurato l'accesso sudo basato su password, eseguire il seguente comando per eseguire il manuale e inserire la password sudo.</block>
  <block id="111dd0947a16442f317af649a2aac536" category="list-text">Ottenere l'IP del bilanciamento del carico del servizio traefik se il tipo di entressType è AccTraefik.</block>
  <block id="25ce05402248633e67c7cbc234573b60" category="list-text">Astra Control Center richiede una licenza per il funzionamento di tutte le sue funzionalità. Per aggiungere una licenza, accedere a account &gt; License (account &gt; licenza), fare clic su Add License (Aggiungi licenza) e caricare il file di licenza.</block>
  <block id="bf3293f2603ff733102e45d1152bc0a1" category="admonition">In caso di problemi con l'installazione o la configurazione di NetApp Astra Control Center, è disponibile la knowledge base dei problemi noti<block ref="695f48b1d8b7348c0e2828947d24161e" category="inline-link-rx"></block>.</block>
  <block id="1e89038a8ae648db9dd4b203267abd3a" category="inline-link-macro">Avanti: Registra i tuoi cluster Tanzu Kubernetes.</block>
  <block id="c7f57c40ce02379584ec7748d9444ee0" category="paragraph"><block ref="c7f57c40ce02379584ec7748d9444ee0" category="inline-link-macro-rx"></block></block>
  <block id="318a4bce7f9fca07a60ed82408fbcd29" category="doc">Panoramica di VMware Tanzu Kubernetes Grid (TKG)</block>
  <block id="11e5f8209ef45e9884518caf7b5bc68d" category="paragraph">VMware Tanzu Kubernetes Grid, noto anche come TKG, consente di implementare cluster Tanzu Kubernetes in ambienti cloud ibridi o cloud pubblici. TKG viene installato come cluster di gestione, che è un cluster Kubernetes stesso, che implementa e gestisce i cluster Tanzu Kubernetes. Questi cluster Tanzu Kubernetes sono i cluster Kubernetes per il carico di lavoro su cui viene implementato il carico di lavoro effettivo.</block>
  <block id="9a67a32e17609515d2fc11383d1a7b59" category="paragraph">Tanzu Kubernetes Grid si basa su alcuni dei promettenti progetti della community upstream e offre una piattaforma Kubernetes sviluppata, commercializzata e supportata da VMware. Oltre alla distribuzione Kubernetes, Tanzu Kubernetes Grid fornisce add-on aggiuntivi che sono servizi essenziali per la produzione come Registro di sistema, bilanciamento del carico, autenticazione e così via. VMware TKG con cluster di gestione è ampiamente utilizzato negli ambienti vSphere 6.7 e, anche se supportato, non è un'implementazione consigliata per gli ambienti vSphere 7 perché TKGS dispone di funzionalità di integrazione nativa con vSphere 7.</block>
  <block id="4e6c29e9760f3e53993a64a5f6c63aaa" category="image-alt">VMware Tanzu Kubernetes Grid con cluster di gestione</block>
  <block id="ec30336a82729146050b0931adab64f2" category="paragraph">Per ulteriori informazioni su Tanzu Kubernetes Grid, consultare la documentazione <block ref="f4dbc56b610d9f5cd603e1a13bb6dedf" category="inline-link-macro-rx"></block>.</block>
  <block id="86fcbed2a7f5b8edced11b10bd1e4266" category="paragraph">A seconda che il sistema Tanzu Kubernetes Grid venga installato on-premise sul cluster vSphere o in ambienti cloud, preparare e implementare il sistema Tanzu Kubernetes Grid seguendo la guida all'installazione <block ref="492c3fae38681e036fd18bedc1bf8ae5" category="inline-link-macro-rx"></block>.</block>
  <block id="c1f07986544fbf96897f8099577b0e72" category="paragraph">Dopo aver installato il cluster di gestione per Tanzu Kubernetes Grid, implementare i cluster di utenti o i cluster di workload in base alle esigenze seguendo la documentazione <block ref="7d3f6d9f879d392af501006eacd0d221" category="inline-link-macro-rx"></block>. Il cluster di gestione VMware TKG richiede la fornitura di una chiave SSH per l'installazione e il funzionamento dei cluster Tanzu Kubernetes. Questa chiave può essere utilizzata per accedere ai nodi del cluster utilizzando<block ref="5ef871b8f1f696f9bb22de1dff45a81c" prefix=" " category="inline-code"></block> utente.</block>
  <block id="f78d920d9d248820ddf7a3acdd9a34c0" category="doc">Panoramica di VMware vSphere con Tanzu</block>
  <block id="25e19f6e213533d24e711ce5e6738fa9" category="paragraph">VMware vSphere con Tanzu, noto anche come vSphere Pod, consente di utilizzare i nodi dell'hypervisor ESXi nell'ambiente VMware vSphere come nodi di lavoro in un ambiente Kubernetes bare Metal.</block>
  <block id="bac31e763c1b2955be0a10de0a4d8012" category="image-alt">VMware vSphere con Kubernetes</block>
  <block id="c2e55cf1007600b25e0708bfe26a41f3" category="paragraph">Un ambiente VMware vSphere con Tanzu è abilitato sotto la gestione del carico di lavoro proprio come un cluster TKGS nativo.</block>
  <block id="c2556907e1f90b93c9c43e198113de8b" category="paragraph">Viene creato un cluster di supervisore virtualizzato per fornire un piano di controllo altamente disponibile per Kubernetes e vengono creati singoli namespace per ogni applicazione per garantire l'isolamento delle risorse per gli utenti.</block>
  <block id="9ff6aa8ffa487db2f0aebe3967972d77" category="image-alt">Cluster di supervisori</block>
  <block id="9e2885b693a2045e931fda4aeb8bf28f" category="paragraph">Quando VMware vSphere con Tanzu è attivato, ogni host ESXi dispone dell'applicazione Spherelet installata e configurata. Questo consente a ciascun nodo di agire come lavoratore in un'implementazione di Kubernetes e di gestire i pod implementati su ciascun nodo.</block>
  <block id="b3ba0fe968ce39dcfc6fe8cc0f1b02da" category="image-alt">Namespace</block>
  <block id="c44d7c5351501c027261c0480a658d6d" category="paragraph">Attualmente, VMware vSphere con Tanzu e vSphere Pod supportano solo il driver vSphere CSI locale. Ciò è possibile grazie alla creazione da parte degli amministratori di policy di storage nel client vSphere che consentono di selezionare le destinazioni di storage attualmente disponibili per l'utilizzo come datastore vSphere. Questi criteri vengono utilizzati per creare volumi persistenti per le applicazioni containerizzate.</block>
  <block id="fe41e8fdcbc9d8447c9077fbd167fe8d" category="admonition">Sebbene attualmente non sia disponibile alcun supporto per il driver NetApp Astra Trident CSI che consente la connettività diretta ad array di storage ONTAP ed Element esterni, questi sistemi storage NetApp vengono spesso utilizzati per supportare lo storage primario per l'ambiente vSphere, Inoltre, è possibile utilizzare in questo modo gli avanzati strumenti di gestione dei dati e di efficienza dello storage di NetApp.</block>
  <block id="70aaffec040bcf9e5cf77c0ccabb8f11" category="paragraph">Per ulteriori informazioni su VMware vSphere con Tanzu, consultare la documentazione <block ref="0cdaad1423fdb034ad0ee788d57a7a82" category="inline-link-macro-rx"></block>.</block>
  <block id="af4fcf3aff174981414dc5c9fce2f4ec" category="section-title">Creare un'istantanea dell'applicazione</block>
  <block id="29335406e75e8b137ee91c9f44068bc6" category="paragraph">Un'istantanea di un'applicazione crea una copia Snapshot di ONTAP e una copia dei metadati dell'applicazione che possono essere utilizzati per ripristinare o clonare l'applicazione in un momento specifico in base a tale copia Snapshot.</block>
  <block id="9bb92323cd91f66cadcdc492341cddd5" category="section-title">Creare un backup dell'applicazione</block>
  <block id="c4c29bc3f7db6d04fde98415386e1e7f" category="list-text">Per ripristinare un'applicazione, accedere alla scheda applicazioni &gt; gestite e fare clic sull'applicazione in questione. Fare clic sul menu a discesa accanto al nome dell'applicazione e fare clic su Restore (Ripristina).</block>
  <block id="2c0d64177d5c89bc452e9f1eb0fd4f65" category="list-text">Immettere i dettagli del nuovo spazio dei nomi, selezionare il cluster in cui si desidera clonarlo e scegliere se clonarlo da uno snapshot esistente, da un backup o dallo stato corrente dell'applicazione. Fare clic su Next (Avanti), quindi su Clone (Clona) nel riquadro di revisione dopo aver esaminato i dettagli.</block>
  <block id="ef0b684dddd1cea4885513d892f39cfa" category="paragraph"><block ref="ef0b684dddd1cea4885513d892f39cfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3901d4e16e17c29d42ccb430b94cc402" category="paragraph"><block ref="3901d4e16e17c29d42ccb430b94cc402" category="inline-image-macro-rx" type="image"></block></block>
  <block id="15693c045ae1b118bd5c3f8e9cee5c08" category="summary">Per consentire ad Astra Control Center di gestire i carichi di lavoro, devi prima registrare i cluster Tanzu Kubernetes.</block>
  <block id="3a16c17a7d5ce69951add72b2e46c340" category="doc">Registra i tuoi cluster VMware Tanzu Kubernetes con Astra Control Center</block>
  <block id="a723b0aede16ae3d3bdd6761d359595b" category="section-title">Registrare i cluster VMware Tanzu Kubernetes</block>
  <block id="779e6578abb36499d7c5399b33269c9c" category="list-text">Il primo passo consiste nell'aggiungere i cluster Tanzu Kubernetes all'Astra Control Center e gestirli. Accedere a Clusters e fare clic su Add a Cluster (Aggiungi cluster), caricare il file kubeconfig per il cluster Tanzu Kubernetes e fare clic su Select Storage (Seleziona storage).</block>
  <block id="d9687c204aa759a004b29f4f41e01908" category="list-text">Una volta aggiunto, il cluster passa allo stato di rilevamento mentre Astra Control Center lo ispeziona e installa gli agenti necessari. Lo stato del cluster diventa<block ref="396d45b57c2fbe3318e7b93272a2686b" prefix=" " category="inline-code"></block> una volta completata la registrazione.</block>
  <block id="1e7084bafe0fe7d10e28e10eea2641aa" category="admonition">Tutti i cluster di Tanzu Kubernetes gestiti da Astra Control Center devono avere accesso al registro delle immagini utilizzato per l'installazione, poiché gli agenti installati sui cluster gestiti estraggono le immagini da tale registro.</block>
  <block id="f3eca6ba1067d4a61b1229f18ab1a463" category="list-text">Importa i cluster ONTAP come risorse storage da gestire come back-end dal centro di controllo Astra. Quando i cluster Tanzu Kubernetes vengono aggiunti ad Astra e viene configurato uno storageclass, il cluster ONTAP viene automaticamente scoprito e ispezionato a supporto dello storageclass, ma non viene importato nel centro di controllo Astra da gestire.</block>
  <block id="3c786ecd99f0ebd5edd64d81ad32375c" category="list-text">Per importare i cluster ONTAP, accedere a backend, fare clic sul menu a discesa e selezionare Manage (Gestisci) accanto al cluster ONTAP da gestire. Immettere le credenziali del cluster ONTAP, fare clic su informazioni di revisione, quindi fare clic su Importa backend storage.</block>
  <block id="af64f63e0642401224fc8f9c2ec7d1c5" category="list-text">Una volta aggiunti i backend, lo stato diventa disponibile. Questi backend ora dispongono delle informazioni sui volumi persistenti nel cluster Tanzu Kubernetes e sui volumi corrispondenti nel sistema ONTAP.</block>
  <block id="688cdc8b62507f4c74f7452e7889821d" category="list-text">Per il backup e il ripristino nei cluster Tanzu Kubernetes utilizzando Astra Control Center, è necessario eseguire il provisioning di un bucket di storage a oggetti che supporti il protocollo S3. Le opzioni attualmente supportate sono ONTAP S3, StorageGRID, AWS S3 e lo storage Microsoft Azure Blob. Ai fini di questa installazione, configureremo un bucket AWS S3. Accedere a Bucket, fare clic su Add bucket (Aggiungi bucket) e selezionare Generic S3. Inserisci i dettagli sul bucket S3 e le credenziali per accedervi, fai clic sulla casella di controllo Rendi questo bucket il bucket predefinito per il cloud, quindi fai clic su Aggiungi.</block>
  <block id="f1b8312f03a9ec379a8e0fc00f20be33" category="paragraph"><block ref="f1b8312f03a9ec379a8e0fc00f20be33" category="inline-link-macro-rx"></block></block>
  <block id="7654a00ca744e9bf01021439190e3119" category="doc">Panoramica di VMware Tanzu Kubernetes Grid Integrated Edition (TKGI)</block>
  <block id="644bd75ee9c13f7d8778e4638d9eb2b2" category="paragraph">VMware Tanzu Kubernetes Grid Integrated (TKGI) Edition, precedentemente noto come VMware Enterprise PKS, è una piattaforma standalone per l'orchestrazione di container basata su Kubernetes con funzionalità come gestione del ciclo di vita, monitoraggio dello stato dei cluster, networking avanzato, un registro dei container e così via. TKGI fornisce e gestisce i cluster Kubernetes con il piano di controllo TKGI, che consiste in BOSH e Ops Manager.</block>
  <block id="a84b33dfae5a2fdc1618084442bc3df0" category="paragraph">TKGI può essere installato e utilizzato in ambienti vSphere o OpenStack on-premise o in uno dei principali cloud pubblici delle rispettive offerte IaaS. Inoltre, l'integrazione di TKGI con NSX-T e Harbor consente casi di utilizzo più ampi per i carichi di lavoro aziendali. Per ulteriori informazioni su TKGI e sulle sue funzionalità, consulta la documentazione <block ref="0b1e387b87be5caa8371b58b8e02b1f8" category="inline-link-macro-rx"></block>.</block>
  <block id="26f1f37ed65557967fe3a789aa75c364" category="paragraph">TKGI viene installato in una varietà di configurazioni su una varietà di piattaforme basate su diversi casi di utilizzo e design. Seguire la guida <block ref="54093918574a441541c9219fc9d087f1" category="inline-link-macro-rx"></block> Per installare e configurare TKGI e i relativi prerequisiti. TKGI utilizza le macchine virtuali Bosh come nodi per i cluster Tanzu Kubernetes che eseguono immagini di configurazione immutabili e qualsiasi modifica manuale sulle macchine virtuali Bosh non rimane persistente durante i riavvii.</block>
  <block id="58959a34911d9e88e191f3453ddc81f0" category="paragraph">Note importanti:</block>
  <block id="d7fc6fcd5f3c3c3fca9edded9bf380e1" category="list-text">NetApp Trident richiede un accesso privilegiato ai container. Quindi, durante l'installazione di TKGI, assicurarsi di selezionare la casella di controllo Enable Privileged Containers (Abilita container privilegiati) nella fase per configurare i piani dei nodi del cluster Tanzu Kubernetes.</block>
  <block id="651650f759262b05cb38b56003e55784" category="image-alt">Privileged Containers in TKGI</block>
  <block id="956d281862a0ec3c4bb386cd28bf959c" category="list-text">NetApp consiglia di implementare tutti gli ambienti di produzione in implementazioni master multiple per la tolleranza agli errori, scegliendo la configurazione dei nodi di lavoro per soddisfare i requisiti dei carichi di lavoro previsti. Pertanto, un piano cluster TKGI consigliato consiste di almeno tre master e tre lavoratori con almeno quattro vCPU e 12 GB di RAM per un carico di lavoro altamente intensivo.</block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">In questa sezione vengono fornite le procedure dettagliate necessarie per spostare i dati MapR-FS in NFS ONTAP utilizzando NetApp XCP.</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">Da MapR-FS a NFS ONTAP</block>
  <block id="59b0eb4059face89ab060ea59984c8a7" category="inline-link-macro">Precedente: DA GPF a NFS - passaggi dettagliati.</block>
  <block id="13f1dc977877024b0f36272f1af2b238" category="paragraph"><block ref="13f1dc977877024b0f36272f1af2b238" category="inline-link-macro-rx"></block></block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">Eseguire il provisioning di tre LUN per ciascun nodo MapR e assegnare alle LUN la proprietà di tutti i nodi MapR.</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">Durante l'installazione, scegliere i LUN aggiunti di recente per i dischi del cluster MapR utilizzati per MapR-FS.</block>
  <block id="f7dc1a091cd04b392f9a99c5390b9ce2" category="inline-link">Documentazione di MapR 6.1</block>
  <block id="24cb5309ea8c5a7c3244adf133110ecf" category="list-text">Installare un cluster MapR in base a.<block ref="a38d60fa0425a18b5925139ceca806ea" category="inline-link-rx"></block>.</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">Controllare le operazioni di base di Hadoop utilizzando i comandi MapReduce, ad esempio<block ref="b5a58cfcf19813db2fae678c75e004c8" prefix=" " category="inline-code"></block>.</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">Conservare i dati dei clienti in MapR-FS. Ad esempio, utilizzando Teragen, abbiamo generato circa un terabyte di dati campione in MapR-FS.</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">Configurare MapR-FS come esportazione NFS.</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">Disattivare il servizio nlockmgr su tutti i nodi MapR.</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">Esportare cartelle specifiche da MapR-FS su tutti i nodi MapR in<block ref="84a05a173e6cd86a4169f3dbd5897873" prefix=" " category="inline-code"></block> file. Non esportare la cartella padre con permessi diversi quando si esportano le sottocartelle.</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">Aggiornare il servizio NFS MapR-FS.</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">Assegnare un intervallo IP virtuale a un server specifico o a un gruppo di server nel cluster MapR. Il cluster MapR assegna quindi un IP a un server specifico per l'accesso ai dati NFS. Gli IP abilitano la disponibilità elevata, il che significa che, in caso di guasto di un server o di una rete con un determinato IP, è possibile utilizzare l'IP successivo dell'intervallo di IP per l'accesso NFS.</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">Se si desidera fornire l'accesso NFS da tutti i nodi MapR, è possibile assegnare un set di IP virtuali a ciascun server e utilizzare le risorse di ciascun nodo MapR per l'accesso ai dati NFS.</block>
  <block id="fa6899b17d5e71a360316c355d34c8b3" category="paragraph"><block ref="fa6899b17d5e71a360316c355d34c8b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb6de965ede92bf8bb036bb8fea6eba" category="paragraph"><block ref="8cb6de965ede92bf8bb036bb8fea6eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="031b138609c608ed553a74b2a1c439e1" category="paragraph"><block ref="031b138609c608ed553a74b2a1c439e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">Controllare gli IP virtuali assegnati a ciascun nodo MapR e utilizzarli per l'accesso ai dati NFS.</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">Montare il file MapR-FS esportato con NFS utilizzando l'IP virtuale assegnato per controllare il funzionamento di NFS. Tuttavia, questo passaggio non è necessario per il trasferimento dei dati utilizzando NetApp XCP.</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">Configurare NetApp XCP per il trasferimento dei dati dal gateway NFS MapR-FS a NFS ONTAP.</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">Configurare la posizione del catalogo per XCP.</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">Copiare il file di licenza in<block ref="0c8468e8bc6e9c8ce8e4de412fee0c10" prefix=" " category="inline-code"></block>.</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">Attivare XCP utilizzando<block ref="974d7928831087bfbec5968aec9bea85" prefix=" " category="inline-code"></block> comando.</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">Controllare l'origine per l'esportazione NFS.</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">Trasferire i dati utilizzando XCP da più nodi MapR da IP di origine multipli e IP di destinazione multipli (LIF ONTAP).</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">Controllare la distribuzione del carico sul controller di storage.</block>
  <block id="93a2605b6bf89fdb9970a6dbc77dee03" category="paragraph"><block ref="93a2605b6bf89fdb9970a6dbc77dee03" category="inline-link-macro-rx"></block></block>
  <block id="2e240897109c5037e05afe0bf035d177" category="inline-link-macro">Precedente: Conclusione.</block>
  <block id="1c08b76510a159f0dcb62c62d5584a78" category="paragraph"><block ref="1c08b76510a159f0dcb62c62d5584a78" category="inline-link-macro-rx"></block></block>
  <block id="b5062caa115b4047ecd2ef0d7177923b" category="paragraph">In questo TR sono stati utilizzati i seguenti riferimenti:</block>
  <block id="7a5b516d0c7b523466aabf4d65c5920e" category="list-text">Architettura e componenti di Apache Spark</block>
  <block id="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link"><block ref="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link-rx"></block></block>
  <block id="e37c2ea27f7286c4bd6a5fda415b8de8" category="paragraph"><block ref="e37c2ea27f7286c4bd6a5fda415b8de8" category="inline-link-rx"></block></block>
  <block id="63e2d6091a94e7952a98f50aab0149ce" category="list-text">Casi di utilizzo di Apache Spark</block>
  <block id="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link"><block ref="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link-rx"></block></block>
  <block id="7bc4162d3088ec5f539bb8bccd911d30" category="paragraph"><block ref="7bc4162d3088ec5f539bb8bccd911d30" category="inline-link-rx"></block></block>
  <block id="506326e78695dcca6de9cbc14a77c5b7" category="list-text">Le sfide di Apache</block>
  <block id="6f8995e5d73fedcfa04d4c714e6f7a46" category="inline-link"><block ref="6f8995e5d73fedcfa04d4c714e6f7a46" category="inline-link-rx"></block></block>
  <block id="a4047ab5c68e6bd8f8ad5dfc79e46847" category="paragraph"><block ref="a4047ab5c68e6bd8f8ad5dfc79e46847" category="inline-link-rx"></block></block>
  <block id="635dbe8a61ae76776533cf731db5ca3d" category="list-text">NLP. Scintilla</block>
  <block id="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link"><block ref="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link-rx"></block></block>
  <block id="4f2faa20c7d825b4d0501e1086305aac" category="paragraph"><block ref="4f2faa20c7d825b4d0501e1086305aac" category="inline-link-rx"></block></block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="list-text">BERT</block>
  <block id="94f39b7b282094c13473d8b26a45d1f1" category="inline-link"><block ref="94f39b7b282094c13473d8b26a45d1f1" category="inline-link-rx"></block></block>
  <block id="aff4ff24147d7c4a2645c7781e081f7f" category="paragraph"><block ref="aff4ff24147d7c4a2645c7781e081f7f" category="inline-link-rx"></block></block>
  <block id="b507f78e88e67a8302f19d731bc75b06" category="list-text">Deep and Cross Network for ad Click Predictions</block>
  <block id="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link"><block ref="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link-rx"></block></block>
  <block id="ae454d032cd3c53237c03ee439566905" category="paragraph"><block ref="ae454d032cd3c53237c03ee439566905" category="inline-link-rx"></block></block>
  <block id="4a695ebb62ee4f32f7dd893fa1e282f9" category="inline-link"><block ref="4a695ebb62ee4f32f7dd893fa1e282f9" category="inline-link-rx"></block></block>
  <block id="c0ce2c750c3848619c847bc001ba66be" category="paragraph"><block ref="c0ce2c750c3848619c847bc001ba66be" category="inline-link-rx"></block></block>
  <block id="becd6832ca6f3b6680d480b5802d1435" category="list-text">ETL streaming</block>
  <block id="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link"><block ref="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link-rx"></block></block>
  <block id="8d325f57229e685a7ad47c71dd567604" category="paragraph"><block ref="8d325f57229e685a7ad47c71dd567604" category="inline-link-rx"></block></block>
  <block id="31a31ad34b829349beab62dc154bb53c" category="list-text">Soluzioni NetApp e-Series per Hadoop</block>
  <block id="7cc9f35180bb40054e46d3046347f4fd" category="inline-link"><block ref="7cc9f35180bb40054e46d3046347f4fd" category="inline-link-rx"></block></block>
  <block id="ea07fc98557e1b8c5b675972fe1621da" category="paragraph"><block ref="ea07fc98557e1b8c5b675972fe1621da" category="inline-link-rx"></block></block>
  <block id="6e1ead71812900db964474f24a84ff5e" category="list-text">Analisi del sentimento da Customer Communications con NetApp ai</block>
  <block id="270a8289ec3296709282f87be3043182" category="inline-link"><block ref="270a8289ec3296709282f87be3043182" category="inline-link-rx"></block></block>
  <block id="5d6e0d6396516ff7be3c4a58b49ef3a7" category="paragraph"><block ref="5d6e0d6396516ff7be3c4a58b49ef3a7" category="inline-link-rx"></block></block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="list-text">Soluzioni NetApp per l'analisi dei dati moderna</block>
  <block id="a435d889d8c30f88d959b581e585cb98" category="inline-link"><block ref="a435d889d8c30f88d959b581e585cb98" category="inline-link-rx"></block></block>
  <block id="2e0db0f40c94a679b5a5692c131d03f4" category="paragraph"><block ref="2e0db0f40c94a679b5a5692c131d03f4" category="inline-link-rx"></block></block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="list-text">SnapMirror</block>
  <block id="c932e562e101240deed6e4be0656dfd6" category="inline-link"><block ref="c932e562e101240deed6e4be0656dfd6" category="inline-link-rx"></block></block>
  <block id="750daab11890513d7529766b651ae531" category="paragraph"><block ref="750daab11890513d7529766b651ae531" category="inline-link-rx"></block></block>
  <block id="a7ac1d2e69b9bbb9a2accb2ec30a1d69" category="list-text">XCP</block>
  <block id="e7d54d48522774aa8774f3733414d084" category="inline-link"><block ref="f575d0e12f7a285daadcaf60a35e305e" category="inline-link-rx"></block></block>
  <block id="a0b810672fcf48d5064bdbf73f520d55" category="paragraph"><block ref="d41dfcb87efb2171f45941c801c9f5cc" category="inline-link-rx"></block></block>
  <block id="e367efbc26bd12c0d6ae37dd6a55ef9b" category="list-text">Cloud Sync</block>
  <block id="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link"><block ref="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link-rx"></block></block>
  <block id="b8cfbcc5c9748a8f12142a1b9aae0e67" category="paragraph"><block ref="b8cfbcc5c9748a8f12142a1b9aae0e67" category="inline-link-rx"></block></block>
  <block id="ce9b5cd96205262213c417b501e9ed55" category="list-text">Toolkit DataOps</block>
  <block id="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link"><block ref="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link-rx"></block></block>
  <block id="20a0f3ab42054c3aa4add8c8901b4aa9" category="paragraph"><block ref="20a0f3ab42054c3aa4add8c8901b4aa9" category="inline-link-rx"></block></block>
  <block id="c7ebb883721f7d9264fd6ef2ae03fc71" category="summary">Questo report tecnico illustra i vantaggi offerti da NetApp a una soluzione Splunk SmartStore, dimostrando al contempo un framework per la progettazione e il dimensionamento di Splunk SmartStore nel tuo ambiente. Il risultato è una soluzione semplice, scalabile e resiliente che offre un TCO convincente.</block>
  <block id="766d1a96c4f198ecfe92484b980e9b31" category="doc">TR-4869: NetApp StorageGRID con Splunk SmartStore</block>
  <block id="2dafc6e921d43527cceb2ba642abf973" category="paragraph">Karthikeyan Nagalingam, Bobby Oommen, Joseph Kandatilparambil</block>
  <block id="648e525fafbee4c7b749ab8740beb0d3" category="paragraph">Splunk Enterprise è la soluzione leader di mercato per la gestione di eventi e informazioni di sicurezza (SIEM) che promuove i risultati nei team di sicurezza, IT e DevOps. I volumi di dati continuano a crescere a velocità esponenziali, creando enormi opportunità per le aziende in grado di sfruttare questa vasta risorsa. Splunk Enterprise continua a essere adottato in una vasta gamma di casi di utilizzo. Man mano che i casi di utilizzo aumentano, anche la quantità di dati che Splunk Enterprise acquisisce ed elabora. L'architettura tradizionale di Splunk Enterprise è un design scale-out distribuito che offre un accesso e una disponibilità dei dati eccellenti. Tuttavia, le aziende che utilizzano questa architettura devono affrontare i costi crescenti associati alla scalabilità per soddisfare il volume di dati in rapida crescita.</block>
  <block id="6a7254f4c4c618a79510973c24f6b258" category="paragraph">Splunk SmartStore con NetApp StorageGRID risolve questa sfida offrendo un nuovo modello di implementazione in cui calcolo e storage sono separati. Questa soluzione offre inoltre scalabilità ed elasticità senza pari per gli ambienti Splunk Enterprise, consentendo ai clienti di scalare su uno o più siti, riducendo al contempo i costi consentendo la scalabilità indipendente di calcolo e storage e aggiungendo tiering intelligente allo storage a oggetti S3 conveniente basato sul cloud.</block>
  <block id="f8ff71716eed4ad221efc3e0d60beaf6" category="paragraph">La soluzione ottimizza la quantità di dati nello storage locale mantenendo le performance di ricerca, consentendo di scalare on-demand calcolo e storage. SmartStore valuta automaticamente i modelli di accesso ai dati per determinare quali dati devono essere accessibili per l'analisi in tempo reale e quali dati devono risiedere in uno storage a oggetti S3 a basso costo.</block>
  <block id="5c56ae45ba2fb5c42451dffdb2e64b55" category="paragraph">Questo report tecnico illustra i vantaggi offerti da NetApp a una soluzione Splunk SmartStore, dimostrando al contempo un framework per la progettazione e il dimensionamento di Splunk SmartStore nel tuo ambiente. Il risultato è una soluzione semplice, scalabile e resiliente che offre un TCO convincente. StorageGRID offre lo storage a oggetti basato su API/protocollo S3, scalabile e conveniente, noto anche come storage remoto, consentendo alle organizzazioni di scalare la propria soluzione Splunk a un costo inferiore, aumentando al contempo la resilienza.</block>
  <block id="9841b81741e6066deac80b48e24f10fd" category="admonition">Splunk SmartStore si riferisce allo storage a oggetti come archivi remoti o Tier di storage remoto.</block>
  <block id="4c1ead791cca9ec5a7b94356255ce5ef" category="section-title">Informazioni su NetApp StorageGRID</block>
  <block id="57f13ae6637bd7ac5af4d0b1c4342cf7" category="paragraph">NetApp StorageGRID è una soluzione di storage a oggetti software-defined per archivi di grandi dimensioni, archivi multimediali e archivi di dati web. Con StorageGRID, NetApp sfrutta due decenni di esperienza nella fornitura di soluzioni di innovazione e gestione dei dati leader del settore, aiutando le organizzazioni a gestire e massimizzare il valore delle proprie informazioni sia on-premise che in implementazioni di cloud pubblico, privato o ibrido.</block>
  <block id="6281e52aec6aad8556d89bbf44d95436" category="paragraph">StorageGRID offre uno storage sicuro e durevole per i dati non strutturati su larga scala. Le policy integrate di gestione del ciclo di vita basate sui metadati ottimizzano la posizione dei dati durante l'intero ciclo di vita. I contenuti vengono posizionati nella giusta posizione, al momento giusto e nel giusto Tier di storage per ridurre i costi. Il namespace singolo consente di accedere ai dati tramite una singola chiamata, indipendentemente dalla posizione geografica dello storage StorageGRID. I clienti possono implementare e gestire più istanze di StorageGRID tra i data center e nell'infrastruttura cloud.</block>
  <block id="d0a72d49cbe69b32b6e889db2e1429c9" category="paragraph">Un sistema StorageGRID è composto da nodi eterogenei, ridondanti e distribuiti a livello globale che possono essere integrati con le applicazioni client esistenti e di prossima generazione.</block>
  <block id="5680b078511221b1538af544a52a477e" category="paragraph"><block ref="5680b078511221b1538af544a52a477e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4077a77339f68c64c1e50f20961e468f" category="paragraph">IDC MarketScape ha recentemente nominato NetApp come leader nell'ultimo report, IDC MarketScape: Worldwide Object-Based Storage 2019 Vendor Assessment. Con quasi 20 anni di implementazioni in produzione nei settori più esigenti, StorageGRID è leader riconosciuto nel campo dei dati non strutturati.</block>
  <block id="a2146cca70b8afc5500f690b84357813" category="paragraph">Con StorageGRID, puoi ottenere i seguenti risultati:</block>
  <block id="0d29e2d2977160f50fc59018cd24d6ee" category="list-text">Implementa più istanze di StorageGRID per accedere ai dati da qualsiasi posizione tra i data center e il cloud attraverso un singolo namespace che si adatta facilmente a centinaia di petabyte.</block>
  <block id="770d656b5273d26168b61ba6ede38cfd" category="list-text">Flessibilità per l'implementazione e la gestione centralizzata tra le infrastrutture.</block>
  <block id="5926e6b363cbfe237a46219c7f92fe02" category="list-text">Durata senza pari grazie alla durata di quindici nove anni che sfrutta la codifica Erasure (EC) a più livelli.</block>
  <block id="77a48d0beb74ba75ef47c32ed1115a01" category="list-text">Abilita funzionalità multi-cloud ibride con integrazioni validate in Amazon S3 Glacier e Azure Blob.</block>
  <block id="ffa0a5ca524779112b69eb9e53aacf31" category="list-text">Rispettare gli obblighi normativi e facilitare la conformità attraverso la conservazione dei dati a prova di manomissione, senza API proprietarie o lock-in del vendor.</block>
  <block id="6e9d67cdb6f2e5564ae28e0389bcc679" category="inline-link">Pagina principale di NetApp StorageGRID</block>
  <block id="206008935f811359069d9b35cb5c874e" category="paragraph">Per ulteriori informazioni su come StorageGRID può aiutarti a risolvere i problemi di gestione dei dati non strutturati più complessi, consulta la<block ref="56ef38793a035acc851dabaa0c795287" category="inline-link-rx"></block>.</block>
  <block id="04bfb82e5f80fda36ff56ad540caaa63" category="section-title">A proposito di Splunk Enterprise</block>
  <block id="a643f0cfa3f1b40b8f79f3609f0aa84f" category="paragraph">Splunk Enterprise è una piattaforma per trasformare i dati in attività. I dati generati da varie fonti, come file di log, siti Web, dispositivi, sensori e applicazioni, vengono inviati e analizzati da Splunk Indexers, consentendo di ricavare informazioni complete dai dati. Potrebbe identificare le violazioni dei dati, evidenziare le tendenze dei clienti e dei prodotti, trovare opportunità per ottimizzare l'infrastruttura o creare informazioni utili in una vasta gamma di casi di utilizzo.</block>
  <block id="6118f726dd6c9b9e82e01638e958e5c8" category="section-title">A proposito di Splunk SmartStore</block>
  <block id="9ce6098334cce9db7edb3314ee645a2e" category="paragraph">Splunk SmartStore espande i vantaggi dell'architettura Splunk semplificando al contempo la sua capacità di scalare in modo conveniente. Il disaccoppiamento delle risorse di calcolo e storage comporta nodi indicizzatori ottimizzati per i/o con esigenze di storage significativamente ridotte, in quanto memorizzano solo un sottoinsieme di dati come cache. Non è necessario aggiungere ulteriore calcolo o storage quando è necessaria una sola di queste risorse, il che consente di ottenere risparmi significativi sui costi. È possibile utilizzare uno storage a oggetti basato su S3 conveniente e facilmente scalabile, che semplifica ulteriormente l'ambiente, riduce i costi e consente di mantenere un set di dati più esteso.</block>
  <block id="fde880b7e5def5ccc70e3e98ba15b442" category="paragraph">Splunk SmartStore offre un valore significativo alle organizzazioni, tra cui:</block>
  <block id="16fc7d5921f88ca7b8070e1913a6fb74" category="list-text">Riduzione dei costi di storage grazie allo spostamento dei dati warm in uno storage a oggetti S3 ottimizzato per i costi</block>
  <block id="9ce78e75b3ecebf85fe0d43f2cf80505" category="list-text">Scalabilità perfetta disaccoppiando storage e calcolo</block>
  <block id="1dd6f3d1f3ac2a43dc2e69386b1b15ca" category="list-text">Semplificare la business continuity sfruttando lo storage resiliente nativo del cloud</block>
  <block id="8db09dd9a1d2508a1e11189bfe47d246" category="inline-link-macro">Avanti: Vantaggi di questa soluzione.</block>
  <block id="0032cf08702e09af53bf601b3f83e323" category="paragraph"><block ref="0032cf08702e09af53bf601b3f83e323" category="inline-link-macro-rx"></block></block>
  <block id="43fc68a998702bc80e46c46de6c28621" category="doc">Script Python per ogni caso di utilizzo principale</block>
  <block id="6af3c467ec5223400f1d1e91f69cb12b" category="inline-link-macro">Precedente: Soluzione di cloud ibrido.</block>
  <block id="45d040833437bf9dd9f64d4dfa4981c4" category="paragraph"><block ref="45d040833437bf9dd9f64d4dfa4981c4" category="inline-link-macro-rx"></block></block>
  <block id="cfb5f1c014066f18d7979fa1d35a934d" category="paragraph">I tre script Python riportati di seguito corrispondono ai tre principali casi di utilizzo testati. Il primo è<block ref="b01d528ada3b5a6e0e9094642b727562" prefix=" " category="inline-code"></block>.</block>
  <block id="d3abf6f12cafa2cc1b795b31cd547c75" category="paragraph">Il secondo script è<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block>.</block>
  <block id="6e9120b39f924b2eed528e3bcdd009ac" category="paragraph">Il terzo script è<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block>.</block>
  <block id="be0ba1bf6a99c201834567c4d58fc40e" category="paragraph"><block ref="be0ba1bf6a99c201834567c4d58fc40e" category="inline-link-macro-rx"></block></block>
  <block id="727c63651b565bca2eb7d8a48e0fefd9" category="summary">Questa sezione riassume questo documento relativo alle soluzioni di storage NetApp per Apache Spark.</block>
  <block id="265d8449fb55764666dffa0a87f0c3fc" category="inline-link-macro">Precedente: Script Python per ogni caso di utilizzo principale.</block>
  <block id="7fc4ed21f18b26424c49779d455d4f51" category="paragraph"><block ref="7fc4ed21f18b26424c49779d455d4f51" category="inline-link-macro-rx"></block></block>
  <block id="900200cfc3f2577215c327d16f34840a" category="paragraph">In questo documento, discutiamo dell'architettura di Apache Spark, dei casi di utilizzo dei clienti e del portfolio di storage NetApp in relazione a big data, analytics moderni e ai, ML e DL. Nei nostri test di convalida delle performance basati su strumenti di benchmarking standard di settore e sulla domanda dei clienti, le soluzioni NetApp Spark hanno dimostrato performance superiori rispetto ai sistemi Hadoop nativi. Una combinazione dei casi di utilizzo dei clienti e dei risultati delle performance presentati in questo report può aiutarti a scegliere una soluzione Spark appropriata per la tua implementazione.</block>
  <block id="7772bd81086ccf1a440798ec74c6c795" category="paragraph"><block ref="7772bd81086ccf1a440798ec74c6c795" category="inline-link-macro-rx"></block></block>
  <block id="dce4db89f623baec1071c07c6784f4b1" category="summary">Un moderno data center aziendale è un cloud ibrido che connette più ambienti di infrastruttura distribuita attraverso un piano di gestione continua dei dati con un modello operativo coerente, on-premise e/o in più cloud pubblici. Per ottenere il massimo da un cloud ibrido, devi essere in grado di spostare perfettamente i dati tra ambienti on-premise e multi-cloud senza la necessità di conversioni di dati o refactoring delle applicazioni.</block>
  <block id="e27d277adca53504bfe79d8a5e7c2084" category="doc">Soluzione di cloud ibrido</block>
  <block id="bbbb8f5ce180b59d7cf72bfd9ff78bf6" category="inline-link-macro">Precedente: Risultati del test.</block>
  <block id="e8be57661ebf09e93d86ee83e74adbc3" category="paragraph"><block ref="e8be57661ebf09e93d86ee83e74adbc3" category="inline-link-macro-rx"></block></block>
  <block id="9cf7905c60934870d86a546076b272e4" category="paragraph">I clienti hanno indicato di iniziare il loro percorso nel cloud ibrido spostando lo storage secondario nel cloud per casi di utilizzo come la protezione dei dati o spostando meno carichi di lavoro business-critical come lo sviluppo delle applicazioni e DevOps nel cloud. Passano quindi a carichi di lavoro più critici. Hosting di contenuti e web, sviluppo di applicazioni e DevOps, database, analytics e applicazioni containerizzate sono tra i carichi di lavoro di cloud ibrido più diffusi. La complessità, i costi e i rischi dei progetti ai aziendali hanno storicamente ostacolato l'adozione dell'ai dalla fase sperimentale alla produzione.</block>
  <block id="38ddba87301d0e027f020fd24b8a5ade" category="paragraph">Con una soluzione di cloud ibrido NetApp, i clienti possono beneficiare di strumenti integrati per la sicurezza, la governance dei dati e la conformità con un unico pannello di controllo per la gestione dei dati e del workflow in ambienti distribuiti, ottimizzando al contempo il costo totale di proprietà in base al consumo. La figura seguente è una soluzione di esempio di un partner di servizi cloud che ha il compito di fornire connettività multi-cloud per i dati di analisi dei big data dei clienti.</block>
  <block id="10ebc90118ac5ab60f289bf34b75d978" category="inline-image-macro">Esempio di soluzione di un partner di servizi cloud.</block>
  <block id="ad71e01672e98de491e72d22ba403059" category="paragraph"><block ref="ad71e01672e98de491e72d22ba403059" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207f35bf95973770d860aeee0abe32a2" category="paragraph">In questo scenario, i dati IoT ricevuti in AWS da diverse origini vengono memorizzati in una posizione centrale in NetApp Private Storage (NPS). Lo storage NPS è connesso ai cluster Spark o Hadoop situati in AWS e Azure, consentendo l'esecuzione di applicazioni di big data analytics in più cloud che accedono agli stessi dati. I requisiti e le sfide principali per questo caso di utilizzo includono:</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">I clienti vogliono eseguire lavori di analisi sugli stessi dati utilizzando più cloud.</block>
  <block id="bf871745f8e53cd8c13aca4c2ae67522" category="list-text">I dati devono essere ricevuti da fonti diverse, ad esempio ambienti on-premise e cloud, attraverso diversi sensori e hub.</block>
  <block id="cb1726ae6d68d40c3bc9861c2b26a1a0" category="list-text">La soluzione deve essere efficiente e conveniente.</block>
  <block id="6dc7db5e9c1da14f7d61e2a7f4428219" category="list-text">La sfida principale è quella di creare una soluzione conveniente ed efficiente in grado di offrire servizi di analisi ibridi tra diversi ambienti on-premise e cloud.</block>
  <block id="cc4772ffa75dd53e0fb87df4b15528cd" category="paragraph">La nostra soluzione per la protezione dei dati e la connettività multicloud risolve il problema di avere applicazioni di analisi del cloud su più hyperscaler. Come mostrato nella figura precedente, i dati provenienti dai sensori vengono trasmessi e acquisiti nel cluster AWS Spark tramite Kafka. I dati vengono memorizzati in una condivisione NFS residente in NPS, che si trova all'esterno del cloud provider all'interno di un data center Equinix.</block>
  <block id="88971c24837a2734fa58ba8805336328" category="paragraph">Poiché NetApp NPS è connesso ad Amazon AWS e Microsoft Azure rispettivamente tramite Direct Connect e Express Route Connections, i clienti possono sfruttare il modulo di analisi in-place per accedere ai dati da entrambi i cluster di analisi Amazon e AWS. Di conseguenza, poiché sia lo storage on-premise che NPS esegue il software ONTAP,<block ref="fcca72a796080b3a5e2b7b1394bd00ad" category="inline-link-rx"></block> Può eseguire il mirroring dei dati NPS nel cluster on-premise, fornendo analisi del cloud ibrido su cloud on-premise e multipli.</block>
  <block id="6e53d162faf0b7bc51e81ca980f05f86" category="paragraph">Per ottenere le migliori performance, NetApp consiglia di utilizzare più interfacce di rete e connessioni dirette o percorsi espressi per accedere ai dati dalle istanze cloud. Abbiamo altre soluzioni di data mover, tra cui<block ref="0adb843c17d646acd72646e9688dde2b" category="inline-link-rx"></block> e.<block ref="4c1cade27212922d2ee7525beab5b4a9" category="inline-link-rx"></block> Per aiutare i clienti a creare cluster Spark di cloud ibrido basati su applicazioni, sicuri e convenienti.</block>
  <block id="1e73bec6e2f584224cb16d4550039696" category="inline-link-macro">Segue: Script Python per ogni caso di utilizzo principale.</block>
  <block id="cf6b62d678290b47b2c7abc2f11eb6d5" category="paragraph"><block ref="cf6b62d678290b47b2c7abc2f11eb6d5" category="inline-link-macro-rx"></block></block>
  <block id="9fa345c6a2f967ec80e8b940a9d2a1c3" category="summary">Poiché i clienti si rendono conto della potenza e della facilità di utilizzo dell'analisi dei dati Splunk, desiderano indicizzare una quantità di dati in continua crescita. Man mano che la quantità di dati cresce, anche l'infrastruttura di calcolo e storage necessaria per il servizio IT.</block>
  <block id="f9a3e09b74e61e83c0352f2953dcdc87" category="doc">Tiering intelligente e risparmi sui costi</block>
  <block id="7bcf31269131a9e7ab4d163f239fc4e5" category="inline-link-macro">Precedente: Vantaggi di questa soluzione.</block>
  <block id="b27eab207fc06febce259cb1c08777a3" category="paragraph"><block ref="b27eab207fc06febce259cb1c08777a3" category="inline-link-macro-rx"></block></block>
  <block id="e09913e41f1a0082ec190482abfeff57" category="paragraph">Poiché i clienti si rendono conto della potenza e della facilità di utilizzo dell'analisi dei dati Splunk, desiderano indicizzare una quantità di dati in continua crescita. Man mano che la quantità di dati cresce, anche l'infrastruttura di calcolo e storage necessaria per il servizio IT. Dato che i dati meno recenti vengono referenziati meno frequentemente, il commit della stessa quantità di risorse di calcolo e il consumo di costoso storage primario diventano sempre più inefficienti. Per operare su larga scala, i clienti traggono vantaggio dal passaggio dei dati Warm a un Tier più conveniente, liberando il calcolo e lo storage primario per i dati hot.</block>
  <block id="f7300ec91634b8cd535c45fd11ee503f" category="paragraph">Splunk SmartStore con StorageGRID offre alle organizzazioni una soluzione scalabile, performante e conveniente. Poiché SmartStore è consapevole dei dati, valuta automaticamente i modelli di accesso ai dati per determinare quali dati devono essere accessibili per l'analisi in tempo reale (dati hot) e quali dati devono risiedere in uno storage a lungo termine più economico (dati warm). SmartStore utilizza l'API AWS S3 standard di settore in modo dinamico e intelligente, collocando i dati nello storage S3 fornito da StorageGRID. L'architettura flessibile scale-out di StorageGRID consente al Tier di dati Warm di crescere in modo conveniente in base alle esigenze. L'architettura basata su nodo di StorageGRID garantisce che i requisiti di performance e costi siano soddisfatti in modo ottimale.</block>
  <block id="d75fb5ef86bb0625c22c38dd2229c627" category="paragraph">L'immagine seguente illustra il tiering Splunk e StorageGRID.</block>
  <block id="821f09f0a5870b1dd3ee40e65f17b546" category="paragraph"><block ref="821f09f0a5870b1dd3ee40e65f17b546" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6821c40fa59a17fa0f78dbb9e556be5" category="paragraph">La combinazione leader del settore di Splunk SmartStore e NetApp StorageGRID offre i vantaggi dell'architettura disaccoppiata attraverso una soluzione full-stack.</block>
  <block id="32c614a5724d73faf7f06f754330bbac" category="paragraph"><block ref="32c614a5724d73faf7f06f754330bbac" category="inline-link-macro-rx"></block></block>
  <block id="331c0d2ba7a09b3ae7f6fac4652625da" category="summary">Questa pagina descrive le Best practice per migliorare le performance di questa soluzione.</block>
  <block id="69cefd131c612b28f058caddd20f5cac" category="doc">Linee guida sulle Best practice per le performance</block>
  <block id="25075404ed18180817b5ff523b98b3ea" category="inline-link-macro">Precedente: Test delle performance con generatore di carichi di lavoro producete-consumate.</block>
  <block id="78f6cc0a5eeea34ea4a6b6d750751008" category="paragraph"><block ref="78f6cc0a5eeea34ea4a6b6d750751008" category="inline-link-macro-rx"></block></block>
  <block id="21414169b395738292b2ac2fd8ca50a9" category="list-text">Per ONTAP, quando possibile, utilizzare una dimensione GET &gt;=1 MB.</block>
  <block id="ce2e9b8aaceb2d2993c90188d874af95" category="list-text">In aumento<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> e.<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> poll<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> On broker Node consente di trasferire l'attività di tiering aumentata al Tier S3. Questi risultati sono con<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> e.<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> impostare su 32.</block>
  <block id="1a48e01d01924d18e32943982eb6d924" category="list-text">I bucket S3 devono essere mirati a otto componenti per aggregato membro.</block>
  <block id="b5a9dc3c7ec54467d103e00eaa0efb21" category="list-text">I collegamenti Ethernet che guidano il traffico S3 devono utilizzare un MTU di 9k, quando possibile, sia sullo storage che sul client.</block>
  <block id="9a2dcec18734a6b09898eef44edd5f9a" category="paragraph"><block ref="9a2dcec18734a6b09898eef44edd5f9a" category="inline-link-macro-rx"></block></block>
  <block id="af7ba099603ccd4070a5102166f2c998" category="summary">In base a questa convalida, i data scientist e i tecnici possono accedere ai dati NFS dai notebook AWS SageMaker Jupyter tramite i bucket S3 di NetApp Cloud Volumes ONTAP. Questo approccio consente un facile accesso e condivisione degli stessi dati da NFS e S3 senza la necessità di software aggiuntivo.</block>
  <block id="4fb1e7ca4e76c4bb7a3052dc8d47879b" category="inline-link-macro">Precedente: Dualità dei dati per data scientist e altre applicazioni.</block>
  <block id="51218734514eb89f2125e2ee2c444e31" category="paragraph"><block ref="51218734514eb89f2125e2ee2c444e31" category="inline-link-macro-rx"></block></block>
  <block id="8053f00cf5e08f449b7cafe189c73a39" category="list-text">Classificazione del testo con SageMaker BlazingText</block>
  <block id="7fba377195a6600e8ac2b2d5a433e7d3" category="inline-link"><block ref="7fba377195a6600e8ac2b2d5a433e7d3" category="inline-link-rx"></block></block>
  <block id="d8908a1e1cf55570441dd5a42baadacc" category="paragraph"><block ref="d8908a1e1cf55570441dd5a42baadacc" category="inline-link-rx"></block></block>
  <block id="d6667429b7c60bcbf5e5d593e91d6cae" category="list-text">Supporto della versione di ONTAP per lo storage a oggetti S3</block>
  <block id="91ef54d96688b56bf968f57803df6675" category="inline-link"><block ref="91ef54d96688b56bf968f57803df6675" category="inline-link-rx"></block></block>
  <block id="53a581d907d105a589be9419e91b16fa" category="paragraph"><block ref="53a581d907d105a589be9419e91b16fa" category="inline-link-rx"></block></block>
  <block id="904837c9cf9bc52a96ce17d051fddec9" category="cell">Aprile 2023</block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">Il data fabric basato su NetApp semplifica e integra la gestione dei dati in ambienti cloud e on-premise per accelerare la trasformazione digitale. Il data fabric basato su NetApp offre servizi e applicazioni per la gestione dei dati coerenti e integrati (building block) per visibilità e approfondimenti dei dati, accesso e controllo dei dati, protezione e sicurezza dei dati.</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">Data fabric basato su NetApp per l'architettura dei big data</block>
  <block id="32e0d2b797e6706a73e8146d103572c7" category="inline-link-macro">Precedente: Panoramica della soluzione.</block>
  <block id="45af7a946606481f9e2b5f0434aa0484" category="paragraph"><block ref="45af7a946606481f9e2b5f0434aa0484" category="inline-link-macro-rx"></block></block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">Il data fabric basato su NetApp semplifica e integra la gestione dei dati in ambienti cloud e on-premise per accelerare la trasformazione digitale.</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">Il data fabric basato su NetApp offre servizi e applicazioni per la gestione dei dati coerenti e integrati (building block) per visibilità e approfondimenti dei dati, accesso e controllo dei dati, protezione e sicurezza dei dati, come mostrato nella figura seguente.</block>
  <block id="22313f8779f9135c9b421ac0d4b320fb" category="paragraph"><block ref="22313f8779f9135c9b421ac0d4b320fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">Casi di utilizzo comprovati per i clienti del data fabric</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">Il data fabric basato su NetApp offre ai clienti i seguenti nove casi di utilizzo comprovati:</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">Accelera i carichi di lavoro di analisi</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">Accelera la trasformazione DevOps</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">Costruire un'infrastruttura di cloud hosting</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">Integra i servizi dati cloud</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">Proteggere e proteggere i dati</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">Ottimizza i dati non strutturati</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">Ottieni efficienze nel data center</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">Offri informazioni e controllo sui dati</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">Semplifica e automatizza</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">Questo documento tratta due dei nove casi di utilizzo (insieme alle relative soluzioni):</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">Accesso diretto NetApp NFS</block>
  <block id="233060aa11b5715000c000e94576cca9" category="paragraph">L'accesso diretto NetApp NFS (precedentemente noto come NetApp in-place Analytics Module) (mostrato nella figura seguente) consente ai clienti di eseguire lavori di analisi dei big data sui dati NFSv3 o NFSv4 esistenti o nuovi senza spostare o copiare i dati. Impedisce più copie di dati ed elimina la necessità di sincronizzare i dati con un'origine. Ad esempio, nel settore finanziario, lo spostamento dei dati da un luogo all'altro deve soddisfare obblighi legali, il che non è un compito facile. In questo scenario, l'accesso diretto NetApp NFS analizza i dati finanziari dalla posizione originale. Un altro vantaggio chiave è che l'utilizzo dell'accesso diretto NetApp NFS semplifica la protezione dei dati Hadoop utilizzando comandi Hadoop nativi e abilita i flussi di lavoro per la protezione dei dati sfruttando il ricco portfolio di gestione dei dati di NetApp.</block>
  <block id="96e1e6bac181280c42ba5de56a8ef4c2" category="paragraph"><block ref="96e1e6bac181280c42ba5de56a8ef4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">L'accesso diretto NetApp NFS offre due tipi di opzioni di implementazione per i cluster Hadoop/Spark:</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">Per impostazione predefinita, i cluster Hadoop/Spark utilizzano Hadoop Distributed file System (HDFS) per lo storage dei dati e il file system predefinito. L'accesso diretto NetApp NFS può sostituire l'HDFS predefinito con lo storage NFS come file system predefinito, consentendo operazioni di analisi dirette sui dati NFS.</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">In un'altra opzione di implementazione, l'accesso diretto NetApp NFS supporta la configurazione di NFS come storage aggiuntivo insieme a HDFS in un singolo cluster Hadoop/Spark. In questo caso, il cliente può condividere i dati attraverso le esportazioni NFS e accedervi dallo stesso cluster insieme ai dati HDFS.</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">I vantaggi principali dell'utilizzo dell'accesso diretto NetApp NFS includono:</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">Analizza i dati dalla posizione corrente, impedendo il dispendio di tempo e performance dello spostamento dei dati di analisi in un'infrastruttura Hadoop come HDFS.</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">Riduce il numero di repliche da tre a uno.</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">Consente agli utenti di separare il calcolo e lo storage per scalare in modo indipendente.</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">Offre protezione dei dati aziendali sfruttando le funzionalità di gestione dei dati avanzate di ONTAP.</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">È certificato con la piattaforma dati Hortonworks.</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">Consente implementazioni di analisi dei dati ibride.</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">Riduce i tempi di backup sfruttando la funzionalità multithread dinamica.</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">Elementi di base per i big data</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">Il data fabric basato su NetApp integra i servizi e le applicazioni di gestione dei dati (building block) per l'accesso, il controllo, la protezione e la sicurezza dei dati, come mostrato nella figura seguente.</block>
  <block id="f0a67f0f8f389fb239ce107f693a7e68" category="paragraph"><block ref="f0a67f0f8f389fb239ce107f693a7e68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">Gli elementi di base della figura precedente includono:</block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">*Accesso diretto NetApp NFS.* offre i più recenti cluster Hadoop e Spark con accesso diretto ai volumi NetApp NFS senza requisiti aggiuntivi di software o driver.</block>
  <block id="2867a490011894512662b9423698d0e0" category="list-text">*NetApp Cloud Volumes ONTAP e servizi di volume cloud.* storage connesso definito tramite software basato su ONTAP eseguito in AWS (Amazon Web Services) o Azure NetApp Files (ANF) nei servizi cloud Microsoft Azure.</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">*Tecnologia NetApp SnapMirror*. Offre funzionalità di protezione dei dati tra istanze cloud on-premise e ONTAP o NPS.</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">*Cloud service provider.* questi provider includono AWS, Microsoft Azure, Google Cloud e IBM Cloud.</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">*PaaS.* servizi di analisi basati sul cloud come Amazon Elastic MapReduce (EMR) e Databricks in AWS, Microsoft Azure HDInsight e Azure Databricks.</block>
  <block id="35848dde21e4a5f344385ead6dec9a43" category="inline-link-macro">Pagina successiva: Protezione dei dati Hadoop e NetApp.</block>
  <block id="149584f581a09d835c88f233c514412e" category="paragraph"><block ref="149584f581a09d835c88f233c514412e" category="inline-link-macro-rx"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">Questa sezione descrive l'hardware e il software utilizzati per la certificazione Confluent. Queste informazioni sono applicabili all'implementazione di Kafka con lo storage NetApp.</block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="doc">Dettagli sull'architettura della soluzione</block>
  <block id="40328f8a932f8ae1964c73c1f2eca76b" category="paragraph"><block ref="40328f8a932f8ae1964c73c1f2eca76b" category="inline-link-macro-rx"></block></block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">Questa sezione descrive l'hardware e il software utilizzati per la verifica confluente. Queste informazioni sono applicabili all'implementazione della piattaforma confluente con lo storage NetApp. La seguente tabella illustra l'architettura della soluzione testata e i componenti di base.</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Confluent Kafka versione 6.2</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">Tre zookeeper</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">Cinque server di broker</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">Cinque server di strumenti</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">Una Grafana</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">Un centro di controllo</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">Linux (Ubuntu 18.04)</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">Tutti i server</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">NetApp StorageGRID per lo storage su più livelli</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">Software StorageGRID</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">1 SG1000 (bilanciamento del carico)</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">4 x SGF6024</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">4 SSD 24 x 800</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">Protocollo S3</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">4 x 100 GbE (connettività di rete tra istanze di broker e StorageGRID)</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">15 server Fujitsu PRIMERGY RX2540</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">Ciascuno dotato di: * 2 CPU, 16 core fisici totali * Intel Xeon * 256 GB di memoria fisica * 100 GbE a doppia porta</block>
  <block id="b320345f652aacf7148c76dff24e2f68" category="inline-link-macro">Avanti: Panoramica sulla tecnologia.</block>
  <block id="c88aa001e26103d0ebe4894b3c9ab9f5" category="paragraph"><block ref="c88aa001e26103d0ebe4894b3c9ab9f5" category="inline-link-macro-rx"></block></block>
  <block id="39e4c49e9af8047395aa4031e5c5f3a9" category="summary">Questa pagina descrive i componenti utilizzati per completare questa soluzione, tra cui NetApp StorageGRID, Splunk Enterprise e Splunk SmartStore.</block>
  <block id="0f641483b3a1a8cfcb4b0ad971a2d016" category="inline-link-macro">Precedente: Tiering intelligente e risparmi sui costi.</block>
  <block id="b1320bfc03a3d1edb16e0f717149a713" category="paragraph"><block ref="b1320bfc03a3d1edb16e0f717149a713" category="inline-link-macro-rx"></block></block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="section-title">NetApp StorageGRID</block>
  <block id="5ab9d0d9b506bd4b5bf294baccd4ef0a" category="paragraph">NetApp StorageGRID è una piattaforma di storage a oggetti dalle performance elevate e conveniente. Offre una gestione dei dati globale intelligente e basata su policy utilizzando un'architettura grid distribuita e basata su nodi. Semplifica la gestione di petabyte di dati non strutturati e miliardi di oggetti attraverso il suo onnipresente namespace globale a oggetti combinato con sofisticate funzionalità di gestione dei dati. L'accesso a oggetti a chiamata singola si estende tra i siti e semplifica le architetture ad alta disponibilità garantendo al contempo un accesso continuo agli oggetti indipendentemente dalle interruzioni del sito o dell'infrastruttura.</block>
  <block id="d67c579ad5ceca0ec4f8fe6a86f203cf" category="paragraph">La multi-tenancy consente di gestire in modo sicuro più applicazioni dati non strutturate e cloud all'interno dello stesso grid, aumentando il ROI e i casi di utilizzo per StorageGRID. È possibile creare più livelli di servizio con policy del ciclo di vita degli oggetti basate sui metadati, ottimizzando durata, protezione, performance e località in più aree geografiche. Gli utenti possono regolare le policy e riallineare il panorama dei dati senza interruzioni in base ai cambiamenti dei requisiti.</block>
  <block id="0d2b0fb2b312d872db772396e149b541" category="paragraph">SmartStore sfrutta StorageGRID come Tier di storage remoto e consente ai clienti di implementare più siti distribuiti geograficamente per una disponibilità e una durata affidabili, presentati come un singolo namespace a oggetti. In questo modo, Splunk SmartStore può sfruttare le performance elevate, la capacità densa e la capacità di StorageGRID di scalare fino a centinaia di nodi in più siti fisici utilizzando un singolo URL per interagire con gli oggetti. Questo singolo URL consente inoltre di espandere, aggiornare e riparare lo storage senza interruzioni, anche oltre un singolo sito. L'esclusivo motore di policy per la gestione dei dati di StorageGRID offre livelli ottimizzati di performance, durata e rispetto dei requisiti delle località dei dati.</block>
  <block id="5dba46907e72d7502229329d2aafd8a2" category="section-title">Splunk Enterprise</block>
  <block id="f9ed96cf2d028d3cfa9c658c6ec5ae72" category="paragraph">Splunk, leader nella raccolta e nell'analisi dei dati generati dalle macchine, aiuta a semplificare e modernizzare L'IT attraverso le sue funzionalità di analisi operativa. Si espande anche in analytics di business, sicurezza e casi di utilizzo IoT. Lo storage è un elemento fondamentale per una corretta implementazione del software Splunk.</block>
  <block id="1812fb837f2c63812e909b4457b0fa17" category="paragraph">I dati generati dalle macchine sono il tipo di big data in più rapida crescita. Il formato è imprevedibile e proviene da diverse fonti, spesso a velocità elevate e in grandi volumi. Queste caratteristiche del carico di lavoro sono spesso indicate come scarico digitale. Splunk SmartStore aiuta a comprendere questi dati e fornisce il tiering intelligente dei dati per il posizionamento ottimizzato dei dati hot e warm sul Tier di storage più conveniente.</block>
  <block id="fb289ff7f529e1f2477823c61e7d9c8f" category="section-title">Splunk SmartStore</block>
  <block id="bd069a1be23f237559be08ae79727806" category="paragraph">Splunk SmartStore è una funzionalità di indicizzazione che utilizza lo storage a oggetti (noto anche come storage remoto o Tier di storage remoto) come StorageGRID per memorizzare i dati warm utilizzando il protocollo S3.</block>
  <block id="9e5e9e455aa469c6579c4cde82cf69fc" category="paragraph">Con l'aumentare del volume di dati di un'implementazione, la domanda di storage supera in genere la domanda di risorse di computer. SmartStore consente di gestire le risorse di calcolo e storage dell'indicizzatore in modo conveniente scalando separatamente calcolo e storage.</block>
  <block id="1ab3873a2fa155a27933ac3e2b4ae709" category="paragraph">SmartStore introduce un Tier di storage remoto, utilizzando il protocollo S3, e un gestore della cache. Queste funzionalità consentono ai dati di risiedere localmente sugli indicizzatori o sullo storage remoto. Il gestore della cache, che risiede sull'indicizzatore, gestisce lo spostamento dei dati tra l'indicizzatore e il Tier di storage remoto. I dati vengono memorizzati nei bucket (hot e warm) insieme ai metadati del bucket.</block>
  <block id="85a6e51e1b2fd3e4be531f269e108f39" category="paragraph">Con SmartStore, puoi ridurre al minimo l'impatto dello storage dell'indicizzatore e scegliere risorse di calcolo ottimizzate per i/o perché la maggior parte dei dati risiede nel Tier di storage remoto. L'indicizzatore mantiene una cache locale, che rappresenta la quantità minima di dati necessaria per restituire i risultati richiesti e previsti. La cache locale contiene bucket hot, copie di bucket warm che partecipano a ricerche attive o recenti e metadati bucket.</block>
  <block id="8cc78103debf2dcfe53620b96565dad4" category="paragraph">Splunk SmartStore con StorageGRID consente ai clienti di scalare in modo incrementale l'ambiente con uno storage remoto dalle performance elevate e conveniente, fornendo al contempo un elevato grado di flessibilità alla soluzione globale. Ciò consente ai clienti di aggiungere qualsiasi componente (hot storage e/o storage S3 a caldo) in qualsiasi quantità in qualsiasi momento, sia che abbiano bisogno di più indicizzatori, di modificare la conservazione dei dati o di aumentare il tasso di acquisizione senza interruzioni.</block>
  <block id="5cb48860c8dadcd442724a4122e031bd" category="inline-link-macro">Pagina successiva: Funzionalità StorageGRID flessibili per Splunk SmartStore.</block>
  <block id="9a206b91ebbd6c75f73fba261d1eed1c" category="paragraph"><block ref="9a206b91ebbd6c75f73fba261d1eed1c" category="inline-link-macro-rx"></block></block>
  <block id="bd8f37587e7778e9d19d350dd4bd6d3a" category="summary">In questa sezione vengono descritti gli utenti che potrebbero essere interessati al contenuto di questa soluzione.</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="doc">Pubblico di riferimento</block>
  <block id="c1416f7786ac2faa1173c4336b6eb03e" category="paragraph"><block ref="c1416f7786ac2faa1173c4336b6eb03e" category="inline-link-macro-rx"></block></block>
  <block id="49997701037fef2c24b57a2e7186d0ab" category="paragraph">Il mondo dell'analytics e della scienza dei dati tocca diverse discipline nell'IT e nel business:</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">Il data scientist ha bisogno della flessibilità necessaria per utilizzare i propri strumenti e le librerie preferite.</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">Il data engineer deve sapere come i dati scorrono e dove risiedono.</block>
  <block id="529ac4605b034914d0e8b489a81e45e0" category="list-text">Un tecnico DevOps ha bisogno dei tool per integrare le nuove applicazioni ai e ML nelle pipeline ci e CD.</block>
  <block id="090e55ccd8633a454f9d471ca3ed004d" category="list-text">Gli amministratori e gli architetti del cloud devono essere in grado di configurare e gestire le risorse del cloud ibrido.</block>
  <block id="3cb782c6019ddcbb4e7f6bf8ae154d40" category="list-text">Gli utenti aziendali desiderano avere accesso alle applicazioni di analisi, ai, ML e DL.</block>
  <block id="3dfd24951a51ec1661b0294f59bea86e" category="paragraph">In questo report tecnico, descriviamo come NetApp AFF, e-Series, StorageGRID, NFS direct access, Apache Spark, Horovod e keras aiutano ciascuno di questi ruoli a portare valore al business.</block>
  <block id="1f3c9b64432ff113f81d3897c98ed74b" category="inline-link-macro">Avanti: Tecnologia della soluzione.</block>
  <block id="fdd31e37014fd5b0f491f1d30b29c4c3" category="paragraph"><block ref="fdd31e37014fd5b0f491f1d30b29c4c3" category="inline-link-macro-rx"></block></block>
  <block id="404af9ebdf8554a92ea8d3dde06945b4" category="doc">TR-4623: NetApp e-Series E5700 e Splunk Enterprise</block>
  <block id="1dcb8fb2d6ad519f4a7ecd244f9c7c76" category="paragraph">Mitch Blackburn, NetApp</block>
  <block id="8c121c8c1e758ef244a52184e2d48c66" category="paragraph">TR-4623 descrive l'architettura integrata del design NetApp e-Series e Splunk. Ottimizzato per bilanciamento dello storage dei nodi, affidabilità, performance, capacità dello storage e densità, Questa progettazione utilizza il modello di nodo Splunk Clustered Index, con una maggiore scalabilità e un TCO inferiore. Il disaccoppiamento dello storage dal calcolo offre la possibilità di scalare ciascuno separatamente, risparmiando il costo dell'overprovisioning uno o l'altro. Inoltre, questo documento riassume i risultati dei test delle performance ottenuti da uno strumento di simulazione degli eventi del log della macchina Splunk.</block>
  <block id="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="paragraph"><block ref="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="inline-link-macro-rx"></block></block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">In questo caso di utilizzo, il requisito del cliente è quello di creare rapidamente ed efficientemente nuovi cluster Hadoop/Spark basati su un cluster Hadoop esistente contenente una grande quantità di dati di analisi per DevTest e scopi di reporting nello stesso data center e in sedi remote.</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="doc">Caso d'utilizzo 3: Abilitare DevTest sui dati Hadoop esistenti</block>
  <block id="aeab228f25b5fbe0b00f83117579246e" category="inline-link-macro">Precedente: Caso d'utilizzo 2 - Backup e disaster recovery dal cloud all'on-premise.</block>
  <block id="cf44ed74ea7e07a8e4478e43d9537e07" category="paragraph"><block ref="cf44ed74ea7e07a8e4478e43d9537e07" category="inline-link-macro-rx"></block></block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">Scenario</block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">In questo scenario, i cluster Spark/Hadoop multipli sono costruiti da un'implementazione di data Lake Hadoop di grandi dimensioni on-premise e in ubicazioni di disaster recovery.</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="section-title">Requisiti e sfide</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">I requisiti e le sfide principali per questo caso di utilizzo includono:</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">Creare più cluster Hadoop per DevTest, QA o qualsiasi altro scopo che richieda l'accesso agli stessi dati di produzione. La sfida consiste nel clonare un cluster Hadoop molto grande più volte istantaneamente e in modo molto efficiente in termini di spazio.</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">Sincronizza i dati di Hadoop con DevTest e i team di reporting per l'efficienza operativa.</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">Distribuire i dati Hadoop utilizzando le stesse credenziali in produzione e nei nuovi cluster.</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">Utilizza policy pianificate per creare in modo efficiente cluster di QA senza influire sul cluster di produzione.</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">Soluzione</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">La tecnologia FlexClone viene utilizzata per rispondere ai requisiti appena descritti. La tecnologia FlexClone è la copia in lettura/scrittura di una copia Snapshot. Legge i dati dai dati di copia Snapshot padre e consuma solo spazio aggiuntivo per i blocchi nuovi/modificati. È veloce ed efficiente in termini di spazio.</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">Innanzitutto, è stata creata una copia Snapshot del cluster esistente utilizzando un gruppo di coerenza NetApp.</block>
  <block id="4b481b20e942087b64c5bb7b07d9dca9" category="paragraph">Copie Snapshot all'interno di NetApp System Manager o al prompt di amministrazione dello storage. Il gruppo di coerenza copie Snapshot sono copie Snapshot di gruppo coerenti con l'applicazione e il volume FlexClone viene creato in base alle copie Snapshot del gruppo di coerenza. Vale la pena ricordare che un volume FlexClone eredita la policy di esportazione NFS del volume padre. Una volta creata la copia Snapshot, è necessario installare un nuovo cluster Hadoop per DevTest e per la creazione di report, come illustrato nella figura seguente. Il modulo Analytics in-place accede al volume NFS clonato dal nuovo cluster Hadoop attraverso gli utenti del modulo Analytics in-place e l'autorizzazione di gruppo per i dati NFS.</block>
  <block id="4c490dfedbcc5a021b8a4c823e337d41" category="paragraph">Per ottenere un accesso corretto, il nuovo cluster deve avere lo stesso UID e GUID per gli utenti configurati nelle configurazioni di gruppo e utenti del modulo Analytics in-place.</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">Questa immagine mostra il cluster Hadoop per DevTest.</block>
  <block id="4157075925c8c1518cc71d1d0abab403" category="paragraph"><block ref="4157075925c8c1518cc71d1d0abab403" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e10ad11fd299ee6f161f17d772a78a48" category="inline-link-macro">Successivo: Caso d'utilizzo 4 - protezione dei dati e connettività multicloud.</block>
  <block id="8109e574f349ced8f667b9389c9189a4" category="paragraph"><block ref="8109e574f349ced8f667b9389c9189a4" category="inline-link-macro-rx"></block></block>
  <block id="cc2e9a005ff6b9d50a1fca9914e8eac0" category="summary">In questa sezione viene descritto il problema del ridenominazione sciocco e le modifiche necessarie al server NFS e al client NFS per risolvere il problema.</block>
  <block id="0d5e61a5d0c056718a15d6df7037a50c" category="doc">Soluzione NetApp per problemi di ridenominazione sciocco per carichi di lavoro da NFS a Kafka</block>
  <block id="5b7b60a56a6be9e9e9e8ff305a6e8ac6" category="paragraph"><block ref="5b7b60a56a6be9e9e9e8ff305a6e8ac6" category="inline-link-macro-rx"></block></block>
  <block id="e5ee0fc73f4f4f38e75acb2c0b2343be" category="paragraph">Kafka si basa sul presupposto che il file system sottostante sia conforme a POSIX, ad esempio XFS o Ext4. Il ribilanciamento delle risorse Kafka rimuove i file mentre l'applicazione li sta ancora utilizzando. Un file system conforme a POSIX consente di procedere con l'annullamento del collegamento. Tuttavia, il file viene rimosso solo dopo che tutti i riferimenti al file sono stati rimossi. Se il file system sottostante è collegato in rete, il client NFS intercetta le chiamate di sconnessione e gestisce il flusso di lavoro. Poiché il file non è collegato, il client NFS invia una richiesta di ridenominazione al server NFS e, all'ultima chiusura del file non collegato, effettua un'operazione di rimozione del file rinominato. Questo comportamento viene comunemente definito come ridenominazione sciocco di NFS ed è orchestrato dal client NFS.</block>
  <block id="f17efbdff90d69935a8d84a6215665a5" category="paragraph">Qualsiasi broker Kafka che utilizza lo storage da un server NFSv3 si verifica in problemi a causa di questo comportamento. Tuttavia, il protocollo NFSv4.x dispone di funzionalità per risolvere questo problema consentendo al server di assumersi la responsabilità dei file aperti e non collegati. I server NFS che supportano questa funzionalità opzionale comunicano la proprietà al client NFS al momento dell'apertura del file. Il client NFS interrompe quindi la gestione di unlink quando vengono aperte le porte in sospeso e consente al server di gestire il flusso. Sebbene la specifica NFSv4 fornisca linee guida per l'implementazione, fino ad ora non esistevano implementazioni server NFS note che supportassero questa funzionalità opzionale.</block>
  <block id="219af746424bba4643138d0820ab40b5" category="paragraph">Le seguenti modifiche sono necessarie per consentire al server NFS e al client NFS di risolvere il problema del ridenominazione sciocco:</block>
  <block id="36efd47a4ba95b58e3b2a0f2ed7420ad" category="list-text">*Modifiche al client NFS (Linux).* al momento dell'apertura del file, il server NFS risponde con un flag, che indica la capacità di gestire lo scollegamento dei file aperti. Le modifiche al lato client NFS consentono al server NFS di gestire lo scollegamento in presenza del flag. NetApp ha aggiornato il client NFS Linux open-source con queste modifiche. Il client NFS aggiornato è ora generalmente disponibile in RHEL8.7 e RHEL9.1.</block>
  <block id="f400588f268c9f90112ff6290a81575a" category="list-text">*Modifiche al server NFS.* il server NFS tiene traccia dell'apertura. Lo scollegamento su un file aperto esistente è ora gestito dal server per corrispondere alla semantica POSIX. Quando l'ultima apertura viene chiusa, il server NFS avvia la rimozione effettiva del file ed evita così il processo di ridenominazione sciocco. Il server NFS di ONTAP ha implementato questa funzionalità nella sua ultima versione, ONTAP 9.12.1.</block>
  <block id="21a87b96dd7bfc9863d6bca5fc12f005" category="paragraph">Con le suddette modifiche al client e al server NFS, Kafka può sfruttare in tutta sicurezza tutti i vantaggi dello storage NFS collegato alla rete.</block>
  <block id="29d38aea11265de7104c96a7a3818299" category="inline-link-macro">Successivo: Convalida funzionale - correzione ridenominazione non rapida.</block>
  <block id="b75f47bcddf300f706113b833f9e5857" category="paragraph"><block ref="b75f47bcddf300f706113b833f9e5857" category="inline-link-macro-rx"></block></block>
  <block id="8a1762b0db0285b0ca6661669e3a9aec" category="summary">Per la convalida funzionale, abbiamo mostrato che un cluster Kafka con un montaggio NFSv3 per lo storage non esegue operazioni Kafka come la ridistribuzione delle partizioni, mentre un altro cluster montato su NFSv4 con la correzione può eseguire le stesse operazioni senza interruzioni.</block>
  <block id="2b1635c7ae2a72d0b26454157a03e197" category="doc">Convalida funzionale - correzione del ridenominazione senza problemi</block>
  <block id="bfc46a432aa7385a6228ff50401aca2b" category="inline-link-macro">Precedente: Soluzione NetApp per problemi di ridenominazione sciocco nel carico di lavoro NFS-Kafka.</block>
  <block id="6e56361f7ef0ac98b8b5c8c120de1fd8" category="paragraph"><block ref="6e56361f7ef0ac98b8b5c8c120de1fd8" category="inline-link-macro-rx"></block></block>
  <block id="a8ead7a6a54d47ea0a38e64908ab321f" category="section-title">Configurazione della convalida</block>
  <block id="e087dbbdc5792f1e574cdf41c135d858" category="paragraph">La configurazione viene eseguita su AWS. La seguente tabella mostra i diversi componenti della piattaforma e la configurazione ambientale utilizzati per la convalida.</block>
  <block id="7a785978a6b38bb45ae8786c30a1781e" category="cell">Componente della piattaforma</block>
  <block id="c704d8c873b1a8d5d0243075656aa1f5" category="cell">Configurazione dell'ambiente</block>
  <block id="cccdd75af54f32ac7f570bbcca39f516" category="cell">Confluent Platform versione 7.2.1</block>
  <block id="185b9d1a84206af090c5f70ac68f24ad" category="list-text">3 zookeeper – t3.xlarge</block>
  <block id="6677060ff0c6c4620e427121a576713c" category="list-text">4 server di broker – r3.xlarge</block>
  <block id="61e62294effd3d2046982e7d5a22b824" category="list-text">1 x Grafana – t3.xlarge</block>
  <block id="1e2657a43dca2051e4684eb73c2a856c" category="list-text">1 centro di controllo – t3.xlarge</block>
  <block id="2dcca349e332f9e312cebc29485dadf0" category="list-text">3 x Produttore/consumatore</block>
  <block id="29c331c65dbb1c85faa29881b295fbfc" category="cell">Sistema operativo su tutti i nodi</block>
  <block id="00ecb59dfdd1b1378b38c6b7bf8e91dc" category="cell">RHEL8.7o versione successiva</block>
  <block id="4f04a8a7e04e79aafa7150a5ae2bab1b" category="cell">Istanza di NetApp Cloud Volumes ONTAP</block>
  <block id="d09d15c71c68b596f76c57a87a19e0e5" category="cell">Istanza a nodo singolo – M5.2xLarge</block>
  <block id="3ba4ec8d167c12be652d6829ce6e51d8" category="paragraph">La figura seguente mostra la configurazione architetturale per questa soluzione.</block>
  <block id="b3c6c8984f5671892932b2a7eacc5bf4" category="inline-image-macro">Queste immagini mostrano la topologia AWS contenente un VPC contenente tre subnet private con un produttore swarm, il cluster Kafka e l'istanza CVO rispettivamente.</block>
  <block id="2eee6b516bfba2cd7f7f3bbe52d98104" category="paragraph"><block ref="2eee6b516bfba2cd7f7f3bbe52d98104" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d580bb4c55b441a712ec6c9dc12d38b" category="section-title">Flusso architettonico</block>
  <block id="82c8c0c94e152cc00496c6c5a1fa76b0" category="list-text">*Compute.* abbiamo utilizzato un cluster Kafka a quattro nodi con un ensemble di zookeeper a tre nodi in esecuzione su server dedicati.</block>
  <block id="e236bd14d5d59a952978645a606dd7f9" category="list-text">*Monitoring.* abbiamo utilizzato due nodi per una combinazione Prometheus-Grafana.</block>
  <block id="c375f003dbf6b1accc45fd3811ce2b82" category="list-text">*Workload.* per la generazione dei workload, abbiamo utilizzato un cluster a tre nodi separato in grado di produrre e consumare da questo cluster Kafka.</block>
  <block id="ada284cbb65ff7bad5814ecb0c6ecb2f" category="list-text">*Storage.* abbiamo utilizzato un'istanza NetApp Cloud Volumes ONTAP a nodo singolo con due volumi AWS-EBS GP2 da 500 GB collegati all'istanza. Questi volumi sono stati quindi esposti al cluster Kafka come singolo volume NFSv4.1 attraverso un LIF.</block>
  <block id="e86dc7584f98dc172fd46661ef8b935a" category="paragraph">Le proprietà predefinite di Kafka sono state scelte per tutti i server. Lo stesso è stato fatto per lo sciame dello zooteeper.</block>
  <block id="91c26176df142d17ab999313541632c5" category="section-title">Metodologia di test</block>
  <block id="c31fea06105fe5260bb879284c6181e0" category="list-text">Aggiornare<block ref="9733772c7c0780d4ef7a6a8d6a9dbd7d" prefix=" " category="inline-code"></block> al volume kafka, come segue:</block>
  <block id="5ca41832794ba1f8118f718465d6ffe4" category="list-text">Sono stati creati due cluster Kafka simili con la seguente differenza:</block>
  <block id="fc1a46a26a283c18443e516b58cb0a58" category="list-text">*Cluster 1.* il server NFS v4.1 di back-end con ONTAP versione 9.12.1 pronto per la produzione è stato ospitato da un'istanza CVO di NetApp. RHEL 8.7/RHEL 9.1 è stato installato sui broker.</block>
  <block id="183a9a6c4f97a876554696844cf5cd19" category="list-text">*Cluster 2.* il server NFS back-end era un server Linux NFSv3 generico creato manualmente.</block>
  <block id="8dac413f2b3b7fdfc73d642ae6e79a33" category="list-text">È stato creato un argomento dimostrativo su entrambi i cluster Kafka.</block>
  <block id="dc30a10b7f3dac3bcce7b54e12502e89" category="paragraph">Cluster 1:</block>
  <block id="0cdb385ae4a7f7449cf10919962c71c8" category="inline-image-macro">Questa schermata mostra l'argomento demo creato sul cluster 1.</block>
  <block id="c99c5591acf7724aed404fdd225a51d6" category="paragraph"><block ref="c99c5591acf7724aed404fdd225a51d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83655cf6beab33b344c9ae17bec532d0" category="paragraph">Cluster 2:</block>
  <block id="772ab3218dd37dea5c304575fe358498" category="inline-image-macro">Questa schermata mostra l'argomento della demo creato sul cluster 2.</block>
  <block id="1fd29f3ac81f16a73dae3761643fac74" category="paragraph"><block ref="1fd29f3ac81f16a73dae3761643fac74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb392c27040a7eb25cfeb1d96323917e" category="list-text">I dati sono stati caricati in questi nuovi argomenti creati per entrambi i cluster. Questa operazione è stata eseguita utilizzando il toolkit Producer-perf-test incluso nel pacchetto predefinito di Kafka:</block>
  <block id="bd5bb4c79c0fd5aea6e14277bbd9c5fe" category="list-text">È stato eseguito un controllo dello stato di salute per il broker-1 per ciascuno dei cluster utilizzando telnet:</block>
  <block id="ec97e8f78ae99ff145018ede90a47c77" category="list-text">telnet<block ref="da440d4c50d5bbb0ffa4021d6db8332c" prefix=" " category="inline-code"></block></block>
  <block id="a93dad1338160e3b828529ad6a585d13" category="list-text">telnet<block ref="2a3da46f5894b7e15be0ea3be46975cc" prefix=" " category="inline-code"></block></block>
  <block id="a7892fb38856d45eb1f6cd89d3118830" category="paragraph">Nella schermata successiva viene mostrato un controllo dello stato di salute dei broker su entrambi i cluster:</block>
  <block id="855ba5b1fb4b822400c8e412d08df6e4" category="inline-image-macro">Questa schermata mostra la lettura per un controllo dello stato di salute riuscito su entrambi i broker.</block>
  <block id="0017223ce5bee33d9165b88b478ac306" category="paragraph"><block ref="0017223ce5bee33d9165b88b478ac306" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a63ad47b1692dcaccf39fb2a5c42e393" category="list-text">Per attivare la condizione di errore che causa il crash dei cluster Kafka che utilizzano i volumi di storage NFSv3, abbiamo avviato il processo di riassegnazione delle partizioni su entrambi i cluster. La riassegnazione delle partizioni è stata eseguita utilizzando<block ref="5cbd65bd2e4824bbb4876b792e513e10" prefix=" " category="inline-code"></block>. Il processo dettagliato è il seguente:</block>
  <block id="9ea6b7d5de4fbe3c468699ad3c8bb6ef" category="list-text">Per riassegnare le partizioni per un argomento in un cluster Kafka, abbiamo generato la configurazione di riassegnazione proposta JSON (eseguita per entrambi i cluster).</block>
  <block id="c4c8306a70b22c96715a3f79fe60eca9" category="list-text">Il JSON di riassegnazione generato è stato quindi salvato in<block ref="d773b1c180323b61e54dc5acaa6fb66f" prefix=" " category="inline-code"></block>.</block>
  <block id="05e65fb821eccc3b4cb26cc7285d75f8" category="list-text">Il processo di riassegnazione effettiva delle partizioni è stato attivato dal seguente comando:</block>
  <block id="83c299e30316ef5659e9b3bbd34b40ad" category="list-text">Dopo alcuni minuti di completamento della riassegnazione, un altro controllo dello stato di salute dei broker ha dimostrato che il cluster che utilizza volumi di storage NFSv3 ha riscontrato un problema di ridenominazione sciocco e si è bloccato, mentre il cluster 1 utilizza volumi di storage NetApp ONTAP NFSv4.1 con la correzione delle operazioni senza interruzioni.</block>
  <block id="197bc98012d3a74f45e086c86b7237bc" category="inline-image-macro">Questa schermata mostra l'output di un broker bloccato.</block>
  <block id="b32b7199140b7e4479d72c3f0c8c506b" category="paragraph"><block ref="b32b7199140b7e4479d72c3f0c8c506b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7796cd6b11de5af34093097d2db9b94f" category="list-text">Cluster1-Broker-1 è attivo.</block>
  <block id="fef78f6445fec5a3c0d0cb2008e6c34e" category="list-text">Cluster2-broker-1 è morto.</block>
  <block id="e413a6c934b14b11c478c905d8c0489b" category="list-text">Dopo aver controllato le directory di log di Kafka, era chiaro che il cluster 1 che utilizzava i volumi di storage NetApp ONTAP NFSv4.1 con la correzione aveva un'assegnazione pulita delle partizioni, mentre il cluster 2 utilizzava lo storage NFSv3 generico non era dovuto a problemi di ridenominazione sciocco, che hanno portato al crash. La figura seguente mostra il ribilanciamento delle partizioni del cluster 2, che ha causato un problema di ridenominazione sciocco sullo storage NFSv3.</block>
  <block id="1c2cca9f5ca8cce4b11ebdc970e4a78c" category="inline-image-macro">Questa schermata mostra l'output del log per il blocco del cluster 2.</block>
  <block id="14b7c5d09f2ae8862c1f59ee1823a5e3" category="paragraph"><block ref="14b7c5d09f2ae8862c1f59ee1823a5e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43fea21bb45bdea6ebc007efbf3c0053" category="paragraph">La figura seguente mostra un ribilanciamento pulito delle partizioni del cluster 1 utilizzando lo storage NetApp NFSv4.1.</block>
  <block id="1ac73d9186e013f2157d22422bc044ff" category="inline-image-macro">Questa schermata mostra l'output del log per un'assegnazione corretta della partizione pulita per il cluster 1, mentre</block>
  <block id="bdab654bf4d623f517718ee0c01ce4f2" category="paragraph"><block ref="bdab654bf4d623f517718ee0c01ce4f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ecf40a5f4c022357e753dea69b66285" category="inline-link-macro">Perché scegliere NetApp NFS per i workload Kafka?</block>
  <block id="1a2139ac1273f5dc6ebea0a90a0b8caa" category="paragraph"><block ref="1a2139ac1273f5dc6ebea0a90a0b8caa" category="inline-link-macro-rx"></block></block>
  <block id="4ea8220421596c898f8150bfebdf4ccb" category="summary">Questo test di verifica ha raggiunto 31,74 Gbps di throughput di tiering su Confluent con un controller di storage NetApp ONTAP.</block>
  <block id="f86bb9f7d3cb6d2f8473494c8bd135ec" category="inline-link-macro">Precedente: Linee guida sulle Best practice per le performance.</block>
  <block id="65b905a56baa366aa274945ca5b7cad4" category="paragraph"><block ref="65b905a56baa366aa274945ca5b7cad4" category="inline-link-macro-rx"></block></block>
  <block id="93a10982e8e304323ad8af9a9387d775" category="paragraph">Questo test di verifica ha raggiunto 31,74 Gbps di throughput di tiering su Confluent con il controller di storage NetApp ONTAP.</block>
  <block id="0f2f674cce6910ae97ee7ecc7bd9de18" category="list-text">Cos'è Confluent?</block>
  <block id="e6deab0ab2821160c056af4c7766624c" category="inline-link"><block ref="e6deab0ab2821160c056af4c7766624c" category="inline-link-rx"></block></block>
  <block id="ce3026317a00b57c81627bd64a1b3311" category="paragraph"><block ref="ce3026317a00b57c81627bd64a1b3311" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">Dettagli del parametro S3-sink</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="list-text">Apache Kafka</block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="58a229be829dc9196abdaff6a4a26864" category="list-text">S3 in ONTAP Best practice</block>
  <block id="f47b79954bb4ad3165d7f99db02fe933" category="inline-link"><block ref="f47b79954bb4ad3165d7f99db02fe933" category="inline-link-rx"></block></block>
  <block id="e98b34b649783312d3b317c7441a20a5" category="paragraph"><block ref="e98b34b649783312d3b317c7441a20a5" category="inline-link-rx"></block></block>
  <block id="3075344c29b864c90ae1411c1db26e87" category="list-text">Gestione dello storage a oggetti S3</block>
  <block id="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link"><block ref="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link-rx"></block></block>
  <block id="8a93310a8dd4b405a8711f82adeb3c23" category="paragraph"><block ref="8a93310a8dd4b405a8711f82adeb3c23" category="inline-link-rx"></block></block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">Documentazione sui prodotti NetApp</block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="1b70ac0a972fddf1e1a33e6ed9df49c7" category="cell">Settembre 2022</block>
  <block id="f362fde28c17f629ded4d965d576f423" category="summary">Splunk Enterprise è la soluzione SIEM leader di mercato che offre risultati ai team di sicurezza, IT e DevOps. L'utilizzo di Splunk è aumentato notevolmente nelle organizzazioni dei nostri clienti. Pertanto, è necessario aggiungere più origini dati mantenendo i dati per un periodo più lungo, insistendo così sull'infrastruttura Splunk.</block>
  <block id="3613797d0f4ca076e9cb8ba4c75e87e6" category="inline-link-macro">Precedente: Performance di SmartStore a sito singolo.</block>
  <block id="5fdd4eaa62513aac277472bf713d1bee" category="paragraph"><block ref="5fdd4eaa62513aac277472bf713d1bee" category="inline-link-macro-rx"></block></block>
  <block id="25c2a1fd1c8874a3e0526920fe7f440d" category="paragraph">La combinazione di Splunk SmartStore e NetApp StorageGRID è progettata per fornire un'architettura scalabile alle organizzazioni per ottenere migliori performance di acquisizione con SmartStore e lo storage a oggetti StorageGRID e una maggiore scalabilità per un ambiente Splunk in più aree geografiche.</block>
  <block id="fbf1f1e6f0848252d39ef48e7e18146f" category="list-text">Risorse di documentazione NetApp StorageGRID</block>
  <block id="68d4d5362a15088f2ac3fa494c971af5" category="inline-link"><block ref="68d4d5362a15088f2ac3fa494c971af5" category="inline-link-rx"></block></block>
  <block id="580c43c30953ec671dd4a70120e1b513" category="paragraph"><block ref="580c43c30953ec671dd4a70120e1b513" category="inline-link-rx"></block></block>
  <block id="2e85fc867cab94d246e0bf6043b361cd" category="paragraph"><block ref="2e85fc867cab94d246e0bf6043b361cd" category="inline-link-rx"></block></block>
  <block id="e145cc414457b4a232fb0b63ce9f44ab" category="list-text">Documentazione Splunk Enterprise</block>
  <block id="f710d46c12a05abcfde056d779cb608c" category="inline-link"><block ref="f710d46c12a05abcfde056d779cb608c" category="inline-link-rx"></block></block>
  <block id="2ab8bf37a62983163c96b3c2f9a275d4" category="paragraph"><block ref="2ab8bf37a62983163c96b3c2f9a275d4" category="inline-link-rx"></block></block>
  <block id="14c366ebe94ed0bdf5d5eecad5a08411" category="list-text">Splunk Enterprise informazioni su SmartStore</block>
  <block id="98bda64923adc1da4a0e009dd52832a4" category="inline-link"><block ref="98bda64923adc1da4a0e009dd52832a4" category="inline-link-rx"></block></block>
  <block id="86d261d18a8cb6ce8f95f58af41452e5" category="paragraph"><block ref="86d261d18a8cb6ce8f95f58af41452e5" category="inline-link-rx"></block></block>
  <block id="b437e6537685614b8004334bad18e424" category="list-text">Splunk Enterprise Distributed Deployment Manual</block>
  <block id="048c67f334d3e1bbcb765e563d076b7d" category="inline-link"><block ref="048c67f334d3e1bbcb765e563d076b7d" category="inline-link-rx"></block></block>
  <block id="0a25fd44eb7af79f8d9bb0e91d7dfec3" category="paragraph"><block ref="0a25fd44eb7af79f8d9bb0e91d7dfec3" category="inline-link-rx"></block></block>
  <block id="d043516086780b04d9c8b38186019be3" category="list-text">Splunk Enterprise Gestione di Indexer e Clusters di Indexer</block>
  <block id="87fbe590fc8f855078f14ba53325eb46" category="inline-link"><block ref="87fbe590fc8f855078f14ba53325eb46" category="inline-link-rx"></block></block>
  <block id="d0438efbc1a0dbee965023150ccf9334" category="paragraph"><block ref="d0438efbc1a0dbee965023150ccf9334" category="inline-link-rx"></block></block>
  <block id="e4c2e8edac362acab7123654b9e73432" category="cell">1.0</block>
  <block id="d1cdbd3c8324f3afbc5b420ce471feff" category="cell">Luglio 2022</block>
  <block id="c9fee86e220b694a9ca26cb5d3943276" category="summary">Questo documento descrive i benchmark delle performance per la piattaforma Confluent su NetApp ONTAP utilizzando un kit di benchmarking per lo storage a più livelli.</block>
  <block id="5514e652e396365ccb56f1b2b5371569" category="doc">TR-4941: Confluenza con i controller di storage NetApp ONTAP</block>
  <block id="1e0e02def11263577d232ee8ce69c727" category="paragraph">Karthikeyan Nagalingam, Joe Scott, NetApp Rankesh Kumar, Confluent</block>
  <block id="f79dab50e0f9664c4b4d604319a8cbbe" category="paragraph">Per rendere la piattaforma Confluent più scalabile ed elastica, l'IT deve essere in grado di scalare e bilanciare i carichi di lavoro molto rapidamente. Lo storage a più livelli consente di gestire l'archiviazione di enormi volumi di dati in Confluent riducendo il carico operativo. L'idea fondamentale è separare lo storage dei dati dall'elaborazione dei dati, il che rende molto più semplice la scalabilità di ciascuno di essi in modo indipendente.</block>
  <block id="44f523cee834fac14fc6966d940c5e92" category="paragraph">Dotato di innovazioni leader del settore, il software per la gestione dei dati NetApp ONTAP offre a Confluent numerosi vantaggi ovunque i dati siano presenti.</block>
  <block id="ff221b4a7c17defefb1a32cf9136086d" category="inline-link-macro">Avanti: Soluzione.</block>
  <block id="700a1e72f5247529520dfae6b0d991e3" category="paragraph"><block ref="700a1e72f5247529520dfae6b0d991e3" category="inline-link-macro-rx"></block></block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">Questo documento descrive le soluzioni dati del cloud ibrido che utilizzano i sistemi storage NetApp AFF e FAS, NetApp Cloud Volumes ONTAP, NetApp Connected Storage e la tecnologia FlexClone per Spark e Hadoop. Queste architetture di soluzioni consentono ai clienti di scegliere una soluzione di protezione dei dati appropriata per il proprio ambiente. NetApp ha progettato queste soluzioni in base all'interazione con i clienti e ai casi di utilizzo aziendali.</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="doc">TR-4657: Soluzioni dati di cloud ibrido NetApp - Spark e Hadoop in base ai casi di utilizzo dei clienti</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">Karthikeyan Nagalingam e Sathish Thyagarajan, NetApp</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">Questo documento descrive le soluzioni dati del cloud ibrido che utilizzano i sistemi storage NetApp AFF e FAS, NetApp Cloud Volumes ONTAP, NetApp Connected Storage e la tecnologia FlexClone per Spark e Hadoop. Queste architetture di soluzioni consentono ai clienti di scegliere una soluzione di protezione dei dati appropriata per il proprio ambiente. NetApp ha progettato queste soluzioni in base all'interazione con i clienti e ai casi di utilizzo aziendali. Questo documento fornisce le seguenti informazioni dettagliate:</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">Perché abbiamo bisogno della protezione dei dati per gli ambienti Spark e Hadoop e per le sfide dei clienti.</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">Il data fabric basato sulla visione di NetApp e i suoi elementi di base e servizi.</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">Come questi building block possono essere utilizzati per progettare flussi di lavoro flessibili per la protezione dei dati.</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">I pro e i contro di diverse architetture basate su casi di utilizzo reali dei clienti. Ogni caso d'utilizzo fornisce i seguenti componenti:</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="list-text">Scenari dei clienti</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">Soluzioni</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">Riepilogo delle soluzioni</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">Perché la protezione dei dati Hadoop?</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">In un ambiente Hadoop e Spark, è necessario risolvere i seguenti problemi:</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">*Errori software o umani.* un errore umano negli aggiornamenti software durante l'esecuzione delle operazioni dei dati Hadoop può portare a comportamenti errati che possono causare risultati imprevisti dal lavoro. In tal caso, dobbiamo proteggere i dati per evitare errori o risultati irragionevoli. Ad esempio, a causa di un aggiornamento software eseguito in modo non corretto per un'applicazione di analisi del segnale di traffico, una nuova funzionalità che non riesce ad analizzare correttamente i dati del segnale di traffico sotto forma di testo normale. Il software continua ad analizzare JSON e altri formati di file non di testo, con il risultato che il sistema di analisi del controllo del traffico in tempo reale produce risultati di previsione che sono punti dati mancanti. Questa situazione può causare uscite guaste che potrebbero causare incidenti ai segnali stradali. La protezione dei dati può risolvere questo problema fornendo la possibilità di eseguire rapidamente il rollback alla versione dell'applicazione precedente.</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">*Dimensione e scalabilità.* la dimensione dei dati di analisi cresce giorno per giorno a causa del numero sempre crescente di origini dati e volumi. I social media, le app mobili, l'analisi dei dati e le piattaforme di cloud computing sono le principali fonti di dati nell'attuale mercato dei big data, che sta crescendo molto rapidamente, e quindi i dati devono essere protetti per garantire operazioni accurate dei dati.</block>
  <block id="80908b4b31d37977701d3694fbc636ac" category="list-text">*Protezione dei dati nativa di Hadoop.* Hadoop ha un comando nativo per proteggere i dati, ma questo comando non fornisce coerenza dei dati durante il backup. Supporta solo il backup a livello di directory. Le snapshot create da Hadoop sono di sola lettura e non possono essere utilizzate per riutilizzare direttamente i dati di backup.</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Problemi di protezione dei dati per i clienti Hadoop e Spark</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Una sfida comune per i clienti di Hadoop e Spark consiste nel ridurre i tempi di backup e aumentare l'affidabilità del backup senza influire negativamente sulle performance del cluster di produzione durante la protezione dei dati.</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">I clienti devono anche ridurre al minimo i tempi di inattività dell'obiettivo del punto di ripristino (RPO) e dell'obiettivo del tempo di ripristino (RTO) e controllare i siti di disaster recovery on-premise e basati sul cloud per una business continuity ottimale. Questo controllo deriva in genere dalla disponibilità di strumenti di gestione di livello Enterprise.</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">Gli ambienti Hadoop e Spark sono complicati perché non solo il volume di dati è enorme e in crescita, ma la velocità di arrivo dei dati è in aumento. Questo scenario rende difficile creare rapidamente ambienti DevTest e QA efficienti e aggiornati dai dati di origine. NetApp riconosce queste sfide e offre le soluzioni presentate in questo documento.</block>
  <block id="1f60e9ce60971dc2129b30c8820ff343" category="inline-link-macro">Successivo: Data fabric basato su NetApp per l'architettura dei big data.</block>
  <block id="b8d3f7ee1ffc74c6a96c88a193dc6f1e" category="paragraph"><block ref="b8d3f7ee1ffc74c6a96c88a193dc6f1e" category="inline-link-macro-rx"></block></block>
  <block id="191ea533aa1478d35c965840430fbfe6" category="summary">Le soluzioni NetApp Modern Data Analytics sono un insieme di funzionalità tecnologiche e strategiche che dimostrano le funzionalità dello storage NetApp in tutto lo spazio ai.</block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">Questa sezione presenta le lezioni apprese da questa certificazione.</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">Linee guida sulle Best practice</block>
  <block id="524a5aa4f422c84af378b5418bb1539b" category="inline-link-macro">Precedente: Cluster di auto-ribilanciamento confluenti.</block>
  <block id="ae7f441436d5c9a5dc4278e4ea2b87e8" category="paragraph"><block ref="ae7f441436d5c9a5dc4278e4ea2b87e8" category="inline-link-macro-rx"></block></block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">In base alla nostra convalida, lo storage a oggetti S3 è la soluzione migliore per Confluent per conservare i dati.</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">Possiamo utilizzare SAN ad alto throughput (in particolare FC) per mantenere i dati hot del broker o il disco locale, perché, nella configurazione dello storage a più livelli Confluent, la dimensione dei dati contenuti nella directory dei dati broker si basa sulle dimensioni del segmento e sul tempo di conservazione quando i dati vengono spostati nello storage a oggetti.</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">Gli archivi di oggetti offrono performance migliori quando segment.bytes è più elevato; abbiamo testato 512 MB.</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">In Kafka, la lunghezza della chiave o del valore (in byte) per ciascun record prodotto per l'argomento è controllata da<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block> parametro. Per StorageGRID, le performance di acquisizione e recupero degli oggetti S3 sono aumentate a valori più elevati. Ad esempio, 512 byte hanno fornito un recupero da 5,8 Gbps, 1024 byte hanno fornito un recupero s3 da 7,5 Gbps e 2048 byte sono forniti quasi a 10 Gbps.</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">La figura seguente illustra l'acquisizione e il recupero dell'oggetto S3 in base a.<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block>.</block>
  <block id="b50ee24368ac624f2816b9e550167cb9" category="paragraph"><block ref="b50ee24368ac624f2816b9e550167cb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">*Tuning di Kafka.* per migliorare le performance dello storage a più livelli, è possibile aumentare TierFetcherNumThreads e TierArchiverNumThreads. Come linea guida generale, si desidera aumentare TierFetcherNumThreads in modo che corrisponda al numero di core della CPU fisica e aumentare TierArchiverNumThreads fino alla metà del numero di core della CPU. Ad esempio, nelle proprietà del server, se si dispone di un computer con otto core fisici, impostare confluent.Tier.fetcher.num.threads = 8 e confluent.Tier.archiver.num.threads = 4.</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">*Intervallo di tempo per l'eliminazione dell'argomento.* quando un argomento viene cancellato, l'eliminazione dei file di segmenti di registro nella memoria a oggetti non inizia immediatamente. Piuttosto, esiste un intervallo di tempo con un valore predefinito di 3 ore prima che venga eseguita l'eliminazione di tali file. È possibile modificare la configurazione, confluent.tier.topic.delete.check.interval.ms, per modificare il valore di questo intervallo. Se si elimina un argomento o un cluster, è anche possibile eliminare manualmente gli oggetti nel rispettivo bucket.</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">*ACL su argomenti interni dello storage a più livelli.* Una Best practice consigliata per le implementazioni on-premise è abilitare un autorizzatore ACL sugli argomenti interni utilizzati per lo storage a più livelli. Impostare le regole ACL per limitare l'accesso a questi dati solo all'utente del broker. In questo modo si proteggono gli argomenti interni e si impedisce l'accesso non autorizzato ai dati e ai metadati dello storage a più livelli.</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">Sostituire l'utente<block ref="a802c5bf62b7c5970725474468cf46f4" prefix=" " category="inline-code"></block> con l'effettivo broker principal nella tua implementazione.</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">Ad esempio, il comando<block ref="bccf46e0861de44696513d6cbea91e4c" prefix=" " category="inline-code"></block> Imposta gli ACL sull'argomento interno per lo storage a più livelli. Attualmente, esiste solo un singolo argomento interno relativo allo storage a più livelli. Nell'esempio viene creato un ACL che fornisce l'autorizzazione principale Kafka per tutte le operazioni sull'argomento interno.</block>
  <block id="c7aa1f1ea2c8ad1712056dd97321d808" category="inline-link-macro">Successivo: Dimensionamento.</block>
  <block id="de8a38c4c90ce81d8c4b82c44500e504" category="paragraph"><block ref="de8a38c4c90ce81d8c4b82c44500e504" category="inline-link-macro-rx"></block></block>
  <block id="69efde21ccf40f1dda4d665f81bacefe" category="summary">In questo scenario, è stata modernizzata una grande piattaforma di analytics per i servizi finanziari e le banche di investimento utilizzando la soluzione di storage NetApp NFS per ottenere un miglioramento significativo nell'analisi dei rischi di investimento e dei derivati per la sua business unit quantitativa e di gestione delle risorse.</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="doc">Caso d'utilizzo 5: Accelerare i carichi di lavoro di analisi</block>
  <block id="c8ea1eda8e0ac121148ac86dee9649a7" category="inline-link-macro">Precedente: Caso di utilizzo 4 - protezione dei dati e connettività multicloud.</block>
  <block id="87fb2a1eb3f12014af6e5dd36ba66e5e" category="paragraph"><block ref="87fb2a1eb3f12014af6e5dd36ba66e5e" category="inline-link-macro-rx"></block></block>
  <block id="24b0e878b8196875cd088397ac8312a9" category="paragraph">Nell'ambiente esistente del cliente, l'infrastruttura Hadoop utilizzata per la piattaforma di analisi ha sfruttato lo storage interno dei server Hadoop. A causa della natura proprietaria dell'ambiente JBOD, molti clienti interni all'interno dell'organizzazione non sono stati in grado di sfruttare il proprio modello quantitativo Monte Carlo, una simulazione che si basa sui campioni ricorrenti di dati in tempo reale. La capacità non ottimale di comprendere gli effetti dell'incertezza nei movimenti di mercato serviva in modo sfavorevole per la business unit di gestione quantitativa delle risorse.</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">La business unit quantitativa della banca desiderava un metodo di previsione efficiente per ottenere previsioni precise e tempestive. A tale scopo, il team ha riconosciuto la necessità di modernizzare l'infrastruttura, ridurre i tempi di attesa i/o esistenti e migliorare le performance delle applicazioni di analisi come Hadoop e Spark per simulare in modo efficiente i modelli di investimento, misurare i potenziali guadagni e analizzare i rischi.</block>
  <block id="5ff37557b096819452a25d129a312360" category="paragraph">Il cliente disponeva di JBOD per la soluzione Spark esistente. NetApp ONTAP, NetApp StorageGRID e MinIO Gateway to NFS sono stati quindi sfruttati per ridurre i tempi di attesa i/o per il gruppo finanziario quantitativo della banca che esegue simulazioni e analisi su modelli di investimento che valutano potenziali guadagni e rischi. Questa immagine mostra la soluzione Spark con lo storage NetApp.</block>
  <block id="095ba715431845442ef6bf2f4283ad1c" category="paragraph"><block ref="095ba715431845442ef6bf2f4283ad1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">Come mostrato nella figura precedente, i sistemi AFF A800, A700 e StorageGRID sono stati implementati per accedere ai file di parquet attraverso i protocolli NFS e S3 in un cluster Hadoop a sei nodi con Spark e i servizi di metadati YARN e Hive per le operazioni di analisi dei dati.</block>
  <block id="bc12facb8aa0a34db56b00fdbc21c351" category="paragraph">Una soluzione DAS (Direct-Attached Storage) nel vecchio ambiente del cliente ha avuto lo svantaggio di scalare calcolo e storage in modo indipendente. Con la soluzione NetApp ONTAP per Spark, la business unit di analisi finanziaria della banca è stata in grado di separare lo storage dal calcolo e di portare le risorse dell'infrastruttura in modo più efficace secondo necessità.</block>
  <block id="582c4aa65d1bd005ddc785db8b807fca" category="paragraph">Utilizzando ONTAP con NFS, le CPU dei server di calcolo sono state quasi completamente utilizzate per i job SQL di Spark e il tempo di attesa i/o è stato ridotto di quasi il 70%, fornendo quindi una potenza di calcolo e un incremento delle performance migliori per i carichi di lavoro di Spark. In seguito, l'aumento dell'utilizzo della CPU ha anche consentito al cliente di sfruttare GPU, come GPUDirect, per un'ulteriore modernizzazione della piattaforma. Inoltre, StorageGRID offre un'opzione di storage a basso costo per i carichi di lavoro Spark e il gateway MinIO fornisce un accesso sicuro ai dati NFS attraverso il protocollo S3. Per i dati nel cloud, NetApp consiglia Cloud Volumes ONTAP, Azure NetApp Files e NetApp Cloud Volumes Service.</block>
  <block id="6e362ed6e741056d737b93021ab2f3f9" category="paragraph"><block ref="6e362ed6e741056d737b93021ab2f3f9" category="inline-link-macro-rx"></block></block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="doc">Dimensionamento</block>
  <block id="5ffdfbbb428796f516e072e038d107b0" category="inline-link-macro">Precedente: Linee guida sulle Best practice.</block>
  <block id="49575973ec85e64724d2a45d401f32b3" category="paragraph"><block ref="49575973ec85e64724d2a45d401f32b3" category="inline-link-macro-rx"></block></block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">Il dimensionamento di Kafka può essere eseguito con quattro modalità di configurazione: Semplice, granulare, inversa e partizioni.</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">Semplice</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">La modalità Simple è adatta per gli utenti Apache Kafka per la prima volta o per i primi casi di utilizzo. Per questa modalità, vengono forniti requisiti come throughput Mbps, fanout di lettura, conservazione e percentuale di utilizzo delle risorse (il valore predefinito è 60%). Si accede anche all'ambiente, ad esempio on-premise (bare-metal, VMware, Kubernetes o OpenStack) o al cloud. In base a queste informazioni, il dimensionamento di un cluster Kafka fornisce il numero di server richiesti per il broker, lo zookeeper, gli impiegati di connessione Apache Kafka, il registro dello schema, un proxy REST, ksqlDB e il centro di controllo Confluent.</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">Per lo storage su più livelli, prendere in considerazione la modalità di configurazione granulare per il dimensionamento di un cluster Kafka. La modalità granulare è adatta agli utenti esperti di Apache Kafka o a casi di utilizzo ben definiti. Questa sezione descrive il dimensionamento per produttori, processori di streaming e consumatori.</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">Produttori</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">Per descrivere i produttori di Apache Kafka (ad esempio un client nativo, un proxy REST o un connettore Kafka), fornire le seguenti informazioni:</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">*Nome.* Spark.</block>
  <block id="0ae6d6b48753e01bf1ae73bb86ee6276" category="list-text">*Tipo produttore.* applicazione o servizio, proxy (REST, MQTT, Altro) e database esistente (RDBMS, NOSQL, Altro). È anche possibile selezionare "non so".</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">*Throughput medio.* in eventi al secondo (ad esempio 1,000,000).</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">*Throughput massimo.* in eventi al secondo (ad esempio 4,000,000).</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">*Dimensione media dei messaggi.* in byte, non compressi (massimo 1 MB; 1000 ad esempio).</block>
  <block id="dd6d45bc2ad71619bde2260f1776e9b2" category="list-text">*Message format.* le opzioni includono Avro, JSON, buffer di protocollo, binario, testo, "Non lo so" e altri.</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">*Fattore di replica.* le opzioni sono 1, 2, 3 (raccomandazione confluente), 4, 5, oppure 6.</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">*Tempo di conservazione.* un giorno (ad esempio). Per quanto tempo vuoi che i tuoi dati siano memorizzati in Apache Kafka? Inserire -1 con qualsiasi unità per un tempo infinito. Il calcolatore presuppone un tempo di conservazione di 10 anni per una conservazione infinita.</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">Selezionare la casella di controllo "Enable Tiered Storage to Decrease Broker Count and Allow for Infinite Storage?" (attiva lo storage a livelli per ridurre il numero di broker e consentire lo storage</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">Quando lo storage su più livelli è attivato, i campi di conservazione controllano l'hot set di dati memorizzati localmente sul broker. I campi di conservazione dell'archivio controllano la durata della memorizzazione dei dati nello storage a oggetti di archiviazione.</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">*Archival Storage Retention.* un anno (ad esempio). Per quanto tempo vuoi che i tuoi dati siano memorizzati nello storage di archiviazione? Inserire -1 con qualsiasi unità per una durata infinita. Il calcolatore presuppone una conservazione di 10 anni per una conservazione infinita.</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">*Growth Multiplier.* 1 (ad esempio). Se il valore di questo parametro si basa sul throughput corrente, impostarlo su 1. Per dimensionare in base alla crescita aggiuntiva, impostare questo parametro su un moltiplicatore di crescita.</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">*Numero di istanze produttore.* 10 (ad esempio). Quante istanze di produttori saranno in esecuzione? Questo input è necessario per incorporare il carico della CPU nel calcolo del dimensionamento. Un valore vuoto indica che il carico della CPU non è incorporato nel calcolo.</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">Sulla base di questo esempio di input, il dimensionamento ha il seguente effetto sui produttori:</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">Throughput medio in byte non compressi: 1 Gbps. Throughput massimo in byte non compressi: 4 Gbps. Throughput medio in byte compressi: 400 Mbps. Throughput massimo in byte compressi: 1,6 Gbps. Si basa su un tasso di compressione predefinito del 60% (è possibile modificare questo valore).</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">Storage hotset on-broker totale richiesto: 31,104 TB, inclusa la replica, compressa. Storage di archiviazione off-broker totale richiesto: 378,432 TB, compresso. Utilizzare <block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block> Per il dimensionamento StorageGRID.</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">I processori stream devono descrivere le proprie applicazioni o servizi che consumano dati da Apache Kafka e riproducono in Apache Kafka. Nella maggior parte dei casi, questi sono integrati in flussi ksqlDB o Kafka.</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">*Nome.* Spark streamer.</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">*Tempo di elaborazione.* quanto tempo impiega questo processore per elaborare un singolo messaggio?</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1 ms (semplice, stateless transformation) [esempio], 10 ms (stateful in-memory operation).</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100 ms (funzionamento su disco o rete stateful), 1000 ms (chiamata DI PAUSA di terze parti).</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">Ho eseguito un benchmark di questo parametro e so esattamente quanto tempo occorre.</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">*Conservazione dell'output.* 1 giorno (esempio). Un stream processor produce l'output di Apache Kafka. Per quanto tempo vuoi che questi dati di output siano memorizzati in Apache Kafka? Inserire -1 con qualsiasi unità per una durata infinita.</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">Selezionare la casella di controllo "Enable Tiered Storage to Decrease Broker Count and Allow for Infinite Storage?" (attiva lo storage a più livelli per ridurre il numero di broker e</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">*Archival Storage Retention.* 1 anno (ad esempio). Per quanto tempo vuoi che i tuoi dati siano memorizzati nello storage di archiviazione? Inserire -1 con qualsiasi unità per una durata infinita. Il calcolatore presuppone una conservazione di 10 anni per una conservazione infinita.</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">*Output Passthrough percent.* 100 (ad esempio). Un stream processor produce l'output di Apache Kafka. Quale percentuale di throughput in entrata verrà restituita ad Apache Kafka? Ad esempio, se il throughput in entrata è 20 Mbps e questo valore è 10, il throughput in uscita sarà 2 Mbps.</block>
  <block id="d1a6a4732f959b58cd8c77edcf10b31b" category="list-text">Da quali applicazioni viene letto? Selezionare "Spark" (Spark), il nome utilizzato nel dimensionamento basato sul tipo di produttore. In base all'input di cui sopra, è possibile prevedere i seguenti effetti del dimensionamento sulle istanze del processo di flusso e sulle stime delle partizioni degli argomenti:</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">Questa applicazione di elaborazione del flusso richiede il seguente numero di istanze. Gli argomenti in entrata probabilmente richiedono anche queste partizioni. Contattare Confluent per confermare questo parametro.</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">1,000 per throughput medio senza moltiplicatore di crescita</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">4,000 per throughput di picco senza moltiplicatore di crescita</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">1,000 per un throughput medio con un moltiplicatore di crescita</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">4,000 per throughput di picco con un moltiplicatore di crescita</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">Consumatori</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">Descrivi le tue applicazioni o servizi che consumano dati da Apache Kafka e non vengono prodotti in Apache Kafka, ad esempio un client nativo o un connettore Kafka.</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">*Nome.* Spark consumer.</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">*Tempo di elaborazione.* quanto tempo impiega questo cliente per elaborare un singolo messaggio?</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1 ms (ad esempio, un'attività semplice e senza stato come la registrazione)</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10 ms (scritture rapide in un datastore)</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100 ms (scritture lente in un datastore)</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1000 ms (chiamata DI RIPOSO di terze parti)</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">Alcuni altri processi di riferimento di durata nota.</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">*Consumer type.* Application, proxy, or sink to a existing datastore (RDBMS, NoSQL, other).</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">Da quali applicazioni viene letto? Collegare questo parametro al produttore e al dimensionamento del flusso determinati in precedenza.</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">In base all'input di cui sopra, è necessario determinare il dimensionamento per le istanze consumer e le stime delle partizioni degli argomenti. Un'applicazione consumer richiede il seguente numero di istanze.</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">2,000 per throughput medio, nessun moltiplicatore di crescita</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">8,000 per throughput di picco, nessun moltiplicatore di crescita</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">2,000 per throughput medio, incluso il moltiplicatore di crescita</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">8,000 per throughput di picco, incluso il moltiplicatore di crescita</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">Gli argomenti in entrata probabilmente necessitano anche di questo numero di partizioni. Contatta Confluent per confermare.</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">Oltre ai requisiti per i produttori, i processori di streaming e i consumatori, devi fornire i seguenti requisiti aggiuntivi:</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">*Tempo di ricostruzione.* ad esempio, 4 ore. Se un host del broker Apache Kafka si guasta, i dati vengono persi e viene eseguito il provisioning di un nuovo host per sostituire l'host guasto, quanto velocemente deve essere ricostruito questo nuovo host? Lasciare vuoto questo parametro se il valore non è noto.</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">*Obiettivo di utilizzo delle risorse (percentuale).* ad esempio, 60. In che modo desiderate che i vostri host siano utilizzati durante il throughput medio? Confluent consiglia un utilizzo del 60% a meno che non si utilizzino cluster di bilanciamento automatico Confluent, nel qual caso l'utilizzo può essere maggiore.</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">Descrivi il tuo ambiente</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">*In quale ambiente verrà eseguito il tuo cluster?* Amazon Web Services, Microsoft Azure, piattaforma cloud Google, bare-metal on-premise, VMware on premise, OpenStack on premise o Kubernates on premise?</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">*Dettagli host.* numero di core: 48 (ad esempio), tipo di scheda di rete (10GbE, 40GbE, 16GbE, 1GbE o altro tipo).</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">*Storage Volumes.* host: 12 (ad esempio). Quanti dischi rigidi o SSD sono supportati per host? Confluent consiglia 12 dischi rigidi per host.</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">*Capacità/volume di storage (in GB).* 1000 (ad esempio). Quanto storage può memorizzare un singolo volume in gigabyte? Confluent consiglia dischi da 1 TB.</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">*Configurazione dello storage.* come vengono configurati i volumi dello storage? Confluent consiglia RAID10 per sfruttare tutte le funzionalità confluenti. JBOD, SAN, RAID 1, RAID 0, RAID 5, e altri tipi sono supportati.</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">*Throughput di un volume singolo (Mbps).* 125 (ad esempio). Quanto velocemente un singolo volume di storage può leggere o scrivere in megabyte al secondo? Confluent consiglia dischi rigidi standard, che in genere hanno un throughput di 125 MBps.</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">*Capacità di memoria (GB).* 64 (ad esempio).</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">Dopo aver determinato le variabili ambientali, selezionare Size my Cluster (dimensione cluster). In base ai parametri di esempio sopra indicati, abbiamo determinato il seguente dimensionamento per Confluent Kafka:</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">* Apache Kafka.* numero di broker: 22. Il cluster è legato allo storage. Considerare la possibilità di abilitare lo storage a più livelli per ridurre il numero di host e consentire lo storage infinito.</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">*Apache Zooseeper.* Conteggio: 5; Apache Kafka Connect Workers: Conteggio: 2; Registro dello schema: Conteggio: 2; REST Proxy: Conteggio: 2; ksqlDB: Conteggio: 2; Centro di controllo confluente: Conteggio: 1.</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">Utilizza la modalità inversa per i team di piattaforme senza un caso d'utilizzo. Utilizzare la modalità Partitions per calcolare il numero di partizioni richiesto da un singolo argomento. Vedere<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block> per il dimensionamento in base alle modalità di reverse e partitions.</block>
  <block id="4127d3e6d7b548701a1cf83ef1d7a922" category="paragraph"><block ref="4127d3e6d7b548701a1cf83ef1d7a922" category="inline-link-macro-rx"></block></block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">Per questa soluzione, NetApp ha validato la migrazione dei dati da dati Lake (HDFS) e dati del cluster MapR a NFS ONTAP. I dati risiedevano in MapR-FS e HDFS. NetApp XCP ha introdotto una nuova funzionalità che consente la migrazione diretta dei dati da un file system distribuito come HDFS e MapR-FS a ONTAP NFS.</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS e MapR-FS su NFS ONTAP</block>
  <block id="9577f33e5dfe124ba394a5c90a123928" category="inline-link-macro">Precedente: GPF per NetApp ONTAP NFS.</block>
  <block id="a503c5d00affd8b681837e8b44490492" category="paragraph"><block ref="a503c5d00affd8b681837e8b44490492" category="inline-link-macro-rx"></block></block>
  <block id="9c02792070008c1748647d8bdbe24432" category="paragraph">Per questa soluzione, NetApp ha validato la migrazione dei dati da dati Lake (HDFS) e dati del cluster MapR a NFS ONTAP. I dati risiedevano in MapR-FS e HDFS. NetApp XCP ha introdotto una nuova funzionalità che consente la migrazione diretta dei dati da un file system distribuito come HDFS e MapR-FS a ONTAP NFS. XCP utilizza thread asincroni e chiamate API HDFS C per comunicare e trasferire dati da MapR- FS e HDFS. La figura seguente mostra la migrazione dei dati da un data Lake (HDFS) e MapR-FS a un NFS ONTAP. Con questa nuova funzionalità, non è necessario esportare l'origine come condivisione NFS.</block>
  <block id="4581f9b32af32647aa31b2f9d57f6f1f" category="paragraph"><block ref="4581f9b32af32647aa31b2f9d57f6f1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">Perché i clienti stanno passando da HDFS e MapR-FS a NFS?</block>
  <block id="b075c8e6a9009d582333c59e237e3646" category="paragraph">La maggior parte delle distribuzioni Hadoop, come Cloudera e Hortonworks, utilizza le distribuzioni HDFS e MapR per memorizzare i dati utilizzando il proprio file system chiamato MapR-FS. I dati HDFS e MapR-FS forniscono informazioni preziose ai data scientist che possono essere sfruttate nell'apprendimento automatico (ML) e nel deep learning (DL). I dati in HDFS e MapR-FS non sono condivisi, il che significa che non possono essere utilizzati da altre applicazioni. I clienti cercano dati condivisi, in particolare nel settore bancario in cui i dati sensibili dei clienti vengono utilizzati da più applicazioni. L'ultima versione di Hadoop (3.x o successiva) supporta l'origine dati NFS, a cui è possibile accedere senza software aggiuntivo di terze parti. Con la nuova funzionalità XCP di NetApp, è possibile spostare i dati direttamente da HDFS e MapR-FS a NetApp NFS per fornire l'accesso a più applicazioni</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">I test sono stati eseguiti in Amazon Web Services (AWS) per trasferire i dati da MapR-FS a NFS per il test iniziale delle performance con 12 nodi MAPR e 4 server NFS.</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">Dimensione</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">VCPU</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="cell">Memoria</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">Rete</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">Server NFS</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">i3en.24xlarge</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488 GiB</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">8 SSD NVMe 7500</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">Nodi MapR</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en.12xLarge</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384GiB</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">4 SSD NVMe 7500</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">In base ai test iniziali, abbiamo ottenuto un throughput di 20 Gbps e siamo stati in grado di trasferire 2 PB al giorno di dati.</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link">TR-4863: TR-4863: Linee guida sulle Best practice per NetApp XCP - Data Mover, migrazione dei file e analisi</block>
  <block id="6371d61614d0beaedb75e85d2c297d8f" category="paragraph">Per ulteriori informazioni sulla migrazione dei dati HDFS senza esportare HDFS in NFS, vedere la sezione "fasi di implementazione - NAS" in<block ref="6a602f6a965c96a94215a45f0077e771" category="inline-link-rx"></block>.</block>
  <block id="aa722a0d50c9e3bfe81a7128f0e649d7" category="inline-link-macro">Avanti: Benefici per il business.</block>
  <block id="4e39bc17db35d21d84b6fb1e9786fdb5" category="paragraph"><block ref="4e39bc17db35d21d84b6fb1e9786fdb5" category="inline-link-macro-rx"></block></block>
  <block id="bf06620c2cdf1b79a1673e62b409eae0" category="summary">La soluzione NetApp per il problema del ridenominazione sciocco offre una forma di storage semplice, economica e gestita centralmente per carichi di lavoro che in precedenza erano incompatibili con NFS.</block>
  <block id="83abec4269fdeaff3d2819895273a563" category="inline-link-macro">Precedente: Panoramica delle performance e validazione con AFF on-premise.</block>
  <block id="d620ffb7e12e202c45f9f8ca1cd8c18a" category="paragraph"><block ref="d620ffb7e12e202c45f9f8ca1cd8c18a" category="inline-link-macro-rx"></block></block>
  <block id="e6f7341043f7816d4a31b223bf8d3be3" category="paragraph">La soluzione NetApp per il problema del ridenominazione sciocco offre una forma di storage semplice, economica e gestita centralmente per carichi di lavoro che in precedenza erano incompatibili con NFS. Questo nuovo paradigma consente ai clienti di creare cluster Kafka più gestibili che siano più facili da migrare e eseguire il mirroring ai fini del disaster recovery e della protezione dei dati. Abbiamo anche visto che NFS offre ulteriori vantaggi, come la riduzione dell'utilizzo della CPU e un tempo di recovery più rapido, un notevole miglioramento dell'efficienza dello storage e migliori performance grazie a NetApp ONTAP.</block>
  <block id="7cd1d87ec9e0fa1c7a867ad6377c7d37" category="paragraph"><block ref="7cd1d87ec9e0fa1c7a867ad6377c7d37" category="inline-link-macro-rx"></block></block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">In questa configurazione, viene illustrato come leggere e scrivere argomenti nello storage a oggetti da Kafka direttamente utilizzando il connettore del sink Kafka s3. Per questo test, abbiamo utilizzato un cluster Confluent autonomo, ma questa configurazione è applicabile a un cluster distribuito.</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">Connettore s3 confluente</block>
  <block id="9b154eb37aabb62c75c78bd31457468f" category="inline-link-macro">Precedente: Test delle performance con scalabilità.</block>
  <block id="aa4f22f43748e77c4fb71f8cb5333c25" category="paragraph"><block ref="aa4f22f43748e77c4fb71f8cb5333c25" category="inline-link-macro-rx"></block></block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">Amazon S3 Sink Connector esporta i dati dagli argomenti di Apache Kafka in oggetti S3 nei formati Avro, JSON o Bytes. Amazon S3 sink Connector esegue periodicamente il polling dei dati da Kafka e a sua volta li carica in S3. Un partitioner viene utilizzato per suddividere i dati di ogni partizione Kafka in blocchi. Ogni blocco di dati viene rappresentato come un oggetto S3. Il nome della chiave codifica l'argomento, la partizione Kafka e l'offset iniziale di questo blocco di dati.</block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">Scarica Confluent Kafka dal sito Web di Confluent.</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">Disimballare il pacchetto in una cartella sul server.</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">Esportare due variabili.</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">Per un'installazione autonoma di Confluent Kafka, il cluster crea una cartella root temporanea in<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block>. Inoltre, crea Zoosekeeper, Kafka, un registro dello schema, Connect, un server ksql, e control center da cui copiare i rispettivi file di configurazione<block ref="5f8dd6e4b96ae5c78585ed0293d4338d" prefix=" " category="inline-code"></block>. Vedere il seguente esempio:</block>
  <block id="fc1644d2d2819b87443b810d963409fa" category="list-text">Configurare Zoosekeeper. Non è necessario modificare nulla se si utilizzano i parametri predefiniti.</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">Nella configurazione precedente, è stato aggiornato il<block ref="2f11dbffae155119df4dc4d60229477e" prefix=" " category="inline-code"></block> proprietà. Per impostazione predefinita, sono necessari tre Zooseeper per la selezione dei leader Kafka.</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">Abbiamo creato un file myid in<block ref="417022983f4126687b04c2a16a36183c" prefix=" " category="inline-code"></block> Con un ID univoco:</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">Abbiamo utilizzato l'ultimo numero di indirizzi IP per il file myid. Abbiamo utilizzato i valori predefiniti per Kafka, CONNECT, Control-Center, Kafka, Kafka-REST, configurazioni del server ksql e del registro di sistema dello schema.</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">Avviare i servizi Kafka.</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">Per ciascuna configurazione è disponibile una cartella di log che consente di risolvere i problemi. In alcuni casi, l'avvio dei servizi richiede più tempo. Assicurarsi che tutti i servizi siano attivi e in esecuzione.</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">Installare Kafka Connect utilizzando<block ref="dcd3bd9446852f6dec3cf416e98154dc" prefix=" " category="inline-code"></block>.</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">È inoltre possibile installare una versione specifica utilizzando<block ref="edb107f75d4831212ad61dd615bc468f" prefix=" " category="inline-code"></block>.</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">Per impostazione predefinita,<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block> è installato in<block ref="6ae652b878f3c54eeaed9d623a1a8c82" prefix=" " category="inline-code"></block>.</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">Aggiornare il percorso del plug-in con il nuovo<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block>.</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">Arrestare e riavviare i servizi confluenti.</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">Configurare l'ID di accesso e la chiave segreta in<block ref="40f203cedcd08f7589920d1a469a96d9" prefix=" " category="inline-code"></block> file.</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">Verificare che il bucket sia raggiungibile.</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">Configurare il file di proprietà s3-sink per la configurazione s3 e bucket.</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">Importare alcuni record nel bucket s3.</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">Caricare il connettore s3-sink.</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">Controllare lo stato del sink s3.</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">Controllare il registro per assicurarsi che s3-sink sia pronto ad accettare gli argomenti.</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">Consulta gli argomenti di Kafka.</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">Controllare gli oggetti nel bucket s3.</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">Per verificare il contenuto, copiare ciascun file da S3 al file system locale eseguendo il seguente comando:</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">Archivi Apache</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">Per stampare i record, utilizzare avro-tools-1.11.0.1.jar (disponibile in<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block>).</block>
  <block id="e621a272d292cd32516db52fc07b5855" category="inline-link-macro">Avanti: Cluster di auto-ribilanciamento confluenti.</block>
  <block id="56b9b2115a3169192950ec86c26f6add" category="paragraph"><block ref="56b9b2115a3169192950ec86c26f6add" category="inline-link-macro-rx"></block></block>
  <block id="fd79b6614eaf33c0131b98cf6d33aef4" category="summary">In questa pagina vengono descritti in dettaglio i principali casi di utilizzo e architetture ai, ML e DL.</block>
  <block id="029e93fe56123e362c90a853d36c91c9" category="doc">Principali casi di utilizzo e architetture ai, ML e DL</block>
  <block id="4204e74b027f3052d00f7e876556fd90" category="inline-link-macro">Precedente: Riepilogo dei casi di utilizzo.</block>
  <block id="8fc7ffb01920f82159e7c7fc73617df5" category="paragraph"><block ref="8fc7ffb01920f82159e7c7fc73617df5" category="inline-link-macro-rx"></block></block>
  <block id="38fe3ee7a8452539638ebb43094bf303" category="paragraph">I principali casi di utilizzo e la metodologia di ai, ML e DL possono essere suddivisi nelle seguenti sezioni:</block>
  <block id="28ab286fd15a84ffcfa82ffe262b2d07" category="section-title">Pipeline SPARK NLP e deduzione distribuita TensorFlow</block>
  <block id="b66d8859b0ca8adab0c5459ef44ed90c" category="paragraph">Il seguente elenco contiene le librerie NLP open-source più diffuse che sono state adottate dalla community di data science con diversi livelli di sviluppo:</block>
  <block id="357d19386660ae0694f2fa195678b61a" category="inline-link">Natural Language Toolkit (NLTK)</block>
  <block id="b7c0dd146600af70e881dce2c233cdb9" category="list-text"><block ref="202d1986e5208977bf54b6b767767c39" category="inline-link-rx"></block>. Il toolkit completo per tutte le tecniche NLP. È stato mantenuto fin dai primi anni 2000.</block>
  <block id="76e3c26aea345cd63928dae30c7683b8" category="inline-link">TextBlob</block>
  <block id="9733a294c2e8cbac3f50f2b1c6165ac9" category="list-text"><block ref="29dbbb204c6bb7c5433e577a001773ba" category="inline-link-rx"></block>. Un tool NLP facile da usare API Python costruita su NLTK e Pattern.</block>
  <block id="b8dc45aaa0db9ddabebf51171beed13a" category="inline-link">Stanford Core NLP</block>
  <block id="e566a3c30415cf2003b1ae965e897b0c" category="list-text"><block ref="3aea58940b1efe70ecaf2254ccc89f1e" category="inline-link-rx"></block>. Servizi e pacchetti NLP in Java sviluppati da Stanford NLP Group.</block>
  <block id="7013def92af3dd7db98d1285170b5c5a" category="inline-link">GENsim</block>
  <block id="f669b3f1322541dcae0edc94f45435ac" category="list-text"><block ref="7b679f834cae0cff7425a8dc62e2ec2e" category="inline-link-rx"></block>. Topic Modeling for Humans è iniziato come una raccolta di script Python per il progetto Czech Digital Mathematics Library.</block>
  <block id="2840ef6b507856e3306a32ffe28a8886" category="inline-link">Spacy</block>
  <block id="418cc23cee80079d8aa2ccd37169bfc0" category="list-text"><block ref="bc5121a0541ff390725a7d480b19b87f" category="inline-link-rx"></block>. Workflow NLP industriali end-to-end con Python e Cython con accelerazione GPU per i trasformatori.</block>
  <block id="e0b205fce51b69be7136044a22a371ab" category="inline-link">Fasttext</block>
  <block id="07ad1b642fbcf4cbc6f67e8f5b7ce593" category="list-text"><block ref="53fd0bea11d98e3b7893bc4fbf501c85" category="inline-link-rx"></block>. Una libreria NLP gratuita, leggera e open-source per l'apprendimento delle parole e la classificazione delle frasi creata dal laboratorio ai Research (FAIR) di Facebook.</block>
  <block id="12680128425c827ef65d76f354329e97" category="inline-link">SPARK ML</block>
  <block id="27e7661d3fd9daf238bb981e30734c3c" category="paragraph">Spark NLP è una soluzione singola e unificata per tutte le attività e i requisiti NLP che consente di ottenere software scalabile, dalle performance elevate e ad alta precisione basato su NLP per casi di utilizzo in produzione reali. Sfrutta l'apprendimento del trasferimento e implementa gli algoritmi e i modelli più recenti nella ricerca e nei vari settori. A causa della mancanza di supporto completo da parte di Spark per le librerie di cui sopra, Spark NLP è stato costruito su<block ref="3b3cfa486b6d50798f20e9b1ded08f31" category="inline-link-rx"></block> Sfruttare il motore di elaborazione dei dati distribuiti in-memory di Spark per scopi generali come libreria NLP di livello Enterprise per flussi di lavoro di produzione mission-critical. I suoi annotatori utilizzano algoritmi basati su regole, machine learning e TensorFlow per potenziare le implementazioni di deep learning. Questo copre i comuni compiti di NLP, inclusi, a titolo esemplificativo ma non esaustivo, la tokenizzazione, la lemmatizzazione, lo stemming, il tagging part-of-speech, il riconoscimento di entità nominate, controllo ortografico e analisi del sentimento.</block>
  <block id="5f29df192bff436cf72d454f30a968c1" category="paragraph">Le rappresentazioni di encoder bidirezionali di Transformers (BERT) sono tecniche di apprendimento automatico basate su trasformatore per NLP. Ha reso popolare il concetto di pre-training e fine tuning. L'architettura dei trasformatori di BERT è nata dalla traduzione automatica, che modella le dipendenze a lungo termine meglio dei modelli di linguaggio basati su Neural Network (RNN) ricorrenti. Ha inoltre introdotto il task Masked Language Modeling (MLM), in cui il 15% casuale di tutti i token viene mascherato e il modello li prevede, consentendo una reale bidirezionalità.</block>
  <block id="8f1fadc17d848b3be53c2009f5f9070a" category="inline-link">FinBERT</block>
  <block id="f12fa7d8a39cc8394ad5dfb1afe14bee" category="inline-link">Reuters TRC2</block>
  <block id="3795ebdf5b8232c65a11ceced659b1d5" category="inline-link">Financial PhraseBank</block>
  <block id="575e9b077146ddbbac786ed0a40a1a21" category="inline-link">Analisi del sentimento per le notizie finanziarie</block>
  <block id="189f0cc22e5920c5fbe48e7f7a384fa4" category="inline-link">Spiegare il documento DL</block>
  <block id="8171f59448f55698ad8ecd07ce1633b6" category="paragraph">L'analisi del sentimento finanziario è complessa a causa del linguaggio specializzato e della mancanza di dati etichettati in quel dominio.<block ref="9c44f0ce83f7021f3ece2b04fda553fb" category="inline-link-rx"></block>, Un modello linguistico basato su BERT preaddestrato, è stato adattato al dominio<block ref="a21d1b93ad8a312fcc9c56c81567ecca" category="inline-link-rx"></block>, un corpus finanziario, e messo a punto con i dati etichettati (<block ref="14fa31c8eadcc29b01046706cfe3add5" category="inline-link-rx"></block>) per la classificazione del sentimento finanziario. I ricercatori hanno estratto 4, 500 frasi dagli articoli di notizie con termini finanziari. Poi 16 esperti e master studenti con background finanziari hanno etichettato le frasi come positive, neutrali e negative. Abbiamo creato un workflow Spark end-to-end per analizzare il sentimento per le trascrizioni delle chiamate delle aziende Top-10 NASDAQ dal 2016 al 2020 utilizzando FinBERT e due altre pipeline preformate (<block ref="6d4ea12c876c5a993aa1b5d0f03f167f" category="inline-link-rx"></block>,<block ref="520f5e4ba9970dad735654cb1f0d1138" category="inline-link-rx"></block>) Di Spark NLP.</block>
  <block id="026dcbbbfad27f6209a41e9dab2f3aed" category="paragraph">Il motore di deep learning sottostante per Spark NLP è TensorFlow, una piattaforma open source end-to-end per l'apprendimento automatico che consente la creazione di modelli semplici, una produzione ML solida ovunque e potenti sperimentazioni per la ricerca. Pertanto, quando si eseguono le nostre pipeline in Spark<block ref="cbfea9758df7100c6471e30d3f36d3e1" prefix=" " category="inline-code"></block> In pratica, abbiamo eseguito TensorFlow distribuito con parallelizzazione di dati e modelli tra un nodo master e più nodi di lavoro, oltre allo storage collegato alla rete montato sul cluster.</block>
  <block id="159bdf3f5d37e56033c6c1736f86b085" category="section-title">Formazione distribuita Horovod</block>
  <block id="ba6c44669e2888938a004611469c95dc" category="inline-link">TR-3969: Soluzioni NetApp per Hadoop</block>
  <block id="6f5ab42847eab5c573282c94e51100a9" category="paragraph">La convalida Hadoop principale per le performance correlate a MapReduce viene eseguita con TeraGen, TeraSort, TeraValidate e DFSIO (lettura e scrittura). I risultati della convalida TeraGen e TeraSort sono presentati nella<block ref="c56c49d0c7359320f900743306997a3c" category="inline-link-rx"></block> Per e-Series e nella sezione "Tiering dello storage" (xref) per AFF.</block>
  <block id="2c41734dc7928bdea8c2eab845ad7074" category="inline-link">Hovorod su Spark</block>
  <block id="7509c08cb8b336b99de5f0cd33f545fd" category="paragraph">In base alle richieste dei clienti, riteniamo che la formazione distribuita con Spark sia uno dei casi di utilizzo più importanti. In questo documento, abbiamo utilizzato<block ref="e46884ff7ae14dc4a4c2907aa0145199" category="inline-link-rx"></block> Per convalidare le performance di Spark con le soluzioni di cloud ibrido, nativo e on-premise di NetApp utilizzando i controller di storage NetApp All Flash FAS (AFF), Azure NetApp Files e StorageGRID.</block>
  <block id="57b5eacba6da62ec21ea18f95421ef6b" category="paragraph">Il pacchetto Horovod on Spark offre un comodo wrapper intorno a Horovod che semplifica l'esecuzione di workload di training distribuiti nei cluster Spark, consentendo un loop di progettazione di modelli ristretti in cui l'elaborazione dei dati, la formazione sui modelli e la valutazione dei modelli vengono eseguite in Spark, dove risiedono i dati di formazione e deduzione.</block>
  <block id="e556cc2b256f6dd2bbe1cdfdb528c858" category="inline-link">Vendita al negozio Kaggle Rossmann</block>
  <block id="f2280eb8ac361218b35f9fc97d4027b4" category="paragraph">Esistono due API per l'esecuzione di Horovod su Spark: Un'API di stima di alto livello e un'API di esecuzione di livello inferiore. Sebbene entrambi utilizzino lo stesso meccanismo sottostante per lanciare Horovod sugli esecutori di Spark, l'API Estimator astratta l'elaborazione dei dati, il loop di training del modello, il checkpoint del modello, la raccolta di metriche e il training distribuito. Abbiamo utilizzato gli stimatori di Horovod Spark, TensorFlow e keras per una preparazione dei dati end-to-end e un workflow di training distribuito basato su<block ref="d30b6f4a07a765f48b43dd15bf3bc8ea" category="inline-link-rx"></block> concorrenza.</block>
  <block id="fa3406903536d0cf09bf8e66ae33aebf" category="inline-link-macro">Script Python per ogni caso di utilizzo principale.</block>
  <block id="94f33f4ba60c5f66bf0c60c3e391a81b" category="paragraph">Lo script<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> si trova nella sezione <block ref="9843d2ebe8b4d4385946214b6f8e40b8" category="inline-link-macro-rx"></block> Contiene tre parti:</block>
  <block id="1e0ac520c0a0627793f8b0ca3703e8e1" category="list-text">La prima parte esegue varie fasi di pre-elaborazione dei dati su un set iniziale di file CSV forniti da Kaggle e raccolti dalla community. I dati di input vengono separati in un set di training con un<block ref="13148717f8faa9037f37d28971dfc219" prefix=" " category="inline-code"></block> e un dataset di test.</block>
  <block id="80ee77d4db5b8f731e911e7c47803afa" category="list-text">La seconda parte definisce un modello di rete neurale profonda (DNN) con funzione di attivazione sigmoid logaritmica e un ottimizzatore Adam, ed esegue un training distribuito del modello utilizzando Horovod su Spark.</block>
  <block id="6c32e5a10a8b9f7e225e92b30c4eb494" category="list-text">La terza parte esegue la previsione sul set di dati di test utilizzando il modello migliore che riduce al minimo l'errore medio assoluto complessivo del set di convalida. Viene quindi creato un file CSV di output.</block>
  <block id="ca1ff924f88675800b52c7c1b223b4a2" category="inline-link-macro">"Apprendimento automatico"</block>
  <block id="a67083c66285446e108268f795b72b24" category="paragraph">Vedere la sezione <block ref="65cdc2076a502903b78fb8128fc1a214" category="inline-link-macro-rx"></block> per diversi risultati di confronto tra runtime.</block>
  <block id="840da3122eba37f84480a8dc769a8cc3" category="section-title">Deep learning multi-worker con keras per la previsione CTR</block>
  <block id="0359d40b3d1a900a1841f1e8bd783cd5" category="inline-link">TR-4904: Formazione distribuita in Azure - previsione dei tassi click-through</block>
  <block id="4debf96216c552af520b74d3d0d2f2dc" category="paragraph">Con i recenti progressi nelle piattaforme E nelle applicazioni ML, è ora molto importante concentrarsi sull'apprendimento su larga scala. Il tasso di click-through (CTR) è definito come il numero medio di click-through per cento impressioni di annunci online (espresso in percentuale). È ampiamente adottato come parametro chiave in diversi mercati verticali e casi di utilizzo del settore, tra cui digital marketing, retail, e-commerce e service provider. Consulta la nostra<block ref="5e9febd4c244550b32d7bb781b595741" category="inline-link-rx"></block> Per ulteriori dettagli sulle applicazioni di CTR e un'implementazione del workflow ai cloud end-to-end con Kubernetes, ETL di dati distribuiti e training sui modelli con DAK e CUDA ML.</block>
  <block id="45c832c8d01426bfb65d74b7c547ad0c" category="inline-link">Set di dati Click Logs Criteo Terabyte</block>
  <block id="be1115ec919e48805da898209ea2c15a" category="paragraph">In questo report tecnico abbiamo utilizzato una variante di<block ref="1a19f40e7660b78c77663f74c89e1e7b" category="inline-link-rx"></block> (Vedere TR-4904) per l'apprendimento approfondito distribuito multi-worker che utilizza keras per creare un workflow Spark con modelli DCN (Deep and Cross Network), confrontando le sue performance in termini di funzione di errore di perdita di log con un modello di riferimento Spark ML Logistic Regression. DCN acquisisce in modo efficiente le interazioni efficaci delle funzioni di gradi limitati, apprende interazioni altamente non lineari, non richiede alcuna progettazione manuale delle funzioni o ricerca completa e ha un costo di calcolo basso.</block>
  <block id="71b755d753dcdba2aeca91b65c167330" category="paragraph">I dati per i sistemi recommender su scala web sono per lo più discreti e categorici, il che porta a un ampio e sparso spazio di funzionalità che è difficile per l'esplorazione delle funzionalità. Questo ha limitato la maggior parte dei sistemi su larga scala a modelli lineari come la regressione logistica. Tuttavia, l'identificazione delle funzionalità spesso predittive e allo stesso tempo l'esplorazione di funzioni incrociate rare o invisibili è la chiave per fare buone previsioni. I modelli lineari sono semplici, interpretabili e facili da scalare, ma sono limitati nel loro potere espressivo.</block>
  <block id="793743a945a26aaa07de844420d013af" category="paragraph">Le funzionalità incrociate, d'altro canto, si sono dimostrate significative nel migliorare l'espressività dei modelli. Sfortunatamente, spesso richiede un'ingegneria delle funzionalità manuale o una ricerca completa per identificare tali funzionalità. La generalizzazione di interazioni di funzionalità non visibili è spesso difficile. L'utilizzo di una rete interneurale come DCN evita l'ingegneria delle funzionalità specifiche dell'attività, applicando esplicitamente il passaggio delle funzionalità in modo automatico. La rete incrociata è costituita da più livelli, in cui il più alto grado di interazione è determinato in modo probabile dalla profondità del livello. Ogni livello produce interazioni di ordine superiore in base a quelle esistenti e mantiene le interazioni dai livelli precedenti.</block>
  <block id="70725839e7d887ef6f8c815f325d4592" category="paragraph">Una rete neurale profonda (DNN) ha la promessa di acquisire interazioni molto complesse tra le varie funzionalità. Tuttavia, rispetto alla rete DCN, richiede quasi un ordine di grandezza più parametri, non è in grado di formare funzioni incrociate in modo esplicito e potrebbe non riuscire ad apprendere in modo efficiente alcuni tipi di interazioni tra funzionalità. La rete è efficiente in termini di memoria e facile da implementare. La formazione congiunta dei componenti Cross e DNN acquisisce in modo efficiente le interazioni predittive delle funzionalità e offre performance all'avanguardia sul set di dati CTR Criteo.</block>
  <block id="9830e1f81f623b33106acc186b93374e" category="inline-link">ml</block>
  <block id="fefc70efb4580c1020c62303f76330f7" category="inline-link">mllib</block>
  <block id="2c9e5f067c0c14c56aa757d792108648" category="inline-link">DeepCTR</block>
  <block id="75e8e622ae2ef0cb646ef505a0b3f7be" category="paragraph">Un modello DCN inizia con un livello di incorporamento e stacking, seguito da una rete incrociata e una rete profonda in parallelo. Questi a loro volta sono seguiti da un livello di combinazione finale che combina le uscite dalle due reti. I dati di input possono essere un vettore con funzioni sparse e dense. In Spark, entrambi<block ref="e0c7aa0ef7a63ea331cba99be2697841" category="inline-link-rx"></block> e.<block ref="495fc8cfd173be827e5c6c8258a34e04" category="inline-link-rx"></block> le librerie contengono il tipo<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block>. È quindi importante che gli utenti distinguano i due e si ricordino quando chiamano le rispettive funzioni e metodi. Nei sistemi recommender su scala web come la previsione CTR, gli input sono per lo più caratteristiche categoriche, ad esempio<block ref="bf8b858b1d67b8d7c2676d6a7353c3c9" prefix=" " category="inline-code"></block>. Tali caratteristiche sono spesso codificate come vettori one-hot, ad esempio,<block ref="624411787ac52373d7cc41183768999c" prefix=" " category="inline-code"></block>. One-hot-encoding (OHE) con<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block> è utile quando si gestiscono set di dati reali con vocabolari in continua evoluzione e in crescita. Abbiamo modificato gli esempi in<block ref="0be922124247f224cab64b030781eed7" category="inline-link-rx"></block> Elaborare vocabolari di grandi dimensioni, creando vettori di incorporamento nel livello di incorporamento e stacking della nostra rete DCN.</block>
  <block id="565d2d07d9c220babb78adab27c2243a" category="inline-link">Dataset Criteo Display Ads</block>
  <block id="d05de658e793ee731e5a3782c453caa6" category="paragraph">Il<block ref="8cb83117ecfa6e6678785dbda34d1999" category="inline-link-rx"></block> prevede il tasso di click-through degli annunci. Dispone di 13 caratteristiche intere e 26 caratteristiche categoriche in cui ogni categoria ha un'elevata cardinalità. Per questo set di dati, un miglioramento di 0.001 nella perdita di log è praticamente significativo a causa delle grandi dimensioni dell'input. Un piccolo miglioramento della precisione di previsione per una base di utenti di grandi dimensioni può potenzialmente portare a un aumento significativo dei ricavi di un'azienda. Il set di dati contiene 11 GB di log utente da un periodo di 7 giorni, che equivale a circa 41 milioni di record. Abbiamo utilizzato Spark<block ref="26ef62452ce5167b94d9bf8e4552df44" prefix=" " category="inline-code"></block> suddividere casualmente i dati per il training (80%), la convalida incrociata (10%) e il restante 10% per il test.</block>
  <block id="e871e132ed2e9c6d6213da57972adec1" category="paragraph">DCN è stato implementato su TensorFlow con keras. L'implementazione del processo di training del modello con DCN comprende quattro componenti principali:</block>
  <block id="18aca2eb061782e34fcc772d780e4327" category="list-text">*Elaborazione e incorporamento dei dati.* le funzionalità a valore reale vengono normalizzate applicando una trasformazione del log. Per le funzionalità categoriche, le funzionalità sono incorporate in vettori densi di dimensione 6×(categoria cardinalità)1/4. Concatenando tutte le incorporazioni si ottiene un vettore di dimensione 1026.</block>
  <block id="190befa8188b0e07126d23d7488e79e7" category="list-text">*Optimization.* abbiamo applicato l'ottimizzazione stocastica mini-batch con Adam Optimizer. La dimensione del batch è stata impostata su 512. La normalizzazione batch è stata applicata alla rete profonda e la norma del gradiente clip è stata impostata su 100.</block>
  <block id="023b8b252258fa415118862dec994bbf" category="list-text">*Regolarizzazione.* abbiamo utilizzato la sospensione anticipata, in quanto la regolarizzazione L2 o il dropout non sono stati trovati efficaci.</block>
  <block id="5f7ce3c44b690052b88504fd4c0ff7bb" category="list-text">*Hyperparameters.* i risultati vengono riportati in base a una ricerca in griglia sul numero di livelli nascosti, la dimensione del livello nascosto, la velocità di apprendimento iniziale e il numero di livelli incrociati. Il numero di livelli nascosti variava da 2 a 5, con dimensioni dei livelli nascosti comprese tra 32 e 1024. Per DCN, il numero di strati incrociati era da 1 a 6. Il tasso di apprendimento iniziale è stato ottimizzato da 0.0001 a 0.001 con incrementi di 0.0001. Tutti gli esperimenti hanno subito interrotto la fase di training 150,000, oltre la quale ha iniziato a verificarsi un overfitting.</block>
  <block id="a5203fd5d2ee4a156e177b2b5b5ecb45" category="inline-link">DeepFM</block>
  <block id="ca099c15c1ba89f9956f37979064b6ea" category="inline-link">XDeepFM</block>
  <block id="43d5f147547ecf24ebc038feb06a8312" category="inline-link">Int. Auto</block>
  <block id="79249d5f44965bf593f3105190bac784" category="inline-link">DCN v2</block>
  <block id="ebca0d5eb18ce917a3f0d2d49746eb3d" category="paragraph">Oltre a DCN, abbiamo anche testato altri modelli di deep-learning molto diffusi per la previsione CTR, tra cui<block ref="256b68047e4850e72fc6a1a263d88e86" category="inline-link-rx"></block>,<block ref="dc65ad48383bc08407486976f4411f66" category="inline-link-rx"></block>,<block ref="a61c3ddacc920697ed1145d7ed359d25" category="inline-link-rx"></block>, e.<block ref="8b59d0e884bf752e43135b866516c089" category="inline-link-rx"></block>.</block>
  <block id="408be753ce98edae615db82036085d63" category="section-title">Architetture utilizzate per la convalida</block>
  <block id="2150013c97241fde077622292dd996b4" category="paragraph">Per questa convalida, abbiamo utilizzato quattro nodi di lavoro e un nodo master con una coppia ha AFF-A800. Tutti i membri del cluster erano connessi tramite switch di rete 10 GbE.</block>
  <block id="de404d7688ac5c78348bfea711a12792" category="paragraph">Per la convalida della soluzione NetApp Spark, abbiamo utilizzato tre diversi controller di storage: E5760, E5724 e AFF-A800. I controller di storage e-Series erano collegati a cinque nodi dati con connessioni SAS a 12 Gbps. Il controller di storage AFF ha-Pair offre volumi NFS esportati attraverso connessioni 10 GbE ai nodi di lavoro Hadoop. I membri del cluster Hadoop erano connessi tramite connessioni 10GbE nelle soluzioni e-Series, AFF e StorageGRID Hadoop.</block>
  <block id="f3952bdea9a512245a3b2e368bdd17a4" category="inline-image-macro">Architetture utilizzate per la convalida.</block>
  <block id="2f2f17293788ab5e5b754a35afe8b3b5" category="paragraph"><block ref="2f2f17293788ab5e5b754a35afe8b3b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d69bb7b5d4a03684a8454a168278a99a" category="inline-link-macro">Segue: Risultati del test.</block>
  <block id="8e32abf231872a250f5352294ee7f66d" category="paragraph"><block ref="8e32abf231872a250f5352294ee7f66d" category="inline-link-macro-rx"></block></block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">In questa convalida, abbiamo utilizzato quattro server come server NSD (Network Shared Disk) per fornire dischi fisici per GPFS. LE GPF vengono create sui dischi NSD per esportarle come esportazioni NFS in modo che i client NFS possano accedervi, come mostrato nella figura seguente. Abbiamo utilizzato XCP per copiare i dati da NFS esportati da GPFS in un volume NetApp NFS.</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">GPF per NetApp ONTAP NFS</block>
  <block id="823313a32a4a1131e0469fac26acbdac" category="inline-link-macro">Precedente: Soluzione data mover per l'ai.</block>
  <block id="c4e4b7ebe157b09b7d1a0db25078dc45" category="paragraph"><block ref="c4e4b7ebe157b09b7d1a0db25078dc45" category="inline-link-macro-rx"></block></block>
  <block id="9a1bdf4376c8448278cf38263e4da8c7" category="paragraph"><block ref="9a1bdf4376c8448278cf38263e4da8c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">Elementi essenziali DELLA GPF</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">In GPFS vengono utilizzati i seguenti tipi di nodo:</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">*Admin node.* specifica un campo opzionale contenente un nome di nodo utilizzato dai comandi di amministrazione per comunicare tra i nodi. Ad esempio, il nodo admin<block ref="f2fde43b571e78e29f67743af45165cb" prefix=" " category="inline-code"></block> può passare un controllo di rete a tutti gli altri nodi del cluster.</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">Nodo *Quorum.* determina se un nodo è incluso nel pool di nodi da cui è derivato il quorum. È necessario almeno un nodo come nodo di quorum.</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">*Manager Node.* indica se un nodo fa parte del pool di nodi da cui è possibile selezionare i gestori del file system e i gestori dei token. È consigliabile definire più di un nodo come nodo manager. Il numero di nodi da assegnare come manager dipende dal carico di lavoro e dal numero di licenze del server GPFS di cui si dispone. Se si eseguono lavori paralleli di grandi dimensioni, potrebbero essere necessari più nodi di gestione rispetto a un cluster a quattro nodi che supporta un'applicazione Web.</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">*Server NSD.* il server che prepara ogni disco fisico per l'utilizzo con GPFS.</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">*Protocol node.* nodo che condivide i dati GPFS direttamente tramite qualsiasi protocollo SSH (Secure Shell) con NFS. Questo nodo richiede una licenza server GPFS.</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">Elenco delle operazioni per GPFS, NFS e XCP</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">Questa sezione fornisce l'elenco delle operazioni che creano GPFS, esportano GPFS come esportazione NFS e trasferiscono i dati utilizzando XCP.</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">Creare GPFS</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">Per creare GPFS, attenersi alla seguente procedura:</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">Scaricare e installare l'accesso ai dati in scala di spettro per la versione Linux su uno dei server.</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">Installare il pacchetto prerequisito (ad esempio Chef) in tutti i nodi e disattivare Security-Enhanced Linux (SELinux) in tutti i nodi.</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">Impostare il nodo di installazione e aggiungere il nodo admin e il nodo GPFS al file di definizione del cluster.</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">Aggiungere il nodo manager, il nodo quorum, i server NSD e il nodo GPFS.</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">Aggiungere i nodi GUI, admin e GPFS e, se necessario, aggiungere un server GUI aggiuntivo.</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">Aggiungere un altro nodo GPFS e controllare l'elenco di tutti i nodi.</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">Specificare un nome cluster, un profilo, un binario shell remoto, un binario copia file remoto e un intervallo di porte da impostare su tutti i nodi GPFS nel file di definizione del cluster.</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">Visualizzare le impostazioni di configurazione GPFS e aggiungere un nodo admin aggiuntivo.</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">Disattivare la raccolta di dati e caricare il pacchetto di dati su IBM Support Center.</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">Abilitare NTP e controllare le configurazioni prima dell'installazione.</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">Configurare, creare e controllare i dischi NSD.</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">Creare il GPFS.</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">Montare il GPFS.</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">Verificare e fornire le autorizzazioni necessarie per GPFS.</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">Verificare la lettura e la scrittura del GPFS eseguendo<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> comando.</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">Esportare GPFS in NFS</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">Per esportare GPFS in NFS, attenersi alla seguente procedura:</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">Esportare GPFS come NFS tramite<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> file.</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">Installare i pacchetti server NFS richiesti.</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">Avviare il servizio NFS.</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">Elencare i file nella GPFS per convalidare il client NFS.</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">Configurare il client NFS</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">Per configurare il client NFS, attenersi alla seguente procedura:</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">Esportare il GPFS come NFS attraverso<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> file.</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">Avviare i servizi client NFS.</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">Montare il GPFS tramite il protocollo NFS sul client NFS.</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">Convalidare l'elenco dei file GPFS nella cartella NFS Mounted.</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">Spostare i dati da NFS esportati da GPFS a NetApp NFS utilizzando XCP.</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">Convalidare i file GPFS sul client NFS.</block>
  <block id="ae2b7fcf15ee142a2de2b3ba9573b414" category="inline-link-macro">Avanti: Da HDFS e MapR-FS a NFS ONTAP.</block>
  <block id="545d9ad8cb56e65641eb4e8083301a39" category="paragraph"><block ref="545d9ad8cb56e65641eb4e8083301a39" category="inline-link-macro-rx"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">Questo test si basa sulla funzionalità dei cluster a bilanciamento automatico, che automatizza il ribilanciamento in base alle modifiche della topologia del cluster o al carico non uniforme.</block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">Clusters a bilanciamento automatico confluente</block>
  <block id="6dec1258fbcccbfaa7098758abb00055" category="inline-link-macro">Precedente: Connettore kafka s3.</block>
  <block id="6e3bea5fe8473b6e884edafaf7fcf1d4" category="paragraph"><block ref="6e3bea5fe8473b6e884edafaf7fcf1d4" category="inline-link-macro-rx"></block></block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">Se hai già gestito un cluster Kafka in precedenza, probabilmente conosci le sfide legate alla riassegnazione manuale delle partizioni a diversi broker per garantire che il carico di lavoro sia bilanciato in tutto il cluster. Per le organizzazioni con implementazioni Kafka di grandi dimensioni, rimescolare grandi quantità di dati può essere scoraggiante, noioso e rischioso, soprattutto se le applicazioni mission-critical sono costruite sul cluster. Tuttavia, anche per i più piccoli casi di utilizzo di Kafka, il processo richiede tempo e può essere soggetto a errori umani.</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">Nel nostro laboratorio, abbiamo testato la funzionalità dei cluster di bilanciamento automatico Confluent, che automatizza il ribilanciamento in base alle modifiche della topologia dei cluster o al carico non uniforme. Il test di ribilanciamento confluente consente di misurare il tempo necessario per aggiungere un nuovo broker quando un guasto al nodo o il nodo di scalabilità richiede il ribilanciamento dei dati tra broker. Nelle configurazioni Kafka classiche, la quantità di dati da ribilanciare aumenta con la crescita del cluster, ma, nello storage a più livelli, il ribilanciamento è limitato a una piccola quantità di dati. In base alla nostra convalida, il ribilanciamento dello storage a più livelli richiede secondi o minuti in una classica architettura Kafka e cresce linearmente con la crescita del cluster.</block>
  <block id="c9e4cfc44588cc591252c88cad0a3a09" category="paragraph">Nei cluster con bilanciamento automatico, i ribilanciamenti delle partizioni sono completamente automatizzati per ottimizzare il throughput di Kafka, accelerare la scalabilità dei broker e ridurre il carico operativo di un cluster di grandi dimensioni. A stato stazionario, i cluster con bilanciamento automatico monitorano l'inclinazione dei dati tra i broker e riassegnano continuamente le partizioni per ottimizzare le performance del cluster. Quando la piattaforma viene scalata verso l'alto o verso il basso, i cluster a bilanciamento automatico riconoscono automaticamente la presenza di nuovi broker o la rimozione di vecchi broker e attivano una successiva riassegnazione delle partizioni. In questo modo potrai aggiungere e decommissionare facilmente i broker, rendendo i cluster Kafka fondamentalmente più elastici. Questi vantaggi non richiedono interventi manuali, calcoli complessi o il rischio di errori umani che le riassegnazioni delle partizioni comportano in genere. Di conseguenza, i ribilanciamenti dei dati vengono completati in meno tempo e puoi concentrarti su progetti di streaming di eventi di valore superiore, invece di dover monitorare costantemente i tuoi cluster.</block>
  <block id="cc87abc70119e2ad833c42a865a33659" category="inline-link-macro">Segue: Linee guida sulle Best practice.</block>
  <block id="caf8da5a9482899a1495e1e052a4b287" category="paragraph"><block ref="caf8da5a9482899a1495e1e052a4b287" category="inline-link-macro-rx"></block></block>
  <block id="edeeafbd44ff39ea2ff14f5de4488b69" category="summary">Questa pagina descrive le diverse aree in cui è possibile utilizzare questa soluzione.</block>
  <block id="bf9bdab57c82171f2cc9bcebdc37b2c2" category="doc">Riepilogo del caso d'utilizzo</block>
  <block id="2a4bf885433f99fb55281d25340cf2b5" category="inline-link-macro">Precedente: Panoramica delle soluzioni NetApp Spark.</block>
  <block id="105ad1f4294f02452bad1ed7ad67aa5d" category="paragraph"><block ref="105ad1f4294f02452bad1ed7ad67aa5d" category="inline-link-macro-rx"></block></block>
  <block id="badfbf9255d6b555592b41ab34e4efc6" category="section-title">Dati in streaming</block>
  <block id="4cc7dbb8e0e56a0e190e0ad588a8ba78" category="paragraph">Apache Spark è in grado di elaborare i dati in streaming, utilizzati per processi di estrazione, trasformazione e carico (ETL) in streaming, per l'arricchimento dei dati, per l'attivazione del rilevamento degli eventi e per analisi complesse delle sessioni:</block>
  <block id="35658693f34a1c5dc8b752f79caeb198" category="list-text">*Streaming ETL.* i dati vengono continuamente ripuliti e aggregati prima di essere inseriti negli archivi dati. Netflix utilizza lo streaming di Kafka e Spark per creare una soluzione di monitoraggio dei dati e consigli sui film online in tempo reale in grado di elaborare miliardi di eventi al giorno da diverse origini dati. Tuttavia, l'ETL tradizionale per l'elaborazione in batch viene trattato in modo diverso. Questi dati vengono letti per primi, quindi convertiti in un formato di database prima di essere scritti nel database.</block>
  <block id="1e8d9d663f583499f32f92ca2486e7df" category="list-text">*Arricchimento dei dati.* lo streaming Spark arricchisce i dati live con dati statici per consentire un'analisi dei dati più in tempo reale. Ad esempio, gli inserzionisti online possono fornire annunci personalizzati e mirati, diretti in base alle informazioni sul comportamento dei clienti.</block>
  <block id="e3c0d503686e9ab8960903bc80d3f700" category="list-text">*Rilevamento eventi trigger.* lo streaming Spark consente di rilevare e rispondere rapidamente a comportamenti anomali che potrebbero indicare problemi potenzialmente gravi. Ad esempio, gli istituti finanziari utilizzano i trigger per rilevare e arrestare le transazioni di frode, mentre gli ospedali utilizzano i trigger per rilevare i cambiamenti sanitari pericolosi rilevati nei segni vitali di un paziente.</block>
  <block id="af8f12b6a4cff696802c46442e36e264" category="list-text">*Analisi complessa della sessione.* lo streaming di Spark raccoglie eventi come l'attività dell'utente dopo l'accesso a un sito Web o a un'applicazione, che vengono quindi raggruppati e analizzati. Ad esempio, Netflix utilizza questa funzionalità per fornire consigli sui filmati in tempo reale.</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="inline-link">TR-4912: Linee guida sulle Best practice per lo storage a più livelli Confluent Kafka con NetApp</block>
  <block id="61fb23ef88a4d1404b2410cf94238fb5" category="paragraph">Per ulteriori informazioni su configurazione dei dati in streaming, verifica di Confluent Kafka e test delle performance, consulta<block ref="10063fdbf72f58440f18bb49eb2309fe" category="inline-link-rx"></block>.</block>
  <block id="2a80513f40f0c2a9c11009fa83049bd9" category="section-title">Apprendimento automatico</block>
  <block id="c2e9a1abebd45c1d446eb49fb690afd7" category="paragraph">Il framework integrato Spark consente di eseguire query ripetute sui set di dati utilizzando la libreria di apprendimento automatico (MLlib). MLlib viene utilizzato in aree come clustering, classificazione e riduzione delle dimensioni per alcune funzioni comuni dei big data, come l'intelligence predittiva, la segmentazione dei clienti per scopi di marketing e l'analisi del sentimento. MLlib viene utilizzato nella sicurezza di rete per eseguire ispezioni in tempo reale dei pacchetti di dati per indicazioni di attività dannose. Aiuta i provider di sicurezza a conoscere le nuove minacce e a restare al passo con gli hacker, proteggendo i propri clienti in tempo reale.</block>
  <block id="03d3e10f072ae25d491b55767b4fc37e" category="section-title">Apprendimento approfondito</block>
  <block id="b45690b6bb62bd55da7e1911ed880ec6" category="paragraph">TensorFlow è un framework di deep learning diffuso in tutto il settore. TensorFlow supporta la formazione distribuita su un cluster di CPU o GPU. Questo training distribuito consente agli utenti di eseguirlo su una grande quantità di dati con molti livelli profondi.</block>
  <block id="9981faa66d13ca7ba415a6c70dc52893" category="paragraph">Fino a poco tempo fa, se volevamo utilizzare TensorFlow con Apache Spark, dovevamo eseguire tutte le ETL necessarie per TensorFlow in PySpark e quindi scrivere i dati nello storage intermedio. Tali dati verranno quindi caricati nel cluster TensorFlow per l'effettivo processo di training. Questo flusso di lavoro richiedeva all'utente di mantenere due diversi cluster, uno per ETL e uno per la formazione distribuita di TensorFlow. L'esecuzione e la manutenzione di più cluster erano in genere noiose e dispendiose in termini di tempo.</block>
  <block id="082ad29f115c5cd4ab167c596b90688c" category="paragraph">DataFrame e RDD nelle versioni precedenti di Spark non erano adatti per l'apprendimento approfondito perché l'accesso casuale era limitato. In Spark 3.0 con il progetto Hydrogen, è stato aggiunto il supporto nativo per i framework di deep learning. Questo approccio consente la pianificazione non basata su MapReduce sul cluster Spark.</block>
  <block id="44cd5d1ec9ffc51f82d838faf685ef6e" category="section-title">Analisi interattiva</block>
  <block id="11bb4412e7e82514a739cb60053e30df" category="paragraph">Apache Spark è abbastanza veloce da eseguire query esplorative senza campionamenti con linguaggi di sviluppo diversi da Spark, tra cui SQL, R e Python. SPARK utilizza strumenti di visualizzazione per elaborare dati complessi e visualizzarli in modo interattivo. Spark with Structured streaming esegue query interattive in base ai dati in tempo reale in analisi web che consentono di eseguire query interattive in base alla sessione corrente di un visitatore web.</block>
  <block id="d89f01bf7c0ceacaf30849bab08e0939" category="section-title">Sistema consigliato</block>
  <block id="38c79706797b854a06f30876828ee766" category="paragraph">Nel corso degli anni, i sistemi di recommender hanno apportato enormi cambiamenti alla nostra vita, in quanto aziende e consumatori hanno risposto a cambiamenti drastici nello shopping online, nell'intrattenimento online e in molti altri settori. In effetti, questi sistemi sono tra i casi di successo più evidenti dell'ai in produzione. In molti casi pratici di utilizzo, i sistemi consigliati sono combinati con i chatbot o ai conversazionali interfacciati con un backend NLP per ottenere informazioni rilevanti e produrre utili inferenze.</block>
  <block id="6346d11f3fda24eb2d12fa4ac478fe3b" category="paragraph">Oggi, molti retailer stanno adottando modelli di business più recenti, come l'acquisto online e il ritiro in negozio, il ritiro in marciapiede, il pagamento automatico, la scansione e la partenza e molto altro ancora. Questi modelli sono diventati preminenti durante la pandemia di COVID-19, rendendo gli acquisti più sicuri e convenienti per i consumatori. L'ai è fondamentale per queste tendenze digitali in crescita, che sono influenzate dal comportamento dei consumatori e viceversa. Per soddisfare le crescenti esigenze dei consumatori, aumentare l'esperienza del cliente, migliorare l'efficienza operativa e aumentare i ricavi, NetApp aiuta i clienti aziendali e le aziende a utilizzare algoritmi di apprendimento automatico e di deep learning per progettare sistemi di raccomandazione più rapidi e precisi.</block>
  <block id="b32f1d719ba1fea2cad3538a4795c552" category="paragraph">Esistono diverse tecniche utilizzate per fornire consigli, tra cui il filtraggio collaborativo, i sistemi basati sui contenuti, il modello DLRM (Deep Learning recommender Model) e le tecniche ibride. In precedenza, i clienti utilizzavano PySpark per implementare il filtraggio collaborativo per la creazione di sistemi di raccomandazione. Spark MLlib implementa Alternating Least Squares (ALS) per il filtraggio collaborativo, un algoritmo molto popolare tra le aziende prima dell'ascesa di DLRM.</block>
  <block id="9389b39b238fbd5ad61de2fea371853d" category="section-title">Elaborazione del linguaggio naturale</block>
  <block id="18bfab6309a4addeb7e1dae07d2a4b89" category="inline-link">Gartner</block>
  <block id="47fa981bf7641c90f0ce83a88c21234e" category="paragraph">L'intelligenza artificiale conversa, resa possibile dall'elaborazione del linguaggio naturale (NLP), è il ramo dell'intelligenza artificiale che aiuta i computer a comunicare con gli esseri umani. La tecnologia NLP è prevalente in tutti i mercati verticali del settore e in molti casi di utilizzo, dagli smart Assistant ai chatbot, alla ricerca con Google e al testo predittivo. Secondo a.<block ref="be3a50ddc5683c6936ee69409b86e212" category="inline-link-rx"></block> Secondo le previsioni, entro il 2022, il 70% delle persone interagirà quotidianamente con le piattaforme di ai convergenti. Per una conversazione di alta qualità tra un essere umano e una macchina, le risposte devono essere rapide, intelligenti e naturali.</block>
  <block id="9cac4209da8ee0481a45fa299b66e587" category="paragraph">I clienti hanno bisogno di una grande quantità di dati per elaborare e formare i propri modelli NLP e ASR (Automatic Speech Recognition). Devono anche spostare i dati all'edge, al core e al cloud e hanno bisogno della potenza necessaria per eseguire l'inferenza in millisecondi per stabilire una comunicazione naturale con gli esseri umani. NetApp ai e Apache Spark sono la combinazione ideale per calcolo, storage, elaborazione dei dati, training sui modelli, messa a punto, e implementazione.</block>
  <block id="33984e410ab674dcea1f21af4c5db4ec" category="paragraph">L'analisi del sentimento è un campo di studio all'interno di NLP in cui i sentimenti positivi, negativi o neutri vengono estratti dal testo. L'analisi del sentimento ha una varietà di casi di utilizzo, dalla determinazione delle performance dei dipendenti del centro di supporto nelle conversazioni con i chiamanti alla fornitura di risposte dei chatbot automatizzate appropriate. Inoltre, è stato utilizzato per prevedere il prezzo delle azioni di un'azienda in base alle interazioni tra i rappresentanti dell'azienda e il pubblico durante le chiamate trimestrali sui guadagni. Inoltre, l'analisi del sentimento può essere utilizzata per determinare la posizione del cliente sui prodotti, servizi o supporto forniti dal marchio.</block>
  <block id="511405f2428e9a6a71530b7f2cdcbc21" category="inline-link">John Snow Labs</block>
  <block id="351594930581e8fa82cf694de7562fd2" category="inline-link">sentimento di notizie finanziarie</block>
  <block id="322f98ff217f4c12ea8f1b3ea41f4024" category="paragraph">Abbiamo utilizzato<block ref="0f17ea1334fb20ed83c3ab03268616d7" category="inline-link-rx"></block> libreria da<block ref="22825786ea861b373c2a5fdda9f62d81" category="inline-link-rx"></block> Per caricare pipeline preaddestrate e rappresentazioni di encoder bidirezionali da modelli di Transformers (BERT), tra cui<block ref="25bfdf207733b5ead40d4d36ea328e85" category="inline-link-rx"></block> e.<block ref="9c44f0ce83f7021f3ece2b04fda553fb" category="inline-link-rx"></block>, esecuzione di togenizzazione, riconoscimento di entità denominate, training sui modelli, analisi di adattamento e sentimento su larga scala. Spark NLP è l'unica libreria NLP open-source in produzione che offre trasformatori all'avanguardia come BERT, ALBERT, ELECTRA, XLNet, DistillBERT, Roberta, DeBERTA, XLM-Roberta, Longformer, ELMO, Universal sentence Encoder, Google T5, MarianMT e GPT2. La libreria funziona non solo in Python e R, ma anche nell'ecosistema JVM (Java, Scala e Kotlin) su larga scala estendendo Apache Spark in modo nativo.</block>
  <block id="e4f0ac4ff07b9b5031299d0b3702fedb" category="inline-link-macro">Avanti: Principali casi di utilizzo e architetture di ai, ML e DL.</block>
  <block id="84fcdcaf39dee89e28f1b44c28ad46ef" category="paragraph"><block ref="84fcdcaf39dee89e28f1b44c28ad46ef" category="inline-link-macro-rx"></block></block>
  <block id="34ea6423c17a78bdf284132538078bac" category="summary">Questo documento descrive i seguenti argomenti, il problema di ridenominazione e la convalida della soluzione, riducendo l'utilizzo della CPU per ridurre il tempo di attesa i/o, accelerando il tempo di recovery del broker Kafka e le performance nel cloud e on-premise.</block>
  <block id="47e33b895b285760d0d1bcb64e42e5d0" category="doc">TR-4947: Carico di lavoro Apache Kafka con storage NetApp NFS - convalida funzionale e performance</block>
  <block id="62233ad21bd81bbbff938616c0106477" category="paragraph">Shantanu Chakole, Karthikeyan Nagalingam e Joe Scott, NetApp</block>
  <block id="8150fcf9bdcb89b4901e10f34571667e" category="paragraph">Kafka è un sistema di messaggistica distribuito publish-subscribe con una solida coda in grado di accettare grandi quantità di dati dei messaggi. Con Kafka, le applicazioni possono scrivere e leggere i dati su argomenti in modo molto rapido. A causa della sua tolleranza agli errori e della sua scalabilità, Kafka viene spesso utilizzato nel grande spazio di dati come un modo affidabile per acquisire e spostare molti flussi di dati molto rapidamente. I casi di utilizzo includono elaborazione dello streaming, monitoraggio delle attività del sito Web, raccolta e monitoraggio delle metriche, aggregazione dei log, analisi in tempo reale e così via.</block>
  <block id="91bd7e3ce9e18912d60b1c4cd3f9f7d2" category="inline-link">ridenominazione sciocco</block>
  <block id="7453e2e58a9df0c80d79a8fd0ab4ed1e" category="paragraph">Anche se le normali operazioni di Kafka su NFS funzionano bene, il<block ref="99770e723960c674a5dd9394155d2111" category="inline-link-rx"></block> Il problema blocca l'applicazione durante il ridimensionamento o la partizione di un cluster Kafka in esecuzione su NFS. Si tratta di un problema significativo perché un cluster Kafka deve essere ridimensionato o ripartizionato a scopo di bilanciamento del carico o di manutenzione. Ulteriori dettagli sono disponibili<block ref="eff8c14b44ddf611b2ff09607d7665a2" category="inline-link-rx"></block>.</block>
  <block id="229b214236b3c346dc9f6c75d096604b" category="paragraph">Questo documento descrive i seguenti argomenti:</block>
  <block id="995fd45f2f5174bc9a5d8029655c1b88" category="list-text">Il problema di ridenominazione e la convalida della soluzione</block>
  <block id="7c9e8a4fdb767e60565e9c4b4d95eed2" category="list-text">Riduzione dell'utilizzo della CPU per ridurre i tempi di attesa i/O.</block>
  <block id="915a1ce7d578786f5aa93e503452d2b9" category="list-text">Tempi di recovery più rapidi per i broker Kafka</block>
  <block id="5810e3ce10e4e8edfee5f25cae3459c1" category="list-text">Performance nel cloud e on-premise</block>
  <block id="7910f734d679965fb4e725f87dcb3c61" category="section-title">Perché utilizzare lo storage NFS per i workload Kafka?</block>
  <block id="932e5edaa1f66c6b109d045d3c7ba0bc" category="paragraph">I carichi di lavoro Kafka nelle applicazioni di produzione possono eseguire lo streaming di enormi quantità di dati tra le applicazioni. Questi dati vengono conservati e memorizzati nei nodi del broker Kafka nel cluster Kafka. Kafka è nota anche per la disponibilità e il parallelismo, che si ottiene suddividendo gli argomenti in partizioni e replicando le partizioni in tutto il cluster. Ciò significa che l'enorme quantità di dati che scorre attraverso un cluster Kafka è generalmente moltiplicata per dimensioni. NFS rende il ribilanciamento dei dati con il variare del numero di broker molto rapido e semplice. Per ambienti di grandi dimensioni, ribilanciamento dei dati in DAS quando il numero di broker cambia è molto lungo e, nella maggior parte degli ambienti Kafka, il numero di broker cambia frequentemente.</block>
  <block id="a49afd0b2827b8f1d1b83a36f75d3efc" category="paragraph">Altri vantaggi includono:</block>
  <block id="889d2761ec65245a621931da633b8cfe" category="list-text">*Maturità.* NFS è un protocollo maturo, il che significa che la maggior parte degli aspetti dell'implementazione, della protezione e dell'utilizzo sono ben noti.</block>
  <block id="c231daeb716325a2bca62a5e30431c8d" category="list-text">*Open.* NFS è un protocollo aperto e il suo continuo sviluppo è documentato nelle specifiche Internet come protocollo di rete libero e aperto.</block>
  <block id="6526aeb62806bf842c7ab66949c2de0c" category="list-text">* Conveniente.* NFS è una soluzione a basso costo per la condivisione di file di rete facile da configurare perché utilizza l'infrastruttura di rete esistente.</block>
  <block id="8c70ad2ab84f33f7d462109fc8edc329" category="list-text">*Gestione centralizzata.* la gestione centralizzata di NFS riduce la necessità di aggiungere software e spazio su disco nei singoli sistemi utente.</block>
  <block id="dbb4f7d4eb0147816ffd5d84e4a79e19" category="list-text">*Distributed.* NFS può essere utilizzato come file system distribuito, riducendo la necessità di dispositivi di storage su supporti rimovibili.</block>
  <block id="37377984e38462f1628867b8e7a1e772" category="section-title">Perché scegliere NetApp per i workload Kafka?</block>
  <block id="300fdb82e8f9a8b6ebb6d42a92483544" category="paragraph">L'implementazione NetApp NFS è considerata uno standard di riferimento per il protocollo e viene utilizzata in innumerevoli ambienti NAS aziendali. Oltre alla credibilità di NetApp, offre anche i seguenti vantaggi:</block>
  <block id="f7e7d6aebe6163c0f639238b2e1a0333" category="list-text">Affidabilità ed efficienza</block>
  <block id="735980c2ea138788423c50ba2ef7c6c5" category="list-text">Scalabilità e performance</block>
  <block id="a8fbd78750bfdd72ecb8371fa5fa9648" category="list-text">Alta disponibilità (partner ha in un cluster NetApp ONTAP)</block>
  <block id="e005f1a13de2a01927e39ecb29ff1a7c" category="list-text">*Disaster Recovery (NetApp SnapMirror).* il tuo sito non funziona o vuoi partire da un altro sito e continuare da dove hai interrotto.</block>
  <block id="81757222cee28779fe25327e8ef3f5a2" category="list-text">Gestibilità del sistema storage (amministrazione e gestione con NetApp OnCommand).</block>
  <block id="7d411cbcfa7cf122ac8423795b89a4b8" category="list-text">*Bilanciamento del carico.* il cluster consente di accedere a volumi diversi da file di dati LIF ospitati su nodi diversi.</block>
  <block id="6c38013b179499c32ccf05a98b927de6" category="list-text">*Operazioni senza interruzioni.* le LIF o gli spostamenti dei volumi sono trasparenti per i client NFS.</block>
  <block id="4d7de9fb7cbfcd5bb144aea084dd9e99" category="inline-link-macro">Pagina successiva: Soluzione NetApp per problemi di ridenominazione sciocco per i carichi di lavoro da NFS a Kafka.</block>
  <block id="771648345c64342ddd78bfb7ade5c3df" category="paragraph"><block ref="771648345c64342ddd78bfb7ade5c3df" category="inline-link-macro-rx"></block></block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">Questa sezione descrive i vantaggi di questa soluzione per il business.</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">Benefici per il business</block>
  <block id="aaff67cd4222a3be5071cf651cab3d48" category="inline-link-macro">Precedente: Da HDFS e MapR-FS a NFS ONTAP.</block>
  <block id="4e24fd6dd4cc9fa99c4dddfa8f40ee3e" category="paragraph"><block ref="4e24fd6dd4cc9fa99c4dddfa8f40ee3e" category="inline-link-macro-rx"></block></block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">Il trasferimento dei dati dall'analisi dei big data all'ai offre i seguenti vantaggi:</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">Capacità di estrarre dati da diversi file system Hadoop e GPFS in un sistema storage NFS unificato</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">Un metodo automatizzato e integrato con Hadoop per trasferire i dati</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">Riduzione del costo dello sviluppo delle librerie per lo spostamento dei dati dai file system Hadoop</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">Prestazioni massime grazie al throughput aggregato di più interfacce di rete da una singola origine di dati utilizzando NIPAM</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">Metodi pianificati e on-demand per il trasferimento dei dati</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">Efficienza dello storage e funzionalità di gestione aziendale per dati NFS unificati utilizzando il software di gestione dei dati ONTAP</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">Nessun costo per lo spostamento dei dati con il metodo Hadoop per il trasferimento dei dati</block>
  <block id="a3b97091403bff3b38419087acb1c19e" category="inline-link-macro">Segue: Passaggi dettagliati DA GPF a NFS.</block>
  <block id="5e982872ec65785f5d685290b9c40026" category="paragraph"><block ref="5e982872ec65785f5d685290b9c40026" category="inline-link-macro-rx"></block></block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">Abbiamo ottenuto la certificazione con la piattaforma confluente con Kafka per lo storage su più livelli in NetApp StorageGRID.</block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">Verifica confluente</block>
  <block id="b0167c15bc26c48af07aea36aba706fa" category="inline-link-macro">Precedente: Panoramica della tecnologia.</block>
  <block id="0a569fd987814c0464300156b2e26414" category="paragraph"><block ref="0a569fd987814c0464300156b2e26414" category="inline-link-macro-rx"></block></block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">Abbiamo eseguito la verifica con la piattaforma confluente 6.2 Tiered Storage in NetApp StorageGRID. I team NetApp e Confluent hanno lavorato insieme a questa verifica ed hanno eseguito i casi di test richiesti per la verifica.</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">Configurazione della piattaforma confluente</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">Per la verifica abbiamo utilizzato la seguente configurazione.</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">Per la verifica, abbiamo utilizzato tre zookeeper, cinque broker, cinque server di esecuzione script di test, server named tools con 256 GB di RAM e 16 CPU. Per lo storage NetApp, abbiamo utilizzato StorageGRID con un bilanciamento del carico SG1000 con quattro SGF6024. Lo storage e i broker erano connessi tramite connessioni 100GbE.</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">La figura seguente mostra la topologia di rete della configurazione utilizzata per la verifica confluente.</block>
  <block id="82dc8b1c8f1a6f08261f17b764e74bf4" category="paragraph"><block ref="82dc8b1c8f1a6f08261f17b764e74bf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">I server degli strumenti fungono da client applicativi che inviano richieste ai nodi confluenti.</block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">Configurazione dello storage a più livelli confluente</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">La configurazione dello storage a più livelli richiede i seguenti parametri in Kafka:</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">Per la verifica, abbiamo utilizzato StorageGRID con il protocollo HTTP, ma funziona anche HTTPS. La chiave di accesso e la chiave segreta vengono memorizzate nel nome file fornito in<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> parametro.</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">Storage a oggetti NetApp - StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">Abbiamo configurato la configurazione a sito singolo in StorageGRID per la verificazione.</block>
  <block id="1ba0fc45020f864c62328d58df2351ef" category="paragraph"><block ref="1ba0fc45020f864c62328d58df2351ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">Test di verifica</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">Abbiamo completato i seguenti cinque casi di test per la verifica. Questi test vengono eseguiti sul framework Trogdor. I primi due erano test di funzionalità e i restanti tre erano test di performance.</block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">Test di correttezza dell'archivio di oggetti</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">Questo test determina se tutte le operazioni di base (ad esempio, GET/put/delete) sull'API dell'archivio di oggetti funzionano correttamente in base alle esigenze dello storage su più livelli. Si tratta di un test di base che ogni servizio dell'archivio di oggetti dovrebbe superare prima dei seguenti test. Si tratta di un test assertivo che può essere superato o non superato.</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">Test di correttezza delle funzionalità di tiering</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">Questo test determina se la funzionalità di storage a più livelli end-to-end funziona correttamente con un test assertivo che supera o non supera. Il test crea un argomento di test che per impostazione predefinita è configurato con il tiering attivato e una dimensione hotset altamente ridotta. Produce un flusso di eventi per l'argomento di test appena creato, attende che i broker archivino i segmenti nell'archivio di oggetti, quindi consuma il flusso di eventi e convalida che il flusso consumato corrisponda al flusso prodotto. Il numero di messaggi prodotti per il flusso di eventi è configurabile, il che consente all'utente di generare un carico di lavoro sufficientemente grande in base alle esigenze di test. La dimensione ridotta degli hotset garantisce che i fetch consumer al di fuori del segmento attivo vengano serviti solo dall'archivio di oggetti; questo aiuta a verificare la correttezza dell'archivio di oggetti per le letture. Questo test è stato eseguito con e senza un'iniezione di errori dello store di oggetti. Abbiamo simulato il guasto del nodo arrestando il servizio di gestione dei servizi in uno dei nodi in StorageGRID e convalidando che la funzionalità end-to-end funziona con lo storage a oggetti.</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">Benchmark Tier fetch</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">Questo test ha validato le prestazioni di lettura dello storage a più livelli e verificato l'intervallo di richieste di lettura di recupero sotto carico pesante dai segmenti generati dal benchmark. In questo benchmark, Confluent ha sviluppato client personalizzati per soddisfare le richieste di recupero del Tier.</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">Benchmark sui carichi di lavoro producete-consumate</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">Questo test ha generato indirettamente il carico di lavoro di scrittura nell'archivio di oggetti attraverso l'archiviazione dei segmenti. Il carico di lavoro di lettura (segmenti letti) è stato generato dallo storage a oggetti quando i gruppi di consumatori hanno recuperato i segmenti. Questo carico di lavoro è stato generato dallo script di test. Questo test ha verificato le prestazioni di lettura e scrittura sullo storage a oggetti in thread paralleli. Abbiamo eseguito test con e senza l'iniezione di errori del negozio di oggetti come abbiamo fatto per il test di correttezza della funzionalità di tiering.</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">Benchmark del carico di lavoro di conservazione</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">Questo test ha controllato le prestazioni di eliminazione di un archivio di oggetti con un carico di lavoro pesante di conservazione degli argomenti. Il carico di lavoro di conservazione è stato generato utilizzando uno script di test che produce molti messaggi in parallelo a un argomento di test. L'argomento del test è stato configurato con un'impostazione di conservazione aggressiva basata sulle dimensioni e sul tempo che ha causato la rimozione continua del flusso di eventi dall'archivio di oggetti. I segmenti sono stati quindi archiviati. Ciò ha portato a un gran numero di eliminazioni nello storage a oggetti da parte del broker e alla raccolta delle performance delle operazioni di eliminazione degli archivi di oggetti.</block>
  <block id="b2ce010f52b23eb40ba6b51b92837acb" category="inline-link-macro">Avanti: Test delle performance con scalabilità.</block>
  <block id="4a94c930da0f9f0974ad6d4f2d17726b" category="paragraph"><block ref="4a94c930da0f9f0974ad6d4f2d17726b" category="inline-link-macro-rx"></block></block>
  <block id="16147684eb6910d9d73a43bb83091da4" category="summary">I data scientist e i tecnici spesso devono accedere ai dati memorizzati nel formato NFS, ma l'accesso a questi dati direttamente dal protocollo S3 in AWS SageMaker può essere difficile perché AWS supporta solo l'accesso al bucket S3. Tuttavia, NetApp ONTAP offre una soluzione abilitando l'accesso a due protocolli per NFS e S3. Con questa soluzione, data scientist e ingegneri possono accedere ai dati NFS dai notebook AWS SageMaker tramite i bucket S3 di NetApp Cloud Volumes ONTAP. Questo approccio consente un facile accesso e condivisione degli stessi dati da NFS e S3 senza la necessità di software aggiuntivo.</block>
  <block id="e8ce8afdd7d335aed5b93d4a41ae0115" category="doc">TR-4967: Gestione dei dati nel cloud con la dualità di NetApp file-object e AWS SageMaker</block>
  <block id="6b9283149a6cf88268f83de626fe265f" category="paragraph"><block ref="6b9283149a6cf88268f83de626fe265f" category="inline-link-macro-rx"></block></block>
  <block id="e2e44d09263d2131a3697ad71cadb51b" category="doc">NVA-1157-DEPLOY: Workload Apache Spark con soluzione storage NetApp</block>
  <block id="ddf79baf38c476a90774aad122f73cb5" category="paragraph">NVA-1157-DEPLOY descrive le performance e la convalida delle funzionalità di Apache Spark SQL su sistemi storage NetApp NFS AFF. Esamina la configurazione, l'architettura e i test delle performance in base a diversi scenari, oltre a consigli per l'utilizzo di Spark con il software di gestione dei dati NetApp ONTAP. Vengono inoltre illustrati i risultati dei test basati su un gruppo di dischi (JBOD) rispetto al controller di storage NetApp AFF A800.</block>
  <block id="39234cd00ad225afa457b33c5b2c5957" category="paragraph"><block ref="39234cd00ad225afa457b33c5b2c5957" category="inline-link-macro-rx"></block></block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">Con la configurazione di NetApp StorageGRID, abbiamo eseguito i test dello storage su più livelli con da tre a quattro nodi per i carichi di lavoro consumer e di produzione.</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">Test delle performance con scalabilità</block>
  <block id="ef1ee9d1f1e9874aca751251bbce31bf" category="inline-link-macro">Precedente: Verifica confluente.</block>
  <block id="6d08115c54837de983d3ddc9dcd8f038" category="paragraph"><block ref="6d08115c54837de983d3ddc9dcd8f038" category="inline-link-macro-rx"></block></block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">Con la configurazione di NetApp StorageGRID, abbiamo eseguito il test dello storage su più livelli con da tre a quattro nodi per carichi di lavoro consumer e di produttori. Secondo i nostri test, il tempo di completamento e i risultati delle performance erano direttamente proporzionali al numero di nodi StorageGRID. L'installazione di StorageGRID richiedeva almeno tre nodi.</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">Il tempo necessario per completare le operazioni di produzione e di consumo è diminuito in modo lineare con l'aumento del numero di nodi di storage.</block>
  <block id="544baf869b5baa766e8839cd33697872" category="paragraph"><block ref="544baf869b5baa766e8839cd33697872" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">Le performance per l'operazione di recupero s3 sono aumentate linearmente in base al numero di nodi StorageGRID. StorageGRID supporta fino a 200 nodi StorgeGRID.</block>
  <block id="2cd319a657a7fccb8f747dab6f102dcc" category="paragraph"><block ref="2cd319a657a7fccb8f747dab6f102dcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c8105fbc386e60a03fe0cf5390eb0ce" category="inline-link-macro">Successivo: Connettore s3 confluente.</block>
  <block id="40acd085e3c223b35d81906b1c904f46" category="paragraph"><block ref="40acd085e3c223b35d81906b1c904f46" category="inline-link-macro-rx"></block></block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">Hadoop DistCp è uno strumento nativo utilizzato per la copia di intercluster e intracluster di grandi dimensioni. Il processo di base di Hadoop DistCp è un tipico workflow di backup che utilizza strumenti nativi di Hadoop come MapReduce per copiare i dati di Hadoop da un'origine HDFS a una destinazione corrispondente.</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Protezione dei dati Hadoop e NetApp</block>
  <block id="9445444fbd9e863564ea85ad226c0e80" category="inline-link-macro">Precedente: Data fabric basato su NetApp per l'architettura dei big data.</block>
  <block id="e30c587da81860e05b3f8ecfb5b9965b" category="paragraph"><block ref="e30c587da81860e05b3f8ecfb5b9965b" category="inline-link-macro-rx"></block></block>
  <block id="5f45c95989226891db648114a547a6bd" category="paragraph">Hadoop DistCp è uno strumento nativo utilizzato per la copia di intercluster e intracluster di grandi dimensioni. Il processo di base di Hadoop DistCp illustrato nella figura seguente è un tipico workflow di backup che utilizza strumenti nativi di Hadoop come MapReduce per copiare i dati di Hadoop da un'origine HDFS a una destinazione corrispondente. L'accesso diretto NetApp NFS consente ai clienti di impostare NFS come destinazione per lo strumento Hadoop DistCp per copiare i dati dall'origine HDFS in una condivisione NFS tramite MapReduce. L'accesso diretto NetApp NFS funge da driver NFS per lo strumento DistCp.</block>
  <block id="6369c8cb38b142174d2f84d12d2f0420" category="paragraph"><block ref="6369c8cb38b142174d2f84d12d2f0420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a4849340a20db94ed712aca71c30b915" category="inline-link-macro">Pagina successiva: Panoramica dei casi di utilizzo della protezione dei dati Hadoop.</block>
  <block id="817c6593a9a8efc031ec597b5d11d605" category="paragraph"><block ref="817c6593a9a8efc031ec597b5d11d605" category="inline-link-macro-rx"></block></block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">Questo caso di utilizzo si basa su un cliente che trasmette dati che deve eseguire il backup dei dati di analisi basati sul cloud nel proprio data center on-premise.</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="doc">Caso d'utilizzo 2: Backup e disaster recovery dal cloud all'on-premise</block>
  <block id="d05b5b5452aa966fcd3c8947a172f44a" category="inline-link-macro">Precedente: Caso d'utilizzo 1 - Backup dei dati Hadoop.</block>
  <block id="d6b3b64a2054103914910c4432cc9e18" category="paragraph"><block ref="d6b3b64a2054103914910c4432cc9e18" category="inline-link-macro-rx"></block></block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">Questo caso di utilizzo si basa su un cliente che trasmette dati che deve eseguire il backup dei dati di analisi basati sul cloud nel proprio data center on-premise, come illustrato nella figura seguente.</block>
  <block id="063e138ba69a95a99bd2f908b540e210" category="paragraph"><block ref="063e138ba69a95a99bd2f908b540e210" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">In questo scenario, i dati dei sensori IoT vengono acquisiti nel cloud e analizzati utilizzando un cluster open source Apache Spark all'interno di AWS. Il requisito è di eseguire il backup dei dati elaborati dal cloud a on-premise.</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">L'attivazione della protezione dei dati non dovrebbe causare alcun effetto sulle performance del cluster Spark/Hadoop di produzione nel cloud.</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">I dati dei sensori cloud devono essere spostati e protetti on-premise in modo efficiente e sicuro.</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">Flessibilità per il trasferimento dei dati dal cloud all'on-premise in diverse condizioni, ad esempio on-demand, istantaneo e durante i bassi tempi di carico del cluster.</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">Il cliente utilizza AWS Elastic Block Store (EBS) per lo storage HDFS del cluster Spark per ricevere e acquisire dati dai sensori remoti tramite Kafka. Di conseguenza, lo storage HDFS funge da origine per i dati di backup.</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">Per soddisfare questi requisiti, il cloud NetApp ONTAP viene implementato in AWS e viene creata una condivisione NFS per fungere da destinazione di backup per il cluster Spark/Hadoop.</block>
  <block id="c260f0b6bfdb6eff1473aafbf5bd075a" category="paragraph">Una volta creata la condivisione NFS, il modulo di analisi in-place viene utilizzato per copiare i dati dallo storage EBS HDFS nella condivisione NFS di ONTAP. Una volta che i dati risiedono in NFS nel cloud ONTAP, la tecnologia SnapMirror può essere utilizzata per eseguire il mirroring dei dati dal cloud allo storage on-premise in modo sicuro ed efficiente.</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">Questa immagine mostra il backup e il disaster recovery dal cloud alla soluzione on-premise.</block>
  <block id="94c7a6b63152038de5e8b2763cdef06c" category="paragraph"><block ref="94c7a6b63152038de5e8b2763cdef06c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bbd6a10b63926b84e9a28da6d4214925" category="inline-link-macro">Successivo: Caso d'utilizzo 3 - abilitazione di DevTest sui dati Hadoop esistenti.</block>
  <block id="e0f915fb1893e398d54abc6f9d00ca57" category="paragraph"><block ref="e0f915fb1893e398d54abc6f9d00ca57" category="inline-link-macro-rx"></block></block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">In questa sezione vengono fornite le procedure dettagliate necessarie per configurare GPFS e spostare i dati in NFS utilizzando NetApp XCP.</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">PASSAGGI dettagliati DA GPF a NFS</block>
  <block id="b523cc107fd56956277d38d32b34c938" category="inline-link-macro">Precedente: Benefici per il business.</block>
  <block id="c415260b3bf5ed05c37515a8e4e526f3" category="paragraph"><block ref="c415260b3bf5ed05c37515a8e4e526f3" category="inline-link-macro-rx"></block></block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">Configurare GPFS</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">Scaricare e installare Spectrum Scale Data Access per Linux su uno dei server.</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">Installare il pacchetto prerequisito (inclusi chef e kernel header) su tutti i nodi.</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">Disattivare SELinux in tutti i nodi.</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">Configurare il nodo di installazione.</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">Aggiungere il nodo admin e il nodo GPFS al file di definizione del cluster.</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">Aggiungere il nodo manager e il nodo GPFS.</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">Aggiungere il nodo quorum e il nodo GPFS.</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">Aggiungere i server NSD e il nodo GPFS.</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">Aggiungere i nodi GUI, admin e GPFS.</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">Aggiungere un altro server GUI.</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">Aggiungere un altro nodo GPFS.</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">Verificare ed elencare tutti i nodi.</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">Specificare un nome del cluster nel file di definizione del cluster.</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">Specificare il profilo.</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">Specificare il binario della shell remota che deve essere utilizzato da GPFS; use<block ref="f8b2a03096b35c105ccb9e1687ea4d21" prefix=" " category="inline-code"></block>.</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">Specificare il binario di copia del file remoto da utilizzare da GPFS; Use<block ref="795f05204859c09fe2f151b742bf82f9" prefix=" " category="inline-code"></block>.</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">Specificare l'intervallo di porte da impostare su tutti i nodi GPFS; utilizzare<block ref="3b552a3fb3ecdff1af07892680e6d03a" prefix=" " category="inline-code"></block>.</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">Visualizzare le impostazioni di configurazione di GPFS.</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">Aggiungere un nodo admin.</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">Abilitare NTP.</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">Controllare le configurazioni prima dell'installazione.</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">Configurare i dischi NSD.</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">Creare i dischi NSD.</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">Controllare lo stato del disco NSD.</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">Controllare e fornire le autorizzazioni necessarie per GPFS.</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">Controllare la lettura e la scrittura della GPFS eseguendo<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> comando.</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">Per esportare GPFS in NFS, attenersi alla seguente procedura:</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">Elencare i file in GPFS per convalidare il client NFS.</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">Configurare il client NFS</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">Installare i pacchetti nel client NFS.</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">Convalidare l'elenco dei file GPFS nella cartella montata su NFS.</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">Spostare i dati dal file NFS esportato con GPFS al NetApp NFS utilizzando XCP.</block>
  <block id="96a4b9abe25ad94a1d4ab8e0d2237ef6" category="inline-link-macro">Avanti: Da MapR-FS a NFS ONTAP.</block>
  <block id="742eb558b5f30d090f7c3ae58b2a554e" category="paragraph"><block ref="742eb558b5f30d090f7c3ae58b2a554e" category="inline-link-macro-rx"></block></block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">In un cluster di big data, i dati vengono memorizzati in HDFS o HCFS, come MapR-FS, Windows Azure Storage Blob, S3 o il file system Google. Abbiamo eseguito test con HDFS, MapR-FS e S3 come origine per copiare i dati nell'esportazione NFS di NetApp ONTAP con l'aiuto di NIPAM utilizzando il comando distcp hadoop dall'origine.</block>
  <block id="6d1963202b436934d6b74acc8232dc94" category="inline-link-macro">Precedente: Sfide per i clienti.</block>
  <block id="501ee0e125dd4449de2b29015fab6f3e" category="paragraph"><block ref="501ee0e125dd4449de2b29015fab6f3e" category="inline-link-macro-rx"></block></block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">In un cluster di big data, i dati vengono memorizzati in HDFS o HCFS, come MapR-FS, Windows Azure Storage Blob, S3 o il file system Google. Abbiamo eseguito test con HDFS, MapR-FS e S3 come origine per copiare i dati nell'esportazione NFS di NetApp ONTAP con l'aiuto di NIPAM utilizzando<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> comando dall'origine.</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">Il seguente diagramma illustra il tipico spostamento dei dati da un cluster Spark in esecuzione con storage HDFS a un volume NFS NetApp ONTAP in modo che NVIDIA possa elaborare le operazioni ai.</block>
  <block id="d824b1bb9493b5a6c5a2e74871468633" category="paragraph"><block ref="d824b1bb9493b5a6c5a2e74871468633" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">Il<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> Il comando utilizza il programma MapReduce per copiare i dati. NIPAM lavora con MapReduce per fungere da driver per il cluster Hadoop durante la copia dei dati. NIPAM può distribuire un carico su più interfacce di rete per una singola esportazione. Questo processo massimizza il throughput di rete distribuendo i dati tra più interfacce di rete quando si copiano i dati da HDFS o HCFS a NFS.</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">NIPAM non è supportato o certificato con MapR.</block>
  <block id="e68fb74f51fcafb391476c585b1e434d" category="inline-link-macro">Next: Soluzione data mover per l'ai.</block>
  <block id="1f4c259e626baca3c7947e6f3db323d4" category="paragraph"><block ref="1f4c259e626baca3c7947e6f3db323d4" category="inline-link-macro-rx"></block></block>
  <block id="b446e9930ab89aa25e7b422c4c23d83f" category="inline-link-macro">Precedente: Da MapR-FS a NFS ONTAP.</block>
  <block id="185bcaf9470b338d9a2b58870d7bd2bd" category="paragraph"><block ref="185bcaf9470b338d9a2b58870d7bd2bd" category="inline-link-macro-rx"></block></block>
  <block id="ca79886b03835c933143f8eb102ac932" category="list-text">Best practice per il modulo NetApp in-place Analytics</block>
  <block id="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link"><block ref="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link-rx"></block></block>
  <block id="026671d583a546d6b62291e018f78bf7" category="paragraph"><block ref="026671d583a546d6b62291e018f78bf7" category="inline-link-rx"></block></block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">Guida all'implementazione e alle Best practice per i volumi NetApp FlexGroup</block>
  <block id="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link"><block ref="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link-rx"></block></block>
  <block id="f473bc55fb079f0338493530316efc6f" category="paragraph"><block ref="f473bc55fb079f0338493530316efc6f" category="inline-link-rx"></block></block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">Versione 3.0</block>
  <block id="b9365bb9132d1eb8770275a763fc5d69" category="cell">Gennaio 2022</block>
  <block id="e4005842db89b4abb778385f9a8a758f" category="cell">Sposta direttamente i dati da HDFS e MapR-FS a NFS utilizzando NetApp XCP.</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">Versione 2.0</block>
  <block id="d835981d77534f5f20446d4648ad7e5b" category="cell">Gennaio 2020</block>
  <block id="637f51ce71f8f8cadc4b75dfda96d45c" category="cell">XCP incluso come data mover predefinito. Aggiunta di MapR-FS a NFS e GPFS al trasferimento dati NFS.</block>
  <block id="a10ba827ae758dee0e50d44366fd3d6d" category="cell">Novembre 2018</block>
  <block id="722462e25c63551f73985fc89f6a2139" category="summary">La soluzione consente di aggiungere risorse di calcolo, hot storage o S3 per soddisfare la crescente domanda in termini di numero di utenti o tasso di acquisizione in implementazioni singole e multisito.</block>
  <block id="4932435adc5992fde32a04e44fd251b8" category="doc">Vantaggi di questa soluzione</block>
  <block id="0dd05c4d24d98f033770c01356b3ce26" category="paragraph"><block ref="0dd05c4d24d98f033770c01356b3ce26" category="inline-link-macro-rx"></block></block>
  <block id="bf89e1232480b95d07f648df24c3695b" category="list-text">*Prestazioni.* la combinazione di Splunk SmartStore e NetApp StorageGRID offre una rapida migrazione dei dati tra bucket hot e bucket warm utilizzando lo storage a oggetti. StorageGRID accelera il processo di migrazione fornendo performance veloci per carichi di lavoro a oggetti di grandi dimensioni.</block>
  <block id="e0be1ad556d6601e63eb8f1b6208c55e" category="list-text">*Compatibile con più siti.* l'architettura distribuita di StorageGRID consente a Splunk SmartStore di estendere le implementazioni su siti singoli e multipli attraverso un singolo namespace globale in cui è possibile accedere ai dati da qualsiasi sito, indipendentemente dalla posizione in cui risiedono i dati.</block>
  <block id="9efd709ebdaac869f02b49e17fe9e92b" category="list-text">*Maggiore scalabilità.* scalare le risorse di storage in modo indipendente dalle risorse di calcolo per soddisfare esigenze e richieste in evoluzione nel tuo ambiente Splunk, fornendo così un TCO migliorato.</block>
  <block id="52fb1ca9da3811c1cb86cd4347f98a64" category="list-text">*Capacità.* raggiungi volumi in rapida crescita nell'implementazione di Splunk con StorageGRID scalando un singolo namespace a oltre 560 PB.</block>
  <block id="ff501c8a6a8c7b1ee7a3c656b6f4055a" category="list-text">*Disponibilità dei dati.* Ottimizza disponibilità, performance, geodistribuzione, conservazione, protezione, e i costi dello storage con policy basate sui metadati che possono adattarsi in modo dinamico con l'evolversi del valore di business dei dati.</block>
  <block id="bf1b0e32d877d343f0b3bc9ba43cb688" category="inline-link">Linee guida fornite da Splunk</block>
  <block id="29c3e2f956fc4b206ef3c7bbbb3730b0" category="paragraph">Aumenta le performance con la cache SmartStore, un componente dell'indicizzatore che gestisce il trasferimento delle copie bucket tra storage locale (hot) e remoto (warm). Il dimensionamento di Splunk per questa soluzione si basa su<block ref="d615ab802f29a9ee4a18e420480d049f" category="inline-link-rx"></block>. La soluzione consente di aggiungere risorse di calcolo, hot storage o S3 per soddisfare la crescente domanda in termini di numero di utenti o tasso di acquisizione in implementazioni singole e multisito.</block>
  <block id="a013f15cce9510e1b717f058d9322b0f" category="inline-link-macro">Avanti: Tiering intelligente e risparmi sui costi.</block>
  <block id="1dd4851efea44091fc608ccfa49a8da6" category="paragraph"><block ref="1dd4851efea44091fc608ccfa49a8da6" category="inline-link-macro-rx"></block></block>
  <block id="7e838102a13e780977b21c90f648a5d0" category="summary">Questa sezione descrive la natura e i componenti di Apache Spark e il loro contributo a questa soluzione.</block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="doc">Tecnologia della soluzione</block>
  <block id="b47e85e30f997f214c7850de9dd795da" category="inline-link-macro">Precedente: Pubblico di riferimento.</block>
  <block id="9e972d78946023378ffbea0f999c2d03" category="paragraph"><block ref="9e972d78946023378ffbea0f999c2d03" category="inline-link-macro-rx"></block></block>
  <block id="f4387c90411f7b92618497bc53b16256" category="paragraph">Apache Spark è un popolare framework di programmazione per la scrittura di applicazioni Hadoop che funziona direttamente con Hadoop Distributed file System (HDFS). Spark è pronto per la produzione, supporta l'elaborazione dei dati in streaming ed è più veloce di MapReduce. Spark dispone di un caching dei dati in-memory configurabile per un'iterazione efficiente e la shell Spark è interattiva per l'apprendimento e l'esplorazione dei dati. Con Spark, puoi creare applicazioni in Python, Scala o Java. Le applicazioni SPARK sono costituite da uno o più lavori che hanno uno o più compiti.</block>
  <block id="6a696023a577a0d26763ef9c382b4b1f" category="paragraph">Ogni applicazione Spark dispone di un driver Spark. In modalità YARN-Client, il driver viene eseguito sul client localmente. In modalità YARN-Cluster, il driver viene eseguito nel cluster sul master dell'applicazione. In modalità cluster, l'applicazione continua a funzionare anche se il client si disconnette.</block>
  <block id="fed4e6478ab0d82b2e98b4f5bd62f0e2" category="paragraph"><block ref="fed4e6478ab0d82b2e98b4f5bd62f0e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6feb0bd2b4db4693572a9fc2e517e888" category="paragraph">Esistono tre cluster manager:</block>
  <block id="4c79d7007667a60b712836e2f93d6bfc" category="list-text">*Standalone.* questo gestore fa parte di Spark, che semplifica la configurazione di un cluster.</block>
  <block id="c0a5bce529ff277ee2735538a7b43913" category="list-text">*Apache Mesos.* questo è un gestore di cluster generale che esegue anche MapReduce e altre applicazioni.</block>
  <block id="24683e4dfc33dc5b20a0d9a75c0ff150" category="list-text">*Hadoop YARN.* questo è un resource manager in Hadoop 3.</block>
  <block id="569531fd384ec251943946598eb00dcb" category="paragraph">Il dataset distribuito resiliente (RDD) è il componente principale di Spark. RDD ricrea i dati persi e mancanti dai dati memorizzati nel cluster e memorizza i dati iniziali provenienti da un file o creati a livello di programmazione. Le RDD vengono create da file, dati in memoria o da un altro RDD. La programmazione SPARK esegue due operazioni: Trasformazione e azioni. La trasformazione crea un nuovo RDD basato su uno esistente. Le azioni restituiscono un valore da un RDD.</block>
  <block id="06b482c7bd2522ec4a62ccc70b71c37e" category="paragraph">Le trasformazioni e le azioni si applicano anche ai DataSet e ai DataFrame di Spark. Un set di dati è una raccolta distribuita di dati che offre i benefici delle RDDs (tipizzazione forte, utilizzo delle funzioni lambda) con i benefici del motore di esecuzione ottimizzato di Spark SQL. È possibile costruire un dataset da oggetti JVM e manipolarlo utilizzando trasformazioni funzionali (mappa, mappa piatta, filtro e così via). Un DataFrame è un dataset organizzato in colonne denominate. È concettualmente equivalente a una tabella in un database relazionale o a un frame di dati in R/Python. I DataFrame possono essere costruiti da un'ampia gamma di origini come file di dati strutturati, tabelle in Hive/HBase, database esterni on-premise o nel cloud o RDDs esistenti.</block>
  <block id="89d836212e4c5086ebcd9e5fbd6a4b37" category="paragraph">Le applicazioni SPARK includono uno o più lavori Spark. I job eseguono task negli esecutori e gli esecutori vengono eseguiti in CONTAINER DI FILATI. Ogni esecutore viene eseguito in un singolo container e gli esecutori esistono per tutta la vita di un'applicazione. Un esecutore viene fissato dopo l'avvio dell'applicazione e IL FILATO non ridimensiona il container già allocato. Un esecutore può eseguire task contemporaneamente sui dati in-memory.</block>
  <block id="93b777568c6fc956b8dcbf6cb778cf8e" category="inline-link-macro">Pagina successiva: Panoramica delle soluzioni NetApp Spark.</block>
  <block id="2e9d493fc7f04097c722ddfd7bf4cba7" category="paragraph"><block ref="2e9d493fc7f04097c722ddfd7bf4cba7" category="inline-link-macro-rx"></block></block>
  <block id="7d68f597b217695f6702ae71ae4eb455" category="summary">StorageGRID offre un'ampia gamma di funzionalità che gli utenti possono sfruttare e personalizzare per il loro ambiente in continua evoluzione. Dall'implementazione alla scalabilità di Splunk SmartStore, il tuo ambiente richiede una rapida adozione dei cambiamenti e dovrebbe essere senza interruzioni per Splunk. Le policy di gestione dei dati flessibili (ILM) e i classificatori del traffico (QoS) di StorageGRID consentono di pianificare e adattarsi al tuo ambiente.</block>
  <block id="0fc3cf31004e01f169ca3af4ef687576" category="doc">Funzionalità StorageGRID flessibili per Splunk SmartStore</block>
  <block id="0a0da304981bebd25b6bd55cb6151bf0" category="paragraph"><block ref="0a0da304981bebd25b6bd55cb6151bf0" category="inline-link-macro-rx"></block></block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">Gestione semplice con Grid Manager</block>
  <block id="5b552d68210e15d5ed4e4d186264b453" category="paragraph">Grid Manager è l'interfaccia grafica basata su browser che consente di configurare, gestire e monitorare il sistema StorageGRID in ubicazioni distribuite globalmente in un singolo pannello di controllo, come mostrato nell'immagine seguente.</block>
  <block id="9c4d5c64a1fc501b7fb5d68cb8048ddc" category="paragraph"><block ref="9c4d5c64a1fc501b7fb5d68cb8048ddc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52d198c85ec187eb3bbff17442a01baa" category="paragraph">Eseguire le seguenti operazioni con l'interfaccia di Grid Manager:</block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">Gestisci repository distribuiti a livello globale e scalabili in petabyte di oggetti come immagini, video e record.</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">Monitorare i nodi e i servizi di grid per garantire la disponibilità degli oggetti.</block>
  <block id="52134209a1824af49cd06b67ca3aedc7" category="list-text">Gestire il posizionamento dei dati a oggetti nel tempo utilizzando le regole ILM (Information Lifecycle Management). Queste regole regolano ciò che accade ai dati di un oggetto dopo l'acquisizione, il modo in cui sono protetti dalla perdita, dove sono memorizzati i dati dell'oggetto e per quanto tempo.</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">Monitorare transazioni, performance e operazioni all'interno del sistema.</block>
  <block id="356e4420bfe7b6226984261d66ec9e0b" category="section-title">Applicazione NetApp StorageGRID per Splunk</block>
  <block id="d4503ceebebf47c506c3003f760662a2" category="paragraph">L'applicazione NetApp StorageGRID per Splunk è un'applicazione specifica per Splunk Enterprise. Questa applicazione funziona in combinazione con il componente aggiuntivo NetApp StorageGRID per Splunk. Fornisce visibilità sullo stato di salute di StorageGRID, sulle informazioni sull'utilizzo dell'account, sui dettagli di controllo della sicurezza, sull'utilizzo e sul monitoraggio delle risorse e così via.</block>
  <block id="c7b8ad57a7270e26eba0ed9da1fa0b6c" category="paragraph">L'immagine seguente mostra l'applicazione StorageGRID per Splunk.</block>
  <block id="7c39625522ddbadc65ea87056e2d32c9" category="paragraph"><block ref="7c39625522ddbadc65ea87056e2d32c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7e07b036910adce42ba90efc47f818e" category="section-title">Policy ILM</block>
  <block id="fce13f2ee25ffdd1859d6a17a94b0e73" category="paragraph">StorageGRID dispone di policy di gestione dei dati flessibili che includono la conservazione di più copie degli oggetti e l'utilizzo di schemi EC (erasure coding) come 2+1 e 4+2 (e molti altri) per memorizzare gli oggetti in base ai requisiti specifici di performance e protezione dei dati. Con il variare dei carichi di lavoro e dei requisiti nel tempo, è comune che anche le policy ILM debbano cambiare nel tempo. La modifica delle policy ILM è una funzionalità fondamentale che consente ai clienti StorageGRID di adattarsi al loro ambiente in continua evoluzione in modo rapido e semplice.</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">Performance</block>
  <block id="3f7d13681fac5c1ca00c53ae2a27efaa" category="paragraph">StorageGRID scala le performance aggiungendo più nodi, che possono essere macchine virtuali o appliance bare metal o appositamente costruite come SG5712, SG5760, SG6060 o SGF6024. Nei nostri test, abbiamo superato i principali requisiti di performance di SmartStore con un grid a tre nodi di dimensioni minime utilizzando l'appliance SG6060. Man mano che i clienti scalano l'infrastruttura Splunk con indicizzatori aggiuntivi, possono aggiungere più nodi di storage per aumentare performance e capacità.</block>
  <block id="8a0453356d4720c8c5a67e5e2a16b419" category="section-title">Configurazione del bilanciamento del carico e dell'endpoint</block>
  <block id="08de46c3a8d44cfa799d969abfa407eb" category="paragraph">I nodi di amministrazione in StorageGRID forniscono l'interfaccia utente (interfaccia utente) e l'endpoint REST API per visualizzare, configurare e gestire il sistema StorageGRID, nonché registri di controllo per tenere traccia dell'attività del sistema. Per fornire un endpoint S3 altamente disponibile per lo storage remoto Splunk SmartStore, abbiamo implementato il bilanciamento del carico StorageGRID, che viene eseguito come servizio sui nodi di amministrazione e sui nodi gateway. Inoltre, il bilanciamento del carico gestisce anche il traffico locale e comunica con GSLB (Global Server Load Balancing) per agevolare il disaster recovery.</block>
  <block id="d2134190f6b031237d4b1523c86c29a2" category="paragraph">Per migliorare ulteriormente la configurazione degli endpoint, StorageGRID fornisce policy di classificazione del traffico integrate nel nodo di amministrazione, consente di monitorare il traffico dei workload e di applicare vari limiti di qualità del servizio (QoS) ai carichi di lavoro. I criteri di classificazione del traffico vengono applicati agli endpoint del servizio bilanciamento del carico StorageGRID per i nodi gateway e i nodi di amministrazione. Queste policy possono essere utili per la limitazione e il monitoraggio del traffico.</block>
  <block id="923a187b8784c27278acc68df21738b8" category="inline-link-macro">Avanti: Architettura Splunk.</block>
  <block id="ec27327edf763f5474f1428dfcc067b1" category="paragraph"><block ref="ec27327edf763f5474f1428dfcc067b1" category="inline-link-macro-rx"></block></block>
  <block id="19e775234c718c1f4e40d8023fe9dbad" category="paragraph"><block ref="19e775234c718c1f4e40d8023fe9dbad" category="inline-link-macro-rx"></block></block>
  <block id="996099c5b9fa96634feb727528db335e" category="list-text">Che cos'è Apache Kafka?</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="64512a184434b7e7734cf3c0a7283f2a" category="list-text">Che cos'è un ridenominazione sciocco?</block>
  <block id="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link"><block ref="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link-rx"></block></block>
  <block id="0bf644a00aca415462aeb30f96e502cf" category="paragraph"><block ref="0bf644a00aca415462aeb30f96e502cf" category="inline-link-rx"></block></block>
  <block id="4a15e598cdac14bbb90bb0e4020f4a79" category="list-text">ONATP viene letto per le applicazioni di streaming.</block>
  <block id="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link"><block ref="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link-rx"></block></block>
  <block id="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="paragraph"><block ref="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="inline-link-rx"></block></block>
  <block id="6a12d786416c40632fb0604b5414460b" category="list-text">Stupido: Rinominare il problema con Kafka.</block>
  <block id="e31eb904be590e91ff0fbce5199e738b" category="inline-link"><block ref="e31eb904be590e91ff0fbce5199e738b" category="inline-link-rx"></block></block>
  <block id="0c1546e70acde7c8a21a85e45df7d5a1" category="paragraph"><block ref="0c1546e70acde7c8a21a85e45df7d5a1" category="inline-link-rx"></block></block>
  <block id="02aed7d7f25878a636d26b696ed151bb" category="list-text">Documentazione sui prodotti NetApp</block>
  <block id="e861ab8ac55c9110672ee8b4ba3c5990" category="list-text">Che cos'è NFS?</block>
  <block id="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link"><block ref="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link-rx"></block></block>
  <block id="6b6d6a7e1bfbb25506c4af7f443a7b25" category="paragraph"><block ref="6b6d6a7e1bfbb25506c4af7f443a7b25" category="inline-link-rx"></block></block>
  <block id="9fee8c35c177577e85d941aa2c9dedc4" category="list-text">Cos'è la riassegnazione delle partizioni Kafka?</block>
  <block id="2363cdcf0f5fc9a387ed87b925979747" category="inline-link"><block ref="2363cdcf0f5fc9a387ed87b925979747" category="inline-link-rx"></block></block>
  <block id="12b4d09f121a118c1b63eba5f3523fa2" category="paragraph"><block ref="12b4d09f121a118c1b63eba5f3523fa2" category="inline-link-rx"></block></block>
  <block id="f06a814ac7d838a2d019219102377120" category="list-text">Che cos'è il benchmark OpenMessaging?</block>
  <block id="9466397f90b4d13297982537f7f1f157" category="inline-link"><block ref="9466397f90b4d13297982537f7f1f157" category="inline-link-rx"></block></block>
  <block id="f42769fbe9abef93dd4da40d8f886c4a" category="paragraph"><block ref="f42769fbe9abef93dd4da40d8f886c4a" category="inline-link-rx"></block></block>
  <block id="bcc483eab76f7252a6d3060ae223f024" category="list-text">Come migrare un broker Kafka?</block>
  <block id="7702dea2646d94249d97c22a4dcb6f96" category="inline-link"><block ref="7702dea2646d94249d97c22a4dcb6f96" category="inline-link-rx"></block></block>
  <block id="ebdd7bc6eaa2157f5f400c61c1826417" category="paragraph"><block ref="ebdd7bc6eaa2157f5f400c61c1826417" category="inline-link-rx"></block></block>
  <block id="3f7e227a8b3d0fc0cdcbf84e2bc565ac" category="list-text">Come monitorate il broker Kafka con Prometheus?</block>
  <block id="2d2cb8fe8b8d32b7fb984622e41036f1" category="paragraph"><block ref="2d2cb8fe8b8d32b7fb984622e41036f1" category="inline-link-rx"></block></block>
  <block id="c8219112931de58f84e7a14a0d24d1ce" category="list-text">Piattaforma gestita per Apache Kafka</block>
  <block id="a96e98488edf9123c2fb5281e71c6ec2" category="paragraph"><block ref="a96e98488edf9123c2fb5281e71c6ec2" category="inline-link-rx"></block></block>
  <block id="0cb1f340d12ba20e283d00e1e0823526" category="list-text">Supporto per Apache Kafka</block>
  <block id="14bb5ca8b6287991417f8f43b4d9eb0c" category="paragraph"><block ref="14bb5ca8b6287991417f8f43b4d9eb0c" category="inline-link-rx"></block></block>
  <block id="9d5591555b2fbddd314212720dc97729" category="list-text">Servizi di consulenza per Apache Kafka</block>
  <block id="583ea5ea8c7ad81fed86a1925483124c" category="paragraph"><block ref="583ea5ea8c7ad81fed86a1925483124c" category="inline-link-rx"></block></block>
  <block id="fb4d860c1938626a4cb9b8f66c6eb6f2" category="cell">Marzo 2023</block>
  <block id="b7d338a537a3a1d0186080c4c4ba47eb" category="summary">Questa pagina descrive la tecnologia utilizzata in questa soluzione.</block>
  <block id="1ac2a5604ed02bc66c4d6241b534d13b" category="inline-link-macro">Precedente: Soluzione.</block>
  <block id="9ec2e79862a05fa25e8c20aa973e0d4b" category="paragraph"><block ref="9ec2e79862a05fa25e8c20aa973e0d4b" category="inline-link-macro-rx"></block></block>
  <block id="55473d705d75e19b6040dbe34242319c" category="paragraph">Questa sezione descrive la tecnologia utilizzata in questa soluzione.</block>
  <block id="7f1512274139985d5f21a72e13808522" category="section-title">Storage controller NetApp ONTAP</block>
  <block id="b691cb82ce5ecb3d94f82b73ef3c2219" category="paragraph">NetApp ONTAP è un sistema operativo per lo storage Enterprise dalle performance elevate.</block>
  <block id="f8b80927eb906c831742041c4c139be1" category="paragraph">NetApp ONTAP 9.8 introduce il supporto per le API di Amazon Simple Storage Service (S3). ONTAP supporta un sottoinsieme di azioni API di Amazon Web Services (AWS) S3 e consente la rappresentazione dei dati come oggetti nei sistemi basati su ONTAP tra i cloud provider (AWS, Azure e GCP) e on-premise.</block>
  <block id="9496ba5a97ab04d734dc449f86646ffe" category="paragraph">Il software NetApp StorageGRID è la soluzione NetApp di punta per lo storage a oggetti. ONTAP integra StorageGRID fornendo un punto di acquisizione e pre-elaborazione all'edge, espandendo il data fabric basato su NetApp per i dati a oggetti e aumentando il valore del portfolio di prodotti NetApp.</block>
  <block id="d6e8f345bdd21d285f35171c2da8cd3a" category="paragraph">L'accesso a un bucket S3 viene fornito tramite applicazioni client e utente autorizzate. Il seguente diagramma mostra l'applicazione che accede a un bucket S3.</block>
  <block id="a38dfb3b286ff4854c6f5d67ebc15e13" category="inline-image-macro">Questa figura mostra l'applicazione che accede a un bucket S3.</block>
  <block id="6090835a60a6e1de5e0c995ca8c5e5f8" category="paragraph"><block ref="6090835a60a6e1de5e0c995ca8c5e5f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5088428c842a8d5e45f2e6597af4138" category="section-title">Casi di utilizzo principali</block>
  <block id="5c2f4a513e63ae351e5dc0b7412a43c2" category="paragraph">Lo scopo principale del supporto delle API S3 è fornire l'accesso agli oggetti su ONTAP. L'architettura di storage unificata di ONTAP ora supporta file (NFS e SMB), blocchi (FC e iSCSI) e oggetti (S3).</block>
  <block id="1af2e65957e458000d1181bb9eba2517" category="section-title">Applicazioni S3 native</block>
  <block id="c0889d6b193afe7d0069e3d99bc5f310" category="paragraph">Un numero crescente di applicazioni è in grado di sfruttare il supporto ONTAP per l'accesso a oggetti utilizzando S3. Sebbene sia adatto per carichi di lavoro di archiviazione ad alta capacità, la necessità di performance elevate nelle applicazioni S3 native sta crescendo rapidamente e include:</block>
  <block id="a768caa988605a2846599cf7e2d0c26a" category="list-text">Analytics</block>
  <block id="9d0996a44c6d51cf223e833dceecb286" category="list-text">Intelligenza artificiale</block>
  <block id="1669cbc398e4228e7e05d6b2e030cbe7" category="list-text">Acquisizione edge-to-core</block>
  <block id="bd1a4166acf45c62946d7592a64ad52d" category="paragraph">I clienti possono ora utilizzare strumenti di gestione familiari come Gestore di sistema di ONTAP per eseguire rapidamente il provisioning dello storage a oggetti dalle performance elevate per lo sviluppo e le operazioni in ONTAP, sfruttando le efficienze e la sicurezza dello storage di ONTAP.</block>
  <block id="50472ac5cace1b7798b3f92db5c3049e" category="section-title">Endpoint FabricPool</block>
  <block id="5050f2389b47df5462550d8e11451e9d" category="paragraph">A partire da ONTAP 9.8, FabricPool supporta il tiering dei bucket in ONTAP, consentendo il tiering ONTAP-ONTAP. Si tratta di un'opzione eccellente per i clienti che desiderano riutilizzare l'infrastruttura FAS esistente come endpoint dell'archivio di oggetti.</block>
  <block id="10beb552e5ed01d5c890a260a1d6af16" category="paragraph">FabricPool supporta il tiering a ONTAP in due modi:</block>
  <block id="1e53159984d41f5ea848cdf412430a06" category="list-text">*Tiering del cluster locale.* i dati inattivi vengono suddivisi in livelli in un bucket situato nel cluster locale utilizzando le LIF del cluster.</block>
  <block id="08be0ca0511f2294cbbaf9d92327996b" category="list-text">*Tiering del cluster remoto.* i dati inattivi vengono suddivisi in livelli in un bucket situato su un cluster remoto in modo simile a un Tier cloud FabricPool tradizionale utilizzando le IC LIF sul client FabricPool e le LIF dei dati sull'archivio di oggetti ONTAP.</block>
  <block id="bda29d8d2c5de29e5ec15858a0f72c79" category="paragraph">ONTAP S3 è adatto per le funzionalità S3 sui cluster esistenti senza hardware e gestione aggiuntivi. Per implementazioni superiori a 300 TB, il software NetApp StorageGRID continua a essere la soluzione NetApp di punta per lo storage a oggetti. Non è richiesta una licenza FabricPool quando si utilizza ONTAP o StorageGRID come livello cloud.</block>
  <block id="5a7adb78ef640711a870d82123f00775" category="section-title">NetApp ONTAP per lo storage a più livelli confluente</block>
  <block id="9a5bc88300f877a695de175398887e0e" category="paragraph">Ogni data center deve garantire l'esecuzione delle applicazioni business-critical e la disponibilità e la sicurezza dei dati importanti. Il nuovo sistema NetApp AFF A900 è basato sul software ONTAP edizione Enterprise e su un design ad alta resilienza. Il nostro nuovo sistema di storage NVMe estremamente veloce elimina le interruzioni delle operazioni mission-critical, riduce al minimo l'ottimizzazione delle performance e protegge i dati dagli attacchi ransomware.</block>
  <block id="42dfa85904e1fd1b7fb41d4278c38047" category="paragraph">Dall'implementazione iniziale alla scalabilità del cluster Confluent, il tuo ambiente richiede un rapido adattamento alle modifiche senza interruzioni per le tue applicazioni business-critical. La gestione dei dati aziendali, la qualità del servizio (QoS) e le performance di ONTAP ti consentono di pianificare e adattarsi al tuo ambiente.</block>
  <block id="36509bd95b243830a012c72c8a2d5844" category="paragraph">L'utilizzo di NetApp ONTAP e dello storage a più livelli confluente semplifica la gestione dei cluster Apache Kafka sfruttando ONTAP come destinazione di storage scale-out e consente una scalabilità indipendente delle risorse di calcolo e storage per Confluent.</block>
  <block id="e09818a7d7d98185cdb0309cf3aca8f5" category="paragraph">Un server ONTAP S3 si basa sulle funzionalità di storage scale-out avanzate di ONTAP. La scalabilità del cluster ONTAP può essere eseguita senza problemi estendendo i bucket S3 per utilizzare i nuovi nodi aggiunti al cluster ONTAP.</block>
  <block id="1ccfe00aee80492f09968d6b208801d5" category="section-title">Gestione semplice con Gestore di sistema di ONTAP</block>
  <block id="4fdad8328864e9de2db5338bb25291fc" category="paragraph">Gestore di sistema ONTAP è un'interfaccia grafica basata su browser che consente di configurare, gestire e monitorare il controller di storage ONTAP in ubicazioni distribuite a livello globale in un unico pannello di controllo.</block>
  <block id="c99eb67a4e6cbe9ba119a72c95161fab" category="inline-image-macro">Questa figura mostra lo spazio di lavoro Gestore di sistema di ONTAP.</block>
  <block id="45e8e67e3e5407c5dc518dd00eb8249b" category="paragraph"><block ref="45e8e67e3e5407c5dc518dd00eb8249b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783157c9c38b4e88d7eefffe21cd97d3" category="paragraph">È possibile configurare e gestire ONTAP S3 con Gestore di sistema e l'interfaccia utente di ONTAP. Quando si attiva S3 e si creano bucket utilizzando Gestione sistema, ONTAP fornisce le Best practice predefinite per una configurazione semplificata. Se si configurano il server S3 e i bucket dalla CLI, è comunque possibile gestirli con System Manager, se lo si desidera, o viceversa.</block>
  <block id="d1623a9fec2de2642847391236e62e9b" category="paragraph">Quando si crea un bucket S3 utilizzando Gestione di sistema, ONTAP configura un livello di servizio delle performance predefinito il più alto disponibile sul sistema. Ad esempio, in un sistema AFF, l'impostazione predefinita è estrema. I livelli di servizio delle performance sono gruppi di policy QoS adattivi predefiniti. Invece di uno dei livelli di servizio predefiniti, è possibile specificare un gruppo di criteri QoS personalizzato o nessun gruppo di criteri.</block>
  <block id="bbcb9e2700fba39c3b7b7fd438155100" category="paragraph">I gruppi di criteri QoS adattivi predefiniti includono:</block>
  <block id="f1ec0b0c482a42bad395f01e7f2b6c1d" category="list-text">*Extreme.* utilizzato per applicazioni che richiedono la latenza più bassa e le performance più elevate.</block>
  <block id="06e90efc82fff7e3090ba9ff1a3bd2a3" category="list-text">*Performance.* utilizzato per applicazioni con esigenze di performance e latenza modeste.</block>
  <block id="7aa0f5702784b1be0a3c5ed9e6f3df8e" category="list-text">*Valore.* utilizzato per applicazioni per le quali throughput e capacità sono più importanti della latenza.</block>
  <block id="113d20f8cc4d864cdfea1b0f611cbb0a" category="list-text">*Custom.* specificare un criterio QoS personalizzato o nessun criterio QoS.</block>
  <block id="42cc32e2c7857ba980019c70438e92ed" category="paragraph">Se si seleziona *Use for Tiering* (Usa per il tiering), non viene selezionato alcun livello di servizio delle performance e il sistema tenta di selezionare supporti a basso costo con performance ottimali per i dati a più livelli.</block>
  <block id="5cc287af927b81043d030fc6a1ece879" category="paragraph">ONTAP tenta di eseguire il provisioning di questo bucket su Tier locali che dispongono dei dischi più appropriati, soddisfacendo il livello di servizio scelto. Tuttavia, se è necessario specificare quali dischi includere nel bucket, è consigliabile configurare lo storage a oggetti S3 dalla CLI specificando i Tier locali (aggregato). Se si configura il server S3 dalla CLI, è comunque possibile gestirlo con System Manager, se necessario.</block>
  <block id="74869eb3dfe4756dab5491da2a3de2ad" category="paragraph">Se si desidera specificare gli aggregati da utilizzare per i bucket, è possibile farlo solo utilizzando la CLI.</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="section-title">Confluente</block>
  <block id="0c0e3a803cf68a8772ebf58a68b20124" category="paragraph">Confluent Platform è una piattaforma per lo streaming di dati completa che consente di accedere, memorizzare e gestire facilmente i dati come flussi continui e in tempo reale. Creato dai creatori originali di Apache Kafka, Confluent amplia i vantaggi di Kafka con funzionalità di livello Enterprise, eliminando al contempo il peso della gestione o del monitoraggio di Kafka. Oggi, oltre il 80% dei Fortune 100 è basato su tecnologia di streaming dei dati e la maggior parte utilizza Confluent.</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">Perché confluente?</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">Integrando dati storici e in tempo reale in un'unica fonte di verità centrale, Confluent semplifica la creazione di una categoria completamente nuova di applicazioni moderne e basate sugli eventi, l'acquisizione di una pipeline universale di dati e lo sblocco di nuovi casi di utilizzo potenti con scalabilità, performance e affidabilità complete.</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">A cosa serve Confluent?</block>
  <block id="d3c11d67f567698de4c90210b84c554d" category="paragraph">Confluent Platform ti consente di concentrarti su come ricavare il valore di business dai tuoi dati piuttosto che preoccuparsi delle meccaniche sottostanti, come ad esempio il modo in cui i dati vengono trasportati o integrati tra sistemi diversi. In particolare, Confluent Platform semplifica la connessione delle origini dati a Kafka, la creazione di applicazioni di streaming e la protezione, il monitoraggio e la gestione dell'infrastruttura Kafka. Attualmente, Confluent Platform viene utilizzata per un'ampia gamma di casi di utilizzo in numerosi settori, dai servizi finanziari, al retail omnichannel e alle auto autonome, al rilevamento delle frodi, ai microservizi e all'IoT.</block>
  <block id="870b2318ccfd123ac0f7e9ef1396d49d" category="paragraph">La figura seguente mostra i componenti della piattaforma confluente.</block>
  <block id="9d880468cb22c04bd894fc612814dbab" category="inline-image-macro">Questa figura mostra i componenti della piattaforma confluente.</block>
  <block id="f64c3e5205853c0df35b5f05dcb208a1" category="paragraph"><block ref="f64c3e5205853c0df35b5f05dcb208a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05fafb4336e843d4634bd9ac122177c8" category="section-title">Panoramica della tecnologia Confluent Event Streaming</block>
  <block id="51be25b0145a0beca811de24a62b5cb4" category="inline-link">Kafka</block>
  <block id="0139d991fe55319f2e19e039da969fcf" category="paragraph">Il fulcro della piattaforma confluente è<block ref="66a1a9ec54e6ef0a1c109ad94b972ac9" category="inline-link-rx"></block>, la piattaforma di streaming distribuito open source più diffusa. Le principali funzionalità di Kafka includono:</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">Pubblicare e sottoscrivere flussi di record.</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">Memorizzare i flussi di record in modo tollerante agli errori.</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">Elaborazione di flussi di record.</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">Confluent Platform include anche il Registro di sistema dello schema, il proxy REST, oltre 100 connettori Kafka preintegrati e ksqlDB.</block>
  <block id="82ff0b3d0476bb8ca2283ff06c017658" category="section-title">Panoramica delle funzionalità aziendali della piattaforma Confluent</block>
  <block id="ed2c640e88db15d474de830703c8783b" category="list-text">*Confluent Control Center.* sistema basato su interfaccia utente per la gestione e il monitoraggio di Kafka. Consente di gestire facilmente Kafka Connect e creare, modificare e gestire le connessioni ad altri sistemi.</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">*Confluent per Kubernetes.* Confluent per Kubernetes è un operatore di Kubernetes. Gli operatori di Kubernetes estendono le funzionalità di orchestrazione di Kubernetes fornendo funzionalità e requisiti unici per una specifica applicazione della piattaforma. Per Confluent Platform, ciò include una notevole semplificazione del processo di implementazione di Kafka su Kubernetes e l'automazione delle attività tipiche del ciclo di vita dell'infrastruttura.</block>
  <block id="d63f46631d40c1c76b1a1a46445584aa" category="list-text">* Connettori Kafka Connect.* i connettori utilizzano l'API Kafka Connect per connettere Kafka ad altri sistemi come database, archivi di valori chiave, indici di ricerca e file system. Confluent Hub dispone di connettori scaricabili per le fonti di dati e i sink più diffusi, incluse le versioni completamente testate e supportate di questi connettori con Confluent Platform. Ulteriori dettagli sono disponibili<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>.</block>
  <block id="9103a2961d6b4c593517d3d641763e5c" category="list-text">*Cluster con bilanciamento automatico.* offre bilanciamento del carico automatico, rilevamento degli errori e riparazione automatica. Fornisce inoltre supporto per l'aggiunta o la disattivazione di broker in base alle necessità, senza tuning manuale.</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">*Collegamento di cluster confluente.* collega direttamente i cluster e esegue il mirroring degli argomenti da un cluster all'altro tramite un bridge di collegamento. Il collegamento dei cluster semplifica la configurazione di implementazioni di cloud ibrido, multi-cluster e multi-data center.</block>
  <block id="c1712fa040f6accce664a82ba6d58b94" category="list-text">*Confluent auto data balancer.* monitora il cluster per il numero di broker, la dimensione delle partizioni, il numero di partizioni e il numero di leader all'interno del cluster. Consente di spostare i dati per creare un carico di lavoro uniforme nel cluster, riducendo al contempo il ribilanciamento del traffico per ridurre al minimo l'effetto sui carichi di lavoro di produzione durante il ribilanciamento.</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">*Confluent Replicator.* semplifica la gestione di più cluster Kafka in più data center.</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">*Tiered storage.* offre opzioni per l'archiviazione di grandi volumi di dati Kafka utilizzando il tuo cloud provider preferito, riducendo così il carico operativo e i costi. Con lo storage a più livelli, puoi mantenere i dati su uno storage a oggetti conveniente e scalare i broker solo quando hai bisogno di più risorse di calcolo.</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">*Confluent JMS client.* Confluent Platform include un client compatibile con JMS per Kafka. Questo client Kafka implementa l'API standard JMS 1.1, utilizzando i broker Kafka come backend. Questo è utile se si utilizzano applicazioni legacy con JMS e si desidera sostituire il message broker JMS esistente con Kafka.</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">*Il proxy MQTT confluente.* offre un modo per pubblicare i dati direttamente su Kafka da dispositivi e gateway MQTT senza la necessità di un broker MQTT al centro.</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">*I plug-in di sicurezza confluenti.* i plug-in di sicurezza confluenti vengono utilizzati per aggiungere funzionalità di sicurezza a vari strumenti e prodotti della piattaforma confluente. Attualmente, è disponibile un plug-in per il proxy REST confluente che consente di autenticare le richieste in entrata e propagare l'identità autenticata alle richieste a Kafka. Ciò consente ai client proxy REST confluenti di utilizzare le funzionalità di sicurezza multi-tenant del broker Kafka.</block>
  <block id="0265b0b07689b6439fc600eec3164763" category="inline-link-macro">Avanti: Convalida delle performance confluente.</block>
  <block id="7d58203770f3360011c58049bd5dc048" category="paragraph"><block ref="7d58203770f3360011c58049bd5dc048" category="inline-link-macro-rx"></block></block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">Questo documento fornisce le linee guida sulle Best practice per l'utilizzo di Kafka con lo storage NetApp, inclusi i test di certificazione di Confluent Kafka, i risultati delle performance, la messa a punto, i connettori Kafka e la funzionalità di ribilanciamento automatico.</block>
  <block id="0c7a4422707cf3f11c73c66ea0d5d215" category="inline-link-macro">Precedente: Dimensionamento.</block>
  <block id="f902aefc255b4eb6b31c283ad42816de" category="paragraph"><block ref="f902aefc255b4eb6b31c283ad42816de" category="inline-link-macro-rx"></block></block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">Questo documento fornisce le linee guida sulle Best practice per l'utilizzo dello storage a livelli confluente con lo storage NetApp, inclusi test di verifica, risultati delle performance dello storage a livelli, tuning, connettori Confluent S3 e funzionalità di bilanciamento automatico. Considerando le policy ILM, le performance costanti con test delle performance multipli per la verifica e le API S3 standard di settore, lo storage a oggetti NetApp StorageGRID è la scelta ottimale per lo storage a livelli confluente.</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">Che cos'è Apache Kafka</block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">Storage infinito nella piattaforma confluente</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">Confluent Tiered Storage - Best practice e dimensionamento</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">Connettore Amazon S3 sink per Confluent Platform</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">Dimensionamento di Kafka</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">Dimensionamento StorageGRID</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">Casi di utilizzo di Kafka</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">Cluster Kafka con bilanciamento automatico nella piattaforma confluente 6.0</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="a5091aedd97daf7c5a5297fa5d73a469" category="cell">Dicembre 2021</block>
  <block id="ca052b24845534e817869836d49d519a" category="summary">Questo documento si concentra sull'architettura di Apache Spark, sui casi di utilizzo dei clienti e sul portfolio di storage NetApp relativi all'analisi dei big data e all'intelligenza artificiale. Presenta inoltre diversi risultati di test utilizzando gli standard di settore ai, machine learning e strumenti di deep learning rispetto a un sistema Hadoop tipico, in modo da poter scegliere la soluzione Spark appropriata.</block>
  <block id="58b2293adcda372fb415412d23f01a8e" category="doc">TR-4570: Soluzioni storage NetApp per Apache Spark: Architettura, casi di utilizzo e risultati delle performance</block>
  <block id="057e5f9ddc5d049ab86855dceffd6d14" category="paragraph">Rick Huang, Karthikeyan Nagalingam, NetApp</block>
  <block id="550fd771b94cb8eb3739d16af31243f3" category="paragraph">Questo documento si concentra sull'architettura di Apache Spark, sui casi di utilizzo dei clienti e sul portfolio di storage NetApp relativi all'analisi dei big data e all'intelligenza artificiale (ai). Presenta inoltre diversi risultati di test utilizzando strumenti di ai standard di settore, machine learning (ML) e deep learning (DL) rispetto a un sistema Hadoop tipico, in modo da poter scegliere la soluzione Spark appropriata. Per iniziare, è necessaria un'architettura Spark, componenti appropriati e due modalità di implementazione (cluster e client).</block>
  <block id="9e19cfda234e917201ce19469f25275b" category="paragraph">Questo documento fornisce anche casi di utilizzo per i clienti per risolvere i problemi di configurazione e illustra una panoramica del portfolio di storage NetApp relativo all'analisi dei big data e ai, ML e DL con Spark. Concludiamo con i risultati dei test derivati dai casi di utilizzo specifici di Spark e dal portfolio di soluzioni NetApp Spark.</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="section-title">Sfide per i clienti</block>
  <block id="ce663ffc6a85b2c97e60368b5a9c76e3" category="paragraph">Questa sezione si concentra sulle sfide dei clienti con analisi dei big data e ai/ML/DL nei settori di crescita dei dati come retail, digital marketing, banking, produzione discreta, produzione di processi, enti pubblici e servizi professionali.</block>
  <block id="8a5bab0d8f4c0d1b73de5ada6b1c91e6" category="section-title">Performance imprevedibili</block>
  <block id="9790dc49aa09b4759e4c6ebc65fb4c42" category="paragraph">Le implementazioni Hadoop tradizionali utilizzano generalmente hardware commodity. Per migliorare le performance, devi mettere a punto la rete, il sistema operativo, il cluster Hadoop, i componenti dell'ecosistema come Spark e l'hardware. Anche se si sintonizzano ciascun livello, può essere difficile raggiungere i livelli di performance desiderati perché Hadoop viene eseguito su hardware commodity non progettato per le performance elevate nel proprio ambiente.</block>
  <block id="b496a0269649d7b570c2052646fd23b6" category="section-title">Guasti dei supporti e dei nodi</block>
  <block id="21af95409591262fb36555acb96262d8" category="paragraph">Anche in condizioni normali, l'hardware commodity è soggetto a guasti. Se un disco su un nodo dati si guasta, il master Hadoop considera il nodo non integro per impostazione predefinita. Quindi, copia dati specifici da quel nodo in rete dalle repliche a un nodo integro. Questo processo rallenta i pacchetti di rete per qualsiasi job Hadoop. Il cluster deve quindi copiare di nuovo i dati e rimuovere i dati replicati in eccesso quando il nodo non integro torna allo stato integro.</block>
  <block id="03d4836e0d1deb07679d400b8c88a880" category="section-title">Lock-in del vendor Hadoop</block>
  <block id="bb33286c56b053ae85ab21a377bd4347" category="paragraph">I distributori Hadoop dispongono di una propria distribuzione Hadoop con il proprio controllo delle versioni, che blocca il cliente a tali distribuzioni. Tuttavia, molti clienti richiedono supporto per l'analisi in-memory che non colleghi il cliente a specifiche distribuzioni Hadoop. Hanno bisogno della libertà di cambiare le distribuzioni e di portare con sé le loro analisi.</block>
  <block id="a940c960f38c44b75bf1da78215690c2" category="section-title">Mancanza di supporto per più di una lingua</block>
  <block id="65a27ee7da3f8c68004d31f60ab65e55" category="paragraph">I clienti spesso richiedono il supporto di più lingue oltre ai programmi Java MapReduce per eseguire i propri lavori. Opzioni come SQL e script offrono maggiore flessibilità per ottenere risposte, più opzioni per l'organizzazione e il recupero dei dati e metodi più rapidi per spostare i dati in un framework di analisi.</block>
  <block id="f3e2f69098f73bd8bb3cf61330433955" category="section-title">Difficoltà di utilizzo</block>
  <block id="e2bdfb6bb3e956b38b6aacde957996df" category="paragraph">Per qualche tempo, si lamenta che Hadoop è difficile da utilizzare. Anche se Hadoop è diventato più semplice e potente con ogni nuova versione, questa critica ha persistito. Hadoop richiede di comprendere i modelli di programmazione Java e MapReduce, una sfida per gli amministratori di database e le persone con competenze di scripting tradizionali.</block>
  <block id="5f5f8f99cf4c6ebc0b81445be5328bf6" category="section-title">Framework e strumenti complessi</block>
  <block id="74faacaf156cd022099bed5469595b3e" category="paragraph">I team ai delle aziende devono affrontare diverse sfide. Anche con una conoscenza esperta di data science, gli strumenti e i framework per diversi ecosistemi di implementazione e applicazioni potrebbero non tradursi semplicemente da uno all'altro. Una piattaforma per la scienza dei dati dovrebbe integrarsi perfettamente con le corrispondenti piattaforme per i big data basate su Spark con facilità di spostamento dei dati, modelli riutilizzabili, codice pronto all'uso e strumenti che supportino le Best practice per la prototipazione, la convalida, il controllo delle versioni, la condivisione, il riutilizzo, e implementazione rapida dei modelli in produzione.</block>
  <block id="067be0651f3de8fd60ec45827a4078ed" category="section-title">Perché scegliere NetApp?</block>
  <block id="8ff43bcedde084850831da9cdcc5a43a" category="paragraph">NetApp può migliorare la tua esperienza con Spark nei seguenti modi:</block>
  <block id="dc5106ccf618944587be46565f5585cd" category="list-text">L'accesso diretto NetApp NFS (mostrato nella figura seguente) consente ai clienti di eseguire lavori di big data analytics sui dati NFSv3 o NFSv4 esistenti o nuovi senza spostare o copiare i dati. Impedisce più copie di dati ed elimina la necessità di sincronizzare i dati con un'origine.</block>
  <block id="38bc62edaebd471500fa64a4758f7f04" category="list-text">Storage più efficiente e minore replica dei server. Ad esempio, la soluzione NetApp e-Series Hadoop richiede due repliche anziché tre dei dati, mentre la soluzione FAS Hadoop richiede un'origine dati ma non una replica o copie dei dati. Le soluzioni di storage NetApp producono inoltre meno traffico server-server.</block>
  <block id="2fc945668748ad0173e63b5db34773e7" category="list-text">Migliore comportamento del cluster e del job Hadoop durante il guasto di disco e nodo.</block>
  <block id="343500ea6d724fe727d127f6409b86c2" category="list-text">Migliori performance di acquisizione dei dati.</block>
  <block id="109f256618c8d9037bb2cd6cc28f5959" category="inline-image-macro">Configurazioni alternative di Apache Spark.</block>
  <block id="ce1f5d61aacdba15be898e2d6408542f" category="paragraph"><block ref="ce1f5d61aacdba15be898e2d6408542f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40771867b1bf0db74b9505757197a17a" category="paragraph">Ad esempio, nel settore finanziario e sanitario, lo spostamento dei dati da un luogo all'altro deve soddisfare gli obblighi legali, il che non è un compito facile. In questo scenario, l'accesso diretto NetApp NFS analizza i dati finanziari e sanitari dalla posizione originale. Un altro vantaggio chiave è che l'utilizzo dell'accesso diretto NetApp NFS semplifica la protezione dei dati Hadoop utilizzando i comandi Hadoop nativi e abilitando i flussi di lavoro per la protezione dei dati con il ricco portfolio di gestione dei dati di NetApp.</block>
  <block id="a9e81b3240a7c1ae64fc23e96c84f4ea" category="paragraph">L'accesso diretto NetApp NFS offre due tipi di opzioni di implementazione per i cluster Hadoop/Spark:</block>
  <block id="4e8fe573a9fe74b6429508c87337b99b" category="list-text">Per impostazione predefinita, i cluster Hadoop o Spark utilizzano HDFS (Distributed file System) di Hadoop per lo storage dei dati e il file system predefinito. L'accesso diretto NetApp NFS può sostituire l'HDFS predefinito con lo storage NFS come file system predefinito, consentendo l'analisi diretta dei dati NFS.</block>
  <block id="071998ed00d39b3ff27f5410b196f9cc" category="list-text">In un'altra opzione di implementazione, l'accesso diretto NetApp NFS supporta la configurazione di NFS come storage aggiuntivo insieme a HDFS in un singolo cluster Hadoop o Spark. In questo caso, il cliente può condividere i dati attraverso le esportazioni NFS e accedervi dallo stesso cluster insieme ai dati HDFS.</block>
  <block id="c1923befca33cfe6cc9ace80af8580b6" category="paragraph">I vantaggi principali dell'utilizzo dell'accesso diretto NetApp NFS includono:</block>
  <block id="91221d408b0c171556751f29fb9d8071" category="list-text">Analisi dei dati dalla posizione corrente, che impedisce il dispendioso in termini di tempo e performance dello spostamento dei dati di analisi in un'infrastruttura Hadoop come HDFS.</block>
  <block id="1675635f440b61b7219bf7ed2bb2ed27" category="list-text">Riduzione del numero di repliche da tre a uno.</block>
  <block id="16f81b84f137a7a52da9ba8d798af622" category="list-text">Consentendo agli utenti di separare calcolo e storage per scalare in modo indipendente.</block>
  <block id="71946d3c421aea3a8238a481bebe1919" category="list-text">Protezione dei dati aziendali sfruttando le ricche funzionalità di gestione dei dati di ONTAP.</block>
  <block id="abebb9b977d736f599ab76c517961b24" category="list-text">Certificazione con la piattaforma dati Hortonworks.</block>
  <block id="3c41c2d3511fa95c83687fae6fb57754" category="list-text">Implementazione di data analytics ibridi.</block>
  <block id="05550a44691e53e07f81616af5d58e20" category="list-text">Riduzione dei tempi di backup sfruttando la funzionalità multithread dinamica.</block>
  <block id="009b0bd3acc58fbc1c3db15692583fa9" category="paragraph">Vedere<block ref="217abb9bc41aa22d30da41b7958b4152" category="inline-link-rx"></block> Per il backup dei dati Hadoop, il backup e il disaster recovery dal cloud al on-premise, l'abilitazione di DevTest sui dati Hadoop esistenti, la protezione dei dati e la connettività multicloud e l'accelerazione dei carichi di lavoro di analytics.</block>
  <block id="3100ca44a05fa97ed5f07875f442084e" category="paragraph">Le sezioni seguenti descrivono le funzionalità di storage importanti per i clienti Spark.</block>
  <block id="da2518ef48c60077e2b2c0be7fed7193" category="section-title">Tiering dello storage</block>
  <block id="d9a83ca3a623dce37a2f84027f1495ce" category="paragraph">Con il tiering dello storage Hadoop, è possibile memorizzare file con diversi tipi di storage in conformità con una policy di storage. I tipi di storage includono<block ref="27369b3bf4483e8dcfd85ba9a39a947f" prefix=" " category="inline-code"></block>,<block ref="75e52a0ecfafeda17a34fc60111c1f0b" prefix=" " category="inline-code"></block>,<block ref="a957a3153eb7126b1c5f8b6aac35de53" prefix=" " category="inline-code"></block>,<block ref="714f8e54e71566bd1c2e29328288a62c" prefix=" " category="inline-code"></block>,<block ref="7fc1aa11178f33b4f796d69c73f7f0b4" prefix=" " category="inline-code"></block>, e.<block ref="fa4fdcc80e19a0848c6360538fdd86ef" prefix=" " category="inline-code"></block>.</block>
  <block id="3107c066ea7eeb48bd5f87594a08fd7a" category="paragraph">&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD abbiamo eseguito la convalida del tiering dello storage Hadoop su un controller di storage NetApp AFF e su un controller di storage e-Series con unità SSD e SAS con diverse policy di storage. Il cluster Spark con AFF-A800 ha quattro nodi di lavoro di calcolo, mentre il cluster con e-Series ne ha otto. Questo serve principalmente a confrontare le prestazioni dei dischi a stato solido (SSD) rispetto ai dischi rigidi (HDD).</block>
  <block id="dba657bcaa661bcf5461e260c00e4f06" category="paragraph">Abbiamo eseguito la convalida del tiering dello storage Hadoop su un controller di storage NetApp AFF e su un controller di storage e-Series con unità SSD e SAS con policy di storage diverse. Il cluster Spark con AFF-A800 ha quattro nodi di lavoro di calcolo, mentre il cluster con e-Series ne ha otto. Abbiamo fatto questo principalmente per confrontare le performance dei dischi a stato solido con quelle dei dischi rigidi. &gt;&gt;&gt;&gt;&gt;&gt; a51c9dddf73ca69e1120ce05edc7b0b9607b96eae</block>
  <block id="36edc8f5974bdf6ad51a220254b99dfb" category="paragraph">La figura seguente mostra le performance delle soluzioni NetApp per un SSD Hadoop.</block>
  <block id="d09520ed9b4a17ada38e70314907675f" category="inline-image-macro">È il momento di ordinare 1 TB di dati.</block>
  <block id="55fdf8b2dd620bd73dcd37db50e0f0e5" category="paragraph"><block ref="55fdf8b2dd620bd73dcd37db50e0f0e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2f530d95c6332b106d86a53b41e4a36" category="inline-link">TR-3969 soluzione NetApp e-Series per Hadoop</block>
  <block id="8cdadd1c9614abebd1b476daba691f36" category="list-text">La configurazione baseline NL-SAS utilizzava otto nodi di calcolo e 96 dischi NL-SAS. Questa configurazione ha generato 1 TB di dati in 4 minuti e 38 secondi. Vedere<block ref="f08cd7da48b5d74d9eaab10199016f47" category="inline-link-rx"></block> per informazioni dettagliate sulla configurazione del cluster e dello storage.</block>
  <block id="f895fa75cdc40f4e672bba6f7a873e25" category="list-text">Utilizzando TeraGen, la configurazione SSD ha generato 1 TB di dati a una velocità di 15,66 volte superiore rispetto alla configurazione NL-SAS. Inoltre, la configurazione SSD utilizzava la metà del numero di nodi di calcolo e la metà del numero di dischi (24 unità SSD in totale). In base al tempo di completamento del lavoro, la velocità era quasi doppia rispetto alla configurazione NL-SAS.</block>
  <block id="f14f651fb8150de92c527d88344df494" category="list-text">Utilizzando TeraSort, la configurazione SSD ha ordinato 1 TB di dati 1138.36 volte più rapidamente della configurazione NL-SAS. Inoltre, la configurazione SSD utilizzava la metà del numero di nodi di calcolo e la metà del numero di dischi (24 unità SSD in totale). Pertanto, per disco, la velocità era circa tre volte superiore rispetto alla configurazione NL-SAS. &lt;&lt;&lt;&lt;&lt;&lt;&lt; TESTA</block>
  <block id="52be2edb04819f386804af38bd53a55d" category="list-text">La transizione da dischi rotanti a all-flash migliora le performance. Il numero di nodi di calcolo non era il collo di bottiglia. Con lo storage all-flash di NetApp, le performance di runtime sono perfettamente scalabili.</block>
  <block id="8cc25131075ed11b8263304fceebc5c6" category="list-text">Con NFS, i dati erano funzionalmente equivalenti a quelli del pool, il che può ridurre il numero di nodi di calcolo in base al carico di lavoro. Gli utenti del cluster Apache Spark non devono ribilanciare manualmente i dati quando cambiano il numero di nodi di calcolo.</block>
  <block id="dc406f8350f51d99347d8d026c0435a5" category="list-text">In sintesi, la transizione dai dischi rotanti a all-flash migliora le performance. Il numero di nodi di calcolo non era il collo di bottiglia. Con lo storage all-flash NetApp, le performance di runtime sono perfettamente scalabili.</block>
  <block id="6ed171c4fe1ca516676ea457d91105b1" category="list-text">Con NFS, i dati erano funzionalmente equivalenti a quelli del pool, il che può ridurre il numero di nodi di calcolo in base al carico di lavoro. Gli utenti del cluster Apache Spark non devono ribilanciare manualmente i dati quando cambiano il numero di nodi di calcolo. &gt;&gt;&gt;&gt;&gt;&gt; a51c9dddf73ca69e1120ce05edc7b0b9607b96eae</block>
  <block id="c13c2e056adb51078f3067ba570d2780" category="section-title">Scalabilità delle performance - scalabilità orizzontale</block>
  <block id="beb08cca1e99e0bdbf11c74ebb62d5ea" category="paragraph">Quando è necessaria una maggiore potenza di calcolo da un cluster Hadoop in una soluzione AFF, è possibile aggiungere nodi dati con un numero appropriato di controller storage. NetApp consiglia di iniziare con quattro nodi di dati per array di controller storage e di aumentare il numero fino a otto nodi di dati per controller storage, a seconda delle caratteristiche del carico di lavoro.</block>
  <block id="431bd1a68814e184bc49ff7231450049" category="paragraph">AFF e FAS sono perfetti per l'analisi in-place. In base ai requisiti di calcolo, è possibile aggiungere gestori di nodi, mentre le operazioni senza interruzioni consentono di aggiungere un controller di storage on-demand senza downtime. Offriamo funzionalità complete con AFF e FAS, come SUPPORTO multimediale NVME, efficienza garantita, riduzione dei dati, QOS, analisi predittiva, tiering del cloud, replica, implementazione del cloud e sicurezza. Per aiutare i clienti a soddisfare i propri requisiti, NetApp offre funzionalità come analisi del file system, quote e bilanciamento del carico on-box senza costi di licenza aggiuntivi. NetApp offre performance migliori in termini di numero di processi simultanei, latenza inferiore, operazioni più semplici e throughput di gigabyte al secondo superiore rispetto alla concorrenza. Inoltre, NetApp Cloud Volumes ONTAP viene eseguito su tutti e tre i principali cloud provider.</block>
  <block id="ccfed4ad520d8db8b13dc91438d30680" category="section-title">Scalabilità delle performance - scalabilità verticale</block>
  <block id="9341bdabe891be81d2be3440a4c413b5" category="paragraph">Le funzionalità di scale-up consentono di aggiungere dischi ai sistemi AFF, FAS ed e-Series quando è necessaria una capacità di storage aggiuntiva. Con Cloud Volumes ONTAP, la scalabilità dello storage a livello di PB è una combinazione di due fattori: Il tiering dei dati utilizzati di rado per lo storage a oggetti dallo storage a blocchi e lo stacking delle licenze Cloud Volumes ONTAP senza elaborazione aggiuntiva.</block>
  <block id="1a4f71bef2c7cfcc6846e82e9e0e0331" category="section-title">Protocolli multipli</block>
  <block id="11d6ae97757031ae53e1437c9c9b61bd" category="paragraph">I sistemi NetApp supportano la maggior parte dei protocolli per le implementazioni Hadoop, tra cui SAS, iSCSI, FCP, InfiniBand, E NFS.</block>
  <block id="98ed4f29e9a08c43fe10dda6782e567e" category="section-title">Soluzioni operative e supportate</block>
  <block id="dc15faa991f0a6740734b42c6e08c347" category="inline-link">MapR</block>
  <block id="464e596f1568de8e5f19e16e09beaaa8" category="inline-link">Hortonworks</block>
  <block id="f1fd1913c968a1c383c88631e335a7ca" category="inline-link">certificazione</block>
  <block id="7454739e907f5595ae61d84b8547f574" category="inline-link">partner</block>
  <block id="b1202a92f536818c64c3005cf78d8e35" category="paragraph">Le soluzioni Hadoop descritte in questo documento sono supportate da NetApp. Queste soluzioni sono certificate anche con i principali distributori Hadoop. Per ulteriori informazioni, consultare<block ref="cc609e66e0173716d91f0397bfa09e1b" category="inline-link-rx"></block> sito, il<block ref="030fa12946d3d4653223853ac09b7183" category="inline-link-rx"></block> E il Cloudera<block ref="110185abc20d52e7eb83135b84742416" category="inline-link-rx"></block> e.<block ref="a573734769be98dedf1aa2242c0eb40c" category="inline-link-rx"></block> siti.</block>
  <block id="7a2a776baec23a88727e6039089b8193" category="inline-link-macro">Successivo: Pubblico di riferimento.</block>
  <block id="e8020665ce34622c78e50d808e554235" category="paragraph"><block ref="e8020665ce34622c78e50d808e554235" category="inline-link-macro-rx"></block></block>
  <block id="614eb548d72efbb3690b5c131745db1b" category="summary">Questa pagina descrive la convalida delle performance di Confluent all'interno dei parametri di questa soluzione.</block>
  <block id="28052d386826afbb88768d0629570b19" category="doc">Convalida delle performance confluente</block>
  <block id="e0c5d30e7d8ab807973bb9e8800f9f30" category="paragraph"><block ref="e0c5d30e7d8ab807973bb9e8800f9f30" category="inline-link-macro-rx"></block></block>
  <block id="3ec7b1ca1aaf25c9bbca707f1ca8e466" category="paragraph">Abbiamo eseguito la verifica con la piattaforma confluente per lo storage su più livelli su NetApp ONTAP. I team NetApp e Confluent hanno lavorato insieme a questa verifica ed hanno eseguito i test case richiesti per l'IT.</block>
  <block id="1f567e45477749710cbc14cf6b10afc4" category="section-title">Configurazione confluente</block>
  <block id="99b45ae42dbbf816c910ba27197525dc" category="paragraph">Per la configurazione, abbiamo utilizzato tre zookeeper, cinque broker e cinque server di test con 256 GB di RAM e 16 CPU. Per lo storage NetApp, abbiamo utilizzato ONTAP con una coppia AFF A900 ha. Lo storage e i broker sono stati connessi tramite connessioni a 100 GbE.</block>
  <block id="77727c2ca2ac5beb0de2853929b43367" category="paragraph">La figura seguente mostra la topologia di rete della configurazione utilizzata per la verifica dello storage su più livelli.</block>
  <block id="57e8d3257fec5774d2e8d38588771a69" category="inline-image-macro">Questa figura mostra la topologia di rete della configurazione utilizzata per la verifica dello storage su più livelli.</block>
  <block id="e1265b0a6795e57b3d1df5094ecde2bb" category="paragraph"><block ref="e1265b0a6795e57b3d1df5094ecde2bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d9b75f4efe285b9777255f14c81323b" category="paragraph">I server degli strumenti agiscono come client applicativi che inviano o ricevono eventi da o verso i nodi confluenti.</block>
  <block id="1068af448bd05a968329fd2341036bfb" category="paragraph">Abbiamo utilizzato i seguenti parametri di test:</block>
  <block id="3bfb3f2755d25ed45d39dad8b3ed3008" category="paragraph">Per la verifica, abbiamo utilizzato ONTAP con il protocollo HTTP, ma anche HTTPS ha funzionato. La chiave di accesso e la chiave segreta vengono memorizzate nel nome file fornito in<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> parametro.</block>
  <block id="86d7ae5e1e87e4958b4fafcbca603956" category="section-title">Storage controller NetApp – ONTAP</block>
  <block id="b915ce35d395a0d68a794b87705f95fa" category="paragraph">Abbiamo configurato una singola configurazione di coppia ha in ONTAP per la verifica.</block>
  <block id="b9d2b35b3cfffa153fd4ed3401cb9dd9" category="inline-image-macro">Questa immagine mostra come l'ambiente è stato configurato come una singola coppia ha per la verifica.</block>
  <block id="0ccd17060e15591b9c8588dc7d974ecd" category="paragraph"><block ref="0ccd17060e15591b9c8588dc7d974ecd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7069b530e46a91698a16159b7d083019" category="section-title">Risultati della verifica</block>
  <block id="3af1efc909fae49a716fe2d22ba24290" category="paragraph">Abbiamo completato i seguenti cinque casi di test per la verifica. I primi due erano test di funzionalità e i restanti tre erano test di performance.</block>
  <block id="09da8339466c8b6111e4f310f1b78cb5" category="paragraph">Questo test esegue operazioni di base come GET, put ed DELETE nell'archivio di oggetti utilizzato per lo storage a più livelli utilizzando le chiamate API.</block>
  <block id="622ce818e2b8228cee071a827a43e1b2" category="paragraph">Questo test verifica la funzionalità end-to-end dello storage a oggetti. Crea un argomento, crea un flusso di eventi per l'argomento appena creato, attende che i broker archivino i segmenti nello storage a oggetti, consuma il flusso di eventi e convalida le corrispondenze del flusso consumato con il flusso prodotto. Questo test è stato eseguito con e senza un'iniezione di errori dello store di oggetti. Abbiamo simulato il guasto del nodo arrestando il servizio di gestione dei servizi in uno dei nodi in ONTAP e convalidando che la funzionalità end-to-end funziona con lo storage a oggetti.</block>
  <block id="2712a580ff4c3586c7ba3534b78aad18" category="section-title">Generatore di carichi di lavoro producete-consumate</block>
  <block id="0c22172129c2d0d58a5685fa1094fca0" category="paragraph">Questo test genera indirettamente il carico di lavoro di scrittura nell'archivio di oggetti attraverso l'archiviazione dei segmenti. Il carico di lavoro di lettura (segmenti letti) è stato generato dallo storage a oggetti quando i gruppi di consumatori hanno recuperato i segmenti. Questo carico di lavoro è stato generato da uno script TOCC. Questo test ha verificato le prestazioni di lettura e scrittura sullo storage a oggetti in thread paralleli. Abbiamo eseguito test con e senza l'iniezione di errori del negozio di oggetti come abbiamo fatto per il test di correttezza della funzionalità di tiering.</block>
  <block id="2a7273e52c0214e6f0b27bf1e870960e" category="section-title">Generatore di workload di conservazione</block>
  <block id="48771387cb6a84889bc1db951598f78c" category="paragraph">Questo test ha controllato le prestazioni di eliminazione di uno storage a oggetti con un carico di lavoro di conservazione degli argomenti pesante. Il carico di lavoro di conservazione è stato generato utilizzando uno script TOCC che produce molti messaggi in parallelo a un argomento di test. L'argomento del test è stato configurato con un'impostazione di conservazione aggressiva basata sulle dimensioni e sul tempo che ha causato la rimozione continua del flusso di eventi dall'archivio di oggetti. I segmenti sono stati quindi archiviati. Ciò ha portato a numerose eliminazioni nello storage a oggetti da parte del broker e alla raccolta delle performance delle operazioni di eliminazione degli archivi di oggetti.</block>
  <block id="047fb529cf71ef63efe04d4185302684" category="paragraph">Per informazioni dettagliate sulla verifica, consultare<block ref="86830f666762f920df1dddf1c71e6509" category="inline-link-rx"></block> sito web.</block>
  <block id="0e20876ceb73ae36999db9f6c412bdc5" category="inline-link-macro">Avanti: Test delle performance con generatore di carichi di lavoro producete-consumate.</block>
  <block id="ab82cfabb720bf1d31365b6ce33825f9" category="paragraph"><block ref="ab82cfabb720bf1d31365b6ce33825f9" category="inline-link-macro-rx"></block></block>
  <block id="d4baa2e552beefa00e93883ed51f3ba2" category="summary">On-premise, abbiamo utilizzato il controller di storage NetApp AFF A900 con ONTAP 9.12.1RC1 per convalidare le performance e la scalabilità di un cluster Kafka. Abbiamo utilizzato lo stesso tested delle Best practice per lo storage a più livelli precedenti con ONTAP e AFF.</block>
  <block id="1e753c720a0b773dd9d69024ca734577" category="doc">Panoramica e validazione delle performance con AFF A900 on-premise</block>
  <block id="8f5ebe1b5fee3c826c16a4c5e9c8f473" category="inline-link-macro">Precedente: Panoramica delle performance e validazione in AWS.</block>
  <block id="dfaa047aba8947a9ca42df42a70eb4ad" category="paragraph"><block ref="dfaa047aba8947a9ca42df42a70eb4ad" category="inline-link-macro-rx"></block></block>
  <block id="94391d4f56386aadb6f39e1a596f2427" category="paragraph">On-premise, abbiamo utilizzato il controller di storage NetApp AFF A900 con ONTAP 9.12.1RC1 per convalidare le performance e la scalabilità di un cluster Kafka. Abbiamo utilizzato lo stesso tested delle Best practice per lo storage a più livelli precedenti con ONTAP e AFF.</block>
  <block id="b1e7584c9874b52caeb25c3646e8f273" category="paragraph">Abbiamo utilizzato Confluent Kafka 6.2.0 per valutare AFF A900. Il cluster include otto nodi di broker e tre nodi di zookeeper. Per il test delle performance, abbiamo utilizzato cinque nodi di lavoro OMB.</block>
  <block id="e41e134e8e174865d04443048e1866af" category="paragraph"><block ref="e41e134e8e174865d04443048e1866af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">Configurazione dello storage</block>
  <block id="637d24b49cc32320a5e44ea905f65d10" category="paragraph">Abbiamo utilizzato le istanze di NetApp FlexGroups per fornire un singolo namespace per le directory di log, semplificando il ripristino e la configurazione. Abbiamo utilizzato NFSv4.1 e pNFS per fornire accesso diretto al percorso ai dati del segmento di registro.</block>
  <block id="50ff5e789ae0742f2485b5147c072643" category="section-title">Tuning del client</block>
  <block id="fc3a7751877b7f4e9a71c82ad3da7e44" category="paragraph">Ogni client ha montato l'istanza di FlexGroup con il seguente comando.</block>
  <block id="a5b2794b174e20f0b6dd9350cba3df82" category="paragraph">Inoltre, abbiamo aumentato il<block ref="44d907b0e69e5aa31320f9e86a7ef440" prefix=" " category="inline-code"></block> dal valore predefinito<block ref="ea5d2f1c4608232e07d3aa3d998e5135" prefix=" " category="inline-code"></block> a.<block ref="045117b0e0a11a242b9765e79cbf113f" prefix=" " category="inline-code"></block>. Corrisponde al limite predefinito di slot di sessione in ONTAP.</block>
  <block id="31305973da10c7b492918a2ad2b3deee" category="section-title">Messa a punto del broker Kafka</block>
  <block id="8f9087ae165490f7d809fb8ffd625bba" category="paragraph">Per massimizzare il throughput nel sistema sottoposto a test, abbiamo aumentato significativamente i parametri predefiniti per alcuni pool di thread chiave. Si consiglia di seguire le Best practice di Confluent Kafka per la maggior parte delle configurazioni. Questo tuning è stato utilizzato per massimizzare la concorrenza tra i/o in sospeso e storage. Questi parametri possono essere regolati in modo da corrispondere alle risorse di calcolo e agli attributi di storage del broker.</block>
  <block id="0e80721091b1e58209e2877462ebbd21" category="section-title">Metodologia di test del generatore di workload</block>
  <block id="9707ee58e22a2478985c56025e656cad" category="paragraph">Abbiamo utilizzato le stesse configurazioni OMB utilizzate per i test cloud per il driver di throughput e la configurazione degli argomenti.</block>
  <block id="dbdfae7d08a693255815e0890397b78f" category="list-text">È stato eseguito il provisioning di un'istanza di FlexGroup utilizzando Ansible su un cluster AFF.</block>
  <block id="6c2577e00543c33096c33e1b2e79742d" category="list-text">PNFS è stato attivato su ONTAP SVM.</block>
  <block id="7fe5c7aaf126c7432ba86d9e145f59a4" category="list-text">Il carico di lavoro è stato attivato con il driver di throughput utilizzando la stessa configurazione del carico di lavoro di Cloud Volumes ONTAP. Vedere la sezione "<block ref="f628eac6c1ff8c1b0462e81ea7b2efc1" category="inline-xref-macro-rx"></block>" sotto. Il carico di lavoro utilizzava un fattore di replica di 3, il che significa che in NFS sono state mantenute tre copie di segmenti di log.</block>
  <block id="dfe2c8a29d6798ed2d2dae4af3b4e5e7" category="inline-xref">analisi dei limiti dello storage</block>
  <block id="c2a038ea3f35076598b99806cd90a3c5" category="list-text">Infine, abbiamo completato le misurazioni utilizzando un backlog per misurare la capacità dei consumatori di recuperare i messaggi più recenti. OMB crea un backlog mettendo in pausa i consumatori durante l'inizio di una misurazione. Ciò produce tre fasi distinte: Creazione di backlog (traffico solo produttore), eliminazione dei backlog (una fase pesante per i consumatori in cui i consumatori si mettono al passo con gli eventi persi in un argomento) e lo stato stazionario. Vedere la sezione "<block ref="a2eee99fc052f067d68a9273d62093f1" category="inline-xref-macro-rx"></block>" per ulteriori informazioni.</block>
  <block id="158bb82f009332b2fe16aba7bebc0c15" category="section-title">Performance a stato stazionario</block>
  <block id="216824b7a5a0da585075bc35333402f6" category="paragraph">Abbiamo valutato AFF A900 utilizzando il benchmark OpenMessaging per fornire un confronto simile a Cloud Volumes ONTAP in AWS e DAS in AWS. Tutti i valori delle performance rappresentano il throughput del cluster Kafka a livello di produttore e consumatore.</block>
  <block id="34121e3b81b5330bbb499603af5609e6" category="paragraph">Le performance a stato stazionario con Confluent Kafka e AFF A900 hanno raggiunto un throughput medio di oltre 3,4 Gbps sia per i produttori che per i consumatori. Si tratta di oltre 3.4 milioni di messaggi nel cluster Kafka. Visualizzando il throughput sostenuto in byte al secondo per BrokerTopicMetrics, vediamo le eccellenti performance di stato stazionario e il traffico supportato da AFF A900.</block>
  <block id="c99b1e0f8a1447330448c8c7dc3df6b6" category="inline-image-macro">Questo grafico mostra il throughput di rete del broker.</block>
  <block id="0b01283779b69987a07a2c2d50ccb15d" category="paragraph"><block ref="0b01283779b69987a07a2c2d50ccb15d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9877d3e22635e0b37f0b74ab2d832d05" category="paragraph">Questo si allinea perfettamente con la visualizzazione dei messaggi inviati per argomento. Il seguente grafico fornisce una descrizione dettagliata per argomento. Nella configurazione testata abbiamo visto quasi 900.000 messaggi per argomento in quattro argomenti.</block>
  <block id="a0a1dff924171568d861731a12802528" category="paragraph"><block ref="a0a1dff924171568d861731a12802528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc35bf5a15bb7c42ab972c7038f773f5" category="section-title">Performance estreme e analisi dei limiti dello storage</block>
  <block id="58b4fe8d21ee892b9633349960eaa7ab" category="paragraph">Per AFF, abbiamo anche testato con OMB utilizzando la funzionalità di backlog. La funzionalità di backlog mette in pausa gli abbonamenti consumer mentre nel cluster Kafka viene creato un backlog di eventi. Durante questa fase, si verifica solo il traffico del produttore, che genera eventi che vengono impegnati nei registri. In questo modo si emulano più da vicino i flussi di lavoro di elaborazione batch o di analisi offline; in questi flussi di lavoro, le sottoscrizioni consumer vengono avviate e devono leggere i dati storici che sono già stati rimossi dalla cache del broker.</block>
  <block id="5519a4dc3c42cae95400800bbaeaecfc" category="paragraph">Per comprendere le limitazioni dello storage sul throughput consumer in questa configurazione, abbiamo misurato la fase solo produttore per capire quanto traffico di scrittura potrebbe assorbire l'A900. Vedere la sezione successiva "<block ref="dbf93a9130703fe2432219c42c2bf311" category="inline-xref-macro-rx"></block>" per capire come sfruttare questi dati.</block>
  <block id="feec11a45c1fd079250c6f3603d708cd" category="paragraph">Durante la parte solo produttore di questa misurazione, abbiamo riscontrato un throughput elevato che ha spinto i limiti delle performance di A900 (quando le altre risorse di broker non erano sature e il traffico consumer e dei produttori).</block>
  <block id="364db2a868997ed12ba4b16039b53a68" category="paragraph"><block ref="364db2a868997ed12ba4b16039b53a68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f237b36d09d10702066fb620cf352dcf" category="admonition">Abbiamo aumentato le dimensioni del messaggio a 16.000 per questa misurazione per limitare le spese generali per messaggio e massimizzare il throughput dello storage ai punti di montaggio NFS.</block>
  <block id="9e1dbe9319ed19b15341f3000f56398a" category="paragraph">Il cluster Confluent Kafka ha raggiunto un picco di throughput dei produttori di 4,03 Gbps.</block>
  <block id="3355268f822f520fe03b272691c2e428" category="paragraph">Dopo che OMB ha completato il popolamento dell'eventbacklog, il traffico consumer è stato riavviato. Durante le misurazioni con il deflusso del backlog, abbiamo osservato un throughput dei consumatori di oltre 20 Gbps in tutti gli argomenti. Il throughput combinato per il volume NFS che memorizza i dati di log OMB si avvicinava a ~30 Gbps.</block>
  <block id="157a25969caf77d231e319ce70f0b637" category="section-title">Guida al dimensionamento</block>
  <block id="2e4bacad236b9e36d868b929042e2bad" category="inline-link">guida al dimensionamento</block>
  <block id="eec877a6f9c2530996fae2423259c2c6" category="paragraph">Amazon Web Services offre un<block ref="e9ae0e8f89540055129f0fae422bdb9a" category="inline-link-rx"></block> Per il dimensionamento e la scalabilità dei cluster Kafka.</block>
  <block id="cc4abcaa3ba3e4f795b82759d3dcd056" category="paragraph">Questo dimensionamento fornisce una formula utile per determinare i requisiti di throughput dello storage per il cluster Kafka:</block>
  <block id="f2fb73fb163775775c1145d28c68ad20" category="paragraph">Per un throughput aggregato prodotto nel cluster di tcluster con un fattore di replica di r, il throughput ricevuto dallo storage del broker è il seguente:</block>
  <block id="0acbbdd0cc159664d8baab43c6d168bd" category="paragraph">Questo può essere ulteriormente semplificato:</block>
  <block id="28c949d6bdead032a1410c176cbf74cb" category="paragraph">Questa formula consente di selezionare la piattaforma ONTAP appropriata per le tue esigenze di hot Tier Kafka.</block>
  <block id="df3f8ed04b35156def4360bb05a77cc1" category="paragraph">La seguente tabella illustra il throughput previsto dal produttore per l'A900 con diversi fattori di replica:</block>
  <block id="329589e3ff014cb50ee2238aecc6a867" category="cell">Fattore di replica</block>
  <block id="75ec49708cc8881a7762e3740e342ca3" category="cell">Throughput produttore (GPPS)</block>
  <block id="c2b3050f7fde2050bb86e4e9ef0f7567" category="cell">3 (misurato)</block>
  <block id="31053ad0506e935470ca21b43cae98cf" category="cell">3.4</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5.1</block>
  <block id="a9d9d1b0257dda96d595bd00149cccdb" category="cell">10.2</block>
  <block id="e5a7cf20f86f14251d25ab33d3eb07fb" category="paragraph"><block ref="e5a7cf20f86f14251d25ab33d3eb07fb" category="inline-link-macro-rx"></block></block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">Questa sezione fornisce un riepilogo dei casi di utilizzo e delle soluzioni fornite da NetApp per soddisfare i vari requisiti di protezione dei dati Hadoop.</block>
  <block id="23496143e5ca83c13eb4d953786abdcd" category="inline-link-macro">Precedente: Caso d'utilizzo 5 - accelerare i carichi di lavoro di analisi.</block>
  <block id="09b7371b2ae3168a3c54b30e4966e86e" category="paragraph"><block ref="09b7371b2ae3168a3c54b30e4966e86e" category="inline-link-macro-rx"></block></block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">Questa sezione fornisce un riepilogo dei casi di utilizzo e delle soluzioni fornite da NetApp per soddisfare i vari requisiti di protezione dei dati Hadoop. Utilizzando il data fabric basato su NetApp, i clienti possono:</block>
  <block id="ce0bf05854efb234905c751e40774ab5" category="list-text">Avere la flessibilità di scegliere le giuste soluzioni per la protezione dei dati sfruttando le ricche funzionalità di gestione dei dati di NetApp e l'integrazione con i flussi di lavoro nativi di Hadoop.</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">Ridurre i tempi di backup del cluster Hadoop di quasi il 70%.</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">Elimina qualsiasi effetto sulle performance derivante dai backup del cluster Hadoop.</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">Protezione dei dati multicloud e accesso ai dati da diversi cloud provider contemporaneamente a una singola fonte di dati di analisi.</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">Crea copie cluster Hadoop veloci ed efficienti in termini di spazio utilizzando la tecnologia FlexClone.</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">Per ulteriori informazioni sulle informazioni descritte in questo documento, consultare i seguenti documenti e/o siti Web:</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">Soluzioni NetApp per l'analisi dei big data</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">Apache Spark workload con lo storage NetApp</block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">Soluzioni storage NetApp per Apache Spark</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">Apache Hadoop su data fabric abilitato da NetApp</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="list-text">Modulo NetApp in-place Analytics</block>
  <block id="1d669c79bffe95dd384dffb8309a0d40" category="inline-link"><block ref="1d669c79bffe95dd384dffb8309a0d40" category="inline-link-rx"></block></block>
  <block id="fde1cd76fa73f8065aeb8a97c77b40ec" category="paragraph"><block ref="fde1cd76fa73f8065aeb8a97c77b40ec" category="inline-link-rx"></block></block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">Ringraziamenti</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">Paul Burland, Sales Rep, ANZ Victoria District Sales, NetApp</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">Hoseb Dermanilian, Business Development Manager, NetApp</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">Lee Dorrier, Director MPSG, NetApp</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">David Thiessen, Systems Engineer, ANZ Victoria District se, NetApp</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">Gennaio 2018</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">Ottobre 2021</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">Aggiornato con il caso di utilizzo n. 5: Accelerare il carico di lavoro di analisi</block>
  <block id="b0c400a1c1ac5de2cbdc877645b349a0" category="summary">Questa sezione descrive l'hardware e il software utilizzati per la verifica delle performance nell'implementazione della piattaforma confluente con NetApp ONTAP per lo storage su più livelli. La seguente tabella illustra l'architettura della soluzione e i componenti di base.</block>
  <block id="c0db72d078098472051229dbdb83118e" category="inline-link-macro">Precedente: Panoramica.</block>
  <block id="875353af43abce06e81496931b9482ef" category="paragraph"><block ref="875353af43abce06e81496931b9482ef" category="inline-link-macro-rx"></block></block>
  <block id="5197b1c9433e86b5ed33786625f77786" category="paragraph">I controller di storage Confluent e NetApp AFF A900 con tecnologia ONTAP sono sistemi distribuiti progettati per i flussi di dati. Entrambi sono scalabili orizzontalmente, tolleranti agli errori e offrono eccellenti prestazioni sotto carico. Si integrano a vicenda nello streaming di dati distribuiti e nell'elaborazione del flusso con costi di storage inferiori grazie a tecnologie per la riduzione dei dati che riducono al minimo l'impatto dei dati. Il controller di storage AFF A900 offre performance elevate, consentendo al contempo il disaccoppiamento delle risorse di calcolo e storage dei dati. Ciò semplifica l'amministrazione del sistema e consente di scalare le risorse in modo indipendente.</block>
  <block id="8ebef54f33ae0fdc7c4dcb83539b6eac" category="inline-image-macro">Immagine che mostra la panoramica della soluzione.</block>
  <block id="52dff9f6353660d69eddc1e9fdee4a83" category="paragraph"><block ref="52dff9f6353660d69eddc1e9fdee4a83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f75094292f4afb812bc29237348d9948" category="cell">Confluent Platform versione 6.2</block>
  <block id="5cc4fd015c7740c575d319eefacbce83" category="list-text">3 zookeeper</block>
  <block id="8f6a506566bd03a47cafb69561bafe0f" category="list-text">8 server di broker</block>
  <block id="aa76981d988c82fc8b387682968887e6" category="list-text">5 server di strumenti</block>
  <block id="b56d58a9a181bae1fa65f36407ea002c" category="list-text">1 Grafana</block>
  <block id="4af3adf9207f6f8d2d6d9edda08f0638" category="list-text">1 centro di controllo</block>
  <block id="de4d788671df5cf79fda01236d8fc9a6" category="cell">NetApp ONTAP per i bucket Warm</block>
  <block id="37e0c77638b1388d83b997c8dffdb6d3" category="list-text">1 coppia AFF A900 ad alta disponibilità (ha)</block>
  <block id="2e1c9b5ce764f890af0aebf38f1a500a" category="list-text">100 GbE</block>
  <block id="983e16c42b860c2511053f17d60918c8" category="list-text">2 CPU; 16 core fisici in totale</block>
  <block id="ce4750dd79017960eed95bd3b2677eb4" category="list-text">Intel Xeon</block>
  <block id="01dcc4e221fc9ff7472c5102b082eaf4" category="list-text">256 GB di memoria fisica</block>
  <block id="433304c312dd41f05955324749c0a47f" category="list-text">Doppia porta 100 GbE</block>
  <block id="39bc57d27d632df4261bc60caf39a90c" category="paragraph"><block ref="39bc57d27d632df4261bc60caf39a90c" category="inline-link-macro-rx"></block></block>
  <block id="d7023badac36eeb28bf29785a97c493c" category="inline-link-macro">Precedente: Dettagli sull'architettura della soluzione.</block>
  <block id="258ee3f437d6a20985ccf4e13065a097" category="paragraph"><block ref="258ee3f437d6a20985ccf4e13065a097" category="inline-link-macro-rx"></block></block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">NetApp StorageGRID è una piattaforma di storage a oggetti dalle performance elevate e conveniente. Utilizzando lo storage a più livelli, la maggior parte dei dati su Confluent Kafka, che sono memorizzati nello storage locale o NELLO storage SAN del broker, viene scaricata nell'archivio a oggetti remoto. Questa configurazione comporta significativi miglioramenti operativi riducendo i tempi e i costi per ribilanciare, espandere o ridurre i cluster o sostituire un broker guasto. Lo storage a oggetti svolge un ruolo importante nella gestione dei dati che risiedono nel Tier dell'archivio di oggetti, motivo per cui è importante scegliere lo storage a oggetti giusto.</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">StorageGRID offre una gestione dei dati globale intelligente e basata su policy utilizzando un'architettura grid distribuita e basata su nodi. Semplifica la gestione di petabyte di dati non strutturati e miliardi di oggetti attraverso il suo onnipresente namespace globale a oggetti combinato con sofisticate funzionalità di gestione dei dati. L'accesso a oggetti a chiamata singola si estende tra i siti e semplifica le architetture ad alta disponibilità garantendo al contempo un accesso continuo agli oggetti, indipendentemente dalle interruzioni del sito o dell'infrastruttura.</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">La multi-tenancy consente di gestire in modo sicuro più cloud non strutturati e applicazioni dati aziendali all'interno dello stesso grid, aumentando il ROI e i casi di utilizzo per NetApp StorageGRID. Puoi creare diversi livelli di servizio con policy sul ciclo di vita degli oggetti basate sui metadati, ottimizzando durata, protezione, performance e località in più aree geografiche. Gli utenti possono regolare le policy di gestione dei dati, monitorare e applicare i limiti di traffico per riallinearsi con il panorama dei dati senza interruzioni in base al cambiamento dei requisiti in ambienti IT in continua evoluzione.</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">StorageGRID Grid Manager è un'interfaccia grafica basata su browser che consente di configurare, gestire e monitorare il sistema StorageGRID in ubicazioni distribuite a livello globale in un unico pannello di controllo.</block>
  <block id="a96dbd2aff4998074bc0ca48dc4817d5" category="paragraph"><block ref="a96dbd2aff4998074bc0ca48dc4817d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">Con l'interfaccia Gestore griglia di StorageGRID è possibile eseguire le seguenti attività:</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">Policy di Information Lifecycle Management</block>
  <block id="a1d8b1b1990901cd5a97dd0f3dee2da9" category="inline-link-macro">Policy ILM</block>
  <block id="37e0a993cc0a3c5aacb623e412befc5b" category="inline-link-macro">Regole ILM</block>
  <block id="0beeefc6ac257658ea119788351ad268" category="paragraph">StorageGRID offre policy di gestione dei dati flessibili che includono la conservazione delle copie di replica degli oggetti e l'utilizzo di schemi EC (erasure coding) come 2+1 e 4+2 (tra gli altri) per memorizzare gli oggetti, a seconda dei requisiti specifici di performance e protezione dei dati. Con il variare dei carichi di lavoro e dei requisiti nel tempo, è comune che anche le policy ILM debbano cambiare nel tempo. La modifica delle policy ILM è una funzionalità fondamentale che consente ai clienti StorageGRID di adattarsi al loro ambiente in continua evoluzione in modo rapido e semplice. Controllare <block ref="b2ddd4069e5288685e27e7989fb1a613" category="inline-link-macro-rx"></block> e. <block ref="7593bc4c70a5537fc14593339f7e6540" category="inline-link-macro-rx"></block> configurazione in StorageGRID.</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712, SG5760, SG6060 O SGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">StorageGRID scala le performance aggiungendo più nodi di storage, che possono essere macchine virtuali, bare metal o appliance appositamente costruite come <block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block>. Nei nostri test, abbiamo superato i requisiti di performance chiave di Apache Kafka con un grid a tre nodi di dimensioni minime utilizzando l'appliance SGF6024. Man mano che i clienti scalano il cluster Kafka con broker aggiuntivi, possono aggiungere più nodi di storage per aumentare performance e capacità.</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">Bilanciamento del carico e configurazione degli endpoint</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">I nodi di amministrazione in StorageGRID forniscono l'interfaccia utente (interfaccia utente) e l'endpoint REST API per visualizzare, configurare e gestire il sistema StorageGRID, nonché registri di controllo per tenere traccia dell'attività del sistema. Per fornire un endpoint S3 altamente disponibile per lo storage a più livelli Confluent Kafka, abbiamo implementato il bilanciamento del carico StorageGRID, che viene eseguito come servizio su nodi di amministrazione e nodi gateway. Inoltre, il bilanciamento del carico gestisce anche il traffico locale e comunica con GSLB (Global Server Load Balancing) per agevolare il disaster recovery.</block>
  <block id="95ae2f11a98975eca88411c818226d25" category="paragraph">Per migliorare ulteriormente la configurazione degli endpoint, StorageGRID fornisce policy di classificazione del traffico integrate nel nodo di amministrazione, consente di monitorare il traffico dei workload e applica vari limiti di qualità del servizio (QoS) ai carichi di lavoro. I criteri di classificazione del traffico vengono applicati agli endpoint del servizio bilanciamento del carico StorageGRID per i nodi gateway e i nodi di amministrazione. Queste policy possono essere utili per la definizione e il monitoraggio del traffico.</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">Classificazione del traffico in StorageGRID</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">StorageGRID dispone di funzionalità QoS integrate. I criteri di classificazione del traffico possono aiutare a monitorare diversi tipi di traffico S3 provenienti da un'applicazione client. È quindi possibile creare e applicare policy per limitare il traffico in base alla larghezza di banda in/out, al numero di richieste simultanee in lettura/scrittura o alla velocità di richiesta in lettura/scrittura.</block>
  <block id="611f69baa46f691eeeb33645e83f0fcb" category="paragraph">Apache Kafka è un'implementazione framework di un bus software che utilizza l'elaborazione del flusso scritta in Java e Scala. Il suo scopo è fornire una piattaforma unificata, ad alto throughput e a bassa latenza per la gestione dei feed di dati in tempo reale. Kafka può connettersi a un sistema esterno per l'esportazione e l'importazione dei dati tramite Kafka Connect e fornisce Kafka Streams, una libreria di elaborazione del flusso Java. Kafka utilizza un protocollo binario basato su TCP ottimizzato per l'efficienza e basato su un'astrazione "message set" che raggruppa naturalmente i messaggi per ridurre l'overhead del roundtrip di rete. Ciò consente operazioni su disco sequenziali più grandi, pacchetti di rete più grandi e blocchi di memoria contigui, consentendo a Kafka di trasformare un flusso bursty di scritture casuali di messaggi in scritture lineari. La figura seguente mostra il flusso di dati di base di Apache Kafka.</block>
  <block id="d1675da945892e06b2f84c42c32b7074" category="paragraph"><block ref="d1675da945892e06b2f84c42c32b7074" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">Kafka memorizza i messaggi chiave-valore che provengono da un numero arbitrario di processi chiamati produttori. I dati possono essere suddivisi in partizioni diverse all'interno di diversi argomenti. All'interno di una partizione, i messaggi vengono ordinati in base agli offset (la posizione di un messaggio all'interno di una partizione) e indicizzati e memorizzati insieme a un indicatore data e ora. Altri processi denominati consumer possono leggere i messaggi dalle partizioni. Per l'elaborazione dei flussi, Kafka offre l'API Streams che consente di scrivere applicazioni Java che consumano dati da Kafka e di riscrivere i risultati a Kafka. Apache Kafka funziona anche con sistemi di elaborazione del flusso esterni come Apache Apex, Apache Flink, Apache Spark, Apache Storm e Apache NiFi.</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">Kafka viene eseguito su un cluster di uno o più server (chiamati broker) e le partizioni di tutti gli argomenti vengono distribuite tra i nodi del cluster. Inoltre, le partizioni vengono replicate su più broker. Questa architettura consente a Kafka di inviare flussi di messaggi enormi in modo fault-tolerant e ha consentito al reparto IT di sostituire alcuni dei sistemi di messaggistica convenzionali come Java message Service (JMS), Advanced message Queuing Protocol (AMQP) e così via. A partire dalla release 0.11.0.0, Kafka offre scritture transazionali, che forniscono un'elaborazione del flusso esattamente una volta usando l'API Streams.</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">Kafka supporta due tipi di argomenti: Regolare e compatto. Gli argomenti regolari possono essere configurati con un tempo di conservazione o un limite di spazio. Se ci sono record più vecchi del tempo di conservazione specificato o se viene superato il limite di spazio per una partizione, Kafka può eliminare i vecchi dati per liberare spazio di storage. Per impostazione predefinita, gli argomenti sono configurati con un tempo di conservazione di 7 giorni, ma è anche possibile memorizzare i dati a tempo indeterminato. Per gli argomenti compattati, i record non scadono in base ai limiti di tempo o spazio. Kafka considera invece i messaggi successivi come aggiornamenti dei messaggi meno recenti con la stessa chiave e garantisce di non eliminare mai l'ultimo messaggio per chiave. Gli utenti possono eliminare completamente i messaggi scrivendo un cosiddetto messaggio tombstone con il valore null per una chiave specifica.</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">Kafka offre cinque API principali:</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">*Producer API.* consente a un'applicazione di pubblicare flussi di record.</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">*API Consumer.* consente a un'applicazione di iscriversi ad argomenti ed elaborare flussi di record.</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">*Connector API.* esegue le API riutilizzabili di produttori e consumatori che possono collegare gli argomenti alle applicazioni esistenti.</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">*Streams API.* questa API converte i flussi di input in output e produce il risultato.</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">*Admin API.* utilizzato per gestire argomenti Kafka, broker e altri oggetti Kafka.</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">Le API consumer e Producer si basano sul protocollo di messaggistica Kafka e offrono un'implementazione di riferimento per i clienti consumer e Producer Kafka in Java. Il protocollo di messaging sottostante è un protocollo binario che gli sviluppatori possono utilizzare per scrivere i propri client consumer o Producer in qualsiasi linguaggio di programmazione. In questo modo, Kafka viene sbloccato dall'ecosistema JVM (Java Virtual Machine). Un elenco di client non Java disponibili viene mantenuto nel wiki Apache Kafka.</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Casi di utilizzo di Apache Kafka</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">Apache Kafka è più popolare per la messaggistica, il monitoraggio delle attività dei siti Web, le metriche, l'aggregazione dei log, l'elaborazione dei flussi, sourcing degli eventi e registrazione del commit.</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">Kafka ha migliorato il throughput, il partizionamento integrato, la replica e la tolleranza agli errori, il che lo rende una buona soluzione per le applicazioni di elaborazione dei messaggi su larga scala.</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">Kafka può ricostruire le attività di un utente (visualizzazioni di pagine, ricerche) in una pipeline di monitoraggio come un insieme di feed di iscrizione alla pubblicazione in tempo reale.</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">Kafka viene spesso utilizzato per il monitoraggio dei dati operativi. Ciò comporta l'aggregazione di statistiche da applicazioni distribuite per produrre feed centralizzati di dati operativi.</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">Molte persone utilizzano Kafka come sostituto di una soluzione di aggregazione dei log. L'aggregazione dei log generalmente raccoglie i file di log fisici dai server e li colloca in una posizione centrale (ad esempio, un file server o HDFS) per l'elaborazione. Kafka astratta i dettagli dei file e fornisce un'astrazione più pulita dei dati di log o degli eventi come flusso di messaggi. Ciò consente un'elaborazione a latenza ridotta e un supporto più semplice per più origini dati e un consumo di dati distribuito.</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">Molti utenti di Kafka elaborano i dati in pipeline di elaborazione costituite da più fasi, in cui i dati di input raw vengono utilizzati da argomenti di Kafka e quindi aggregati, arricchiti o altrimenti trasformati in nuovi argomenti per un ulteriore consumo o un'elaborazione di follow-up. Ad esempio, una pipeline di elaborazione per consigliare articoli di notizie potrebbe strisciare il contenuto degli articoli dai feed RSS e pubblicarlo in un argomento "articoli". Un'ulteriore elaborazione potrebbe normalizzare o deduplicare questo contenuto e pubblicare il contenuto pulito dell'articolo su un nuovo argomento, mentre una fase finale di elaborazione potrebbe tentare di consigliare questo contenuto agli utenti. Tali pipeline di elaborazione creano grafici dei flussi di dati in tempo reale in base ai singoli argomenti.</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">L'origine degli eventi è uno stile di progettazione dell'applicazione per cui le modifiche di stato vengono registrate come una sequenza di record ordinata in base al tempo. Il supporto di Kafka per i dati di log memorizzati di grandi dimensioni lo rende un eccellente backend per un'applicazione costruita in questo stile.</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">Kafka può fungere da commit-log esterno per un sistema distribuito. Il log consente di replicare i dati tra i nodi e funge da meccanismo di risyncing per i nodi guasti per il ripristino dei dati. La funzione di compattazione del log di Kafka aiuta a supportare questo caso d'utilizzo.</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">Confluent Platform è una piattaforma Enterprise-ready che completa Kafka con funzionalità avanzate progettate per accelerare lo sviluppo e la connettività delle applicazioni, consentire trasformazioni attraverso l'elaborazione del flusso, semplificare le operazioni aziendali su larga scala e soddisfare rigorosi requisiti architetturali. Creato dai creatori originali di Apache Kafka, Confluent amplia i vantaggi di Kafka con funzionalità di livello Enterprise, eliminando al contempo il peso della gestione o del monitoraggio di Kafka. Oggi, oltre il 80% delle aziende Fortune 100 è basato su tecnologia di streaming dei dati, e la maggior parte di esse utilizza Confluent.</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">Confluent Platform ti consente di concentrarti su come ricavare il valore di business dai tuoi dati piuttosto che preoccuparsi delle meccaniche sottostanti, come ad esempio il modo in cui i dati vengono trasportati o integrati tra sistemi diversi. In particolare, Confluent Platform semplifica la connessione delle origini dati a Kafka, la creazione di applicazioni di streaming e la protezione, il monitoraggio e la gestione dell'infrastruttura Kafka. Attualmente, Confluent Platform viene utilizzata per un'ampia gamma di casi di utilizzo in numerosi settori, dai servizi finanziari alla vendita al dettaglio, alle auto autonome, al rilevamento delle frodi, Microservizi e IoT.</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">La figura seguente mostra i componenti della piattaforma Confluent Kafka.</block>
  <block id="a4eaf48584aaa7df975a9275a8b4ee24" category="paragraph"><block ref="a4eaf48584aaa7df975a9275a8b4ee24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0693822e07a3206c53912f33e3d67758" category="section-title">Panoramica della tecnologia di streaming degli eventi di Confluent</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">Il fulcro della piattaforma confluente è<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block>, la piattaforma di streaming distribuito open-source più diffusa. Le principali funzionalità di Kafka sono le seguenti:</block>
  <block id="55be5d4d3f7143137050de9374d03f6f" category="section-title">Panoramica delle funzionalità aziendali della piattaforma Confluent</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">*Confluent Control Center.* sistema basato su GUI per la gestione e il monitoraggio di Kafka. Consente di gestire facilmente Kafka Connect e creare, modificare e gestire le connessioni ad altri sistemi.</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">*Connettori confluenti verso Kafka.* i connettori utilizzano l'API Kafka Connect per connettere Kafka ad altri sistemi come database, archivi di valori chiave, indici di ricerca e file system. Confluent Hub dispone di connettori scaricabili per le fonti di dati e i sink più diffusi, incluse le versioni completamente testate e supportate di questi connettori con Confluent Platform. Ulteriori dettagli sono disponibili<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>.</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">*Cluster con bilanciamento automatico.* offre bilanciamento del carico automatico, rilevamento degli errori e riparazione automatica. Fornisce supporto per l'aggiunta o la disattivazione di broker in base alle necessità, senza tuning manuale.</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">*Confluent auto data balancer.* monitora il cluster per il numero di broker, la dimensione delle partizioni, il numero di partizioni e il numero di leader all'interno del cluster. Consente di spostare i dati per creare un carico di lavoro uniforme nel cluster, riducendo al contempo il ribilanciamento del traffico per ridurre al minimo l'effetto sui carichi di lavoro di produzione durante il ribilanciamento.</block>
  <block id="4f9143a5adb8a0385a1c660d201ef274" category="inline-link-macro">Avanti: Verifica confluente.</block>
  <block id="d566a24bfcb09090b96a073132a83173" category="paragraph"><block ref="d566a24bfcb09090b96a073132a83173" category="inline-link-macro-rx"></block></block>
  <block id="90f0f970ed32524c528ba2778079d485" category="summary">NetApp dispone di tre portfolio di storage: FAS/AFF, e-Series e Cloud Volumes ONTAP. Abbiamo validato AFF e e-Series con il sistema di storage ONTAP per le soluzioni Hadoop con Apache Spark. Il data fabric basato su NetApp integra applicazioni e servizi di gestione dei dati (building block) per l'accesso, il controllo, la protezione e la sicurezza dei dati.</block>
  <block id="12a9f57585cd6b3b985dd451bf552845" category="doc">Panoramica delle soluzioni NetApp Spark</block>
  <block id="255ce02d0613433bc0a7c76f4afde71e" category="inline-link-macro">Precedente: Tecnologia della soluzione.</block>
  <block id="dd12a34c3b567f24a9da980ebdd52821" category="paragraph"><block ref="dd12a34c3b567f24a9da980ebdd52821" category="inline-link-macro-rx"></block></block>
  <block id="5e1c0d548834c9871fb6687dd0f1adab" category="paragraph">NetApp dispone di tre portfolio di storage: FAS/AFF, e-Series e Cloud Volumes ONTAP. Abbiamo validato AFF e e-Series con il sistema di storage ONTAP per le soluzioni Hadoop con Apache Spark. Il data fabric basato su NetApp integra i servizi e le applicazioni di gestione dei dati (building block) per l'accesso, il controllo, la protezione e la sicurezza dei dati, come mostrato nella figura seguente.</block>
  <block id="710b54a5dd637d8e21574c4fb3eea545" category="inline-image-macro">Il data fabric fornisce applicazioni e servizi di gestione dei dati.</block>
  <block id="84996abc8bbc3c77ef59d8a39c852d30" category="paragraph"><block ref="84996abc8bbc3c77ef59d8a39c852d30" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829a597c83ae2b02e991f062bb891ace" category="list-text">*Accesso diretto NetApp NFS.* offre i più recenti cluster Hadoop e Spark con accesso diretto ai volumi NetApp NFS senza requisiti aggiuntivi di software o driver.</block>
  <block id="d075304bce816c2722d405cac9bf4877" category="list-text">*La tecnologia NetApp SnapMirror.* offre funzionalità di protezione dei dati tra istanze cloud o NPS ONTAP on-premise e on-premise.</block>
  <block id="bd162abba0390e6a6e2e2581d449bf77" category="paragraph">La seguente figura illustra la soluzione Spark con lo storage NetApp.</block>
  <block id="0ec1ecf37e474c5f4116ab4ae95e84d9" category="inline-image-macro">Soluzione SPARK con lo storage NetApp.</block>
  <block id="0847e549ec9fd7e676ad66196c4210a2" category="paragraph"><block ref="0847e549ec9fd7e676ad66196c4210a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc4d71ccd96e1b29bc3437c1cb6a245e" category="paragraph">La soluzione Spark di ONTAP utilizza il protocollo di accesso diretto NetApp NFS per l'analisi in-place e i flussi di lavoro ai, ML e DL utilizzando l'accesso ai dati di produzione esistenti. I dati di produzione disponibili per i nodi Hadoop vengono esportati per eseguire lavori analitici in-place e ai, ML e DL. È possibile accedere ai dati da elaborare nei nodi Hadoop con l'accesso diretto NetApp NFS o senza di essi. In Spark con la versione standalone o.<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> Cluster manager, è possibile configurare un volume NFS utilizzando<block ref="9e2ac298651bd7b0cfb93c36f03ec623" prefix=" " category="inline-code"></block>. Abbiamo validato tre casi di utilizzo con set di dati diversi. I dettagli di queste validazioni sono presentati nella sezione "risultati del test". (xref)</block>
  <block id="955ae639ea2500f38215e8263610b119" category="paragraph">La seguente figura illustra il posizionamento dello storage NetApp Apache Spark/Hadoop.</block>
  <block id="78157b6c5aece6e0b7b7ea998dce3a8a" category="inline-image-macro">Posizionamento dello storage NetApp Apache Spark/Hadoop.</block>
  <block id="5af92584fa4ab2b78abca73f9bbdcf42" category="paragraph"><block ref="5af92584fa4ab2b78abca73f9bbdcf42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cf3adbf38f17f8e0c86c8531fc379b7" category="paragraph">Abbiamo identificato le caratteristiche esclusive della soluzione Spark e-Series, della soluzione Spark AFF/FAS ONTAP e della soluzione Spark StorageGRID, e abbiamo eseguito test e validazione dettagliati. In base alle nostre osservazioni, NetApp consiglia la soluzione e-Series per le installazioni in ambiente e le nuove implementazioni scalabili e la soluzione AFF/FAS per l'analisi in-place, i carichi di lavoro ai, ML e DL utilizzando i dati NFS esistenti e StorageGRID per ai, ML e DL e le analisi dei dati moderne quando è richiesto lo storage a oggetti.</block>
  <block id="675ed5324aa6eda280e015498c583161" category="inline-image-macro">Soluzioni NetApp consigliate per Spark.</block>
  <block id="d3deaa8bf3eb6619cb86d00d661a22e9" category="paragraph"><block ref="d3deaa8bf3eb6619cb86d00d661a22e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa7b20f32446fa30f765cd0b1ca93739" category="paragraph">Un data Lake è un repository di storage per set di dati di grandi dimensioni in formato nativo che può essere utilizzato per attività di analisi, ai, ML e DL. Abbiamo creato un repository di data Lake per le soluzioni e-Series, AFF/FAS e StorageGRID SG6060 Spark. Il sistema e-Series fornisce l'accesso HDFS al cluster Hadoop Spark, mentre i dati di produzione esistenti sono accessibili attraverso il protocollo di accesso diretto NFS al cluster Hadoop. Per i set di dati che risiedono nello storage a oggetti, NetApp StorageGRID offre accesso sicuro S3 e S3a.</block>
  <block id="22ad538f7c0e01603f9410a9bdc10d04" category="inline-link-macro">Segue: Riepilogo dei casi di utilizzo.</block>
  <block id="5de3601bc15319fca36066c272d6321d" category="paragraph"><block ref="5de3601bc15319fca36066c272d6321d" category="inline-link-macro-rx"></block></block>
  <block id="6e74710636e2da95cda4899adcdf891e" category="summary">I dati sono disponibili in NFS e accessibili da S3 da AWS SageMaker.</block>
  <block id="8394db253ec71ed9d59b9429983b8eb4" category="doc">Dualità dei dati per data scientist e altre applicazioni</block>
  <block id="352ca87bc1d3676d3b2548644189d052" category="paragraph"><block ref="352ca87bc1d3676d3b2548644189d052" category="inline-link-macro-rx"></block></block>
  <block id="f4900d1d4a0a26325c4c9514e57c2c75" category="paragraph">I notebook NetApp BlueXP, NetApp Cloud Volumes ONTAP e AWS SageMaker sono necessari per il caso di utilizzo della doppia funzionalità dei dati.</block>
  <block id="6e6b6052efed2574e2dc05cbdc5d66d5" category="paragraph">La seguente tabella elenca i componenti software necessari per implementare il caso d'utilizzo.</block>
  <block id="9b9477e579c3b44dd623d5a6e1ea8d78" category="cell">BlueXP</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="cell">NetApp Cloud Volumes ONTAP</block>
  <block id="dda9f6d67571441afa5cfb6b54b70873" category="cell">Notebook AWS SageMaker</block>
  <block id="5ac7b083aa99c6ec0d7a272c37dc611d" category="section-title">Procedure di implementazione</block>
  <block id="cc5f7f3bee6dcb16913051d6fc267977" category="paragraph">L'implementazione della soluzione per la dualità dei dati comporta le seguenti attività:</block>
  <block id="6bb1f60bf0d00924a1bba54557e1feae" category="list-text">Connettore BlueXP</block>
  <block id="cf25fa6cf104cc1a67119acb6d4d364d" category="list-text">Dati per l'apprendimento automatico</block>
  <block id="5a1439989b12745b5a4ed4b944539247" category="list-text">AWS SageMaker</block>
  <block id="59b20c2117a395af59d54a6533498e99" category="list-text">Apprendimento automatico validato dai notebook Jupyter</block>
  <block id="46e0bb4f28dbf5013a68a8a69a3cf9f5" category="section-title">Connettore BlueXP</block>
  <block id="de3e31c5aaf9bdeca7bc072f649ddc2e" category="paragraph">In questa convalida, abbiamo utilizzato AWS. È applicabile anche a Azure e Google Cloud. Per creare un connettore BlueXP in AWS, attenersi alla seguente procedura:</block>
  <block id="4d7b48a5181bdd203b2ff52910c67d94" category="list-text">Abbiamo utilizzato le credenziali basate sull'abbonamento mcarl-marketplace in BlueXP.</block>
  <block id="c0caffb5ab49caead75d39f6416ba841" category="list-text">Scegli la regione adatta al tuo ambiente (ad esempio, US-East-1 [N. Virginia]), quindi selezionare il metodo di autenticazione (ad esempio, assumere le chiavi role o AWS). In questa convalida, utilizziamo le chiavi AWS.</block>
  <block id="86b72593a2ce2f4e46e7669ced916111" category="list-text">Fornire il nome del connettore e creare un ruolo.</block>
  <block id="71ffd00d3592df40d0db94a71ceab12d" category="list-text">Fornire i dettagli di rete, ad esempio VPC, subnet o coppia di chiavi, a seconda che sia necessario un IP pubblico o meno.</block>
  <block id="b5b37cef840fa0a17af0ef55c09a0e1f" category="list-text">Fornire i dettagli per il gruppo di protezione, ad esempio l'accesso HTTP, HTTPS o SSH dal tipo di origine, ad esempio le informazioni su Anywhere e sull'intervallo IP.</block>
  <block id="45b20434e20aeebd5991cd84f2cf11c9" category="list-text">Esaminare e creare BlueXP Connector.</block>
  <block id="92043f8a1dc0b0180854c25bcf5ff79d" category="list-text">Verificare che lo stato dell'istanza di BlueXP EC2 sia in esecuzione nella console AWS e controllare l'indirizzo IP dalla scheda *Networking*.</block>
  <block id="7044ee6a43ee2152ca6d008fcb8228c3" category="list-text">Accedere all'interfaccia utente del connettore dal portale BlueXP oppure utilizzare l'indirizzo IP per l'accesso dal browser.</block>
  <block id="064d933c0c02c4fe7ef1a07ad3a537d7" category="paragraph">Per creare un'istanza di Cloud Volumes ONTAP in BlueXP, attenersi alla seguente procedura:</block>
  <block id="da6e487de6af8700c3cf58ffb20a876c" category="list-text">Creare un nuovo ambiente di lavoro, selezionare il provider cloud e selezionare il tipo di istanza di Cloud Volumes ONTAP (ad esempio CVO singolo, ha o Amazon FSxN per ONTAP).</block>
  <block id="dcb89e397dde3dedb1a32224f0c15b78" category="list-text">Fornire dettagli come il nome e le credenziali del cluster Cloud Volumes ONTAP. In questa convalida, abbiamo creato un'istanza di Cloud Volumes ONTAP chiamata<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block>.</block>
  <block id="9cf479af21359b2928a1b672d60577f2" category="list-text">Selezionare i servizi necessari per Cloud Volumes ONTAP. In questa convalida, abbiamo scelto di eseguire solo il monitoraggio, quindi abbiamo disattivato *Data Sense &amp; Compliance* e *Backup to Cloud Services*.</block>
  <block id="cb95ef3838d59d553c71f50b1cadee27" category="list-text">Nella sezione *Location &amp; Connectivity*, selezionare la regione AWS, VPC, subnet, gruppo di sicurezza, metodo di autenticazione SSH, e una password o una coppia di chiavi.</block>
  <block id="fdd5d37c21ee01084537317345b3d78b" category="list-text">Scegliere il metodo di ricarica. Per questa convalida abbiamo utilizzato *Professional*.</block>
  <block id="00efec60d606ea6ad0bafe93bc77df92" category="list-text">È possibile scegliere un pacchetto preconfigurato, ad esempio *POC e piccoli carichi di lavoro*, *carichi di lavoro di produzione di dati applicativi e database*, *DR conveniente* o *carichi di lavoro di produzione dalle performance più elevate*. In questa convalida, scegliamo *POC e workload di piccole dimensioni*.</block>
  <block id="f22934293c2f2a761ea26fa4ae1828e1" category="list-text">Creare un volume con una dimensione specifica, protocolli consentiti e opzioni di esportazione. In questa convalida, abbiamo creato un volume chiamato<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block>.</block>
  <block id="f2706214c4a60177d14fb8495cbc6924" category="list-text">Scegliere un tipo di disco del profilo e una policy di tiering. In questa convalida, abbiamo disattivato *efficienza dello storage* e *SSD General- purpose – Dynamic Performance*.</block>
  <block id="40d3f73a73f67ce67b286aef7a5d3ecb" category="list-text">Infine, esaminare e creare l'istanza di Cloud Volumes ONTAP. Quindi attendere 15-20 minuti affinché BlueXP crei l'ambiente di lavoro Cloud Volumes ONTAP.</block>
  <block id="a8b538b74c3f662c2248af9c6d4742db" category="list-text">Configurare i seguenti parametri per attivare il protocollo di dualità. Il protocollo di dualità (NFS/S3) è supportato da ONTAP 9. 12.1 e versioni successive.</block>
  <block id="15b53c14b58ee146309847451d1eb90a" category="list-text">In questa convalida, abbiamo creato una SVM chiamata<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block> e volume<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block>.</block>
  <block id="3514969b2381af83551c246e34b74403" category="list-text">Verificare che SVM disponga del supporto del protocollo per NFS e S3. In caso contrario, modificare la SVM per supportarla.</block>
  <block id="e41c06ffff0f8c9cadbc7f8bb37f8ae5" category="list-text">Creare e installare un certificato CA, se necessario.</block>
  <block id="0395f8062a8a7f4af05113bae8133737" category="list-text">Creare una policy sui dati del servizio.</block>
  <block id="6e16e110899749a795fe713253d850e7" category="list-text">Controllare i dettagli dell'aggregato.</block>
  <block id="5d3f8e127103f0d5cf3de305db892b4d" category="list-text">Creare un utente e un gruppo.</block>
  <block id="efa22127bde2d3ab2e4f5b9a42d14814" category="list-text">Creare un bucket sul volume NFS.</block>
  <block id="c3fd6f44bf88d3f0eae4742edb58eafc" category="paragraph">Per creare un notebook AWS da AWS SageMaker, attenersi alla seguente procedura:</block>
  <block id="31378aab1ee6190e0b7fe33c501a5625" category="list-text">Assicurarsi che l'utente che sta creando un'istanza di notebook disponga di un criterio IAM AmazonSageMakerFullAccess o faccia parte di un gruppo esistente che dispone dei diritti AmazonSageMakerFullAccess. In questa convalida, l'utente fa parte di un gruppo esistente.</block>
  <block id="13c1455885d16af64f1bb96c4e48680a" category="list-text">Fornire le seguenti informazioni:</block>
  <block id="bb8101aed18120fa18dedaa994ffeea0" category="list-text">Nome dell'istanza del notebook.</block>
  <block id="6239d232142a089e53e7a13fa721237a" category="list-text">Tipo di istanza.</block>
  <block id="37056dac7373f7e1b74382036d25b69e" category="list-text">Identificatore della piattaforma.</block>
  <block id="38e2059c32c628cf89e90a6844a93800" category="list-text">Selezionare il ruolo IAM che dispone dei diritti AmazonSageMakerFullAccess.</block>
  <block id="55d7da5ede713135b1c2ebd7a615c3b4" category="list-text">Root access (accesso root): Abilitare.</block>
  <block id="8f0e92e4434abc32ff62a914ae9f2ba6" category="list-text">Encryption key (chiave di crittografia) - selezionare NO customed Encryption (</block>
  <block id="8b77028d248afd826900d895636b4e98" category="list-text">Mantenere le restanti opzioni predefinite.</block>
  <block id="78456ee20793f732edfa9105bbb4e490" category="list-text">In questa convalida, i dettagli dell'istanza di SageMaker sono i seguenti:</block>
  <block id="e90e797343ea3f751b0c32e808edaff8" category="inline-image-macro">Schermata che illustra il passaggio.</block>
  <block id="07d5be91bebaccd4767fcceff99f3dde" category="paragraph"><block ref="07d5be91bebaccd4767fcceff99f3dde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69e41ee119a70fc66edf204cbcf365b1" category="paragraph"><block ref="69e41ee119a70fc66edf204cbcf365b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4789a9ab6472480889e111503d068623" category="list-text">Avviare il notebook AWS.</block>
  <block id="faf1aea43a6d3bd1af488b8baa828561" category="paragraph"><block ref="faf1aea43a6d3bd1af488b8baa828561" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbfbebd805ee7945ad38bc26f8fa9f1b" category="list-text">Aprire il laboratorio Jupyter.</block>
  <block id="bcca330921c0ce477877bc982c12a6fb" category="paragraph"><block ref="bcca330921c0ce477877bc982c12a6fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab3269ab0de58f5611205f6ace06f3af" category="list-text">Accedere al terminale e montare il volume Cloud Volumes ONTAP.</block>
  <block id="cc0649b0871fde24c4a46e09186a36e0" category="list-text">Controllare il bucket creato sul volume Cloud Volumes ONTAP utilizzando i comandi CLI AWS.</block>
  <block id="4f31ff9815d3a8a959e7c557213068d6" category="paragraph">In questa convalida, abbiamo utilizzato un set di dati di dbpedia, un'iniziativa della community basata su crowd, per estrarre contenuti strutturati dalle informazioni create in vari progetti Wikimedia.</block>
  <block id="06d6ccf33b49ed20a34cdc26b6820253" category="list-text">Scaricare i dati dalla posizione di dbpedia GitHub ed estrarli. Utilizzare lo stesso terminale utilizzato nella sezione precedente.</block>
  <block id="7f50b7f719282741fdf7ce5b8ca1f3dd" category="list-text">Copiare i dati nella posizione Cloud Volumes ONTAP e controllarli dal bucket S3 utilizzando l'interfaccia CLI AWS.</block>
  <block id="0ecfbac978ab3f5979ec31eb5574d93e" category="list-text">Eseguire la convalida di base per assicurarsi che la funzionalità di lettura/scrittura funzioni sul bucket S3.</block>
  <block id="877169a066e14f0512d5f119945ef14d" category="section-title">Convalida l'apprendimento automatico dai notebook Jupyter</block>
  <block id="6f73420916237ed836932ccf967d82ba" category="paragraph">La seguente convalida fornisce i modelli di creazione, formazione e implementazione dell'apprendimento automatico attraverso la classificazione del testo utilizzando l'esempio di SageMaker BlazingText riportato di seguito:</block>
  <block id="3cf03767e04159d1ec88e7fb0827b487" category="list-text">Installare i pacchetti boto3 e SageMaker.</block>
  <block id="b1282d58a4dcde0a2015d98ad33afd4c" category="paragraph">Uscita:</block>
  <block id="39017441ac701ebaef8de7116e7f71a0" category="list-text">Nella fase successiva, i dati <block ref="0a726fdd06082d233cd4eade40f12612" prefix="(" category="inline-code"></block>) viene scaricato dal bucket s3<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block> A un'istanza Jupyter notebook utilizzata nell'apprendimento automatico.</block>
  <block id="a270350e3527fea9a36815fa5fe04ba0" category="list-text">Il codice seguente crea il mapping tra gli indici interi e le etichette delle classi utilizzate per recuperare il nome effettivo della classe durante l'inferenza.</block>
  <block id="d17fa3d0aed3f8aaa5e78b447054126d" category="paragraph">L'output elenca i file e le cartelle in<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block> Bucket utilizzati come dati per la convalida dell'apprendimento automatico AWS SageMaker.</block>
  <block id="0cfbf64679378e3e5367734fd2bd69aa" category="list-text">Avviare la fase di pre-elaborazione dei dati per pre-elaborare i dati di training in un formato di testo tobenizzato, separato dallo spazio, che può essere utilizzato dall'algoritmo BlazingText e dalla libreria nltk per mettere in token le frasi di input dal set di dati dbpedia. Scarica il token nltk e altre librerie. Il<block ref="6d49a792c1080aa5b33d27ec694621b6" prefix=" " category="inline-code"></block> Applicato a ogni istanza di dati in parallelo utilizza il modulo multiprocessing Python.</block>
  <block id="d68566815a7248bae03e105c2db8853a" category="list-text">Caricare il set di dati formattato e formativo in S3 in modo che possa essere utilizzato da SageMaker per eseguire i lavori di training. Quindi caricare due file nel bucket e nella posizione del prefisso utilizzando l'SDK Python.</block>
  <block id="bc41af112e1f02120a4a6e16f34767ef" category="list-text">Impostare una posizione di output su S3 in cui viene caricato l'artefatto del modello in modo che gli artefatti possano essere l'output del lavoro di training dell'algoritmo. Creare un<block ref="6e3281884db83f9ee468a6e798b6bdfb" prefix=" " category="inline-code"></block> oggetto per avviare il lavoro di training.</block>
  <block id="41215e143c2b3810b37c4e4f47819077" category="list-text">Definire il SageMaker<block ref="a0b1f5f7b93af313b6e2452f52c8f3f6" prefix=" " category="inline-code"></block> Con configurazioni delle risorse e hyperparameters per formare la classificazione del testo nel dataset dbpedia utilizzando la modalità supervisionata su un'istanza c4.4xlarge.</block>
  <block id="6c773c4d6e4a7dda7e00352894786bdb" category="list-text">Preparare un handshake tra i canali dati e l'algoritmo. A tale scopo, creare<block ref="0e021845d2c0e4ad94a91ce444c13681" prefix=" " category="inline-code"></block> oggetti dei canali dati e conservarli in un dizionario che l'algoritmo deve utilizzare.</block>
  <block id="3b29bef19a742b8ab66cddf620871d31" category="list-text">Al termine del lavoro, viene visualizzato il messaggio lavoro completato. Il modello addestrato si trova nel bucket S3 configurato come<block ref="212ad7a4c11069727ffd02f333d7d8b1" prefix=" " category="inline-code"></block> nello stimatore.</block>
  <block id="6cb5683d87e53b375bd915572f960759" category="list-text">Una volta completato il training, implementa il modello addestrato come endpoint in hosting in tempo reale Amazon SageMaker per fare previsioni.</block>
  <block id="4254a612097ca58653de7c0c39da8df2" category="list-text">Per impostazione predefinita, il modello restituisce una previsione con la maggiore probabilità. Per recuperare la parte superiore<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block> previsioni, set<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block> nel file di configurazione.</block>
  <block id="67be4f1bb90039baec0d8f73ff82a47e" category="list-text">Eliminare l'endpoint prima di chiudere il notebook.</block>
  <block id="891844576f11e816faf55d68309946b4" category="paragraph"><block ref="891844576f11e816faf55d68309946b4" category="inline-link-macro-rx"></block></block>
  <block id="5273463fa2459ed38da1af200de6f150" category="summary">Questa pagina descrive le performance di Splunk SmartStore su un controller NetApp StorageGRID. Splunk SmartStore sposta i dati warm nello storage remoto, che è lo storage a oggetti StorageGRID nella convalida delle performance.</block>
  <block id="b646ed758d0eaa12ba9fab12788f9ad4" category="doc">Performance di SmartStore a sito singolo</block>
  <block id="47251bcda6f5d3ff81fc5968fa702aad" category="inline-link-macro">Precedente: Architettura Splunk.</block>
  <block id="10da3263ceac590ab423073945a99eac" category="paragraph"><block ref="10da3263ceac590ab423073945a99eac" category="inline-link-macro-rx"></block></block>
  <block id="b72db8dc34d5e01f398d66c9de42c11f" category="paragraph">Questa sezione descrive le performance di Splunk SmartStore su un controller NetApp StorageGRID. Splunk SmartStore sposta i dati warm nello storage remoto, che in questo caso è lo storage a oggetti StorageGRID nella convalida delle performance.</block>
  <block id="1d01dcffdd1257afb01e4194d766d2f9" category="paragraph"><block ref="1d01dcffdd1257afb01e4194d766d2f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32b74ac1eb4eb0530a3f976e96e3120d" category="paragraph">Abbiamo utilizzato EF600 per lo storage hot/cache e StorageGRID 6060 per lo storage remoto. Per la convalida delle performance abbiamo utilizzato la seguente architettura. Abbiamo utilizzato due teste di ricerca, quattro forwarder pesanti per inoltrare i dati agli indicizzatori, sette generatori di eventi Splunk (Eventgens) per generare i dati in tempo reale e 18 indicizzatori per memorizzare i dati.</block>
  <block id="a2fd19ff7e04cf04d5d99320b979cd00" category="paragraph"><block ref="a2fd19ff7e04cf04d5d99320b979cd00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45940e86de61b51821b0ec7959b3d551" category="paragraph">Questa tabella elenca l'hardware utilizzato per la convalida delle performance di SmartStorage.</block>
  <block id="5e536c35aec296fa99efa02703d1eb07" category="cell">Componente Splunk</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">Attività</block>
  <block id="95dd022b7af0f9fcfb9ed21236830169" category="cell">Core</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">SISTEMA OPERATIVO</block>
  <block id="2fda610cb12c654fe037d4130498d5ae" category="cell">Forwarder pesante</block>
  <block id="66d25b75f626d8f6c535a4b4d25c9906" category="cell">Responsabile dell'acquisizione dei dati e dell'inoltro dei dati agli indicizzatori</block>
  <block id="6d53d218eec402993fef5394aef9acdf" category="cell">16 core</block>
  <block id="f4e3903ba78addf6fadac4a2d7285203" category="cell">32 GB DI RAM</block>
  <block id="d3dd61dd737f0e824caf9d717bc1a59d" category="cell">SLITTA 15 SP2</block>
  <block id="84f200201a8fe699d8d701c940bade8e" category="cell">Indicizzatore</block>
  <block id="aa7f73db0dcc93a83403f1afb650efdd" category="cell">Gestisce i dati dell'utente</block>
  <block id="6f4922f45568161a8cdf4ad2299f6d23" category="cell">18</block>
  <block id="c91b59f2eae5ebf309d600609f87a36f" category="cell">Testa di ricerca</block>
  <block id="21dd53b3176e5a03137d603514a60ece" category="cell">Il front-end dell'utente cerca i dati negli indicizzatori</block>
  <block id="f8b32f50f478eb80dca360b13aa78e92" category="cell">Search head deployer</block>
  <block id="e14f0b3b9201c717d9cae1db6969fb64" category="cell">Gestisce gli aggiornamenti per i cluster di teste di ricerca</block>
  <block id="a6230a0628a31d41191b4ef7800745ed" category="cell">Master del cluster</block>
  <block id="0ac993c5a472613a0cd368ccfefd6009" category="cell">Gestisce l'installazione e gli indicizzatori di Splunk</block>
  <block id="a91966f90c29f7d9420d2fd902f4aac2" category="cell">Console di monitoraggio e master di licenza</block>
  <block id="0cb149f6f77c10496cf7645357f9fd17" category="cell">Esegue il monitoraggio centralizzato dell'intera implementazione di Splunk e gestisce le licenze di Splunk</block>
  <block id="c247e74124395bc7279d790ac384786e" category="section-title">Convalida delle performance dello store remoto SmartStore</block>
  <block id="30cf0ca744869370aafb6cfecdd7b4c6" category="paragraph">In questa convalida delle performance, abbiamo configurato la cache SmartStore nello storage locale su tutti gli indicizzatori per 10 giorni di dati. Abbiamo abilitato<block ref="6255199182bd8af7ba33e8a06e144dc4" prefix=" " category="inline-code"></block> (750 MB di dimensione del bucket) in Splunk Cluster Manager e le modifiche sono state inviate a tutti gli indicizzatori. Per misurare le performance di caricamento, abbiamo acquisito 10 TB al giorno per 10 giorni e abbiamo eseguito il rollover di tutti i bucket hot per riscaldarsi contemporaneamente e abbiamo catturato il throughput di picco e medio per istanza e per l'intera implementazione dalla dashboard di SmartStore Monitoring Console.</block>
  <block id="4fc95542b54fee8da424a2e0ab281aeb" category="paragraph">Questa immagine mostra i dati acquisiti in un giorno.</block>
  <block id="c1b0c9568cd6b9bf236fb9566021d8a4" category="paragraph"><block ref="c1b0c9568cd6b9bf236fb9566021d8a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b72140907b2e824ba4a35a2f01bac4e6" category="paragraph">Abbiamo eseguito il seguente comando dal cluster master (il nome dell'indice è<block ref="b6f5a7e4d9c3de59289306e2636a7438" prefix=" " category="inline-code"></block>). Quindi, abbiamo acquisito il throughput di caricamento medio e massimo per istanza e per l'intera implementazione attraverso le dashboard della console di monitoraggio SmartStore.</block>
  <block id="94a0389fcc3ce42eea7a3f351f5d39b5" category="admonition">Il master del cluster dispone di un'autenticazione senza password per tutti gli indicizzatori (rtp-idx0001…rtp-idx0018).</block>
  <block id="d27688c7ebc58e3f620120997e317180" category="paragraph">Per misurare le performance di download, abbiamo sfrattato tutti i dati dalla cache eseguendo due volte la CLI di evict utilizzando il seguente comando.</block>
  <block id="4faf8abcf7e17175784cdc9d58df1608" category="admonition">Abbiamo eseguito il seguente comando dal cluster master ed eseguito la ricerca dall'area di ricerca oltre 10 giorni di dati dall'archivio remoto da StorageGRID. Abbiamo quindi catturato il throughput di upload medio e massimo per istanza e per l'intera implementazione attraverso le dashboard della console di monitoraggio SmartStore.</block>
  <block id="995931f06acb79ea5ac83df17d692a1d" category="paragraph">Le configurazioni dell'indicizzatore sono state inviate dal cluster master SmartStore. Il cluster master aveva la seguente configurazione per l'indicizzatore.</block>
  <block id="514109dd07ed0bb93081e9e36291b879" category="paragraph">Abbiamo eseguito la seguente query di ricerca sull'head di ricerca per raccogliere la matrice delle performance.</block>
  <block id="39b8fe84a2982bcbeb6d733343e0678d" category="paragraph"><block ref="39b8fe84a2982bcbeb6d733343e0678d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67e03c2395d7a876b5160fefc76f9bb9" category="paragraph">Abbiamo raccolto le informazioni sulle performance dal cluster master. Le performance massime sono state di 61,34 Gbps.</block>
  <block id="0feb590fe449a8a847517a38f1e0415f" category="paragraph"><block ref="0feb590fe449a8a847517a38f1e0415f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2850e7edd48f5666ab4f82242ddb37d2" category="paragraph">Le performance medie sono state di circa 29 Gbps.</block>
  <block id="2a1437158884c9696a6d4cac546972b1" category="paragraph"><block ref="2a1437158884c9696a6d4cac546972b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283456e93c96a11ef44a18693dd6c886" category="section-title">Performance StorageGRID</block>
  <block id="f5451e9a153b2f625ec0bc944af01be5" category="inline-link">Eventgen</block>
  <block id="764a1901ab00adf1e8e26712bf39c23a" category="paragraph">Le performance di SmartStore si basano sulla ricerca di schemi e stringhe specifici da grandi quantità di dati. In questa convalida, gli eventi vengono generati utilizzando<block ref="6cec2d19baf7e588a52847e567dab457" category="inline-link-rx"></block> Su un indice Splunk specifico (eventgen-test) attraverso l'head di ricerca e la richiesta va a StorageGRID per la maggior parte delle query. L'immagine seguente mostra i riscontri e le mancate risposte dei dati della query. I dati di accesso provengono dal disco locale e i dati di mancato accesso provengono dal controller StorageGRID.</block>
  <block id="3b8a6855a0eb4beaf2c787f34a2428d7" category="admonition">Il colore verde mostra i dati dei riscontri e il colore arancione mostra i dati dei mancati riscontri.</block>
  <block id="0bf13ffd9c4e3655384eea9760fdd547" category="paragraph"><block ref="0bf13ffd9c4e3655384eea9760fdd547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6fa8244cc2900d6f36b3144c7e748ac" category="paragraph">Quando la query viene eseguita per la ricerca su StorageGRID, il tempo per la velocità di recupero S3 da StorageGRID viene mostrato nell'immagine seguente.</block>
  <block id="5e789be14498e5bac09395d944ced093" category="paragraph"><block ref="5e789be14498e5bac09395d944ced093" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e3fd399eb98a5a8fae1dc144ff614f3" category="section-title">Utilizzo dell'hardware StorageGRID</block>
  <block id="8e8a6c088425467c00be94a9d15d015b" category="paragraph">L'istanza di StorageGRID ha un bilanciamento del carico e tre controller StorageGRID. L'utilizzo della CPU per tutti e tre i controller va dal 75% al 100%.</block>
  <block id="5c78f5ad926b76e88a749362fb6e3412" category="paragraph"><block ref="5c78f5ad926b76e88a749362fb6e3412" category="inline-image-macro-rx" type="image"></block></block>
  <block id="140097f96ea2b213b6f37f9d71009a5e" category="section-title">SmartStore con controller di storage NetApp: Vantaggi per il cliente</block>
  <block id="7f18772207b4ab40d0e7574fc68b95b6" category="list-text">*Disaccoppiamento di calcolo e storage.* Splunk SmartStore separa calcolo e storage, consentendo una scalabilità indipendente.</block>
  <block id="4e1a3208fe0742415bc087d082943293" category="list-text">*Data on-demand.* SmartStore avvicina i dati al calcolo on-demand e offre flessibilità di calcolo e storage ed efficienza dei costi per ottenere una maggiore conservazione dei dati su larga scala.</block>
  <block id="f3295a31a8b7a9b5d76cb1a1e7f67f28" category="list-text">* Conforme alle API AWS S3.* SmartStore utilizza l'API AWS S3 per comunicare con lo storage di ripristino, che è un archivio di oggetti conforme alle API AWS S3 e S3 come StorageGRID.</block>
  <block id="4fda7aba03882818928ff7bc3a03f0e5" category="list-text">* Riduce i requisiti e i costi di storage.* SmartStore riduce i requisiti di storage per i dati vecchi (caldo/freddo). L'IT ha bisogno di una sola copia dei dati perché lo storage NetApp offre protezione dei dati e si occupa di guasti e alta disponibilità.</block>
  <block id="c27703d92f7f2316dfa63670f02dd6b6" category="list-text">*Guasto hardware.* il guasto del nodo in un'implementazione SmartStore non rende i dati inaccessibili e offre un ripristino dell'indicizzatore molto più rapido in caso di guasto hardware o squilibrio dei dati.</block>
  <block id="ed20f2e9df3c744293f044d87722ce0f" category="list-text">Cache applicativa e data-aware.</block>
  <block id="f57d44dedead861d1eef7e912b9cbd86" category="list-text">Aggiunta di indicizzatori di rimozione e installazione del cluster on-demand.</block>
  <block id="98613866f09e0e2416018bef4be916d3" category="list-text">Il Tier di storage non è più legato all'hardware.</block>
  <block id="a2a5916477583887c69c752ae6366750" category="paragraph"><block ref="a2a5916477583887c69c752ae6366750" category="inline-link-macro-rx"></block></block>
  <block id="2ea9ecb649c5974bc03036a15d95f5bf" category="summary">La soluzione data mover per l'ai si basa sulle esigenze dei clienti di elaborare i dati Hadoop dalle operazioni ai. NetApp trasferisce i dati da HDFS a NFS utilizzando NIPAM. In un caso di utilizzo, il cliente doveva spostare i dati su NFS on-premise e un altro cliente doveva spostare i dati da Windows Azure Storage Blob a Cloud Volumes Service per elaborare i dati dalle istanze cloud della GPU nel cloud.</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">Soluzione di data mover per l'ai</block>
  <block id="2337521acd1f46c410245430b841caa8" category="inline-link-macro">Precedente: Soluzione di data mover.</block>
  <block id="ee202fa3d5706f12ab6d57e9cb4b4cba" category="paragraph"><block ref="ee202fa3d5706f12ab6d57e9cb4b4cba" category="inline-link-macro-rx"></block></block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">Il seguente diagramma illustra i dettagli della soluzione data mover.</block>
  <block id="27f83ed51cc554467134084d77b0e050" category="paragraph"><block ref="27f83ed51cc554467134084d77b0e050" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">Per creare la soluzione di data mover sono necessari i seguenti passaggi:</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">LA SAN ONTAP fornisce HDFS e il NAS fornisce il volume NFS tramite NIPAM al cluster di data Lake di produzione.</block>
  <block id="0fad6dd0225bf5a5e9c668c30ea5d38a" category="list-text">I dati del cliente sono in HDFS e NFS. I dati NFS possono essere dati di produzione di altre applicazioni utilizzate per l'analisi dei big data e le operazioni ai.</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">La tecnologia NetApp FlexClone crea un clone del volume NFS di produzione e lo fornisce al cluster ai on-premise.</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">I dati di un LUN SAN HDFS vengono copiati in un volume NFS con NIPAM e il<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> comando. NIPAM utilizza la larghezza di banda di più interfacce di rete per trasferire i dati. Questo processo riduce i tempi di copia dei dati in modo che sia possibile trasferire più dati.</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">Entrambi i volumi NFS vengono forniti al cluster ai per le operazioni ai.</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">Per elaborare i dati NFS on-the-premise con GPU nel cloud, i volumi NFS vengono mirrorati su NetApp Private Storage (NPS) con la tecnologia NetApp SnapMirror e montati sui cloud service provider per GPU.</block>
  <block id="c590e653cde69438d43731b18edd533c" category="list-text">Il cliente desidera elaborare i dati nei servizi EC2/EMR, HDInsight o DataProc nelle GPU dei provider di servizi cloud. Il data mover di Hadoop sposta i dati dai servizi Hadoop ai Cloud Volumes Services con NIPAM e a.<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> comando.</block>
  <block id="8cae7d7989a25f83bf9df9952b16ed2b" category="list-text">I dati Cloud Volumes Service vengono forniti all'ai tramite il protocollo NFS.i dati elaborati tramite l'ai possono essere inviati in una posizione on-premise per l'analisi dei big data oltre al cluster NVIDIA tramite NIPAM, SnapMirror e NPS.</block>
  <block id="980894bd0921c687decdf218e89107e2" category="paragraph">In questo scenario, il cliente dispone di dati con un elevato numero di file nel sistema NAS in una posizione remota richiesta per l'elaborazione dell'ai sul controller di storage NetApp on-premise. In questo scenario, è meglio utilizzare XCP Migration Tool per migrare i dati a una velocità superiore.</block>
  <block id="002cfe6c68deff9c2fcb4fbb3820a5ff" category="paragraph">Il cliente del caso di utilizzo ibrido può utilizzare Cloud Sync per migrare i dati on-premise dai dati NFS, CIFS e S3 al cloud e viceversa per l'elaborazione ai utilizzando GPU come quelle di un cluster NVIDIA. Sia Cloud Sync che lo strumento di migrazione XCP vengono utilizzati per la migrazione dei dati NFS su NetApp ONTAP NFS.</block>
  <block id="22033f5439b399254e73f6f3588b9b9e" category="inline-link-macro">Pagina successiva: GPF per NetApp ONTAP NFS.</block>
  <block id="f56cb05715de107bd001dd11a41b0cf6" category="paragraph"><block ref="f56cb05715de107bd001dd11a41b0cf6" category="inline-link-macro-rx"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">Questo caso di utilizzo è importante per un partner di servizi cloud che ha il compito di fornire connettività multi-cloud per i dati di analisi dei big data dei clienti.</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="doc">Caso d'utilizzo 4: Protezione dei dati e connettività multicloud</block>
  <block id="2c8eccdfa6390b1d09b2527f7d7d2cc5" category="inline-link-macro">Precedente: Caso d'utilizzo 3 - abilitazione di DevTest sui dati Hadoop esistenti.</block>
  <block id="fda5cc5b496f5f7aa6de18740227bc15" category="paragraph"><block ref="fda5cc5b496f5f7aa6de18740227bc15" category="inline-link-macro-rx"></block></block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">In questo scenario, i dati IoT ricevuti in AWS da diverse origini vengono memorizzati in una posizione centrale in NPS. Lo storage NPS è connesso ai cluster Spark/Hadoop situati in AWS e Azure, consentendo l'esecuzione di applicazioni di analisi dei big data in più cloud che accedono agli stessi dati.</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">I dati devono essere ricevuti da fonti diverse, ad esempio on-premise e cloud, attraverso diversi sensori e hub.</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">La soluzione deve essere efficiente e conveniente.</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">La sfida principale è quella di creare una soluzione conveniente ed efficiente in grado di offrire servizi di analisi ibridi tra cloud diversi e on-premise.</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">Questa immagine illustra la soluzione per la protezione dei dati e la connettività multicloud.</block>
  <block id="faaf8e6278dc7a68fd1dd98dfe7f525a" category="paragraph"><block ref="faaf8e6278dc7a68fd1dd98dfe7f525a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14c23633f1ab374f4c801386847ba2f8" category="paragraph">Come mostrato nella figura precedente, i dati provenienti dai sensori vengono trasmessi e acquisiti nel cluster AWS Spark tramite Kafka. I dati vengono memorizzati in una condivisione NFS residente in NPS, che si trova all'esterno del cloud provider all'interno di un data center Equinix. Poiché NetApp NPS è connesso ad Amazon AWS e Microsoft Azure rispettivamente tramite Direct Connect e Express Route Connections, i clienti possono sfruttare l'Analytics Module in-place per accedere ai dati da entrambi i cluster di analisi Amazon e AWS. Questo approccio risolve l'utilizzo di analytics nel cloud in più hyperscaler.</block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">Di conseguenza, poiché sia lo storage on-premise che NPS esegue il software ONTAP, SnapMirror può eseguire il mirroring dei dati NPS nel cluster on-premise, fornendo analisi del cloud ibrido tra cloud on-premise e multipli.</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">Per ottenere le migliori performance, NetApp consiglia di utilizzare interfacce di rete multiple e percorsi di connessione diretta/express per accedere ai dati dalle istanze cloud.</block>
  <block id="1ef541fe0fa79d247c0f1751629bb504" category="inline-link-macro">Successivo: Caso d'utilizzo 5 - accelerare i carichi di lavoro di analisi.</block>
  <block id="7dfabd0b120fe0403ff107668db4094a" category="paragraph"><block ref="7dfabd0b120fe0403ff107668db4094a" category="inline-link-macro-rx"></block></block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">Questo documento descrive le linee guida sulle Best practice per l'utilizzo di Kafka su un controller di storage NetApp.</block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthikeyan Nagalingam, Joseph Kandatilparambil, NetApp Rankesh Kumar, Confluent</block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">Apache Kafka è una piattaforma per lo streaming di eventi distribuita dalla community in grado di gestire migliaia di miliardi di eventi al giorno. Inizialmente concepito come coda di messaggistica, Kafka si basa su un'astrazione di un log di commit distribuito. Da quando è stata creata e open-source da LinkedIn nel 2011, Kafka si è evoluta da una coda di messaggi a una piattaforma completa per lo streaming di eventi. Confluent offre la distribuzione di Apache Kafka con la Confluent Platform. La piattaforma Confluent integra Kafka con funzionalità commerciali e di community aggiuntive progettate per migliorare l'esperienza di streaming di operatori e sviluppatori in produzione su vasta scala.</block>
  <block id="e1c012d650a6912ddb72ab0ee914d169" category="paragraph">Questo documento descrive le linee guida sulle Best practice per l'utilizzo dello storage a livelli confluente su un'offerta di storage a oggetti NetApp, fornendo i seguenti contenuti:</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">Verifica confluente con lo storage a oggetti NetApp: NetApp StorageGRID</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">Tiered storage performance test</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">Linee guida sulle Best practice per Confluent sui sistemi storage NetApp</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">Perché lo storage a livelli confluente?</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">Questo articolo di Confluent</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">Confluent è diventata la piattaforma di streaming real-time predefinita per molte applicazioni, in particolare per i big data, gli analytics e i carichi di lavoro di streaming. Tiered Storage consente agli utenti di separare il calcolo dallo storage nella piattaforma Confluent. L'archiviazione dei dati risulta più conveniente, consente di memorizzare quantità virtualmente infinite di dati e di scalare i carichi di lavoro on-demand in su (o in giù) e semplifica le attività amministrative come il ribilanciamento dei dati e dei tenant. I sistemi storage compatibili con S3 possono sfruttare tutte queste funzionalità per democratizzare i dati con tutti gli eventi in un unico posto, eliminando la necessità di un'ingegneria dei dati complessa. Per ulteriori informazioni sul motivo per cui dovresti utilizzare lo storage a più livelli per Kafka, consulta <block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block>.</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">Perché scegliere NetApp StorageGRID per lo storage su più livelli?</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRID è una piattaforma di storage a oggetti leader del settore di NetApp. StorageGRID è una soluzione di storage a oggetti, software-defined, che supporta API a oggetti standard di settore, inclusa l'API S3 (Simple Storage Service) di Amazon. StorageGRID archivia e gestisce i dati non strutturati su larga scala per fornire uno storage a oggetti sicuro e durevole. I contenuti vengono posizionati nella giusta posizione, al momento giusto e nel giusto Tier di storage, ottimizzando i flussi di lavoro e riducendo i costi per i contenuti multimediali distribuiti a livello globale.</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">Il principale elemento di differenziazione per StorageGRID è il motore di policy per la gestione del ciclo di vita delle informazioni (ILM) che consente la gestione del ciclo di vita dei dati basata su policy. Il motore delle policy può utilizzare i metadati per gestire il modo in cui i dati vengono memorizzati per tutta la vita utile, per ottimizzare inizialmente le performance e ottimizzare automaticamente i costi e la durata con l'invecchiamento dei dati.</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">Abilitare lo storage a livelli confluente</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">L'idea di base dello storage su più livelli è separare le attività dello storage dei dati dall'elaborazione dei dati. Grazie a questa separazione, la scalabilità indipendente del Tier di storage e del Tier di elaborazione dei dati diventa molto più semplice.</block>
  <block id="e963c7bc15c18e21f60a9969d876e3e8" category="paragraph">Una soluzione storage a più livelli per Confluent deve affrontare due fattori. Innanzitutto, deve aggirare o evitare proprietà comuni di coerenza e disponibilità degli archivi di oggetti, come incoerenze nelle operazioni DI ELENCO e occasionali indisponibilità degli oggetti. In secondo luogo, deve gestire correttamente l'interazione tra lo storage su più livelli e il modello di tolleranza agli errori e replica di Kafka, inclusa la possibilità che i leader zombie continuino a tierare gli intervalli di offset. Lo storage a oggetti NetApp offre la disponibilità costante degli oggetti e il modello ha che rendono lo storage stanco disponibile per gli intervalli di offset del Tier. Lo storage a oggetti NetApp offre una disponibilità degli oggetti coerente e un modello ha per rendere lo storage stanco disponibile per gli intervalli di offset del Tier.</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">Con lo storage a più livelli, puoi utilizzare piattaforme dalle performance elevate per letture e scritture a bassa latenza in prossimità della coda dei dati in streaming e puoi anche utilizzare archivi di oggetti scalabili e più economici come NetApp StorageGRID per letture storiche ad alto throughput. Disponiamo anche di una soluzione tecnica per Spark con controller di storage netapp e i dettagli sono qui. La figura seguente mostra come Kafka si inserisce in una pipeline di analytics in tempo reale.</block>
  <block id="c7e421673ed217d2262c482dc24d0995" category="paragraph"><block ref="c7e421673ed217d2262c482dc24d0995" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66b784e6401c98dcf152747d22976bf7" category="paragraph">La figura seguente mostra come NetApp StorageGRID si inserisce nel livello di storage a oggetti di Confluent Kafka.</block>
  <block id="f4e981d58b1468737da82402b3cce7f1" category="paragraph"><block ref="f4e981d58b1468737da82402b3cce7f1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c3dbe3ccb3831e313d1d072656fa861" category="inline-link-macro">Pagina successiva: Dettagli sull'architettura della soluzione.</block>
  <block id="adcb27f49e58936cf868bc3cc2726dd7" category="paragraph"><block ref="adcb27f49e58936cf868bc3cc2726dd7" category="inline-link-macro-rx"></block></block>
  <block id="7caace9abf76a798c629a9134d1bb259" category="summary">Un potenziale caso di utilizzo per l'accesso a due protocolli di NFS e S3 riguarda l'apprendimento automatico e la scienza dei dati. Ad esempio, un team di data scientist potrebbe lavorare a un progetto di machine learning utilizzando AWS SageMaker, che richiede l'accesso ai dati memorizzati nel formato NFS. Tuttavia, potrebbe essere necessario accedere e condividere i dati tramite i bucket S3 per collaborare con altri membri del team o per integrarli con altre applicazioni che utilizzano S3.</block>
  <block id="c065dcd23d9d1ec5adae07e55bed5122" category="paragraph"><block ref="c065dcd23d9d1ec5adae07e55bed5122" category="inline-link-macro-rx"></block></block>
  <block id="ee8cf3bf54dea46135e299d79fa1c179" category="paragraph">Questa soluzione utilizza le seguenti tecnologie:</block>
  <block id="a03ea23912d3b35c875ff398aa4888af" category="list-text">*AWS SageMaker notebook.* offre funzionalità di apprendimento automatico a sviluppatori e data scientist per creare, formare e implementare modelli ML di alta qualità in modo efficiente.</block>
  <block id="bbe2552dc6295d353c02fd85c243f334" category="list-text">*NetApp BlueXP.* consente il rilevamento, l'implementazione e il funzionamento dello storage on-premise, nonché su AWS, Azure e Google Cloud. Offre protezione dei dati contro la perdita di dati, le minacce informatiche e le interruzioni non pianificate e ottimizza lo storage e l'infrastruttura dei dati.</block>
  <block id="aa6fa71ab9848c5875470d36bbc2138a" category="list-text">*NetApp Cloud Volumes ONTAP.* offre volumi di storage di livello Enterprise con protocolli NFS, SMB/CIFS, iSCSI e S3 su AWS, Azure e Google Cloud, offrendo agli utenti una maggiore flessibilità nell'accesso e nella gestione dei dati nel cloud.</block>
  <block id="eea496572a01ca3e5ced1dfe99a5809c" category="paragraph">NetApp Cloud Volumes ONTAP è stato creato da BlueXP per memorizzare i dati ML.</block>
  <block id="923baf107dc23ca10f968a4fdecd4f4f" category="paragraph">La figura seguente mostra i componenti tecnici della soluzione.</block>
  <block id="8afbfe3aeb9c594404d5c244cf8f6024" category="inline-image-macro">Questa figura mostra i componenti tecnici della soluzione.</block>
  <block id="eaf4eb821a18e60305e45cf9cce407dd" category="paragraph"><block ref="eaf4eb821a18e60305e45cf9cce407dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55c5281d80934f950192f768715495f0" category="paragraph">Utilizzando NetApp Cloud Volumes ONTAP, il team può memorizzare i dati in un'unica posizione e renderli accessibili con i protocolli NFS e S3. I data scientist possono accedere ai dati in formato NFS direttamente da AWS SageMaker, mentre altri membri del team o applicazioni possono accedere agli stessi dati tramite i bucket S3.</block>
  <block id="f8ba1b513231e9ca54a5c3b94733c28d" category="paragraph">Questo approccio consente di accedere e condividere i dati in modo semplice ed efficiente senza la necessità di software aggiuntivo o migrazione dei dati tra diverse soluzioni di storage. Inoltre, consente di ottimizzare il workflow e la collaborazione tra i membri del team, consentendo uno sviluppo più rapido ed efficace dei modelli di machine learning.</block>
  <block id="90c0fb73ec9f52bf43a1ec0b34196d95" category="inline-link-macro">Avanti: Dualità dei dati per data scientist e altre applicazioni.</block>
  <block id="b425d409342f0d671a0dd6742f8bf09f" category="paragraph"><block ref="b425d409342f0d671a0dd6742f8bf09f" category="inline-link-macro-rx"></block></block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">Questo documento fornisce linee guida per lo spostamento dei dati di analisi dei big data e dei dati HPC nell'ai utilizzando NetApp XCP e NIPAM. Discutiamo inoltre dei vantaggi per il business derivanti dal passaggio dei dati da big data e HPC all'ai.</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">TR-4732: Dai dati di analisi dei big data all'intelligenza artificiale</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">Questo documento descrive come spostare i dati di analisi dei big data e i dati HPC nell'ai. L'ai elabora i dati NFS attraverso le esportazioni NFS, mentre i clienti spesso dispongono dei propri dati ai in una piattaforma di analisi dei big data, come lo storage HDFS, Blob o S3, oltre a piattaforme HPC come GPFS. Questo documento fornisce linee guida per lo spostamento dei dati di analisi dei big data e dei dati HPC nell'ai utilizzando NetApp XCP e NIPAM. Discutiamo inoltre dei vantaggi per il business derivanti dal passaggio dei dati da big data e HPC all'ai.</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">Concetti e componenti</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">Storage per l'analisi dei big data</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">L'analisi dei big data è il principale provider di storage per HDFS. Un cliente utilizza spesso un file system compatibile con Hadoop (HCFS) come Windows Azure Blob Storage, MapR file System (MapR-FS) e lo storage a oggetti S3.</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">File system parallelo generale</block>
  <block id="432f31a1b9dc5a8ef1f048ea3f4f98c8" category="paragraph">Il GPFS di IBM è un file system aziendale che offre un'alternativa a HDFS. LE GPF offrono alle applicazioni la flessibilità necessaria per decidere le dimensioni dei blocchi e il layout di replica, garantendo buone performance ed efficienza.</block>
  <block id="2aff401779cc49866458a642f15c0181" category="inline-link">TR-4382: Modulo NetApp in-place Analytics.</block>
  <block id="ae1165a7ed0006d2dae65ea849898810" category="paragraph">Il NetApp in-place Analytics Module (NIPAM) funge da driver per i cluster Hadoop per accedere ai dati NFS. Ha quattro componenti: Un pool di connessioni, un NFS InputStream, una cache di handle di file e un NFS OutputStream. Per ulteriori informazioni, vedere<block ref="aedae5b2590b798973be1ab298f44ab7" category="inline-link-rx"></block></block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Copia distribuita Hadoop</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">La copia distribuita di Hadoop (DistCp) è uno strumento di copia distribuita utilizzato per attività di coping tra cluster e intra-cluster di grandi dimensioni. Questo strumento utilizza MapReduce per la distribuzione dei dati, la gestione degli errori e il reporting. Espande l'elenco di file e directory e li inserisce per mappare le attività per copiare i dati dall'elenco di origine. L'immagine seguente mostra l'operazione DistCp in HDFS e non in HDFS.</block>
  <block id="1a76b3e0f1199267d461c961d30d07a5" category="paragraph"><block ref="1a76b3e0f1199267d461c961d30d07a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">Hadoop DistCp sposta i dati tra i due sistemi HDFS senza utilizzare un driver aggiuntivo. NetApp fornisce il driver per i sistemi non HDFS. Per una destinazione NFS, NIPAM fornisce il driver per copiare i dati utilizzati da Hadoop DistCp per comunicare con le destinazioni NFS durante la copia dei dati.</block>
  <block id="1a4c7c9b6e3157ccd0101fd0836c0bfc" category="section-title">NetApp Cloud Volumes Service</block>
  <block id="05fc55cae9e8b2a7fb40e978e4971707" category="paragraph">NetApp Cloud Volumes Service è un file service nativo del cloud con performance estreme. Questo servizio aiuta i clienti ad accelerare il time-to-market, aumentando e diminuendo rapidamente le risorse e utilizzando le funzionalità NetApp per migliorare la produttività e ridurre i tempi di inattività del personale. Cloud Volumes Service è la giusta alternativa per il disaster recovery e il backup nel cloud, in quanto riduce l'impatto complessivo del data center e consuma meno storage di cloud pubblico nativo.</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">NetApp XCP è un software client che consente una migrazione dei dati rapida e affidabile da qualsiasi a NetApp e da NetApp a NetApp. Questo tool è progettato per copiare una grande quantità di dati NAS non strutturati da qualsiasi sistema NAS a un controller di storage NetApp. XCP Migration Tool utilizza un motore di streaming i/o multicore e multicanale in grado di elaborare molte richieste in parallelo, ad esempio migrazione dei dati, elenchi di file o directory e report di spazio. Questo è il tool di migrazione dei dati NetApp predefinito. È possibile utilizzare XCP per copiare i dati da un cluster Hadoop e HPC allo storage NetApp NFS. Il diagramma seguente mostra il trasferimento dei dati da un cluster Hadoop e HPC a un volume NetApp NFS utilizzando XCP.</block>
  <block id="cd7e68aa30250a331c260fee49ff230e" category="paragraph"><block ref="cd7e68aa30250a331c260fee49ff230e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc188738e6cc2e9f8314e1b95f18ebfd" category="section-title">NetApp Cloud Sync</block>
  <block id="1bce96270b79327e5daf4c0745d66023" category="paragraph">NetApp Cloud Sync è un software-as-a-service ibrido per la replica dei dati che trasferisce e sincronizza i dati NFS, S3 e CIFS in modo perfetto e sicuro tra storage on-premise e cloud storage. Questo software viene utilizzato per la migrazione dei dati, l'archiviazione, la collaborazione, l'analisi e altro ancora. Dopo il trasferimento dei dati, Cloud Sync sincronizza continuamente i dati tra l'origine e la destinazione. In futuro, trasferisce il delta. Inoltre, protegge i dati all'interno della tua rete, nel cloud o on-premise. Questo software si basa su un modello pay-as-you-go, che fornisce una soluzione conveniente e offre funzionalità di monitoraggio e reporting per il trasferimento dei dati.</block>
  <block id="cbba30a09e75669ecb5b3b2d83a25284" category="inline-link-macro">Successivo: Sfide per i clienti.</block>
  <block id="63aa417c654afafebdbdfcaf7a13c8b6" category="paragraph"><block ref="63aa417c654afafebdbdfcaf7a13c8b6" category="inline-link-macro-rx"></block></block>
  <block id="6a67053961e2b9d7e16bf757a5bea347" category="doc">Analisi dei dati moderna: Soluzioni diverse per diverse strategie di analisi</block>
  <block id="8e1e8679efe4694874eb9820dff26af8" category="paragraph">Questo white paper descrive le moderne strategie delle soluzioni di analisi dei dati di NetApp. Include dettagli sui risultati di business, le sfide dei clienti, le tendenze tecnologiche, l'architettura legacy della concorrenza, i flussi di lavoro moderni, casi di utilizzo, settori, cloud, partner tecnologici, data mover, NetApp Active IQ, NetApp DataOps Toolkit, Hadoop to Spark, storage software-defined con NetApp Astra Control, container, gestione dei dati aziendali, archiviazione e tiering per raggiungere gli obiettivi di ai e analisi e come NetApp e i clienti stanno modernizzando insieme la propria architettura dei dati.</block>
  <block id="9a13b1875b1cf906383834093477aa0b" category="paragraph"><block ref="9a13b1875b1cf906383834093477aa0b" category="inline-link-macro-rx"></block></block>
  <block id="4b3608ccf8a7154699127b487cc49627" category="paragraph">Questo documento descrive come spostare i dati dai sistemi di analisi dei big data e di calcolo ad alte performance (HPC) in modo che possano essere utilizzati nei flussi di lavoro di intelligenza artificiale (ai). In genere, l'ai elabora i dati NFS attraverso le esportazioni NFS. Tuttavia, potresti avere i tuoi dati ai in una piattaforma di big data analytics e high performance computing (HPC). Potrebbe trattarsi di HDFS (Distributed file System) Hadoop, BLOB (Binary Large Object), S3 o GPFS (General Parallel file System) di IBM. In questo documento, descriviamo come spostare i dati da una piattaforma di analisi dei big data e GPFS a NFS utilizzando comandi nativi di Hadoop, NetApp in-place Analytics Module (NIPAM) e NetApp XCP. Questo documento illustra anche i vantaggi per il business derivanti dal trasferimento dei dati dai big data e dall'HPC all'ai.</block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">In questa sezione viene fornita una descrizione dettagliata dei casi di utilizzo della protezione dei dati, che costituiscono l'oggetto del presente documento. Le restanti sezioni forniscono ulteriori dettagli per ciascun caso di utilizzo, ad esempio il problema del cliente (scenario), i requisiti, le sfide e le soluzioni.</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Panoramica dei casi di utilizzo della protezione dei dati Hadoop</block>
  <block id="d161097dc6596d3807b21a5635856d71" category="inline-link-macro">Precedente: Protezione dei dati Hadoop e NetApp.</block>
  <block id="1a5df0b83f496dc00b4a331caac0d5cd" category="paragraph"><block ref="1a5df0b83f496dc00b4a331caac0d5cd" category="inline-link-macro-rx"></block></block>
  <block id="817ac2975197bd6c376a7918a798981f" category="section-title">Caso d'utilizzo 1: Backup dei dati Hadoop</block>
  <block id="385dae214dc9bab52698dc7cd42632ad" category="paragraph">In questo caso di utilizzo, il modulo di analisi in-place ha aiutato un grande istituto finanziario a ridurre la lunga finestra di backup da più di 24 ore a poco meno di poche ore.</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">Utilizzando il data fabric basato su NetApp come elementi di base, una grande azienda di radiodiffusione è stata in grado di soddisfare il proprio requisito di backup dei dati cloud nel proprio data center on-premise, a seconda delle diverse modalità di trasferimento dei dati, come on-demand, istantaneo, O in base al carico del cluster Hadoop/Spark.</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">Le soluzioni NetApp hanno aiutato un distributore di musica online a creare rapidamente più cluster Hadoop efficienti in termini di spazio in diverse filiali per creare report ed eseguire attività DevTest quotidiane utilizzando policy pianificate.</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">Un grande provider di servizi ha utilizzato il data fabric basato su NetApp per fornire ai propri clienti analytics multicloud da diverse istanze di cloud.</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">Una delle più grandi banche di investimento e servizi finanziari ha utilizzato la soluzione di storage NAS di NetApp per ridurre i tempi di attesa i/o e accelerare la piattaforma di analisi finanziaria quantitativa.</block>
  <block id="2afe208a471bf6c54f0ccc97f4c6508d" category="inline-link-macro">Successivo: Caso d'utilizzo 1 - Backup dei dati Hadoop.</block>
  <block id="aac250a096aacf9aed26ebbd137818da" category="paragraph"><block ref="aac250a096aacf9aed26ebbd137818da" category="inline-link-macro-rx"></block></block>
  <block id="b27064a5ca31ea524411e6ce281c8f0c" category="paragraph">NetApp offre una soluzione semplice e scalabile per Splunk SmartStore che massimizza le performance e la resilienza offrendo al contempo un TCO convincente.</block>
  <block id="8eac57fa6403d9c896c24cb94767e954" category="summary">Ora che esiste una soluzione per il problema del ridenominazione sciocco nello storage NFS con Kafka, è possibile creare solide implementazioni che sfruttano lo storage NetApp ONTAP per il carico di lavoro Kafka. Questo non solo riduce significativamente l'overhead operativo, ma offre anche i seguenti vantaggi ai cluster Kafka.</block>
  <block id="76827cff700415303c6b7420a1869192" category="doc">Perché scegliere NetApp NFS per i workload Kafka?</block>
  <block id="dfcc8e1c7335951df2dcc87acef063d3" category="inline-link-macro">Precedente: Convalida funzionale - correzione del ridenominazione.</block>
  <block id="daa2168d5bad682cea233a9548c0172f" category="paragraph"><block ref="daa2168d5bad682cea233a9548c0172f" category="inline-link-macro-rx"></block></block>
  <block id="984b2b530f32710e640393a80677e426" category="paragraph">Ora che esiste una soluzione per il problema del ridenominazione sciocco nello storage NFS con Kafka, è possibile creare solide implementazioni che sfruttano lo storage NetApp ONTAP per il carico di lavoro Kafka. Questo non solo riduce significativamente l'overhead operativo, ma offre anche i seguenti vantaggi ai cluster Kafka:</block>
  <block id="2dbec01439aed1c5b5fbe8a521623f2d" category="list-text">*Utilizzo ridotto della CPU per i broker Kafka.* l'utilizzo dello storage NetApp ONTAP disaggregato separa le operazioni di i/o dei dischi dal broker e riduce così l'impatto della CPU.</block>
  <block id="24c6011da569f3cc3fede5c4eafff91e" category="list-text">*Tempi di recovery più rapidi per i broker.* poiché lo storage NetApp ONTAP disaggregato è condiviso tra i nodi dei broker Kafka, una nuova istanza di calcolo può sostituire un broker difettoso in qualsiasi momento in una frazione del tempo rispetto alle implementazioni Kafka convenzionali senza ricostruire i dati.</block>
  <block id="04615fed33ad7a5a209c685460f2c557" category="list-text">*Efficienza dello storage.* con il provisioning del layer di storage dell'applicazione tramite NetApp ONTAP, i clienti possono sfruttare tutti i vantaggi dell'efficienza dello storage forniti con ONTAP, come compressione dei dati in linea, deduplica e compaction.</block>
  <block id="c7444ea1ca211e0d3dd1b89c4f792d00" category="paragraph">Questi vantaggi sono stati testati e validati in casi di test di cui discutiamo in dettaglio in questa sezione.</block>
  <block id="454cd026e1a6a7761ee25bf6682aeb2b" category="section-title">Riduzione dell'utilizzo della CPU sul broker Kafka</block>
  <block id="70c59ac3ed6ee89fe977676b2dba2f05" category="paragraph">Abbiamo scoperto che l'utilizzo complessivo della CPU è inferiore rispetto alla controparte DAS quando abbiamo eseguito carichi di lavoro simili su due cluster Kafka separati che erano identici nelle specifiche tecniche ma differivano nelle tecnologie di storage. Non solo l'utilizzo complessivo della CPU è inferiore quando il cluster Kafka utilizza lo storage ONTAP, ma l'aumento dell'utilizzo della CPU ha dimostrato un gradiente più delicato rispetto a un cluster Kafka basato su DAS.</block>
  <block id="029bc8dc2b20f11a166635df18b0a419" category="section-title">Configurazione architetturale</block>
  <block id="c9d177e7e6018d464567bf6a8f9773e7" category="paragraph">La seguente tabella mostra la configurazione ambientale utilizzata per dimostrare un utilizzo ridotto della CPU.</block>
  <block id="5ed4a4dbe122b39d7103642bff11de54" category="cell">Tool di benchmarking Kafka 3.2.3: OpenMessaging</block>
  <block id="e2322efe17a0927e7f855686b9597301" category="list-text">3 zookeeper – t2.small</block>
  <block id="ea55ea3b374458b5777457efaf0db679" category="list-text">3 server di broker – i3en.2xlarge</block>
  <block id="d521f24278937c9ada520622e97168d8" category="list-text">1 x Grafana – c5n.2xlarge</block>
  <block id="3cb61b8b67329a8a20d9128458cf6633" category="list-text">4 x Produttore/Consumer -- c5n.2xlarge</block>
  <block id="d34010cfee0f2a6d774e450acd135088" category="cell">RHEL 8.7 o versione successiva</block>
  <block id="bce5fbe7fa89f635a887c6af2f95a9be" category="cell">Istanza a nodo singolo – M5.2xLarge</block>
  <block id="a27bb92a9fdd5b8b4c084b824b810232" category="section-title">Tool di benchmarking</block>
  <block id="d483516be45a355eab4c7f9b129540c9" category="inline-link">OpenMessaging</block>
  <block id="0a48e066bcee681066419fb01ccd9f16" category="paragraph">Lo strumento di benchmarking utilizzato in questo caso di test è<block ref="3990ab384d3299fd4c655b02444eb5d6" category="inline-link-rx"></block> framework. OpenMessaging è indipendente dal vendor e dal linguaggio; fornisce linee guida di settore per finanza, e-commerce, IoT e big data; aiuta a sviluppare applicazioni di messaggistica e streaming su sistemi e piattaforme eterogenee. La figura seguente mostra l'interazione dei client OpenMessaging con un cluster Kafka.</block>
  <block id="ac6d62ee86368b8c24366434f9b5d5a1" category="inline-image-macro">Questa immagine mostra l'interazione dei client OpenMessaging con un cluster Kafka.</block>
  <block id="370c47f03f13e0b2954d14225811e64c" category="paragraph"><block ref="370c47f03f13e0b2954d14225811e64c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6250495e61aa2eb3c47f71d21f58c6f8" category="list-text">*Compute.* abbiamo utilizzato un cluster Kafka a tre nodi con un ensemble di zookeeper a tre nodi in esecuzione su server dedicati. Ciascun broker disponeva di due mount point NFSv4.1 su un singolo volume sull'istanza CVO di NetApp attraverso una LIF dedicata.</block>
  <block id="f91ee5c5359f2260d72c50f2c8009925" category="list-text">*Monitoring.* abbiamo utilizzato due nodi per una combinazione Prometheus-Grafana. Per la generazione dei carichi di lavoro, abbiamo un cluster a tre nodi separato che può produrre e consumare da questo cluster Kafka.</block>
  <block id="e2b1493c4214be739b2c9349a2c481ef" category="list-text">*Storage.* abbiamo utilizzato un'istanza NetApp Cloud Volumes ONTAP a nodo singolo con sei volumi AWS-EBS GP2 da 250 GB montati sull'istanza. Questi volumi sono stati quindi esposti al cluster Kafka come sei volumi NFSv4.1 attraverso LIF dedicate.</block>
  <block id="ede634748bd4515e69245593cfc4478c" category="list-text">*Configurazione.* i due elementi configurabili in questo test case erano i broker Kafka e i carichi di lavoro OpenMessaging.</block>
  <block id="b053d1656e3b9dcaa2b4834fbdc4fb86" category="list-text">*Broker config.* per i broker Kafka sono state selezionate le seguenti specifiche. Abbiamo utilizzato il fattore di replica di 3 per tutte le misurazioni, come evidenziato di seguito.</block>
  <block id="d5ee20b40da2061d10bff33a6f13467a" category="inline-image-macro">Questa immagine mostra le specifiche selezionate per i broker Kafka.</block>
  <block id="d0255d634f4013c1da82b391ac0fa7f5" category="paragraph"><block ref="d0255d634f4013c1da82b391ac0fa7f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82f54619faeaa86063f362102c160601" category="list-text">*OpenMessaging benchmark (OMB) workload config.* sono state fornite le seguenti specifiche. Abbiamo specificato un tasso di produzione target, evidenziato di seguito.</block>
  <block id="da43f96a4bfe17af8039df6b15f4f6da" category="inline-image-macro">Questa immagine mostra le specifiche selezionate per la configurazione del carico di lavoro del benchmark OpenMessaging.</block>
  <block id="39e4197e665f900596d0136c11eaa851" category="paragraph"><block ref="39e4197e665f900596d0136c11eaa851" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6067cc387407f4d8dc9d623c770cfd" category="list-text">Sono stati creati due cluster simili, ciascuno con un proprio set di benchmark di sciami di cluster.</block>
  <block id="c85bb905404dda665035e21b11ab1a58" category="list-text">Cluster 1.* cluster Kafka basato su NFS.</block>
  <block id="9ed0b3eccef17299a0119b0f28568e78" category="list-text">Cluster 2.* cluster Kafka basato su DAS.</block>
  <block id="a38c46362b3feb9b3bb5f53b1957d50f" category="list-text">Utilizzando un comando OpenMessaging, carichi di lavoro simili sono stati attivati su ciascun cluster.</block>
  <block id="c18ed3feb8720fe4fc76d90a9fa6a6e3" category="list-text">La configurazione del tasso di produzione è stata aumentata in quattro iterazioni e l'utilizzo della CPU è stato registrato con Grafana. Il tasso di produzione è stato impostato sui seguenti livelli:</block>
  <block id="04207e7bb62b9b5d14bdb603f74e683c" category="list-text">10,000</block>
  <block id="e19784a5420512b2876c7b24680652b5" category="list-text">40,000</block>
  <block id="e57650a6c15f273334d41da58fa72111" category="list-text">80,000</block>
  <block id="ee70718f6a92d6c1b099a6942f594963" category="list-text">100,000</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">Osservazione</block>
  <block id="524fdb84d137ea63c19f5efab343f82b" category="paragraph">L'utilizzo dello storage NetApp NFS con Kafka offre due vantaggi principali:</block>
  <block id="612e27ad9fd383437f1445cf80d554b1" category="list-text">*È possibile ridurre l'utilizzo della CPU di quasi un terzo.* l'utilizzo complessivo della CPU con carichi di lavoro simili è stato inferiore per NFS rispetto agli SSD DAS; i risparmi variano dal 5% per velocità di produzione inferiori al 32% per velocità di produzione superiori.</block>
  <block id="bc31b9852409e970a3a4659fef4b4f93" category="list-text">*Una riduzione di tre volte nella deriva di utilizzo della CPU a velocità di produzione più elevate.* come previsto, si è verificata una deriva verso l'alto per l'aumento dell'utilizzo della CPU con l'aumento dei tassi di produzione. Tuttavia, l'utilizzo della CPU sui broker Kafka che utilizzano DAS è aumentato dal 31% per il tasso di produzione inferiore al 70% per il tasso di produzione più elevato, un aumento del 39%. Tuttavia, con un backend di storage NFS, l'utilizzo della CPU è aumentato dal 26% al 38%, con un aumento del 12%.</block>
  <block id="6299b9c8f7a14a0a0ca7407cbb9a187a" category="inline-image-macro">Questo grafico illustra il comportamento di un cluster basato su DAS.</block>
  <block id="1e669d4d02de91a94a05137bdd1dc491" category="paragraph"><block ref="1e669d4d02de91a94a05137bdd1dc491" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60e393621d29424b529201d4bc48e3b4" category="inline-image-macro">Questo grafico illustra il comportamento di un cluster basato su NFS.</block>
  <block id="68437c53e33bd5423258ea6fd20a35f5" category="paragraph"><block ref="68437c53e33bd5423258ea6fd20a35f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03d4293a3bcf73010216e2f0399fd571" category="paragraph">Inoltre, con 100,000 messaggi, DAS mostra un utilizzo della CPU maggiore rispetto a un cluster NFS.</block>
  <block id="a0e6052c526d2d343fa217b609c943a6" category="inline-image-macro">Questo grafico illustra il comportamento di un cluster basato su DAS con 100,000 messaggi.</block>
  <block id="7c994cd9d5150762faf629fff71db6c6" category="paragraph"><block ref="7c994cd9d5150762faf629fff71db6c6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9d76c4aeb68cf4d7ef9bf3ce121bdd2" category="inline-image-macro">Questo grafico illustra il comportamento di un cluster basato su NFS con 100,000 messaggi.</block>
  <block id="0dd7c57e19e01e516dc697178954bfd5" category="paragraph"><block ref="0dd7c57e19e01e516dc697178954bfd5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60a5caa55d79e52e0af298cf19b5c73d" category="section-title">Recupero più rapido del broker</block>
  <block id="bc0ed21388f4042414a88362de068e14" category="paragraph">Abbiamo scoperto che i broker Kafka si ripristinano più velocemente quando utilizzano lo storage NetApp NFS condiviso. Quando un broker si blocca in un cluster Kafka, questo broker può essere sostituito da un broker sano con lo stesso ID broker. Dopo aver eseguito questo test case, abbiamo scoperto che, nel caso di un cluster Kafka basato su DAS, il cluster ricostruisce i dati su un nuovo broker sano aggiunto, il che richiede tempo. Nel caso di un cluster Kafka basato su NetApp NFS, il broker che sostituisce continua a leggere i dati dalla directory di log precedente e a ripristinarli molto più velocemente.</block>
  <block id="61c964c4267b0fa60eeaa1a7ccdf706e" category="paragraph">La seguente tabella mostra la configurazione ambientale per un cluster Kafka che utilizza NAS.</block>
  <block id="f874b8bfe50ce846d8156aabe96e5a34" category="cell">Kafka 3.2.3</block>
  <block id="687972ccb765e5204fa2220ba3dff130" category="list-text">4 x produttore/consumatore -- c5n.2xlarge</block>
  <block id="31638173210d76d464e93c8f3f53711c" category="list-text">1 nodo Kafka di backup – i3en.2xlarge</block>
  <block id="5d27021addda02398c54d28a4ceee767" category="cell">RHEL8.7 o versione successiva</block>
  <block id="6c2cacbcd5f4927358fee9d8a0b60252" category="paragraph">La figura seguente mostra l'architettura di un cluster Kafka basato su NAS.</block>
  <block id="78f0f1d311c4aae35de324851ecea08a" category="inline-image-macro">Questa figura illustra l'architettura di un cluster Kafka basato su NAS.</block>
  <block id="f11ab4a9f30f1c13023294b83c1968fb" category="paragraph"><block ref="f11ab4a9f30f1c13023294b83c1968fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64898c42d1ced91d44ff2e383b066de3" category="list-text">*Compute.* un cluster Kafka a tre nodi con un ensemble di zookeeper a tre nodi in esecuzione su server dedicati. Ciascun broker dispone di due punti di montaggio NFS per un singolo volume sull'istanza NetApp CVO tramite un LIF dedicato.</block>
  <block id="06e870f499bc90bbe828323be8625621" category="list-text">*Monitoring.* due nodi per una combinazione Prometheus-Grafana. Per la generazione dei carichi di lavoro, utilizziamo un cluster a tre nodi separato in grado di produrre e utilizzare questo cluster Kafka.</block>
  <block id="1a5c8241b05feb71d0733c2cc2f073c2" category="list-text">*Storage.* un'istanza NetApp Cloud Volumes ONTAP a nodo singolo con sei volumi GP2 AWS-EBS da 250 GB montati sull'istanza. Questi volumi vengono quindi esposti al cluster Kafka come sei volumi NFS attraverso LIF dedicate.</block>
  <block id="1f4b2c66cbc586fa9658b18333582240" category="list-text">*Configurazione Broker.* l'elemento configurabile in questo caso di test sono i broker Kafka. Per i broker Kafka sono state selezionate le seguenti specifiche. Il<block ref="2aa7cd054835892b354c130576c17b61" prefix=" " category="inline-code"></block> È impostato su un valore alto perché questo determina la velocità con cui un determinato nodo viene estratto dall'elenco ISR. Quando si passa da un nodo cattivo a un nodo integro, non si desidera che l'ID broker sia escluso dall'elenco ISR.</block>
  <block id="d6068b616491b51ff179d0138965bba4" category="inline-image-macro">Questa immagine mostra le specifiche scelte per i broker Kafka.</block>
  <block id="4bc3bbed275832f042bf33735b245eee" category="paragraph"><block ref="4bc3bbed275832f042bf33735b245eee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f6ea5961f5640ce4fa828022abc91c1" category="list-text">Sono stati creati due cluster simili:</block>
  <block id="71754d8c640cd0a117a3c82af0bd3646" category="list-text">Un cluster confluente basato su EC2.</block>
  <block id="c4b4e0617e4a38a83a00fc9bd8083465" category="list-text">Un cluster confluente basato su NetApp NFS.</block>
  <block id="fbbf8c78f6f01371b1caa7b79bfa91b9" category="list-text">È stato creato un nodo Kafka di standby con una configurazione identica ai nodi del cluster Kafka originale.</block>
  <block id="b2d04ce59538c1ba125aa91697b3854f" category="list-text">Su ciascuno dei cluster è stato creato un argomento di esempio e sono stati popolati circa 110 GB di dati su ciascuno dei broker.</block>
  <block id="25bb70a763a5456f70f68d98646ecbd6" category="list-text">*Cluster basato su EC2.* Su Cui è mappata Una directory di dati del broker Kafka<block ref="8463a3643fa4431218a88d6e1e85f064" prefix=" " category="inline-code"></block> (Nella figura seguente, Broker-1 del cluster1 [terminale sinistro]).</block>
  <block id="bbec1799f53d01620bdd78881b0f0310" category="list-text">*Cluster NetApp basato su NFS.* Una directory di dati del broker Kafka è montata su NFS point<block ref="ecabd55f704fe0f0dcc41be6e7e7ab83" prefix=" " category="inline-code"></block> (Nella figura seguente, Broker-1 del cluster2 [terminale destro]).</block>
  <block id="86f85a2a5eed8a784f9a06a8fe205c9a" category="inline-image-macro">Questa immagine mostra due schermate del terminale.</block>
  <block id="390d46f539d5037b90b3b548ca4abc79" category="paragraph"><block ref="390d46f539d5037b90b3b548ca4abc79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02296aafa9e3a6424418dd97a673e931" category="list-text">In ciascuno dei cluster, il broker-1 è stato terminato per attivare un processo di recovery del broker non riuscito.</block>
  <block id="fe4c3f604a59eb786f64f0fc5a7cfa01" category="list-text">Una volta terminato il broker, l'indirizzo IP del broker è stato assegnato come IP secondario al broker di standby. Ciò era necessario perché un broker in un cluster Kafka è identificato da quanto segue:</block>
  <block id="597bfb23e3e10c354a661882e4728565" category="list-text">*Indirizzo IP.* assegnato riassegnando l'IP del broker guasto al broker di standby.</block>
  <block id="d86a6ec6cd64cd7365ad5d46f7c32d85" category="list-text">*Broker ID.* questa opzione è stata configurata nel broker di standby<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block>.</block>
  <block id="c71af5d75ff28fc80b8aa2c6c6832c39" category="list-text">Al momento dell'assegnazione IP, il servizio Kafka è stato avviato sul broker di standby.</block>
  <block id="e6f0e1804a85ff41f08342fa0cd0e8c5" category="list-text">Dopo un po', i log del server sono stati estratti per controllare il tempo impiegato per creare i dati sul nodo sostitutivo nel cluster.</block>
  <block id="b4e6de827ba8af76c3d7cf0e11dee63e" category="paragraph">Il recupero del broker Kafka è stato quasi nove volte più veloce. Il tempo necessario per ripristinare un nodo broker guasto è risultato notevolmente più veloce quando si utilizza lo storage condiviso NetApp NFS rispetto all'utilizzo di SSD DAS in un cluster Kafka. Per 1 TB di dati su argomenti, il tempo di ripristino per un cluster basato su DAS è stato di 48 minuti, rispetto a meno di 5 minuti per un cluster Kafka basato su NetApp-NFS.</block>
  <block id="fcd5351f741ba27a03aeaa4aff141fde" category="paragraph">Abbiamo osservato che il cluster basato su EC2 ha impiegato 10 minuti per ricostruire i 110 GB di dati sul nuovo nodo del broker, mentre il cluster basato su NFS ha completato il ripristino in 3 minuti. Abbiamo anche osservato nei log che gli offset consumer per le partizioni EC2 erano 0, mentre nel cluster NFS gli offset consumer sono stati rilevati dal broker precedente.</block>
  <block id="01a0d5c558a836a74adf3dc3fe1de25d" category="section-title">Cluster basato SU DAS</block>
  <block id="542ac5d9dd4769eb5fb4a8a7da3aa594" category="list-text">Il nodo di backup è iniziato alle 08:55:53,730.</block>
  <block id="b5f0acf8be0dd329b7dae7c96c9b3dc8" category="inline-image-macro">Questa immagine mostra l'output del log per un cluster basato su DAS.</block>
  <block id="04b616f87a48976d96105dd8da106220" category="paragraph"><block ref="04b616f87a48976d96105dd8da106220" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d48d1996a0b89fc5aa313e48f1c2c149" category="list-text">Il processo di ricostruzione dei dati è terminato alle 09:05:24,860. L'elaborazione di 110 GB di dati richiede circa 10 minuti.</block>
  <block id="56e5a0f063355e55045e219c7ff3cae3" category="paragraph"><block ref="56e5a0f063355e55045e219c7ff3cae3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d10d1e0d7dc7546ca2ee585553c90f24" category="section-title">Cluster basato su NFS</block>
  <block id="e163d6812be40c2618b43cc9d2ed21a1" category="list-text">Il nodo di backup è stato avviato alle 09:39:17,213. La voce del registro di avvio viene evidenziata di seguito.</block>
  <block id="1af763f7fe72be73a16f6a9010023e1f" category="inline-image-macro">Questa immagine mostra l'output del log per un cluster basato su NFS.</block>
  <block id="97d0b1f6f9620cf3ad52778c81887d14" category="paragraph"><block ref="97d0b1f6f9620cf3ad52778c81887d14" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459f0a82f7fc8505de6db94698f5e9c8" category="list-text">Il processo di ricostruzione dei dati è terminato alle 09:42:29,115. L'elaborazione di 110 GB di dati richiede circa 3 minuti.</block>
  <block id="f21adb2cdf95034f20ec22d797a2b2be" category="paragraph"><block ref="f21adb2cdf95034f20ec22d797a2b2be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24c9b21a2ca87ae467a56b044593521b" category="paragraph">Il test è stato ripetuto per i broker contenenti circa 1 TB di dati, che hanno richiesto circa 48 minuti per il DAS e 3 minuti per NFS. I risultati sono illustrati nel seguente grafico.</block>
  <block id="6994918ac91afbe69dd9a20ab257afa1" category="inline-image-macro">Questo grafico mostra il tempo necessario per il ripristino del broker in base alla quantità di dati caricati sul broker per un cluster basato su DAS o NFS.</block>
  <block id="a853fdd02599082a126937405a2c304c" category="paragraph"><block ref="a853fdd02599082a126937405a2c304c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f94ef2603834178da773ec5ccd97683b" category="paragraph">Poiché il provisioning del layer di storage del cluster Kafka è stato eseguito tramite NetApp ONTAP, abbiamo ottenuto tutte le funzionalità di efficienza dello storage di ONTAP. Questo è stato testato generando una quantità significativa di dati su un cluster Kafka con storage NFS fornito su Cloud Volumes ONTAP. Abbiamo potuto constatare che le funzionalità di ONTAP hanno ridotto notevolmente lo spazio.</block>
  <block id="747684069b5286f0282d40e544a04812" category="list-text">4 x produttore/consumatore -- c5n.2xlargo *</block>
  <block id="d1030267f4090d953bd3cabbb565b51b" category="cell">Istanza a nodo singolo – M5.2xLarge</block>
  <block id="717373873e977ccdc16d9a371e92b55b" category="list-text">*Compute.* abbiamo utilizzato un cluster Kafka a tre nodi con un ensemble di zookeeper a tre nodi in esecuzione su server dedicati. Ciascun broker disponeva di due punti di montaggio NFS su un singolo volume sull'istanza NetApp CVO tramite un LIF dedicato.</block>
  <block id="493b3bd02a683f505d957bb27957e1b6" category="list-text">*Monitoring.* abbiamo utilizzato due nodi per una combinazione Prometheus-Grafana. Per la generazione dei carichi di lavoro, abbiamo utilizzato un cluster a tre nodi separato in grado di produrre e utilizzare questo cluster Kafka.</block>
  <block id="cce21f164c30f5ce10f914c4542e252f" category="list-text">*Storage.* abbiamo utilizzato un'istanza NetApp Cloud Volumes ONTAP a nodo singolo con sei volumi AWS-EBS GP2 da 250 GB montati sull'istanza. Questi volumi sono stati quindi esposti al cluster Kafka come sei volumi NFS attraverso LIF dedicate.</block>
  <block id="68f29d01fbebb4ad998127522e13950b" category="list-text">*Configurazione.* gli elementi configurabili in questo test case erano i broker Kafka.</block>
  <block id="86e1dede1fc5701676bec82003409aff" category="paragraph">La compressione è stata disattivata alla fine del produttore, consentendo così ai produttori di generare un throughput elevato. L'efficienza dello storage è stata invece gestita dal livello di elaborazione.</block>
  <block id="7da10cbdbba2e826cd4954054b5c1843" category="list-text">È stato eseguito il provisioning di un cluster Kafka con le specifiche indicate in precedenza.</block>
  <block id="e857c1394ce43b04a9548d5a3dec0ee5" category="list-text">Sul cluster, sono stati prodotti circa 350 GB di dati utilizzando il tool OpenMessaging Benchmarking.</block>
  <block id="efc4a3d9bfed3a9a80b0caea9016ca6c" category="list-text">Una volta completato il carico di lavoro, le statistiche sull'efficienza dello storage sono state raccolte utilizzando Gestione di sistema di ONTAP e l'interfaccia CLI.</block>
  <block id="9c9850d81b369454a9610d48c5bfe8a0" category="paragraph">Per i dati generati con lo strumento OMB, abbiamo registrato un risparmio di spazio di ~33% con un rapporto di efficienza dello storage di 1.70:1. Come mostrato nelle figure seguenti, lo spazio logico utilizzato dai dati prodotti era di 420,3 GB e lo spazio fisico utilizzato per contenere i dati era di 281,7 GB.</block>
  <block id="f11c8594ca77ceb3e0ab124768dd061d" category="inline-image-macro">Questa immagine mostra il risparmio di spazio in VMDISK.</block>
  <block id="e9cfd3a2897ae25384f04fb11643ac21" category="paragraph"><block ref="e9cfd3a2897ae25384f04fb11643ac21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3afbd9828e011526955ca93b48b57524" category="inline-image-macro">Schermata</block>
  <block id="1509f2dafd7ef601c7bf6b69e651ebaf" category="paragraph"><block ref="1509f2dafd7ef601c7bf6b69e651ebaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="419c9cc44cd35123f9e118ff58d18c8d" category="paragraph"><block ref="419c9cc44cd35123f9e118ff58d18c8d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9336817b144fc8ca86c3b1bf261ff0dc" category="inline-link-macro">Pagina successiva: Panoramica delle performance e validazione in AWS.</block>
  <block id="2843eeeffb833436dcf46445acebde91" category="paragraph"><block ref="2843eeeffb833436dcf46445acebde91" category="inline-link-macro-rx"></block></block>
  <block id="dbb940c31f0b7d7563745993661f70d4" category="summary">Abbiamo eseguito test dello storage su più livelli con cinque o otto nodi broker durante un carico di lavoro di produzione-consumo con un controller di storage NetApp a coppia AFF A900 ha. Secondo i nostri test, il tempo di completamento e i risultati delle performance sono stati scalati in base al numero di nodi broker fino a quando l'utilizzo delle risorse di AFF A900 non ha raggiunto il 100%. La configurazione del controller di storage ONTAP richiedeva almeno una coppia ha.</block>
  <block id="91e1cb9730965860cb465802520e6a45" category="doc">Test delle performance con generatore di carichi di lavoro producete-consumate</block>
  <block id="3daa014912cbb3dddcdeae426aea8652" category="inline-link-macro">Precedente: Convalida delle performance confluente.</block>
  <block id="262b5107278b398d0de9b7ef6b52e5d0" category="paragraph"><block ref="262b5107278b398d0de9b7ef6b52e5d0" category="inline-link-macro-rx"></block></block>
  <block id="b15c40872cdd0b1e0a152907f2194e69" category="paragraph">Le performance per l'operazione di recupero S3 sono aumentate linearmente in base al numero di nodi di broker confluenti. Lo storage controller ONTAP supporta fino a 12 coppie ha in una singola implementazione.</block>
  <block id="ec043d5e2714e1035038cbeb1aa3cba8" category="paragraph">Il seguente grafico mostra il traffico di tiering S3 combinato con cinque o otto nodi broker. Abbiamo massimizzato le prestazioni della coppia ha singola AFF A900.</block>
  <block id="ffff2891cfdd07445c4e1e5261739c68" category="inline-image-macro">Questo grafico dei dati mostra il traffico di tiering S3 combinato con cinque o otto nodi di broker.</block>
  <block id="388c51cbcac77b72c2e68dc334f9cf73" category="paragraph"><block ref="388c51cbcac77b72c2e68dc334f9cf73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1efe906cedfd00618bda4d39b41a52fd" category="paragraph">Il seguente grafico mostra il throughput di Kafka a circa 31,74 GBps.</block>
  <block id="e7aff80741661a5eb60f57649077f9c5" category="inline-image-macro">Questo grafico dei dati mostra il throughput di Kafka a circa 31,74 GBps.</block>
  <block id="1dc39288e0903ff9947d26bba4d46cef" category="paragraph"><block ref="1dc39288e0903ff9947d26bba4d46cef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6821411dfc3b7f483da21b37082dfc" category="paragraph">Abbiamo anche osservato un throughput simile nel controller di storage ONTAP<block ref="d40e53103e181690f77a04eadc8aa6cc" prefix=" " category="inline-code"></block> report.</block>
  <block id="12521f8f565efeb65b076c8966841804" category="inline-link-macro">Segue: Linee guida sulle Best practice per le performance.</block>
  <block id="4d8306a1e68c76874ac5d8c93a819977" category="paragraph"><block ref="4d8306a1e68c76874ac5d8c93a819977" category="inline-link-macro-rx"></block></block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">In questo scenario, il cliente dispone di un grande repository Hadoop on-premise e desidera eseguirne il backup a scopo di disaster recovery. Tuttavia, l'attuale soluzione di backup del cliente è costosa e presenta una lunga finestra di backup di oltre 24 ore.</block>
  <block id="8efec9e11b7742f59dbe1af079e1c1d0" category="inline-link-macro">Precedente: Panoramica dei casi di utilizzo della protezione dei dati Hadoop.</block>
  <block id="259b434ecfae95df231c879645a98918" category="paragraph"><block ref="259b434ecfae95df231c879645a98918" category="inline-link-macro-rx"></block></block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">Compatibilità con le versioni precedenti del software:</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">La soluzione di backup alternativa proposta deve essere compatibile con le versioni software attualmente in esecuzione utilizzate nel cluster Hadoop di produzione.</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">Per soddisfare gli SLA impegnati, la soluzione alternativa proposta dovrebbe raggiungere RPO e RTO molto bassi.</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">Il backup creato dalla soluzione di backup NetApp può essere utilizzato nel cluster Hadoop costruito localmente nel data center e nel cluster Hadoop in esecuzione nella posizione di disaster recovery presso il sito remoto.</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">La soluzione proposta deve essere conveniente.</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">La soluzione proposta deve ridurre l'effetto delle performance sui processi di analisi in produzione attualmente in esecuzione durante i tempi di backup.</block>
  <block id="e3d4f6860e578b28733c41c2c852f821" category="section-title">Soluzione di backup esistente del cliente</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">La figura seguente mostra la soluzione di backup nativa Hadoop originale.</block>
  <block id="2975218bd3c71a4ac4eac95d3529a9cb" category="paragraph"><block ref="2975218bd3c71a4ac4eac95d3529a9cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">I dati di produzione sono protetti su nastro attraverso il cluster di backup intermedio:</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">I dati HDFS1 vengono copiati in HDFS2 eseguendo il<block ref="56eafdf3e9748260b9403493314dc20d" prefix=" " category="inline-code"></block> comando.</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">Il cluster di backup funge da gateway NFS e i dati vengono copiati manualmente su nastro attraverso Linux<block ref="9c95319bf274672d6eae7eb97c3dfda5" prefix=" " category="inline-code"></block> tramite la libreria di nastri.</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">I vantaggi della soluzione di backup nativa Hadoop originale includono:</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">La soluzione si basa sui comandi nativi di Hadoop, che consentono all'utente di non dover apprendere nuove procedure.</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">La soluzione sfrutta l'architettura e l'hardware standard di settore.</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">Gli svantaggi della soluzione di backup nativa Hadoop originale includono:</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">La lunga finestra di backup supera le 24 ore, rendendo vulnerabili i dati di produzione.</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">Peggioramento significativo delle performance del cluster durante i tempi di backup.</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">La copia su nastro è un processo manuale.</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">La soluzione di backup è costosa in termini di hardware richiesto e di ore umane richieste per i processi manuali.</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">Soluzioni di backup</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">In base a queste sfide e requisiti e tenendo conto del sistema di backup esistente, sono state suggerite tre possibili soluzioni di backup. Le seguenti sottosezioni descrivono ciascuna di queste tre diverse soluzioni di backup, etichettate dalla soluzione A alla soluzione C.</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">Soluzione A</block>
  <block id="8ee7b0fbb95cf5b1c98578a7ef03b9eb" category="paragraph">La soluzione A aggiunge il modulo di analisi in-place al cluster di backup Hadoop, che consente backup secondari sui sistemi di storage NetApp NFS, eliminando il requisito del nastro, come mostrato nella figura seguente.</block>
  <block id="411ee6c684ee720eff303771433e41d6" category="paragraph"><block ref="411ee6c684ee720eff303771433e41d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">Le attività dettagliate per la soluzione A includono:</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">Il cluster di produzione Hadoop contiene i dati di analisi del cliente nell'HDFS che richiede protezione.</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">Il cluster di backup Hadoop con HDFS funge da posizione intermedia per i dati. Solo un gruppo di dischi (JBOD) fornisce lo storage per HDFS sia nei cluster Hadoop di produzione che di backup.</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">Proteggere i dati di produzione di Hadoop dal cluster di produzione HDFS al cluster di backup HDFS mediante l'esecuzione di<block ref="900bb9daf20a55f63530a23a8ff21d21" prefix=" " category="inline-code"></block> comando.</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">Lo snapshot Hadoop viene utilizzato per proteggere i dati dalla produzione al cluster di backup Hadoop.</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">Il controller di storage NetApp ONTAP fornisce un volume esportato NFS, che viene fornito al cluster di backup Hadoop.</block>
  <block id="b0e42779d51b21a745cae08f938ec60a" category="list-text">Eseguendo il<block ref="e23fdb1dae75e2830274d92fdf2535ed" prefix=" " category="inline-code"></block> Utilizzando MapReduce e più mappatori, i dati di analisi sono protetti dal cluster di backup Hadoop a NFS utilizzando il modulo di analisi in-place.</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">Una volta archiviati i dati in NFS sul sistema storage NetApp, le tecnologie NetApp Snapshot, SnapRestore e FlexClone vengono utilizzate per eseguire il backup, il ripristino e la duplicazione dei dati Hadoop in base alle necessità.</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">I dati Hadoop possono essere protetti nel cloud e nelle posizioni di disaster recovery utilizzando la tecnologia SnapMirror.</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">I vantaggi della soluzione A includono:</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">I dati di produzione di Hadoop sono protetti dal cluster di backup.</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">I dati HDFS sono protetti tramite NFS, consentendo la protezione in ambienti cloud e di disaster recovery.</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">Migliora le performance trasferendo le operazioni di backup nel cluster di backup.</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">Elimina le operazioni manuali su nastro</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">Consente funzioni di gestione aziendale tramite gli strumenti NetApp.</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">Richiede modifiche minime all'ambiente esistente.</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">È una soluzione conveniente.</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">Lo svantaggio di questa soluzione è che richiede un cluster di backup e mappatori aggiuntivi per migliorare le performance.</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">Il cliente ha recentemente implementato la soluzione A per la sua semplicità, i costi e le performance complessive.</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">In questa soluzione, è possibile utilizzare i dischi SAN di ONTAP invece di JBOD. Questa opzione trasferisce il carico dello storage del cluster di backup su ONTAP; tuttavia, il downside è che sono richiesti switch fabric SAN.</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">Soluzione B</block>
  <block id="304af2b0b47890c7db8f6097978fdede" category="paragraph">La soluzione B aggiunge il modulo di analisi in-place al cluster Hadoop di produzione, eliminando la necessità di eseguire il backup del cluster Hadoop, come illustrato nella figura seguente.</block>
  <block id="303388aba87d7dcff207a6cd098b0cfe" category="paragraph"><block ref="303388aba87d7dcff207a6cd098b0cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">Le attività dettagliate per la soluzione B includono:</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">Lo storage controller NetApp ONTAP fornisce l'esportazione NFS al cluster Hadoop di produzione.</block>
  <block id="3c321f811c173c1f133bdcc77fc81a33" category="paragraph">Nativo di Hadoop<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> Command protegge i dati Hadoop dal cluster di produzione HDFS a NFS attraverso il modulo di analisi in-place.</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">Una volta archiviati i dati in NFS sul sistema storage NetApp, le tecnologie Snapshot, SnapRestore e FlexClone vengono utilizzate per eseguire il backup, il ripristino e la duplicazione dei dati Hadoop in base alle necessità.</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">I vantaggi della soluzione B includono:</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">Il cluster di produzione viene leggermente modificato per la soluzione di backup, semplificando l'implementazione e riducendo i costi aggiuntivi dell'infrastruttura.</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">Non è necessario un cluster di backup per l'operazione di backup.</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">I dati di produzione HDFS sono protetti nella conversione in dati NFS.</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">La soluzione consente funzioni di gestione aziendale tramite gli strumenti NetApp.</block>
  <block id="02946730aaff0e3d8abfa986a2fe949d" category="paragraph">Lo svantaggio di questa soluzione è che è implementata nel cluster di produzione, che può aggiungere ulteriori attività di amministratore nel cluster di produzione.</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">Soluzione C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">Nella soluzione C, il provisioning dei volumi SAN NetApp viene eseguito direttamente nel cluster di produzione Hadoop per lo storage HDFS, come illustrato nella figura seguente.</block>
  <block id="dc460b3501caf17186202576855a6d3c" category="paragraph"><block ref="dc460b3501caf17186202576855a6d3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">I passaggi dettagliati per la soluzione C includono:</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">Lo storage SAN NetApp ONTAP viene fornito nel cluster di produzione Hadoop per lo storage dei dati HDFS.</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">Le tecnologie NetApp Snapshot e SnapMirror vengono utilizzate per eseguire il backup dei dati HDFS dal cluster Hadoop di produzione.</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">Durante il processo di backup della copia Snapshot non si verificano effetti sulle performance per il cluster Hadoop/Spark, poiché il backup si trova a livello di storage.</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">La tecnologia Snapshot offre backup completi in pochi secondi, indipendentemente dalle dimensioni dei dati.</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">I vantaggi della soluzione C includono:</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">È possibile creare backup efficienti in termini di spazio utilizzando la tecnologia Snapshot.</block>
  <block id="5788267ffe4023e91b333de591766cca" category="inline-link-macro">Successivo: Caso d'utilizzo 2 - Backup e disaster recovery dal cloud all'on-premise.</block>
  <block id="1619284091911820ebd1407554fb6da7" category="paragraph"><block ref="1619284091911820ebd1407554fb6da7" category="inline-link-macro-rx"></block></block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">Questa pagina illustra le sfide che un cliente potrebbe affrontare quando tenta di accedere ai dati dalle analisi dei big data per le operazioni di ai.</block>
  <block id="14fd125cf7cc7e6f58e0a07d30ecda87" category="paragraph"><block ref="14fd125cf7cc7e6f58e0a07d30ecda87" category="inline-link-macro-rx"></block></block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">I clienti potrebbero affrontare le seguenti sfide quando tentano di accedere ai dati dalle analisi dei big data per le operazioni di ai:</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">I dati dei clienti si trovano in un repository di data Lake. Il data Lake può contenere diversi tipi di dati, ad esempio dati strutturati, non strutturati, semistrutturati, log e dati machine-to-machine. Tutti questi tipi di dati devono essere elaborati nei sistemi ai.</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">Ai non è compatibile con i file system Hadoop. Un'architettura ai tipica non è in grado di accedere direttamente ai dati HDFS e HCFS, che devono essere spostati in un file system ai-understandable (NFS).</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">Il trasferimento dei dati del data Lake all'ai richiede in genere processi specializzati. La quantità di dati nel data Lake può essere molto grande. Un cliente deve disporre di un modo efficiente, ad alto throughput e conveniente per trasferire i dati nei sistemi ai.</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">Sincronizzazione dei dati. Se un cliente desidera sincronizzare i dati tra la piattaforma per big data e l'ai, a volte i dati elaborati tramite l'ai possono essere utilizzati con i big data per l'elaborazione analitica.</block>
  <block id="02c553e123c56e4cba5728b7e83bb80b" category="inline-link-macro">Avanti: Soluzione per il data mover.</block>
  <block id="205e8a4d3382497ff57947382c577faa" category="paragraph"><block ref="205e8a4d3382497ff57947382c577faa" category="inline-link-macro-rx"></block></block>
  <block id="bc0316be7ba1d2f8b53c282f09f9b532" category="summary">Un cluster Kafka con il layer di storage montato su NetApp NFS è stato sottoposto a benchmark per le performance nel cloud AWS. Gli esempi di benchmarking sono descritti nelle sezioni seguenti.</block>
  <block id="02b742a6a1f227191aecb81d8822d2ee" category="doc">Panoramica delle performance e validazione in AWS</block>
  <block id="514db64c2189adefee1fd55171e6c154" category="inline-link-macro">Precedente: Perché scegliere NetApp NFS per i workload Kafka?.</block>
  <block id="5ff5bf199d6f8c7420eaf142a44e1b84" category="paragraph"><block ref="5ff5bf199d6f8c7420eaf142a44e1b84" category="inline-link-macro-rx"></block></block>
  <block id="28e2dfa4242e2b504727dab8605d1432" category="section-title">Kafka nel cloud AWS con NetApp Cloud Volumes ONTAP (coppia ad alta disponibilità e nodo singolo)</block>
  <block id="1dc7a426b0cbf7d35c5edda73f68403d" category="paragraph">Un cluster Kafka con NetApp Cloud Volumes ONTAP (coppia ha) è stato sottoposto a benchmark per le performance nel cloud AWS. Questo benchmarking è descritto nelle sezioni seguenti.</block>
  <block id="a0d574b61a80df70bd921b269853cc18" category="cell">RHEL8.6</block>
  <block id="462fed98d4e5a4d1be4d08b1fdd3f0df" category="cell">Istanza coppia HA – m5dn.12xLarge x istanza nodo singolo 2node - m5dn.12xLarge x 1 nodo</block>
  <block id="29e8b4fdf26266c94b184b76858f935e" category="section-title">Configurazione di NetApp Cluster Volume ONTAP</block>
  <block id="febbbf2a22b781c8cb2d828a8cbf52d6" category="list-text">Per la coppia Cloud Volumes ONTAP ha, abbiamo creato due aggregati con tre volumi su ciascun aggregato su ciascun controller di storage. Per il singolo nodo Cloud Volumes ONTAP, creiamo sei volumi in un aggregato.</block>
  <block id="72bcc37cf8850d4e74a6305d71727956" category="inline-image-macro">Questa immagine mostra le proprietà di aggr3 e aggr22.</block>
  <block id="3fb62725866c106a90b2f81d00b4bfd8" category="paragraph"><block ref="3fb62725866c106a90b2f81d00b4bfd8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="518fcf406a83698c4ba5d2f41cafab41" category="inline-image-macro">Questa immagine mostra le proprietà di aggr2.</block>
  <block id="2ec040888274c50ed4f2140a40ff8b70" category="paragraph"><block ref="2ec040888274c50ed4f2140a40ff8b70" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a6501fcefae41cda9ecf425cdc1ef15" category="list-text">Per ottenere performance di rete migliori, abbiamo attivato il networking ad alta velocità sia per la coppia ha che per il singolo nodo.</block>
  <block id="a4de9e1c332b656e2e19024cce28f939" category="inline-image-macro">Queste immagini mostrano come abilitare il networking ad alta velocità.</block>
  <block id="ebfcaff376ca9e4653f751fb35b6ff05" category="paragraph"><block ref="ebfcaff376ca9e4653f751fb35b6ff05" category="inline-image-macro-rx" type="image"></block></block>
  <block id="678217b29dc6cbf917f08c79a1819f92" category="list-text">Abbiamo notato che la NVRAM ONTAP aveva più IOPS, quindi abbiamo modificato gli IOPS a 2350 per il volume root Cloud Volumes ONTAP. Il disco del volume root in Cloud Volumes ONTAP aveva una dimensione di 47 GB. Il seguente comando ONTAP è per la coppia ha e lo stesso passo è applicabile per il singolo nodo.</block>
  <block id="71ac6dbf3d671b6b9db5497aad37fc67" category="inline-image-macro">Queste immagini mostrano come modificare le proprietà del volume.</block>
  <block id="a278e7398c9bee17762c3a92d2e6f247" category="paragraph"><block ref="a278e7398c9bee17762c3a92d2e6f247" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a5f2ebf87b5aa37d2e02d041ede98e4f" category="list-text">*Compute.* abbiamo utilizzato un cluster Kafka a tre nodi con un ensemble di zookeeper a tre nodi in esecuzione su server dedicati. Ciascun broker disponeva di due punti di montaggio NFS su un singolo volume nell'istanza di Cloud Volumes ONTAP tramite un LIF dedicato.</block>
  <block id="dcb39d8372b01f5eb051372b3d943fbd" category="list-text">*Storage.* abbiamo utilizzato un'istanza di ha-Pair Cloud Volumes ONTAP con un volume AWS-EBS GP3 da 6 TB montato sull'istanza. Il volume è stato quindi esportato nel broker Kafka con un montaggio NFS.</block>
  <block id="e4d534a810d0b173e29dc8ae17ae8e30" category="paragraph"><block ref="e4d534a810d0b173e29dc8ae17ae8e30" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cce0ad6ab772599285bd32c539025c1f" category="section-title">Configurazioni di benchmarking di OpenMessage</block>
  <block id="6a1fe63829e046313e1b3073459bf538" category="list-text">Per migliorare le performance NFS, abbiamo bisogno di più connessioni di rete tra il server NFS e il client NFS, che possono essere create utilizzando nconnect. Montare i volumi NFS sui nodi di broker con l'opzione nconnect eseguendo il seguente comando:</block>
  <block id="a973eefced896f4a698ed64af6dc0199" category="list-text">Verificare le connessioni di rete in Cloud Volumes ONTAP. Il seguente comando ONTAP viene utilizzato dal singolo nodo Cloud Volumes ONTAP. Lo stesso passaggio si applica alla coppia Cloud Volumes ONTAP ha.</block>
  <block id="828ed34406e4dab30166070e0af1f142" category="list-text">Utilizziamo il seguente Kafka<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> In tutti i broker Kafka per la coppia Cloud Volumes ONTAP ha. Il<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> la proprietà è diversa per ogni broker e le proprietà rimanenti sono comuni per gli broker. Per il broker1, il<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> il valore è il seguente:</block>
  <block id="66ddebf2d4ab98ff8682a008dc466ce6" category="list-text">Per il broker2, il<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> il valore della proprietà è il seguente:</block>
  <block id="fcfc381980a9ed554f51cbfd5b77616a" category="list-text">Per il broker3, il<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> il valore della proprietà è il seguente:</block>
  <block id="00d57462d7009374713be86d6c491d89" category="list-text">Per il singolo nodo Cloud Volumes ONTAP, Kafka<block ref="21d5034d4d99d6ca0da314367f1cccd6" prefix=" " category="inline-code"></block> È uguale alla coppia Cloud Volumes ONTAP ha, ad eccezione di<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> proprietà.</block>
  <block id="cf168cce281f1eccdc9f9fb55c933d29" category="list-text">Per il broker1, il<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> il valore è il seguente:</block>
  <block id="1692ac5191f19e15cf0e3a8af0820752" category="list-text">Per il broker2, il<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> il valore è il seguente:</block>
  <block id="4b0728fa62359454465b3a26a608d83c" category="list-text">Il carico di lavoro nell'OMB viene configurato con le seguenti proprietà:<block ref="9a97642a426510e31f49e0a98ed35e46" prefix=" " category="inline-code"></block>.</block>
  <block id="433b44cf3e6084d97e5162a06d481873" category="paragraph">Il<block ref="f21d26061df60c086aedb156e38f66b5" prefix=" " category="inline-code"></block> può variare in base al caso di utilizzo. Nel nostro test delle performance, abbiamo utilizzato 3K.</block>
  <block id="bd9348653b0cfa7f0962b694fa058428" category="paragraph">Abbiamo utilizzato due diversi driver, Sync o throughput, da OMB per generare il carico di lavoro sul cluster Kafka.</block>
  <block id="50e5861dab89d00bf88787e044b2c24f" category="list-text">Il file yaml utilizzato per le proprietà del driver Sync è il seguente<block ref="46c2adf6b9dc6e5883c47b1d76feb008" prefix=" " category="inline-code"></block>:</block>
  <block id="9ae100f8fb1875133a485c355266af55" category="list-text">Il file yaml utilizzato per le proprietà del driver di throughput è il seguente<block ref="658e4b47fcd8812e9b0b2886af867717" prefix=" " category="inline-code"></block>:</block>
  <block id="a887b430cb278fa8f52827a223308324" category="list-text">È stato eseguito il provisioning di un cluster Kafka secondo le specifiche descritte in precedenza utilizzando Terraform e Ansible. Il terraform viene utilizzato per costruire l'infrastruttura utilizzando istanze AWS per il cluster Kafka e Ansible crea il cluster Kafka su di essi.</block>
  <block id="d9a3b4ca51b8378374ab25c3f90ec2a2" category="list-text">È stato attivato un carico di lavoro OMB con la configurazione del carico di lavoro descritta sopra e il driver Sync.</block>
  <block id="3f6a85702112dff5bcd0970b7ceb3f02" category="list-text">È stato attivato un altro carico di lavoro con il driver di throughput con la stessa configurazione del carico di lavoro.</block>
  <block id="5f2da6c069f19294c52f39a18639f0d2" category="paragraph">Sono stati utilizzati due diversi tipi di driver per generare carichi di lavoro per confrontare le performance di un'istanza di Kafka in esecuzione su NFS. La differenza tra i driver è la proprietà di scaricamento dei log.</block>
  <block id="59f70e2d523801f5ede7c9bb7b48cc76" category="paragraph">Per una coppia Cloud Volumes ONTAP ha:</block>
  <block id="ffb03fd768825b381d478b114716f8cf" category="list-text">Throughput totale generato in modo coerente dal driver Sync: ~1236 Mbps.</block>
  <block id="84c96e7c92d1f10aac5f3600c7df9299" category="list-text">Throughput totale generato per il driver di throughput: Picco ~1412 Mbps.</block>
  <block id="5896e2cd1e01fb8ef69cdf280a9a38e3" category="paragraph">Per un singolo nodo Cloud Volumes ONTAP:</block>
  <block id="d3c9dedf3eb9fce5e9a983948c3cef0e" category="list-text">Throughput totale generato in modo coerente dal driver Sync: ~ 1962 MBps.</block>
  <block id="86acf2bdaf8de60bbc77d3dc8f0e1b12" category="list-text">Throughput totale generato dal driver di throughput: Picco ~1660 MBps</block>
  <block id="4bb1ab47e2a029960970bd2e246f9a57" category="paragraph">Il driver Sync è in grado di generare un throughput coerente quando i log vengono trasferiti istantaneamente sul disco, mentre il driver di throughput genera burst di throughput quando i log vengono impegnati su disco in massa.</block>
  <block id="920a7d00fe9032493a9a70c1e6c8972a" category="paragraph">Questi numeri di throughput vengono generati per la configurazione AWS specificata. Per requisiti di performance più elevati, i tipi di istanze possono essere scalati e ottimizzati ulteriormente per ottenere numeri di throughput migliori. Il throughput totale o il tasso totale è la combinazione di un tasso di produttore e di consumo.</block>
  <block id="c5616509b949bfcdee10d7e87918ec9d" category="inline-image-macro">Qui sono presentati quattro grafici diversi. Driver di throughput coppia CVO-ha. Driver CVO-ha Pair Sync. Driver di throughput CVO a nodo singolo. Driver CVO-single node Sync.</block>
  <block id="0e33cf4077892dd25c1212a135870c2b" category="paragraph"><block ref="0e33cf4077892dd25c1212a135870c2b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c6ad6fcb6db991d86273d33ed35d3c9" category="paragraph">Verificare il throughput dello storage durante l'esecuzione del benchmarking del throughput o del driver di sincronizzazione.</block>
  <block id="22156e4cc2df3388f0f9dfe0c178db37" category="inline-image-macro">Questo grafico mostra le performance in termini di latenza, IOPS e throughput.</block>
  <block id="cd86eb722445699d358d0ded28ff649a" category="paragraph"><block ref="cd86eb722445699d358d0ded28ff649a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43553dc216049ebf89672dd26173e4b2" category="inline-link-macro">Pagina successiva: Panoramica delle performance e validazione con AFF on-premise.</block>
  <block id="310a0beeb0f22515730a4e70d0b545ec" category="paragraph"><block ref="310a0beeb0f22515730a4e70d0b545ec" category="inline-link-macro-rx"></block></block>
  <block id="881214767967db331c99550277ceb793" category="summary">Questa pagina descrive l'architettura di Splunk, incluse le definizioni chiave, le implementazioni distribuite di Splunk, Splunk SmartStore, il flusso di dati, requisiti hardware e software, requisiti singoli e multisito e così via.</block>
  <block id="1e6ade59f7284c0bca28eaeeeeed0a30" category="doc">Architettura Splunk</block>
  <block id="aa91789a439fe45bd8d608e61ca9da8c" category="inline-link-macro">Precedente: Funzionalità Flexible StorageGRID per Splunk SmartStore.</block>
  <block id="263af6ab01a543147e86a15ed7794682" category="paragraph"><block ref="263af6ab01a543147e86a15ed7794682" category="inline-link-macro-rx"></block></block>
  <block id="a8449bda57f23b9282f766113987bdf2" category="section-title">Definizioni delle chiavi</block>
  <block id="56eee8e9cc278d0a414a6d5697a4675f" category="paragraph">Le due tabelle successive elencano i componenti Splunk e NetApp utilizzati nell'implementazione di Distributed Splunk.</block>
  <block id="5078bea36734bcaa4a0c1e3a0e6e4606" category="paragraph">Questa tabella elenca i componenti hardware Splunk per la configurazione di Distributed Splunk Enterprise.</block>
  <block id="a5aa1df4c3c47c407c84c66303cf0ece" category="cell">Repository per i dati Splunk Enterprise</block>
  <block id="872c8a2437dfbfa5be0882eabc86bcd3" category="cell">Forwarder universale</block>
  <block id="5873147385b9bd833ffd9a046374c97b" category="cell">Il front-end utente utilizzato per cercare i dati negli indicizzatori</block>
  <block id="e4ae9d4eb2313305a17cde160f405a17" category="cell">Gestisce l'installazione Splunk di indicizzatori e teste di ricerca</block>
  <block id="805ac84d9852820feaf2e2b643a07efb" category="cell">Console di monitoraggio</block>
  <block id="5cf5006c1d7fdc954614a4e4185a2c62" category="cell">Strumento di monitoraggio centralizzato utilizzato per l'intera implementazione</block>
  <block id="fdccec582408614d1e2f7428910b1c8f" category="cell">Master di licenza</block>
  <block id="7c3b9b8892864eb6fa5cb2a32b85cc93" category="cell">License master gestisce le licenze Splunk Enterprise</block>
  <block id="06262b5ad14fe5851defa5b0b70c86c6" category="cell">Server di implementazione</block>
  <block id="ebe1fa5d8a359a6db13876ab1142fa50" category="cell">Aggiorna le configurazioni e distribuisce le applicazioni al componente di elaborazione</block>
  <block id="4fabea287d13a082b71f046f9d8be91d" category="cell">Componente di storage</block>
  <block id="b1edd0b37872fd00feb3bb2738987b41" category="cell">Storage all-flash utilizzato per gestire i dati hot Tier. Noto anche come storage locale.</block>
  <block id="518d90155e7eb8bf96c6b7852ba519a6" category="cell">Storage a oggetti S3 utilizzato per gestire i dati del warm Tier. Utilizzato da SmartStore per spostare i dati tra il livello hot e quello warm. Noto anche come storage remoto.</block>
  <block id="310a27e25811a8eca9b6e5edd921a267" category="paragraph">Questa tabella elenca i componenti dell'architettura di storage Splunk.</block>
  <block id="40f14800d20c9cecbec85dbb2cf35592" category="cell">Componente responsabile</block>
  <block id="a5847d984bf6ac525e00b95b93be4e94" category="cell">SmartStore</block>
  <block id="6b64d740ca8627e515d54827d95bc7cb" category="cell">Offre agli indexer la possibilità di eseguire il tiering dei dati dallo storage locale allo storage a oggetti.</block>
  <block id="2f9304fe9b427489507405bef9a0bb9f" category="cell">Splunk</block>
  <block id="4194726ee334e1085d93e002837b73f0" category="cell">Caldo</block>
  <block id="cc42c7d2fb33f9ccc06f2e23486a9b0e" category="cell">Il punto di destinazione in cui i forwarder universali posizionano i dati appena scritti. Lo storage è scrivibile e i dati sono ricercabili. Questo livello di dati è generalmente composto da SSD o HDD veloci.</block>
  <block id="f156996831cd546988bf05451ede7b02" category="cell">Gestore cache</block>
  <block id="52520fc1f4cef574661d086d8efcb1f8" category="cell">Gestisce la cache locale dei dati indicizzati, recupera i dati a caldo dallo storage remoto quando si verifica una ricerca ed esalta i dati meno utilizzati dalla cache.</block>
  <block id="18297117d3d251afceed9ecbe797c849" category="cell">Caldo</block>
  <block id="810be2ef6ffed5e543f948bf5984d544" category="cell">I dati vengono rotolati logicamente nel bucket, rinominato nel Tier caldo per primo dal Tier caldo. I dati all'interno di questo Tier sono protetti e, come il Tier hot, possono essere composti da SSD o HDD di capacità superiore. I backup incrementali e completi sono supportati utilizzando soluzioni di protezione dei dati comuni.</block>
  <block id="392d70ca39f31f10bd637936769788df" category="cell">StorageGRID</block>
  <block id="7cf9c58117f9052c5d5a43b3add7f6a4" category="section-title">Implementazioni distribuite Splunk</block>
  <block id="11c2b5859cb0c1d37b40f8df716542e2" category="paragraph">Per supportare ambienti di grandi dimensioni in cui i dati provengono da molte macchine, è necessario elaborare grandi volumi di dati. Se molti utenti devono cercare i dati, è possibile scalare l'implementazione distribuendo le istanze di Splunk Enterprise su più computer. Si tratta di un'implementazione distribuita.</block>
  <block id="113f0bd975880424e2c87874233b2afb" category="paragraph">In una distribuzione distribuita tipica, ogni istanza di Splunk Enterprise esegue un'attività specializzata e risiede su uno dei tre livelli di elaborazione corrispondenti alle principali funzioni di elaborazione.</block>
  <block id="ac31b29e5bbd68654aeb200e66227fb8" category="paragraph">La tabella seguente elenca i Tier di elaborazione di Splunk Enterprise.</block>
  <block id="9483f17a69bd0b52dbc44f9106718634" category="cell">Tier</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">Componente</block>
  <block id="7d38267cdf833b2983d3487954ebf88e" category="cell">Immissione dei dati</block>
  <block id="2d361d5fe6d74b7550e0aa35d94342ec" category="cell">Spedizioniere</block>
  <block id="b2eebf5023a2a2ba3b35711069723656" category="cell">Uno spedizioniere consuma i dati e li inoltra a un gruppo di indicizzatori.</block>
  <block id="521d4edc7c22d5f63bc5912ff2afa61a" category="cell">Indicizzazione</block>
  <block id="65265b43bef75c5bacc53c21e38eb8fc" category="cell">Un indicizzatore indicizza i dati in entrata che di solito riceve da un gruppo di forwarder. L'indicizzatore trasforma i dati in eventi e li memorizza in un indice. L'indicizzatore ricerca anche i dati indicizzati in risposta alle richieste di ricerca da un capo di ricerca.</block>
  <block id="ff5b0dc94726e93d5db5cf7922183f2b" category="cell">Gestione della ricerca</block>
  <block id="d4c174b1ebc77694020097497547d218" category="cell">Una testa di ricerca funge da risorsa centrale per la ricerca. Le teste di ricerca in un cluster sono intercambiabili e hanno accesso alle stesse ricerche, dashboard, oggetti conoscenza e così via da qualsiasi membro del cluster di teste di ricerca.</block>
  <block id="86f51d8f8fa8928e0f6ddba31139676e" category="paragraph">La tabella seguente elenca i componenti importanti utilizzati in un ambiente Splunk Enterprise distribuito.</block>
  <block id="dee8af298acfc4c4bcb9fda657125917" category="cell">Responsabilità</block>
  <block id="3b656ff8459bec2d80d19d367bd71d19" category="cell">Master del cluster di indice</block>
  <block id="407a3e34682f31b649e8cbd865fdf50c" category="cell">Coordina le attività e gli aggiornamenti di un cluster di indicizzatori</block>
  <block id="dad2f7ca532f008e8192d418406da758" category="cell">Gestione degli indici</block>
  <block id="85ba71585b2b8c323c8eb899fa033227" category="cell">Cluster di indice</block>
  <block id="f13c7b75bef35de7c42cc0569f76e366" category="cell">Gruppo di indicizzatori Splunk Enterprise configurati per replicare i dati l'uno con l'altro</block>
  <block id="9f45bd6fe25c3f5597af0f46bfdb20db" category="cell">Gestisce l'implementazione e gli aggiornamenti del cluster master</block>
  <block id="bc2eef462c1a0c8b778b607c304ba877" category="cell">Gestione della testa di ricerca</block>
  <block id="58f4a17edb05ffec840bf2b176bf6eca" category="cell">Cluster testa di ricerca</block>
  <block id="70f36c7a653c3724df8921edce177b22" category="cell">Gruppo di teste di ricerca che funge da risorsa centrale per la ricerca</block>
  <block id="2ddcaa7e88a6ad9c095422ca4e601d85" category="cell">Bilanciamento del carico</block>
  <block id="fe613dab61d63209235cf49513b00d8a" category="cell">Utilizzato dai componenti in cluster per gestire la domanda crescente da parte di teste di ricerca, indicizzatori e destinazioni S3 per distribuire il carico tra i componenti in cluster.</block>
  <block id="184f98cf6a6dd19d0815179e63be4298" category="cell">Gestione del carico per i componenti in cluster</block>
  <block id="e32d50596edede1bfe3978d8b7b5c5ac" category="paragraph">Scopri i seguenti vantaggi delle implementazioni distribuite di Splunk Enterprise:</block>
  <block id="9431943c093a5cc181eccd505ca50f4c" category="list-text">Accesso a fonti di dati diverse o distribuite</block>
  <block id="e825b2fa62f5af51541982cc503c8825" category="list-text">Fornire funzionalità per gestire le esigenze di dati per aziende di qualsiasi dimensione e complessità</block>
  <block id="c63fa16ec4ed3d9b3803c2d1e1548fe6" category="list-text">Ottieni un'elevata disponibilità e garantisci il disaster recovery con la replica dei dati e l'implementazione multisito</block>
  <block id="e2475a05ae25f0e8f31932cc309db3f1" category="paragraph">SmartStore è una funzionalità di indicizzazione che consente agli archivi di oggetti remoti come Amazon S3 di memorizzare i dati indicizzati. Con l'aumentare del volume di dati di un'implementazione, la domanda di storage supera in genere la domanda di risorse di calcolo. SmartStore consente di gestire le risorse di calcolo e storage dell'indicizzatore in modo conveniente, scalando separatamente tali risorse.</block>
  <block id="4b253fe4960ecb87fdd7a6c05a125003" category="paragraph">SmartStore introduce un Tier di storage remoto e un gestore della cache. Queste funzionalità consentono ai dati di risiedere localmente sugli indicizzatori o sul Tier di storage remoto. Il gestore della cache gestisce lo spostamento dei dati tra l'indicizzatore e il Tier di storage remoto, configurato sull'indicizzatore.</block>
  <block id="98941a2e255442c92447b445a4a6bc6e" category="paragraph">Con SmartStore, puoi ridurre al minimo l'impatto dello storage dell'indicizzatore e scegliere risorse di calcolo ottimizzate per i/O. La maggior parte dei dati risiede nello storage remoto. L'indicizzatore mantiene una cache locale che contiene una quantità minima di dati: Hot bucket, copie di warm bucket che partecipano a ricerche attive o recenti e metadati bucket.</block>
  <block id="2d153b33a50f3343c2aeb68789ee8e26" category="section-title">Flusso di dati Splunk SmartStore</block>
  <block id="3306b50d7dd22a0698c2245e7cd06bee" category="paragraph">Quando i dati in entrata da varie origini raggiungono gli indicizzatori, i dati vengono indicizzati e salvati localmente in un bucket hot. L'indicizzatore replica anche i dati del bucket hot su indicizzatori di destinazione. Finora, il flusso di dati è identico al flusso di dati per gli indici non SmartStore.</block>
  <block id="ad1e15c21ba7587e1631977abe48ab09" category="paragraph">Quando il bucket caldo si riscalda, il flusso di dati diverge. L'indicizzatore di origine copia il bucket warm nell'archivio remoto di oggetti (Tier storage remoto) lasciando la copia esistente nella cache, perché le ricerche tendono a essere eseguite su dati indicizzati di recente. Tuttavia, gli indicizzatori di destinazione eliminano le copie perché l'archivio remoto offre un'elevata disponibilità senza mantenere più copie locali. La copia master del bucket ora risiede nell'archivio remoto.</block>
  <block id="3d39641a906c56e9e12b0f019f23bc1d" category="paragraph">La seguente immagine mostra il flusso di dati di Splunk SmartStore.</block>
  <block id="9fb3b10aa394792f93ac799606bd8ed5" category="paragraph"><block ref="9fb3b10aa394792f93ac799606bd8ed5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fa16046e839496393e84b6a20e9604e" category="paragraph">Il gestore della cache sull'indicizzatore è centrale per il flusso di dati SmartStore. Recupera le copie dei bucket dall'archivio remoto in base alle necessità per gestire le richieste di ricerca. Inoltre, la cache consente di evitare copie di bucket più vecchie o meno ricercate, in quanto la probabilità di partecipare alle ricerche diminuisce nel tempo.</block>
  <block id="715f39bb7952ceb84a6bd1bb44c1ac4d" category="paragraph">Il compito del gestore della cache è quello di ottimizzare l'utilizzo della cache disponibile, garantendo al contempo che le ricerche abbiano accesso immediato ai bucket di cui hanno bisogno.</block>
  <block id="4b2ba4c21a026c9139cf1484818f31c0" category="paragraph">La tabella seguente elenca i componenti software necessari per implementare la soluzione. I componenti software utilizzati in qualsiasi implementazione della soluzione possono variare in base ai requisiti del cliente.</block>
  <block id="aa76f43f5e0552119cc8d5313c67296e" category="cell">Famiglia di prodotti</block>
  <block id="df644ae155e79abf54175bd15d75f363" category="cell">Nome del prodotto</block>
  <block id="892b5a336dfe285f2d5c04ccd3d6c465" category="cell">Versione del prodotto</block>
  <block id="1b3e6de2b0fe97c3177ea5a4ad142554" category="cell">Storage a oggetti StorageGRID</block>
  <block id="36552b079970ffb2dd1314115af76c4b" category="cell">11.6</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">n/a.</block>
  <block id="66985170e641a7e20698bfec3c1d889f" category="cell">CentOS 7.x</block>
  <block id="9d8d169ace12276d008f0d0b88b61261" category="cell">Splunk Enterprise con SmartStore</block>
  <block id="75809dde56e3fe2c2fb740f1b55807ac" category="cell">8.0.3</block>
  <block id="3192356dc19e9b4ec43ba340bad657ee" category="section-title">Requisiti di un singolo sito e di più siti</block>
  <block id="98b8bd4f9670277f1f0e59a574019582" category="paragraph">In un ambiente Enterprise Splunk (implementazioni medie e grandi) in cui i dati provengono da molte macchine e in cui molti utenti devono cercare i dati, è possibile scalare l'implementazione distribuendo le istanze di Splunk Enterprise su siti singoli e multipli.</block>
  <block id="22e1b76cf9acbfd35603b013eefcb079" category="paragraph">La tabella seguente elenca i componenti utilizzati in un ambiente Splunk Enterprise distribuito.</block>
  <block id="1fbd0b2f11fe7779db6380b6d09478df" category="cell">Gruppo di indicizzatori Splunk Enterprise configurati per la replica reciproca dei dati</block>
  <block id="4e21e57c1860bf98fe3d0af8068f827d" category="cell">Bilanciatori di carico</block>
  <block id="03d7fbb295d0abb68bf4d3ce22d6d448" category="cell">Gestione del carico per i componenti in cluster</block>
  <block id="a0ebc1066e0250b1b42f1a66ae974836" category="paragraph">Questa figura mostra un esempio di implementazione distribuita a sito singolo.</block>
  <block id="733ecc3327823660187d1d7d76df7079" category="paragraph"><block ref="733ecc3327823660187d1d7d76df7079" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf99a89b389bc74dc1a403695b28d6cd" category="paragraph">Questa figura mostra un esempio di implementazione distribuita su più siti.</block>
  <block id="d10d5e57a05119c14c599013d15d6553" category="paragraph"><block ref="d10d5e57a05119c14c599013d15d6553" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80d955d16c5178cc40e347dfe675a443" category="paragraph">Le seguenti tabelle elencano il numero minimo di componenti hardware necessari per implementare la soluzione. I componenti hardware utilizzati in implementazioni specifiche della soluzione possono variare in base ai requisiti del cliente.</block>
  <block id="40b955882ffd3093985177c3721cfed2" category="admonition">Indipendentemente dal fatto che siano stati implementati Splunk SmartStore e StorageGRID in un singolo sito o in più siti, tutti i sistemi vengono gestiti da StorageGRID GRID Manager in un unico pannello di controllo. Per ulteriori informazioni, consulta la sezione "Gestione semplice con Grid Manager".</block>
  <block id="1605af3a62fa950fe8374a69086fdc94" category="paragraph">Questa tabella elenca l'hardware utilizzato per un singolo sito.</block>
  <block id="380dbc8d9d2c8a17f6ebb0b2c62d3e85" category="cell">Disco</block>
  <block id="b3e1f4c67ee07a73dcdaff1cf34f2640" category="cell">Capacità utilizzabile</block>
  <block id="3b0649c72650c313a357338dcdfb64ec" category="cell">Nota</block>
  <block id="1c594a38f9aafa3a439c25bc55815b40" category="cell">StorageGRID SG1000</block>
  <block id="b179d20c2d3e6e91708b69931e8fcf32" category="cell">Nodo Admin e bilanciamento del carico</block>
  <block id="48f09b085e666c51e35dbe89367de826" category="cell">StorageGRID SG6060</block>
  <block id="ab570142c34522356bdf33666f6532a3" category="cell">X48, 8 TB (HDD NL-SAS)</block>
  <block id="1792805a48a4da5ef5a78aa014da1f84" category="cell">1 PB</block>
  <block id="ecefe4d01bf4079d1e2833e9a7de2db7" category="cell">Storage remoto</block>
  <block id="9327a762e04913fc832ee2b182848716" category="paragraph">Questa tabella elenca l'hardware utilizzato per una configurazione multisito (per sito).</block>
  <block id="41cac74c281e47bb6feb1ef8db664ce4" category="cell">Nodo Admin e bilanciamento del carico</block>
  <block id="aadc7d80b20e9c743c2920297937f9fd" category="section-title">Bilanciamento del carico NetApp StorageGRID: SG1000</block>
  <block id="b3f51763a6ba0ae7fe6d83095cb24299" category="paragraph">Lo storage a oggetti richiede l'utilizzo di un bilanciamento del carico per presentare lo spazio dei nomi dello storage cloud. StorageGRID supporta i bilanciatori di carico di terze parti di vendor leader come F5 e Citrix, ma molti clienti scelgono il bilanciatore StorageGRID di livello Enterprise per semplicità, resilienza e performance elevate. Il bilanciamento del carico StorageGRID è disponibile come macchina virtuale, container o appliance appositamente costruite.</block>
  <block id="01f9bf7333b91ead20b7d1ac12ba4bca" category="paragraph">StorageGRID SG1000 semplifica l'utilizzo di gruppi ad alta disponibilità (ha) e il bilanciamento intelligente del carico per le connessioni del percorso dati S3. Nessun altro sistema di storage a oggetti on-premise fornisce un bilanciamento del carico personalizzato.</block>
  <block id="2f1a2bc20d9d0cddf636827860bdeb21" category="paragraph">L'appliance SG1000 offre le seguenti funzionalità:</block>
  <block id="fee5222c1281869dd7c4e3e4b7225065" category="list-text">Un bilanciamento del carico e, facoltativamente, un nodo di amministrazione funzionano per un sistema StorageGRID</block>
  <block id="7ea5a035cfe0609861da7628e7dedc64" category="list-text">Il programma di installazione dell'appliance StorageGRID per semplificare l'implementazione e la configurazione dei nodi</block>
  <block id="224d05cfece712836874ae47446c6d1b" category="list-text">Configurazione semplificata di endpoint S3 e SSL</block>
  <block id="59bf11863992b10be7d53c81c21a0220" category="list-text">Larghezza di banda dedicata (rispetto alla condivisione di un bilanciamento del carico di terze parti con altre applicazioni)</block>
  <block id="1436fddc15afc971733cc42610be3718" category="list-text">Fino a 4 x 100 Gbps di larghezza di banda Ethernet aggregata</block>
  <block id="4ff66456ad21f2aa88ad918b2a19287d" category="paragraph">L'immagine seguente mostra l'appliance SG1000 Gateway Services.</block>
  <block id="3e44556364ce6907a44a9fb5c09eab69" category="paragraph"><block ref="3e44556364ce6907a44a9fb5c09eab69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c69ff1785c16ab7db216e04b62e5ef4f" category="section-title">SG6060</block>
  <block id="40b11d9d6e72b8f3d6f6cd150ea6d5b3" category="paragraph">L'appliance StorageGRID SG6060 include un controller di calcolo (SG6060) e uno shelf di storage controller (e-Series E2860) che contiene due storage controller e 60 dischi. Questo apparecchio offre le seguenti funzioni:</block>
  <block id="5d61368716b8937ccfa3ae30bdeb3add" category="list-text">Scalabilità fino a 400 PB in un singolo namespace.</block>
  <block id="b08da7d555d413c82fa9476b78a3d1b4" category="list-text">Larghezza di banda Ethernet aggregata fino a 4 volte 25 Gbps.</block>
  <block id="3b384482ee0276a75964f52aab736cac" category="list-text">Include il programma di installazione dell'appliance StorageGRID per semplificare l'implementazione e la configurazione dei nodi.</block>
  <block id="3d6b68fb6989ac04a76612b7d50b5046" category="list-text">Ogni appliance SG6060 può disporre di uno o due shelf di espansione aggiuntivi per un totale di 180 dischi.</block>
  <block id="470503fbecc72cbe91b61c6e9b999cbe" category="list-text">Due controller e-Series E2800 (configurazione duplex) per il supporto del failover del controller di storage.</block>
  <block id="920a659800fa3289516e73f0b8d0cd70" category="list-text">Shelf di dischi a cinque cassetti che contiene sessanta dischi da 3.5 pollici (due dischi a stato solido e 58 dischi NL-SAS).</block>
  <block id="d60b006794c926c67e95ce7f49fffbed" category="paragraph">L'immagine seguente mostra l'appliance SG6060.</block>
  <block id="8d3bb0a39a1d477f7f0b8789769c96c5" category="paragraph"><block ref="8d3bb0a39a1d477f7f0b8789769c96c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad24897680a673883f3a8e9467ea3271" category="section-title">Design Splunk</block>
  <block id="c2d7b4acc3efe890969906f2a0be4bea" category="paragraph">La seguente tabella elenca la configurazione Splunk per un singolo sito.</block>
  <block id="5132d0e71971db5ca9827d470220eae9" category="cell">16 core</block>
  <block id="3988099dd7392a8b60a290ca560ac95d" category="cell">CentOS 8.1</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10</block>
  <block id="86e7f660faa5812369ca3195a6ab944a" category="cell">Il front-end dell'utente cerca i dati negli indicizzatori</block>
  <block id="9bc779a08fe3e6d54c4355c4ee8c4a95" category="paragraph">Le seguenti tabelle descrivono la configurazione di Splunk per le configurazioni multisito.</block>
  <block id="9605b47d211de50422182b81685da619" category="paragraph">Questa tabella elenca la configurazione Splunk per una configurazione multisito (sito A).</block>
  <block id="d9de1b6846e3235226dba66773043a15" category="cell">Responsabile dell'acquisizione dei dati e dell'inoltro dei dati agli indicizzatori.</block>
  <block id="76132c1712ff61ff02378720304f6529" category="cell">Esegue il monitoraggio centralizzato dell'intera implementazione di Splunk e gestisce le licenze di Splunk.</block>
  <block id="2d3db4a7f27e8f892b40be60e8c003b4" category="paragraph">Questa tabella elenca la configurazione Splunk per una configurazione multisito (sito B).</block>
  <block id="b9006101b0f69e04590f5276d5cab52a" category="inline-link-macro">Avanti: Performance di SmartStore a sito singolo.</block>
  <block id="f7c6952971373a408f0b926fb7202e6f" category="paragraph"><block ref="f7c6952971373a408f0b926fb7202e6f" category="inline-link-macro-rx"></block></block>
  <block id="49c9a66d1f76b5f264fea5d54130b82a" category="summary">Abbiamo utilizzato gli script TeraSort e TeraValidate nello strumento di benchmarking TeraGen per misurare la convalida delle performance Spark con le configurazioni E5760, E5724 e AFF-A800. Inoltre, sono stati testati tre casi di utilizzo principali: Pipeline NLP Spark e training distribuito TensorFlow, training distribuito Horovod e deep learning multi-worker con keras per la previsione CTR con DeepFM.</block>
  <block id="41be8de44faa8ba43210d7494ee095d2" category="doc">Risultati del test</block>
  <block id="0daa7dd4f2822f3e63bdac1bd5870a75" category="inline-link-macro">Precedente: Principali casi di utilizzo e architetture ai, ML e DL.</block>
  <block id="26d27784aaeb94a4670d31f46185d57d" category="paragraph"><block ref="26d27784aaeb94a4670d31f46185d57d" category="inline-link-macro-rx"></block></block>
  <block id="60637296d8b6dcd84aaff3afc778241d" category="paragraph">Abbiamo utilizzato gli script TeraSort e TeraValidate nello strumento di benchmarking TeraGen per misurare la convalida delle performance Spark con le configurazioni E5760, E5724 e AFF-A800. Inoltre, sono stati testati tre casi di utilizzo principali: Pipeline SPARK NLP e training distribuito TensorFlow, training distribuito Horovod e deep learning multi-worker con keras per la previsione CTR con DeepFM.</block>
  <block id="653a9ba51c0af0c11aab6af3ecfdc8c6" category="paragraph">Per la convalida di e-Series e StorageGRID, abbiamo utilizzato il fattore di replica Hadoop 2. Per la convalida AFF, abbiamo utilizzato una sola fonte di dati.</block>
  <block id="6cdf0c4c6177a49f44f3688dd2a5b9ad" category="paragraph">La seguente tabella elenca la configurazione hardware per la convalida delle prestazioni di Spark.</block>
  <block id="00e536f9715964bf964b4961d7287f95" category="cell">Nodi di lavoro Hadoop</block>
  <block id="ce1dc110e77caccbe12e51dce2d1c9b7" category="cell">Tipo di disco</block>
  <block id="c8fafade5cff4119459018fc205beed1" category="cell">Dischi per nodo</block>
  <block id="bb43878952414106e66a5d3e8902dd46" category="cell">Controller dello storage</block>
  <block id="2db46c628cfb3bd1545d3b5a14b4a9c5" category="cell">SAS</block>
  <block id="d748fcab9e84c60a5a7b1e5ed2d052c8" category="cell">Singola coppia ad alta disponibilità (ha)</block>
  <block id="fb5e436e0878dfd2227011932c4eb93c" category="cell">E5760</block>
  <block id="072b030ba126b2f4b2374f342be9ed44" category="cell">60</block>
  <block id="6303aa59a000812ac121a6f5238d6c2c" category="cell">Coppia ha singola</block>
  <block id="83ac07c2ad3d90f5c6608cfaa2eec573" category="cell">E5724</block>
  <block id="1ff1de774005f8da13f42943881c655f" category="cell">24</block>
  <block id="26b9fff68b23131979be5c2d9a456454" category="cell">AFF800</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">SSD</block>
  <block id="bddda15d92b567df6d8aa197c281ddc4" category="paragraph">La seguente tabella elenca i requisiti software.</block>
  <block id="8b6f93f33bce541c7f50f8aff637e2e1" category="cell">RHEL</block>
  <block id="299e5505ce975112afaefec130cc83e0" category="cell">7.9</block>
  <block id="bedb19167c4cde670f36a4985efbadd2" category="cell">Ambiente di runtime OpenJDK</block>
  <block id="4fda350b2148254bcd9e67bbdbecdc93" category="cell">1.8.0</block>
  <block id="b185818332a596af6cda9cae4dc594f6" category="cell">Server VM OpenJDK a 64 bit</block>
  <block id="681eea6b2a996d12035edc50dc4cb4c2" category="cell">25.302</block>
  <block id="30a2ec41610037af662087fe85d19a4d" category="cell">2.24.1</block>
  <block id="87f16b82c65c9274a67305d08b5dfecb" category="cell">GCC/G++</block>
  <block id="b87ed8b82b1cf2cb4e4ddaa75ec9e0e4" category="cell">11.2.1</block>
  <block id="8cde774d6f7333752ed72cacddb05126" category="cell">Scintilla</block>
  <block id="f2f87b58be0d57ecf71ada8df361a2d9" category="cell">3.2.1</block>
  <block id="17e918efeeeb8f100c695e284d5c0a08" category="cell">PySpark</block>
  <block id="1f4e00506ff9fb5fe179f2ba1c60ff61" category="cell">3.1.2</block>
  <block id="401534b4a193f467279a370076ccb955" category="cell">SparkNLP</block>
  <block id="de8a4e99bb5f22ded6d686cfd948274b" category="cell">3.4.2</block>
  <block id="074dd699710da0ec1eb45f13b31788e3" category="cell">TensorFlow</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="7fee7bb66f4294c3e32783efa7d9bafc" category="cell">Ere</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">Horovod</block>
  <block id="35a0c5fdc22109515a67a96e5e7fb914" category="cell">0.24.3</block>
  <block id="14bdb1335d2386afb42f726416a2a83b" category="section-title">Analisi del sentimento finanziario</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="inline-link">TR-4910: Analisi del sentimento da Customer Communications con NetApp ai</block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="inline-link">NetApp DataOps Toolkit</block>
  <block id="559cf37b505e9001d46e6d6bd73e746c" category="inline-link">SDK NVIDIA Riva</block>
  <block id="e65b49198d65919095402991b0cf5624" category="inline-link">Framework di Tao</block>
  <block id="3f57666cb1b915db482629c0554b2d92" category="paragraph">Abbiamo pubblicato<block ref="36713788fc49ad5281ee4a8956df0b3b" category="inline-link-rx"></block>, In cui è stata costruita una pipeline di ai conversazionale end-to-end utilizzando<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>, Storage AFF e sistema NVIDIA DGX. La pipeline esegue l'elaborazione del segnale audio batch, il riconoscimento vocale automatico (ASR), l'apprendimento del trasferimento e l'analisi del sentimento utilizzando il DataOps Toolkit,<block ref="8702bd0254f484bdfe9f1ec1c2a853b1" category="inline-link-rx"></block>e il<block ref="bba656873bd8ccd45c0c4fc908390474" category="inline-link-rx"></block>. Espandendo il caso d'uso dell'analisi del sentimento nel settore dei servizi finanziari, abbiamo creato un workflow SparkNLP, caricato tre modelli BERT per varie attività NLP, come il riconoscimento delle entità nominate, e ottenuto un sentimento a livello di frase per le chiamate trimestrali sui guadagni delle prime 10 aziende NASDAQ.</block>
  <block id="ffeb7ccd27ad1e7d783757733dadec57" category="paragraph">Il seguente script<block ref="e313c2865ad76497c3eaf980ccfa3d03" prefix=" " category="inline-code"></block> Utilizza il modello FinBERT per elaborare le trascrizioni in HDFS e produrre conteggi di sentimenti positivi, neutri e negativi, come mostrato nella seguente tabella:</block>
  <block id="077259b584adffb379f7f2638be91edc" category="paragraph">La seguente tabella elenca l'analisi del sentimento a livello di frase e di chiamata degli utili per le prime 10 aziende NASDAQ dal 2016 al 2020.</block>
  <block id="30702e828192097c5634358e6047d0cf" category="cell">I conteggi dei sentimenti e la percentuale</block>
  <block id="7838fb6ed7918fca8c7797b3b68952d2" category="cell">Tutte le 10 aziende</block>
  <block id="8b10e4ae9eeb5684921a9ab27e4d87aa" category="cell">AAAPL</block>
  <block id="48af4341f745163f945fa838eeabb062" category="cell">AMD</block>
  <block id="261fd26b0151a81370d097e4ed4c6505" category="cell">N. AMZN</block>
  <block id="85fd1bb0e226da6a33e9b5dc1a4952f1" category="cell">CSCO</block>
  <block id="e15ce71ff533c9125f11a46c09e2412b" category="cell">GOOGL</block>
  <block id="fc39dab34bbe435680d30933db783ba0" category="cell">INTC</block>
  <block id="b004b3ecde24c85e32c1923f10d3fb62" category="cell">MSFT</block>
  <block id="7f5f6a07b14840f4d8a22caa3df2aed0" category="cell">NVDA</block>
  <block id="4f65a47dc5d0d8a27379f2b1b4d9281b" category="cell">Conteggi positivi</block>
  <block id="9e6adb1432c4a75a33d48693328e4159" category="cell">7447</block>
  <block id="18d10dc6e666eab6de9215ae5b3d54df" category="cell">1567</block>
  <block id="5c572eca050594c7bc3c36e7e8ab9550" category="cell">743</block>
  <block id="f90f2aca5c640289d0a29417bcb63a37" category="cell">290</block>
  <block id="08d98638c6fcd194a4b1e6992063e944" category="cell">682</block>
  <block id="795c7a7a5ec6b460ec00c5841019b9e9" category="cell">826</block>
  <block id="677e09724f0e2df9b6c000b75b5da10d" category="cell">824</block>
  <block id="f47d0ad31c4c49061b9e505593e3db98" category="cell">904</block>
  <block id="41ae36ecb9b3eee609d05b90c14222fb" category="cell">417</block>
  <block id="be201b8b1b0b81005e46d49fd301124c" category="cell">Conteggi neutrali</block>
  <block id="1ab0418ab8dc5325176cd1e26660234f" category="cell">64067</block>
  <block id="34ad9bc83e3c72c62281cb2c744ac966" category="cell">6856</block>
  <block id="1796a48fa1968edd5c5d10d42c7b1813" category="cell">7596</block>
  <block id="71e63ef5b7249cfc60852f0e0f5bf4c8" category="cell">5086</block>
  <block id="126c2da128e5b044dc53405c25b4d8de" category="cell">6650</block>
  <block id="dd5bfdeb57f7c75d400de61e99d78e2e" category="cell">5914</block>
  <block id="80c0e8c4457441901351e4abbcf8c75c" category="cell">6099</block>
  <block id="6e4243f5511fd6ef0f03e9f386d54403" category="cell">5715</block>
  <block id="67ba02d73c54f0b83c05507b7fb7267f" category="cell">6189</block>
  <block id="e65849536f4b2170d6b42c8309222fac" category="cell">Conteggi negativi</block>
  <block id="d860bd12ce9c026814bbdfc1c573f0f5" category="cell">1787</block>
  <block id="c24cd76e1ce41366a4bbe8a49b02a028" category="cell">253</block>
  <block id="979d472a84804b9f647bc185a877a8b5" category="cell">213</block>
  <block id="68d30a9594728bc39aa24be94b319d21" category="cell">84</block>
  <block id="a2557a7b2e94197ff767970b67041697" category="cell">189</block>
  <block id="e2ef524fbf3d9fe611d5a8e90fefdc9c" category="cell">97</block>
  <block id="6a9aeddfc689c1d0e3b9ccc3ab651bc5" category="cell">282</block>
  <block id="7647966b7343c29048673252e490f736" category="cell">89</block>
  <block id="691ec36991472d115c60f32cd84bfc5b" category="cell">Conteggi senza categoria</block>
  <block id="084b6fbb10729ed4da8c3d3f5a3ae7c9" category="cell">196</block>
  <block id="fbd7939d674997cdb4692d34de8633c4" category="cell">76</block>
  <block id="2706e1e04688749582425d394866306e" category="cell">(conteggi totali)</block>
  <block id="b72e37e992d9e460ce2a491a974d13b5" category="cell">73497</block>
  <block id="9f6f2381bc56ef668e94f6d1fb4f6309" category="cell">8676</block>
  <block id="a563b6d5abbf137175059d6bb14672cc" category="cell">8552</block>
  <block id="1134ac57b5b1d38b7d70c1b6feaa28cf" category="cell">5536</block>
  <block id="e1e1f667ce4596e5644be6fab627c226" category="cell">7521</block>
  <block id="176bf6219855a6eb1f3a30903e34b6fb" category="cell">6837</block>
  <block id="75da5036f659fe64b53f3d9b39412967" category="cell">7205</block>
  <block id="e6be4c22a5963ab00dfe8f3b695b5332" category="cell">6822</block>
  <block id="2ea1202aed1e0ce30d41be4919b0cc99" category="cell">6695</block>
  <block id="14d1ed13bbef7783a73cfb9346480ce2" category="paragraph">In termini di percentuali, la maggior parte delle frasi pronunciate dagli amministratori delegati e dai CFO è fattuale e quindi ha un sentimento neutrale. Durante una chiamata sui guadagni, gli analisti pongono domande che potrebbero trasmettere un sentimento positivo o negativo. Vale la pena di analizzare in maniera quantitativa il modo in cui il sentimento negativo o positivo influisce sui prezzi delle azioni nello stesso giorno o nel giorno successivo di negoziazione.</block>
  <block id="3957e5ecad1215aa086504cf2c9ba9cc" category="paragraph">La seguente tabella elenca l'analisi del sentimento a livello di frase per le prime 10 aziende NASDAQ, espressa in percentuale.</block>
  <block id="e8a6f3527192d64ba338192ce83f6283" category="cell">Percentuale di sentimento</block>
  <block id="3289297424e01eda5b788c083bbf3147" category="cell">Positivo</block>
  <block id="3e263985564016f5774bfb75e31efb0d" category="paragraph">10.13%</block>
  <block id="d983b23f5dc08dfb28a31a898b6fbb6a" category="cell">18.06%</block>
  <block id="ed5f9ec0b398f0f53408828898412855" category="cell">8.69%</block>
  <block id="4d8e8cc0a97724584c1cd94c9485d555" category="cell">5.24%</block>
  <block id="d43cdfa633a84f9ca5043f4eb9363a38" category="cell">9.07%</block>
  <block id="a134c476ebd0c219b3cc879185d436ce" category="cell">12.08%</block>
  <block id="27cd80a0bdc79a724fdc31fa8841e19b" category="cell">11.44%</block>
  <block id="e954976d9376dfe5860acd553772a6df" category="cell">13.25%</block>
  <block id="d30929e6786318e19a22c88447dcc97c" category="cell">6.23%</block>
  <block id="e9bb5320b3890b6747c91b5a71ae5a01" category="cell">Neutro</block>
  <block id="6c3d5ec0fc8197d1a8f8366e142e37aa" category="cell">87.17%</block>
  <block id="578429551436bef848f19eccdd93fb73" category="cell">79.02%</block>
  <block id="bd443bde0360eb444a5906bea9d081b0" category="cell">88.82%</block>
  <block id="97840fcb1a1f07bef3a12ef2d7975f09" category="cell">91.87%</block>
  <block id="32edca53c1f1f00d865543b435d4ce3a" category="cell">88.42%</block>
  <block id="407967ec786c26ce4ee7608c076fa6d7" category="cell">86.50%</block>
  <block id="9784395b081e78ec535161a5ba0ffd1e" category="cell">84.65%</block>
  <block id="5d4b03024bcea7385ffc5808dd9c3b74" category="cell">83.77%</block>
  <block id="b73c3663139621b36cfdafbeab44fae9" category="cell">92.44%</block>
  <block id="ffb9356ff2b7da85c75c92fa7ea03b8b" category="cell">Negativo</block>
  <block id="672484e7c4fb5894b2ec75fd7e277fe4" category="cell">2.43%</block>
  <block id="c1fbc8ff600d3f571e0c440833db1a10" category="cell">2.92%</block>
  <block id="161a790eac04cd27fc3e4ffd23ba452d" category="cell">2.49%</block>
  <block id="5fd44dd7fb1198b1903141531424bb54" category="cell">1.52%</block>
  <block id="6916237a9f5c4ed45ddfff6fe37f45e7" category="cell">2.51%</block>
  <block id="43045dfce9b4c190cfa4dad2e4bf9457" category="cell">1.42%</block>
  <block id="248199b9ac50bd355476016ad093ac09" category="cell">3.91%</block>
  <block id="1cdf97682ca1bcd645e8dbcebb105529" category="cell">2.96%</block>
  <block id="8098f29a2cea86e839d8ca03f50d52ce" category="cell">1.33%</block>
  <block id="0d015d96f63a8c12d96b8399482b593f" category="cell">Senza categoria</block>
  <block id="1291f0b93a9f9d5a7e7391a09b5ec0cc" category="cell">0.27%</block>
  <block id="9f1ef07877f9d85a82bd500f408b4814" category="cell">0%</block>
  <block id="6a040d1ee7200a1dc349a598a163cc38" category="cell">1.37%</block>
  <block id="d9fd62085e1ade721df051f8bc4c320d" category="cell">0.01%</block>
  <block id="28bf86a8e29245437d4ad59ea6e80962" category="paragraph">In termini di runtime del workflow, abbiamo riscontrato un significativo miglioramento di 4,78 volte<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> A un ambiente distribuito in HDFS e un ulteriore miglioramento del 0.14% grazie all'utilizzo di NFS.</block>
  <block id="87509d62c8804cdab48bea9e54013be4" category="paragraph">Come mostrato nella figura seguente, il parallelismo dei dati e dei modelli ha migliorato l'elaborazione dei dati e la velocità di deduzione del modello TensorFlow distribuito. La posizione dei dati in NFS ha prodotto un runtime leggermente migliore perché il collo di bottiglia del workflow è il download di modelli preformati. Se aumentiamo le dimensioni del set di dati delle trascrizioni, il vantaggio di NFS è più evidente.</block>
  <block id="493d0790c882abcf160f461d269c7ec5" category="inline-image-macro">Runtime del workflow end-to-end per l'analisi del sentimento di SPARK NLP.</block>
  <block id="bb9cd55aa92ceddf07506d9a2aaaa151" category="paragraph"><block ref="bb9cd55aa92ceddf07506d9a2aaaa151" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3484d035679c83a95496eb633ffde0d3" category="section-title">Formazione distribuita con performance Horovod</block>
  <block id="319e0ff7f30f4729140562f5e123c5cb" category="inline-link-macro">"Script Python per ogni caso di utilizzo principale"</block>
  <block id="e37af8307fb97140dbcc0c8e2293d58f" category="paragraph">Il seguente comando ha prodotto informazioni di runtime e un file di log nel cluster Spark utilizzando un singolo<block ref="eb0a191797624dd3a48fa681d3061212" prefix=" " category="inline-code"></block> nodo con 160 esecutori ciascuno con un core. La memoria dell'esecutore era limitata a 5 GB per evitare errori di memoria esaurita. Vedere la sezione <block ref="033a864c436cdbcbe38983e75952a07f" category="inline-link-macro-rx"></block> per ulteriori dettagli sull'elaborazione dei dati, sul training del modello e sul calcolo della precisione del modello in<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block>.</block>
  <block id="6281f693bbc375a45312622b626d3bcd" category="paragraph">Il runtime risultante con dieci epoche di training è stato il seguente:</block>
  <block id="842bc4f8403cd2df9f22939e3df59aee" category="paragraph">Ci sono voluti più di 43 minuti per elaborare i dati di input, formare un modello DNN, calcolare la precisione e produrre checkpoint TensorFlow e un file CSV per i risultati delle previsioni. Abbiamo limitato il numero di epoche di training a 10, che in pratica è spesso impostato a 100 per garantire una precisione del modello soddisfacente. Il tempo di training in genere è in grado di scalare in modo lineare con il numero di epoche.</block>
  <block id="1e580bbdb11118035631867d15ad9f25" category="paragraph">Successivamente, abbiamo utilizzato i quattro nodi di lavoro disponibili nel cluster ed eseguito lo stesso script in<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> Modalità con dati in HDFS:</block>
  <block id="3661bcf870f3d2b11b0489ed7f0585a7" category="paragraph">Il runtime risultante è stato migliorato come segue:</block>
  <block id="206c83ab2ec1ea280656b18c0e2dc4dd" category="paragraph">Con il modello di Horovod e il parallelismo dei dati in Spark, abbiamo visto una velocità di runtime di 5,29x<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> contro<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> con dieci epoche di training. Questo è mostrato nella figura seguente con le legende<block ref="99c35850ff7cf7e436b03acedd4c59b3" prefix=" " category="inline-code"></block> e.<block ref="509820290d57f333403f490dde7316f4" prefix=" " category="inline-code"></block>. Il training sul modello DNN TensorFlow sottostante può essere ulteriormente accelerato con le GPU, se disponibili. Prevediamo di condurre questo test e di pubblicare i risultati in un report tecnico futuro.</block>
  <block id="216851565edc166c4409515484cac08b" category="paragraph">Il nostro test successivo ha confrontato i runtime con i dati di input che risiedono in NFS rispetto a HDFS. Il volume NFS su AFF A800 è stato montato<block ref="e5f5dfd1cb98e0a4c27a3ce6df3ca358" prefix=" " category="inline-code"></block> Tra i cinque nodi (un master, quattro dipendenti) nel cluster Spark. Abbiamo eseguito un comando simile a quello dei test precedenti, con<block ref="97a9c2c856bc676ba715d3eecc314be6" prefix=" " category="inline-code"></block> Parametro ora che punta al montaggio NFS:</block>
  <block id="3ba4d622f15813cc383c433722b46d27" category="paragraph">Il runtime risultante con NFS è stato il seguente:</block>
  <block id="7e1d2a49ae0a0e06a39a62e2c7c74877" category="paragraph">Si è verificato un ulteriore velocismo di 1,43 volte, come mostrato nella figura seguente. Pertanto, con uno storage all-flash NetApp collegato al cluster, i clienti possono usufruire dei vantaggi di un rapido trasferimento e distribuzione dei dati per i flussi di lavoro di Horovod Spark, ottenendo una velocità di 7,55 volte superiore rispetto all'esecuzione su un singolo nodo.</block>
  <block id="88caa92ecc3ebb345f81205aa696e3ac" category="inline-image-macro">Horovod Spark Workflow Runtime.</block>
  <block id="56085b16b09d835f05c89b29473a0e73" category="paragraph"><block ref="56085b16b09d835f05c89b29473a0e73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b32c8309a0c0ca3edc35cb1597b9182c" category="section-title">Modelli di deep learning per performance di previsione CTR</block>
  <block id="6ff877f80b732c197c0a432029ad1920" category="paragraph">Per i sistemi di raccomandazione progettati per massimizzare il CTR, è necessario imparare sofisticate interazioni di funzionalità dietro i comportamenti degli utenti che possono essere calcolati matematicamente da basso ordine a alto ordine. Le interazioni di funzionalità di basso e alto ordine devono essere ugualmente importanti per un buon modello di deep learning senza polarizzare l'uno o l'altro. DeepFM (Deep Factorization Machine), una rete neurale basata su macchine per la fattorizzazione, combina macchine per la fattorizzazione per consigli e un apprendimento approfondito per l'apprendimento delle funzionalità in una nuova architettura di rete neurale.</block>
  <block id="a22645195470eca2abbe24e7d40cde8e" category="inline-link">&amp;Amp; modelli profondi</block>
  <block id="4028a7777950de6e915d72e379bde75d" category="paragraph">Anche se le macchine convenzionali di fattorizzazione modellano le interazioni a coppie come prodotto interno di vettori latenti tra le funzionalità e possono teoricamente acquisire informazioni di ordine elevato, in pratica, i professionisti dell'apprendimento automatico di solito utilizzano solo le interazioni di funzionalità di secondo ordine a causa dell'elevata complessità di calcolo e storage. Varianti di rete neurali profonde come quelle di Google<block ref="6c51a2ff49c9929908a73e863a1421f0" category="inline-link-rx"></block> d'altro canto, impara sofisticate interazioni di funzionalità in una struttura di rete ibrida combinando un modello ampio lineare e un modello profondo.</block>
  <block id="a22f6dcc8bc499f7332ab04cdb36fcf9" category="paragraph">Ci sono due input per questo modello ampio e profondo, uno per il modello ampio sottostante e l'altro per il deep, l'ultima parte del quale richiede ancora un esperto di ingegneria delle funzionalità e quindi rende la tecnica meno generalizzabile per altri domini. A differenza di Wide &amp; Deep Model, DeepFM può essere addestrato in modo efficiente con funzionalità raw senza alcuna progettazione delle funzioni, perché la sua parte ampia e profonda condividono lo stesso input e lo stesso vettore di inclusione.</block>
  <block id="03eaefcaa3f1aca8b4ffa8b95a4798b9" category="inline-link-macro">"Script Python per ogni caso di utilizzo principale".</block>
  <block id="105a0d9d76e001ecdab02b77ca3a98ae" category="paragraph">Abbiamo elaborato per la prima volta il Criteo<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> (11 GB) in un file CSV denominato<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> Memorizzato in un montaggio NFS<block ref="17d831727f14e5379e2f4773837ccfa4" prefix=" " category="inline-code"></block> utilizzo di<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block> dalla sezione <block ref="43e008bfee5963b21d09b0af490bfdd7" category="inline-link-macro-rx"></block> All'interno di questo script, la funzione<block ref="000f75d2ea65c8a3d82d62e405ce82ee" prefix=" " category="inline-code"></block> esegue diversi metodi di stringa per rimuovere le schede e inserire<block ref="f89bb99ea60d9e9cbbc95ce1a8f1a63a" prefix=" " category="inline-code"></block> come delimitatore e.<block ref="918d67b3695a9c52a0e182a621fc33da" prefix=" " category="inline-code"></block> come novità. Tenere presente che è necessario elaborare solo l'originale<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> una volta, in modo che il blocco di codice sia visualizzato come commenti.</block>
  <block id="c960954a8d119eab5ff32a80d7fcc8e8" category="paragraph">Per i seguenti test di diversi modelli DL, abbiamo utilizzato<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> come file di input. Nelle successive esecuzioni dei test, il file CSV di input è stato letto in un Spark DataFrame con schema contenente un campo di<block ref="cdb10f764735165c687209f811432621" prefix=" " category="inline-code"></block>, caratteristiche ad alta densità di numeri interi<block ref="2c94c76f60323031573497e25961744a" prefix=" " category="inline-code"></block>e funzioni sparse<block ref="57fae172685844997d173fa4248d66f8" prefix=" " category="inline-code"></block>. Quanto segue<block ref="78d07f07ead3482e696c0c224c2a7ed5" prefix=" " category="inline-code"></block> Command acquisisce un input CSV, allena i modelli DeepFM con una suddivisione del 20% per la convalida incrociata e sceglie il modello migliore dopo dieci epoche di training per calcolare l'accuratezza della previsione sul set di test:</block>
  <block id="52703dd8fd8c710b0aed616d19ddc0fb" category="paragraph">Tenere presente che dal file di dati<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> È superiore a 11 GB, è necessario impostare un valore sufficiente<block ref="af770896b1954b7c355d9becfe487e40" prefix=" " category="inline-code"></block> maggiore della dimensione del set di dati per evitare errori.</block>
  <block id="650f108a9978f10b1e3b0a8cbdcd6ac1" category="inline-link">Freccia Apache</block>
  <block id="caa01fc7f9a1a61f1bc803760af8e97f" category="paragraph">In quanto sopra<block ref="0ce62b6d4610e91242b63139adeb9432" prefix=" " category="inline-code"></block> anche la configurazione è stata abilitata<block ref="d19d750623d06d371730c4055a0fbbbf" category="inline-link-rx"></block>, Che converte un DataFrame Spark in un DataFrame Pandas con<block ref="5d77cff4a1fdffb38c875e9a11a310fb" prefix=" " category="inline-code"></block> metodo.</block>
  <block id="e20380d4fed48eae6cd24a0df1477ba7" category="paragraph">Dopo la suddivisione casuale, nel set di dati di training sono presenti più di 36 M di righe e 9 M di esempi nel set di test:</block>
  <block id="e6219a2eedbe95f3aa16ed53c4733845" category="paragraph">Poiché questo report tecnico è incentrato sul test della CPU senza utilizzare alcuna GPU, è fondamentale creare TensorFlow con i flag appropriati del compilatore. Questo passaggio evita di invocare librerie con accelerazione GPU e sfrutta al meglio le istruzioni AVX (Advanced Vector Extensions) e AVX2 di TensorFlow. Queste funzionalità sono progettate per calcoli algebrici lineari come addizione vettorizzata, moltiplicazioni di matrice all'interno di un training feed-forward o DNN back-propagation. L'istruzione FMA (Fused Multiply Add) disponibile con AVX2 che utilizza registri a virgola mobile (FP) a 256 bit è ideale per i tipi di dati e codice intero, con una velocità fino a 2 volte superiore. Per il codice FP e i tipi di dati, AVX2 raggiunge una velocità dell'8% su AVX.</block>
  <block id="6c396013ff0ebff6a2a96cdc20a4ba4c" category="inline-link">Bazel</block>
  <block id="97139e366bae36e316c93ce5b5e7e10b" category="paragraph">Per creare TensorFlow dall'origine, NetApp consiglia di utilizzare<block ref="0bf1f7ee55f693a3c117cb75493ba615" category="inline-link-rx"></block>. Per il nostro ambiente, abbiamo eseguito i seguenti comandi nel prompt della shell per l'installazione<block ref="ffd93b30364fb8893d5bbb6fdb312666" prefix=" " category="inline-code"></block>,<block ref="1208feb4bf9c4dd21156d8231d098ba1" prefix=" " category="inline-code"></block>E Bazel.</block>
  <block id="29fe549665f940a68b9303eae3e3a61e" category="paragraph">È necessario abilitare GCC 5 o versioni successive per utilizzare le funzionalità C++17 durante il processo di creazione, fornito da RHEL con Software Collections Library (SCL). I seguenti comandi vengono installati<block ref="188b06575e77785e6b73e5e85b8e6ada" prefix=" " category="inline-code"></block> E GCC 11.2.1 sul nostro cluster RHEL 7.9:</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">articolo</block>
  <block id="d4b82f54dfee1e5c527d0d5f8cb0d7aa" category="paragraph">Si noti che gli ultimi due comandi sono disponibili<block ref="1dde0514b51c7c8f49cc63e4b54b8b37" prefix=" " category="inline-code"></block>, che utilizza<block ref="03fec70ce2bd12477f18ac0667e43d67" prefix=" " category="inline-code"></block> (GCC 11.2.1). Inoltre, assicurarsi di<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> La versione è superiore alla 1.8.3 (fornita con RHEL 7.9). Fare riferimento a questo<block ref="7d93914bddb4046675adee0145ba45bd" category="inline-link-rx"></block> per l'aggiornamento<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> a 2.24.1.</block>
  <block id="dc06a2e6ab4959266b8e70b6a4ecc45c" category="inline-link-macro">"Script Python per ogni caso di utilizzo principale",</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="inline-link">CUDA</block>
  <block id="c55692ca5ecd175c73f55ba5b9319688" category="paragraph">Supponiamo che tu abbia già clonato l'ultimo repo master TensorFlow. Quindi, creare un<block ref="1629dee48cc4e53161f9b2be8614e062" prefix=" " category="inline-code"></block> directory con un<block ref="09498dbadf45966909850dc8a47ebb13" prefix=" " category="inline-code"></block> File per la creazione di TensorFlow dall'origine con AVX, AVX2 e FMA. Eseguire<block ref="e2d5a00791bce9a01f99bc6fd613a39d" prefix=" " category="inline-code"></block> E specificare la posizione binaria di Python corretta.<block ref="be1c72ed18fb5f637a2d34d959decb73" category="inline-link-rx"></block> È disattivato per i test perché non abbiamo utilizzato una GPU. R<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> il file viene generato in base alle impostazioni. Inoltre, abbiamo modificato il file e il set<block ref="4e1b2fd49a68e112bae6de1bc453f18c" prefix=" " category="inline-code"></block> Per attivare il supporto HDFS. Fare riferimento a.<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> nella sezione <block ref="2aec9284f17908b1690444cda81e493c" category="inline-link-macro-rx"></block> per un elenco completo di impostazioni e flag.</block>
  <block id="8329b0f29ec7368fd026b86d981f9dc7" category="paragraph">Dopo aver creato TensorFlow con i flag corretti, eseguire il seguente script per elaborare il set di dati Criteo Display Ads, formare un modello DeepFM e calcolare l'area sotto la curva caratteristica operativa ricevitore (ROC AUC) in base ai punteggi di previsione.</block>
  <block id="d5a94c8db568912353007fdff822667e" category="paragraph">Dopo dieci epoche di training, abbiamo ottenuto il punteggio AUC nel set di dati di test:</block>
  <block id="e3c9ed451390735cd8c4f8e5eb0e31f5" category="paragraph">In modo simile ai casi di utilizzo precedenti, abbiamo confrontato il runtime del workflow Spark con i dati che risiedono in posizioni diverse. La figura seguente mostra un confronto della previsione CTR di apprendimento approfondito per un runtime di workflow Spark.</block>
  <block id="3737826be0460f743becdc4c64050946" category="inline-image-macro">Confronto della previsione CTR di deep learning per un runtime di workflow Spark.</block>
  <block id="d27b678d975cf1fb0769c3e664f4f2dd" category="paragraph"><block ref="d27b678d975cf1fb0769c3e664f4f2dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7eb641fcfa1ced825edab271ee870e9" category="inline-link-macro">Avanti: Soluzione di cloud ibrido.</block>
  <block id="3f5dc233ecdfc868e2a067d1eb7d8811" category="paragraph"><block ref="3f5dc233ecdfc868e2a067d1eb7d8811" category="inline-link-macro-rx"></block></block>
  <block id="0a1bc6b4024485ff9b55c99c1237e175" category="doc">Utilizzo ottimale di cluster e GPU con Run:ai</block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="doc">Setup (Configurazione)</block>
  <block id="dbb4dd9a11f48db13d63eedaae717fe5" category="doc">Creazione di progetti per i team Data Science e allocazione delle GPU</block>
  <block id="22d09d229a06f294b0f45804f8e639d3" category="paragraph">I ricercatori possono inviare i carichi di lavoro attraverso la CLI Run:ai, Kubeflow o processi simili. Per ottimizzare l'allocazione delle risorse e creare priorità, Run:ai introduce il concetto di progetti. I progetti sono entità di quota che associano un nome di progetto all'allocazione e alle preferenze della GPU. Si tratta di un metodo semplice e conveniente per gestire più team di data science.</block>
  <block id="c0bd05e9d88cf015eac684873bfd14c7" category="paragraph">Un ricercatore che invia un workload deve associare un progetto a una richiesta di workload. Lo scheduler Run:ai confronta la richiesta con le allocazioni correnti e il progetto e determina se il carico di lavoro può essere allocato o se deve rimanere in uno stato in sospeso.</block>
  <block id="800f40fa67f69116bf6f38cd07456608" category="paragraph">In qualità di amministratore di sistema, è possibile impostare i seguenti parametri nella scheda Run:ai Projects (Esegui: Progetti ai):</block>
  <block id="9c429f2284a95aaa299c7d85ccb16734" category="list-text">*Model projects.* Imposta un progetto per utente, imposta un progetto per team di utenti e imposta un progetto per un progetto organizzativo reale.</block>
  <block id="638c2d891d4e85bcfae409499fba817c" category="inline-link">Elevato utilizzo del cluster con allocazione della GPU con quota eccessiva</block>
  <block id="c83553858a60514501e9751c0747dea0" category="inline-link">Equità nell'allocazione delle risorse di base</block>
  <block id="6b4330df9a37bcfef1faecd1e8973464" category="inline-link">Equità nell'overquota</block>
  <block id="b2f1422cf0d082a495bbf865b9a5621d" category="list-text">*Quote di progetto.* ogni progetto è associato a una quota di GPU che può essere allocata per questo progetto contemporaneamente. Si tratta di una quota garantita nel senso che i ricercatori che utilizzano questo progetto possono ottenere questo numero di GPU indipendentemente dallo stato del cluster. Di norma, la somma dell'allocazione del progetto deve essere uguale al numero di GPU nel cluster. Oltre a questo, un utente di questo progetto può ricevere una quota eccessiva. Finché le GPU non vengono utilizzate, un ricercatore che utilizza questo progetto può ottenere più GPU. In vengono illustrati scenari di test con quote superiori e considerazioni di equità<block ref="9563fd9ab6978412dc97d80a70e51786" category="inline-link-rx"></block>,<block ref="a8ad108feafc827856baa28b0b9070ed" category="inline-link-rx"></block>, e.<block ref="be867f64efefe193012b1dfc6c82f783" category="inline-link-rx"></block>.</block>
  <block id="20a3a45fbbd9502add12fd216350d569" category="list-text">Creare un nuovo progetto, aggiornare un progetto esistente ed eliminare un progetto esistente.</block>
  <block id="3bf13b237342258b6ddb3f167d679a3b" category="inline-link">Run:documentazione ai</block>
  <block id="77332641abf52ec5dc1af8b23b2339f3" category="list-text">*Limita l'esecuzione dei job su gruppi di nodi specifici*. È possibile assegnare progetti specifici da eseguire solo su nodi specifici. Ciò è utile quando il team di progetto ha bisogno di hardware specializzato, ad esempio con memoria sufficiente. In alternativa, un team di progetto potrebbe essere il proprietario di hardware specifico acquistato con un budget specializzato, oppure quando potrebbe essere necessario indirizzare i carichi di lavoro di build o interattivi per lavorare su hardware più debole e indirizzare i carichi di lavoro di formazione più lunghi o non presidiati su nodi più veloci. Per i comandi per raggruppare i nodi e impostare l'affinità per un progetto specifico, vedere <block ref="eae60ce89b8727160634b52e7654bf73" category="inline-link-rx"></block>.</block>
  <block id="2bd802cca9bf193b441123437f5d39ca" category="list-text">*Limitare la durata dei lavori interattivi*. I ricercatori spesso si dimenticano di chiudere lavori interattivi. Ciò potrebbe comportare uno spreco di risorse. Alcune organizzazioni preferiscono limitare la durata dei lavori interattivi e chiuderli automaticamente.</block>
  <block id="10c2495ded559d79de96be22751712dc" category="paragraph">La figura seguente mostra la vista progetti con quattro team creati. A ciascun team viene assegnato un numero diverso di GPU per i diversi carichi di lavoro, con il numero totale di GPU pari a quello delle GPU totali disponibili in un cluster costituito da due DGX-1.</block>
  <block id="9ba047faa1d241a6153be986be27097f" category="paragraph"><block ref="9ba047faa1d241a6153be986be27097f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4804b15e4766599ceade052b5ca8af9" category="inline-link-macro">Successivo: Invio di job in Run ai CLI</block>
  <block id="9c6088fad9917e07026030c1d3eaad09" category="paragraph"><block ref="9c6088fad9917e07026030c1d3eaad09" category="inline-link-macro-rx"></block></block>
  <block id="ccc33823c0dc5e9ee0838a5eaa86f076" category="doc">Dettagli sui test per la Sezione 4.9</block>
  <block id="ed8e4613850a4014b0e6ef830982caf2" category="paragraph">Questa sezione contiene i dettagli dei test per la sezione <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>.</block>
  <block id="f354c9a7a0a52e7a5a3514252ea5f8b7" category="paragraph">Inoltrare i lavori nel seguente ordine:</block>
  <block id="9e727fdd3aec8274f46685441900280d" category="cell">Progetto</block>
  <block id="b3428404a5be1cf95d4e53b2ddc8288a" category="cell">N. di GPU</block>
  <block id="96b0141273eabab320119c467cdcaf17" category="cell">Totale</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">Commento</block>
  <block id="ae7ccf7b1a6a1a023f611a294572a900" category="cell">team-d</block>
  <block id="17b3673d5c28fb72e7cc48549f489dd4" category="cell">6/8</block>
  <block id="ffe090618e54b7916fa47cf8881019b1" category="cell">Il carico di lavoro del team-b/c viene messo in pausa e spostato a.<block ref="7c6c2e5d48ab37a007cbf70d3ea25fa4" prefix=" " category="inline-code"></block>.</block>
  <block id="f82056dbbe3376b10ac622b0bdaae914" category="cell">8/8</block>
  <block id="bccfe4ac65004fb31c146d17003d00e8" category="cell">I carichi di lavoro degli altri team (b/c) vengono interrompiti e spostati<block ref="7c6c2e5d48ab37a007cbf70d3ea25fa4" prefix=" " category="inline-code"></block>.</block>
  <block id="be46ffa9e65cb964fc3236de02c41e4e" category="paragraph">Vedere la seguente sequenza di comandi eseguiti:</block>
  <block id="3bf38f884fd74f6e6f1ec3d80018edd8" category="paragraph">A questo punto, si dovrebbero avere i seguenti stati:</block>
  <block id="e55f05703a3e04fbd9e10f76ae925cc9" category="cell">GPU allocate</block>
  <block id="26cc9c6ccae01f319282379c339cd90b" category="cell">Carichi di lavoro in coda</block>
  <block id="9320270de4ff6824ae7a21f729fb7d44" category="cell">squadra a.</block>
  <block id="36d2df43ead992a1e3c86acd0cec69f9" category="cell">4/4</block>
  <block id="238ff8d9192e9c01e50a8d6d21f1607b" category="cell">team-b</block>
  <block id="867c7d7d65c50ae3679fabce2eab87a3" category="cell">2/2</block>
  <block id="3b40d1328b825dda4b761a8e534669b7" category="cell">team-c</block>
  <block id="3b099141b6a7e4e8804c3fda5ed4f440" category="paragraph">Vedere la sezione <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block> per una discussione sullo scenario di test.</block>
  <block id="5d52789e4f8028aca21d5650bed8273b" category="inline-link-macro">Pagina successiva: Dettagli sui test per la Sezione 4.10</block>
  <block id="61a1556247485f1d0fbb34dbe36d1503" category="paragraph"><block ref="61a1556247485f1d0fbb34dbe36d1503" category="inline-link-macro-rx"></block></block>
  <block id="9a50201aa3bf66a7a0337ccf29d20c90" category="doc">Tecnologia della soluzione</block>
  <block id="ed4a202c34987f40d5e245e76a65a243" category="paragraph">La figura seguente illustra l'architettura di sistema ai conversazionale proposta. È possibile interagire con il sistema sia con il segnale vocale che con l'immissione di testo. Se viene rilevato un input vocale, Jarvis ai-as-service (AIaaS) esegue ASR per produrre testo per Dialog Manager. Dialog Manager memorizza gli stati di conversazione, indirizza il testo ai servizi corrispondenti e passa i comandi al motore di adempimento. Jarvis NLP Service prende il testo, riconosce intenti ed entità e restituisce tali intenti e slot di entità a Dialog Manager, che invia quindi Action al motore di adempimento. Fulfillment Engine è costituito da API di terze parti o database SQL che rispondono alle query degli utenti. Dopo aver ricevuto il risultato da Fulfillment Engine, Dialog Manager indirizza il testo a Jarvis TTS AIaaS per produrre una risposta audio per l'utente finale. Possiamo archiviare la cronologia delle conversazioni, annotare frasi con intenti e slot per il training NEMO in modo che il servizio NLP migliori man mano che un maggior numero di utenti interagisce con il sistema.</block>
  <block id="308a0722262fbc3adde5d5d900ad0c36" category="paragraph"><block ref="308a0722262fbc3adde5d5d900ad0c36" category="inline-image-macro-rx" type="image"></block></block>
  <block id="930dd6e7cbd550494f96b487d9d38ec8" category="section-title">Requisiti hardware</block>
  <block id="863eef2617ffc374c485389aabdd8a24" category="paragraph">Questa soluzione è stata validata utilizzando una stazione DGX e un sistema storage AFF A220. Jarvis richiede una GPU T4 o V100 per eseguire calcoli di rete neurali profondi.</block>
  <block id="6c4fbfa85e86ba1acd8a66b367a3b2c4" category="paragraph">La seguente tabella elenca i componenti hardware necessari per implementare la soluzione come testata.</block>
  <block id="71c9e70899509bff35197ba9da10dafc" category="cell">GPU T4 O V100</block>
  <block id="8f452959667e7665cddf2484ddca1724" category="cell">Stazione NVIDIA DGX</block>
  <block id="9d273bd32c1fceb91b7d6a4d40e98bdd" category="section-title">Requisiti software</block>
  <block id="f7a05af899e536cde0a9c8476c2da0a1" category="paragraph">La seguente tabella elenca i componenti software necessari per implementare la soluzione come testata.</block>
  <block id="5acec1d6c6e07042eb0c19bc926d2633" category="cell">Versione o altre informazioni</block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="cell">Software per la gestione dei dati NetApp ONTAP</block>
  <block id="eaf2f97729e8d5e4d205672da8afc9a5" category="cell">9.6</block>
  <block id="efdec37786e687a58664ebd4ef6bdba4" category="cell">Firmware dello switch Cisco NX-OS</block>
  <block id="976d6c35e21478ef03ca2cec2a74dc71" category="cell">7.0(3)I6(1)</block>
  <block id="a62649c559be1634e22dd7df0b58ad32" category="cell">SISTEMA OPERATIVO NVIDIA DGX</block>
  <block id="4a5be8fea83a32ad5c7fc31b02ef1028" category="cell">4.0.4 - Ubuntu 18.04 LTS</block>
  <block id="0664d9eb73230b2a0b514b0facae8ade" category="cell">NVIDIA Jarvis Framework</block>
  <block id="cc5f21cb121669006a19c9fde049f048" category="cell">EA v0.2</block>
  <block id="dfcc0491fc5a6e738ca8b5ef3a258093" category="cell">NVIDIA NEMO</block>
  <block id="317fe32bf712dffb43ddc0ee8dde8c3c" category="cell">nvcr.io/nvidia/nemo:v0.10</block>
  <block id="44769dc982b2126503d2d014bcf7c15a" category="cell">Piattaforma container Docker</block>
  <block id="0cc9a8e76e0a79d0e0072e0a0d675fe5" category="cell">18.06.1-ce [e68fc7a]</block>
  <block id="3032d0de2852f0bb1e13142c2c47cd5b" category="inline-link-macro">Avanti: Costruisci un assistente virtuale utilizzando Jarvis, Cloud Sync e NEMO Overview</block>
  <block id="5cefb81f0324c44ec13c02fa7700924b" category="paragraph"><block ref="5cefb81f0324c44ec13c02fa7700924b" category="inline-link-macro-rx"></block></block>
  <block id="e2b5e920360785877a1831ff4b128520" category="summary">Installazione di NetApp</block>
  <block id="9af8334f3fca73145524498c2f49ee10" category="inline-link-macro">Avanti:Panoramica</block>
  <block id="02e8a07ffc2e2c5240049e5214d70427" category="paragraph"><block ref="02e8a07ffc2e2c5240049e5214d70427" category="inline-link-macro-rx"></block></block>
  <block id="c755c33dca37a8aaffbf190bdf3f5fef" category="paragraph">Questa soluzione è stata implementata con un sistema NetApp AFF A800, due server DGX-1 e due switch Cisco Nexus 3232C 100GbE. Ciascun server DGX-1 è connesso agli switch Nexus con quattro connessioni da 100 GbE utilizzate per le comunicazioni tra GPU utilizzando RDMA (Remote Direct Memory Access) su RoCE (Converged Ethernet). Anche le comunicazioni IP tradizionali per l'accesso allo storage NFS avvengono su questi collegamenti. Ogni controller di storage è collegato agli switch di rete utilizzando quattro collegamenti da 100 GbE. La figura seguente mostra l'architettura della soluzione ONTAP ai utilizzata in questo report tecnico per tutti gli scenari di test.</block>
  <block id="782c9fdc3f29358987c2f5b99fe9e6b9" category="paragraph"><block ref="782c9fdc3f29358987c2f5b99fe9e6b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf8b135ff3c775c5b9bbba1b2f7a61ce" category="section-title">Hardware utilizzato in questa soluzione</block>
  <block id="3b31e2e4387e938056251a113831e6da" category="inline-link">NVA-1121</block>
  <block id="a4ec49885c617f2b2500789af7e6eebf" category="paragraph">Questa soluzione è stata validata utilizzando l'architettura di riferimento ONTAP ai, due nodi DGX-1 e un sistema storage AFF A800. Vedere<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> per ulteriori informazioni sull'infrastruttura utilizzata in questa convalida.</block>
  <block id="fe59cdcdefd7c53625e1e745b9c5be09" category="cell">Sistemi DGX-1</block>
  <block id="6da64488bfb7f3216610e30ced34ff23" category="cell">Switch Nexus 3232C</block>
  <block id="142f782bb2b326679982208fe40cec31" category="inline-link">NVIDIA DeepOps</block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="inline-link">Trident di NetApp</block>
  <block id="31bbf80f0649d07d3e8340123f1a6963" category="inline-link">TR-4798</block>
  <block id="8e926487edd9348114ada5fa88a732df" category="paragraph">Questa soluzione è stata convalidata utilizzando un'implementazione Kubernetes di base con l'operatore Run:ai installato. Kubernetes è stato implementato utilizzando<block ref="1c894f7463797b81796e78efc8345fb0" category="inline-link-rx"></block> motore di implementazione, che implementa tutti i componenti necessari per un ambiente pronto per la produzione. DeepOps implementato automaticamente<block ref="ca1c90879f9a0e8dc4ff805fb398f7ff" category="inline-link-rx"></block> Per l'integrazione persistente dello storage con l'ambiente k8s, sono state create classi di storage predefinite in modo che i container sfruttino lo storage del sistema storage AFF A800. Per ulteriori informazioni su Trident con Kubernetes su ONTAP ai, vedere<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block>.</block>
  <block id="a2525584dd9d2a9522ddea95841c06b3" category="cell">9.6p4</block>
  <block id="80afba45eb055fc9bdc48c90d1debd06" category="cell">Versione di Kubernetes</block>
  <block id="4bbe90408850f459864a71c8054732f1" category="cell">1.17</block>
  <block id="f1112223b41fddc71fd6a626582dfb78" category="cell">Versione di Trident</block>
  <block id="43d66966083b0e0feac8fb9be14ba5b8" category="cell">20.04.0</block>
  <block id="e993176eed424766bc6bd4758eaf2cb6" category="cell">Esegui:ai CLI</block>
  <block id="5e6305186adf6e7dcf03f5cbfc802c49" category="cell">v2.1.13</block>
  <block id="f3eeed8e4b2791f80e2f123c4720aef5" category="cell">Run:ai Orchestration Kubernetes Operator version</block>
  <block id="bf8c2933a2f54ce25fe986f66d3bffa3" category="cell">1.0.39</block>
  <block id="076ca75e2fc5b6ea85d72b0a9adc8844" category="inline-link">Esegui: Prerequisiti del cluster GPU ai</block>
  <block id="eaec7f01752b17abf6125d8f29a8543c" category="paragraph">Ulteriori requisiti software per Run:ai sono disponibili all'indirizzo<block ref="98bb21d82bcd499a183c82dcfc9b02f3" category="inline-link-rx"></block>.</block>
  <block id="cc352f05f03c970b081b8afa29693b60" category="inline-link-macro">Avanti: Utilizzo ottimale di cluster e GPU con Run ai</block>
  <block id="b1b09355c9538fe149372d3728c98bb1" category="paragraph"><block ref="b1b09355c9538fe149372d3728c98bb1" category="inline-link-macro-rx"></block></block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="doc">Panoramica sulla tecnologia</block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">Panoramica di NetApp</block>
  <block id="d30aa8861afaf98888c2367f107a8bc6" category="paragraph">NetApp è l'autorità dei dati per il cloud ibrido. NetApp offre una gamma completa di servizi dati del cloud ibrido che semplificano la gestione di applicazioni e dati in ambienti cloud e on-premise per accelerare la trasformazione digitale. Insieme ai nostri partner, NetApp consente alle organizzazioni globali di liberare il pieno potenziale dei propri dati per espandere i punti di contatto dei clienti, promuovere una maggiore innovazione e ottimizzare le operazioni.</block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="section-title">NetApp ONTAP ai</block>
  <block id="ee86473f0dbd191846077276ce455778" category="paragraph">NetApp ONTAP ai, basato su sistemi NVIDIA DGX e storage all-flash connesso al cloud, ottimizza il flusso dei dati in modo affidabile e accelera l'analisi, la formazione e l'inferenza con il data fabric che si estende dall'edge al core al cloud. Offre alle organizzazioni IT un'architettura che offre i seguenti vantaggi:</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">Elimina le complessità di progettazione</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">Consente una scalabilità indipendente di calcolo e storage</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">Consente ai clienti di partire da piccoli e scalare perfettamente</block>
  <block id="6cb062d50ca0d4a2bfa0caec33fea16f" category="list-text">Offre una vasta gamma di opzioni di storage per diverse performance e costi. NetApp ONTAP ai offre stack di infrastruttura convergente che incorporano NVIDIA DGX-1, un sistema ai petaflop-scale e switch Ethernet NVIDIA Mellanox dalle performance elevate per unificare i carichi di lavoro ai, semplificare l'implementazione e accelerare il ROI. Abbiamo utilizzato ONTAP ai con un sistema storage DGX-1 e NetApp AFF A800 per questo report tecnico. La seguente immagine mostra la topologia di ONTAP ai con il sistema DGX-1 utilizzato per questa convalida.</block>
  <block id="3eedc2d7451e7ff0440f17c9e61227dc" category="paragraph"><block ref="3eedc2d7451e7ff0440f17c9e61227dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="section-title">Piano di controllo ai di NetApp</block>
  <block id="e1fc355cf7f97dbf25407695f8852241" category="paragraph">Il NetApp ai Control Plane ti consente di liberare ai e ML con una soluzione che offre scalabilità estrema, implementazione semplificata e disponibilità dei dati continua. La soluzione ai Control Plane integra Kubernetes e Kubeflow con un data fabric abilitato da NetApp. Kubernetes, la piattaforma di orchestrazione dei container standard di settore per le implementazioni native del cloud, offre scalabilità e portabilità dei workload. Kubeflow è una piattaforma open-source per l'apprendimento automatico che semplifica la gestione e l'implementazione, consentendo agli sviluppatori di fare più scienza dei dati in meno tempo. Un data fabric abilitato da NetApp offre disponibilità e portabilità dei dati senza compromessi per garantire che i dati siano accessibili attraverso la pipeline, dall'edge al core al cloud. Questo report tecnico utilizza il NetApp ai Control Plane in una pipeline MLRun. L'immagine seguente mostra la pagina di gestione del cluster Kubernetes, in cui è possibile avere endpoint diversi per ciascun cluster. Abbiamo collegato i volumi persistenti NFS al cluster Kubernetes e le immagini seguenti mostrano un volume persistente connesso al cluster, dove<block ref="33155b45dbdad2f412212744fbe6f8dc" category="inline-link-rx"></block> offre supporto dello storage persistente e funzionalità di gestione dei dati.</block>
  <block id="b058638c35435549e77a90b91abd3305" category="paragraph"><block ref="b058638c35435549e77a90b91abd3305" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eee185b539f0e52d8b64916066463222" category="paragraph"><block ref="eee185b539f0e52d8b64916066463222" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d371ade9f9702601a7e2f8f57c8b013" category="paragraph"><block ref="7d371ade9f9702601a7e2f8f57c8b013" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1dc271f7d3ae88e2a019314b7e4fd8e" category="section-title">Panoramica di Iguazio</block>
  <block id="0c9fe13fe6a660070e99a54151edd7c3" category="paragraph">Iguazio Data Science Platform è una piattaforma PaaS (Data Science Platform as a Service) completamente integrata e sicura che semplifica lo sviluppo, accelera le performance, facilita la collaborazione e affronta le sfide operative. Questa piattaforma incorpora i seguenti componenti e la piattaforma Iguazio Data Science è presentata nella seguente immagine:</block>
  <block id="2137518d79f0a3dfe335e8c02312cf96" category="list-text">Un workbench per la scienza dei dati che include notebook Jupyter, motori di analisi integrati e pacchetti Python</block>
  <block id="68ed19bfa85e4c4677e50979864e169b" category="list-text">Gestione dei modelli con monitoraggio degli esperimenti e funzionalità di pipeline automatizzate</block>
  <block id="37a28d84cd653345f1f2c036cb732f2d" category="list-text">Dati gestiti e SERVIZI ML su un cluster Kubernetes scalabile</block>
  <block id="77fdda1a79199ac02cde44b4249cb509" category="list-text">Nuclio, un framework di funzioni senza server in tempo reale</block>
  <block id="96a6f4a99a7526e82a294d44ed005701" category="list-text">Un livello di dati estremamente veloce e sicuro che supporta SQL, NoSQL, database Time-Series, file (oggetti semplici) e streaming</block>
  <block id="00a48f02675717eaf6082c4ba536a366" category="list-text">Integrazione con origini dati di terze parti come NetApp, Amazon S3, HDFS, database SQL e protocolli di streaming o messaggistica</block>
  <block id="901630ad39a688431a68dc119f5378a3" category="list-text">Dashboard in tempo reale basati su Grafana</block>
  <block id="887fce38ef8ddd8546748bb746ed7e5a" category="paragraph"><block ref="887fce38ef8ddd8546748bb746ed7e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="961027a0ac9a1d9515fa54a5d5372c79" category="inline-link-macro">Avanti: Requisiti software e hardware</block>
  <block id="a10e3ee0949323f601d4c9624980eb47" category="paragraph"><block ref="a10e3ee0949323f601d4c9624980eb47" category="inline-link-macro-rx"></block></block>
  <block id="46ded0be5f6c48090d38435b6dafa3e2" category="summary">Questa sezione fornisce una panoramica dei tre scenari validati in questa soluzione.</block>
  <block id="71446ef316489c70b5279867eb81a86b" category="doc">Piano di test e validazione</block>
  <block id="8e593eca45d74047c3d169456d36d74a" category="paragraph"><block ref="8e593eca45d74047c3d169456d36d74a" category="inline-link-macro-rx"></block></block>
  <block id="68cdc250e271cc43502e5f009d0ebec7" category="paragraph">Per questa progettazione della soluzione, sono stati validati i seguenti tre scenari:</block>
  <block id="83c38d8dc6bc37fe6bb9691e75d0f881" category="list-text">Un'attività di inferenza, con e senza offuscamento di Protopia, all'interno di uno spazio di lavoro JupyterLab orchestrato utilizzando il NetApp DataOps Toolkit per Kubernetes.</block>
  <block id="da4ec54ac3b4b67b77d52ccf0ebaefc0" category="list-text">Un processo di deduzione in batch, con e senza offuscamento di Protopia, su Kubernetes con un volume di dati orchestrato utilizzando NetApp DataOps Toolkit per Kubernetes.</block>
  <block id="5526e24c695504cfa8b2187b0a3da212" category="list-text">Un'attività di deduzione che utilizza un'istanza di NVIDIA Triton Inference Server orchestrata utilizzando NetApp DataOps Toolkit per Kubernetes. Abbiamo applicato l'offuscamento protopico all'immagine prima di invocare l'API di inferenza Triton per simulare il requisito comune che prevede l'offuscamento dei dati trasmessi sulla rete. Questo flusso di lavoro è applicabile ai casi di utilizzo in cui i dati vengono raccolti all'interno di una zona attendibile ma devono essere trasferiti all'esterno di tale zona attendibile per l'deduzione. Senza l'offuscamento di Protopia, non è possibile implementare questo tipo di workflow senza che i dati sensibili abbandonino la zona attendibile.</block>
  <block id="a53c037982ff4e0cd4a61ba90c4c21d3" category="inline-link-macro">Pagina successiva: Test della configurazione.</block>
  <block id="9a1eb36c3c2949c4b9618b70f9947341" category="paragraph"><block ref="9a1eb36c3c2949c4b9618b70f9947341" category="inline-link-macro-rx"></block></block>
  <block id="67d45a00257105f21f4427f31e0c9fa1" category="summary">Questo report tecnico fornisce ai clienti indicazioni di progettazione per eseguire l'analisi del sentimento in un centro di supporto globale di livello Enterprise utilizzando le tecnologie di gestione dei dati NetApp con un framework software NVIDIA che utilizza l'apprendimento del trasferimento e l'intelligenza artificiale conversazionale.</block>
  <block id="22268d4ee4f32cda2f20141957aac961" category="paragraph">Rick Huang, Sathish Thyagarajan e David Arnette, NetApp Diego Sosa-Coba, SFL Scientific</block>
  <block id="0c450c48691e7a55b657f2cb7d18a0dd" category="paragraph">Questo report tecnico fornisce ai clienti indicazioni di progettazione per eseguire l'analisi del sentimento in un centro di supporto globale di livello Enterprise utilizzando le tecnologie di gestione dei dati NetApp con un framework software NVIDIA che utilizza l'apprendimento del trasferimento e l'intelligenza artificiale conversazionale. Questa soluzione è applicabile a qualsiasi settore che desideri ottenere informazioni sui clienti da file di testo o vocali registrati che rappresentano registri di chat, e-mail e altre comunicazioni di testo o audio. Abbiamo implementato una pipeline end-to-end per dimostrare il riconoscimento vocale automatico, l'analisi del sentimento in tempo reale e le funzionalità di riqualificazione del modello di elaborazione del linguaggio naturale di apprendimento approfondito su un cluster di calcolo accelerato dalla GPU con storage all-flash NetApp connesso al cloud. È possibile formare e ottimizzare enormi modelli linguistici all'avanguardia per eseguire rapidamente l'inferenza con il centro di supporto globale, al fine di creare un'esperienza del cliente eccezionale e valutazioni obiettive e a lungo termine delle performance dei dipendenti.</block>
  <block id="549c85ede9b39be6ef0eec80db7e098c" category="paragraph">L'analisi del sentimento è un campo di studio all'interno di Natural Language Processing (NLP) attraverso il quale i sentimenti positivi, negativi o neutri vengono estratti dal testo. I sistemi di intelligenza artificiale convergente sono saliti a un livello di integrazione quasi globale man mano che sempre più persone vengono a interagire con loro. L'analisi del sentimento ha una varietà di casi di utilizzo, dalla determinazione delle performance dei dipendenti del centro di supporto nelle conversazioni con i chiamanti e la fornitura di risposte dei chatbot automatizzate appropriate alla previsione del prezzo delle azioni di un'azienda in base alle interazioni tra i rappresentanti dell'azienda e il pubblico alle chiamate trimestrali sui guadagni. Inoltre, l'analisi del sentimento può essere utilizzata per determinare la posizione del cliente sui prodotti, servizi o supporto forniti dal marchio.</block>
  <block id="5855677156d63ad3c93a7b5382098060" category="paragraph">Questa soluzione end-to-end utilizza modelli NLP per eseguire un'analisi del sentimento di alto livello che abilita i framework analitici del centro di supporto. Le registrazioni audio vengono elaborate in testo scritto e il sentimento viene estratto da ciascuna frase della conversazione. I risultati, aggregati in una dashboard, possono essere creati per analizzare i sentimenti delle conversazioni, sia storicamente che in tempo reale. Questa soluzione può essere generalizzata ad altre soluzioni con modalità dati e esigenze di output simili. Con i dati appropriati, è possibile eseguire altri casi di utilizzo. Ad esempio, è possibile analizzare le richieste di guadagno dell'azienda per verificare il sentimento utilizzando la stessa pipeline end-to-end. Altre forme di analisi NLP, come la modellazione topica e il riconoscimento di entità nominate (NER), sono possibili anche grazie alla natura flessibile della pipeline.</block>
  <block id="ea4f750fd9fd89aeff4ca8d4162fb673" category="paragraph">Queste implementazioni di ai sono state rese possibili da NVIDIA RIVA, NVIDIA TAO Toolkit e NetApp DataOps Toolkit che hanno collaborato. I tool NVIDIA vengono utilizzati per implementare rapidamente soluzioni ai dalle performance elevate utilizzando modelli e pipeline precostruiti. Il NetApp DataOps Toolkit semplifica varie attività di gestione dei dati per accelerare lo sviluppo.</block>
  <block id="7a7e97f7fcf4e2974d9a6feee2b056f8" category="section-title">Valore per il cliente</block>
  <block id="3815ef30c3d6c6bdc3862cc9530d091e" category="paragraph">Le aziende vedono il valore di uno strumento di valutazione dei dipendenti e reazione dei clienti per conversazioni testuali, audio e video per l'analisi del sentimento. I manager traggono vantaggio dalle informazioni presentate nella dashboard, consentendo una valutazione dei dipendenti e della soddisfazione dei clienti in base a entrambe le parti della conversazione.</block>
  <block id="da210ea22d819ca26070a3795f9a14d4" category="paragraph">Inoltre, il NetApp DataOps Toolkit gestisce la versione e l'allocazione dei dati all'interno dell'infrastruttura del cliente. Questo porta ad aggiornamenti frequenti delle analisi presentate all'interno della dashboard senza creare costi di storage dei dati ingombranti.</block>
  <block id="e5fcadecc4515efec9267b8ad57b28a5" category="inline-link-macro">Successivo: Casi d'utilizzo.</block>
  <block id="93b7bce28e36a4eebec23c8fd4be315d" category="paragraph"><block ref="93b7bce28e36a4eebec23c8fd4be315d" category="inline-link-macro-rx"></block></block>
  <block id="4c2588a1e3dbf6824a4f05095df75f83" category="paragraph">Anche se tutte le applicazioni di oggi non sono basate sull'intelligenza artificiale, sono in evoluzione funzionalità che consentono loro di accedere agli enormi benefici dell'intelligenza artificiale. Per supportare l'adozione dell'ai, le applicazioni hanno bisogno di un'infrastruttura che fornisca loro le risorse necessarie per funzionare a un livello ottimale e supportare la loro continua evoluzione.</block>
  <block id="31965de7c735983bb41a0b7e70361db2" category="paragraph">Per le applicazioni basate sull'ai, le ubicazioni edge fungono da principale fonte di dati. I dati disponibili possono essere utilizzati per il training se raccolti da più postazioni edge in un determinato periodo di tempo per formare un set di dati di training. Il modello addestrato può quindi essere implementato di nuovo nelle posizioni periferiche in cui sono stati raccolti i dati, consentendo un'inferenza più rapida senza la necessità di trasferire ripetutamente i dati di produzione su una piattaforma di inferenza dedicata.</block>
  <block id="9e53c147a93fed13d4349cba2a35e36b" category="paragraph">La soluzione di inferenza ai di NetApp HCI, basata su nodi di calcolo NetApp H615c con GPU NVIDIA T4 e sistemi storage connessi al cloud, è stata sviluppata e verificata da NetApp e NVIDIA. NetApp HCI semplifica l'implementazione delle soluzioni di inferenza ai nei data center edge affrontando aree di ambiguità, eliminando le complessità di progettazione e finendo con le congetture. Questa soluzione offre alle organizzazioni IT un'architettura prescrittiva che:</block>
  <block id="9c4a53996590c74a0de3bba81f878254" category="list-text">Consente l'inferenza ai nei data center edge</block>
  <block id="20c3f996d396cc8c92788bb3585a6e86" category="list-text">Ottimizza il consumo delle risorse GPU</block>
  <block id="06e81c54cb9157aa59541289f1163daf" category="list-text">Fornisce una piattaforma di deduzione basata su Kubernetes per flessibilità e scalabilità</block>
  <block id="ba37c372c4a9119e45c7f525f4743cfc" category="paragraph">I data center edge gestiscono ed elaborano i dati in posizioni molto vicine al punto di generazione. Questa vicinanza aumenta l'efficienza e riduce la latenza nella gestione dei dati. Molti mercati verticali hanno realizzato i vantaggi di un data center edge e stanno adottando in maniera massicciata questo approccio distribuito all'elaborazione dei dati.</block>
  <block id="b501a0f0a3e7d559cecfad08c330227e" category="paragraph">La seguente tabella elenca i mercati verticali e le applicazioni edge.</block>
  <block id="06ce2a25e5d12c166a36f654dbea6012" category="cell">Verticale</block>
  <block id="1ddf333c6654f7f89c739dddfb4cc429" category="cell">Applicazioni</block>
  <block id="077262cc53a1fb1b5f651d31b6bf81ba" category="cell">Medico</block>
  <block id="9da98fbc1c3d290fefb743a2df8914b4" category="cell">La diagnostica assistita dal computer assiste il personale medico nella diagnosi precoce delle malattie</block>
  <block id="fa0a7aa1622ad105e9cdf5a706058333" category="cell">Petrolio e gas</block>
  <block id="55dae4e2e7f267e43e5768e66c7c3771" category="cell">Ispezione autonoma di impianti di produzione remoti, video e analisi delle immagini</block>
  <block id="252ddb15657f2c60bddc73633a7bf8c0" category="cell">Aviazione</block>
  <block id="7a84f6faf76fd3533ae6ca65d28c53eb" category="cell">Assistenza per il controllo del traffico aereo e analisi dei feed video in tempo reale</block>
  <block id="81ea9456adf225bcf11b668b427fd4f2" category="cell">Contenuti multimediali e di intrattenimento</block>
  <block id="5015819e58d425b19f8acc93866e76fa" category="cell">Filtraggio dei contenuti audio/video per offrire contenuti adatti alle famiglie</block>
  <block id="616e90f12cb95950bc1c75396902393a" category="cell">Analisi del business</block>
  <block id="3e4c06851690089d4952320e9df36dc2" category="cell">Riconoscimento del marchio per analizzare l'aspetto del marchio negli eventi televisivi in streaming live</block>
  <block id="a9f7ecebb493e129aafb4cbfd73e85df" category="cell">E-Commerce</block>
  <block id="5df4fc692c9317012855d6935bf10310" category="cell">Bundle intelligente di offerte di fornitori per trovare combinazioni di merchant e warehouse ideali</block>
  <block id="053e0bc8b9627b28e2ed8029a34b35bd" category="cell">Vendita al dettaglio</block>
  <block id="7cf7816e39e6e0c259a79dc29c5a5e7c" category="cell">Checkout automatizzato per riconoscere gli articoli inseriti nel carrello da un cliente e facilitare il pagamento digitale</block>
  <block id="165f5687ea9050fba239731810d0abe8" category="cell">Città intelligente</block>
  <block id="a47b360ffbe39c5a39c7e12e2ae8fdf5" category="cell">Migliorare il flusso del traffico, ottimizzare il parcheggio e migliorare la sicurezza dei pedoni e dei ciclisti</block>
  <block id="e86883c7cfc07afcf1e5ad8dffd7e1cc" category="cell">Produzione</block>
  <block id="f4d790a35097fa97c2687ac573b25338" category="cell">Controllo di qualità, monitoraggio della linea di assemblaggio e identificazione dei difetti</block>
  <block id="2273d1167a6212812d95dc8fadbae78e" category="cell">Servizio clienti</block>
  <block id="bf4948e47ea0d77a86e639979879262d" category="cell">Automazione del servizio clienti per analizzare e valutare le richieste (telefono, e-mail e social media)</block>
  <block id="8e54e9aa508ea37f7fe734e86ba9da27" category="cell">Agricoltura</block>
  <block id="7fb956270d49b22c3226bc1db2b0269f" category="cell">Pianificazione intelligente delle attività e delle operazioni agricole per ottimizzare l'applicazione di fertilizzanti e erbicida</block>
  <block id="134481f7bea652a34fa2ada120d250e5" category="list-text">Data scientist</block>
  <block id="8d26f0555c7ace3d4b297da8c12fb31b" category="list-text">Architetti IT</block>
  <block id="c114d2813b0041352b49187ebc28b62b" category="list-text">Consulenti sul campo</block>
  <block id="2d6d0cc18609f97853f883c1891397d2" category="list-text">Servizi professionali</block>
  <block id="467f739adb5605167109d76676b44696" category="list-text">Responsabili IT</block>
  <block id="dcfa1c08d3b0126217af0b8690305c08" category="list-text">Chiunque abbia bisogno di un'infrastruttura in grado di offrire innovazione IT e solidi servizi di dati e applicazioni in sedi periferiche</block>
  <block id="ad54e6f7d665098e981d7e41732ce4c2" category="inline-link-macro">Avanti: Architettura</block>
  <block id="dcea35e5c6c7dfb5a3d0b5083bb4bb90" category="paragraph"><block ref="dcea35e5c6c7dfb5a3d0b5083bb4bb90" category="inline-link-macro-rx"></block></block>
  <block id="66bc9494be0116470b223f2e07873f77" category="summary">Questa pagina descrive le attività da completare per implementare un cluster Kubernetes in cui implementare la soluzione NetApp ai Control Plane. Se si dispone già di un cluster Kubernetes, è possibile saltare questa sezione se si utilizza una versione di Kubernetes supportata da Kubeflow e NetApp Trident.</block>
  <block id="2034cc978abb3057c4cf27e92b16ee74" category="doc">Implementazione di Kubernetes</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">Documentazione ufficiale del Kubeflow</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link">Documentazione di Trident</block>
  <block id="7c1ab988344d6a8d8cd9a30d6240955a" category="paragraph">Questa sezione descrive le attività da completare per implementare un cluster Kubernetes in cui implementare la soluzione NetApp ai Control Plane. Se si dispone già di un cluster Kubernetes, è possibile saltare questa sezione se si utilizza una versione di Kubernetes supportata da Kubeflow e NetApp Trident. Per un elenco delle versioni di Kubernetes supportate da Kubeflow, vedere la<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>. Per un elenco delle versioni di Kubernetes supportate da Trident, vedere<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="ef8333b35fd982099a6ca0c7799b5618" category="paragraph">Per le implementazioni on-premise di Kubernetes che incorporano nodi bare-metal con GPU NVIDIA, NetApp consiglia di utilizzare il tool di implementazione DeepOps Kubernetes di NVIDIA. Questa sezione descrive l'implementazione di un cluster Kubernetes utilizzando DeepOps.</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">Prima di eseguire l'esercizio di implementazione descritto in questa sezione, si presuppone che siano già state eseguite le seguenti attività:</block>
  <block id="612cba744b0eac9a7f153d2c4b8975da" category="list-text">Sono già stati configurati nodi Kubernetes bare-metal (ad esempio, un sistema NVIDIA DGX che fa parte di un pod ai ONTAP) in base alle istruzioni di configurazione standard.</block>
  <block id="5a881e8e37e19924ac592136b5e7cfd3" category="inline-link">Sito DeepOps GitHub</block>
  <block id="452f5f6e8da4512f6cce223a76ae3558" category="list-text">È stato installato un sistema operativo supportato su tutti i nodi master e worker di Kubernetes e su un host di distribuzione jump. Per un elenco dei sistemi operativi supportati da DeepOps, vedere<block ref="253a2cf380d7db7eaadb375aa91e2221" category="inline-link-rx"></block>.</block>
  <block id="a711e4ccced882d1762a8c653be8e921" category="section-title">Utilizzare NVIDIA DeepOps per installare e configurare Kubernetes</block>
  <block id="47302a7393e0a038a150e679c9b3e80d" category="paragraph">Per implementare e configurare il cluster Kubernetes con NVIDIA DeepOps, eseguire le seguenti operazioni da un host di distribuzione jump:</block>
  <block id="5c51dc3fcfdd9653809e90fa3948c2f4" category="inline-link">Pagina introduttiva</block>
  <block id="0e91d2e60705ecb1730e9b96510019af" category="list-text">Scaricare NVIDIA DeepOps seguendo le istruzioni sul<block ref="6fb71807bf6999d2aec034d498e3ebf6" category="inline-link-rx"></block> Sul sito NVIDIA DeepOps GitHub.</block>
  <block id="2ed5978807d3da780c60a19b3f38a293" category="inline-link">Pagina della Guida all'implementazione di Kubernetes</block>
  <block id="5c18e4efa8c5cc9efb26e3f748b4e26d" category="list-text">Implementare Kubernetes nel cluster seguendo le istruzioni sul<block ref="b336a8bbad16f0e8d58bf87e261f51fa" category="inline-link-rx"></block> Sul sito NVIDIA DeepOps GitHub.</block>
  <block id="e76934323b48d5421aa2271f7e9fbee2" category="inline-link-macro">Pagina successiva: Panoramica sulla configurazione e sull'implementazione di NetApp Trident.</block>
  <block id="4e3ff90ed271e98a6802a9063034ea76" category="paragraph"><block ref="4e3ff90ed271e98a6802a9063034ea76" category="inline-link-macro-rx"></block></block>
  <block id="ffdaf4e44bdc58181aaa1fb09d821794" category="summary">NVIDIA ai Enterprise con NetApp e VMware - utilizza il software NVIDIA NGC</block>
  <block id="a99b0f81ba7eb4c3316c034815d10d6f" category="doc">Utilizzare il software NVIDIA NGC</block>
  <block id="c9af43d59068b9518707160eb6b96225" category="inline-link-macro">Precedente: Configurazione iniziale.</block>
  <block id="594eb3d3a076d44ee9951aa997704c5a" category="paragraph"><block ref="594eb3d3a076d44ee9951aa997704c5a" category="inline-link-macro-rx"></block></block>
  <block id="4161955dbf0998e264bc502f3cedc932" category="paragraph">Questa sezione descrive le attività da eseguire per utilizzare il software NVIDIA NGC Enterprise in un ambiente NVIDIA ai Enterprise.</block>
  <block id="cdc25880ca2e070e7e8937596a923a72" category="inline-link-macro">Pagina successiva: Installazione.</block>
  <block id="990700dce54370c3a1bca7246dfa67a2" category="paragraph"><block ref="990700dce54370c3a1bca7246dfa67a2" category="inline-link-macro-rx"></block></block>
  <block id="7580f940c2b73a449943bf14cfdb743e" category="summary">Questa pagina descrive la configurazione delle risorse cloud per Azure NetApp Files.</block>
  <block id="9ab9ef31301ca94d2090a6ac7e5141f0" category="doc">Requisiti relativi alle risorse cloud</block>
  <block id="1cee510209f529b7ddd8911bbc6e3ee2" category="inline-link-macro">Precedente: Requisiti software.</block>
  <block id="abab2b04b3822b72d0eeb7b61dd84730" category="paragraph"><block ref="abab2b04b3822b72d0eeb7b61dd84730" category="inline-link-macro-rx"></block></block>
  <block id="00130c4c20e30be7264c0ff0d085261b" category="section-title">Configurare Azure NetApp Files</block>
  <block id="d696f60435e09b1c41d1db77b458999b" category="inline-link">QuickStart: Configurazione di Azure NetApp Files e creazione di un volume NFS</block>
  <block id="b955f251da04c8c868b22cbe7663a4f5" category="paragraph">Configurare Azure NetApp Files come descritto in<block ref="f8525997ced72f3cfd70e1aecf287af9" category="inline-link-rx"></block>.</block>
  <block id="4ee734214d7dd4e522f2aab3d8e3d349" category="paragraph">È possibile passare alla sezione "Crea volume NFS per Azure NetApp Files" perché si stanno creando volumi tramite Trident. Prima di continuare, attenersi alla seguente procedura:</block>
  <block id="b1d13ce152415787185b9f596f9635e1" category="list-text">Registratevi per Azure NetApp Files e per il provider di risorse NetApp (tramite la shell Azure) (<block ref="7a85c4f09a460b2978e2b516b5474576" category="inline-link-rx"></block>).</block>
  <block id="4c21364a09ae3c9dab758e383fcae62d" category="list-text">Creare un account in Azure NetApp Files (<block ref="27e1abf4e17aeb1c0d418f5fee2f2b5f" category="inline-link-rx"></block>).</block>
  <block id="97f203356061531d1acaf022df0d4c3c" category="list-text">Configurare un pool di capacità (un minimo di 4 TB Standard o Premium, a seconda delle esigenze) (<block ref="16f1daa909eef5f1fe1f552d6b28d086" category="inline-link-rx"></block>).la seguente tabella elenca i requisiti di configurazione di rete per l'impostazione nel cloud. Il cluster e Azure NetApp Files devono trovarsi nella stessa rete virtuale Azure o in una rete VNET peered.</block>
  <block id="ddcf50c29294d4414f3f7c1bbc892cb5" category="cell">Risorse</block>
  <block id="3e19b1ddc4033d0c6c439dad720f730d" category="cell">Tipo/versione</block>
  <block id="f938809a358080d4c7a941e59abfca40" category="cell">Servizio Azure Kubernetes</block>
  <block id="f2d1dd8f39098da402272f7606fd2638" category="cell">1.18.14</block>
  <block id="21b6b0c072968b7235d21d8ec72be5dc" category="cell">Nodo dell'agente</block>
  <block id="e5262abb96ddec17ecbca3557e70ea26" category="cell">3x Standard_DS2_v2</block>
  <block id="c64f4eaffc33134095fd3105b3d63832" category="cell">Nodo GPU</block>
  <block id="11fed615c3da90add7abe544e965fa14" category="cell">3x Standard_NC6s_v3</block>
  <block id="7450cfde7058dc5e1f7909d0280fd7ae" category="cell">Azure NetApp Files</block>
  <block id="238f4027146f2469c7d1209e594471e4" category="cell">Pool di capacità standard</block>
  <block id="9163995275052e5abd777ae389b15dfd" category="cell">Capacità in TB</block>
  <block id="a6a0cae93cb8ecdef629c6de5f05989c" category="inline-link-macro">Segue: Riepilogo del caso d'uso previsto con un click-through.</block>
  <block id="a5efee0d52d97830d344cded6ac0bf5c" category="paragraph"><block ref="a5efee0d52d97830d344cded6ac0bf5c" category="inline-link-macro-rx"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">Questo documento descrive un'architettura di calcolo e storage per implementare deduzione di intelligenza artificiale (ai) basata su GPU su storage controller NetApp e server Lenovo ThinkSystem in un ambiente edge che soddisfa gli scenari applicativi emergenti.</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">TR-4886: Ai Inferencing at the Edge - NetApp con Lenovo ThinkSystem - progettazione di soluzioni</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">Sathish Thyagarajan, NetApp Miroslav Hodak, Lenovo</block>
  <block id="290612199861c31d1036b185b4e69b75" category="section-title">Riepilogo</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">Diversi scenari applicativi emergenti, come i sistemi avanzati di assistenza alla guida (ADAS), Industry 4.0, smart cities e Internet of Things (IoT), richiedono l'elaborazione di flussi di dati continui con una latenza quasi nulla. Questo documento descrive un'architettura di calcolo e storage per implementare deduzione di intelligenza artificiale (ai) basata su GPU su storage controller NetApp e server Lenovo ThinkSystem in un ambiente edge che soddisfi questi requisiti. Questo documento fornisce inoltre dati sulle performance per il benchmark MLPerf Inference standard di settore, valutando varie attività di inferenza su edge server dotati di GPU NVIDIA T4. Analizziamo le performance degli scenari di inferenza offline, single stream e multistream e mostriamo che l'architettura con un sistema di storage condiviso in rete a costi contenuti è altamente performante e fornisce un punto centrale per la gestione di dati e modelli per più edge server.</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">Le aziende stanno generando sempre più enormi volumi di dati all'edge della rete. Per ottenere il massimo valore dai sensori intelligenti e dai dati IoT, le organizzazioni sono alla ricerca di una soluzione di streaming di eventi in tempo reale che consenta l'edge computing. I lavori più impegnativi dal punto di vista computazionale vengono quindi eseguiti sempre più all'edge, al di fuori dei data center. L'inferenza dell'ai è uno dei fattori trainanti di questa tendenza. Gli edge server forniscono una potenza di calcolo sufficiente per questi carichi di lavoro, soprattutto quando si utilizzano acceleratori, ma lo storage limitato è spesso un problema, soprattutto negli ambienti multisserver. In questo documento mostreremo come puoi implementare un sistema storage condiviso nell'ambiente edge e in che modo esso benefici per i carichi di lavoro di inferenza ai senza imporre penalizzazioni in termini di performance.</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">Questo documento descrive un'architettura di riferimento per l'inferenza ai ai edge. Combina più edge server Lenovo ThinkSystem con un sistema storage NetApp per creare una soluzione semplice da implementare e gestire. Si tratta di una guida di riferimento per implementazioni pratiche in varie situazioni, come ad esempio il reparto di produzione con telecamere multiple e sensori industriali, sistemi POS (Point of sale) nelle transazioni al dettaglio o sistemi FSD (Full Self-Driving) che identificano anomalie visive nei veicoli autonomi.</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">Il presente documento illustra il test e la convalida di una configurazione di calcolo e storage costituita da un server edge Lenovo ThinkSystem SE350 e da un sistema storage entry-level NetApp AFF ed EF-Series. Le architetture di riferimento offrono una soluzione efficiente e conveniente per le implementazioni ai, fornendo al contempo servizi dati completi, protezione integrata dei dati, scalabilità perfetta e storage dei dati connesso al cloud con NetApp ONTAP e il software di gestione dei dati NetApp SANtricity.</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">Il presente documento è destinato ai seguenti destinatari:</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">Business leader e Enterprise architect che vogliono produrre l'ai alla periferia della rete.</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">Data scientist, data engineer, ricercatori ai/machine learning (ML) e sviluppatori di sistemi ai.</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">Architetti aziendali che progettano soluzioni per lo sviluppo di modelli e applicazioni ai/ML.</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">Data scientist e ingegneri ai alla ricerca di modi efficienti per implementare modelli di deep learning (DL) e ML.</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">Edge Device Manager e amministratori degli edge server responsabili dell'implementazione e della gestione dei modelli di inferenza edge.</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">Architettura della soluzione</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">Questo server Lenovo ThinkSystem e la soluzione di storage NetApp ONTAP o NetApp SANtricity sono progettati per gestire l'inferenza ai su set di dati di grandi dimensioni utilizzando la potenza di elaborazione delle GPU insieme alle CPU tradizionali. Questa convalida dimostra performance elevate e una gestione ottimale dei dati con un'architettura che utilizza uno o più edge server Lenovo SR350 interconnessi con un singolo sistema di storage NetApp AFF, come mostrato nelle due figure seguenti.</block>
  <block id="5174c42549c4dd0407a40298a4d9e362" category="paragraph"><block ref="5174c42549c4dd0407a40298a4d9e362" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aacb24ff7918ccc37aea66f8c9548b68" category="paragraph"><block ref="aacb24ff7918ccc37aea66f8c9548b68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">La panoramica dell'architettura logica nella figura seguente mostra i ruoli degli elementi di calcolo e storage in questa architettura. In particolare, viene mostrato quanto segue:</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">I dispositivi di calcolo edge che eseguono l'inferenza sui dati ricevuti da telecamere, sensori e così via.</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">Un elemento storage condiviso che serve più scopi:</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">Fornisce una posizione centrale per i modelli di inferenza e altri dati necessari per eseguire l'inferenza. I server di calcolo accedono direttamente allo storage e utilizzano modelli di inferenza in tutta la rete senza la necessità di copiarli localmente.</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">I modelli aggiornati vengono inviati qui.</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">Archivia i dati di input ricevuti dagli edge server per un'analisi successiva. Ad esempio, se i dispositivi edge sono collegati alle telecamere, l'elemento di storage mantiene i video acquisiti dalle telecamere.</block>
  <block id="45d9a14c8d568ce70d22acbde8373657" category="paragraph"><block ref="45d9a14c8d568ce70d22acbde8373657" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">rosso</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">blu</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">Sistema di calcolo Lenovo</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">Sistema storage NetApp AFF</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">Dispositivi edge che eseguono deduzione sugli input provenienti da telecamere, sensori e così via.</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">Storage condiviso con modelli di inferenza e dati provenienti da dispositivi edge per analisi successive.</block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">Questa soluzione NetApp e Lenovo offre i seguenti vantaggi principali:</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">La GPU ha accelerato il computing all'edge della rete.</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">Implementazione di più edge server supportata e gestita da uno storage condiviso.</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">Protezione dei dati efficace per soddisfare gli obiettivi RPO (Recovery Point Objective) e RTO (Recovery Time Objective) ridotti senza perdita di dati.</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">Gestione dei dati ottimizzata con copie Snapshot e cloni NetApp per ottimizzare i flussi di lavoro di sviluppo.</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">Come utilizzare questa architettura</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">Questo documento convalida la progettazione e le performance dell'architettura proposta. Tuttavia, non abbiamo testato alcuni componenti a livello di software, come la gestione di container, workload o modelli e la sincronizzazione dei dati con il cloud o il data center on-premise, perché sono specifici di uno scenario di implementazione. In questo caso, esistono diverse scelte.</block>
  <block id="080e5221e660ab18a3746fe480956ebc" category="paragraph">A livello di gestione dei container, Kubernetes Container Management è una buona scelta ed è ben supportato sia in una versione completamente upstream (Canonical) che in una versione modificata adatta per le implementazioni Enterprise (Red Hat). Il <block ref="8ff9014ec7345470e1bb9286d28496e4" category="inline-link-macro-rx"></block> Che utilizza NetApp Trident e il nuovo aggiunto<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block> Offre tracciabilità integrata, funzioni di gestione dei dati, interfacce e strumenti per data scientist e data engineer da integrare con lo storage NetApp. Kubeflow, IL toolkit ML per Kubernetes, offre funzionalità ai aggiuntive, oltre al supporto per il controllo delle versioni dei modelli e KFServing su diverse piattaforme, come TensorFlow Serving o NVIDIA Triton Inference Server. Un'altra opzione è la piattaforma NVIDIA EGX, che offre la gestione dei carichi di lavoro e l'accesso a un catalogo di container di inferenza ai abilitati per GPU. Tuttavia, queste opzioni potrebbero richiedere sforzi ed esperienza significativi per metterle in produzione e potrebbero richiedere l'assistenza di un vendor di software indipendente (ISV) o di un consulente di terze parti.</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="section-title">Aree di soluzione</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">Il vantaggio principale dell'inferenza ai e dell'edge computing è la capacità dei dispositivi di calcolare, elaborare e analizzare i dati con un elevato livello di qualità senza latenza. Esistono troppi esempi di casi d'utilizzo di edge computing da descrivere in questo documento, ma di seguito sono riportati alcuni esempi importanti:</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">Automobili: Veicoli autonomi</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">La classica illustrazione dell'edge computing si trova nei sistemi avanzati di assistenza alla guida (ADAS) nei veicoli autonomi (AV). L'ai nelle auto senza conducente deve elaborare rapidamente una grande quantità di dati provenienti da telecamere e sensori per essere un pilota sicuro e di successo. Un'interpretazione troppo lunga tra un oggetto e un essere umano può significare vita o morte, pertanto è fondamentale essere in grado di elaborare i dati il più vicino possibile al veicolo. In questo caso, uno o più server di calcolo edge gestiscono l'input da telecamere, RADAR, LDAR e altri sensori, mentre lo storage condiviso contiene modelli di inferenza e memorizza i dati di input provenienti dai sensori.</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">Settore sanitario: Monitoraggio dei pazienti</block>
  <block id="a5031cd8ea18cb91370c532194ecd58e" category="paragraph">Uno dei maggiori impatti dell'intelligenza artificiale e dell'edge computing è la sua capacità di migliorare il monitoraggio continuo dei pazienti per le malattie croniche sia nelle strutture di assistenza domiciliare che nelle unità di terapia intensiva (ICU). I dati provenienti da dispositivi periferici che monitorano i livelli di insulina, la respirazione, l'attività neurologica, il ritmo cardiaco e le funzioni gastrointestinali richiedono un'analisi istantanea dei dati che devono essere utilizzati immediatamente, in quanto il tempo necessario per agire è limitato per salvare la vita di qualcuno.</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">Retail: Pagamento senza cassa</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">L'edge computing può potenziare ai e ML per aiutare i retailer a ridurre i tempi di checkout e aumentare il traffico. I sistemi senza cassiere supportano diversi componenti, ad esempio:</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">Autenticazione e accesso. Collegare l'acquirente fisico a un account validato e consentire l'accesso allo spazio di vendita al dettaglio.</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">Monitoraggio dell'inventario. Utilizzo di sensori, tag RFID e sistemi di visione computerizzata per confermare la selezione o la deselezione degli articoli da parte degli acquirenti.</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">In questo caso, ciascuno degli edge server gestisce ciascun contatore di cassa e il sistema di storage condiviso funge da punto di sincronizzazione centrale.</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">Servizi finanziari: Sicurezza umana nei chioschi e prevenzione delle frodi</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">Le organizzazioni bancarie utilizzano l'ai e l'edge computing per innovare e creare esperienze bancarie personalizzate. I chioschi interattivi che utilizzano l'analisi dei dati in tempo reale e l'inferenza ai consentono ora agli ATM non solo di aiutare i clienti a prelevare denaro, ma anche di monitorare in modo proattivo i chioschi attraverso le immagini acquisite dalle telecamere per identificare i rischi per la sicurezza umana o i comportamenti fraudolenti. In questo scenario, i server di calcolo edge e i sistemi storage condivisi sono collegati a chioschi e telecamere interattivi per aiutare le banche a raccogliere ed elaborare i dati con modelli di inferenza ai.</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">Produzione: Settore 4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">È iniziata la quarta rivoluzione industriale (Industry 4.0), insieme a trend emergenti come Smart Factory e stampa 3D. Per prepararsi a un futuro basato sui dati, la comunicazione machine-to-machine (M2M) e l'IoT su larga scala sono integrati per una maggiore automazione senza la necessità di un intervento umano. La produzione è già altamente automatizzata e l'aggiunta di funzionalità di ai è una naturale continuazione della tendenza a lungo termine. L'ai consente di automatizzare le operazioni che possono essere automatizzate con l'aiuto di computer Vision e altre funzionalità di ai. È possibile automatizzare il controllo di qualità o le attività che si basano sulla visione umana o sul processo decisionale per eseguire analisi più rapide dei materiali sulle linee di assemblaggio nei piani della fabbrica, in modo da aiutare gli impianti di produzione a soddisfare gli standard ISO richiesti per la gestione della qualità e della sicurezza. In questo caso, ogni edge server di calcolo è connesso a un array di sensori che monitorano il processo di produzione e i modelli di inferenza aggiornati vengono inviati allo storage condiviso, in base alle necessità.</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">Telecomunicazioni: Rilevamento della ruggine, ispezione della torre e ottimizzazione della rete</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">Il settore delle telecomunicazioni utilizza tecniche di visione computerizzata e ai per elaborare immagini che rilevano automaticamente la ruggine e identificano le torri cellulari che contengono corrosione e, di conseguenza, richiedono un'ulteriore ispezione. Negli ultimi anni è aumentato l'utilizzo di immagini drone e modelli ai per identificare regioni distinte di una torre per analizzare ruggine, crepe superficiali e corrosione. La domanda continua a crescere per le tecnologie ai che consentono di ispezionare in modo efficiente l'infrastruttura di telecomunicazione e i ripetitori cellulari, valutarne regolarmente il degrado e ripararli tempestivamente quando necessario.</block>
  <block id="50dba7db75064ae2e0beea487226ed46" category="paragraph">Inoltre, un altro caso d'utilizzo emergente nel settore delle telecomunicazioni è l'utilizzo di algoritmi ai e ML per prevedere i modelli di traffico dati, rilevare i dispositivi compatibili con il 5G e automatizzare e aumentare la gestione dell'energia MIMO (Multiple-Input and Multiple-Output). L'hardware MIMO viene utilizzato nelle radio tower per aumentare la capacità di rete, ma ciò comporta costi energetici aggiuntivi. I modelli ML per la "modalità di sospensione MIMO" implementati nei siti cellulari possono prevedere l'utilizzo efficiente delle radio e contribuire a ridurre i costi di consumo energetico per gli operatori di reti mobili (MNOS). Le soluzioni di inferenza ai e edge computing aiutano gli MNOS a ridurre la quantità di dati trasmessi avanti e indietro ai data center, ridurre il TCO, ottimizzare le operazioni di rete e migliorare le performance complessive per gli utenti finali.</block>
  <block id="f45c430b02aac052aef8d958c80ff351" category="paragraph"><block ref="f45c430b02aac052aef8d958c80ff351" category="inline-link-macro-rx"></block></block>
  <block id="a905494ad30a6d54678a2122c04bfd54" category="summary">Esempi di notebook Jupyter e pipeline Kubeflow</block>
  <block id="80e94617849fe0b057f3edcc76a6ac72" category="doc">Esempi di notebook e pipeline</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">NetApp Data Science Toolkit per Kubernetes</block>
  <block id="3da57858cd6a76521b38784effc6a06f" category="paragraph">Il<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> Utilizzabile in combinazione con Kubeflow. L'utilizzo del NetApp Data Science Toolkit con Kubeflow offre i seguenti vantaggi:</block>
  <block id="624a53dc5871ce49612a285ee2bf367e" category="list-text">I data scientist possono eseguire operazioni avanzate di gestione dei dati NetApp direttamente da un Jupyter notebook.</block>
  <block id="1c7d37cb415e8b7777b071784911a77a" category="list-text">Le operazioni avanzate di gestione dei dati NetApp possono essere incorporate nei flussi di lavoro automatizzati utilizzando il framework Kubeflow Pipeline.</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Esempi di Kubeflow</block>
  <block id="987823970c7b662272fb9e0058bf5ff1" category="paragraph">Fare riferimento a.<block ref="3eb5d4ffd5360858e22dfb9799f211d7" category="inline-link-rx"></block> Sezione all'interno del repository GitHub del NetApp Data Science Toolkit per informazioni dettagliate sull'utilizzo del toolkit con Kubeflow.</block>
  <block id="52a739b78342bd0cef8801d4c5c193b6" category="inline-link-macro">Avanti: Implementazione di Apache Airflow.</block>
  <block id="6564dd7688129caf4acb63587998eb65" category="paragraph"><block ref="6564dd7688129caf4acb63587998eb65" category="inline-link-macro-rx"></block></block>
  <block id="bd9091c7320e4b1069eed28f04839354" category="paragraph">Quando si creano pipeline ai/ML personalizzate, configurare l'integrazione, la gestione, la sicurezza e l'accessibilità dei componenti in un'architettura è un'attività complessa. Fornire agli sviluppatori l'accesso e il controllo del proprio ambiente presenta un'altra serie di sfide.</block>
  <block id="820423ca1ad0e872ef04cbb366b6e3de" category="paragraph">La combinazione di NetApp e Iguazio riunisce queste tecnologie come servizi gestiti per accelerare l'adozione della tecnologia e migliorare il time-to-market per le nuove applicazioni ai/ML.</block>
  <block id="b0a9c7dc36cb18f93679b833533b9936" category="paragraph"><block ref="b0a9c7dc36cb18f93679b833533b9936" category="inline-link-macro-rx"></block></block>
  <block id="adb2100439d02c2978c4a5670cda87b8" category="summary">In questa pagina sono elencate le librerie e i framework utilizzati per creare questa attività. Tutti questi componenti sono stati completamente integrati con i controlli di sicurezza e accesso basati sui ruoli di Azure.</block>
  <block id="235ff38f40d20846e27b4c64e964ce28" category="doc">Librerie per l'elaborazione dei dati e la formazione sui modelli</block>
  <block id="542e61809d35e9c83a99b29c87aa40fb" category="inline-link-macro">Precedente: Livelli di performance Azure NetApp Files.</block>
  <block id="b7fe935ab4f924b870ae1983e3f3a271" category="paragraph"><block ref="b7fe935ab4f924b870ae1983e3f3a271" category="inline-link-macro-rx"></block></block>
  <block id="c4e831049faaa8b89e89eebd0a105dab" category="paragraph">La tabella seguente elenca le librerie e i framework utilizzati per creare questa attività. Tutti questi componenti sono stati completamente integrati con i controlli di sicurezza e accesso basati sui ruoli di Azure.</block>
  <block id="faeae27c134f5193efb923d2492daa47" category="cell">Librerie/framework</block>
  <block id="b540cdb28de9a6c72ef1a92504e69423" category="cell">CuML di Dask</block>
  <block id="1fc1b4b6567949aab2cb7e6fecb1e68f" category="inline-link">Libreria cuML</block>
  <block id="efe85bbaa5690074ea98a2bfef62d930" category="cell">Per CONSENTIRE A ML di lavorare su GPU, il<block ref="514c908f6fc3f426a00e1dabdf37831f" category="inline-link-rx"></block> Fornisce l'accesso al pacchetto RAPIDS cuML con DAK. RAPIDS cuML implementa i più diffusi algoritmi ML, tra cui clustering, riduzione delle dimensioni e approcci di regressione, con implementazioni basate su GPU ad alte performance, che offrono velocità fino a 100 volte superiori rispetto agli approcci basati su CPU.</block>
  <block id="ede0db3d6c9043439d0762ee99543654" category="cell">Dask cuDF</block>
  <block id="a9c380d6e09cc11f858b53d56cf69da4" category="inline-link">libreria dask-cudf</block>
  <block id="13a7d0199f9797a3533ff335da46b446" category="cell">CuDF include diverse altre funzioni che supportano l'estrazione, la trasformazione, il carico (ETL) con accelerazione GPU, come il sottosetting dei dati, le trasformazioni, la codifica one-hot e molto altro ancora. Il team RAPIDS gestisce un<block ref="836818db4e43067816d31d2b73198787" category="inline-link-rx"></block> Sono inclusi i metodi di supporto per l'utilizzo di Dask e cuDF.</block>
  <block id="0c9c2e873df681f1ab5b13053be78af7" category="cell">Scikit Impara</block>
  <block id="cd1235fc9b090edba051d73dbc6f66bf" category="inline-link">stimatore</block>
  <block id="1977c9daa1d67de51a4651abdb160c09" category="inline-link">adatta</block>
  <block id="4f54da5a2c4a796e8215f20eb95fddcc" category="cell">Scikit-Learn offre decine di algoritmi e modelli di apprendimento automatico integrati, chiamati stimatori. Ciascuno<block ref="855747fa3f470c1754852d09071dd101" category="inline-link-rx"></block> può essere adattato ad alcuni dati utilizzando its<block ref="e52e604a9dbe357e0fb9bc58f4b62add" category="inline-link-rx"></block> metodo.</block>
  <block id="0dd4d530afb3c99ab869350770d7bebd" category="paragraph">Abbiamo utilizzato due notebook per costruire LE pipeline ML per il confronto; uno è l'approccio convenzionale Pandas scikit-Learn e l'altro è la formazione distribuita con RAPIDS e Dask. Ciascun notebook può essere testato singolarmente per verificarne le prestazioni in termini di tempo e scalabilità. Copriamo ogni notebook singolarmente per dimostrare i vantaggi della formazione distribuita utilizzando RAPIDS e Dask.</block>
  <block id="7dd297826f91c438fab12307224d2c40" category="inline-link-macro">Segue: Caricare i registri di clic di Criteo giorno 15 in Pandas e formare un modello di foresta casuale di scikit-learn.</block>
  <block id="ade9906123700a8bf734457510b6b3c8" category="paragraph"><block ref="ade9906123700a8bf734457510b6b3c8" category="inline-link-macro-rx"></block></block>
  <block id="01360221b637a04fa184dc6b9355fa46" category="summary">Come parte della creazione di questa soluzione, abbiamo eseguito un semplice confronto delle performance. Utilizzando Kubernetes, abbiamo eseguito diversi processi di benchmarking standard di NetApp e abbiamo confrontato i risultati del benchmark con le esecuzioni eseguite utilizzando un semplice comando di esecuzione di Docker.</block>
  <block id="0e2f0f77407bfd956f621e13b8c1be34" category="doc">Test delle performance</block>
  <block id="467941822b3a557a8db7197e12285f14" category="paragraph">Come parte della creazione di questa soluzione, abbiamo eseguito un semplice confronto delle performance. Utilizzando Kubernetes, abbiamo eseguito diversi processi di benchmarking ai standard di NetApp e abbiamo confrontato i risultati del benchmark con le esecuzioni eseguite utilizzando un semplice comando di esecuzione di Docker. Non sono state riscontrate differenze significative in termini di performance. Pertanto, abbiamo concluso che l'utilizzo di Kubernetes per orchestrare i lavori di training ai containerizzati non influisce negativamente sulle performance. Consulta la tabella seguente per i risultati del nostro confronto delle performance.</block>
  <block id="74575b23d5305310e904f87eb02ff980" category="cell">Benchmark</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">Dataset</block>
  <block id="c269688995d2959579fca276425898b8" category="cell">Esecuzione Docker (immagini/sec)</block>
  <block id="b3acbf223e2bb7a3a796e3b698a7748d" category="cell">Kubernetes (immagini/sec)</block>
  <block id="6de4dbc350a60fb9d5ea80ac7854681d" category="cell">TensorFlow a nodo singolo</block>
  <block id="2ec7cdace40d8a092e842288dfe854f7" category="cell">Dati sintetici</block>
  <block id="a5ee9f5535788c17b947b7f2d8354351" category="cell">6,667.2475</block>
  <block id="b573d76a35b8d44de29524f11e873c60" category="cell">6,661.93125</block>
  <block id="b318879f822314efe94c2f096d06465c" category="cell">ImageNet</block>
  <block id="f9622443c76d58838af97acd4f0c12ed" category="cell">6,570.2025</block>
  <block id="f93ed9c22230ae6e2ed85323e8d3dff7" category="cell">6,530.59125</block>
  <block id="83817408eae44458daefc1a9516ad170" category="cell">Synchronous Distributed Two-Node TensorFlow</block>
  <block id="d4b63997154f30598f823403bb4df7ba" category="cell">13,213.70625</block>
  <block id="a328a929a422e4b69be5bbe94694282e" category="cell">13,218.288125</block>
  <block id="209f721713f475a9a0f4ba2743b40853" category="cell">12,941.69125</block>
  <block id="1f07dab13107a813c6d35bb76648ec48" category="cell">12,881.33875</block>
  <block id="68cba59815f152ec72363e2495bab8d2" category="paragraph"><block ref="68cba59815f152ec72363e2495bab8d2" category="inline-link-macro-rx"></block></block>
  <block id="91bc87f1c8c087219cec868bb9eec3e7" category="summary">Per questa convalida, abbiamo eseguito la deduzione per un caso d'utilizzo di rilevamento dell'immagine utilizzando un set di immagini raw. Quindi, abbiamo eseguito la stessa attività di deduzione sullo stesso set di immagini con l'aggiunta dell'offuscamento di Protopia prima dell'inferenza. Abbiamo ripetuto l'attività utilizzando diversi valori DI ALPHA per la componente di offuscamento Protopia.</block>
  <block id="f63c4677c27e0489f346c0711720cc39" category="doc">Confronto della precisione delle deduzione</block>
  <block id="5e2777e1d5ba6adfeabc55064de508f5" category="inline-link-macro">Precedente: Procedura di test.</block>
  <block id="c06030c36071611ee2f3a9a21205eaf8" category="paragraph"><block ref="c06030c36071611ee2f3a9a21205eaf8" category="inline-link-macro-rx"></block></block>
  <block id="0c71eb4e1fba60fba81db988197da57d" category="paragraph">Per questa convalida, abbiamo eseguito la deduzione per un caso d'utilizzo di rilevamento dell'immagine utilizzando un set di immagini raw. Quindi, abbiamo eseguito la stessa attività di deduzione sullo stesso set di immagini con l'aggiunta dell'offuscamento di Protopia prima dell'inferenza. Abbiamo ripetuto l'attività utilizzando diversi valori DI ALPHA per la componente di offuscamento Protopia. Nel contesto dell'offuscamento di Protopia, il valore ALFA rappresenta la quantità di offuscamento applicata, con un valore ALFA più alto che rappresenta un livello più elevato di offuscamento. Abbiamo quindi confrontato la precisione delle deduzione in queste diverse esecuzioni.</block>
  <block id="93d52a2c23957d4188c7b2ce8b2ae884" category="paragraph">Le due tabelle seguenti forniscono dettagli sul nostro caso di utilizzo e delineano i risultati.</block>
  <block id="65a3419ae19e457df9db4c0e110b2538" category="paragraph">Protopia collabora direttamente con i clienti per determinare il valore ALFA appropriato per un caso di utilizzo specifico.</block>
  <block id="e558777bd1568637c97294a33389e930" category="cell">FaceBoxes (PyTorch) -</block>
  <block id="20172a059ee71423ad0d94393e819e10" category="cell">Dataset FDDB</block>
  <block id="06a8fb4576a28a6488c929097c870fe1" category="cell">Offuscamento di Protopia</block>
  <block id="002101f8725e5c78d9f30d87f3fa4c87" category="cell">ALFA</block>
  <block id="d78f1fb7e69f7cddcf3e168f2663db20" category="cell">Precisione</block>
  <block id="646738dcd35eaf5c3f3c9bfdc6a90b78" category="cell">0.9337148153739079</block>
  <block id="b14399cbaac6da4b5b733b483106383f" category="cell">0.05</block>
  <block id="bcf8c22771ff8c7065180f5a6526d4a6" category="cell">0.9028766627325002</block>
  <block id="cb5ae17636e975f9bf71ddf5bc542075" category="cell">0.1</block>
  <block id="1336b1cb08d93aa0a453c53e27efa594" category="cell">0.9024301009661478</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0.2</block>
  <block id="b1cb1b288bfae3850c74795f5691dc4e" category="cell">0.9081836283186224</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0.4</block>
  <block id="b9e8c964d5c5d3e7c815896cd6235239" category="cell">0.9073066107482036</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0.6</block>
  <block id="57489d9101ec373d9e2841292a5b3af9" category="cell">0.8847816568680239</block>
  <block id="57eeec0a6974ecb4e9fcf68fab052f7b" category="cell">0.8</block>
  <block id="8ab8d7756b82eb70d635bc66c1bc532b" category="cell">0.8841195749171925</block>
  <block id="a894124cc6d5c5c71afe060d5dde0762" category="cell">0.9</block>
  <block id="226cc0951c1f30973a4c71f0f567936a" category="cell">0.8455427675252052</block>
  <block id="248a7444f08189bb31ba143eabebe4e5" category="cell">0.95</block>
  <block id="0f39c006b0d74178bc826c1d567a79dc" category="inline-link-macro">Avanti: Velocità di offuscamento.</block>
  <block id="ca9c4b25b025c5564f5ffb65a712a47c" category="paragraph"><block ref="ca9c4b25b025c5564f5ffb65a712a47c" category="inline-link-macro-rx"></block></block>
  <block id="fb0e25ed6b061ae8d5a55a94457e445e" category="summary">Per questa convalida, abbiamo applicato l'offuscamento di Protopia a un'immagine da 1920 x 1080 pixel cinque volte e misurato il tempo necessario per completare ogni volta la fase di offuscamento.</block>
  <block id="9c6852dd5556b48ff70dd2583a5d3aa0" category="doc">Velocità di offuscamento</block>
  <block id="237d31dab91fe077925e5102e132072f" category="inline-link-macro">Precedente: Confronto della precisione delle deduzione.</block>
  <block id="6e3fd8b18c15e04e41fb57acfcafc5aa" category="paragraph"><block ref="6e3fd8b18c15e04e41fb57acfcafc5aa" category="inline-link-macro-rx"></block></block>
  <block id="d6edf1cfcac22abc6c577706f85eb816" category="paragraph">Per questa convalida, abbiamo applicato l'offuscamento di Protopia a un'immagine da 1920 x 1080 pixel cinque volte e misurato il tempo necessario per completare ogni volta la fase di offuscamento. Abbiamo utilizzato PyTorch in esecuzione su una singola GPU NVIDIA V100 per applicare l'offuscamento e abbiamo cancellato la cache della GPU tra un'esecuzione e l'altra. La fase di offuscamento ha richiesto rispettivamente 5,47 ms, 5,27 ms, 4,54 ms, 5,24 ms e 4,84 ms per completare le cinque corse. La velocità media è stata di 5,072 ms.</block>
  <block id="eee25724989c730f34a19e19a1db23b2" category="paragraph"><block ref="eee25724989c730f34a19e19a1db23b2" category="inline-link-macro-rx"></block></block>
  <block id="fcd8d375e90bbb5d8febe3b3eac09c2b" category="doc">Dove trovare informazioni aggiuntive, riconoscimenti e cronologia delle versioni</block>
  <block id="86a4acc956f71e307a08f732dd442d3f" category="paragraph"><block ref="86a4acc956f71e307a08f732dd442d3f" category="inline-link-macro-rx"></block></block>
  <block id="f85150beb9ce598095b212b1de60815f" category="list-text">Software per la gestione dei dati NetApp ONTAP: Libreria di informazioni ONTAP</block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">Storage persistente NetApp per container - NetApp Trident</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="2cd8f6bd0ec1bbc37315b8bc134e16c5" category="list-text">Storage persistente NetApp per container: NetApp Astra Trident</block>
  <block id="89f170193efdf8434f549c8e91adf860" category="list-text">Protopia ai: Inferenza riservata</block>
  <block id="62faa8d62bfb6098877b809cce925de5" category="inline-link"><block ref="62faa8d62bfb6098877b809cce925de5" category="inline-link-rx"></block></block>
  <block id="45b79877f4c11139882c88df94d50fa6" category="paragraph"><block ref="45b79877f4c11139882c88df94d50fa6" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="2c5e74d45708e2fae638e03f88353b75" category="list-text">Server di inferenza NVIDIA Triton</block>
  <block id="2c54e28a12ce15452929a28550a30a96" category="inline-link"><block ref="2c54e28a12ce15452929a28550a30a96" category="inline-link-rx"></block></block>
  <block id="bc5345c4517d46bdf8a87f10d404839f" category="paragraph"><block ref="bc5345c4517d46bdf8a87f10d404839f" category="inline-link-rx"></block></block>
  <block id="fba4b133e329411c361e02e05efed0b9" category="list-text">Documentazione di NVIDIA Triton Inference Server</block>
  <block id="cce40efbd4a717916ccbab694b676e9c" category="inline-link"><block ref="cce40efbd4a717916ccbab694b676e9c" category="inline-link-rx"></block></block>
  <block id="170ba65f4e4807f3643de39afb3f2e16" category="paragraph"><block ref="170ba65f4e4807f3643de39afb3f2e16" category="inline-link-rx"></block></block>
  <block id="ba1d5cc71378020998752955821460b2" category="list-text">FaceBoxes in PyTorch</block>
  <block id="ace8d80d2ede0fadf07325408b376b83" category="inline-link"><block ref="ace8d80d2ede0fadf07325408b376b83" category="inline-link-rx"></block></block>
  <block id="a688d324b63c4f882d06673058aa2f61" category="paragraph"><block ref="a688d324b63c4f882d06673058aa2f61" category="inline-link-rx"></block></block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="section-title">Ringraziamenti</block>
  <block id="121ef407a6a3c08ce9fa247e382d7637" category="list-text">Mark Cates, Principal Product Manager, NetApp</block>
  <block id="fb345adb43ea24ffc891d20327bdca09" category="list-text">Sufian Ahmad, Technical Marketing Engineer, NetApp</block>
  <block id="711ba3fec382e550526a6ab0f49bdf3a" category="list-text">Hadi Esmaeilzadeh, Chief Technology Officer e Professor, Protopia ai</block>
  <block id="0844bd2427e754de1d07ca91d15284a5" category="cell">Cronologia delle versioni del documento</block>
  <block id="b56a5394775a9f077c12cb3e770d913c" category="cell">Maggio 2022</block>
  <block id="1f599c1b266e901a2c8d38e266e23c6f" category="summary">Questa sezione descrive i risultati dettagliati della procedura di test.</block>
  <block id="c87fa6e515cf0976291b387e5a8ab6f6" category="doc">Procedura di test e risultati dettagliati</block>
  <block id="e46c1f341c1cea1321f4c00d15e90b0d" category="inline-link-macro">Precedente: Test della configurazione.</block>
  <block id="5a05f12c2c7f8b9ff569496691352e05" category="paragraph"><block ref="5a05f12c2c7f8b9ff569496691352e05" category="inline-link-macro-rx"></block></block>
  <block id="b70dd619781891706b7d2f44c418a2b5" category="section-title">Training per il riconoscimento delle immagini con ResNet in ONTAP</block>
  <block id="bf523bb892b07c71c90bd7ea34a091a9" category="paragraph">Abbiamo eseguito il benchmark ResNet50 con uno e due server SR670 V2. Questo test ha utilizzato il container NGC MXNet 22.04-py3 per eseguire il training.</block>
  <block id="a08c4eedb9047aae68f44b82037739b0" category="paragraph">In questa convalida abbiamo utilizzato la seguente procedura di test:</block>
  <block id="df1a5f60f20e6aa3336812f58095e04f" category="list-text">Abbiamo cancellato la cache dell'host prima di eseguire lo script per assicurarsi che i dati non fossero già memorizzati nella cache:</block>
  <block id="ab93a65fabd2eaae21f5a6e097320730" category="list-text">Abbiamo eseguito lo script di benchmark con il set di dati ImageNet nello storage server (storage SSD locale) e nel sistema di storage NetApp AFF.</block>
  <block id="9f98453c4a6eede45b87d72527b49e7e" category="list-text">Abbiamo validato le performance dello storage locale e di rete utilizzando<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> comando.</block>
  <block id="47b048d9dcf1d84d76bddb033b842b3b" category="list-text">Per l'esecuzione a nodo singolo, è stato utilizzato il seguente comando:</block>
  <block id="014e128029d9142b6957ca4f1b291090" category="list-text">Per le esecuzioni distribuite, abbiamo utilizzato il modello di parallelizzazione del server dei parametri. Abbiamo utilizzato due server di parametri per nodo e abbiamo impostato il numero di epoch in modo che sia uguale a quello dell'esecuzione a nodo singolo. Abbiamo fatto questo perché la formazione distribuita spesso richiede più epoche a causa della sincronizzazione imperfetta tra i processi. Il diverso numero di epoche può alterare i confronti tra casi a nodo singolo e distribuiti.</block>
  <block id="8f74be345dbaeac65cc3a488503b2a1f" category="section-title">Velocità di lettura dei dati: Storage locale o di rete</block>
  <block id="16d8fe364e1a7846c093983bec75e764" category="paragraph">La velocità di lettura è stata testata utilizzando<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> Su uno dei file per il dataset ImageNet. Nello specifico, abbiamo eseguito i seguenti comandi per i dati locali e di rete:</block>
  <block id="c685a224eb9a88c5b7bd2be45fe5a128" category="paragraph">Entrambi i valori sono simili, a dimostrazione del fatto che lo storage di rete è in grado di fornire dati a una velocità simile allo storage locale.</block>
  <block id="aa613e8f689a1a64605aef401595bfd2" category="section-title">Caso d'utilizzo condiviso: Processi multipli, indipendenti e simultanei</block>
  <block id="7e4312d3e922a98bfc1dc4a84c80f12c" category="paragraph">Questo test ha simulato il caso d'utilizzo previsto per questa soluzione: Training ai multi-job e multi-utente. Ogni nodo ha eseguito il proprio training durante l'utilizzo dello storage di rete condiviso. I risultati vengono visualizzati nella seguente figura, che mostra che il caso della soluzione ha fornito prestazioni eccellenti con tutti i lavori eseguiti essenzialmente alla stessa velocità dei singoli lavori. Il throughput totale è stato scalato in modo lineare con il numero di nodi.</block>
  <block id="2b9215e7cc3c2422637b6f95b0d47d97" category="inline-image-macro">Questa figura mostra le immagini aggregate al secondo.</block>
  <block id="5224aacbc4b8472eb40ead3ee8856b90" category="paragraph"><block ref="5224aacbc4b8472eb40ead3ee8856b90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f5fcaaad259a917b031b3169cd5ad4" category="inline-image-macro">Questa figura mostra il runtime in pochi minuti.</block>
  <block id="8255e8c790967568129f1f898048f1c5" category="paragraph"><block ref="8255e8c790967568129f1f898048f1c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="289b386724c768cabf5ad786a3842335" category="paragraph">Questi grafici mostrano il runtime in pochi minuti e le immagini aggregate al secondo per i nodi di calcolo che utilizzavano otto GPU da ciascun server su reti client da 100 GbE, combinando sia il modello di training simultaneo che il modello di training singolo. Il tempo di esecuzione medio per il modello di training è stato di 35 minuti e 9 secondi. I singoli tempi di esecuzione erano di 34 minuti e 32 secondi, 36 minuti e 21 secondi, 34 minuti e 37 secondi, 35 minuti e 25 secondi, 34 minuti e 31 secondi. Le immagini medie al secondo per il modello di training erano 22,573, mentre le singole immagini al secondo erano 21,764, 23,438, 22,556, 22,564 e 22,547.</block>
  <block id="ce47a442fe1dc7c09bf9a3ec5ed71236" category="paragraph">In base alla nostra convalida, un modello di training indipendente con data runtime NetApp è stato di 34 minuti e 54 secondi con 22,231 immagini/sec. Un modello di training indipendente con runtime dati locali (DAS) è stato di 34 minuti e 21 secondi con 22,102 immagini/sec. Durante queste operazioni, l'utilizzo medio della GPU è stato del 96%, come osservato su nvidia-smi. Si noti che questa media include la fase di test, durante la quale le GPU non sono state utilizzate, mentre l'utilizzo della CPU è stato del 40% come misurato da mpstat. Ciò dimostra che la velocità di erogazione dei dati è sufficiente in ogni caso.</block>
  <block id="f63534f8e2150e0624ee2af349f77999" category="inline-link-macro">Avanti: Modifiche dell'architettura.</block>
  <block id="92a7087794ac4c23f482ff2db8cf1742" category="paragraph"><block ref="92a7087794ac4c23f482ff2db8cf1742" category="inline-link-macro-rx"></block></block>
  <block id="10dedd24e41d2fa9b5a5e681dd5b4882" category="summary">Questa pagina contiene informazioni di base su come NetApp può promuovere i progetti ai, incluse informazioni su container, Kubernetes, NetApp Trident e altro ancora.</block>
  <block id="0b7e964d1176d21b9ba3eceec8ed95ac" category="doc">Concetti e componenti</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">L'ai è una disciplina informatica in cui i computer sono formati per imitare le funzioni cognitive della mente umana. Gli sviluppatori di ai addestrano i computer per imparare e risolvere i problemi in modo simile o addirittura superiore agli esseri umani. Il deep learning e l'apprendimento automatico sono sottocampi dell'ai. Le organizzazioni stanno adottando sempre più ai, ML e DL per supportare le loro esigenze aziendali critiche. Di seguito sono riportati alcuni esempi:</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">Analisi di grandi quantità di dati per scoprire informazioni di business precedentemente sconosciute</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">Interagire direttamente con i clienti utilizzando l'elaborazione del linguaggio naturale</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">Automazione di vari processi e funzioni di business</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">I moderni carichi di lavoro di training e inferenza ai richiedono funzionalità di calcolo estremamente parallele. Pertanto, le GPU vengono sempre più utilizzate per eseguire le operazioni ai perché le funzionalità di elaborazione parallela delle GPU sono notevolmente superiori a quelle delle CPU generiche.</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">I container sono istanze isolate dello spazio utente eseguite su un kernel del sistema operativo host condiviso. L'adozione dei container è in rapida crescita. I container offrono molti degli stessi vantaggi offerti dalle macchine virtuali (VM) per il sandboxing delle applicazioni. Tuttavia, poiché l'hypervisor e i livelli del sistema operativo guest su cui si basano le macchine virtuali sono stati eliminati, i container sono molto più leggeri. La figura seguente mostra una visualizzazione delle macchine virtuali rispetto ai container.</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Sito web di Docker</block>
  <block id="da28cd415837c7f3d1d6221ff490b84b" category="paragraph">I container consentono inoltre un efficiente packaging delle dipendenze delle applicazioni, dei tempi di esecuzione e così via, direttamente con un'applicazione. Il formato di packaging dei container più comunemente utilizzato è Docker Container. Un'applicazione che è stata containerizzata nel formato Docker container può essere eseguita su qualsiasi computer in grado di eseguire i container Docker. Ciò è vero anche se le dipendenze dell'applicazione non sono presenti sul computer perché tutte le dipendenze sono contenute nel container stesso. Per ulteriori informazioni, visitare il<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block>.</block>
  <block id="9c3d617029ed075512781527983e01e4" category="paragraph"><block ref="9c3d617029ed075512781527983e01e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">Sito web di Kubernetes</block>
  <block id="7a1446916a360f9c8ae3b94a97ad8c86" category="paragraph">Kubernetes è una piattaforma open source, distribuita e di orchestrazione dei container, originariamente progettata da Google e ora gestita dalla Cloud Native Computing Foundation (CNCF). Kubernetes consente l'automazione delle funzioni di implementazione, gestione e scalabilità per le applicazioni containerizzate. Negli ultimi anni, Kubernetes è emersa come piattaforma dominante per l'orchestrazione di container. Sebbene siano supportati altri formati di packaging dei container e tempi di esecuzione, Kubernetes viene spesso utilizzato come sistema di orchestrazione per i container Docker. Per ulteriori informazioni, visitare il<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block>.</block>
  <block id="6ea70a0ecace7daa9dfbbc8ff3282de1" category="inline-link">Sito web di Trident</block>
  <block id="f9b736ec48694a34e744a1a0309602bd" category="paragraph">Trident è un orchestratore di storage open source sviluppato e gestito da NetApp che semplifica notevolmente la creazione, la gestione e il consumo dello storage persistente per i carichi di lavoro Kubernetes. Trident, un'applicazione nativa di Kubernetes, viene eseguita direttamente all'interno di un cluster Kubernetes. Con Trident, gli utenti di Kubernetes (sviluppatori, data scientist, amministratori di Kubernetes e così via) possono creare, gestire e interagire con volumi di storage persistenti nel formato standard di Kubernetes che già conoscono. Allo stesso tempo, possono sfruttare le funzionalità avanzate di gestione dei dati di NetApp e un data fabric basato sulla tecnologia NetApp. Trident astratta le complessità dello storage persistente e lo rende semplice da utilizzare. Per ulteriori informazioni, visitare il<block ref="ad5406ed69f3fe0de810f757310402c9" category="inline-link-rx"></block>.</block>
  <block id="47bbe104ad41e6af2ee0dba5dc76d74d" category="inline-link">Sito Web di DeepOps</block>
  <block id="b1c5aef0d1e7ec0339ca5caa48c1b3e3" category="paragraph">DeepOps è un progetto open source di NVIDIA che, utilizzando Ansible, automatizza l'implementazione dei cluster di server GPU in base alle Best practice. DeepOps è modulare e può essere utilizzato per varie attività di implementazione. Per questo documento e per l'esercizio di convalida descritto, DeepOps viene utilizzato per implementare un cluster Kubernetes costituito da nodi di lavoro del server GPU. Per ulteriori informazioni, visitare il<block ref="640792bfd91bad987ba8fd5d776a2824" category="inline-link-rx"></block>.</block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="section-title">Kubeflow</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Sito web di Kubeflow</block>
  <block id="ea77b50ef31a778a66411b993d6cb7d1" category="paragraph">Kubeflow è un toolkit open source ai e ML per Kubernetes sviluppato originariamente da Google. Il progetto Kubeflow rende le implementazioni dei flussi di lavoro ai e ML su Kubernetes semplici, portatili e scalabili. Kubeflow astratta le complessità di Kubernetes, consentendo agli scienziati dei dati di concentrarsi su ciò che conoscono meglio―data science. Vedere la figura seguente per una visualizzazione. Kubeflow ha ottenuto notevoli risultati con la sempre maggiore standardizzazione dei reparti IT aziendali su Kubernetes. Per ulteriori informazioni, visitare il<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block>.</block>
  <block id="a2b0a43dcae6386929654b652393e691" category="paragraph"><block ref="a2b0a43dcae6386929654b652393e691" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">Pipeline Kubeflow</block>
  <block id="384873a621d99250018cd7ce1768f8af" category="paragraph">Le pipeline Kubeflow sono un componente chiave di Kubeflow. Le pipeline Kubeflow sono una piattaforma e uno standard per la definizione e l'implementazione di flussi di lavoro portatili e scalabili ai e ML. Per ulteriori informazioni, consultare<block ref="6de5a235a0c43df48d05588e1b69b959" category="inline-link-rx"></block>.</block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="section-title">Jupyter notebook Server</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">Sito web di Jupyter</block>
  <block id="6ce65fc39d3572cc5ced699e841dc354" category="paragraph">Un Jupyter notebook Server è un'applicazione web open source che consente ai data scientist di creare documenti wiki-like denominati Jupyter Notebooks che contengono codice live e test descrittivi. I notebook Jupyter sono ampiamente utilizzati nella community ai e ML come mezzo per documentare, memorizzare e condividere progetti ai e ML. Kubeflow semplifica il provisioning e l'implementazione di Jupyter notebook Server su Kubernetes. Per ulteriori informazioni sui notebook Jupyter, visitare il<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block>. Per ulteriori informazioni sui notebook Jupyter nel contesto di Kubeflow, vedere<block ref="273f9b54e4f57ca19b4597f14d191196" category="inline-link-rx"></block>.</block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="section-title">Flusso d'aria Apache</block>
  <block id="c01fb6f699235f8c5d36bdda9e155c77" category="paragraph">Apache Airflow è una piattaforma open-source per la gestione del workflow che consente authoring, scheduling e monitoraggio programmatici per flussi di lavoro aziendali complessi. Spesso viene utilizzato per automatizzare i flussi di lavoro ETL e della pipeline di dati, ma non è limitato a questi tipi di flussi di lavoro. Il progetto Airbnb è stato avviato da Airbnb, ma da allora è diventato molto popolare nel settore e ora è sotto gli auspici della Apache Software Foundation. Il flusso d'aria è scritto in Python, i flussi di lavoro del flusso d'aria sono creati tramite script Python e il flusso d'aria è progettato in base al principio della "configurazione come codice". Molti utenti del flusso d'aria aziendale ora eseguono il flusso d'aria su Kubernetes.</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">Diagrammi aciclici diretti (DAG)</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">Nel flusso d'aria, i flussi di lavoro sono denominati diagrammi ad aciclico diretto (DAG). I dag sono costituiti da task che vengono eseguiti in sequenza, in parallelo o in una combinazione dei due, a seconda della definizione DAG. Il programma di pianificazione del flusso d'aria esegue singole attività su un array di lavoratori, rispettando le dipendenze a livello di attività specificate nella definizione DAG. I dag vengono definiti e creati tramite script Python.</block>
  <block id="0b83cba78e13ee67f3ada794b1e8edb8" category="paragraph">NetApp ONTAP 9 è l'ultima generazione di software per la gestione dello storage NetApp che consente a aziende come la tua di modernizzare l'infrastruttura e di passare a un data center cloud-ready. Grazie alle funzionalità di gestione dei dati leader del settore, ONTAP consente di gestire e proteggere i dati con un singolo set di strumenti, indipendentemente dalla posizione in cui risiedono. Puoi anche spostare liberamente i dati ovunque ti servano: Edge, core o cloud. ONTAP 9 include numerose funzionalità che semplificano la gestione dei dati, accelerano e proteggono i tuoi dati critici e la tua infrastruttura a prova di futuro attraverso architetture di cloud ibrido.</block>
  <block id="849f9e6e3176f7bb2abaf1dfdda6f4de" category="section-title">Semplifica la gestione dei dati</block>
  <block id="5d0a72b50313f5f3615263a7d19ee676" category="paragraph">La gestione dei dati è fondamentale per le operazioni IT aziendali, in modo da poter utilizzare le risorse appropriate per le applicazioni e i set di dati. ONTAP include le seguenti funzionalità per ottimizzare e semplificare le operazioni e ridurre il costo totale delle operazioni:</block>
  <block id="30490e1b1bd18c329c3b28df91914ffe" category="list-text">*Compattazione dei dati inline e deduplica estesa.* la compattazione dei dati riduce lo spazio sprecato all'interno dei blocchi di storage e la deduplica aumenta significativamente la capacità effettiva.</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">*Qualità del servizio (QoS) minima, massima e adattiva.* i controlli QoS granulari aiutano a mantenere i livelli di performance per le applicazioni critiche in ambienti altamente condivisi.</block>
  <block id="d9a5709ce7afa0856dd86539f75c8087" category="list-text">*ONTAP FabricPool.* questa funzione offre il tiering automatico dei dati cold per le opzioni di cloud storage pubblico e privato, tra cui Amazon Web Services (AWS), Azure e lo storage basato su oggetti NetApp StorageGRID.</block>
  <block id="ddb2f8d78c57d5743fdee9e17ae053c9" category="section-title">Accelera e proteggi i dati</block>
  <block id="4994fe58be1734616de0863809040200" category="paragraph">ONTAP offre livelli superiori di performance e protezione dei dati ed estende queste funzionalità con le seguenti funzionalità:</block>
  <block id="b109ecc7b4570bf3dbb9f8d082595075" category="list-text">*Prestazioni elevate e bassa latenza.* ONTAP offre il throughput più elevato possibile con la latenza più bassa possibile.</block>
  <block id="9e184f7b8847a390232c0163d45ab461" category="list-text">*Tecnologia NetApp ONTAP FlexGroup.* Un volume FlexGroup è un container di dati dalle performance elevate che può scalare linearmente fino a 20 PB e 400 miliardi di file, fornendo un singolo namespace che semplifica la gestione dei dati.</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">*Protezione dei dati.* ONTAP offre funzionalità di protezione dei dati integrate con gestione comune su tutte le piattaforme.</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">*Crittografia dei volumi NetApp.* ONTAP offre crittografia nativa a livello di volume con supporto per la gestione delle chiavi sia integrata che esterna.</block>
  <block id="0950833529b7822458a242631cce3b3b" category="section-title">Infrastruttura a prova di futuro</block>
  <block id="ba5b61620e18b71a8644dbc382c0c4f1" category="paragraph">ONTAP 9 aiuta a soddisfare le tue esigenze di business esigenti e in continua evoluzione:</block>
  <block id="d9d73747d25ab5e9c5de8f1f61c9ec7c" category="list-text">*Scalabilità perfetta e operazioni senza interruzioni.* ONTAP supporta l'aggiunta senza interruzioni di capacità ai controller esistenti e ai cluster scale-out. Puoi eseguire l'upgrade alle tecnologie più recenti, come NVMe e 32GB FC, senza costose migrazioni dei dati o interruzioni.</block>
  <block id="512a65c054e8b5d06216e0eae55abedb" category="list-text">*Connessione al cloud.* ONTAP è uno dei software di gestione dello storage più connessi al cloud, con opzioni per lo storage definito tramite software (ONTAP Select) e le istanze native del cloud (NetApp Cloud Volumes Service) in tutti i cloud pubblici.</block>
  <block id="5ca60f373401802dfa44501cfa4f5cc7" category="list-text">*Integrazione con le applicazioni emergenti.* utilizzando la stessa infrastruttura che supporta le applicazioni aziendali esistenti, ONTAP offre servizi dati di livello Enterprise per piattaforme e applicazioni di prossima generazione come OpenStack, Hadoop e MongoDB.</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">Copie Snapshot di NetApp</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">Una copia Snapshot di NetApp è un'immagine point-in-time di sola lettura di un volume. L'immagine consuma uno spazio di storage minimo e comporta un overhead delle performance trascurabile, in quanto registra solo le modifiche apportate ai file creati dall'ultima copia Snapshot, come illustrato nella figura seguente.</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">Le copie Snapshot devono la loro efficienza alla tecnologia di virtualizzazione dello storage ONTAP principale, il layout di file Write Anywhere (WAFL). Come un database, WAFL utilizza i metadati per indicare i blocchi di dati effettivi sul disco. Tuttavia, a differenza di un database, WAFL non sovrascrive i blocchi esistenti. Scrive i dati aggiornati in un nuovo blocco e cambia i metadati. È perché ONTAP fa riferimento ai metadati quando crea una copia Snapshot, piuttosto che copiare i blocchi di dati, che le copie Snapshot sono così efficienti. In questo modo si eliminano i tempi di ricerca che altri sistemi devono affrontare per individuare i blocchi da copiare, nonché i costi di creazione della copia stessa.</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">È possibile utilizzare una copia Snapshot per ripristinare singoli file o LUN o per ripristinare l'intero contenuto di un volume. ONTAP confronta le informazioni del puntatore nella copia Snapshot con i dati su disco per ricostruire l'oggetto mancante o danneggiato, senza downtime o costi di performance significativi.</block>
  <block id="9787a3a5983c64cfaf3029a721aab4f0" category="paragraph"><block ref="9787a3a5983c64cfaf3029a721aab4f0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">Tecnologia NetApp FlexClone</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">La tecnologia NetApp FlexClone fa riferimento ai metadati Snapshot per creare copie scrivibili point-in-time di un volume. Le copie condividono i blocchi di dati con i genitori, senza consumare storage, ad eccezione di quanto richiesto per i metadati fino a quando le modifiche non vengono scritte nella copia, come illustrato nella figura seguente. Il software FlexClone consente di copiare quasi istantaneamente anche i set di dati più grandi, anche se le copie tradizionali richiedono pochi minuti o persino ore. Ciò lo rende ideale per situazioni in cui sono necessarie più copie di set di dati identici (ad esempio un'area di lavoro di sviluppo) o copie temporanee di un set di dati (test di un'applicazione rispetto a un set di dati di produzione).</block>
  <block id="423c2edb645c178257ba9d79bd9ac684" category="paragraph"><block ref="423c2edb645c178257ba9d79bd9ac684" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">Tecnologia NetApp SnapMirror Data Replication</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">Il software NetApp SnapMirror è una soluzione di replica unificata conveniente e facile da utilizzare per tutto il data fabric. Replica i dati ad alta velocità su LAN o WAN. Offre un'elevata disponibilità dei dati e una rapida replica dei dati per applicazioni di tutti i tipi, incluse le applicazioni business-critical in ambienti virtuali e tradizionali. Quando si replicano i dati su uno o più sistemi storage NetApp e si aggiornano continuamente i dati secondari, i dati vengono mantenuti aggiornati e disponibili quando necessario. Non sono richiesti server di replica esterni. Vedere la figura seguente per un esempio di architettura che sfrutta la tecnologia SnapMirror.</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">Il software SnapMirror sfrutta le efficienze dello storage NetApp ONTAP inviando solo i blocchi modificati sulla rete. Il software SnapMirror utilizza inoltre la compressione di rete integrata per accelerare i trasferimenti di dati e ridurre l'utilizzo della larghezza di banda di rete fino al 70%. Con la tecnologia SnapMirror, è possibile sfruttare un flusso di dati di replica con risorse limitate per creare un singolo repository che mantiene il mirror attivo e le copie point-in-time precedenti, riducendo il traffico di rete fino al 50%.</block>
  <block id="423eee692f81241addaf586841d0c66a" category="paragraph"><block ref="423eee692f81241addaf586841d0c66a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2e386ef1ace3f8ea71edbaa6f9cbbd00" category="paragraph">Cloud Sync è un servizio NetApp per una sincronizzazione dei dati rapida e sicura. Sia che tu debba trasferire file tra condivisioni di file NFS o SMB on-premise, NetApp StorageGRID, NetApp ONTAP S3, NetApp Cloud Volumes Service, Azure NetApp Files, AWS S3, AWS EFS, Azure Blob, Google Cloud Storage, o IBM Cloud Object Storage, Cloud Sync sposta i file dove servono in modo rapido e sicuro.</block>
  <block id="c1bea6c8c836c6911127e6fe3fde762a" category="paragraph">Una volta trasferiti, i dati sono completamente disponibili per l'utilizzo sia sull'origine che sulla destinazione. Cloud Sync può sincronizzare i dati on-demand quando viene attivato un aggiornamento o sincronizzare continuamente i dati in base a una pianificazione predefinita. Indipendentemente da ciò, Cloud Sync sposta solo i delta, riducendo al minimo il tempo e il denaro speso per la replica dei dati.</block>
  <block id="18c24ab391d7e12f4abcfea370fb4e81" category="paragraph">Cloud Sync è uno strumento SaaS (Software as a Service) estremamente semplice da configurare e utilizzare. I trasferimenti di dati attivati da Cloud Sync vengono eseguiti da broker di dati. I broker di dati Cloud Sync possono essere implementati in AWS, Azure, piattaforma cloud Google o on-premise.</block>
  <block id="0e4fcaf78d0d4feda27a31ecb6944b58" category="paragraph">NetApp XCP è un software basato su client per migrazioni di dati da qualsiasi a NetApp e da NetApp a NetApp e informazioni sui file system. XCP è progettato per scalare e ottenere le massime performance utilizzando tutte le risorse di sistema disponibili per gestire set di dati ad alto volume e migrazioni ad alte performance. XCP consente di ottenere una visibilità completa nel file system con la possibilità di generare report.</block>
  <block id="9a3914e340e4b09762f8231f9fd0ddaa" category="paragraph">NetApp XCP è disponibile in un singolo pacchetto che supporta i protocolli NFS e SMB. XCP include un binario Linux per set di dati NFS e un eseguibile Windows per set di dati SMB.</block>
  <block id="adc911d4d2f4e0008e765523cff39824" category="paragraph">NetApp XCP file Analytics è un software basato su host che rileva le condivisioni di file, esegue scansioni sul file system e fornisce una dashboard per l'analisi dei file. XCP file Analytics è compatibile con sistemi NetApp e non NetApp ed è eseguibile su host Linux o Windows per fornire analisi per NFS e file system esportati da SMB.</block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">NetApp ONTAP FlexGroup Volumes</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">Un set di dati di training può essere una raccolta di potenzialmente miliardi di file. I file possono includere testo, audio, video e altre forme di dati non strutturati che devono essere memorizzati ed elaborati per essere letti in parallelo. Il sistema di storage deve memorizzare un numero elevato di file di piccole dimensioni e leggerli in parallelo per l'i/o sequenziale e casuale</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">Un volume FlexGroup è un singolo namespace che comprende più volumi membri costitutivi, come illustrato nella figura seguente. Dal punto di vista dell'amministratore dello storage, un volume FlexGroup viene gestito e agisce come un volume NetApp FlexVol. I file in un volume FlexGroup vengono allocati a singoli volumi membri e non vengono sottoposti a striping tra volumi o nodi. Consentono le seguenti funzionalità:</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">I volumi FlexGroup offrono diversi petabyte di capacità e bassa latenza prevedibile per carichi di lavoro con metadati elevati.</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">Supportano fino a 400 miliardi di file nello stesso spazio dei nomi.</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">Supportano operazioni parallelizzate nei carichi di lavoro NAS tra CPU, nodi, aggregati e volumi FlexVol costitutivi.</block>
  <block id="07e40bce6e02494c0af7b6a5f2aeaad8" category="paragraph"><block ref="07e40bce6e02494c0af7b6a5f2aeaad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="96e1c56a273105095d8b5e23e670f72f" category="inline-link-macro">Pagina successiva: Requisiti hardware e software.</block>
  <block id="1c3ce2e5bdbf1449bbeba4ecbd124676" category="paragraph"><block ref="1c3ce2e5bdbf1449bbeba4ecbd124676" category="inline-link-macro-rx"></block></block>
  <block id="69e8c6aef5e50150d499e7fa39f846ed" category="summary">NVIDIA ai Enterprise è una suite end-to-end nativa nel cloud di software di ai e analisi dei dati, ottimizzata in modo che ogni organizzazione possa avere successo con l'ai.</block>
  <block id="68cdb7bf3dabd26e338e1ba72b549c69" category="doc">NVIDIA ai Enterprise con NetApp e VMware</block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">Mike Oglesby, NetApp</block>
  <block id="61cb0c1b4a32d4815eb2a785c0c84cb8" category="paragraph">Per gli architetti E gli amministratori IT, gli strumenti di ai possono essere complicati e poco familiari. Inoltre, molte piattaforme ai non sono Enterprise-ready. NVIDIA ai Enterprise, basata su NetApp e VMware, è stata creata per offrire un'architettura ai di livello Enterprise ottimizzata.</block>
  <block id="65590ec18b850984cfb8bbe6ba35fe7d" category="paragraph">NVIDIA ai Enterprise è una suite end-to-end nativa del cloud di software di ai e data analytics ottimizzato, certificato e supportato da NVIDIA per l'esecuzione su VMware vSphere con sistemi certificati NVIDIA. Questo software facilita l'implementazione, la gestione e la scalabilità semplici e rapide dei carichi di lavoro ai nel moderno ambiente di cloud ibrido. NVIDIA ai Enterprise, basata su NetApp e VMware, offre gestione dei dati e dei workload ai di livello Enterprise in un pacchetto semplice e familiare.</block>
  <block id="24c4078c95e6e2df55bd1d251c11f4aa" category="paragraph"><block ref="24c4078c95e6e2df55bd1d251c11f4aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d92209f7d0eac282a9a26e642c20a91" category="inline-link-macro">Avanti: Panoramica sulla tecnologia.</block>
  <block id="51624dfcafe192d37d40a363ccfa4260" category="paragraph"><block ref="51624dfcafe192d37d40a363ccfa4260" category="inline-link-macro-rx"></block></block>
  <block id="c701c7fe143bef79cc6eebc32606262e" category="paragraph">Per ulteriori informazioni sulle informazioni descritte in questo documento, consultare le seguenti risorse:</block>
  <block id="e40030fd64108859627c7a126638f0e6" category="list-text">Piano di controllo ai di NetApp:</block>
  <block id="63178726ae501745b3914ec3aa50969e" category="list-text">Report tecnico NetApp ai Control Plane</block>
  <block id="3ce56c027572d1908d65b63056be024f" category="inline-link"><block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="445a4d3400bdde832e8898d8349696c0" category="paragraph"><block ref="445a4d3400bdde832e8898d8349696c0" category="inline-link-rx"></block></block>
  <block id="de1e4a3a0cae539a34678546eb6e91b3" category="list-text">Storage persistente NetApp per container:</block>
  <block id="193721fbb9ea3851cafcea43a4d95f73" category="list-text">Framework E tool ML:</block>
  <block id="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="inline-link"><block ref="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="inline-link-rx"></block></block>
  <block id="9a8ec45d909b996af4c042e44b5c5f29" category="list-text">TensorFlow: Un framework di apprendimento automatico open-source per tutti<block ref="db3465122fd83ad1dc4cff7e67d794df" category="inline-link-rx"></block></block>
  <block id="4c3db4ae25b5f5aaa206a7fedd201322" category="inline-link"><block ref="4c3db4ae25b5f5aaa206a7fedd201322" category="inline-link-rx"></block></block>
  <block id="60ea9e9ecbf839c413c5e977002eabf4" category="paragraph"><block ref="60ea9e9ecbf839c413c5e977002eabf4" category="inline-link-rx"></block></block>
  <block id="a33d91971f7757996ab0eb8eb0362814" category="inline-link"><block ref="a33d91971f7757996ab0eb8eb0362814" category="inline-link-rx"></block></block>
  <block id="6771540ad76dbed724cb9025978b8510" category="paragraph"><block ref="6771540ad76dbed724cb9025978b8510" category="inline-link-rx"></block></block>
  <block id="c90a0598d42425e6ec2dfb3058534b35" category="inline-link"><block ref="c90a0598d42425e6ec2dfb3058534b35" category="inline-link-rx"></block></block>
  <block id="ef9e62eeb81c0987fbe61de48635886a" category="paragraph"><block ref="ef9e62eeb81c0987fbe61de48635886a" category="inline-link-rx"></block></block>
  <block id="3bc4d41311862190a8fd0d6c8f661971" category="list-text">Iguazio Data Science Platform</block>
  <block id="737d4d1e81ff236001338f46d1623aaa" category="list-text">Documentazione sulla piattaforma Iguazio Data Science</block>
  <block id="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link"><block ref="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link-rx"></block></block>
  <block id="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="paragraph"><block ref="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="inline-link-rx"></block></block>
  <block id="4f0f362becf6baf6e08f490115d76d98" category="list-text">Funzione Nuclio senza server</block>
  <block id="89aa84cdf5db1bece2993801c78914de" category="inline-link"><block ref="89aa84cdf5db1bece2993801c78914de" category="inline-link-rx"></block></block>
  <block id="93eac034cc1c1aaedaf6ed41063825ee" category="paragraph"><block ref="93eac034cc1c1aaedaf6ed41063825ee" category="inline-link-rx"></block></block>
  <block id="b5266d58998338015b5e02ee7e84a833" category="list-text">Framework di orchestrazione della pipeline opensource MLRun</block>
  <block id="b96a861dccea968edc0b7a9ff96203e9" category="inline-link"><block ref="b96a861dccea968edc0b7a9ff96203e9" category="inline-link-rx"></block></block>
  <block id="70a8a001358e056f435199da7e17e427" category="paragraph"><block ref="70a8a001358e056f435199da7e17e427" category="inline-link-rx"></block></block>
  <block id="b3f90aaddad391963c2090db8f1b727e" category="list-text">Sistemi NVIDIA DGX-1</block>
  <block id="45a310b0e4b087b75cb073303044f6f9" category="inline-link"><block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="af828c56c03364ebbde4c582adeb8de3" category="paragraph"><block ref="af828c56c03364ebbde4c582adeb8de3" category="inline-link-rx"></block></block>
  <block id="d6a377b23d0f4dbe3f5bf91d5f6abf74" category="list-text">NVIDIA Tesla V100 Tensor core GPU</block>
  <block id="fad8218d69ce01748faed5492aa5d3ef" category="inline-link"><block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="a724832176ce84a9d4be5c34e44891d3" category="paragraph"><block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="0df7621d860637a2e6e462c56322edab" category="list-text">NVIDIA GPU Cloud</block>
  <block id="5c75bfead88762783d54deaaa3d62735" category="inline-link"><block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="839d9b8469a8d9554891a7515a2b9be7" category="paragraph"><block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="list-text">Sistemi NetApp AFF</block>
  <block id="584122d1d5e8c2c4232e029a6896ba40" category="list-text">Scheda informativa su AFF</block>
  <block id="9a84c14d2692222552174943486e7136" category="inline-link"><block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="0d9d8991a05834f0e52a99b37ce360b8" category="paragraph"><block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="5f662f6dc276dd5a2a83440d0fe63e9b" category="list-text">NetApp Flash Advantage per AFF</block>
  <block id="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link"><block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="72cf25e9f1e13167cd0dde6f285552ea" category="paragraph"><block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="30df7f622635480ab538fb3016f9c36a" category="list-text">Documentazione di ONTAP 9.x.</block>
  <block id="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link"><block ref="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link-rx"></block></block>
  <block id="a5d59e86f09bafae4247836d5135b6a3" category="paragraph"><block ref="a5d59e86f09bafae4247836d5135b6a3" category="inline-link-rx"></block></block>
  <block id="35d8efcf211e40a836698bff14ed0ff6" category="list-text">Report tecnico di NetApp FlexGroup</block>
  <block id="1ab29fc7fde3319a82a477ec308cf820" category="inline-link"><block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="7a26d62dac2be507dcc3e5b9da0ed765" category="paragraph"><block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="47c991332229e0cbfe947beaa428ea61" category="list-text">Guida alla progettazione di reti ONTAP ai con DGX-1 e Cisco</block>
  <block id="b141781260425e95eee945147e2f0d99" category="inline-link"><block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="9fbee18519e76388280bc1f8e3fd6c7e" category="paragraph"><block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="0be3b0697a0ffdfe9065df24ec1d3e16" category="list-text">Guida all'implementazione di ONTAP ai con DGX-1 e Cisco Networking</block>
  <block id="921f17c41dea89b0a711f380e9864e09" category="inline-link"><block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="aef3d0752148699921f8a251537d5ff3" category="paragraph"><block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="205a4f16a51f3acd6dbba76dbeb10818" category="list-text">Guida alla progettazione di reti ONTAP ai con DGX-1 e Mellanox</block>
  <block id="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link"><block ref="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link-rx"></block></block>
  <block id="0a9e1455c4a5a9965867a5efd6b8cc9b" category="paragraph"><block ref="0a9e1455c4a5a9965867a5efd6b8cc9b" category="inline-link-rx"></block></block>
  <block id="913c29df09bcb5715ed7a48c12f3a0da" category="list-text">Networking ai ONTAP</block>
  <block id="ae2703e9b1dff6da048c786142c2e7db" category="list-text">Switch Cisco Nexus serie 3232C</block>
  <block id="bb31172f259c591005fd4cbcdbfadd11" category="inline-link"><block ref="bb31172f259c591005fd4cbcdbfadd11" category="inline-link-rx"></block></block>
  <block id="96eb8aa0e86d101fdf87284d7d6f1bc7" category="paragraph"><block ref="96eb8aa0e86d101fdf87284d7d6f1bc7" category="inline-link-rx"></block></block>
  <block id="8a27a2062df55e0aa73964ea8ec2ab55" category="list-text">Switch Ethernet Mellanox scale-out serie SN2000</block>
  <block id="87a849c2f3c412a491f97674d5e27ed1" category="inline-link"><block ref="fd77c1cd25d650110f7047fa02f8327d" category="inline-link-rx"></block></block>
  <block id="a6c16c720941d75800533dedd69929cc" category="paragraph"><block ref="ad90d1952f7d0f85370461937e4484b7" category="inline-link-rx"></block></block>
  <block id="86608a0b346f307c76f8ae00c9f6bcb9" category="summary">Questo report mostra come clonare rapidamente uno spazio dei nomi dei dati. Dimostra come definire e implementare i workflow di training ai che incorporano la creazione quasi istantanea di dati e le linee di base dei modelli per la tracciabilità e il controllo delle versioni. Mostra inoltre come replicare perfettamente i dati tra siti e regioni e fornire rapidamente spazi di lavoro Jupyter notebook con accesso a set di dati di grandi dimensioni.</block>
  <block id="fffa1b56750a0334993c90d5adc9912a" category="doc">TR-4798: Piano di controllo ai di NetApp</block>
  <block id="27114500e25aba7a27847b772d396575" category="paragraph">Aziende e organizzazioni di ogni dimensione e in molti settori stanno passando all'intelligenza artificiale (ai), all'apprendimento automatico (ML) e al deep learning (DL) per risolvere problemi reali, offrire prodotti e servizi innovativi e ottenere un vantaggio in un mercato sempre più competitivo. Man mano che le organizzazioni aumentano l'utilizzo di ai, ML e DL, devono affrontare molte sfide, tra cui la scalabilità dei workload e la disponibilità dei dati. Questo documento dimostra come affrontare queste sfide utilizzando il NetApp ai Control Plane, una soluzione che unisce le funzionalità di gestione dei dati di NetApp con i più diffusi framework e tool open-source.</block>
  <block id="98300151efa6f504dee4866e49cf2078" category="paragraph">Questo report mostra come clonare rapidamente uno spazio dei nomi dei dati. Mostra inoltre come replicare perfettamente i dati tra siti e regioni per creare una pipeline di dati ai/ML/DL coesa e unificata. Inoltre, ti guida attraverso la definizione e l'implementazione di workflow di training ai, ML e DL che incorporano la creazione quasi istantanea di dati e linee di base dei modelli per la tracciabilità e il controllo delle versioni. Con questa soluzione, è possibile tracciare ogni ciclo di training del modello fino all'esatto set di dati utilizzato per la formazione e/o la convalida del modello. Infine, questo documento illustra come eseguire rapidamente il provisioning delle aree di lavoro dei notebook Jupyter con accesso a set di dati di grandi dimensioni.</block>
  <block id="3a8a3991c7ef251983bda0fd052b9b10" category="inline-link-macro">TR-4890</block>
  <block id="3cbee33bcafaf0315e821a3331b91eb5" category="inline-link-macro">La soluzione di file system parallelo completamente supportata di NetApp BeeGFS</block>
  <block id="63de7cb3a054a3754335c60a0c8ba878" category="paragraph">Nota: Per i training distribuiti in stile HPC su larga scala che coinvolgono un gran numero di server GPU che richiedono l'accesso condiviso allo stesso set di dati, o se si desidera un file system parallelo, consultare la sezione <block ref="f82f3a4db7a848244fd5070f378c86fb" category="inline-link-macro-rx"></block>. Questo report tecnico descrive come includere <block ref="99c493838dffa23aa6d1149e33e3edf0" category="inline-link-macro-rx"></block> Come parte del NetApp ai Control Plane. Questa soluzione è progettata per scalare da una manciata di sistemi NVIDIA DGX A100 fino a un SuperPOD a 140 nodi completo.</block>
  <block id="9f1cc947f3e0236f8d5bc32d8d33509a" category="inline-link">cloud.netapp.com</block>
  <block id="9d50c340b35848862ab6ecbdadc401ed" category="paragraph">Il piano di controllo ai di NetApp è rivolto a data scientist e data engineer e, di conseguenza, è necessaria una competenza minima di NetApp o NetApp ONTAP®. Con questa soluzione, le funzioni di gestione dei dati possono essere eseguite utilizzando interfacce e strumenti semplici e familiari. Se disponete già di storage NetApp nel vostro ambiente, potete testare il NetApp ai Control Plane oggi stesso. Se si desidera provare la soluzione ma non si dispone già di storage NetApp, visitare il sito<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>E potrai essere operativo con una soluzione di storage NetApp basata sul cloud in pochi minuti. La figura seguente fornisce una visualizzazione della soluzione.</block>
  <block id="1f39acb56ba2a8669371819a64348c74" category="paragraph"><block ref="1f39acb56ba2a8669371819a64348c74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6dd86945b1681007efc06cd445661f24" category="inline-link-macro">Avanti: Concetti e componenti.</block>
  <block id="742ed784bbf61aca3af793407a42b1f5" category="paragraph"><block ref="742ed784bbf61aca3af793407a42b1f5" category="inline-link-macro-rx"></block></block>
  <block id="321cf11d6ad313e01614cfa7817893fb" category="doc">Implementazione di Jarvis</block>
  <block id="24a0684c018bf0ed5e7001773d8df2c5" category="inline-link">Programma Jarvis Early Access</block>
  <block id="55ce258288b89404cc493de8c839e20a" category="paragraph">Puoi iscriverti a.<block ref="de4a7b23900edb1996cbcb27f4a65904" category="inline-link-rx"></block> Per accedere ai container Jarvis su NVIDIA GPU Cloud (NGC). Dopo aver ricevuto le credenziali da NVIDIA, puoi implementare Jarvis seguendo questa procedura:</block>
  <block id="e5a6dabbbe3f9144d9f6e72b568893cd" category="list-text">Accedi a NGC.</block>
  <block id="a668e3da095eca41ef93e0c494a6ebad" category="list-text">Imposta la tua organizzazione su NGC:<block ref="7aa2b5d0d3058d0080d19281dc9d071c" prefix=" " category="inline-code"></block>.</block>
  <block id="f3b0315f8d213517a6076eb7aff49cb6" category="list-text">Individuare le risorse Jarvis EA v0.2: I container Jarvis sono in<block ref="57383b3fa3bf1fe40b83355ea69945df" prefix=" " category="inline-code"></block> &gt;<block ref="15ce31151446746acfe9a6cb94ac5cbe" prefix=" " category="inline-code"></block>.</block>
  <block id="6db8e9899d42bcac6aeb824da5e952ef" category="list-text">Selezionare Jarvis: Selezionare<block ref="eb6a57c968a3671eebe48d3c0a1d6a9a" prefix=" " category="inline-code"></block> e fare clic su<block ref="29a846043a00b3f8b78a15edcb8ac726" prefix=" " category="inline-code"></block></block>
  <block id="737af365257800065a6412e56d652acc" category="list-text">Verificare che tutte le risorse funzionino correttamente.</block>
  <block id="8a5fd124171d01a74b1af73e73ab7761" category="list-text">Trova la documentazione per creare le tue applicazioni: I PDF sono disponibili in<block ref="eb6a57c968a3671eebe48d3c0a1d6a9a" prefix=" " category="inline-code"></block> &gt;<block ref="4ce995c78680dc78d6a0745744c2811b" prefix=" " category="inline-code"></block> &gt;<block ref="b8c128190e09e6c57a1df2180e8c73fb" prefix=" " category="inline-code"></block>.</block>
  <block id="f3e3b1e7550f6cf9fe883b01695163b7" category="inline-link-macro">Pagina successiva: Personalizzare gli stati e i flussi per il caso d'utilizzo Retail</block>
  <block id="3ae7e712d75bd01d43546679548a28a1" category="paragraph"><block ref="3ae7e712d75bd01d43546679548a28a1" category="inline-link-macro-rx"></block></block>
  <block id="9783bbad26249ed7f40d89e12ba42020" category="doc">Run:ai Platform for ai workload Orchestration</block>
  <block id="cb39fb629a91fdf37928a15d38e05318" category="list-text">Tempi di innovazione più rapidi. Utilizzando i meccanismi di pooling delle risorse Run:ai, accodamento e prioritizzazione insieme al sistema storage NetApp, i ricercatori vengono rimossi dai problemi di gestione dell'infrastruttura e possono concentrarsi esclusivamente sulla scienza dei dati. Esegui: I clienti ai e NetApp aumentano la produttività eseguendo tutti i carichi di lavoro necessari senza colli di bottiglia della pipeline di dati o di calcolo.</block>
  <block id="8df86cf2931aab70fd9ad1f919f40449" category="list-text">Aumento della produttività del team. Gli algoritmi Run:ai Fairness garantiscono che tutti gli utenti e i team ottenano la loro giusta quota di risorse. È possibile preimpostare le policy relative ai progetti prioritari e la piattaforma consente l'allocazione dinamica delle risorse da un team di utenti all'altro, consentendo agli utenti di ottenere un accesso tempestivo alle risorse GPU più ambite.</block>
  <block id="c835378d4be1896f62ef5d2760340909" category="list-text">Utilizzo della GPU migliorato. Run:ai Scheduler consente agli utenti di utilizzare facilmente GPU frazionali, GPU interi e nodi multipli di GPU per la formazione distribuita su Kubernetes. In questo modo, i carichi di lavoro ai vengono eseguiti in base alle esigenze, non alla capacità. Team di data science in grado di eseguire più esperimenti di ai sulla stessa infrastruttura.</block>
  <block id="5960deb1522a82336a7a31213acea4b0" category="inline-link-macro">Avanti: Tecnologia della soluzione</block>
  <block id="dde440f8f7c47863e65c2d82a820b8a5" category="paragraph"><block ref="d9533ea5c6cb975dff314dace88f2aa4" category="inline-link-macro-rx"></block>.</block>
  <block id="27d597678185c0988ffb2dbb0c1b941d" category="doc">ResNet-50 con ImageNet dataset Benchmark Summary</block>
  <block id="3c97b4929008c9f4091a8070f570ccd4" category="paragraph">Abbiamo validato il funzionamento e le performance di questo sistema utilizzando i benchmark TensorFlow degli standard di settore. Il set di dati ImageNet utilizzato per formare ResNet-50, un famoso modello DL della rete neurale convoluzionale (CNN) per la classificazione delle immagini. ResNet-50 offre un risultato di training accurato con un tempo di elaborazione più rapido, che ci consente di gestire una domanda sufficiente sullo storage.</block>
  <block id="a89cd2a9c8244dab756ec04aeb8247e9" category="inline-link-macro">Eseguire l'installazione ai</block>
  <block id="123704fec3ddad892d7c2ae5c4de301b" category="paragraph"><block ref="123704fec3ddad892d7c2ae5c4de301b" category="inline-link-macro-rx"></block></block>
  <block id="7a879e305f90568b91e8623ce5f9ee39" category="summary">Da maggio 2019, Microsoft offre un servizio di portale nativo di Azure per i file service NFS e SMB aziendali basati sulla tecnologia NetApp ONTAP.</block>
  <block id="0bf51d984b6a6d3fddc0e24f62eb1a14" category="doc">TR-4896: Formazione distribuita in Azure: Rilevamento della corsia - progettazione della soluzione</block>
  <block id="0ab5aa2896d8eed7732e69be5e5782b4" category="paragraph">Muneer Ahmad e Verron Martina, NetApp Ronen Dar, RUN:ai</block>
  <block id="a89ade32996e322edf837476febbc9bd" category="paragraph">Da maggio 2019, Microsoft offre un servizio di portale nativo di Azure per i file service NFS e SMB aziendali basati sulla tecnologia NetApp ONTAP. Questo sviluppo è guidato da una partnership strategica tra Microsoft e NetApp e estende ulteriormente la portata dei servizi dati ONTAP di livello mondiale ad Azure.</block>
  <block id="d6312cb01ee08559dbaa35c308e72268" category="paragraph">NetApp, un provider leader di servizi dati cloud, ha collaborato con RUN: Ai, un'azienda che virtualizza l'infrastruttura ai, per consentire una sperimentazione ai più rapida con un utilizzo completo della GPU. La partnership consente ai team di accelerare l'ai eseguendo numerosi esperimenti in parallelo, con accesso rapido ai dati e sfruttando risorse di calcolo illimitate. RUN: L'ai consente l'utilizzo completo della GPU automatizzando l'allocazione delle risorse, mentre l'architettura comprovata di Azure NetApp Files consente di eseguire ogni esperimento alla massima velocità eliminando le ostruzioni della pipeline dei dati.</block>
  <block id="5234f8ee670afed8c398940a707f25df" category="paragraph">NetApp e RUN: L'ai ha Unito le forze per offrire ai clienti una piattaforma a prova di futuro per il loro viaggio nell'ai in Azure. Dagli analytics al calcolo ad alte performance (HPC) alle decisioni autonome (in cui i clienti possono ottimizzare i propri investimenti IT pagando solo ciò di cui hanno bisogno, quando ne hanno bisogno), l'alleanza tra NetApp e RUN: L'ai offre una singola esperienza unificata in Azure Cloud.</block>
  <block id="dcfa517bb68d187d11e580baf2ecf588" category="summary">Questa pagina descrive l'impostazione di Dask con L'implementazione DI RAPIDS su AKS utilizzando Helm.</block>
  <block id="fd22fb1626b987fa7b72743fa9698ec6" category="doc">Impostare Dask con L'implementazione DI RAPIDS su AKS utilizzando Helm</block>
  <block id="d74bb88aa6e4b1c540be703fda33923e" category="inline-link-macro">Precedente: Installare Trident.</block>
  <block id="6020c64d2124fc0caa426123bfc5ba38" category="paragraph"><block ref="6020c64d2124fc0caa426123bfc5ba38" category="inline-link-macro-rx"></block></block>
  <block id="d81f517b6ad0d9702be81a8199a2246f" category="paragraph">Per configurare la distribuzione di Dask con RAPIDS su AKS utilizzando Helm, attenersi alla seguente procedura:</block>
  <block id="549c839f491ec7099a895dd1cfea7534" category="list-text">Creare uno spazio dei nomi per l'installazione di Dask con RAPIDS.</block>
  <block id="74d041e68ac2a21a636ab14ae78f279d" category="list-text">Creare un PVC per memorizzare il set di dati del tasso di click-through:</block>
  <block id="f5008aa6b27cdcaadbe27960383c8ff6" category="list-text">Salvare il seguente contenuto YAML in un file per creare un PVC.</block>
  <block id="67d464c36bcc48173c964a780459dbfd" category="list-text">Applicare il file YAML al cluster Kubernetes.</block>
  <block id="be0ca76aafd92c18792693b8f05d01ce" category="inline-link"><block ref="be0ca76aafd92c18792693b8f05d01ce" category="inline-link-rx"></block></block>
  <block id="dc7ba914646428512334728c1f0ebd7d" category="list-text">Clonare il<block ref="d126903117bcd329e601af7057853376" prefix=" " category="inline-code"></block> repository (<block ref="4f08c7c28c19e75f4d8607fc65d40067" category="inline-link-rx"></block>).</block>
  <block id="50aef45ee39d958bc589f422bfb6d1bf" category="list-text">Modificare<block ref="ba05023d0f1b5d4b64b6cad4cf9a7ecd" prefix=" " category="inline-code"></block> E includere il PVC creato in precedenza per i lavoratori e l'area di lavoro Jupyter.</block>
  <block id="06867e85b141bb9d17f8ed6b4b685c46" category="list-text">Accedere alla<block ref="47e38535ab0a13ca65c9bba04c686040" prefix=" " category="inline-code"></block> directory del repository.</block>
  <block id="1a985ac965074fab9cfcee28ef954755" category="list-text">Aggiornare<block ref="ba05023d0f1b5d4b64b6cad4cf9a7ecd" prefix=" " category="inline-code"></block> Archiviare e montare il volume utilizzando PVC.</block>
  <block id="52076eb1fec3929530258335052328b3" category="list-text">Accedere alla home directory del repository e implementare Dask con tre nodi di lavoro su AKS utilizzando Helm.</block>
  <block id="bd4e74749939dd3c9f80ff138c18af53" category="inline-link-macro">Avanti: Livelli di performance Azure NetApp Files.</block>
  <block id="52d5e0adb69809963ce4f94104a75b5e" category="paragraph"><block ref="52d5e0adb69809963ce4f94104a75b5e" category="inline-link-macro-rx"></block></block>
  <block id="1d22ea3c852f35081a408a42b1caa719" category="doc">Implementazione di cnvrg.io</block>
  <block id="e1d91df1cfd0e5839c45e06d0504c9d6" category="section-title">Implementare il CORE cnvrg utilizzando Helm</block>
  <block id="7e9e2a4317009b27ebfc0b4cd222ba30" category="paragraph">Helm è il modo più semplice per implementare rapidamente cnvrg utilizzando qualsiasi cluster, on-premise, Minikube o qualsiasi cluster cloud (come AKS, EKS e GKE). Questa sezione descrive come cnvrg è stato installato su un'istanza on-premise (DGX-1) con Kubernetes installato.</block>
  <block id="ea6de3fdf29035cd2d521949527c2a44" category="paragraph">Prima di completare l'installazione, è necessario installare e preparare le seguenti dipendenze sul computer locale:</block>
  <block id="6f49e891fdb1bb11823492f4d315b2fd" category="list-text">Kubectl</block>
  <block id="5e6cef7c129d4703b20be420ac32145c" category="list-text">Timone 3.x</block>
  <block id="93fafc2be5db6c259030d6d8dc989752" category="list-text">Kubernetes cluster 1.15+</block>
  <block id="116efea8faeef9714de76fe9f81d9b82" category="section-title">Implementazione con Helm</block>
  <block id="237800170a9b824a7de8c08766ea114e" category="list-text">Per scaricare i grafici di comando più aggiornati, eseguire il seguente comando:</block>
  <block id="9b821098b02043dada6b07b924f4ef5f" category="list-text">Prima di implementare cnvrg, è necessario disporre dell'indirizzo IP esterno del cluster e del nome del nodo su cui verrà implementato cnvrg. Per implementare cnvrg in un cluster Kubernetes on-premise, eseguire il seguente comando:</block>
  <block id="1d1eb4e0da8bac1b4eaa79c1f0be9e04" category="list-text">Eseguire<block ref="0562418e6d9a76d0dd22b2f186a2203d" prefix=" " category="inline-code"></block> comando. Tutti i servizi e i sistemi vengono installati automaticamente sul cluster. Il processo può richiedere fino a 15 minuti.</block>
  <block id="e269e5751f8883222b6d2f55da7ed811" category="list-text">Il<block ref="0562418e6d9a76d0dd22b2f186a2203d" prefix=" " category="inline-code"></block> il comando può richiedere fino a 10 minuti. Una volta completata l'implementazione, accedere all'URL del cnvrg appena distribuito o aggiungere il nuovo cluster come risorsa all'interno dell'organizzazione. Il<block ref="e7d07ed8aa8dd8cafce4a527a523d6c5" prefix=" " category="inline-code"></block> Il comando indica l'URL corretto.</block>
  <block id="ac0cc75e8d4f0df818dd93a00041897a" category="list-text">Quando lo stato di tutti i container è in esecuzione o completo, cnvrg è stato implementato correttamente. Dovrebbe essere simile al seguente output di esempio:</block>
  <block id="3e82668da957bceb0d0c7024273ab624" category="section-title">Formazione sul modello di visione artificiale con ResNet50 e il set di dati radiologici Chest</block>
  <block id="c9c734dfca60f137a58e1a5cb9c89b62" category="inline-link">Sito di download NIH</block>
  <block id="0c7f26c15912f9f5d0e0473bb21cb9a2" category="paragraph">Il sistema operativo ai cnvrg.io è stato implementato su una configurazione Kubernetes su un'architettura NetApp ONTAP ai basata sul sistema NVIDIA DGX. Per la convalida, abbiamo utilizzato il set di dati radiologici NIH Chest costituito da immagini anonimizzate dei raggi X del torace. Le immagini erano in formato PNG. I dati sono stati forniti dal NIH Clinical Center e sono disponibili tramite<block ref="4e3f11b94ad47864cbd9c6049036ac93" category="inline-link-rx"></block>. Abbiamo utilizzato un campione di 250 GB dei dati con 627, 615 immagini in 15 classi.</block>
  <block id="de53b795a18176edb91a88632f621868" category="paragraph">Il set di dati è stato caricato sulla piattaforma cnvrg ed è stato memorizzato nella cache di un'esportazione NFS dal sistema di storage NetApp AFF A800.</block>
  <block id="ec948f075c372d4beb7d19a5266f22d5" category="section-title">Impostare le risorse di calcolo</block>
  <block id="42af2f71dc8561eb9cfe43d45664ecb3" category="paragraph">L'architettura cnvrg e la funzionalità di meta-scheduling consentono a tecnici e professionisti IT di collegare diverse risorse di calcolo a una singola piattaforma. Nella nostra configurazione, abbiamo utilizzato lo stesso cluster cnvrg implementato per l'esecuzione dei carichi di lavoro di deep-learning. Se è necessario collegare altri cluster, utilizzare la GUI, come mostrato nella seguente schermata.</block>
  <block id="df25fca4c07e68ed339b0e1974a9d59f" category="paragraph"><block ref="df25fca4c07e68ed339b0e1974a9d59f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f541774a08fc687f6e2016c77a6ebca5" category="section-title">Caricare i dati</block>
  <block id="564bfd33ed32c02158989dfcee59ae89" category="paragraph">Per caricare i dati sulla piattaforma cnvrg, è possibile utilizzare la GUI o la CLI cnvrg. Per i set di dati di grandi dimensioni, NetApp consiglia di utilizzare CLI perché si tratta di uno strumento potente, scalabile e affidabile in grado di gestire un gran numero di file.</block>
  <block id="41ad6001e0d3c17bd4a7957e18bd8bab" category="paragraph">Per caricare i dati, attenersi alla seguente procedura:</block>
  <block id="192b006166881688d04f398db712aaeb" category="inline-link">CLI cnvrg</block>
  <block id="8e9fbcfb57e26d7a14f0292c11fae122" category="list-text">Scaricare il<block ref="d3ae4cf97b77cb5805c16205cd459ce4" category="inline-link-rx"></block>.</block>
  <block id="5cea56fcf2481a021f3d93843a22c319" category="list-text">accedere alla directory dei raggi x.</block>
  <block id="1c5a650f398227a4f97ed81accfbbb4b" category="list-text">Inizializzare il set di dati nella piattaforma con<block ref="93683f43f0985082ca58f41ff93ff85f" prefix=" " category="inline-code"></block> comando.</block>
  <block id="5c48f13a3d988e0d618145098a829e3a" category="list-text">Caricare tutti i contenuti della directory nel data Lake centrale con<block ref="3e18d74143663f7fae3446eb44229f0f" prefix=" " category="inline-code"></block> Command.una volta caricati i dati nell'archivio centrale di oggetti (StorageGRID, S3 o altri), è possibile navigare con la GUI. La figura seguente mostra un file PNG di immagine della fibrosi a raggi X del torace caricato. Inoltre, cnvrg consente di eseguire la versione dei dati in modo che qualsiasi modello creato possa essere riprodotto fino alla versione dei dati.</block>
  <block id="935b6e25167b65d839bc1487ebb2fa6e" category="paragraph"><block ref="935b6e25167b65d839bc1487ebb2fa6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="308e9394a715dc64aa4e48e0054775ed" category="section-title">Dati di cach</block>
  <block id="556cde11a66a789acb7e62b934c1a88c" category="paragraph">Per accelerare il training ed evitare il download di oltre 600.000 file per ciascun modello di training ed esperimento, abbiamo utilizzato la funzionalità di caching dei dati dopo che i dati sono stati inizialmente caricati nell'archivio centrale di oggetti data-Lake.</block>
  <block id="3d163413cac9b6cc4726a9c83d37fed3" category="paragraph"><block ref="3d163413cac9b6cc4726a9c83d37fed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d006c100d76e7d21d64055ce3cfe6a24" category="paragraph">Dopo che gli utenti hanno fatto clic su cache, cnvrg scarica i dati nel relativo commit specifico dall'archivio remoto di oggetti e li memorizza nella cache del volume NFS di ONTAP. Al termine, i dati saranno disponibili per il training istantaneo. Inoltre, se i dati non vengono utilizzati per alcuni giorni (ad esempio, per la formazione o l'esplorazione del modello), cnvrg cancella automaticamente la cache.</block>
  <block id="53ad459d9bb7a65de3d1cc839b75c19f" category="section-title">Crea una pipeline ML con i dati memorizzati nella cache</block>
  <block id="db226c80bcb6098ce2f47dd3982cca26" category="paragraph">Cnvrg Flows consente di creare facilmente pipeline ML di produzione. I flussi sono flessibili, possono funzionare per qualsiasi tipo di caso d'utilizzo DI ML e possono essere creati attraverso la GUI o il codice. Ogni componente di un flusso può essere eseguito su una diversa risorsa di calcolo con un'immagine Docker diversa, il che rende possibile la creazione di cloud ibrido e pipeline ML ottimizzate.</block>
  <block id="6b0eae96748d48b032362774a6467411" category="paragraph"><block ref="6b0eae96748d48b032362774a6467411" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e1f18dfff2566b35d7d0e528565c43aa" category="section-title">Creazione del flusso di raggi X del torace: Impostazione dei dati</block>
  <block id="adec555cb8cd4de3f288baed510d1163" category="paragraph">Abbiamo aggiunto il nostro set di dati a un flusso appena creato. Quando si aggiunge il dataset, è possibile selezionare la versione specifica (commit) e indicare se si desidera la versione memorizzata nella cache. In questo esempio, è stato selezionato il commit memorizzato nella cache.</block>
  <block id="6dd780034ed574b328dbc16a6b485b79" category="paragraph"><block ref="6dd780034ed574b328dbc16a6b485b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13e0789c536fc18ddcdc32b4ca598b58" category="section-title">Creazione del flusso di raggi X del torace: Impostazione del modello di training: ResNet50</block>
  <block id="fa3c48d58d8e9fd17365fd986906dd52" category="paragraph">Nella pipeline, è possibile aggiungere qualsiasi tipo di codice personalizzato desiderato. In cnvrg è disponibile anche la libreria ai, una raccolta di componenti ML riutilizzabili. Nella libreria ai sono presenti algoritmi, script, origini dati e altre soluzioni che possono essere utilizzate in qualsiasi ML o flusso di deep learning. In questo esempio, è stato selezionato il modulo ResNet50 preinstallato. Abbiamo utilizzato parametri predefiniti come batch_size:128, epochs:10 e molto altro ancora. Questi parametri possono essere visualizzati nei documenti della ai Library. La seguente schermata mostra il nuovo flusso con il set di dati radiologici collegato a ResNet50.</block>
  <block id="defe5cc08faaa501eeb5fc5500664d29" category="paragraph"><block ref="defe5cc08faaa501eeb5fc5500664d29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf9bb479506589dfd719446fe3e054c7" category="section-title">Definire la risorsa di calcolo per ResNet50</block>
  <block id="943cb3f5c7789c68e811b0accdb6c5d9" category="paragraph">Ogni algoritmo o componente nei flussi cnvrg può essere eseguito su un'istanza di calcolo diversa, con un'immagine Docker diversa. Nella nostra configurazione, volevamo eseguire l'algoritmo di training sui sistemi NVIDIA DGX con l'architettura NetApp ONTAP ai. Nella figura seguente, è stato selezionato<block ref="26591d390a9f009f2af40ff68e37a26a" prefix=" " category="inline-code"></block>, che è un modello di calcolo e una specifica per il nostro cluster on-premise. Abbiamo anche creato una coda di modelli e selezionato più modelli. In questo modo, se il<block ref="26591d390a9f009f2af40ff68e37a26a" prefix=" " category="inline-code"></block> non è possibile allocare le risorse (se, ad esempio, altri data scientist le stanno utilizzando), quindi è possibile attivare la diffusione automatica del cloud aggiungendo un modello di cloud provider. La seguente schermata mostra l'utilizzo di gpu-real come nodo di calcolo per ResNet50.</block>
  <block id="27c8450e6f62877ec794262ae4c5a713" category="paragraph"><block ref="27c8450e6f62877ec794262ae4c5a713" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bee38713f37ae72239f6bda08384dfbb" category="section-title">Monitoraggio e monitoraggio dei risultati</block>
  <block id="546b7da7049f1d7fdf35cdb57fa96c7c" category="paragraph">Una volta eseguito un flusso, cnvrg attiva il motore di monitoraggio e tracciamento. Ogni esecuzione di un flusso viene documentata e aggiornata automaticamente in tempo reale. Hyperparameters, metriche, utilizzo delle risorse (utilizzo della GPU e altro ancora), versione del codice, artefatti, log, E così via sono disponibili automaticamente nella sezione Experiments (esperimenti), come mostrato nelle due schermate seguenti.</block>
  <block id="8fabeb8b8d143d509bb92087cbbf953c" category="paragraph"><block ref="8fabeb8b8d143d509bb92087cbbf953c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdbd22304f732000189e44de22498da1" category="paragraph"><block ref="fdbd22304f732000189e44de22498da1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="debe391efc3dc12a7d87720a4cf068a5" category="paragraph"><block ref="debe391efc3dc12a7d87720a4cf068a5" category="inline-link-macro-rx"></block></block>
  <block id="7661400c51b9fc184bdec46eb5577ff9" category="doc">Ottieni codice da GitHub</block>
  <block id="1a3652d661d6b73b6aa57aff1fa5e4d4" category="paragraph">Ora che il volume NetApp Cloud o NetApp Trident è disponibile per il cluster Iguazio e l'ambiente di sviluppo, è possibile iniziare a rivedere l'applicazione.</block>
  <block id="ae53ae826cc9a587fbaee0e834dd75ca" category="paragraph">Gli utenti dispongono di un proprio spazio di lavoro (directory). Su ogni notebook, il percorso alla directory dell'utente è<block ref="60dfd72bb314eac7d0f73279723af059" prefix=" " category="inline-code"></block>. La piattaforma Iguazio gestisce la directory. Se si seguono le istruzioni riportate sopra, il volume NetApp Cloud è disponibile in<block ref="61bc18ea7642b598a1fcfad2e953599b" prefix=" " category="inline-code"></block> directory.</block>
  <block id="754e85a9ea7f4fbb718080a73790abdb" category="paragraph">Ottieni il codice da GitHub utilizzando un terminale Jupyter.</block>
  <block id="1d706cc291efb1d79274befd6f9dd64c" category="paragraph"><block ref="1d706cc291efb1d79274befd6f9dd64c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12d0e4b8ba8db4e6a7aa1dda942a1ed4" category="paragraph">Al prompt del terminale Jupyter, clonare il progetto.</block>
  <block id="d4095d9e0ab52b6d683ace00b5cbea55" category="paragraph">A questo punto, viene visualizzata la<block ref="fbeae7c8d4df4765206d2abb38069752" prefix=" " category="inline-code"></block> Nella struttura dei file nell'area di lavoro Jupyter.</block>
  <block id="f8161ff446bbd6f76b0d99d6f34a1d7f" category="inline-link-macro">Avanti: Configurare l'ambiente di lavoro</block>
  <block id="48dd929a2f5f248856ce2768950aff4e" category="paragraph"><block ref="48dd929a2f5f248856ce2768950aff4e" category="inline-link-macro-rx"></block></block>
  <block id="15a2a7497ac6041e1b73d7cb41406245" category="doc">TR-4811: Architettura di riferimento ai di NetApp ONTAP per il settore sanitario: Imaging diagnostico - progettazione della soluzione</block>
  <block id="eae34d8ef755492887b6a7aa4362588d" category="paragraph">Rick Huang, Sung-Han Lin, Sathish Thyagarajan, NetApp Jacci Cenci, NVIDIA</block>
  <block id="c92ae00fd88c8477c24628d0f17deceb" category="paragraph">Questa architettura di riferimento offre linee guida per i clienti che creano un'infrastruttura di intelligenza artificiale (ai) utilizzando i sistemi NVIDIA DGX-2 e lo storage NetApp AFF per i casi di utilizzo nel settore sanitario. Include informazioni sui flussi di lavoro di alto livello utilizzati per lo sviluppo di modelli di deep learning (DL) per l'imaging diagnostico medico, i casi di test validati e i risultati. Include anche consigli di dimensionamento per le implementazioni dei clienti.</block>
  <block id="5c6168ae6047f496e6903dde0fd3033c" category="paragraph"><block ref="5c6168ae6047f496e6903dde0fd3033c" category="inline-link-macro-rx"></block></block>
  <block id="65f63f96295566cd4278775eef1b4c8c" category="doc">Allocazione frazionale della GPU per carichi di lavoro meno impegnativi o interattivi</block>
  <block id="1b3d285072ee60a98cde2f66b6e47fde" category="paragraph">Quando ricercatori e sviluppatori stanno lavorando sui propri modelli, sia nelle fasi di sviluppo, tuning di iperparametri o debug, tali carichi di lavoro richiedono di solito meno risorse di calcolo. È quindi più efficiente eseguire il provisioning di GPU e memoria frazionarie in modo che la stessa GPU possa essere allocata contemporaneamente ad altri carichi di lavoro. La soluzione di orchestrazione di Run:ai offre un sistema di condivisione della GPU frazionale per carichi di lavoro containerizzati su Kubernetes. Il sistema supporta i carichi di lavoro che eseguono programmi CUDA ed è particolarmente adatto per attività ai leggere come inferenza e costruzione di modelli. Il sistema di GPU frazionale offre ai team di progettazione ai e data science la possibilità di eseguire più carichi di lavoro contemporaneamente su una singola GPU. Ciò consente alle aziende di eseguire più carichi di lavoro, ad esempio visione artificiale, riconoscimento vocale ed elaborazione del linguaggio naturale sullo stesso hardware, riducendo così i costi.</block>
  <block id="5db1fcd5bb529fa2475aaf893414d2e4" category="paragraph">Esegui: Il sistema di GPU frazionale di ai crea efficacemente GPU logiche virtualizzate con la propria memoria e spazio di calcolo che i container possono utilizzare e accedere come se fossero processori autonomi. In questo modo, è possibile eseguire diversi carichi di lavoro in container, uno accanto all'altro, sulla stessa GPU senza interferire l'uno con l'altro. La soluzione è trasparente, semplice e portatile e non richiede modifiche ai container stessi.</block>
  <block id="71cdf780e37cc9571b5fcd0bf89958b1" category="paragraph">Un'usecase tipica potrebbe visualizzare da due a otto lavori in esecuzione sulla stessa GPU, il che significa che è possibile eseguire otto volte il lavoro con lo stesso hardware.</block>
  <block id="0a1f69603a47f75f701f92ad7d94e3c5" category="paragraph">Per il lavoro<block ref="9ee74d566135099889c5305d14349d44" prefix=" " category="inline-code"></block> appartenente al progetto<block ref="ae7ccf7b1a6a1a023f611a294572a900" prefix=" " category="inline-code"></block> Nella figura seguente, è possibile vedere che il numero di GPU allocate era 0.50. Questo è ulteriormente verificato da<block ref="21c52f2a2730f054205ebdf40f536e5a" prefix=" " category="inline-code"></block> Che indica che la memoria GPU disponibile per il container era di 16,255 MB: Metà dei 32 GB per GPU V100 nel nodo DGX-1.</block>
  <block id="e6d9743072cdc6867ea2980c7db7e7fd" category="paragraph"><block ref="e6d9743072cdc6867ea2980c7db7e7fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9afb11deef37d75cf56adc6e1a2f4020" category="inline-link-macro">Successivo: Elevato utilizzo del cluster con allocazione della GPU con quota eccessiva</block>
  <block id="15968f671ef08561726e3064358c707b" category="paragraph"><block ref="15968f671ef08561726e3064358c707b" category="inline-link-macro-rx"></block></block>
  <block id="c1579c333c7c7a4e52136c7f58a7efc6" category="summary">La soluzione proposta in questo report tecnico è stata dimostrata per supportare l'offerta di esperienze clienti eccezionali di questo tipo e la sfida è ora quella di garantire che le aziende stiano adottando misure per modernizzare l'infrastruttura e i flussi di lavoro dell'ai.</block>
  <block id="9c5e72cb1709251063c12e4bddb1ba12" category="inline-link-macro">Precedente: Video e demo.</block>
  <block id="2f6461cd01fcb0c2d85704a563bd7c19" category="paragraph"><block ref="2f6461cd01fcb0c2d85704a563bd7c19" category="inline-link-macro-rx"></block></block>
  <block id="50d6e8cef34560d1d68c6688a12b1cb8" category="paragraph">Poiché l'esperienza dei clienti è diventata sempre più considerata come un terreno di battaglia competitivo fondamentale, un centro di supporto globale con intelligenza artificiale diventa un componente critico che le aziende di quasi tutti i settori non possono permettersi di trascurare. La soluzione proposta in questo report tecnico è stata dimostrata per supportare l'offerta di esperienze clienti eccezionali di questo tipo e la sfida è ora quella di garantire che le aziende stiano adottando misure per modernizzare l'infrastruttura e i flussi di lavoro dell'ai.</block>
  <block id="f6e349295b2165b25a412793116b8675" category="paragraph">Le migliori implementazioni dell'ai nel servizio clienti non devono sostituire gli agenti umani. Piuttosto, l'ai può consentire loro di creare esperienze eccezionali con i clienti attraverso analisi del sentimento in tempo reale, escalation delle controversie e calcolo affettivo multimodale per rilevare indizi verbali, non verbali e facciali con i quali modelli ai completi possono fornire consigli su larga scala e integrare ciò che un singolo agente umano potrebbe non essere presente. L'ai può anche fornire una migliore corrispondenza tra un particolare cliente e gli agenti attualmente disponibili. Utilizzando l'ai, le aziende possono estrarre il prezioso sentimento dei clienti riguardo alle loro opinioni e impressioni sui prodotti, i servizi e l'immagine del marchio del provider.</block>
  <block id="eb5cb6f03236a80f7ddd5085afa95729" category="paragraph">La soluzione può anche essere utilizzata per costruire dati Time-Series per gli agenti di supporto che fungono da metriche di valutazione obiettiva delle performance. I sondaggi convenzionali sulla soddisfazione dei clienti spesso non hanno risposte sufficienti. Raccogliendo il sentimento a lungo termine dei dipendenti e dei clienti, i datori di lavoro possono prendere decisioni informate in merito alle performance degli agenti di supporto.</block>
  <block id="aa20fc291fbb8ceda8651d8d8ee9dba6" category="paragraph">La combinazione di NetApp, SFL Scientific, framework di orchestrazione open-source e NVIDIA riunisce le più recenti tecnologie come servizi gestiti con grande flessibilità per accelerare l'adozione della tecnologia e migliorare il time-to-market per le nuove applicazioni ai/ML. Questi servizi avanzati vengono forniti on-premise e possono essere facilmente trasferiti per ambienti cloud-native e architetture di implementazione ibride.</block>
  <block id="71fd14327d5bf7e725ab97e00192b238" category="paragraph"><block ref="71fd14327d5bf7e725ab97e00192b238" category="inline-link-macro-rx"></block></block>
  <block id="fcf432f7f886df6aeafb1dec9357085d" category="doc">NVA-1150-DEPLOY: Guida all'implementazione dei sistemi Quantum StorNext con NetApp e-Series</block>
  <block id="806008ac96286a2e08058ba3a3daa601" category="paragraph">Ryan Rodine, NetApp</block>
  <block id="25dbf1b5193ae9eff63687c18c19e6f5" category="paragraph">Questo documento fornisce informazioni dettagliate su come implementare una soluzione di file system parallelo StorNext con i sistemi storage NetApp e-Series. Questa soluzione copre l'array all-flash NetApp EF280, l'array NVMe all-flash NetApp EF300, l'array NVMe all-flash NetApp EF600 e il sistema ibrido NetApp E5760. Offre una caratterizzazione delle performance basata sul benchmark Frametest, uno strumento ampiamente utilizzato per i test nel settore dei media e dell'intrattenimento.</block>
  <block id="a06fe4c2db4f7b09c705e4e8dafb5627" category="paragraph"><block ref="a06fe4c2db4f7b09c705e4e8dafb5627" category="inline-link-macro-rx"></block></block>
  <block id="dc12a1ce34c0a7a264de91bc9b933a62" category="paragraph">In questa sezione, mostreremo quando<block ref="ae7ccf7b1a6a1a023f611a294572a900" prefix=" " category="inline-code"></block> Richiede più GPU (sono sotto la loro quota), il sistema mette in pausa i carichi di lavoro di<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> e.<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> e li sposta in uno stato in sospeso in modo equo e condiviso.</block>
  <block id="86bbd55ea7850716c0c192b19c86176a" category="paragraph">Per ulteriori informazioni, tra cui invio dei job, immagini container utilizzate e sequenze di comandi eseguite, vedere la sezione <block ref="94d73a1896276f719be59227f0e93a14" category="inline-link-macro-rx"></block>.</block>
  <block id="b6ea2a2f48a443e7d027bd652ac84762" category="paragraph">La figura seguente mostra l'utilizzo del cluster risultante, le GPU allocate per team e i processi in sospeso a causa del bilanciamento automatico del carico e della pianificazione preventiva. Possiamo osservare che quando il numero totale di GPU richieste da tutti i carichi di lavoro del team supera il numero totale di GPU disponibili nel cluster, l'algoritmo di equità interna di Run:ai mette in pausa un job per ciascuno<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> e.<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> perché hanno soddisfatto la quota di progetto. In questo modo si ottiene un elevato utilizzo generale del cluster, mentre i team di data science continuano a lavorare sotto i limiti delle risorse stabiliti da un amministratore.</block>
  <block id="d1a54cf8cb2a06c0715d2f042fbf44bd" category="paragraph"><block ref="d1a54cf8cb2a06c0715d2f042fbf44bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d52816ece2166f7a2e0eadf58d617df9" category="paragraph">I risultati di questo scenario di test dimostrano quanto segue:</block>
  <block id="bce83ec0a92a5b10380007a1643b2fd0" category="list-text">*Bilanciamento automatico del carico.* il sistema bilancia automaticamente la quota delle GPU, in modo che ogni team utilizzi ora la propria quota. I carichi di lavoro che sono stati sospesi appartengono ai team che hanno superato la quota.</block>
  <block id="f8be0d1ca354f8cb4aaa4c8aadcea80b" category="list-text">*Fair share pause.* il sistema sceglie di arrestare il carico di lavoro di un team che ha superato la quota e quindi di arrestare il carico di lavoro dell'altro team. Run:ai dispone di algoritmi interni per la correttezza.</block>
  <block id="c088b6e407ba7f9c0274382acfa3eae0" category="inline-link-macro">Avanti: Equità nell'overquota</block>
  <block id="8e015e1b989b11d70fcb778747b8c614" category="paragraph"><block ref="8e015e1b989b11d70fcb778747b8c614" category="inline-link-macro-rx"></block></block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">L'automazione basata sull'ai e l'edge computing sono un approccio leader per aiutare le organizzazioni aziendali a ottenere la trasformazione digitale e massimizzare l'efficienza e la sicurezza delle operazioni. Con l'edge computing, i dati vengono elaborati molto più velocemente perché non devono viaggiare da e verso un data center. Di conseguenza, il costo associato all'invio dei dati avanti e indietro ai data center o al cloud è diminuito.</block>
  <block id="1490b4526090ba1052ae7d989d2f44df" category="inline-link-macro">Precedente: Opzioni di dimensionamento dell'architettura.</block>
  <block id="9d58af74dd11a7bf0a907e66af94ae03" category="paragraph"><block ref="9d58af74dd11a7bf0a907e66af94ae03" category="inline-link-macro-rx"></block></block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">L'automazione basata sull'ai e l'edge computing sono un approccio leader per aiutare le organizzazioni aziendali a ottenere la trasformazione digitale e massimizzare l'efficienza e la sicurezza delle operazioni. Con l'edge computing, i dati vengono elaborati molto più velocemente perché non devono viaggiare da e verso un data center. Di conseguenza, il costo associato all'invio dei dati avanti e indietro ai data center o al cloud è diminuito. Una latenza inferiore e una velocità maggiore possono essere utili quando le aziende devono prendere decisioni quasi in tempo reale utilizzando modelli di inferenza ai implementati all'edge della rete.</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">I sistemi storage NetApp offrono performance uguali o migliori rispetto allo storage SSD locale e offrono i seguenti vantaggi a data scientist, data engineer, sviluppatori ai/ML e decision maker aziendali o IT:</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">Condivisione semplice dei dati tra sistemi ai, analytics e altri sistemi aziendali critici. Questa condivisione dei dati riduce l'overhead dell'infrastruttura, migliora le performance e ottimizza la gestione dei dati in tutta l'azienda.</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">Calcolo e storage scalabili in maniera indipendente per ridurre al minimo i costi e migliorare l'utilizzo delle risorse.</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">Workflow di sviluppo e implementazione ottimizzati grazie a copie Snapshot e cloni integrati per spazi di lavoro degli utenti istantanei ed efficienti in termini di spazio, controllo integrato delle versioni e implementazione automatizzata.</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">Protezione dei dati di livello Enterprise per disaster recovery e business continuity. La soluzione NetApp e Lenovo presentata in questo documento è un'architettura scalabile e flessibile, ideale per le implementazioni di inferenza ai di livello Enterprise all'edge della rete.</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">J.J. Falkanger, Sr Manager, soluzioni HPC e ai, Lenovo</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">Dave Arnette, Technical Marketing Engineer, NetApp</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">Joey Parnell, Tech Lead e-Series ai Solutions, NetApp</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">Cody Harryman, QA Engineer, NetApp</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">Pagina del prodotto array NetApp AFF A-Series</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">Software per la gestione dei dati NetApp ONTAP: Libreria di informazioni ONTAP 9</block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">TR-4727: Introduzione a NetApp EF-Series</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">Scheda informativa sul software NetApp e-Series SANtricity</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="list-text">MLPerf</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">Benchmark TensorFlow</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="list-text">Lenovo ThinkSystem SE350 Edge Server</block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">Array di storage flash unificato Lenovo ThinkSystem DM5100F</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="a4113bc79b3920d11274d7bf9cfafe10" category="paragraph"><block ref="a4113bc79b3920d11274d7bf9cfafe10" category="inline-link-rx"></block></block>
  <block id="5e79a20254a28ffdb604f6cba5216c75" category="cell">Marzo 2021</block>
  <block id="71b3f2dc39aa770e58cd3fad98b76c37" category="cell">Aggiornato con EF e MLPerf Inference v1.1</block>
  <block id="7c0ea3e86521674f72e056d148d4f2ce" category="paragraph">NetApp e Run:ai hanno collaborato a questo report tecnico per dimostrare le funzionalità esclusive della soluzione ai di NetApp ONTAP insieme alla piattaforma Run:ai per semplificare l'orchestrazione dei carichi di lavoro ai. I passaggi precedenti forniscono un'architettura di riferimento per ottimizzare il processo di pipeline di dati e orchestrazione dei carichi di lavoro per un apprendimento approfondito. I clienti che desiderano implementare queste soluzioni sono incoraggiati a contattare NetApp e Run:ai per ulteriori informazioni.</block>
  <block id="f797637684ff1290d12e5495dac050a6" category="inline-link-macro">Pagina successiva: Dettagli sui test per la Sezione 4.8</block>
  <block id="bbe251d46ac2a6899a2a4d5d0e331a43" category="paragraph"><block ref="bbe251d46ac2a6899a2a4d5d0e331a43" category="inline-link-macro-rx"></block></block>
  <block id="74b3e84bf9817092a6f26ddf10a2f3f8" category="summary">Questa pagina fornisce una panoramica della tecnologia utilizzata in questa soluzione.</block>
  <block id="dd5a70c15c985f455edb59eebf8d3eaa" category="paragraph"><block ref="dd5a70c15c985f455edb59eebf8d3eaa" category="inline-link-macro-rx"></block></block>
  <block id="4b2eedb67d8fb9da01af759e6e722a13" category="section-title">Microsoft e NetApp</block>
  <block id="09e4ef7b38fea4a7bdf4341b588176d6" category="paragraph">Da maggio 2019, Microsoft ha fornito un servizio di portale nativo e di prima parte Azure per file service NFS e SMB aziendali basati sulla tecnologia NetApp ONTAP. Questo sviluppo è guidato da una partnership strategica tra Microsoft e NetApp e estende ulteriormente la portata dei servizi dati ONTAP di livello mondiale ad Azure.</block>
  <block id="851e5baafa3bd23201e65e29f2fdf06a" category="paragraph">Il servizio Azure NetApp Files è un servizio di storage di file di livello Enterprise, dalle performance elevate e misurato. Azure NetApp Files supporta qualsiasi tipo di carico di lavoro ed è altamente disponibile per impostazione predefinita. È possibile selezionare i livelli di servizio e di performance e impostare le copie Snapshot tramite il servizio. Azure NetApp Files è un servizio Azure first-party per la migrazione e l'esecuzione dei carichi di lavoro dei file aziendali più esigenti nel cloud, inclusi database, SAP e applicazioni di calcolo ad alte performance senza modifiche del codice.</block>
  <block id="f014a6e06480ef33e3f1ab027f7065ca" category="paragraph">Questa architettura di riferimento offre alle organizzazioni IT i seguenti vantaggi:</block>
  <block id="5116c5071beb9f4f5b673c988c417c71" category="list-text">Consente una scalabilità indipendente di calcolo e storage</block>
  <block id="5e6e9a1ee378cf26b50e61d8bd46d54d" category="list-text">Offre una gamma di Tier di storage per diversi punti di costo e performance</block>
  <block id="295f4f6daaf50c87d2639d407c47f357" category="section-title">Panoramica di DAK e NVIDIA RAPIDS</block>
  <block id="a9dcf931a9aad845de3c5b908d562955" category="paragraph">Dask è un tool di calcolo parallelo open-source che scala le librerie Python su più macchine e fornisce un'elaborazione più rapida di grandi quantità di dati. Fornisce un'API simile alle librerie Python convenzionali a thread singolo, come Pandas, Numpy e scikit-Learn. Di conseguenza, gli utenti nativi di Python non sono costretti a modificare molto nel codice esistente per utilizzare le risorse all'interno del cluster.</block>
  <block id="955647f3573b932f8596ba04ed80b7b6" category="paragraph">NVIDIA RAPIDS è una suite di librerie open-source che consente di eseguire FLUSSI DI lavoro END-to-end DI ANALISI DEI dati E ML interamente su GPU. Insieme a Dask, consente di scalare facilmente da workstation GPU (scale-up) a cluster multi-GPU a più nodi (scale-out).</block>
  <block id="7a9ece70a2d60d73203e927718fd8454" category="paragraph">Per l'implementazione di DAK su un cluster, è possibile utilizzare Kubernetes per l'orchestrazione delle risorse. È inoltre possibile scalare in verticale o in orizzontale i nodi di lavoro in base ai requisiti di processo, che a loro volta possono aiutare a ottimizzare il consumo delle risorse del cluster, come illustrato nella figura seguente.</block>
  <block id="b3951b803e4010ed575c9238d2803949" category="paragraph"><block ref="b3951b803e4010ed575c9238d2803949" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2e194dd3ce5b4d001a02991ef567211" category="inline-link-macro">Avanti: Requisiti software.</block>
  <block id="23704e1baeed350311b18c3583ad89e9" category="paragraph"><block ref="23704e1baeed350311b18c3583ad89e9" category="inline-link-macro-rx"></block></block>
  <block id="232abf87aa3028a990e94f6bb51fe8bd" category="summary">Per eseguire un processo ai e ML a nodo singolo nel cluster Kubernetes, eseguire le attività descritte in questa pagina dall'host di distribuzione jump.</block>
  <block id="46300fa439cc237919f854816fc89fc2" category="doc">Eseguire un carico di lavoro ai a nodo singolo</block>
  <block id="ebbcd572ece7625ba24f2c3ecda6d5b5" category="paragraph">Per eseguire un processo ai e ML a nodo singolo nel cluster Kubernetes, eseguire le seguenti operazioni dall'host di distribuzione jump. Con Trident, è possibile rendere un volume di dati, potenzialmente contenente petabyte di dati, accessibile a un carico di lavoro Kubernetes in modo rapido e semplice. Per rendere un volume di dati accessibile dall'interno di un pod Kubernetes, è sufficiente specificare un PVC nella definizione del pod. Si tratta di un'operazione nativa di Kubernetes, senza richiedere alcuna esperienza NetApp.</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">In questa sezione si presuppone che sia già stato containerizzato (nel formato Docker Container) il carico di lavoro ai e ML specifico che si sta tentando di eseguire nel cluster Kubernetes.</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">Sito Web ImageNet</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">I seguenti comandi di esempio mostrano la creazione di un lavoro Kubernetes per un carico di lavoro di benchmark TensorFlow che utilizza il dataset ImageNet. Per ulteriori informazioni sul set di dati ImageNet, vedere<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block>.</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">Questo processo di esempio richiede otto GPU e quindi può essere eseguito su un singolo nodo di lavoro GPU che dispone di otto o più GPU. Questo job di esempio potrebbe essere inviato in un cluster per il quale un nodo di lavoro con otto o più GPU non è presente o è attualmente occupato con un altro workload. In tal caso, il lavoro rimane in uno stato in sospeso fino a quando tale nodo di lavoro non diventa disponibile.</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">Documentazione ufficiale di Kubernetes</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">Inoltre, per massimizzare la larghezza di banda dello storage, il volume contenente i dati di training necessari viene montato due volte all'interno del pod creato da questo lavoro. Nel pod è montato anche un altro volume. Questo secondo volume verrà utilizzato per memorizzare risultati e metriche. Questi volumi vengono referenziati nella definizione del lavoro utilizzando i nomi dei PVC. Per ulteriori informazioni sui job Kubernetes, consultare<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block>.</block>
  <block id="225e66547943a27f429558dce4e639e2" category="paragraph">An<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> volume con a.<block ref="075a3e36a0a52dcbc568c05788e8a713" prefix=" " category="inline-code"></block> valore di<block ref="4789f23283b3a61f858b641a1bef19a3" prefix=" " category="inline-code"></block> è montato su<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> nel pod creato da questo lavoro di esempio. La dimensione predefinita di<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> Il volume virtuale creato automaticamente dal runtime del container Docker può talvolta essere insufficiente per le esigenze di TensorFlow. Montaggio di un<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> il volume come nell'esempio seguente fornisce un volume sufficientemente grande<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> volume virtuale. Per ulteriori informazioni su<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> volumes (volumi), vedere<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block>.</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">Al singolo contenitore specificato in questa definizione di lavoro di esempio viene assegnato un<block ref="616a0bdac22bb48049712f2f41741fd1" prefix=" " category="inline-code"></block> valore di<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>. Questo valore significa che il container dispone effettivamente dell'accesso root sull'host. Questa annotazione viene utilizzata in questo caso perché il carico di lavoro specifico che viene eseguito richiede l'accesso root. In particolare, un'operazione di cancellazione della cache eseguita dal carico di lavoro richiede l'accesso root. Che sia o meno così<block ref="8be504a312b42bc24ff61c9c2c31990d" prefix=" " category="inline-code"></block> l'annotazione è necessaria a seconda dei requisiti del carico di lavoro specifico che si sta eseguendo.</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">Verificare che il lavoro creato al punto 1 sia in esecuzione correttamente. Il seguente comando di esempio conferma che è stato creato un singolo pod per il lavoro, come specificato nella definizione del lavoro, e che questo pod è attualmente in esecuzione su uno dei nodi di lavoro GPU.</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">Verificare che il lavoro creato al passo 1 sia stato completato correttamente. I seguenti comandi di esempio confermano che il lavoro è stato completato correttamente.</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">*Opzionale:* eliminare gli artefatti del lavoro. I seguenti comandi di esempio mostrano l'eliminazione dell'oggetto di lavoro creato al passo 1.</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">Quando si elimina l'oggetto di lavoro, Kubernetes elimina automaticamente tutti i pod associati.</block>
  <block id="7af76512b5f0f470c6a7a6db368a9818" category="inline-link-macro">Eseguire un carico di lavoro ai distribuito sincrono.</block>
  <block id="e79dd849e38d01ac3faa7090e83320b2" category="paragraph"><block ref="e79dd849e38d01ac3faa7090e83320b2" category="inline-link-macro-rx"></block></block>
  <block id="33204bfa9ee287508f03782fd7ad512e" category="summary">Prima di utilizzare Trident per eseguire il provisioning dinamico delle risorse di storage all'interno del cluster Kubernetes, è necessario creare una o più Kubernetes StorageClasses. Gli esempi riportati in questa pagina rappresentano diversi tipi di StorageClasses che è possibile creare se si sta implementando la soluzione NetApp ai Control Plane su un pod ai ONTAP.</block>
  <block id="6631bf64346739a9880a9789a941a8d6" category="doc">Esempi di storage Classes Kubernetes per implementazioni ai ONTAP</block>
  <block id="d9206a5144976221af82df78ad3d7977" category="paragraph">Prima di utilizzare Trident per eseguire il provisioning dinamico delle risorse di storage all'interno del cluster Kubernetes, è necessario creare una o più Kubernetes StorageClasses. Gli esempi che seguono rappresentano diversi tipi di StorageClasses che potresti voler creare se stai implementando la soluzione NetApp ai Control Plane su un pod ai ONTAP. Per ulteriori informazioni su StorageClasses, vedere<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="f363c1a10e150fdee0f4f310a06acb5e" category="inline-link-macro">Esempi di backend Trident per implementazioni ai ONTAP</block>
  <block id="993143e7434e63409a07cf3e8c422505" category="list-text">NetApp consiglia di creare una StorageClass separata per ogni backend Trident abilitato per FlexGroup creato nella sezione <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, fase 1. Questi StorageClasses granulari consentono di aggiungere i montaggi NFS che corrispondono a LIF specifiche (le LIF specificate al momento della creazione dei Trident Backend) come backend specifico specificato nel file delle specifiche StorageClass. I comandi di esempio che seguono mostrano la creazione di due StorageClasses che corrispondono ai due backend di esempio creati nella sezione <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, fase 1. Per ulteriori informazioni su StorageClasses, vedere<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">Documentazione Kubernetes</block>
  <block id="a596fcc71d1c43e3ba86b1557ac7af81" category="paragraph">Per evitare che un volume persistente venga cancellato quando il PVC (PersistentVolumeClaim) corrispondente viene cancellato, nel seguente esempio viene utilizzato un<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> valore di<block ref="afece4245269582cb2f1009d4fb52047" prefix=" " category="inline-code"></block>. Per ulteriori informazioni su<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> vedi il sito ufficiale<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block>.</block>
  <block id="f053cb3a491d2bc48d41230b10a9b164" category="list-text">NetApp consiglia inoltre di creare un StorageClass che corrisponda al backend Trident abilitato a FlexVol creato nella sezione <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, punto 2. I comandi di esempio che seguono mostrano la creazione di una singola classe di storage per volumi FlexVol.</block>
  <block id="99608a01905f0e69895bbb864a0deba3" category="paragraph">Nell'esempio seguente, un particolare backend non viene specificato nel file di definizione StorageClass perché è stato creato un solo backend Trident abilitato a FlexVol. Quando si utilizza Kubernetes per amministrare volumi che utilizzano questo StorageClass, Trident tenta di utilizzare qualsiasi backend disponibile che utilizzi<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> driver.</block>
  <block id="ee1d27a4ae3e30ff30ef72e305b029e7" category="list-text">NetApp consiglia inoltre di creare una classe di storage generica per i volumi FlexGroup. I seguenti comandi di esempio mostrano la creazione di una singola classe di storage generica per volumi FlexGroup.</block>
  <block id="d4a43a35c5d5a5ce3aefe77ceaa73a5c" category="paragraph">Si noti che un particolare backend non viene specificato nel file di definizione StorageClass. Pertanto, quando si utilizza Kubernetes per amministrare volumi che utilizzano questo StorageClass, Trident tenta di utilizzare qualsiasi backend disponibile che utilizzi<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> driver.</block>
  <block id="b569e24403ad128c09e2d0dbd0116463" category="inline-link-macro">Pagina successiva: Panoramica sull'implementazione di Kubeflow.</block>
  <block id="66f5564ed29f37f0b81d2dde741b9c8f" category="paragraph"><block ref="66f5564ed29f37f0b81d2dde741b9c8f" category="inline-link-macro-rx"></block></block>
  <block id="2732cb29fe3befd83c06e7c220b5456d" category="doc">Dettagli sui test per la Sezione 4.10</block>
  <block id="273936fc522fd7dbe4473de8a0b2a985" category="paragraph">Questa sezione contiene i dettagli dei test per la sezione <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>.</block>
  <block id="cf46f9264bb33ef7576cf671194a0275" category="paragraph">Inoltrare i lavori nel seguente ordine per<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block>,<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block>, e.<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block>:</block>
  <block id="fac80c1054e849e1ec88244c017978e7" category="cell">1 carico di lavoro in coda</block>
  <block id="eefc99cd833e14811fb22b758cbc62e5" category="cell">2 carichi di lavoro in coda</block>
  <block id="001f9003205f670658ffc60b1e4d62d8" category="cell">Due carichi di lavoro che richiedono due GPU ciascuno</block>
  <block id="f0f10ddbe8f00433aad17626c8d96a73" category="cell">Due carichi di lavoro che richiedono due GPU ciascuno</block>
  <block id="61b8291124bff8ee36a1c799e35395e9" category="paragraph">Quindi, eliminare tutti i carichi di lavoro per<block ref="ae7ccf7b1a6a1a023f611a294572a900" prefix=" " category="inline-code"></block>:</block>
  <block id="ed9cf33d84548b5953f8b042c72faef4" category="paragraph">Vedere la sezione <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>, per discussioni sullo scenario di test.</block>
  <block id="543cdcd352596e4ad69b4597a2188c02" category="paragraph"><block ref="543cdcd352596e4ad69b4597a2188c02" category="inline-link-macro-rx"></block></block>
  <block id="efbb4ade01a09771413f4c09880e800a" category="paragraph">In questa sezione, espandiamo lo scenario in cui più team inviano carichi di lavoro e superano la loro quota. In questo modo, dimostreremo come l'algoritmo di equità di Run:ai alloca le risorse del cluster in base al rapporto delle quote preimpostate.</block>
  <block id="3bd5af2e3a75651c4b9c45d26400fbaa" category="paragraph">Obiettivi per questo scenario di test:</block>
  <block id="cc9e23eb4fe1626d97a5dfeab7cf0d25" category="list-text">Mostra il meccanismo di accodamento quando più team richiedono GPU sulla propria quota.</block>
  <block id="050060785f2852b203c9e82254f2946a" category="list-text">Mostrare come il sistema distribuisce una quota equa del cluster tra più team che superano la quota in base al rapporto tra le quote, in modo che il team con la quota maggiore ottenga una quota maggiore della capacità di riserva.</block>
  <block id="9e06f625a31670e60f0a8a09917c3ba0" category="paragraph">Alla fine di <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>, sono presenti due carichi di lavoro in coda: uno per<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> e uno per<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block>. In questa sezione, vengono accodati carichi di lavoro aggiuntivi.</block>
  <block id="286cda6cf9e9438a2cff2827773cfe7a" category="inline-link-macro">Dettagli sui test per la sezione 4.10</block>
  <block id="0e7a9992269080ceaf2b90c188cbb861" category="paragraph">Per ulteriori informazioni, tra cui invio di lavori, immagini container utilizzate e sequenze di comandi eseguite, vedere <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>.</block>
  <block id="b1df8ade330dd8e3c0962d87a58c1ba9" category="paragraph">Quando tutti i lavori vengono inoltrati in base alla sezione <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>, il dashboard di sistema lo mostra<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block>,<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block>, e.<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Tutti hanno più GPU rispetto alla quota preimpostata.<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block> Occupa quattro GPU in più rispetto alla quota soft preimpostata (quattro), mentre<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> e.<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Ciascuna di esse occupa due GPU in più rispetto alla propria quota soft (due). Il rapporto delle GPU con overquota allocate è uguale a quello della quota preimpostata. Questo perché il sistema ha utilizzato la quota preimpostata come riferimento di priorità e fornito di conseguenza quando più team richiedono più GPU, superando la quota. Tale bilanciamento automatico del carico offre equità e prioritizzazione quando i team di data science aziendali sono attivamente impegnati nello sviluppo e nella produzione di modelli di ai.</block>
  <block id="6effcb49094093af4699b050b9994a58" category="paragraph"><block ref="6effcb49094093af4699b050b9994a58" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aa04853a58b1b9ab0033c7e24b9d929" category="paragraph">I risultati di questo scenario di test mostrano quanto segue:</block>
  <block id="b3be1869ca88e0b5881bc6d1da583426" category="list-text">Il sistema inizia a demettere in coda i carichi di lavoro di altri team.</block>
  <block id="d2325970b5cec6b47eb2c10267e3a599" category="list-text">L'ordine di dequeuing viene stabilito in base agli algoritmi di equità, in modo che<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> e.<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Ottenere la stessa quantità di GPU con quote eccessive (poiché hanno una quota simile), e.<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block> Ottiene una quantità doppia di GPU poiché la loro quota è due volte superiore alla quota di<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> e.<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block>.</block>
  <block id="e2cc28c61aaa6ca7e38bd7ed9de398f1" category="list-text">Tutta l'allocazione viene eseguita automaticamente.</block>
  <block id="c21d5f3e7c1336258c406bddcde6e0f8" category="paragraph">Pertanto, il sistema dovrebbe stabilizzarsi nei seguenti stati:</block>
  <block id="8f2185cd998019e76038f11669cfbfb0" category="cell">GPU allocate</block>
  <block id="3b55c08436be9e1008bb19488c139c88" category="cell">8/4</block>
  <block id="f532ced5959572a93091758c821d7ff1" category="cell">Quattro GPU oltre la quota. Coda vuota.</block>
  <block id="c3a4885d143dc5b306446fb380c6cfda" category="cell">4/2</block>
  <block id="b0713292a73176f9754bd528cecde2d1" category="cell">Due GPU oltre la quota. Un carico di lavoro in coda.</block>
  <block id="1f0189591d8d7dc1d3db367398fb49c5" category="cell">0/8</block>
  <block id="7c0de9de98eb6577a96694238e533915" category="cell">Non utilizzare le GPU, non i carichi di lavoro in coda.</block>
  <block id="948c32bf5f56f7dd6f3b2baab5f6d89d" category="paragraph">La figura seguente mostra l'allocazione della GPU per progetto nel tempo nella dashboard Run:ai Analytics per le sezioni <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>, <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>, e. <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>. Ciascuna riga della figura indica il numero di GPU fornite per un determinato team di data science in qualsiasi momento. Possiamo vedere che il sistema alloca dinamicamente le GPU in base ai carichi di lavoro inviati. Ciò consente ai team di superare la quota quando nel cluster sono disponibili GPU, quindi di prevenire i lavori in base all'equità, prima di raggiungere infine uno stato stabile per tutti e quattro i team.</block>
  <block id="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="paragraph"><block ref="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e94097f9836d70dc64016728992696a0" category="inline-link-macro">Successivo: Salvataggio dei dati in un PersistentVolume con provisioning Trident</block>
  <block id="14718f3c808034f0e3239dbaf832a478" category="paragraph"><block ref="14718f3c808034f0e3239dbaf832a478" category="inline-link-macro-rx"></block></block>
  <block id="2bbac71d034e7a7a1fca44c7500e187b" category="doc">NetApp ONTAP ai con NVIDIA</block>
  <block id="4618b9225719de309c0b0f5aa4718c7b" category="paragraph">Panoramica delle soluzioni di infrastruttura convergente ONTAP ai di NetApp e NVIDIA.</block>
  <block id="ab9d770eb05e7725141740f508566fce" category="section-title">NetApp ONTAP ai con sistemi NVIDIA DGX A100</block>
  <block id="e7f098b026755d10f2c3f16d0ff0b1db" category="inline-link-macro">Guida alla progettazione</block>
  <block id="1027b152cc3e8165ce099ede9548be95" category="list-text"><block ref="1027b152cc3e8165ce099ede9548be95" category="inline-link-macro-rx"></block></block>
  <block id="dfb1e9c5f4c5835e6e1a4173130a49c9" category="inline-link-macro">Guida all'implementazione</block>
  <block id="983044e3ba861493c43c08b9285c3125" category="list-text"><block ref="983044e3ba861493c43c08b9285c3125" category="inline-link-macro-rx"></block></block>
  <block id="7c962be0dc8fdf28c1c4279fe5256a22" category="section-title">NetApp ONTAP ai con sistemi NVIDIA DGX A100 e switch Ethernet Mellanox Spectrum</block>
  <block id="d91f70a15d40fe5795af6ded9555e095" category="list-text"><block ref="d91f70a15d40fe5795af6ded9555e095" category="inline-link-macro-rx"></block></block>
  <block id="8e9465b5d4318c8ef9039dfe684619d5" category="list-text"><block ref="8e9465b5d4318c8ef9039dfe684619d5" category="inline-link-macro-rx"></block></block>
  <block id="f737e7cc3d8aa89c5b49c4fe701e9e40" category="summary">In questa convalida, abbiamo eseguito il training per il riconoscimento delle immagini come specificato da MLPerf v2.0. In particolare, abbiamo formato il modello ResNet v2.0 con il dataset ImageNet. La metrica principale è il tempo necessario per raggiungere la precisione desiderata. Inoltre, segnaliamo la larghezza di banda del training in immagini al secondo per valutare meglio l'efficienza dello scale-out.</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">Piano di test</block>
  <block id="813c7764ec170fb5498e50560d32a97f" category="paragraph"><block ref="813c7764ec170fb5498e50560d32a97f" category="inline-link-macro-rx"></block></block>
  <block id="0f25983094bc4cf5cea830260da8ee75" category="paragraph">In questa convalida, abbiamo eseguito il training per il riconoscimento delle immagini come specificato da MLPerf v2.0. In particolare, abbiamo formato il modello ResNet v2.0 con il set di dati ImageNet fino a raggiungere una precisione del 76.1%. La metrica principale è il tempo necessario per raggiungere la precisione desiderata. Inoltre, segnaliamo la larghezza di banda del training in immagini al secondo per valutare meglio l'efficienza dello scale-out.</block>
  <block id="ac3e6a4fbe8e02d639c2defeebeac17f" category="paragraph">Il test case principale ha valutato più processi di training indipendenti (uno per nodo) in esecuzione simultanea. Simula il caso d'utilizzo principale, un sistema condiviso utilizzato da più data scientist. Il secondo caso di test ha valutato l'efficienza dello scale-out.</block>
  <block id="7dc96590f7bab3379a7a79986056d22a" category="inline-link-macro">Segue: Risultati del test.</block>
  <block id="e34017da9a1a8d672a4859eb7c75947a" category="paragraph"><block ref="e34017da9a1a8d672a4859eb7c75947a" category="inline-link-macro-rx"></block></block>
  <block id="60f89129c6220bfb3de5a84b4f6471ca" category="summary">In questa pagina viene descritto come abbiamo utilizzato Pandas e Dask DataFrame per caricare i dati dei registri Click dal dataset Criteo Terabyte. Il caso d'utilizzo è importante nella pubblicità digitale per gli scambi di annunci per creare i profili degli utenti prevedendo se gli annunci verranno cliccati o se lo scambio non utilizza un modello accurato in una pipeline automatica.</block>
  <block id="efdbc2f24f0a87c559175250c645b26b" category="doc">Load Criteo fare clic su Logs giorno 15 in Pandas e formare un modello di foresta casuale scikit-learn</block>
  <block id="2979440f06f7cfcab78b9a92ca964f28" category="inline-link-macro">Precedente: Librerie per l'elaborazione dei dati e la formazione sui modelli.</block>
  <block id="f2982e3861753bd206faa379a769d904" category="paragraph"><block ref="f2982e3861753bd206faa379a769d904" category="inline-link-macro-rx"></block></block>
  <block id="f82859e215621220b9aae984f796ef24" category="paragraph">In questa sezione viene descritto come abbiamo utilizzato Pandas e Dask DataFrame per caricare i dati dei registri Click dall'insieme di dati Criteo Terabyte. Il caso d'utilizzo è importante nella pubblicità digitale per gli scambi di annunci per creare i profili degli utenti prevedendo se gli annunci verranno cliccati o se lo scambio non utilizza un modello accurato in una pipeline automatica.</block>
  <block id="f08833dbbe310e84a1ba564838776db2" category="paragraph">Abbiamo caricato i dati del giorno 15 dal set di dati Click Logs, per un totale di 45 GB. Eseguire la seguente cella nel notebook Jupyter<block ref="687d69c323eb8500d21df9bfb49c3b55" prefix=" " category="inline-code"></block> Crea un Pandas DataFrame che contiene i primi 50 milioni di righe e genera un modello di foresta casuale scikit-Learn.</block>
  <block id="f9964b2f8f54a1422ac46bab70fd1216" category="inline-link">documentazione ufficiale scikit-learn</block>
  <block id="5646953e1414498e1ddf2eb3ab488e27" category="paragraph">Per eseguire la previsione utilizzando un modello di foresta casuale con formazione, eseguire il paragrafo seguente in questo notebook. Abbiamo preso gli ultimi un milione di righe dal giorno 15 come set di test per evitare qualsiasi duplicazione. La cella calcola anche la precisione della previsione, definita come la percentuale di occorrenze che il modello prevede accuratamente se un utente fa clic su un annuncio o meno. Per esaminare eventuali componenti non familiari presenti in questo notebook, consultare la sezione<block ref="27e4d9ca2442a6439517a3ec2c7a4e73" category="inline-link-rx"></block>.</block>
  <block id="4e5653c75e720212b79703e8083de2a8" category="inline-link-macro">Successivo: Caricare il giorno 15 in Dask e formare un modello di foresta casuale di Dask cuML.</block>
  <block id="8c9976282cff1b15934d937349911c30" category="paragraph"><block ref="8c9976282cff1b15934d937349911c30" category="inline-link-macro-rx"></block></block>
  <block id="9892437a073c63ca6232150c28b21c7b" category="doc">NVA-1156-DEPLOY: NetApp EF-Series ai con sistemi NVIDIA DGX A100 e BeeGFS</block>
  <block id="4472645bc6fe350406624df126edf4ac" category="paragraph">Abdel Sadek, Tim Chau, Joe McCormick e David Arnette, NetApp</block>
  <block id="7d8f094cc030aec75a343f1baad8c19d" category="paragraph">Questo documento descrive un'architettura verificata di NetApp per i carichi di lavoro di apprendimento automatico (ML) e intelligenza artificiale (ai) che utilizzano i sistemi storage NetApp EF600 NVMe, il file system parallelo ThinkParQ BeeGFS, i sistemi NVIDIA DGX A100 e gli switch NVIDIA Mellanox Quantum QM8700 200Gbps InfiniBand (IB). Questo documento include anche istruzioni per l'esecuzione dei test di benchmark di convalida al termine dell'implementazione.</block>
  <block id="ac6445146035971ff06dde08fd7cd295" category="paragraph"><block ref="ac6445146035971ff06dde08fd7cd295" category="inline-link-macro-rx"></block></block>
  <block id="28b9eb1a9ba550cf23239eb33610203e" category="doc">Requisiti software e hardware</block>
  <block id="dce011ea921230b4e3061bb70569c598" category="section-title">Configurazione di rete</block>
  <block id="5c56d5a342310a4d1ead67adc85adcab" category="paragraph">Di seguito è riportato il requisito di configurazione di rete per l'impostazione nel cloud:</block>
  <block id="df97d4ea35e2febbb06b9bd1ba29b50e" category="list-text">Il cluster Iguazio e i volumi NetApp Cloud devono trovarsi nello stesso cloud privato virtuale.</block>
  <block id="a8f3c1a7fc956bcddef483bc8797e742" category="list-text">Il cloud manager deve avere accesso alla porta 6443 sui nodi dell'applicazione Iguazio.</block>
  <block id="0d1562d43d3c0d4c52eef4a841896eba" category="list-text">Abbiamo utilizzato Amazon Web Services in questo report tecnico. Tuttavia, gli utenti hanno la possibilità di implementare la soluzione in qualsiasi provider cloud.per i test on-premise in ONTAP ai con NVIDIA DGX-1, abbiamo utilizzato il servizio DNS in hosting Iguazio per comodità.</block>
  <block id="820de5e74a90f4dbc17e37b78258c35b" category="paragraph">I client devono essere in grado di accedere ai domini DNS creati dinamicamente. Se lo si desidera, i clienti possono utilizzare il proprio DNS.</block>
  <block id="43ad77bf4f253415b4e90ea4aa41a2d7" category="paragraph">È possibile installare Iguazio on-premise nel proprio cluster. Abbiamo verificato la soluzione in NetApp ONTAP ai con un sistema NVIDIA DGX-1. La seguente tabella elenca l'hardware utilizzato per testare questa soluzione.</block>
  <block id="7b6f2acc1b4489fd971965be635ea987" category="cell">Sistema NetApp AFF A800</block>
  <block id="55552614d2dd18f2d6c40759f2de9e22" category="cell">1 coppia ad alta disponibilità (ha), include 2 controller e 48 SSD NVMe (3,8 TB o superiore)</block>
  <block id="413400218c4c262991ad8483b3be0a04" category="cell">Switch di rete Cisco Nexus 3232C</block>
  <block id="72f23e74ab545a9064f74aca4d904bf4" category="paragraph">La seguente tabella elenca i componenti software necessari per il test on-premise:</block>
  <block id="f82f50748d06cc9643330a4a8297ba43" category="cell">9.7</block>
  <block id="751601035b4077a9c6f7280ab1d3369c" category="cell">4.4 - Ubuntu 18.04 LTS</block>
  <block id="bb3121464976ef0c6b6b2b81fc75f3c5" category="cell">19.03.5</block>
  <block id="2a820a07d05055e147221622557f34b9" category="cell">Versione container</block>
  <block id="6f3d0f773f6be20d70e6bbbafca93de9" category="cell">20.01-tf1-py2</block>
  <block id="46b6cc5d90605df4689002387db99128" category="cell">Framework per l'apprendimento automatico</block>
  <block id="f060e908e90b13cff9447e18fbb6bb20" category="cell">TensorFlow 1.15.0</block>
  <block id="4ec1f03a0b910370451392d8af8cd05a" category="cell">Iguazio</block>
  <block id="80b1aaf85493db4117fca57135bec077" category="cell">Versione 2.8+</block>
  <block id="20de768bd6142b858c4e99c64e19f37b" category="cell">Server ESX</block>
  <block id="f884cc5c56f9c9a8d4d61568ff64db9c" category="cell">6.5</block>
  <block id="95b4a53c1023a65c982b077b13be4b96" category="paragraph">Questa soluzione è stata completamente testata con Iguazio versione 2.5 e NetApp Cloud Volumes ONTAP per AWS. Il cluster Iguazio e il software NetApp sono entrambi in esecuzione su AWS.</block>
  <block id="efbef76fea5d52b17e66f66b7fbdb1be" category="cell">Versione o tipo</block>
  <block id="1f2c90c0f9931b94eab6d9d2d3a640c9" category="cell">Nodo app</block>
  <block id="8f33b30dd333b320c87f038f61e17523" category="cell">M5.4xGrande</block>
  <block id="b8f3b98512c841c7f30ce704570ac0b6" category="cell">Nodo dati</block>
  <block id="ea93f0324aaeaa177497ea41b52cb9ff" category="cell">I3,4 x grande</block>
  <block id="870032d2d605939c0c8a813ac8534e80" category="inline-link-macro">Avanti: Riepilogo dei casi d'uso per la previsione dei guasti dei dispositivi di rete</block>
  <block id="6b90a2e4861b0a6faf4f640ece131282" category="paragraph"><block ref="6b90a2e4861b0a6faf4f640ece131282" category="inline-link-macro-rx"></block></block>
  <block id="3ff1a758f526c5ceb434059efe27020a" category="summary">Esempio di flussi di lavoro Apache Airflow</block>
  <block id="c5da96d7204df28dd9fdc33139c8a776" category="paragraph">Il<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> Utilizzabile in combinazione con il flusso d'aria. L'utilizzo del NetApp Data Science Toolkit con Airflow consente di incorporare le operazioni di gestione dei dati NetApp in flussi di lavoro automatizzati orchestrati dal flusso d'aria.</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">Esempi di flusso d'aria</block>
  <block id="9fc322b3a5bb56d2d6ac18c15773d1c2" category="paragraph">Fare riferimento a.<block ref="c50bba54faf39c027cd571674d44a9c0" category="inline-link-rx"></block> Sezione all'interno del repository GitHub del NetApp Data Science Toolkit per informazioni dettagliate sull'utilizzo del toolkit con flusso d'aria.</block>
  <block id="64b0abe7a29610e134041ed793101fce" category="inline-link-macro">Segue: Esempio di operazioni Trident.</block>
  <block id="f6c488122d476f1d213cf78dc2ee84d2" category="paragraph"><block ref="f6c488122d476f1d213cf78dc2ee84d2" category="inline-link-macro-rx"></block></block>
  <block id="e7446d382d8184be0a342a2fc45d4394" category="doc">WP-7328: Ai di NetApp Conversational con NVIDIA Jarvis</block>
  <block id="5dabc617366db74ce2a9fa3915f6af5a" category="paragraph">Rick Huang, Sung-Han Lin, NetApp Davide Onofrio, NVIDIA</block>
  <block id="018aacc6ea95e20996bf57b319fd037a" category="paragraph">La famiglia di sistemi NVIDIA DGX è costituita dai primi sistemi al mondo basati su intelligenza artificiale integrata (ai) costruiti appositamente per l'ai aziendale. I sistemi storage NetApp AFF offrono performance estreme e funzionalità di gestione dei dati del cloud ibrido leader di settore. NetApp e NVIDIA hanno collaborato per creare l'architettura di riferimento ai di NetApp ONTAP, una soluzione chiavi in mano per i carichi di lavoro di ai e machine learning (ML) che offre performance, affidabilità e supporto di livello Enterprise.</block>
  <block id="1a76c739ce37834495a22c5db663d24b" category="paragraph">Questo white paper fornisce una guida direzionale ai clienti che sviluppano sistemi di ai conversazionali a supporto di diversi casi di utilizzo in diversi mercati verticali del settore. Include informazioni sull'implementazione del sistema utilizzando NVIDIA Jarvis. I test sono stati eseguiti utilizzando una stazione NVIDIA DGX e un sistema storage NetApp AFF A220.</block>
  <block id="f813bd56d696cb8de386a53a37eed6f6" category="list-text">Enterprise Architect che progettano soluzioni per lo sviluppo di modelli di ai e software per casi di utilizzo conversa dell'ai, come un assistente virtuale al dettaglio</block>
  <block id="0497dfe9ff978e87977c978d3443e206" category="list-text">Data scientist alla ricerca di modi efficienti per raggiungere gli obiettivi di sviluppo della modellazione linguistica</block>
  <block id="e84c345e30f668aa19a041e2e12bc9fe" category="list-text">Data engineer incaricati di gestire ed elaborare dati di testo come domande dei clienti e trascrizioni di dialoghi</block>
  <block id="00101e6b2bf526b1ee79d39389f461fa" category="list-text">Dirigenti e responsabili delle decisioni IT e business leader interessati a trasformare l'esperienza di intelligenza artificiale conversazionale e a ottenere il più rapido time-to-market dalle iniziative di intelligenza artificiale</block>
  <block id="7a83f363d45e73d7915a600e1bbc92ba" category="inline-link-macro">Pagina successiva: Panoramica della soluzione</block>
  <block id="88851610d9d91a7b78ab814276bebba7" category="paragraph"><block ref="88851610d9d91a7b78ab814276bebba7" category="inline-link-macro-rx"></block></block>
  <block id="9d2ca817bb7dd69d6f7dc09932a53524" category="summary">Le soluzioni di intelligenza artificiale di NetApp sono un insieme di soluzioni strategiche e tecniche che dimostrano le funzionalità dello storage NetApp nello spazio ai/ML.</block>
  <block id="b54a1e289898cf21f63715dfe64025b7" category="doc">Soluzioni di intelligenza artificiale NetApp</block>
  <block id="74c071ff3c1d6d6fc39b72d617aefdf8" category="doc">Dettagli sulla distribuzione e sulla convalida della soluzione</block>
  <block id="b122830b8b8edd9e76690ea23b0c4cbd" category="paragraph">Le sezioni seguenti illustrano i dettagli dell'implementazione e della convalida della soluzione.</block>
  <block id="ebe48d794d8ada5d4e067cd5993bdd3e" category="inline-link-macro">Avanti: Implementazione di ONTAP ai</block>
  <block id="3b103491115e62f2388d69086a2eff9d" category="paragraph"><block ref="3b103491115e62f2388d69086a2eff9d" category="inline-link-macro-rx"></block></block>
  <block id="c4e7b8572218b2c9421122c7ab76be25" category="paragraph">NetApp e cnvrg.io hanno collaborato per offrire ai clienti una soluzione completa per la gestione dei dati per lo sviluppo di software ML e DL. ONTAP ai offre calcolo e storage dalle performance elevate per qualsiasi scala operativa, mentre il software cnvrg.io ottimizza i flussi di lavoro di data science e migliora l'utilizzo delle risorse.</block>
  <block id="c6a4d485e7c4cefa4c121ce6c59b28dc" category="inline-link-macro">Avanti: Ringraziamenti</block>
  <block id="0c8a89e4d7937b03d3adc0f1d6530b08" category="paragraph"><block ref="0c8a89e4d7937b03d3adc0f1d6530b08" category="inline-link-macro-rx"></block></block>
  <block id="5328ed3b5c6e4726166e04c16c2e5581" category="summary">Questa sezione descrive il caricamento dei Click Logs di Criteo giorno 15 in Pandas e la formazione di un modello di foresta casuale scikit-learn. In questo esempio, è stato eseguito il caricamento di DataFrame con Dask cuDF e il training di un modello di foresta casuale in Dask cuML.</block>
  <block id="a0432b74d7d4d2ad68e93e947654c865" category="doc">Caricare il giorno 15 in Dask e formare un modello di foresta casuale di Dask cuML</block>
  <block id="7c784438423fe1bee9ab4f91a8fd7559" category="inline-link-macro">Previous: Load Criteo fare clic su Logs giorno 15 in Pandas e formare un modello di foresta casuale scikit-learn.</block>
  <block id="5d5b75a952d74a7d4520c521956b9d7e" category="paragraph"><block ref="5d5b75a952d74a7d4520c521956b9d7e" category="inline-link-macro-rx"></block></block>
  <block id="78dc33cd9d496e2466a0c1e2ba09ab3f" category="inline-link-macro">"Confronto tra i tempi di formazione".</block>
  <block id="4a2764258721dd882c9ec28454963797" category="paragraph">In modo simile alla sezione precedente, caricare Criteo Click Logs Day 15 in Pandas e formare un modello di foresta casuale scikit-learn. In questo esempio, è stato eseguito il caricamento di DataFrame con Dask cuDF e il training di un modello di foresta casuale in Dask cuML. Nella sezione abbiamo confrontato le differenze di tempo e di scala per la formazione <block ref="8d6c01ed5b9db5301efeb6183c858b76" category="inline-link-macro-rx"></block></block>
  <block id="356d8553da3749641cb731d318c85b0c" category="section-title">criteo_dask_RF.ipynb</block>
  <block id="2f4f1a139be92d2b17647025ff8630ab" category="paragraph">Questo notebook importa<block ref="2ea9510c37f7f89e4941ff75f62f21cb" prefix=" " category="inline-code"></block>,<block ref="7bdff0c624ecc34cd492f58859b5a599" prefix=" " category="inline-code"></block>e il necessario<block ref="b2015e522a418c3350d3af1da8790aeb" prefix=" " category="inline-code"></block> librerie, come mostrato nell'esempio seguente:</block>
  <block id="7b871613dade772ae668d694698383bf" category="paragraph">Avviare Dask Client().</block>
  <block id="3e9277d3d0f0519292426b933e52f232" category="paragraph">Se il cluster è configurato correttamente, è possibile visualizzare lo stato dei nodi di lavoro.</block>
  <block id="d6b257c355ced1525e4967c96b62b83e" category="paragraph">Nel nostro cluster AKS viene visualizzato il seguente stato:</block>
  <block id="d94a77691c281e8bf418635fea6ca580" category="paragraph"><block ref="d94a77691c281e8bf418635fea6ca580" category="inline-image-macro-rx" type="image"></block></block>
  <block id="073b2194006d8da73b5f74f3d7224d76" category="paragraph">Si noti che Dask utilizza il paradigma di esecuzione pigro: Invece di eseguire il codice di elaborazione istantaneamente, Dask crea invece un DAG (Directed Acyclic Graph) di esecuzione. IL DAG contiene una serie di attività e le relative interazioni che ciascun lavoratore deve eseguire. Questo layout significa che i task non vengono eseguiti finché l'utente non dice a Task di eseguirli in un modo o nell'altro. Con Dask hai tre opzioni principali:</block>
  <block id="a40049c3d7270ce955d2023f8e2015dc" category="list-text">*Call compute() su un DataFrame.* questa chiamata elabora tutte le partizioni e restituisce i risultati allo scheduler per l'aggregazione finale e la conversione in cuDF DataFrame. Questa opzione deve essere utilizzata con parsimonia e solo in caso di risultati fortemente ridotti, a meno che il nodo dello scheduler non esaurisca la memoria.</block>
  <block id="30e170dbe1dd223491e1a822605da52d" category="list-text">*Call Persistent() su un DataFrame.* questa chiamata esegue il grafico, ma, invece di restituire i risultati al nodo scheduler, li mantiene in memoria nel cluster in modo che l'utente possa riutilizzare questi risultati intermedi lungo la pipeline senza dover eseguire nuovamente la stessa elaborazione.</block>
  <block id="ca013764f3f6faeab137d2d529dba598" category="list-text">*Call head() su un DataFrame.* proprio come con cuDF, questa chiamata restituisce 10 record al nodo Scheduler. Questa opzione consente di verificare rapidamente se il DataFrame contiene il formato di output desiderato o se i record stessi hanno senso, a seconda dell'elaborazione e del calcolo.</block>
  <block id="7ac60f98a199ceae63010c7802a9aefa" category="paragraph">Pertanto, a meno che l'utente non chiami una di queste azioni, i lavoratori sono inattivi in attesa che lo scheduler avvii l'elaborazione. Questo paradigma di esecuzione pigro è comune nei moderni framework di calcolo distribuiti e paralleli come Apache Spark.</block>
  <block id="d887d6a29f39f14cec0f83c5b02c42f8" category="paragraph">Il paragrafo seguente forma un modello di foresta casuale utilizzando Dask cuML per il calcolo distribuito con accelerazione GPU e calcola la precisione di previsione del modello.</block>
  <block id="de76ff3258bd3001f89804efae30da38" category="inline-link-macro">Pagina successiva: Monitorate il task dask utilizzando la dashboard nativa di Task Streams.</block>
  <block id="5db30f2a693de098d03dec622875beec" category="paragraph"><block ref="5db30f2a693de098d03dec622875beec" category="inline-link-macro-rx"></block></block>
  <block id="1a7fa7cc4c79d5163f691ff60e6fc34d" category="doc">Run:ai Dashboard e viste</block>
  <block id="5051a9eb1fad38f876a260ba0a4850af" category="inline-link"><block ref="5051a9eb1fad38f876a260ba0a4850af" category="inline-link-rx"></block></block>
  <block id="3473dab452c5446b1a01a923e9879461" category="paragraph">Dopo aver installato Run:ai sul cluster Kubernetes e aver configurato correttamente i container, vengono visualizzate le seguenti dashboard e viste<block ref="2af90fde6f4d8ae5947b005d1208e742" category="inline-link-rx"></block> nel browser, come mostrato nella figura seguente.</block>
  <block id="f977554b7762214959db36c20484c697" category="paragraph"><block ref="f977554b7762214959db36c20484c697" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8dfd99441ce89d4be896e4fc9757f7d2" category="paragraph">Nel cluster sono presenti 16 GPU totali fornite da due nodi DGX-1. È possibile visualizzare il numero di nodi, il totale delle GPU disponibili, le GPU allocate assegnate con i carichi di lavoro, il numero totale di processi in esecuzione, i processi in sospeso e le GPU allocate inattive. Sul lato destro, il diagramma a barre mostra le GPU per progetto, che riepiloga il modo in cui i diversi team utilizzano la risorsa del cluster. Al centro è riportato l'elenco dei job attualmente in esecuzione con i relativi dettagli, inclusi nome del job, progetto, utente, tipo di job, Il nodo su cui ciascun processo è in esecuzione, il numero di GPU allocate per tale processo, il tempo di esecuzione corrente del processo, l'avanzamento del processo in percentuale e l'utilizzo della GPU per tale processo. Si noti che il cluster è sottoutilizzato (utilizzo della GPU al 23%) perché ci sono solo tre job in esecuzione inviati da un singolo team <block ref="9320270de4ff6824ae7a21f729fb7d44" prefix="(" category="inline-code"></block>).</block>
  <block id="67545e2efac33412706ff883eff2e1c4" category="paragraph">Nella sezione seguente, mostreremo come creare più team nella scheda progetti e allocare GPU per ciascun team per massimizzare l'utilizzo del cluster e gestire le risorse quando sono presenti molti utenti per cluster. Gli scenari di test imitano gli ambienti aziendali in cui le risorse di memoria e GPU sono condivise tra carichi di lavoro di training, deduzione e interattivi.</block>
  <block id="73eea118e4762640a7f60136f3e5c1a0" category="inline-link-macro">Avanti: Creazione di progetti per i team Data Science e allocazione delle GPU</block>
  <block id="7c2c470385b4f61a9e9b5b0881d2f061" category="paragraph"><block ref="7c2c470385b4f61a9e9b5b0881d2f061" category="inline-link-macro-rx"></block></block>
  <block id="c95fe91ba2d256285401bdabdd666ca7" category="doc">NVA-1151-DEPLOY: NetApp ONTAP ai con sistemi NVIDIA DGX A100</block>
  <block id="981ed5a5ebc4fbc2a64f69a42d9ef36c" category="paragraph">David Arnette, NetApp</block>
  <block id="290beddb4a567cd98ba4f9116eee11b4" category="paragraph">NVA-1151-DEPLOY include istruzioni per l'implementazione del sistema storage per un'architettura verificata NetApp (NVA) per i carichi di lavoro di apprendimento automatico (ML) e intelligenza artificiale (ai) utilizzando i sistemi storage NetApp AFF A800, i sistemi NVIDIA DGX A100 e gli switch di rete NVIDIA Mellanox. Include inoltre istruzioni per l'esecuzione dei test di benchmark di convalida al termine dell'implementazione.</block>
  <block id="3f8a5951b902f50dcbc39690406ade15" category="paragraph"><block ref="3f8a5951b902f50dcbc39690406ade15" category="inline-link-macro-rx"></block></block>
  <block id="7d5fc90090e6ef28f1b090f458e3bb91" category="paragraph"><block ref="7d5fc90090e6ef28f1b090f458e3bb91" category="inline-link-macro-rx"></block></block>
  <block id="248f830b158797f9c038ea35ea266b89" category="cell">Agosto 2021</block>
  <block id="d8299632c247aca8f771d7368ee36f9d" category="summary">NVIDIA ai Enterprise con NetApp e VMware - architettura</block>
  <block id="9ca68ac69c80fa519c5ead343d865ce4" category="inline-link-macro">Precedente: Panoramica sulla tecnologia.</block>
  <block id="ab7d7704700b22bf8dd4ce26b09e2562" category="paragraph"><block ref="ab7d7704700b22bf8dd4ce26b09e2562" category="inline-link-macro-rx"></block></block>
  <block id="37810ec69b6e321b4b377d835e7d84ac" category="paragraph">Questa soluzione si basa su un'architettura collaudata e familiare con sistemi certificati NetApp, VMware e NVIDIA. Per ulteriori informazioni, consultare la tabella seguente.</block>
  <block id="95a502ec0ddaf3352c2540e3e9f65a1b" category="cell">Software ai e Data Analytics</block>
  <block id="61da586210da33a8abab150a7d7d0972" category="inline-link-macro">NVIDIA ai Enterprise per VMware</block>
  <block id="7865e440c1b499e7942ca9b659d737d6" category="cell"><block ref="7865e440c1b499e7942ca9b659d737d6" category="inline-link-macro-rx"></block></block>
  <block id="102995a1cdd2c719d7d0aa4d888fa019" category="cell">Piattaforma di virtualizzazione</block>
  <block id="4ce5f3794d6e351daaaaa4f211e419ee" category="cell"><block ref="4ce5f3794d6e351daaaaa4f211e419ee" category="inline-link-macro-rx"></block></block>
  <block id="8cf5fbd26a1d5d924600d38015860908" category="cell">Piattaforma di calcolo</block>
  <block id="aee87e9fe5cc4cf9193cd27c74a0a6e7" category="inline-link-macro">Sistemi certificati NVIDIA</block>
  <block id="b3cdb2e0e953c1639ad63fe06b8c7a37" category="cell"><block ref="b3cdb2e0e953c1639ad63fe06b8c7a37" category="inline-link-macro-rx"></block></block>
  <block id="ddca712fc3b0dad3d85e423eb97d58ea" category="cell">Piattaforma per la gestione dei dati</block>
  <block id="1c317db419d669c4b6473c6d462e881e" category="cell"><block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="121c96ce43abda774fe95c1ccde1603e" category="paragraph"><block ref="121c96ce43abda774fe95c1ccde1603e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23a5db9f9241f7132df83ceacee13eb5" category="inline-link-macro">Avanti: Configurazione iniziale.</block>
  <block id="65ee66895a5d90d6bde80ce787a7e3b7" category="paragraph"><block ref="65ee66895a5d90d6bde80ce787a7e3b7" category="inline-link-macro-rx"></block></block>
  <block id="1e48409a293254dced52407be3dbb722" category="doc">Crea un assistente virtuale utilizzando Jarvis, Cloud Sync e NEMO</block>
  <block id="68dc442228015e015ca6272edb5994e4" category="inline-link-macro">Avanti: Costruisci un assistente virtuale utilizzando Jarvis, Cloud Sync e NEMO Overview</block>
  <block id="f308b9afc8e29196ebb4fe535e29fc51" category="paragraph"><block ref="f308b9afc8e29196ebb4fe535e29fc51" category="inline-link-macro-rx"></block></block>
  <block id="686ebb62ce1be84dcfae0007fb84562d" category="summary">La configurazione utilizzata per la convalida può essere regolata per adattarsi ad altri casi di utilizzo.</block>
  <block id="bf46169695d75ff844d955af09f33e75" category="doc">Modifiche dell'architettura</block>
  <block id="747bf7dbe4329cb636a09e1a7e4b297b" category="inline-link-macro">Precedente: Procedura di test e risultati dettagliati.</block>
  <block id="61862ef71b0230e76d56381617d456b0" category="paragraph"><block ref="61862ef71b0230e76d56381617d456b0" category="inline-link-macro-rx"></block></block>
  <block id="1cf27bd587c6c632877c322cf42c0d97" category="paragraph">La configurazione utilizzata per questa convalida può essere regolata per adattarsi ad altri casi di utilizzo.</block>
  <block id="a752efb5fb2512dc99b2045f032779f7" category="section-title">Regolazioni della CPU</block>
  <block id="122acc941b98ef5a11208d23ed0a8090" category="paragraph">Per questa convalida abbiamo utilizzato un processore Platinum Skylake Intel Xeon 8360Y, come raccomandato da Lenovo. Ci aspettiamo che l'equivalente CPU Cascade Lake, un processore Gold Intel Xeon 6330, offra performance simili perché questo carico di lavoro non è legato alla CPU.</block>
  <block id="3cc37c167d58a1828b00c13cc6018ae8" category="section-title">Aumento della capacità dello storage</block>
  <block id="f40ff1aaa4f2e4ccd4189adfb3584e29" category="paragraph">In base alle tue esigenze di capacità di storage, puoi aumentare lo storage condiviso (volume NFS) on-demand, a patto di disporre di shelf di dischi e modelli di controller aggiuntivi. È possibile eseguire questa operazione dall'interfaccia CLI o dall'interfaccia Web di NetApp del controller di storage come utente amministratore.</block>
  <block id="326221403d8b3298094c46f2012726ea" category="paragraph"><block ref="326221403d8b3298094c46f2012726ea" category="inline-link-macro-rx"></block></block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">Sono stati eseguiti numerosi test per valutare le performance dell'architettura proposta. Esistono sei diversi carichi di lavoro (classificazione delle immagini, rilevamento degli oggetti [piccoli], rilevamento degli oggetti [grandi], imaging medico, comunicazione vocale, E Natural Language Processing [NLP]), che è possibile eseguire in tre diversi scenari: Offline, single stream e multistream.</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">Risultati del test</block>
  <block id="3ee9fa6b3e5baa3db7a7d6587d8d590b" category="paragraph"><block ref="3ee9fa6b3e5baa3db7a7d6587d8d590b" category="inline-link-macro-rx"></block></block>
  <block id="507b481f4f0fb36b82f97222c73fb91d" category="section-title">Risultati del test per AFF</block>
  <block id="817fbb6103e6cb6855c19a5c1b25f817" category="paragraph">Sono stati eseguiti numerosi test per valutare le performance dell'architettura proposta. Esistono sei diversi carichi di lavoro (classificazione delle immagini, rilevamento degli oggetti [piccoli], rilevamento degli oggetti [grandi], imaging medico, comunicazione vocale, E Natural Language Processing [NLP]), che è possibile eseguire in tre diversi scenari: Offline, single stream e multistream.</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">L'ultimo scenario viene implementato solo per la classificazione delle immagini e il rilevamento degli oggetti.</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">Ciò offre 15 possibili carichi di lavoro, tutti testati in tre diverse configurazioni:</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">Server singolo/storage locale</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">Storage di rete/server singolo</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">Storage di rete/multi-server</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">I risultati sono descritti nelle sezioni seguenti.</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">Inferenza ai nello scenario offline per AFF</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">In questo scenario, tutti i dati erano disponibili per il server e il tempo impiegato per elaborare tutti i campioni è stato misurato. I risultati dei test riportano le larghezze di banda in campioni al secondo. Quando sono stati utilizzati più server di calcolo, si riporta la larghezza di banda totale sommata su tutti i server. I risultati per tutti e tre i casi di utilizzo sono mostrati nella figura seguente. Per il caso di due server, segnaliamo la larghezza di banda combinata di entrambi i server.</block>
  <block id="d39bc80b598327ae50c15f64c44bb6ea" category="paragraph"><block ref="d39bc80b598327ae50c15f64c44bb6ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">I risultati mostrano che lo storage di rete non influisce negativamente sulle performance: La modifica è minima e per alcune attività non viene rilevata alcuna. Quando si aggiunge il secondo server, la larghezza di banda totale raddoppia esattamente o, nel peggiore dei casi, la modifica è inferiore all'1%.</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">Inferenza ai in uno scenario a flusso singolo per AFF</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">Questo benchmark misura la latenza. Per il caso di più server di calcolo, segnaliamo la latenza media. I risultati per la suite di attività sono riportati nella figura seguente. Per il caso di due server, segnaliamo la latenza media di entrambi i server.</block>
  <block id="01f3906715186988e276bc34ebc661c0" category="paragraph"><block ref="01f3906715186988e276bc34ebc661c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">I risultati, ancora una volta, mostrano che lo storage di rete è sufficiente per gestire le attività. La differenza tra storage locale e di rete nel caso di un server è minima o nulla. Allo stesso modo, quando due server utilizzano lo stesso storage, la latenza su entrambi i server rimane la stessa o cambia di molto.</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">Inferenza ai nello scenario multistream per AFF</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">In questo caso, il risultato è il numero di flussi che il sistema è in grado di gestire, soddisfacendo al tempo stesso il limite di QoS. Pertanto, il risultato è sempre un numero intero. Per più di un server, viene riportato il numero totale di flussi sommati su tutti i server. Non tutti i carichi di lavoro supportano questo scenario, ma abbiamo eseguito quelli che lo fanno. I risultati dei nostri test sono riassunti nella figura seguente. Per il caso di due server, segnaliamo il numero combinato di flussi da entrambi i server.</block>
  <block id="758b60f43cbc650fded1dcf9be428fa5" category="paragraph"><block ref="758b60f43cbc650fded1dcf9be428fa5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">I risultati mostrano le performance perfette dell'installazione: Lo storage locale e di rete offrono gli stessi risultati e l'aggiunta del secondo server raddoppia il numero di flussi gestibili dall'installazione proposta.</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">Risultati del test per EF</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">Sono stati eseguiti numerosi test per valutare le performance dell'architettura proposta. Esistono sei diversi carichi di lavoro (classificazione delle immagini, rilevamento degli oggetti [piccoli], rilevamento degli oggetti [grandi], imaging medico, comunicazione vocale, E Natural Language Processing [NLP]), eseguiti in due scenari diversi: Offline e single stream. I risultati sono descritti nelle sezioni seguenti.</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">Inferenza ai nello scenario offline per EF</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">In questo scenario, tutti i dati erano disponibili per il server e il tempo impiegato per elaborare tutti i campioni è stato misurato. I risultati dei test riportano le larghezze di banda in campioni al secondo. Per le esecuzioni a nodo singolo, segnaliamo la media di entrambi i server, mentre per due esecuzioni a server segnaliamo la larghezza di banda totale sommata su tutti i server. I risultati dei casi di utilizzo sono mostrati nella figura seguente.</block>
  <block id="8e793f971410e2b57df427d1305ee0a2" category="paragraph"><block ref="8e793f971410e2b57df427d1305ee0a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">Inferenza ai in uno scenario a flusso singolo per EF</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">Questo benchmark misura la latenza. In tutti i casi, segnaliamo la latenza media su tutti i server coinvolti nelle esecuzioni. Vengono forniti i risultati per la suite di attività.</block>
  <block id="5656e3a262dfb3d6e1cba96551717de0" category="paragraph"><block ref="5656e3a262dfb3d6e1cba96551717de0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">I risultati mostrano ancora una volta che lo storage di rete è sufficiente per gestire le attività. La differenza tra lo storage locale e di rete nel caso di un server è minima o nulla. Allo stesso modo, quando due server utilizzano lo stesso storage, la latenza su entrambi i server rimane la stessa o cambia di molto.</block>
  <block id="516a608926718d1a912cf9404f1a63ac" category="inline-link-macro">Avanti: Opzioni di dimensionamento dell'architettura.</block>
  <block id="9cedf0fb8faddf365d88f523ae482015" category="paragraph"><block ref="9cedf0fb8faddf365d88f523ae482015" category="inline-link-macro-rx"></block></block>
  <block id="e1490a61359279998443f8eab1c0483e" category="summary">Questa pagina riassume i vantaggi di Azure NetApp Files in termini di formazione distribuita o su larga scala.</block>
  <block id="b0de8e85db65da6381bb71646929daa6" category="doc">Riepilogo del caso d'uso con la previsione del tasso di click-through</block>
  <block id="d7550d336c660c27c3f1aa9ffdbc1e08" category="inline-link-macro">Precedente: Requisiti relativi alle risorse cloud.</block>
  <block id="6a4fb77bb2a725598588e7db128b749b" category="paragraph"><block ref="6a4fb77bb2a725598588e7db128b749b" category="inline-link-macro-rx"></block></block>
  <block id="3f504d5ee520c44b83e5875afd3f2831" category="inline-link">Fare clic su Log di terabyte</block>
  <block id="ce2803fd5e9b90b62d0792d13e715d11" category="inline-link">Criteo ai Lab</block>
  <block id="b622f3d3bde9c5202a2be0c23982e0b2" category="paragraph">Questo caso d'utilizzo si basa sui dati pubblicamente disponibili<block ref="f00b4c49198828625540594bcd2c0e57" category="inline-link-rx"></block> dataset da<block ref="3ba217c046bd683ab55f300076736b4a" category="inline-link-rx"></block>. Con i recenti progressi nelle piattaforme E nelle applicazioni ML, è ora molto importante concentrarsi sull'apprendimento su larga scala. Il tasso di click-through (CTR) è definito come il numero medio di click-through per cento impressioni di annunci online (espresso in percentuale). È ampiamente adottato come parametro chiave in diversi mercati verticali e casi di utilizzo del settore, tra cui digital marketing, retail, e-commerce e service provider. Di seguito sono riportati alcuni esempi di utilizzo di CTR come metrica importante per il potenziale traffico dei clienti:</block>
  <block id="d86cf69a8b82547a94ca3f6a307cf9a6" category="inline-link">Google Analytics</block>
  <block id="fe123d76ac9bec74ba2056b6a34fbf5d" category="inline-link">Classifica ad</block>
  <block id="747d705222dc64c89cfadd75a9792b30" category="list-text">*Digital marketing:* in<block ref="6c9e2e85af2f8f35c64de5000ebda91e" category="inline-link-rx"></block>, CTR può essere usato per misurare come bene un advertiser o mercantile parole chiavi, annunci, ed elenchi liberi stanno eseguendo. Un CTR elevato è una buona indicazione che gli utenti trovano i tuoi annunci e gli elenchi utili e pertinenti. Il CTR contribuisce anche al CTR previsto dalla parola chiave, che è un componente di<block ref="428c3403a03510f9dc338448b285e764" category="inline-link-rx"></block>.</block>
  <block id="8a2e97f5a0cefdd4b76863bdd3773fb2" category="list-text">*E-commerce:* oltre a sfruttare<block ref="8785133d6074d4ab5f5345c36bc35a21" category="inline-link-rx"></block>, ci sono almeno alcune statistiche dei visitatori in un backend di e-commerce. Anche se queste statistiche potrebbero non sembrare utili a prima vista, in genere sono facili da leggere e potrebbero essere più accurate di altre informazioni. I set di dati di prima parte composti da tali statistiche sono proprietari e sono quindi i più rilevanti per i venditori, gli acquirenti e le piattaforme di e-commerce. Questi set di dati possono essere utilizzati per impostare benchmark, confrontando i risultati con l'anno scorso e ieri, creando una serie temporale per ulteriori analisi.</block>
  <block id="5737cd832bf93fd33459cf0a04787441" category="list-text">*Retail:* i retailer Brick-and-mortar possono correlare il numero di visitatori e il numero di clienti al CTR. Il numero di clienti può essere visto dalla loro storia del punto vendita. Il CTR proveniente dai siti web dei rivenditori o dal traffico pubblicitario potrebbe comportare le vendite di cui sopra. I programmi fedeltà sono un altro caso d'utilizzo, perché i clienti reindirizzati dagli annunci online o da altri siti Web potrebbero unirsi per guadagnare premi. I retailer possono acquisire i clienti attraverso programmi fedeltà e registrare i comportamenti dalle cronologie di vendita per creare un sistema di raccomandazione che non solo preveda i comportamenti di acquisto dei consumatori in diverse categorie, ma anche personalizza i coupon e riduce il tasso di abbandono.</block>
  <block id="32c14bcab423a033bf540425e236d3e6" category="list-text">*Fornitori di servizi:* le aziende di telecomunicazioni e i provider di servizi Internet dispongono di numerosi dati telemetrici di prima parte per utenti che utilizzano in maniera approfondita ai, ML e analytics. Ad esempio, una telecomunicazione può sfruttare ogni giorno i log di cronologia dei domini di primo livello per la navigazione sul Web dei propri abbonati mobili per mettere a punto i modelli esistenti e produrre una segmentazione aggiornata del pubblico, prevedere il comportamento dei clienti e collaborare con gli inserzionisti per inserire annunci in tempo reale per una migliore esperienza online. In questo workflow di marketing basato sui dati, il CTR è una metrica importante per riflettere le conversioni.</block>
  <block id="78ae79f63f58a3ac75e77e3a075fd19e" category="inline-link">Registri Click di Criteo terabyte</block>
  <block id="deb698cbe7918324e2e1564708266732" category="paragraph">Nel contesto del digital marketing,<block ref="cc065865c19a3af4babfdf02c1c6b55d" category="inline-link-rx"></block> Sono ora il set di dati di riferimento per la valutazione della scalabilità delle piattaforme E degli algoritmi ML. Prevedendo il tasso di click-through, un inserzionista può selezionare i visitatori che hanno più probabilità di rispondere agli annunci, analizzare la cronologia di navigazione e mostrare gli annunci più rilevanti in base agli interessi dell'utente.</block>
  <block id="5f326be91a09bc93ca87444e834df2a6" category="paragraph">La soluzione fornita in questo report tecnico evidenzia i seguenti vantaggi:</block>
  <block id="67ccf3c7c1e67c90000dfee83bab38ec" category="list-text">I vantaggi di Azure NetApp Files nella formazione distribuita o su larga scala</block>
  <block id="e15bc9f9b7a013d672cb689660ab9f9f" category="list-text">RAPIDA elaborazione dei dati abilitata per CUDA (cuDF, cuPy e così via) e algoritmi ML (cuML)</block>
  <block id="e150c8d445e71cda899957943e39b75f" category="list-text">Il framework di calcolo parallelo di Dask per la formazione distribuita</block>
  <block id="ec61531814ab09c5338813eecc764692" category="paragraph">Un workflow end-to-end basato su RAPIDS ai e Azure NetApp Files dimostra il drastico miglioramento dei tempi di training dei modelli di foresta casuali di due ordini di grandezza. Questo miglioramento è significativo rispetto all'approccio Pandas convenzionale quando si tratta di log click reali con 45 GB di dati tabulari strutturati (in media) ogni giorno. Ciò equivale a un DataFrame contenente circa venti miliardi di righe. Illustreremo la configurazione dell'ambiente cluster, l'installazione del framework e della libreria, il caricamento e l'elaborazione dei dati, la formazione convenzionale e distribuita, la visualizzazione e il monitoraggio e il confronto dei risultati critici di runtime end-to-end in questo report tecnico.</block>
  <block id="3876b7e4b6a608a0b9001ae2e65c91b1" category="inline-link-macro">Quindi installare e configurare il cluster aks.</block>
  <block id="2f0a1a89887d5c4f057724084bfdb718" category="paragraph"><block ref="2f0a1a89887d5c4f057724084bfdb718" category="inline-link-macro-rx"></block></block>
  <block id="5648f06cc2dff861e557e088190ccbe2" category="paragraph">In questa sezione e nelle sezioni <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>, e. <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>, Abbiamo ideato scenari di test avanzati per dimostrare le funzionalità di orchestrazione Run:ai per la gestione di workload complessi, la pianificazione preventiva automatica e il provisioning di GPU con overquota. Lo abbiamo fatto per ottenere un elevato utilizzo delle risorse del cluster e ottimizzare la produttività del team di data science di livello Enterprise in un ambiente ai ONTAP.</block>
  <block id="fed09193953a2a2d15bfba4063981f8c" category="paragraph">Per queste tre sezioni, impostare i seguenti progetti e quote:</block>
  <block id="d2d5c3e087f684e56b5b81d6212d7ccb" category="cell">Quota</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="207b738b6cd0e1cf6ac4a405dc72102f" category="paragraph">Inoltre, per queste tre sezioni vengono utilizzati i seguenti container:</block>
  <block id="cc6f12794ea24a191cb4f699f1b95036" category="list-text">Notebook Jupyter:<block ref="71f36d3504ef6b5a0ba9f34fe1143008" prefix=" " category="inline-code"></block></block>
  <block id="b8d0bb7e356bfdd7e018a7c62f9343fa" category="list-text">Run:Avvio rapido ai:<block ref="1f2da2a856d7277c86fd9f58e93ae507" prefix=" " category="inline-code"></block></block>
  <block id="c9582d103b2fe8050364d3e629c4e80e" category="paragraph">Per questo scenario di test sono stati stabiliti i seguenti obiettivi:</block>
  <block id="c2d51205301247cd0aa0eca284d3889b" category="list-text">Mostra la semplicità del provisioning delle risorse e il modo in cui le risorse vengono estratte dagli utenti</block>
  <block id="dfd4af458e74e30246827532e692dca7" category="list-text">Mostrare come gli utenti possono eseguire facilmente il provisioning di frazioni di GPU e numero intero di GPU</block>
  <block id="d7bf7c7f0d7884bd8fe07da4f6a8aba3" category="list-text">Mostra come il sistema elimina i colli di bottiglia di calcolo consentendo a team o utenti di superare la quota di risorse se nel cluster sono presenti GPU gratuite</block>
  <block id="f93609e9c7f7c826e6c83bb1f8416207" category="list-text">Mostra come vengono eliminati i colli di bottiglia della pipeline di dati utilizzando la soluzione NetApp durante l'esecuzione di processi a elaborazione intensiva, come il container NetApp</block>
  <block id="8ac218f5a62c8021756a192ac737a7f2" category="list-text">Mostrare come vengono eseguiti diversi tipi di container utilizzando il sistema</block>
  <block id="802125395813e0bec35472d0403ab94e" category="list-text">Notebook Jupyter</block>
  <block id="91c4a4ef606f959264719f8d084aab0e" category="list-text">Container Run:ai</block>
  <block id="23edbe937c996eb973ab4c69f9648893" category="list-text">Mostra un utilizzo elevato quando il cluster è pieno</block>
  <block id="37e875b843ef9539c02d09d3bbee6668" category="inline-link-macro">Dettagli sui test per la Sezione 4.8</block>
  <block id="815a27a2c38741e36d920cbea5587384" category="paragraph">Per informazioni dettagliate sulla sequenza di comandi effettiva eseguita durante il test, vedere <block ref="3a65193f11bb9f699d19b0e9a996cd93" category="inline-link-macro-rx"></block>.</block>
  <block id="9d020ce52f8e9ff0d2f2defe3942d660" category="paragraph">Una volta inviati tutti i 13 carichi di lavoro, è possibile visualizzare un elenco di nomi di container e GPU allocati, come mostrato nella figura seguente. Disponiamo di sette corsi di formazione e sei lavori interattivi, che simulano quattro team di data science, ciascuno con i propri modelli in esecuzione o in fase di sviluppo. Per i lavori interattivi, i singoli sviluppatori utilizzano Jupyter Notebooks per scrivere o eseguire il debug del codice. Pertanto, è adatto per eseguire il provisioning delle frazioni GPU senza utilizzare troppe risorse del cluster.</block>
  <block id="5deafc9e56279ca519f1e3c351856aa8" category="paragraph"><block ref="5deafc9e56279ca519f1e3c351856aa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dbaf41fcdcf0aa8cd93bfdf0e7f916f2" category="list-text">Il cluster deve essere pieno: Vengono utilizzate 16/16 GPU.</block>
  <block id="25421e793bda820f3023762c547a2495" category="list-text">Elevato utilizzo del cluster.</block>
  <block id="fdf3de6e0502b5404d2e0b379421f759" category="list-text">Più esperimenti rispetto alle GPU a causa dell'allocazione frazionale.</block>
  <block id="68cf93a70e0f0fe62bc0428ce8a8b348" category="list-text"><block ref="ae7ccf7b1a6a1a023f611a294572a900" prefix="" category="inline-code"></block> non utilizza tutta la quota; pertanto,<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> e.<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Possibilità di utilizzare GPU aggiuntive per i propri esperimenti, con conseguente riduzione dei tempi di innovazione.</block>
  <block id="9083e59932e59a6f85524ab956fcf772" category="inline-link-macro">Avanti: Equità nell'allocazione delle risorse di base</block>
  <block id="654c44d69d64b0a5a656dd7b1375ac03" category="paragraph"><block ref="654c44d69d64b0a5a656dd7b1375ac03" category="inline-link-macro-rx"></block></block>
  <block id="d3202b7eec66185e032fcad76b4c2aa3" category="paragraph"><block ref="d3202b7eec66185e032fcad76b4c2aa3" category="inline-link-macro-rx"></block></block>
  <block id="27a5a0a02525fbb66788e119b829fe28" category="list-text">Azure NetApp Files:</block>
  <block id="45bd81d391ee3bd9831a237bff32b2c1" category="list-text">Pagina dell'architettura delle soluzioni per Azure NetApp Files</block>
  <block id="57b815cb2da0c842a09d5ef586792c0a" category="inline-link"><block ref="57b815cb2da0c842a09d5ef586792c0a" category="inline-link-rx"></block></block>
  <block id="02508d077a7c6fbe1035568c37610d22" category="paragraph"><block ref="02508d077a7c6fbe1035568c37610d22" category="inline-link-rx"></block></block>
  <block id="f42fced7b7a9bfef49a209632add6f80" category="list-text">Storage persistente Trident per container:</block>
  <block id="158e66cfa121c58b072656402170ca60" category="list-text">Azure NetApp Files e Trident</block>
  <block id="d9fe72ef646d82c8372b45ff009726a2" category="inline-link"><block ref="d9fe72ef646d82c8372b45ff009726a2" category="inline-link-rx"></block></block>
  <block id="e3c781df174a80c19c70a938b96db93a" category="paragraph"><block ref="e3c781df174a80c19c70a938b96db93a" category="inline-link-rx"></block></block>
  <block id="145f2a04d99fdbd7a450ef83e82d471b" category="list-text">Dask e RAPIDE:</block>
  <block id="df5eb1591e808e358e02221e1e0111e6" category="list-text">Dek</block>
  <block id="7db6639777894f081a3d7c055b97900a" category="inline-link"><block ref="7db6639777894f081a3d7c055b97900a" category="inline-link-rx"></block></block>
  <block id="4846c68fb34aec3b1b7b7de96d27e71f" category="paragraph"><block ref="4846c68fb34aec3b1b7b7de96d27e71f" category="inline-link-rx"></block></block>
  <block id="41563f9620e92fbfd1e105e32ac297e4" category="list-text">Installare Dask</block>
  <block id="8659b02378fc9b47aac4428f69411abc" category="inline-link"><block ref="8659b02378fc9b47aac4428f69411abc" category="inline-link-rx"></block></block>
  <block id="972dffc891589785367dd3581a5abcef" category="paragraph"><block ref="972dffc891589785367dd3581a5abcef" category="inline-link-rx"></block></block>
  <block id="3ba7abeba4fd0f5d5ca9072155319afd" category="list-text">API di Dask</block>
  <block id="f7673aa4f6b36ba9952cef7c98115776" category="inline-link"><block ref="f7673aa4f6b36ba9952cef7c98115776" category="inline-link-rx"></block></block>
  <block id="d43a23bd530cae7ba37a2e0ed6513bad" category="paragraph"><block ref="d43a23bd530cae7ba37a2e0ed6513bad" category="inline-link-rx"></block></block>
  <block id="1bfabf7fb7bf05567331dfc3d20c4921" category="list-text">Apprendimento automatico di Dask</block>
  <block id="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link"><block ref="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link-rx"></block></block>
  <block id="d05f63d77306100c615132f350f3fafe" category="paragraph"><block ref="d05f63d77306100c615132f350f3fafe" category="inline-link-rx"></block></block>
  <block id="90223e93e145939c9954970520e1767a" category="list-text">DAK Distributed Diagnostics</block>
  <block id="e7252fe9d67234e05be7dc251c48cf74" category="inline-link"><block ref="e7252fe9d67234e05be7dc251c48cf74" category="inline-link-rx"></block></block>
  <block id="925c8b588cf5ae5fc486494a21fba8ac" category="paragraph"><block ref="925c8b588cf5ae5fc486494a21fba8ac" category="inline-link-rx"></block></block>
  <block id="1b2766572fa1896116e3c218eb697113" category="list-text">TensorFlow: Un framework di apprendimento automatico open-source per tutti</block>
  <block id="d97adf46c9b097cad5eff54e3b65a21f" category="paragraph"><block ref="d97adf46c9b097cad5eff54e3b65a21f" category="inline-link-rx"></block></block>
  <block id="528d52adf23d34a248f0b9bf684c1832" category="paragraph"><block ref="528d52adf23d34a248f0b9bf684c1832" category="inline-link-rx"></block></block>
  <block id="5f751f93279ebf35ea83b9aa80ef02df" category="paragraph"><block ref="5f751f93279ebf35ea83b9aa80ef02df" category="inline-link-macro-rx"></block></block>
  <block id="3ad0505876550699ce505845f96683a7" category="doc">USA NetApp Cloud Sync per archiviare la cronologia delle conversazioni</block>
  <block id="5b7a8a379330d9d43907b47a6d7ee306" category="inline-link-macro">Espandi i modelli di intento utilizzando NEMO Training</block>
  <block id="a7e4c14a726c28e6cb4b935701ac2899" category="paragraph">Scaricando la cronologia delle conversazioni in un file CSV una volta al giorno, possiamo sfruttare Cloud Sync per scaricare i file di log nello storage locale. La figura seguente mostra l'architettura di implementare Jarvis on-premise e in cloud pubblici, utilizzando Cloud Sync per inviare la cronologia delle conversazioni per il training NEMO. I dettagli del training NEMO sono disponibili nella sezione <block ref="14a0a4dd1a1c18cba42b2036fe4dfc33" category="inline-link-macro-rx"></block>.</block>
  <block id="e60c4461b2b4dcf3aa8535e3aab780b3" category="paragraph"><block ref="e60c4461b2b4dcf3aa8535e3aab780b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00717575e300ae9f18fa0a24d97bcca5" category="inline-link-macro">Avanti: Espandi i modelli di intento utilizzando il training NEMO</block>
  <block id="7ee8a10f8da0d566f0c5cccb9528b186" category="paragraph"><block ref="7ee8a10f8da0d566f0c5cccb9528b186" category="inline-link-macro-rx"></block></block>
  <block id="b8b025dc1895637326d2420e912751e0" category="summary">Prima di utilizzare Trident per eseguire il provisioning dinamico delle risorse di storage all'interno del cluster Kubernetes, è necessario creare uno o più backend Trident. Gli esempi riportati in questa pagina rappresentano diversi tipi di backend che è possibile creare se si sta implementando la soluzione per il piano di controllo ai di NetApp su un pod ai di ONTAP.</block>
  <block id="c0fe00dd01499e23426b850b65782c77" category="paragraph">Prima di utilizzare Trident per eseguire il provisioning dinamico delle risorse di storage all'interno del cluster Kubernetes, è necessario creare uno o più backend Trident. Gli esempi che seguono rappresentano diversi tipi di backend che è possibile creare se si sta implementando la soluzione per il piano di controllo ai di NetApp su un pod ai di ONTAP. Per ulteriori informazioni sui backend, consultare<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="1e698f68960fb964df99e73068c9377c" category="list-text">NetApp consiglia di creare un backend Trident abilitato per FlexGroup per ogni LIF di dati (interfaccia di rete logica che fornisce l'accesso ai dati) che si desidera utilizzare sul sistema NetApp AFF. In questo modo, potrai bilanciare i montaggi di volume tra le LIF</block>
  <block id="327a3876126e4773cfcc5e30649c9483" category="paragraph">I comandi di esempio che seguono mostrano la creazione di due backend Trident abilitati per FlexGroup per due diverse LIF di dati associate alla stessa SVM (Storage Virtual Machine) di ONTAP. Questi backend utilizzano<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> driver di storage. ONTAP supporta due tipi principali di volumi di dati: FlexVol e FlexGroup. I volumi FlexVol sono limitati dalle dimensioni (al momento della scrittura, le dimensioni massime dipendono dalla distribuzione specifica). I volumi FlexGroup, invece, possono scalare linearmente fino a 20 PB e 400 miliardi di file, fornendo un singolo namespace che semplifica notevolmente la gestione dei dati. Pertanto, i volumi FlexGroup sono ottimali per i carichi di lavoro ai e ML che si basano su grandi quantità di dati.</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">Se si lavora con una piccola quantità di dati e si desidera utilizzare volumi FlexVol invece di volumi FlexGroup, è possibile creare backend Trident che utilizzano<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> driver di storage invece di<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> driver di storage.</block>
  <block id="d04adbc45ec06c05c1826745b8f4ddf2" category="list-text">NetApp consiglia inoltre di creare uno o più backend Trident abilitati per FlexVol. Se si utilizzano volumi FlexGroup per lo storage dei dataset di training, è possibile utilizzare volumi FlexVol per memorizzare risultati, output, informazioni di debug e così via. Se si desidera utilizzare i volumi FlexVol, è necessario creare uno o più backend Trident abilitati per FlexVol. I comandi di esempio che seguono mostrano la creazione di un singolo backend Trident abilitato a FlexVol che utilizza una singola LIF di dati.</block>
  <block id="f8bc0cf277b3c4424978d08f10f9df70" category="inline-link-macro">Pagina successiva: Esempi di storaglasses Kubernetes per implementazioni ai ONTAP.</block>
  <block id="a58ef634a291d01e3abec43e5619294a" category="paragraph"><block ref="a58ef634a291d01e3abec43e5619294a" category="inline-link-macro-rx"></block></block>
  <block id="0a37acabf89826767b5a5fcb8dacffa3" category="summary">Questa pagina descrive le attività da completare per implementare Kubeflow nel cluster Kubernetes.</block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="doc">Implementazione di Kubeflow</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">In questa sezione vengono descritte le attività da completare per implementare Kubeflow nel cluster Kubernetes.</block>
  <block id="f48269a81318d4bd2dd9e57a8239fe56" category="list-text">Hai già un cluster Kubernetes funzionante e stai eseguendo una versione di Kubernetes supportata da Kubeflow. Per un elenco delle versioni supportate, vedere<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>.</block>
  <block id="3429b7e0331de8d2f8d377b034ca6855" category="inline-link-macro">Implementazione e configurazione di Trident</block>
  <block id="9fc644d78f21555decceeddf5b691fa4" category="list-text">NetApp Trident è già stato installato e configurato nel cluster Kubernetes, come descritto in <block ref="ec7700e2b8d95edf2f2700b590eab273" category="inline-link-macro-rx"></block>.</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="section-title">Impostare la classe di storage Kubernetes predefinita</block>
  <block id="e1be30d98edccc10974d5d339832197c" category="paragraph">Prima di implementare Kubeflow, è necessario specificare un StorageClass predefinito all'interno del cluster Kubernetes. Il processo di implementazione di Kubeflow tenta di eseguire il provisioning di nuovi volumi persistenti utilizzando la classe di storage predefinita. Se non viene indicato StorageClass come StorageClass predefinito, l'implementazione non riesce. Per designare una StorageClass predefinita all'interno del cluster, eseguire la seguente attività dall'host di distribuzione jump. Se è già stata designata una StorageClass predefinita all'interno del cluster, è possibile saltare questo passaggio.</block>
  <block id="e3e4fbe325df2b20670ca04ad0c2a517" category="list-text">Designare uno dei StorageClasses esistenti come StorageClass predefinito. I comandi di esempio che seguono mostrano la designazione di StorageClass denominata<block ref="b3e01914c123afcd317121eb293386c4" prefix=" " category="inline-code"></block> Come StorageClass di default.</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">Il<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Il tipo di backend Trident ha una dimensione minima del PVC che è abbastanza grande. Per impostazione predefinita, Kubeflow tenta di eseguire il provisioning di PVC di dimensioni limitate a poche GB. Pertanto, non è necessario designare un StorageClass che utilizzi<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Tipo di backend come StorageClass predefinito ai fini dell'implementazione di Kubeflow.</block>
  <block id="f12aad36b1ab9194dd8bc67542366bff" category="section-title">Utilizza NVIDIA DeepOps per implementare Kubeflow</block>
  <block id="3e1922d78dd7bdb1e8d7e7bd8f5aa92c" category="paragraph">NetApp consiglia di utilizzare il tool di implementazione Kubeflow fornito da NVIDIA DeepOps. Per implementare Kubeflow nel cluster Kubernetes utilizzando lo strumento di implementazione DeepOps, eseguire le seguenti operazioni dall'host di distribuzione jump.</block>
  <block id="3ede8bc1f55c95b9a16b2429e0b9bbcc" category="admonition">In alternativa, è possibile implementare Kubeflow manualmente seguendo la<block ref="c75d7e23bc80ca81cea11fe427173cb3" category="inline-link-rx"></block> Nella documentazione ufficiale del Kubeflow</block>
  <block id="a73d6d865f72179145299c720c53d39c" category="inline-link">Istruzioni per l'implementazione di Kubeflow</block>
  <block id="04e3c704baa1b4c23cd48a18c10fcf39" category="list-text">Implementare Kubeflow nel cluster seguendo la<block ref="5e7f04c1dfa70dd058d2720be031c44b" category="inline-link-rx"></block> Sul sito NVIDIA DeepOps GitHub.</block>
  <block id="2efdbab31c5d41a149e5092f4b8d7e48" category="list-text">Annotare l'URL del dashboard Kubeflow prodotto dal tool di implementazione DeepOps Kubeflow.</block>
  <block id="b714a06d49f16f8b7f988d95734d177f" category="list-text">Verificare che tutti i pod implementati nello spazio dei nomi Kubeflow mostrino un<block ref="5f241c8c8f985b3c51e05d39cf030f4c" prefix=" " category="inline-code"></block> di<block ref="5bda814c4aedb126839228f1a3d92f09" prefix=" " category="inline-code"></block> e verificare che nessun componente implementato all'interno dello spazio dei nomi sia in stato di errore. L'avvio di tutti i pod potrebbe richiedere alcuni minuti.</block>
  <block id="d6049afd6b1943d1e98ca6347dd907c5" category="list-text">Nel browser Web, accedere alla dashboard centrale di Kubeflow accedendo all'URL annotato al punto 2.</block>
  <block id="64f559cf2e77f73aca6bd3dc9649f62c" category="paragraph">Il nome utente predefinito è<block ref="e0fb0c8707d7da1341e171401e7c9e14" prefix=" " category="inline-code"></block>e la password predefinita è<block ref="ed2b1f468c5f915f3f1cf75d7068baae" prefix=" " category="inline-code"></block>. Per creare altri utenti, seguire le istruzioni in<block ref="f529217f090b2c9cc3764f14abdec5f7" category="inline-link-rx"></block>.</block>
  <block id="2d84920115f9dc91fe2d35c4dc07eaf0" category="paragraph"><block ref="2d84920115f9dc91fe2d35c4dc07eaf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="defd49beb1345ee37b446e866e8b3420" category="inline-link-macro">Segue: Operazioni e attività Kubeflow di esempio.</block>
  <block id="2ecf31480279823ef2aed30a0fc061f2" category="paragraph"><block ref="2ecf31480279823ef2aed30a0fc061f2" category="inline-link-macro-rx"></block></block>
  <block id="9708ffc88c964c7e13b023f7eba9396b" category="doc">NVA-1153-DEPLOY: NetApp ONTAP ai con sistemi NVIDIA DGX A100 e switch Ethernet Mellanox Spectrum</block>
  <block id="5f4c1dd940d24299c2c5a80211b1e330" category="paragraph">NVA-1153-DEPLOY include istruzioni di implementazione del sistema storage per un'architettura verificata NetApp per i carichi di lavoro di apprendimento automatico (ML) e intelligenza artificiale (ai) che utilizzano i sistemi storage NetApp AFF A800, i sistemi NVIDIA DGX A100 e gli switch Ethernet NVIDIA Mellanox Spectrum SN3700V da 200 GB. Include inoltre istruzioni per l'esecuzione dei test di benchmark di convalida al termine dell'implementazione.</block>
  <block id="50f2d8c31ffcba4aeffd6f55fd0f8bd2" category="paragraph"><block ref="50f2d8c31ffcba4aeffd6f55fd0f8bd2" category="inline-link-macro-rx"></block></block>
  <block id="d052a88935efadcc9eebf94684d52e19" category="doc">Elevato utilizzo del cluster</block>
  <block id="8d46742dbd21a217f738a9ca6a31f634" category="paragraph">In questa sezione, emuliamo uno scenario realistico in cui quattro team di data science inviano ciascuno i propri carichi di lavoro per dimostrare la soluzione di orchestrazione Run:ai che raggiunge un elevato utilizzo del cluster mantenendo al contempo la prioritizzazione e il bilanciamento delle risorse GPU. Iniziamo utilizzando il benchmark ResNet-50 descritto nella sezione <block ref="5872a8c23866a6bf186843724ee58ad7" category="inline-link-macro-rx"></block>:</block>
  <block id="14f48338822299bdf82bb4528d3c9e07" category="paragraph">Abbiamo eseguito lo stesso benchmark ResNet-50 di in<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block>. Abbiamo utilizzato la bandiera<block ref="f4fdcbb99cb8e39e4706115c80cb3968" prefix=" " category="inline-code"></block> per i container che non risiedono nel repository del dock pubblico. Abbiamo montato le directory<block ref="39de0dbcfb68c8735bd088c62fa061a4" prefix=" " category="inline-code"></block> e.<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block> Sul nodo host DGX-1 a.<block ref="39de0dbcfb68c8735bd088c62fa061a4" prefix=" " category="inline-code"></block> e.<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block> al container, rispettivamente. Il set di dati è disponibile presso NetApp AFFA800 con<block ref="a64503025c7495ecf42633d117f8b536" prefix=" " category="inline-code"></block> argomento che punta alla directory. Entrambi<block ref="96dbae4bbcb6841c17bc66f858d93982" prefix=" " category="inline-code"></block> e.<block ref="a78db0f035a543e24e7b038d359b5e74" prefix=" " category="inline-code"></block> Significa che allociamo una GPU per questo lavoro. Il primo è un argomento per<block ref="6e38f16215ae91c11fc5c54b74c66d54" prefix=" " category="inline-code"></block> script, mentre quest'ultimo è un flag per<block ref="7897d57a96444dff260ef2bf8a0589b1" prefix=" " category="inline-code"></block> comando.</block>
  <block id="bccb844975c2eec86eb25c0d8e2a989b" category="paragraph">La figura seguente mostra una dashboard panoramica del sistema con il 97% di utilizzo della GPU e tutte le sedici GPU disponibili allocate. È possibile visualizzare facilmente il numero di GPU allocate per ciascun team nel grafico a barre GPU/progetto. Il riquadro dei job in esecuzione mostra i nomi dei job in esecuzione, il progetto, l'utente, il tipo, il nodo, GPU consumate, tempo di esecuzione, avanzamento e dettagli di utilizzo. Un elenco dei workload in coda con il relativo tempo di attesa viene visualizzato in lavori in sospeso. Infine, la casella Nodes offre i numeri GPU e l'utilizzo per i singoli nodi DGX-1 nel cluster.</block>
  <block id="1acc627e7c9d8002628b2e12c91ac683" category="paragraph"><block ref="1acc627e7c9d8002628b2e12c91ac683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5d3b5670d9303fddfb021e681546c0" category="inline-link-macro">Successivo: Allocazione frazionale della GPU per carichi di lavoro meno impegnativi o interattivi</block>
  <block id="3d9997e0f8b3b6a279c8779455e7c760" category="paragraph"><block ref="3d9997e0f8b3b6a279c8779455e7c760" category="inline-link-macro-rx"></block></block>
  <block id="b831e128b8fd177e9c80396ed741b7c1" category="doc">Requisiti hardware e software</block>
  <block id="afee48a46dd68b9618cec81a8ee5ba86" category="paragraph">In questa sezione vengono illustrati i requisiti tecnologici per la soluzione ai di ONTAP.</block>
  <block id="e96b7604f8b75ae786c6c0e1016e46fd" category="inline-link">Sito web ONTAP ai</block>
  <block id="929f5f13d86d1be55b96dba26e773c6f" category="paragraph">Sebbene i requisiti hardware dipendano da carichi di lavoro specifici dei clienti, ONTAP ai può essere implementato su qualsiasi scala per data engineering, formazione sui modelli e deduzione di produzione da una singola GPU fino a configurazioni su scala rack per operazioni ML/DL su larga scala. Per ulteriori informazioni su ONTAP ai, vedere<block ref="7ec9b089c41da1b986bad97e1099df1c" category="inline-link-rx"></block>.</block>
  <block id="41e840b508d9e839f95d16dd582af8d6" category="paragraph">Questa soluzione è stata validata utilizzando un sistema DGX-1 per il calcolo, un sistema storage NetApp AFF A800 e Cisco Nexus 3232C per la connettività di rete. Il sistema AFF A800 utilizzato per questa convalida può supportare fino a 10 sistemi DGX-1 per la maggior parte dei carichi di lavoro ML/DL. La figura seguente mostra la topologia ONTAP ai utilizzata per il training sui modelli in questa convalida.</block>
  <block id="bc2eb92d1e1797a759b677c38f619a8f" category="paragraph"><block ref="bc2eb92d1e1797a759b677c38f619a8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d98e5c43e7b3be89fe8a9076f89f1e99" category="paragraph">Per estendere questa soluzione a un cloud pubblico, Cloud Volumes ONTAP può essere implementato insieme alle risorse di calcolo della GPU del cloud e integrato in un data fabric del cloud ibrido che consente ai clienti di utilizzare le risorse appropriate per un determinato carico di lavoro.</block>
  <block id="4dc70b997a39a64b2def3ef74a96fdb4" category="paragraph">La seguente tabella mostra le versioni software specifiche utilizzate per la convalida della soluzione.</block>
  <block id="d173e10eb6a0fc7969fe540c987e0c7d" category="cell">18.04.4 LTS</block>
  <block id="9b4bffa460105781f82b1d463bde8200" category="cell">4.4.0</block>
  <block id="3c1d47ba5c1ada327abd4532ff9f4437" category="cell">20.02.1</block>
  <block id="0083e57a258edd18b949d3afbf6cfc2a" category="cell">1.15</block>
  <block id="152090ff5e9a05ea7e1cf0c248449638" category="cell">Timone</block>
  <block id="232de5556d4148d75b55012e1230616c" category="cell">3.1.0</block>
  <block id="e5e8ab661917b89b4161959c7dc28442" category="cell">cnvrg.io</block>
  <block id="272f0a04b740763e0a29316bc4af89a4" category="cell">3.0.0</block>
  <block id="d8a31094f88724af6834c47a6697dc56" category="cell">9.6P4</block>
  <block id="9909115a4f9fe32731077286c367501c" category="paragraph">Per la convalida di questa soluzione, Kubernetes è stato implementato come cluster a nodo singolo nel sistema DGX-1. Per le implementazioni su larga scala, è necessario implementare nodi master Kubernetes indipendenti per fornire un'elevata disponibilità dei servizi di gestione e riservare preziose risorse DGX per i carichi di lavoro ML e DL.</block>
  <block id="1c428dd76324aae91879799ae73fbc37" category="inline-link-macro">Pagina successiva: Dettagli sulla distribuzione e sulla convalida della soluzione</block>
  <block id="5e5761a91dc25c881f4ca86678634b1b" category="paragraph"><block ref="5e5761a91dc25c881f4ca86678634b1b" category="inline-link-macro-rx"></block></block>
  <block id="2fb227f90ebf269423fe0cf1a15b8111" category="doc">Definisci richiesta di rimborso per volumi persistenti</block>
  <block id="8f5da11015f2baf835f0e8b421c1cfe9" category="list-text">Salvare il seguente YAML in un file per creare un PVC di tipo Basic.</block>
  <block id="04c58cdb1d0c073dd558caf87f2b8ed1" category="list-text">Applicare il file YAML al cluster Iguazio Kubernetes.</block>
  <block id="f685fdfcc5aedb3ccc237a4020b69cd8" category="section-title">Collega il volume NetApp al notebook Jupyter</block>
  <block id="dc4b8e255a77b2c73f89b702dbb7acc5" category="inline-link">Iguazio Panoramica dei servizi e degli strumenti applicativi</block>
  <block id="11eb1e24a14c1d15ee5e287b4338b764" category="paragraph">Iguazio offre diversi servizi gestiti per fornire ai data scientist uno stack end-to-end completo per lo sviluppo e l'implementazione di applicazioni ai/ML. Per ulteriori informazioni su questi componenti, consultare la sezione<block ref="2cf4dcc22fda31f66959754df93d6196" category="inline-link-rx"></block>.</block>
  <block id="3591be3d07a4f8a37d218b9e92bea432" category="paragraph">Uno dei servizi gestiti è Jupyter notebook. Ogni sviluppatore ottiene la propria implementazione di un container di notebook con le risorse necessarie per lo sviluppo. Per consentire loro l'accesso al NetApp Cloud Volume, è possibile assegnare il volume al relativo container e allocazione delle risorse, utente in esecuzione e impostazioni delle variabili di ambiente per le richieste di rimborso dei volumi persistenti sono presentate nella seguente immagine.</block>
  <block id="e0d870d503aeb797f7626b14c9acb4ae" category="paragraph">Per una configurazione on-premise, fare riferimento a.<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> Nella configurazione di Trident per abilitare le funzionalità di gestione dei dati di NetApp ONTAP, come l'acquisizione di copie Snapshot dei dati o del modello per il controllo delle versioni. Aggiungere la seguente riga nel file di configurazione back-end di Trident per rendere visibili le directory Snapshot:</block>
  <block id="12ce9751e0e6d2a7d593d46e19211984" category="inline-link">Comando Trident</block>
  <block id="71f8fa2d01d0c5a2d9af72f90f65e379" category="paragraph">È necessario creare un file di configurazione back-end Trident in formato JSON, quindi eseguire quanto segue<block ref="1dce3ee9e9ff2b59caf27104be259d37" category="inline-link-rx"></block> come riferimento:</block>
  <block id="2842c07cfacaf614e63dc1f2afef93b2" category="paragraph"><block ref="2842c07cfacaf614e63dc1f2afef93b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d47cd04a0ddb5c3e6a2d9b9bc5c6a120" category="inline-link-macro">Avanti: Implementazione dell'applicazione</block>
  <block id="fafac2eb9a7c4fcf46778865a22a00d2" category="paragraph"><block ref="fafac2eb9a7c4fcf46778865a22a00d2" category="inline-link-macro-rx"></block></block>
  <block id="0de039e647bc53dcce6e7bceb8605cbf" category="paragraph">Aziende e organizzazioni di tutte le dimensioni e in tutti i settori stanno passando all'intelligenza artificiale (ai), all'apprendimento automatico (ML) e al deep learning (DL) per risolvere problemi reali, offrire prodotti e servizi innovativi e ottenere un vantaggio in un mercato sempre più competitivo. Man mano che le organizzazioni aumentano l'utilizzo di ai, ML e DL, devono affrontare molte sfide, tra cui la scalabilità dei workload e la disponibilità dei dati. Queste sfide possono essere affrontate utilizzando la soluzione NetApp ai Control Plane.</block>
  <block id="cae02473f4798da0fdd40f4f598b1d96" category="paragraph">Questa soluzione consente di clonare rapidamente uno spazio dei nomi dei dati. Inoltre, consente di definire e implementare flussi di lavoro di training ai, ML e DL che incorporano la creazione quasi istantanea di dati e linee di base dei modelli per la tracciabilità e il controllo delle versioni. Con questa soluzione, è possibile tracciare ogni singolo modello di training fino ai set di dati esatti con cui il modello è stato addestrato e/o validato. Infine, questa soluzione consente di eseguire rapidamente il provisioning degli spazi di lavoro dei notebook Jupyter con accesso a set di dati di grandi dimensioni.</block>
  <block id="696dba9a093d4ac7b67234745dd57835" category="paragraph">Poiché questa soluzione è rivolta a data scientist e data engineer, è necessaria una competenza minima di NetApp o NetApp ONTAP. Con questa soluzione, le funzioni di gestione dei dati possono essere eseguite utilizzando interfacce e strumenti semplici e familiari. Inoltre, questa soluzione utilizza componenti completamente open-source e liberi. Pertanto, se disponete già di storage NetApp nel vostro ambiente, potete implementare questa soluzione oggi stesso. Se si desidera provare questa soluzione ma non si dispone già di storage NetApp, visitare il sito<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>E potrai essere operativo con una soluzione di storage NetApp basata sul cloud in pochissimo tempo.</block>
  <block id="bf6adc497a862180909278cf6ed029f1" category="doc">TR-4859: Implementazione della scalabilità dello spettro IBM con lo storage NetApp e-Series - Installazione e convalida</block>
  <block id="7d8a7f37eb34080960253271b824ab2f" category="paragraph">Chris Seirer, NetApp</block>
  <block id="fdb4fdcbeafc3d334651614437516062" category="paragraph">TR-4859 descrive il processo di implementazione di una soluzione di file system completamente parallela basata sullo stack software Spectrum Scale di IBM. TR-4859 è progettato per fornire dettagli su come installare Spectrum Scale, convalidare l'infrastruttura e gestire la configurazione.</block>
  <block id="6a51aeb3b4e11ee4436f8ad323e23c5a" category="paragraph"><block ref="6a51aeb3b4e11ee4436f8ad323e23c5a" category="inline-link-macro-rx"></block></block>
  <block id="4c2db3e48f4f33a355c8e493453b53c2" category="inline-link-macro">Avanti: Requisiti software</block>
  <block id="54870296c311c566be3a76b4a4df8e8c" category="paragraph"><block ref="43a6574de87222e6a8a22c8138fc4c45" category="inline-link-macro-rx"></block>.</block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">Panoramica della soluzione</block>
  <block id="fbe29309a183681bc26203d4c65853a2" category="paragraph">In questa sezione viene descritta una pipeline convenzionale per la scienza dei dati e i relativi inconvenienti. Presenta inoltre l'architettura della soluzione di caching dei set di dati proposta.</block>
  <block id="1f14aecc1193f646e0005e27fbc6e63d" category="section-title">Pipeline e svantaggi convenzionali di Data Science</block>
  <block id="17fb7d0ba5495199d3e18fe23dff7b59" category="paragraph">Una sequenza tipica di sviluppo e implementazione del modello ML prevede passaggi iterativi che includono:</block>
  <block id="63e1ded7e3ae73253b5c287bc9bdef02" category="list-text">Acquisizione dei dati</block>
  <block id="52e028dc7ac82e9d4b7b1ae588fecc9a" category="list-text">Pre-elaborazione dei dati (creazione di più versioni dei set di dati)</block>
  <block id="33cd0fcdd9ee7e650043133b12516155" category="list-text">Esecuzione di esperimenti multipli che coinvolgono l'ottimizzazione degli hyperparameter, modelli diversi e così via</block>
  <block id="b85c416c94e0c5314a1e6fcc21d4139e" category="list-text">Monitoringcnvrg.io ha sviluppato una piattaforma completa per automatizzare tutte le attività, dalla ricerca all'implementazione. Un piccolo esempio di schermate della dashboard relative alla pipeline è illustrato nella figura seguente.</block>
  <block id="5a5ade85e7f7478bcba59e8c3891c914" category="paragraph"><block ref="5a5ade85e7f7478bcba59e8c3891c914" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26d6a4638ffd0b7779f1353f5fe54f0d" category="paragraph">È molto comune avere più set di dati in gioco da repository pubblici e dati privati. Inoltre, è probabile che ogni set di dati disponga di più versioni risultanti dalla pulizia dei set di dati o dall'ingegneria delle funzionalità. Una dashboard che fornisce un hub di set di dati e una versione hub è necessaria per garantire che i tool di collaborazione e coerenza siano disponibili per il team, come illustrato nella figura seguente.</block>
  <block id="e884d73b6a4214bea010ec3bbfdad8b6" category="paragraph"><block ref="e884d73b6a4214bea010ec3bbfdad8b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93661dde7027bf31b3d007740a3d4648" category="paragraph">La fase successiva della pipeline è la formazione, che richiede più istanze parallele di modelli di training, ciascuna associata a un dataset e a una determinata istanza di calcolo. L'associazione di un dataset a un certo esperimento con una determinata istanza di calcolo è una sfida perché è possibile che alcuni esperimenti vengano eseguiti da istanze GPU da Amazon Web Services (AWS), mentre altri esperimenti vengono eseguiti da istanze DGX-1 o DGX-2 on-premise. Altri esperimenti potrebbero essere eseguiti nei server CPU in GCP, mentre la posizione del set di dati non si trova in prossimità delle risorse di calcolo che eseguono il training. Una vicinanza ragionevole avrebbe una connettività completa a 10 GbE o più a bassa latenza dallo storage del dataset all'istanza di calcolo.</block>
  <block id="ba4f5ee1b0d01d3416723cfc3ec296ec" category="paragraph">È pratica comune per i data scientist scaricare il set di dati nell'istanza di calcolo che esegue il training ed esegue l'esperimento. Tuttavia, questo approccio può comportare diversi problemi:</block>
  <block id="90b6a1c5b483f6c6b399bc17c5e1af9a" category="list-text">Quando il data scientist scarica il dataset in un'istanza di calcolo, non vi sono garanzie che lo storage di calcolo integrato sia dalle performance elevate (un esempio di sistema dalle performance elevate sarebbe la soluzione NVMe ONTAP AFF A800).</block>
  <block id="5713a88504bb65e3808faac627a6a0fc" category="list-text">Quando il set di dati scaricato risiede in un nodo di calcolo, lo storage può diventare un collo di bottiglia quando i modelli distribuiti vengono eseguiti su più nodi (a differenza dello storage distribuito dalle performance elevate di NetApp ONTAP).</block>
  <block id="299b9ae5439d32ed932f51f3b3aa92d6" category="list-text">La successiva iterazione dell'esperimento di training potrebbe essere eseguita in un'istanza di calcolo diversa a causa di conflitti di coda o priorità, creando nuovamente una distanza di rete significativa dal dataset alla posizione di calcolo.</block>
  <block id="30e37003024e85518a26760a7ab58f4e" category="list-text">Gli altri membri del team che eseguono esperimenti di training sullo stesso cluster di calcolo non possono condividere questo set di dati; ciascuno esegue il (costoso) download del set di dati da una posizione arbitraria.</block>
  <block id="9e5d53150336efb0446a063309805f01" category="list-text">Se sono necessari altri set di dati o versioni dello stesso set di dati per i successivi lavori di formazione, i data scientist devono eseguire nuovamente il (costoso) download del set di dati nell'istanza di calcolo che esegue training.NetApp e cnvrg.io hanno creato una nuova soluzione di caching del set di dati che elimina questi ostacoli. La soluzione crea un'esecuzione accelerata della pipeline ML memorizzando nella cache i set di dati hot sul sistema storage ad alte performance ONTAP. Con ONTAP NFS, i set di dati vengono memorizzati nella cache una sola volta (e una sola volta) in un data fabric basato su NetApp (ad esempio AFF A800), che viene posizionato insieme al calcolo. Poiché lo storage NetApp ONTAP NFS ad alta velocità può servire più nodi di calcolo ML, le performance dei modelli di training sono ottimizzate, offrendo risparmi sui costi, produttività ed efficienza operativa all'organizzazione.</block>
  <block id="9f6302143996033ebb94d536b860acc3" category="section-title">Architettura della soluzione</block>
  <block id="a63af1f206939a3c956a2e8b6ab53103" category="paragraph">Questa soluzione di NetApp e cnvrg.io fornisce il caching dei set di dati, come mostrato nella figura seguente. Il caching dei set di dati consente agli scienziati dei dati di scegliere una versione di set di dati o set di dati desiderata e di spostarla nella cache NFS di ONTAP, che si trova in prossimità del cluster di calcolo ML. Il data scientist può ora eseguire più esperimenti senza incorrere in ritardi o download. Inoltre, tutti i tecnici che collaborano possono utilizzare lo stesso set di dati con il cluster di calcolo collegato (con la libertà di scegliere qualsiasi nodo) senza ulteriori download dal data Lake. Ai data scientist viene offerta una dashboard che tiene traccia e monitora tutti i set di dati e le versioni e fornisce una vista dei set di dati memorizzati nella cache.</block>
  <block id="612eaee91b23ecc385c1b402d44c081f" category="paragraph">La piattaforma cnvrg.io rileva automaticamente i set di dati vecchi che non sono stati utilizzati per un certo periodo di tempo e li eludono dalla cache, mantenendo spazio libero nella cache NFS per i set di dati più utilizzati. È importante notare che il caching dei set di dati con ONTAP funziona nel cloud e on-premise, fornendo così la massima flessibilità.</block>
  <block id="0cb5e14601fcf39745352a9556939aa3" category="paragraph"><block ref="0cb5e14601fcf39745352a9556939aa3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="810aceabf729ffa8c2dfd61a3aaeafaa" category="inline-link-macro">Avanti: Concetti e componenti</block>
  <block id="0a01ff9defa9120e928e7e306e3e3234" category="paragraph"><block ref="0a01ff9defa9120e928e7e306e3e3234" category="inline-link-macro-rx"></block></block>
  <block id="b8b9eab8c1ed7b79387652490f5724ec" category="doc">Installare Trident</block>
  <block id="4b022a47bb6a38cb1b05a5cbec618ccd" category="inline-link-macro">Precedente: Peer AKS VNET e Azure NetApp Files VNET.</block>
  <block id="fec5fee1adce318e5e2f9ce6a66ccc02" category="paragraph"><block ref="fec5fee1adce318e5e2f9ce6a66ccc02" category="inline-link-macro-rx"></block></block>
  <block id="999aa3cd55c654beafcfa7653b65d339" category="paragraph">Per installare Trident utilizzando Helm, attenersi alla seguente procedura:</block>
  <block id="36cd38f49b9afa08222c0dc9ebfe35eb" category="inline-link">origine</block>
  <block id="9c5f8711af47a869d4ef82db9e55eda5" category="list-text">Installare Helm (per istruzioni sull'installazione, visitare il<block ref="adf15389dc6d5fe4bd9024075437080f" category="inline-link-rx"></block>).</block>
  <block id="f7c078ec85c617d77dfa95c309e4df1b" category="list-text">Scaricare ed estrarre il programma di installazione di Trident 20.01.1.</block>
  <block id="7ee913d1a8b01e1a461f9eb99b0bba74" category="list-text">Modificare la directory in<block ref="c84ef67352bb6783ff2881f9f2821c2a" prefix=" " category="inline-code"></block>.</block>
  <block id="5729bb69ffc852a2e2757d743b7cb833" category="list-text">Copia<block ref="c67fd1b99934afa248dfeb285a9a4191" prefix=" " category="inline-code"></block> a una directory del sistema<block ref="b6aef5812b57b2270b8146870910b1d3" prefix=" " category="inline-code"></block>.</block>
  <block id="d7fc4d1537e4623fdcebe9b8ba333cbb" category="list-text">Installare Trident sul cluster Kubernetes (K8s) con Helm (<block ref="cbc920955683fc4acb62f9ea7099333f" category="inline-link-rx"></block>):</block>
  <block id="f515d7de4d597c284ba8042f699a0eab" category="list-text">Modificare la directory in<block ref="e7d07ed8aa8dd8cafce4a527a523d6c5" prefix=" " category="inline-code"></block> directory.</block>
  <block id="27b4c36cae8d1c4fd515d289942c87cc" category="list-text">Installare Trident.</block>
  <block id="6ee4094e2c3617e3e298ec79f9dc2898" category="list-text">Controllare lo stato dei pod Trident.</block>
  <block id="30f93734da9765d3bc7d49ca89932736" category="paragraph">Se tutti i pod sono in funzione, Trident viene installato ed è possibile procedere.</block>
  <block id="cde865911fa15995bc83db30d852300b" category="list-text">Impostare il backend Azure NetApp Files e la classe storage per AKS.</block>
  <block id="476fdb61358f28988640245a33bd9199" category="list-text">Creare un principio di servizio Azure.</block>
  <block id="5cdfb88cd634d9d0eb47237e3251d4bd" category="paragraph">Il service principal è il modo in cui Trident comunica con Azure per gestire le risorse Azure NetApp Files.</block>
  <block id="7c794fc1e683a6843753158bb92cab75" category="paragraph">L'output dovrebbe essere simile al seguente esempio:</block>
  <block id="253a9ccb0f0696ed79c174b388867829" category="list-text">Creare un file json backend Trident, nome di esempio<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block>.</block>
  <block id="c17b83e07524acc467ac01e42fa0ebdb" category="list-text">Utilizzando l'editor di testo preferito, completare i seguenti campi all'interno di<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block> file:</block>
  <block id="1197f8dc56b70115d87008dd2ecd3fca" category="list-text">Sostituire i seguenti campi:</block>
  <block id="b0b2134849d44712e969d6872e7245e5" category="list-text"><block ref="8c443e170595ba0feac007ffb92cb49a" prefix="" category="inline-code"></block>. Il tuo ID di abbonamento Azure.</block>
  <block id="7b42dbe86adeab0d66f36221b33bb0f4" category="list-text"><block ref="bc54592d6183695b841c6d1880ec0bf8" prefix="" category="inline-code"></block>. Il tuo ID tenant Azure dall'output di<block ref="2cb022e0b25eceddfcd6a7ad728f7217" prefix=" " category="inline-code"></block> nella fase precedente.</block>
  <block id="5a8bb8e509b4a424a1df50ef0bb41d89" category="list-text"><block ref="93c5bebdea9c94a0740fe6fd9bb250f0" prefix="" category="inline-code"></block>. Il tuo appID dall'output di<block ref="2cb022e0b25eceddfcd6a7ad728f7217" prefix=" " category="inline-code"></block> nella fase precedente.</block>
  <block id="6334b606a5807346a083767eaab3934f" category="list-text"><block ref="2b53761249254ce6b502f521e5cc0683" prefix="" category="inline-code"></block>. La password dall'output di<block ref="2cb022e0b25eceddfcd6a7ad728f7217" prefix=" " category="inline-code"></block> nella fase precedente.</block>
  <block id="12104fe8975b3ce95324ec3cab160ffc" category="list-text">Chiedere a Trident di creare il backend Azure NetApp Files in<block ref="47cb44be55a0dffa15dfc900a4c687be" prefix=" " category="inline-code"></block> namespace con<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block> come file di configurazione:</block>
  <block id="d6d34c355bcd6b2efe2795a2aeedd247" category="paragraph"><block ref="d6d34c355bcd6b2efe2795a2aeedd247" category="inline-image-macro-rx" type="image"></block></block>
  <block id="004530c3d3b3f442f56243625372db1d" category="list-text">Creare una classe di storage. Kubernetes consente agli utenti di eseguire il provisioning dei volumi utilizzando PVC che specificano una classe di storage in base al nome. Chiedere a K8s di creare una classe di storage<block ref="9df91c80149f52e48e8f845cbad1b55c" prefix=" " category="inline-code"></block> Che fa riferimento al backend Trident creato nel passaggio precedente.</block>
  <block id="e777b114d6f12bc1190a60eaf8498e37" category="list-text">Creare un YAML <block ref="330e60441e96769dd29fd0a282d4f84a" prefix="(" category="inline-code"></block>) per la copia e la classe di storage.</block>
  <block id="01d45e8c6af153b1a477537e02466b5c" category="list-text">Verificare che la classe di storage sia stata creata.</block>
  <block id="445895be8456b7de5e864fc09994551a" category="paragraph"><block ref="445895be8456b7de5e864fc09994551a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d3fec4cfe088bc80c2c2930f051b60b" category="inline-link-macro">Avanti: Configurare Dask con L'implementazione DI RAPIDS su AKS utilizzando Helm.</block>
  <block id="f2d1f2f412dd744c26a147e39bfa708f" category="paragraph"><block ref="f2d1f2f412dd744c26a147e39bfa708f" category="inline-link-macro-rx"></block></block>
  <block id="1f9a7430deed674d394796eaea14138f" category="paragraph">Questo report tecnico offre linee guida per i clienti con team di data science/engineering di piccole o grandi dimensioni per ottimizzare l'utilizzo di cluster e GPU Kubernetes utilizzando la CLI Run:ai e la dashboard di sistema su NetApp ONTAP ai. Include inoltre informazioni sull'installazione della piattaforma Run:ai, scenari di test e comandi dettagliati per i test case validati. La soluzione di orchestrazione Run:ai insieme al NetApp ai Control Plane offre un tempo più rapido per l'innovazione migliorando la produttività degli sviluppatori attraverso un utilizzo ottimale delle risorse.</block>
  <block id="892726726d592ee18c9ee8ad25a088ae" category="inline-link-macro">Segue: Riepilogo</block>
  <block id="e6c479abab08e982bd2f0efd6e3e405a" category="paragraph"><block ref="e6c479abab08e982bd2f0efd6e3e405a" category="inline-link-macro-rx"></block></block>
  <block id="48c4dc7fbfa1197490124f13eb565bd2" category="doc">Implementazione di ONTAP ai</block>
  <block id="70d5c23ad68d59b2546133efdd1c3267" category="inline-link">NVA-1121-DEPLOY: NetApp ONTAP ai, basato su NVIDIA</block>
  <block id="b393f072bc6b17085b75486a2abbcf97" category="paragraph">L'implementazione di ONTAP ai richiede l'installazione e la configurazione dell'hardware di rete, calcolo e storage. Le istruzioni specifiche per l'implementazione dell'infrastruttura ai di ONTAP esulano dall'ambito di questo documento. Per informazioni dettagliate sull'implementazione, vedere<block ref="8c03c9c25bc6aba17e86c510148a3423" category="inline-link-rx"></block>.</block>
  <block id="03e335ae74b1356b294af55e07eb6b70" category="paragraph">Per la convalida di questa soluzione, è stato creato un singolo volume e montato sul sistema DGX-1. Tale punto di montaggio è stato quindi montato sui container per rendere i dati accessibili per la formazione. Per implementazioni su larga scala, NetApp Trident automatizza la creazione e il montaggio dei volumi per eliminare i costi amministrativi e consentire la gestione delle risorse da parte dell'utente finale.</block>
  <block id="328d9c8854162b6d9dae70c57baa7505" category="inline-link-macro">Pagina successiva: Implementazione di Kubernetes</block>
  <block id="5102c02ef61bdeaa79904c17f58ca7e3" category="paragraph"><block ref="5102c02ef61bdeaa79904c17f58ca7e3" category="inline-link-macro-rx"></block></block>
  <block id="9e40fd8f5f0e113c758dfa63adc1221d" category="summary">Kubeflow è in grado di eseguire rapidamente il provisioning dei nuovi server Jupyter notebook per agire come aree di lavoro per scienziati dei dati. Per eseguire il provisioning di un nuovo server Jupyter notebook con Kubeflow, eseguire le attività elencate in questa pagina.</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">Provisioning di un'area di lavoro Jupyter notebook per l'utilizzo da parte di Data Scientist o Developer</block>
  <block id="52d84951381eb0ab7a285dd32b31702c" category="paragraph">Kubeflow è in grado di eseguire rapidamente il provisioning dei nuovi server Jupyter notebook per agire come aree di lavoro per scienziati dei dati. Per eseguire il provisioning di un nuovo server Jupyter notebook con Kubeflow, eseguire le seguenti operazioni. Per ulteriori informazioni sui notebook Jupyter all'interno del contesto Kubeflow, vedere<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block>.</block>
  <block id="5e82e4aa94a53b3b50acf347914be197" category="list-text">Dalla dashboard centrale di Kubeflow, fare clic su notebook Servers nel menu principale per accedere alla pagina di amministrazione del server Jupyter notebook.</block>
  <block id="358d18b5a42ec1d80b04e767298ea372" category="paragraph"><block ref="358d18b5a42ec1d80b04e767298ea372" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208feb7a4d57f0afc49e53fe1fe8b978" category="list-text">Fare clic su New Server (nuovo server) per eseguire il provisioning di un nuovo server Jupyter notebook.</block>
  <block id="3541a3b25823fa3b302c686b6fe2a212" category="paragraph"><block ref="3541a3b25823fa3b302c686b6fe2a212" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f95069a2e81949b101427e1fa4afddf" category="list-text">Assegnare un nome al nuovo server, scegliere l'immagine Docker su cui si desidera basare il server e specificare la quantità di CPU e RAM da riservare al server. Se il campo namespace è vuoto, utilizzare il menu Select namespace (Seleziona spazio dei nomi) nell'intestazione della pagina per scegliere uno spazio dei nomi. Il campo namespace viene quindi compilato automaticamente con lo spazio dei nomi scelto.</block>
  <block id="4fbbbc4aaa49d653f486738eed12357a" category="paragraph">Nell'esempio seguente, il<block ref="aec502449511a35e8b040af72693bf5c" prefix=" " category="inline-code"></block> viene scelto lo spazio dei nomi. Inoltre, vengono accettati i valori predefiniti per l'immagine Docker, la CPU e la RAM.</block>
  <block id="69bc8b3ae7667985c27ce3ef5de0e6ca" category="paragraph"><block ref="69bc8b3ae7667985c27ce3ef5de0e6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="095efbb867f01094d56c633d3337a412" category="list-text">Specificare i dettagli del volume dello spazio di lavoro. Se si sceglie di creare un nuovo volume, il provisioning di tale volume o PVC viene eseguito utilizzando la classe di storage predefinita. Perché un StorageClass che utilizza Trident è stato designato come StorageClass predefinito nella sezione <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>, Il volume o PVC viene fornito con Trident. Questo volume viene montato automaticamente come area di lavoro predefinita all'interno del container Jupyter notebook Server. Tutti i notebook creati dall'utente sul server che non vengono salvati in un volume di dati separato vengono salvati automaticamente in questo volume di spazio di lavoro. Pertanto, i notebook sono persistenti durante i riavvii.</block>
  <block id="c44927b0124469511a724e179c80bfb5" category="paragraph"><block ref="c44927b0124469511a724e179c80bfb5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="555e44b3745904843417371073338d08" category="list-text">Aggiungere volumi di dati. Nell'esempio seguente viene specificato un PVC esistente denominato 'pb-fg-all' e viene accettato il punto di montaggio predefinito.</block>
  <block id="0c73069b282d8e99ecbd8feb39164d40" category="paragraph"><block ref="0c73069b282d8e99ecbd8feb39164d40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b120f9006af3d27ef70eb256c99c6617" category="list-text">*Opzionale:* richiedere l'allocazione del numero desiderato di GPU al notebook server. Nell'esempio seguente, viene richiesta una GPU.</block>
  <block id="c969e6364e4561a959d1ce20f7187723" category="paragraph"><block ref="c969e6364e4561a959d1ce20f7187723" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8da2142543d647576288d71dddabb01" category="list-text">Fare clic su Launch (Avvia) per eseguire il provisioning del nuovo notebook server.</block>
  <block id="37a742c47c216725dd178d8c3c7a3f31" category="list-text">Attendere il provisioning completo del server notebook. Questa operazione può richiedere alcuni minuti se non si è mai eseguito il provisioning di un server utilizzando l'immagine Docker specificata, in quanto l'immagine deve essere scaricata. Una volta completato il provisioning del server, viene visualizzato un segno di spunta verde nella colonna Status (Stato) della pagina di amministrazione del server Jupyter notebook.</block>
  <block id="417a2eafac6842560d3900cf9d12b5bb" category="paragraph"><block ref="417a2eafac6842560d3900cf9d12b5bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0463a63e8059055e703ecd9ffa72e106" category="list-text">Fare clic su Connect (Connetti) per connettersi alla nuova interfaccia Web del server.</block>
  <block id="4fbf21602f4888216386998d62f1defd" category="list-text">Verificare che il volume del set di dati specificato al punto 6 sia montato sul server. Si noti che questo volume viene montato nell'area di lavoro predefinita per impostazione predefinita. Dal punto di vista dell'utente, questa è solo un'altra cartella all'interno dello spazio di lavoro. L'utente, che è probabilmente un data scientist e non un esperto di infrastruttura, non deve possedere alcuna esperienza di storage per utilizzare questo volume.</block>
  <block id="c4b6acc44505864a5dccae2571b74f6a" category="paragraph"><block ref="c4b6acc44505864a5dccae2571b74f6a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7d375154397ce9358d2234ec578ff7e" category="paragraph"><block ref="a7d375154397ce9358d2234ec578ff7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="479d03862d87da58784e60e5cfcec977" category="list-text">Aprire un terminale e, supponendo che sia stato richiesto un nuovo volume nel passaggio 5, eseguire<block ref="109faa0d3af468439c8966d496020840" prefix=" " category="inline-code"></block> Per confermare che un nuovo volume persistente con provisioning Trident è montato come area di lavoro predefinita.</block>
  <block id="68f39a4f77e618e6617c3830fb47de7c" category="paragraph">La directory predefinita dello spazio di lavoro è la directory di base che viene visualizzata quando si accede per la prima volta all'interfaccia Web del server. Pertanto, tutti gli artefatti creati utilizzando l'interfaccia Web vengono memorizzati su questo volume persistente con provisioning Trident.</block>
  <block id="d3e91c75db0cb717734224e6eb72e201" category="paragraph"><block ref="d3e91c75db0cb717734224e6eb72e201" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d739fe0e421e9cb4d6315f0021cc5eb" category="paragraph"><block ref="1d739fe0e421e9cb4d6315f0021cc5eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8c20de15cf5efa2297f9d40d899450e" category="list-text">Utilizzando il terminale, eseguire<block ref="21c52f2a2730f054205ebdf40f536e5a" prefix=" " category="inline-code"></block> Per confermare che il numero corretto di GPU è stato allocato al notebook server. Nell'esempio seguente, una GPU è stata allocata al notebook server come richiesto nel passaggio 7.</block>
  <block id="ed4e7225349e5c6cd33dfd15ad878438" category="paragraph"><block ref="ed4e7225349e5c6cd33dfd15ad878438" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c64f80d07d5c1623b7b2f34e40d7b46c" category="inline-link-macro">Avanti: Esempi di notebook e pipeline.</block>
  <block id="c3714374d558db5573b4ecd4261e206e" category="paragraph"><block ref="c3714374d558db5573b4ecd4261e206e" category="inline-link-macro-rx"></block></block>
  <block id="bd7c9d63c88eb380170362e93db6ba46" category="summary">Questa sezione descrive le configurazioni testate, l'infrastruttura di rete, il server SR670 V2 e i dettagli relativi al provisioning dello storage.</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">Eseguire il test della configurazione</block>
  <block id="ac0ec60d36dfa69ed9c33bff90080b23" category="inline-link-macro">Precedente: Risultati del test.</block>
  <block id="86473a82da3bbf22df039db481fe256f" category="paragraph"><block ref="86473a82da3bbf22df039db481fe256f" category="inline-link-macro-rx"></block></block>
  <block id="a1052c50691421535c201fa50690a1ca" category="paragraph">Questa sezione descrive le configurazioni testate, l'infrastruttura di rete, il server SR670 V2 e i dettagli sul provisioning dello storage NetApp.</block>
  <block id="7c8d74d4c719b2f2e30a143bb98717ad" category="paragraph">Per questa convalida sono stati utilizzati i componenti della soluzione elencati nella tabella seguente.</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="cell">Server Lenovo ThinkSystem</block>
  <block id="35c99b744e4464f42b9b61595c1a1e79" category="list-text">Due server SR670 V2 ciascuno con otto schede GPU NVIDIA A100 da 80 GB</block>
  <block id="222a9edda77d8676279c651c1b06d653" category="list-text">Ogni server contiene 2 CPU Intel Xeon Platinum 8360Y (28 core fisici) e 1 TB di RAM</block>
  <block id="e18f1a9d73bf89b2b1245e5af1a99cf4" category="cell">Linux (Ubuntu – 20.04 con CUDA 11.8)</block>
  <block id="2113187ee3a9451b60e960fdea11bbac" category="cell">Sistema storage NetApp AFF (coppia ha)</block>
  <block id="73b4d2da39f967445be9b79a6016c84c" category="list-text">Software NetApp ONTAP 9.10.1</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">24x 960 GB SSD</block>
  <block id="4028b206981977bc3aea334fd55f4cb9" category="list-text">1 gruppo di interfacce (ifgrp) per controller, con quattro indirizzi IP logici per i mount point</block>
  <block id="82693066c3bae0719e01ba8060494172" category="paragraph">In questa convalida, abbiamo utilizzato ResNet v2.0 con il set di base ImageNet come specificato da MLPerf v2.0. Il set di dati viene memorizzato in un sistema storage NetApp AFF con protocollo NFS. Gli SR670 sono stati collegati al sistema di storage NetApp AFF A400 tramite uno switch 100GbE.</block>
  <block id="e4869dda2a4e140bc138f43895626550" category="paragraph">ImageNet è un set di dati di immagini utilizzato di frequente. Contiene quasi 1.3 milioni di immagini per una dimensione totale di 144 GB. La dimensione media dell'immagine è di 108 KB.</block>
  <block id="3961f6874ee29dab2f4982bc3e0a1be5" category="paragraph">La seguente figura illustra la topologia di rete della configurazione testata.</block>
  <block id="d015822ec6fd4a7fc9867768f5a27898" category="inline-image-macro">Questa immagine mostra il livello di elaborazione, un Lenovo ThinkSystem SR670 V2, il livello di rete, uno switch Ethernet Lenovo e il livello di storage, un controller di storage NetApp AFF A400. Sono incluse tutte le connessioni di rete.</block>
  <block id="1ee331a29f95ebce1684e5e998f3e70c" category="paragraph"><block ref="1ee331a29f95ebce1684e5e998f3e70c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18866bc1d6ba54b48522f7a219e02740" category="paragraph">La seguente tabella elenca la configurazione dello storage.</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">Controller</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">Aggregato</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">Volume FlexGroup</block>
  <block id="f64bc191156dac76ffce8622c16cb21d" category="cell">Dimensione dell'aggregato</block>
  <block id="6bb41960470a19d97556b9240ac0b3ff" category="cell">Dimensione del volume</block>
  <block id="abd2beb6abe5072ffab5f1aad1a8c27f" category="cell">Punto di montaggio del sistema operativo</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">Controller 1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">Aggr1</block>
  <block id="a38b6dcf7d1d2c2957803ba9a28b472e" category="cell">/a400-100g</block>
  <block id="43f5cd38d362fc55ace2f313e6b5cf09" category="cell">9,9 TB</block>
  <block id="09808554056bf39d02319e3dbc2d6667" category="cell">19 TB</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">Controller 2</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">Aggr2</block>
  <block id="a27053e11ec415312f3dc32f4e351b67" category="admonition">La cartella /a400-100g contiene il set di dati utilizzato per la convalida ResNet.</block>
  <block id="1ea4953a2e32bbad1a47dd39cbfe929a" category="inline-link-macro">Segue: Procedura di test e risultati dettagliati.</block>
  <block id="b20175407b354f0dfc3a4d6a98917f6f" category="paragraph"><block ref="b20175407b354f0dfc3a4d6a98917f6f" category="inline-link-macro-rx"></block></block>
  <block id="2625fb6375d503af481868caf90606c9" category="summary">Questa sezione si collega a due notebook Jupyter pertinenti a questo report tecnico.</block>
  <block id="91409fc3ebd20becb4eb816cbcceb02e" category="doc">Notebook Jupyter come riferimento</block>
  <block id="53ffd6a9e0049c8cbf7f940c2b8bc793" category="inline-link-macro">Precedente: Versione di set di dati e modelli con NetApp DataOps Toolkit.</block>
  <block id="01643859d7e5dff013d2acd6a02af35e" category="paragraph"><block ref="01643859d7e5dff013d2acd6a02af35e" category="inline-link-macro-rx"></block></block>
  <block id="cdd5560e07964d04d88721f16446a3b6" category="paragraph">Al report tecnico sono associati due notebook Jupyter:</block>
  <block id="1490d9a5ddbc6bcbe6cedaa01eb50f99" category="inline-link-macro">*CTR-PandasRF-collated.ipynb.*</block>
  <block id="562c7333f0fea5590cfeb818a55e6557" category="list-text"><block ref="6f686a9606ae64621340ea0a5e72dfde" category="inline-link-macro-rx"></block> Questo notebook carica il giorno 15 dal set di dati Click Logs di Criteo Terabyte, elabora e formatta i dati in un Pandas DataFrame, forma un modello di foresta casuale Scikit-learn, esegue la previsione e calcola la precisione.</block>
  <block id="c0cb1f1199ae4e4bdfa626e26a5a25cd" category="inline-link-macro">*criteo_dask_RF.ipynb.*</block>
  <block id="fa93cb17bf7778768ccae778487bf90d" category="list-text"><block ref="01d86d8522c2722466fcbda71181d3ff" category="inline-link-macro-rx"></block> Questo notebook carica il giorno 15 dal set di dati Click Logs di Criteo Terabyte, elabora e formatta i dati in un cuDF Dask, forma un modello di foresta casuale cuML Dask, esegue la previsione e calcola la precisione. Sfruttando nodi di lavoro multipli con GPU, questo approccio di elaborazione e formazione dei dati distribuiti e dei modelli è altamente efficiente. Maggiore è il numero di dati elaborati, maggiore è il risparmio di tempo rispetto a un approccio ML convenzionale. È possibile implementare questo notebook nel cloud, on-premise o in un ambiente ibrido in cui il cluster Kubernetes contiene calcolo e storage in posizioni diverse, purché la configurazione di rete consenta il libero spostamento dei dati e la distribuzione dei modelli.</block>
  <block id="1d1983037d4fd7beac963697b84f82bd" category="paragraph"><block ref="1d1983037d4fd7beac963697b84f82bd" category="inline-link-macro-rx"></block></block>
  <block id="1d126a9d86b70dcdbc0585754993a848" category="summary">Questa soluzione si concentra sull'architettura cluster entry-level e mid-range utilizzando lo storage NetApp e i server Lenovo ottimizzati per i carichi di lavoro di intelligenza artificiale. È destinato ai team di piccole e medie dimensioni per i quali la maggior parte dei processi di calcolo sono a nodo singolo (GPU singola o multipla) o sono distribuiti su alcuni nodi di calcolo. Non si tratta di una limitazione importante, perché la maggior parte dei lavori di training ai giornalieri sono a nodo singolo.</block>
  <block id="119a956725a313a60a3ef97db900f9fa" category="doc">TR-4810: Training sul modello NetApp AFF A400 con Lenovo ThinkSystem SR670 V2 per ai e ML</block>
  <block id="db297dc3a6b72858a5039fa6507a2b34" category="paragraph">Sathish Thyagarajan, David Arnette, NetApp Mircea Troaca, Lenovo</block>
  <block id="252875fbe73a0c4ecbd42a23cc730022" category="paragraph">Questa soluzione presenta un'architettura di cluster midrange che utilizza lo storage NetApp e i server Lenovo ottimizzati per i carichi di lavoro di intelligenza artificiale (ai). È destinato alle piccole e medie imprese per le quali la maggior parte dei lavori di calcolo sono a nodo singolo (GPU singola o multipla) o distribuiti su alcuni nodi di calcolo. Questa soluzione si allinea con la maggior parte dei lavori di training ai giornalieri per molte aziende.</block>
  <block id="2fd79dc2b0743358191fe41cd806d103" category="paragraph">Il presente documento illustra il test e la convalida di una configurazione di calcolo e storage costituita da server Lenovo SR670V2 a otto GPU, un sistema storage NetApp AFF A400 di fascia media e uno switch di interconnessione da 100 GbE. Per misurare le performance, abbiamo utilizzato ResNet50 con il set di dati ImageNet, una dimensione batch di 408, mezza precisione, CUDA e cuDNN. Questa architettura offre una soluzione efficiente e conveniente per le piccole e medie imprese, iniziando con iniziative di ai che richiedono le funzionalità di livello Enterprise dello storage dei dati connesso al cloud di NetApp ONTAP.</block>
  <block id="a186cc4a556d59a6e7b787796afd96a6" category="list-text">Data scientist, data engineer, amministratori di dati e sviluppatori di sistemi ai</block>
  <block id="9f16d751276619605acf16a23befe48e" category="list-text">Architetti aziendali che progettano soluzioni per lo sviluppo di modelli ai</block>
  <block id="e8982c30a351cd862612b0062923a81e" category="list-text">Data scientist e data engineer alla ricerca di metodi efficienti per raggiungere gli obiettivi di sviluppo del deep learning (DL) e dell'apprendimento automatico (ML)</block>
  <block id="ca84e34dfe1115f7b462050a20377876" category="list-text">Business leader e decision maker IT/IT che desiderano ottenere il più rapido time-to-market possibile per le iniziative ai</block>
  <block id="a2dac0ecb0b60ec2625d20a5003869fb" category="paragraph">Questa soluzione con server Lenovo ThinkSystem e NetApp ONTAP con storage AFF è progettata per gestire la formazione ai su grandi set di dati utilizzando la potenza di elaborazione delle GPU insieme alle CPU tradizionali. Questa convalida dimostra performance elevate e una gestione ottimale dei dati con un'architettura scale-out che utilizza uno, due o quattro server Lenovo SR670 V2 insieme a un singolo sistema storage NetApp AFF A400. La figura seguente fornisce una panoramica dell'architettura.</block>
  <block id="9eaa73568302c6f5b850762b65b3f334" category="inline-image-macro">Questa immagine mostra uno switch Ethernet circondato dal server di gestione, quattro SR670 V2S con otto GPU ciascuno e un sistema di storage NetApp ONTAP.</block>
  <block id="d0d5bc4c21e600127e347c093cc29e80" category="paragraph"><block ref="d0d5bc4c21e600127e347c093cc29e80" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9336931f4103d973313cb8539e5c2613" category="list-text">Performance altamente efficienti e convenienti quando si eseguono più lavori di formazione in parallelo</block>
  <block id="81c3992924ee5cdc4cb02692dcae98b4" category="list-text">Performance scalabili basate su diversi numeri di server Lenovo e diversi modelli di controller di storage NetApp</block>
  <block id="bdcea52fecbcd9741f95a6bc0dbbde0f" category="list-text">Protezione dei dati efficace per soddisfare gli obiettivi RPO (Recovery Point Objective) e RTO (Recovery Time Objective) ridotti senza perdita di dati</block>
  <block id="98393526d67c065feb588e5665301706" category="list-text">Gestione dei dati ottimizzata con snapshot e cloni per ottimizzare i flussi di lavoro di sviluppo</block>
  <block id="c8da2691d0a05080662301b92e048a74" category="paragraph"><block ref="c8da2691d0a05080662301b92e048a74" category="inline-link-macro-rx"></block></block>
  <block id="c4c3630750312520bc4b93c16056bfd7" category="doc">NetApp EF-Series ai con NVIDIA</block>
  <block id="e6ee072aeeb0647d8c0cfe75e4cde51d" category="paragraph">Panoramica delle soluzioni di infrastruttura convergente EF-Series ai di NetApp e NVIDIA.</block>
  <block id="0c3efd7c1aae12456ab9935ae5fd15e0" category="section-title">EF-Series ai con sistemi NVIDIA DGX A100 e BeeGFS</block>
  <block id="f512fcc18626023378bfe28dce07116d" category="list-text"><block ref="f512fcc18626023378bfe28dce07116d" category="inline-link-macro-rx"></block></block>
  <block id="ae02a3224f15623423f197426c44a26d" category="list-text"><block ref="ae02a3224f15623423f197426c44a26d" category="inline-link-macro-rx"></block></block>
  <block id="8ce1a272bf4c47418ea6d69083f2df4f" category="inline-link-macro">Guida all'implementazione di BeeGFS</block>
  <block id="7991adac41b3f0e292dee61e87c39052" category="list-text"><block ref="7991adac41b3f0e292dee61e87c39052" category="inline-link-macro-rx"></block></block>
  <block id="f68b67869778246b8f0d8a98ed043512" category="paragraph">In questa sezione vengono fornite informazioni dettagliate sull'implementazione di Virtual Retail Assistant.</block>
  <block id="02216530e0245f79b0b7448e14bffbce" category="inline-link-macro">Avanti: Implementazione di Jarvis</block>
  <block id="a9ca2532d8607b5827969961f314249e" category="paragraph"><block ref="a9ca2532d8607b5827969961f314249e" category="inline-link-macro-rx"></block></block>
  <block id="f0de4adaf6568678921cef0d0e69b81f" category="summary">NVIDIA ai Enterprise con NetApp e VMware - Panoramica sulla tecnologia</block>
  <block id="bdab293b91374abd32d30076de9d29b9" category="paragraph"><block ref="bdab293b91374abd32d30076de9d29b9" category="inline-link-macro-rx"></block></block>
  <block id="51ab86189ca8b1d1a08ac2970d39f90c" category="section-title">NVIDIA ai Enterprise</block>
  <block id="0719941ec04c59670033b3b1f0e3c239" category="paragraph">NVIDIA ai Enterprise è una suite end-to-end nativa del cloud di software di ai e data analytics ottimizzato, certificato e supportato da NVIDIA per l'esecuzione su VMware vSphere con sistemi certificati NVIDIA. Questo software facilita l'implementazione, la gestione e la scalabilità semplici e rapide dei carichi di lavoro ai nel moderno ambiente di cloud ibrido.</block>
  <block id="9052758d35faeab8995feefc50d729ed" category="section-title">NVIDIA GPU CLOUD (NGC)</block>
  <block id="cbd4c44d2b7fc45943b834d2a03f2a63" category="paragraph">NVIDIA NGC ospita un catalogo di software ottimizzato per GPU per i professionisti dell'ai per sviluppare le proprie soluzioni di ai. Fornisce inoltre accesso a vari servizi di ai, tra cui NVIDIA base Command per la formazione sui modelli, NVIDIA Fleet Command per l'implementazione e il monitoraggio dei modelli e NGC Private Registry per l'accesso e la gestione sicuri del software proprietario di ai. Inoltre, i clienti di NVIDIA ai Enterprise possono richiedere il supporto tramite il portale NGC.</block>
  <block id="7ee50a783ac86f99c7b7db29b77e7a2a" category="paragraph">VMware vSphere è la piattaforma di virtualizzazione di VMware, che trasforma i data center in infrastrutture di calcolo aggregate che includono CPU, storage e risorse di rete. VSphere gestisce queste infrastrutture come un ambiente operativo unificato e fornisce agli amministratori gli strumenti per gestire i data center che partecipano a tale ambiente.</block>
  <block id="a8b821c11b6c83cd7165137d4f68a45b" category="paragraph">I due componenti principali di vSphere sono ESXi e vCenter Server. ESXi è la piattaforma di virtualizzazione in cui gli amministratori creano ed eseguono macchine virtuali e appliance virtuali. VCenter Server è il servizio attraverso il quale gli amministratori gestiscono più host connessi in una rete e pool di risorse host.</block>
  <block id="f45c2aa2e74e3412ee9883eb28b7549e" category="paragraph">ONTAP 9, l'ultima generazione di software per la gestione dello storage NetApp, consente alle aziende di modernizzare l'infrastruttura e passare a un data center predisposto per il cloud. Sfruttando le funzionalità di gestione dei dati leader del settore, ONTAP consente la gestione e la protezione dei dati con un singolo set di strumenti, indipendentemente dalla posizione dei dati. Puoi anche spostare liberamente i dati ovunque siano necessari: Edge, core o cloud. ONTAP 9 include numerose funzionalità che semplificano la gestione dei dati, accelerano e proteggono i dati critici e abilitano le funzionalità dell'infrastruttura di nuova generazione nelle architetture di cloud ibrido.</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">Semplifica la gestione dei dati</block>
  <block id="47b2e74e56111387efd2ff8314d1154c" category="paragraph">La gestione dei dati è fondamentale per le operazioni IT aziendali e per i data scientist, in modo che le risorse appropriate vengano utilizzate per le applicazioni ai e per la formazione dei set di dati ai/ML. Le seguenti informazioni aggiuntive sulle tecnologie NetApp non rientrano nell'ambito di questa convalida, ma potrebbero essere rilevanti a seconda dell'implementazione.</block>
  <block id="31c0318dee8b7049a328f752c457824f" category="paragraph">Il software per la gestione dei dati ONTAP include le seguenti funzionalità per ottimizzare e semplificare le operazioni e ridurre il costo totale delle operazioni:</block>
  <block id="258ce6748736436345d3a4ade7bfcd47" category="list-text">Compaction dei dati inline e deduplica estesa. La compattazione dei dati riduce lo spazio sprecato all'interno dei blocchi di storage e la deduplica aumenta significativamente la capacità effettiva. Ciò vale per i dati memorizzati localmente e per i dati a più livelli nel cloud.</block>
  <block id="e0243dd3e4c9bff6b7a18cab1c1e37c8" category="list-text">Qualità del servizio (AQoS) minima, massima e adattativa. I controlli granulari della qualità del servizio (QoS) aiutano a mantenere i livelli di performance per le applicazioni critiche in ambienti altamente condivisi.</block>
  <block id="c3528a5e48bbe189e76cf8d737aa5961" category="inline-link">TR-4598: Best practice FabricPool</block>
  <block id="adc171e1d8b6a0bed3a98762139c9875" category="list-text">NetApp FabricPool. Offre il tiering automatico dei dati cold per le opzioni di cloud storage pubblico e privato, tra cui Amazon Web Services (AWS), Azure e la soluzione di storage NetApp StorageGRID. Per ulteriori informazioni su FabricPool, vedere<block ref="234c921b7066bc1bdd676ae1a510e5c5" category="inline-link-rx"></block>.</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">Accelera e proteggi i dati</block>
  <block id="d9cd75773d759d63134b34db3490eab3" category="paragraph">ONTAP offre livelli superiori di performance e protezione dei dati ed estende queste funzionalità nei seguenti modi:</block>
  <block id="cdea8196113c492688981e0a035baa29" category="list-text">Performance e latenza ridotta. ONTAP offre il throughput più elevato possibile con la latenza più bassa possibile.</block>
  <block id="fa126db4297464dd03b3ceef190df0d0" category="list-text">Protezione dei dati. ONTAP offre funzionalità di protezione dei dati integrate con gestione comune su tutte le piattaforme.</block>
  <block id="892dd840b39835d7da795bbd29f99987" category="list-text">NetApp Volume Encryption (NVE). ONTAP offre crittografia nativa a livello di volume con supporto per la gestione delle chiavi sia integrata che esterna.</block>
  <block id="1f17e94c6f48114ff29ad3267277420c" category="list-text">Multi-tenancy e autenticazione a più fattori. ONTAP consente la condivisione delle risorse dell'infrastruttura con i massimi livelli di sicurezza.</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">Infrastruttura a prova di futuro</block>
  <block id="836ed833c0dea3b588f04d16ca3f850d" category="paragraph">ONTAP aiuta a soddisfare le esigenze di business esigenti e in continua evoluzione con le seguenti funzionalità:</block>
  <block id="b816bfff9511bcd88a9aa06fe0fd6389" category="list-text">Scalabilità perfetta e operazioni senza interruzioni. ONTAP supporta l'aggiunta senza interruzioni di capacità ai controller esistenti e ai cluster scale-out. I clienti possono eseguire l'upgrade alle tecnologie più recenti, come NVMe e 32GB FC, senza costose migrazioni dei dati o interruzioni.</block>
  <block id="74c384c0caae9c39b0e414cecc8c66ea" category="list-text">Connessione al cloud. ONTAP è il software per la gestione dello storage più connesso al cloud, con opzioni per lo storage software-defined (ONTAP Select) e le istanze native del cloud (NetApp Cloud Volumes Service) in tutti i cloud pubblici.</block>
  <block id="2a7e7bc180cc3d059089e02f091bac27" category="list-text">Integrazione con le applicazioni emergenti. ONTAP offre servizi dati di livello Enterprise per piattaforme e applicazioni di prossima generazione, come veicoli autonomi, città intelligenti e industria 4.0, utilizzando la stessa infrastruttura che supporta le applicazioni aziendali esistenti.</block>
  <block id="7cc4f632835e2377fd90f38601a3e0eb" category="paragraph">Il NetApp DataOps Toolkit è uno strumento basato su Python che semplifica la gestione degli spazi di lavoro di sviluppo/formazione e dei server di inferenza supportati dallo storage NetApp scale-out dalle performance elevate. Le funzionalità principali includono:</block>
  <block id="f9e55f3095ff79acd2c7f6315222ba4a" category="list-text">Provisioning rapido di nuove aree di lavoro JupyterLab ad alta capacità supportate da storage NetApp scale-out dalle performance elevate.</block>
  <block id="a9e4b1a2cc4b445907d2b986ab2f3515" category="list-text">Provisioning rapido delle nuove istanze di NVIDIA Triton Inference Server supportate dallo storage NetApp di livello Enterprise.</block>
  <block id="23b97f551923a166ae2d3223b0ed84cc" category="list-text">Clonare quasi instantaneamente le aree di lavoro JupyterLab ad alta capacità per consentire la sperimentazione o l'iterazione rapida.</block>
  <block id="27c7d5bdafd6a9d64ad337b08e104c87" category="list-text">Salvataggio quasi istantaneo di snapshot di aree di lavoro JupyterLab ad alta capacità per backup e/o tracciabilità/baselining.</block>
  <block id="86f28dd8fdffc90314bf94c94e1b3c1c" category="list-text">Provisioning, cloning e snapshot near-instataneamente di volumi di dati ad alta capacità e performance elevate.</block>
  <block id="263db194560bc66bd5de27c72f9b7923" category="paragraph"><block ref="263db194560bc66bd5de27c72f9b7923" category="inline-link-macro-rx"></block></block>
  <block id="9e59f01034d2c132fac901b9c14a5d88" category="summary">Il NetApp DataOps Toolkit per Kubernetes astratta le risorse di storage e i carichi di lavoro Kubernetes fino al livello di spazio di lavoro per la scienza dei dati. Queste funzionalità sono integrate in un'interfaccia semplice e facile da usare, progettata per data scientist e data engineer.</block>
  <block id="7aee811c7e891ab94bb5be40b333faaf" category="doc">Versione di set di dati e modelli con NetApp DataOps Toolkit</block>
  <block id="f7136197d3b16131979b9319c4acce63" category="inline-link-macro">Precedente: Monitoraggio di Dask e RAPIDE con Prometheus e Grafana.</block>
  <block id="402dae1972461d7e7ba986ab6728df6c" category="paragraph"><block ref="402dae1972461d7e7ba986ab6728df6c" category="inline-link-macro-rx"></block></block>
  <block id="fd2d048a9ec0f96d89493b98f72cbe34" category="paragraph">Il NetApp DataOps Toolkit per Kubernetes astratta le risorse di storage e i carichi di lavoro Kubernetes fino al livello di spazio di lavoro per la scienza dei dati. Queste funzionalità sono integrate in un'interfaccia semplice e facile da usare, progettata per data scientist e data engineer. Utilizzando la forma familiare di un programma Python, il Toolkit consente a data scientist e ingegneri di eseguire il provisioning e la distruzione delle aree di lavoro di JupyterLab in pochi secondi. Queste aree di lavoro possono contenere terabyte, o persino petabyte, di capacità di storage, consentendo agli scienziati dei dati di memorizzare tutti i set di dati di training direttamente nelle aree di lavoro dei progetti. Sono finiti i tempi della gestione separata degli spazi di lavoro e dei volumi di dati.</block>
  <block id="4a6c7893abd7ef92fb09d3359e17324d" category="inline-link">Repository di GitHub</block>
  <block id="eb0d40310a9cc0432fac66dc97652c39" category="paragraph">Per ulteriori informazioni, visitare il Toolkit<block ref="64134ca6239d4056f34489b42f2baeed" category="inline-link-rx"></block>.</block>
  <block id="a5e99aa2ffae2218fdcf2038b1b3fd1b" category="doc">TR-4851: Data Lake NetApp StorageGRID per carichi di lavoro di guida autonoma - progettazione della soluzione</block>
  <block id="0e2b7ed1591c52ac15ea956ecb6a5701" category="paragraph">TR-4851 dimostra l'utilizzo dello storage a oggetti NetApp StorageGRID come repository di dati e sistema di gestione per l'apprendimento automatico (ML) e lo sviluppo di software di deep learning (DL). Questo documento descrive il flusso di dati e i requisiti nello sviluppo di software per veicoli autonomi e le funzionalità di StorageGRID che ottimizzano il ciclo di vita dei dati. Questa soluzione si applica a qualsiasi workflow di pipeline di dati multistadio tipico dei processi di sviluppo ML e DL.</block>
  <block id="ba9a0dcacc73fb54c527ad33eceb30c1" category="paragraph"><block ref="ba9a0dcacc73fb54c527ad33eceb30c1" category="inline-link-macro-rx"></block></block>
  <block id="c46aabfbeb0af662ede62f7325853fa2" category="summary">L'elaborazione delle immagini digitali offre numerosi vantaggi, consentendo a molte organizzazioni di sfruttare al meglio i dati associati alle rappresentazioni visive. Questa soluzione NetApp e Protopia offre un design di inferenza ai unico per proteggere e privatizzare i dati ai/ML nel ciclo di vita ML/DL. Consente ai clienti di mantenere la proprietà dei dati sensibili, utilizzare modelli di implementazione del cloud pubblico o ibrido per scalabilità ed efficienza, alleviando i problemi relativi alla privacy e implementando l'inferenza ai ai ai ai edge.</block>
  <block id="b7aff368ab91b524750e403085893177" category="paragraph"><block ref="b7aff368ab91b524750e403085893177" category="inline-link-macro-rx"></block></block>
  <block id="55ece983a5251583397e3db1cd3926ec" category="section-title">Intelligence ambientale</block>
  <block id="d0f24bc92f5b7838f03e893b41066a90" category="paragraph">Esistono diversi modi in cui i settori possono sfruttare le analisi geospaziali nelle aree dei rischi ambientali. I governi e il dipartimento delle opere pubbliche possono trarre utili informazioni sulla salute pubblica e sulle condizioni meteorologiche per consigliare meglio il pubblico durante una pandemia o un disastro naturale come gli incendi. Ad esempio, è possibile identificare un paziente COVID-positivo in spazi pubblici, come aeroporti o ospedali, senza compromettere la privacy della persona interessata e avvisare le rispettive autorità e il pubblico nelle vicinanze per le misure di sicurezza necessarie.</block>
  <block id="4f9352e4f65872238d755155cd23edec" category="section-title">Dispositivi indossabili edge</block>
  <block id="315a1bbca88dbcbdc95471a0061c333f" category="paragraph">Nel settore militare e nei campi di battaglia, è possibile utilizzare l'inferenza ai all'edge come dispositivi indossabili per monitorare la salute dei soldati, monitorare il comportamento dei conducenti e avvisare le autorità sulla sicurezza e i rischi associati all'avvicinamento ai veicoli militari, preservando e proteggendo la privacy dei soldati. Il futuro dei militari sta diventando high-tech con Internet of Battlefield Things (IoBT) e Internet of Military Things (IoMT) per attrezzature da combattimento indossabili che aiutano i soldati a identificare i nemici e a migliorare le performance in battaglia utilizzando il calcolo rapido edge. La protezione e la conservazione dei dati visivi raccolti da dispositivi edge come droni e dispositivi indossabili è fondamentale per tenere a bada hacker e nemici.</block>
  <block id="d6dded41a42f767150e641793fc0c929" category="section-title">Operazioni di evacuazione non combattente</block>
  <block id="c5b381de9b2a4ee73bcc524aa380d725" category="paragraph">Le operazioni di evacuazione dei non combattenti (NEO) sono condotte dal DOD per aiutare a evacuare cittadini e cittadini degli Stati Uniti, personale civile del DOD e persone designate (nazione ospitante (HN) e cittadini di paesi terzi (TCN)) la cui vita è in pericolo per un adeguato rifugio sicuro. I controlli amministrativi in uso utilizzano processi di screening per l'evacuazione in gran parte manuali. Tuttavia, l'accuratezza, la sicurezza e la velocità dell'identificazione degli evacuati, del monitoraggio degli evacuati e dello screening delle minacce potrebbero potenzialmente essere migliorate utilizzando strumenti ai/ML altamente automatizzati combinati con tecnologie di offuscamento video ai/ML.</block>
  <block id="19c95c19bd7c939577775cd0ecce3df1" category="section-title">Ricerca sanitaria e biomedica</block>
  <block id="a047c61461aba5a84a0a221900c33984" category="paragraph">L'elaborazione delle immagini viene utilizzata per diagnosticare patologie per la pianificazione chirurgica da immagini 3D ottenute dalla tomografia computerizzata (TC) o dall'imaging a risonanza magnetica (MRI). Le norme sulla privacy di HIPAA regolano le modalità di raccolta, elaborazione e cancellazione dei dati da parte delle organizzazioni per tutte le informazioni personali e le immagini digitali come le fotografie. Affinché i dati possano qualificarsi come condivisibili in base alle normative HIPAA Safe Harbor, è necessario rimuovere le immagini fotografiche a pieno facciale e le immagini comparabili. Tecniche automatizzate come la deidentificazione o il cranio‐gli algoritmi di spelatura utilizzati per oscurare le caratteristiche facciali di un individuo dalle immagini strutturali TC/RM sono diventati una parte essenziale del processo di condivisione dei dati per gli istituti di ricerca biomedica.</block>
  <block id="2d930616ec617ae047b7b7eaefb0822c" category="section-title">Migrazione nel cloud degli analytics ai/ML</block>
  <block id="073395e7b5fc53b602884ac0aaf757fb" category="inline-link">protezione dei dati</block>
  <block id="2c5c3872e94de8a36eac45213c5bf2e6" category="paragraph">I clienti aziendali hanno tradizionalmente addestrato e implementato modelli ai/ML on-premise. Per motivi di efficienza e scalabilità, questi clienti si stanno espandendo per spostare le funzioni ai/ML in implementazioni di cloud pubblico, ibrido o multi-cloud. Tuttavia, sono vincolati da quali dati possono essere esposti ad altre infrastrutture. Le soluzioni NetApp affrontano una gamma completa di minacce alla cybersicurezza richieste per<block ref="9da3a9a08c9461b229d33f221e8caa37" category="inline-link-rx"></block> E la valutazione della sicurezza e, se combinata con la trasformazione dei dati di Protopia, riducono al minimo i rischi associati alla migrazione dei carichi di lavoro ai/ML di elaborazione delle immagini nel cloud.</block>
  <block id="c9f2e6462caf995f1d336ab4bb33a7c2" category="inline-link">TR-4886 ai Inferencing at the Edge</block>
  <block id="ae1b6ac445119145d739025d55fe616f" category="inline-link">Intelligence e privacy</block>
  <block id="215649425fa669fb4825e25a6ace492e" category="paragraph">Per ulteriori casi di utilizzo per l'edge computing e l'inferenza ai in altri settori, vedere<block ref="922342ea98ca297422c6dc441f974a04" category="inline-link-rx"></block> E il blog NetApp ai,<block ref="bc130be57ffb0325128dc7274bbdbc64" category="inline-link-rx"></block>.</block>
  <block id="5318c453b0f0b1d5351026eca9f9899d" category="paragraph"><block ref="5318c453b0f0b1d5351026eca9f9899d" category="inline-link-macro-rx"></block></block>
  <block id="a7fbadb37067070a61a3da62b548ba3c" category="paragraph">NVIDIA NEMO è un toolkit creato da NVIDIA per la creazione di applicazioni ai conversazionali. Questo toolkit include raccolte di moduli pre-formati per ASR, NLP e TTS, che consentono a ricercatori e data scientist di comporre facilmente architetture di rete neurali complesse e di concentrarsi maggiormente sulla progettazione delle proprie applicazioni.</block>
  <block id="1a56a4858eeec63d31bc890d38325b84" category="paragraph">Come illustrato nell'esempio precedente, NARA può gestire solo un tipo limitato di domanda. Questo perché il modello di NLP pre-addestrato si allena solo su questi tipi di domande. Se vogliamo consentire A NARA di gestire una gamma più ampia di domande, dobbiamo rielaborare il sistema con i nostri set di dati. In questo caso, dimostreremo come possiamo utilizzare NEMO per estendere il modello NLP in modo da soddisfare i requisiti. Iniziamo convertendo il log raccolto da NARA nel formato NEMO, quindi ci alleniamo con il set di dati per migliorare il modello NLP.</block>
  <block id="4e19d1e300ea3cd63472939c24caf65d" category="paragraph">Il nostro obiettivo è consentire A NARA di ordinare gli elementi in base alle preferenze dell'utente. Ad esempio, potremmo chiedere A NARA di suggerire il ristorante di sushi più classificato o di cercare I jeans CON il prezzo più basso. A tal fine, utilizziamo il modello di rilevamento degli intenti e di riempimento degli slot fornito in NEMO come modello di training. Questo modello consente A NARA di comprendere l'intento della ricerca delle preferenze.</block>
  <block id="5cb83e5ef3cd25eb53fa55d635a7758f" category="section-title">Preparazione dei dati</block>
  <block id="807cace7b07fcded06b9d106c4dd4d2d" category="paragraph">Per formare il modello, raccogliamo il dataset per questo tipo di domanda e lo convertiamo nel formato NEMO. Qui sono elencati i file utilizzati per la formazione del modello.</block>
  <block id="dc1d3747ed1059f234cbe4a104700abd" category="section-title">dict.intents.csv</block>
  <block id="e803005a5c3a99889733e9c8e8bba406" category="paragraph">Questo file elenca tutti gli intenti che vogliamo che NEMO comprenda. In questo caso, abbiamo due intenti primari e un solo intento utilizzato per classificare le domande che non si inseriscono in nessuno degli intenti primari.</block>
  <block id="ce2440c5074ba6a1e30fa2ec906dafb4" category="section-title">dict.slots.csv</block>
  <block id="a3fc542c51797c85b30365ba9b2d12c5" category="paragraph">Questo file elenca tutti gli slot che possiamo etichettare sulle nostre domande di training.</block>
  <block id="795cab38744084526a62914e47789fbe" category="section-title">train.sv</block>
  <block id="8a5ae45ea3762f79d1a520bcf61275d5" category="paragraph">Questo è il set di dati di training principale. Ogni riga inizia con la domanda che segue l'elenco delle categorie di intento nel file dict.intent.csv. L'etichetta viene enumerata a partire da zero.</block>
  <block id="db487d8daea13e36203f660d46b3cdfc" category="section-title">train_slot.sv</block>
  <block id="73ade6fc5004174d2abe822c85cdfbef" category="section-title">Formare il modello</block>
  <block id="c764142480a5daa39ac98125503352e8" category="paragraph">Quindi, viene utilizzato il seguente comando per avviare il container. In questo comando, limitiamo il container a utilizzare una singola GPU (ID GPU = 1), poiché si tratta di un esercizio di formazione leggero. Inoltre, mappiamo la nostra area di lavoro locale /Workspace/nemo/ nella cartella all'interno di container /nemo.</block>
  <block id="a712c52af847db1e143ca43fdd44bd39" category="paragraph">All'interno del container, se si desidera partire dal modello BERT originale pre-addestrato, è possibile utilizzare il seguente comando per avviare la procedura di training. data_dir è l'argomento per impostare il percorso dei dati di training. work_dir consente di configurare la posizione in cui si desidera memorizzare i file del punto di verifica.</block>
  <block id="9e654b2215e90d20951b3ddd67a15bc6" category="paragraph">Se abbiamo nuovi set di dati di training e vogliamo migliorare il modello precedente, possiamo utilizzare il seguente comando per continuare dal punto in cui ci siamo fermati. checkpoint_dir porta il percorso alla cartella checkpoint precedente.</block>
  <block id="87eea49f703666c49da2d7987ba093b2" category="section-title">Deduzione del modello</block>
  <block id="484c4e9e4a0a20bf41551f65663fa9d2" category="paragraph">Dobbiamo convalidare le performance del modello formatosi dopo un certo numero di epoche. Il seguente comando consente di eseguire il test della query uno per uno. Ad esempio, in questo comando, si desidera verificare se il modello è in grado di identificare correttamente l'intenzione della query<block ref="fe494faf7f8c52514a674b8162027072" prefix=" " category="inline-code"></block>.</block>
  <block id="de558a28e6333ac9f453a42631f44c12" category="paragraph">Di seguito viene riportato l'output dell'inferenza. Nell'output, possiamo vedere che il nostro modello addestrato può prevedere correttamente l'intenzione find_the_store e restituire le parole chiave a cui siamo interessati. Con queste parole chiave, consentiamo A NARA di cercare ciò che gli utenti desiderano e di effettuare una ricerca più precisa.</block>
  <block id="5b7f09a1d5da38512130330f4d38fd32" category="paragraph"><block ref="5b7f09a1d5da38512130330f4d38fd32" category="inline-link-macro-rx"></block></block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="summary">Questa sezione descrive le attività da completare per implementare il flusso d'aria nel cluster Kubernetes.</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Implementazione di Apache Airflow</block>
  <block id="f23c532f744716d23270b963c3eca570" category="paragraph">NetApp consiglia di eseguire Apache Airflow su Kubernetes. Questa sezione descrive le attività da completare per implementare il flusso d'aria nel cluster Kubernetes.</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">È possibile implementare il flusso d'aria su piattaforme diverse da Kubernetes. L'implementazione del flusso d'aria su piattaforme diverse da Kubernetes non rientra nell'ambito di questa soluzione.</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">Hai già un cluster Kubernetes funzionante.</block>
  <block id="e59b39fd5c122dde3747561247eb2888" category="list-text">NetApp Trident è già stato installato e configurato nel cluster Kubernetes, come descritto nella sezione "implementazione e configurazione di NetApp Trident".</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">Installare Helm</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">Il flusso d'aria viene implementato utilizzando Helm, un popolare gestore di pacchetti per Kubernetes. Prima di implementare il flusso d'aria, è necessario installare Helm sull'host di distribuzione jump. Per installare Helm sull'host di distribuzione jump, seguire la<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> Nella documentazione ufficiale di Helm.</block>
  <block id="678c0949a1824bf54eba73ab0a2609d8" category="paragraph">Prima di implementare il flusso d'aria, è necessario specificare un StorageClass predefinito all'interno del cluster Kubernetes. Il processo di implementazione del flusso d'aria tenta di eseguire il provisioning di nuovi volumi persistenti utilizzando la classe di storage predefinita. Se non viene indicato StorageClass come StorageClass predefinito, l'implementazione non riesce. Per designare una StorageClass predefinita all'interno del cluster, seguire le istruzioni riportate nella sezione <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>. Se è già stata designata una StorageClass predefinita all'interno del cluster, è possibile saltare questo passaggio.</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">USA Helm per implementare il flusso d'aria</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">Per implementare il flusso d'aria nel cluster Kubernetes utilizzando Helm, eseguire le seguenti operazioni dall'host di distribuzione jump:</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">istruzioni per l'implementazione</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">Implementare il flusso d'aria utilizzando Helm seguendo il<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block> Per il diagramma ufficiale del flusso d'aria sull'Artifact Hub. I comandi di esempio che seguono mostrano l'implementazione del flusso d'aria con Helm. Modificare, aggiungere e/o rimuovere i valori in<block ref="b03054dec41b4d504351d411d8221d7f" prefix=" " category="inline-code"></block> file in base alle necessità, a seconda dell'ambiente e della configurazione desiderata.</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">Verificare che tutti i pod del flusso d'aria siano in funzione. L'avvio di tutti i pod potrebbe richiedere alcuni minuti.</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">Ottenere l'URL del servizio Web Airflow seguendo le istruzioni stampate sulla console quando si implementa Airflow utilizzando Helm nel passaggio 1.</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">Verificare che sia possibile accedere al servizio Web Airflow.</block>
  <block id="6a8e19652a540e359304ba812d39ea8e" category="paragraph"><block ref="6a8e19652a540e359304ba812d39ea8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99c61a2c4480337fdf852f9dbe8a8863" category="inline-link-macro">Segue: Esempio di flussi di lavoro Apache Airflow.</block>
  <block id="d719776b249ed9e7109b922484d474a2" category="paragraph"><block ref="d719776b249ed9e7109b922484d474a2" category="inline-link-macro-rx"></block></block>
  <block id="2d316c5d9e0cd748d1890ee69f57dc6c" category="summary">In questa sezione vengono riepilogati i risultati dei test di questa soluzione.</block>
  <block id="b1ee26c1917a17c30b17d7cd6b01e2cd" category="inline-link-macro">Precedente: Piano di test.</block>
  <block id="6385fabeefcfa0be0a013cdd61625e31" category="paragraph"><block ref="6385fabeefcfa0be0a013cdd61625e31" category="inline-link-macro-rx"></block></block>
  <block id="80b6b969d6707ba1b92d65466e8325f0" category="paragraph">La seguente tabella riassume i risultati di tutti i test eseguiti per questa soluzione.</block>
  <block id="f5bc14ae022ba581c26f3bdb35badef1" category="cell">Descrizione del test</block>
  <block id="34d8129946f1108a296f033dc66db266" category="cell">Riepilogo dei risultati</block>
  <block id="ab0d993807168c3a70cdd2952d4edfc0" category="cell">Training sul riconoscimento delle immagini: Più processi simultanei</block>
  <block id="290ba1c81812edd0651d8e18c5895054" category="cell">Performance altamente efficienti. Tutti i lavori venivano eseguiti alla massima velocità anche quando il cluster era completamente utilizzato. I sistemi storage NetApp hanno fornito performance di training paragonabili allo storage SSD locale, consentendo allo stesso tempo una facile condivisione dei dati tra server.</block>
  <block id="d58827ca3ccfccb5c83b1dc9c7e12289" category="cell">Training per il riconoscimento delle immagini: Scale-out</block>
  <block id="afb4fda11ecde317daa521e054df2bd4" category="cell">Altamente efficiente per un massimo di quattro nodi. A quel punto, la scalabilità orizzontale era meno efficiente ma ancora fattibile. L'utilizzo di una rete di calcolo ad alta velocità migliora la scalabilità. Il sistema storage NetApp ha fornito performance di training paragonabili allo storage SSD locale, consentendo al contempo una facile condivisione dei dati tra server.</block>
  <block id="09011e7c7cce04b0b96cec58ace75585" category="paragraph"><block ref="09011e7c7cce04b0b96cec58ace75585" category="inline-link-macro-rx"></block></block>
  <block id="a6214fe1ac9a6825ffe38f3b34489c9d" category="summary">NetApp Run ai ha collaborato alla creazione di questo report tecnico per dimostrare le funzionalità uniche di Azure NetApp Files insieme alla piattaforma DI RUN ai per semplificare l'orchestrazione dei carichi di lavoro ai.</block>
  <block id="a55106260c16aab506cebfb58e07e030" category="paragraph">NetApp e RUN: L'ai ha collaborato alla creazione di questo report tecnico per dimostrare le funzionalità uniche di Azure NetApp Files insieme alla piattaforma RUN: Ai per semplificare l'orchestrazione dei carichi di lavoro ai. Questo report tecnico fornisce un'architettura di riferimento per semplificare il processo di pipeline di dati e orchestrazione dei carichi di lavoro per il training di rilevamento della corsia distribuita.</block>
  <block id="4e51614a389f3ad4fa17e2ce7ad984e7" category="paragraph">In conclusione, per quanto riguarda la formazione distribuita su larga scala (soprattutto in un ambiente di cloud pubblico), il componente di orchestrazione delle risorse e storage è una parte critica della soluzione. Assicurarsi che la gestione dei dati non ostacoli mai l'elaborazione di più GPU, per cui si ottiene un utilizzo ottimale dei cicli GPU. Pertanto, rendendo il sistema il più conveniente possibile per scopi di formazione distribuita su larga scala.</block>
  <block id="269c35b1959d92e9ef6665bb4c60ad5d" category="paragraph">Il data fabric fornito da NetApp supera la sfida consentendo a data scientist e data engineer di connettersi tra loro on-premise e nel cloud per avere dati sincroni, senza eseguire alcun intervento manuale. In altre parole, il data fabric rende più uniforme il processo di gestione del workflow ai distribuito in più sedi. Inoltre, facilita la disponibilità dei dati on-demand avvicinando i dati al calcolo ed eseguendo analisi, training e validazione, dove e quando necessario. Questa funzionalità non solo consente l'integrazione dei dati, ma anche la protezione e la sicurezza dell'intera pipeline di dati.</block>
  <block id="dfcb1d1644aa3be367d0ca7761be62ad" category="summary">Questa pagina descrive i passaggi necessari per creare una subnet delegata per Azure NetApp Files.</block>
  <block id="0143a2caee1b9ab090de587206b65fe6" category="doc">Creare una subnet delegata per Azure NetApp Files</block>
  <block id="d991c79e9311d59d4e38f3115d9c5b24" category="inline-link-macro">Precedente: Installare e configurare il cluster AKS.</block>
  <block id="5dd65debe44935eb5866a15b9a62237e" category="paragraph"><block ref="5dd65debe44935eb5866a15b9a62237e" category="inline-link-macro-rx"></block></block>
  <block id="8bffe528b31ee595be868b5a4af3d25a" category="paragraph">Per creare una subnet delegata per Azure NetApp Files, attenersi alla seguente procedura:</block>
  <block id="1aa0034de6393efa24703b8a479a5aa6" category="list-text">Accedere alle reti virtuali all'interno del portale Azure. Trova la tua rete virtuale appena creata. Dovrebbe avere un prefisso come<block ref="a3f69ea034ab8b71fed9b8fc221db9b4" prefix=" " category="inline-code"></block>.</block>
  <block id="f1621549bc319674bb9e859babb2a671" category="list-text">Fare clic sul nome di VNET.</block>
  <block id="c536871a8fac3a4390226f6e485cf662" category="paragraph"><block ref="c536871a8fac3a4390226f6e485cf662" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5025fbb3995af8640cab85f4f91126b" category="list-text">Fare clic su subnet e fare clic su +Subnet nella barra degli strumenti superiore.</block>
  <block id="22307856839205c5209cc8ce1f4ed0df" category="paragraph"><block ref="22307856839205c5209cc8ce1f4ed0df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e45b350630c9a3b31bf0c1a1f03dffb0" category="list-text">Specificare un nome per la subnet, ad esempio<block ref="d2acea3c674306459e768a41444551ba" prefix=" " category="inline-code"></block> Quindi, sotto delega subnet, selezionare<block ref="0c20a1ae75c1cc4efae31193e0d47718" prefix=" " category="inline-code"></block>. Non cambiare altro. Fare clic su OK.</block>
  <block id="3621b1bf0075cb659f152966504dfc0d" category="paragraph"><block ref="3621b1bf0075cb659f152966504dfc0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8034fc216ae23edc69bb75430f3de2f" category="paragraph">I volumi Azure NetApp Files vengono allocati nel cluster di applicazioni e vengono utilizzati come dichiarazioni di volumi persistenti (PVC) in Kubernetes. A sua volta, questo processo offre la flessibilità di mapparli a diversi servizi, come i notebook Jupyter, le funzioni senza server e così via.</block>
  <block id="ac3654eb11c3b0cfc94c6c1abdc6767a" category="paragraph">Gli utenti dei servizi possono consumare lo storage dalla piattaforma in molti modi. Mentre questo report tecnico illustra gli NFS, i principali vantaggi di Azure NetApp Files sono:</block>
  <block id="42ba8b77b788a422a7e4ba2d8bb2d45e" category="list-text">Fornire agli utenti la possibilità di utilizzare le copie Snapshot.</block>
  <block id="a51448debe1bbe5bb229b849d4057e09" category="list-text">Consente agli utenti di memorizzare grandi quantità di dati su volumi Azure NetApp Files.</block>
  <block id="b7c10d399d058ef3538882e444459ba5" category="list-text">Utilizzo dei vantaggi in termini di performance dei volumi Azure NetApp Files quando si eseguono i modelli su grandi set di file.</block>
  <block id="4b15c9979e20dd7eb0c0263e9d5ab1db" category="inline-link-macro">Avanti: Peer AKS vnet e Azure NetApp Files vnet.</block>
  <block id="a9f725be439e4752193d45f7e7f41851" category="paragraph"><block ref="a9f725be439e4752193d45f7e7f41851" category="inline-link-macro-rx"></block></block>
  <block id="cd24a85c5cf2d1a7af0bade6066be0aa" category="summary">I dati esistono in tre stati: A riposo, in transito e nel calcolo. Una parte importante di qualsiasi servizio di inferenza ai dovrebbe essere la protezione dei dati dalle minacce durante l'intero processo. La protezione dei dati durante le deduzione è fondamentale perché il processo può esporre informazioni private sui clienti esterni e sull'azienda che fornisce il servizio di deduzione.</block>
  <block id="fd8d4cefd4e31d8ce81b0b6c4cf90ae2" category="inline-link-macro">Precedente: Velocità di offuscamento.</block>
  <block id="12deb7181b69808aaa08117bd40978a3" category="paragraph"><block ref="12deb7181b69808aaa08117bd40978a3" category="inline-link-macro-rx"></block></block>
  <block id="4282c9ab06938351529fcc9258e39d5a" category="paragraph">I dati esistono in tre stati: A riposo, in transito e nel calcolo. Una parte importante di qualsiasi servizio di inferenza ai dovrebbe essere la protezione dei dati dalle minacce durante l'intero processo. La protezione dei dati durante le deduzione è fondamentale perché il processo può esporre informazioni private sui clienti esterni e sull'azienda che fornisce il servizio di deduzione. Protopia ai è una soluzione software-only non invadente per deduzione ai riservata nel mercato odierno. Con Protopia, l'ai viene alimentata solo le informazioni trasformate nei record di dati che sono essenziali per eseguire l'attività di ai/ML a portata di mano e niente di più. Questa trasformazione stocastica non è una forma di mascheramento e si basa sul cambiamento matematico della rappresentazione dei dati utilizzando il rumore curato.</block>
  <block id="945691f1b395ce7af4d5e818b4e62b9b" category="paragraph">I sistemi storage NetApp con funzionalità ONTAP offrono le stesse performance o migliori dello storage SSD locale e, in combinazione con il toolkit NetApp DataOps, offrono i seguenti vantaggi a data scientist, data engineer, sviluppatori ai/ML e decision maker IT aziendali o aziendali:</block>
  <block id="2d1d64cb5768a8ce2a6d6bda322d2ecd" category="list-text">Protezione dei dati di livello Enterprise e governance dei dati per disaster recovery, business continuity e requisiti normativi.</block>
  <block id="58b8e67477c25a96d3b430f4ee8d75cf" category="list-text">Invocazione semplificata delle operazioni di gestione dei dati; copie Snapshot delle aree di lavoro dei data scientist per il backup e la tracciabilità dal NetApp DataOps Toolkit nei notebook Jupyter.</block>
  <block id="57e858ddb0a3e1c340cfe4ba7d5c3a14" category="paragraph">La soluzione NetApp e Protopia offre un'architettura scalabile e flessibile, ideale per le implementazioni di inferenza ai di livello Enterprise. Consente la protezione dei dati e fornisce privacy per le informazioni sensibili, laddove i requisiti di inferenza ai confidenziali possono essere soddisfatti con pratiche ai responsabili sia nelle implementazioni on-premise che nel cloud ibrido.</block>
  <block id="6073423c521e84b849e3b84fa1cc380c" category="inline-link-macro">Pagina successiva: Dove trovare ulteriori informazioni, riconoscimenti e cronologia delle versioni.</block>
  <block id="9eebc409a853e8c97008be61e4a0b83a" category="paragraph"><block ref="9eebc409a853e8c97008be61e4a0b83a" category="inline-link-macro-rx"></block></block>
  <block id="431db7b0dc79bb29f07c20c6060c3338" category="summary">In questa sezione sono elencati i notebook Jupyter e altre risorse utili per questa soluzione.</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="doc">Video e demo</block>
  <block id="eeb22c31d24f52a9b8225da48c32dd15" category="inline-link-macro">Precedente: Risultati della convalida.</block>
  <block id="234bbb7420397102b6a782bcaafff71a" category="paragraph"><block ref="234bbb7420397102b6a782bcaafff71a" category="inline-link-macro-rx"></block></block>
  <block id="4b8db041d93aa27fd0cc94a261e224ca" category="inline-link-macro">"Support-Center-Sentiment-Analysis-pipeline.ipynb"</block>
  <block id="4e336784d7218f9fd7024470cba6b522" category="inline-link">"Support-Center-Model-Transfer-Learning-and-fine-Tuning.ipynb"</block>
  <block id="46e3dcdd2c6c30a1d9fcf40d37f0deb3" category="paragraph">Esistono due notebook che contengono la pipeline di analisi del sentimento:<block ref="8ed620ac9482ce00db4c0f6de7250148" category="inline-link-rx"></block> e. <block ref="ff8619e3bd3fbeea07c38337a7b773f7" category="inline-link-macro-rx"></block>. Insieme, questi notebook dimostrano come sviluppare una pipeline per acquisire i dati del centro di supporto ed estrarre sentimenti da ogni frase utilizzando modelli di deep learning all'avanguardia e ottimizzati sui dati dell'utente.</block>
  <block id="fa8c0b2056c13341c1455ad44cc91889" category="section-title">Support Center - Sentiment Analysis Pipeline.ipynb</block>
  <block id="6b3450c2b921c398bbf90a1aee0b016c" category="paragraph">Questo notebook contiene la pipeline Inference RIVA per l'acquisizione di audio, la conversione in testo e l'estrazione di sentimenti da utilizzare in una dashboard esterna. I set di dati vengono scaricati ed elaborati automaticamente, se non è già stato fatto. La prima sezione del notebook è Speech-to-Text, che gestisce la conversione dei file audio in testo. Segue la sezione analisi del sentimento che estrae i sentimenti per ciascuna frase di testo e visualizza i risultati in un formato simile alla dashboard proposta.</block>
  <block id="63abda3d2c420172da9a3a20c7f64dda" category="admonition">Questo notebook deve essere eseguito prima del training e della messa a punto del modello, in quanto il set di dati MP3 deve essere scaricato e convertito nel formato corretto.</block>
  <block id="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="paragraph"><block ref="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="295c2feb943bbe2efca238849828084e" category="section-title">Support Center - Model Training e fine-Tuning.ipynb</block>
  <block id="6efbeb8cfc7e387edbf91bad41170349" category="paragraph">L'ambiente virtuale TAO Toolkit deve essere configurato prima di eseguire il notebook (per istruzioni sull'installazione, consultare la sezione relativa al toolkit TAO nella Panoramica dei comandi).</block>
  <block id="a9d805c9ddfdf62e60632a9754e29404" category="paragraph">Questo notebook si affida al toolkit TAO per mettere a punto modelli di apprendimento approfondito sui dati dei clienti. Come per il notebook precedente, questo è separato in due sezioni per i componenti Speech-to-Text e analisi del sentimento. Ogni sezione passa attraverso l'elaborazione dei dati, la formazione sui modelli e la messa a punto, la valutazione dei risultati e l'esportazione dei modelli. Infine, è disponibile una sezione finale per l'implementazione di entrambi i modelli ottimizzati per L'utilizzo in RIVA.</block>
  <block id="b40454c57dd60f999f3243514cd90ede" category="paragraph"><block ref="b40454c57dd60f999f3243514cd90ede" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f89bf51287609a0c0cf7563b31265c06" category="paragraph"><block ref="f89bf51287609a0c0cf7563b31265c06" category="inline-link-macro-rx"></block></block>
  <block id="cff4cbb413623685c446a2632974cf62" category="summary">Questa pagina confronta il tempo di training del modello utilizzando i Panda convenzionali rispetto a quello di Dask. Per Pandas, abbiamo caricato una quantità inferiore di dati a causa della natura del tempo di elaborazione più lento per evitare l'overflow della memoria. Pertanto, abbiamo interpolato i risultati per offrire un confronto equo.</block>
  <block id="014020acc8f97c1da58961d44b6301eb" category="doc">Confronto dei tempi di training</block>
  <block id="76c5145913d13d6c3105c4265a78047e" category="inline-link-macro">Precedente: Monitorate la Task utilizzando la dashboard nativa dei Task Streams.</block>
  <block id="a871e4d194e2df9c65b061a5fc7cb154" category="paragraph"><block ref="a871e4d194e2df9c65b061a5fc7cb154" category="inline-link-macro-rx"></block></block>
  <block id="c8ed0bb49061765f5f30ba006ea7c5c0" category="paragraph">In questa sezione viene confrontato il tempo di training del modello utilizzando i Panda convenzionali rispetto a quello di Dask. Per Pandas, abbiamo caricato una quantità inferiore di dati a causa della natura del tempo di elaborazione più lento per evitare l'overflow della memoria. Pertanto, abbiamo interpolato i risultati per offrire un confronto equo.</block>
  <block id="5b5214524edbd74fb721da08e61c8a41" category="paragraph">La tabella seguente mostra il confronto dei tempi di training raw quando i dati utilizzati per il modello di foresta casuale Pandas sono significativamente inferiori (50 milioni di righe su 20 miliardi al giorno 15 del set di dati). Questo esempio utilizza solo meno del 0.25% di tutti i dati disponibili. Mentre per Dask-cuML abbiamo addestrato il modello di foresta casuale su tutti i 20 miliardi di righe disponibili. I due approcci hanno consentito di ottenere tempi di formazione comparabili.</block>
  <block id="40a68b5da4b9b224764558bb02ecd028" category="cell">Approccio</block>
  <block id="0e90ab0d7d04d2a878961f8d40071c83" category="cell">Tempo di training</block>
  <block id="24cc88af022e13431f8005b38f74e0fd" category="cell">Scikit-Learn: Utilizzando solo 50M righe nel giorno 15 come dati di training</block>
  <block id="26e394f0b8009246698f4844db682015" category="cell">47 minuti e 21 secondi</block>
  <block id="ed536b2798ed9f16a79fb8f772601548" category="cell">RAPIDS-Dask: Utilizzo di tutte le 20B righe del giorno 15 come dati di training</block>
  <block id="8809f6d1a4b5cbd872b52f83e378e527" category="cell">1 ora, 12 minuti e 11 secondi</block>
  <block id="57093fade268287629c2720356ecac57" category="paragraph">Se si interpolano i risultati dei tempi di training in modo lineare, come mostrato nella tabella seguente, si ha un vantaggio significativo nell'utilizzo della formazione distribuita con Dask. L'approccio convenzionale Pandas scikit-Learn richiede 13 giorni per elaborare e formare 45 GB di dati per un singolo giorno di log click, mentre L'approccio RAPIDS-Dask elabora la stessa quantità di dati 262.39 volte più velocemente.</block>
  <block id="36ebc33745cb5ac06238c615c8aaebdc" category="cell">Scikit-Learn: Utilizzando tutte le 20B righe del giorno 15 come dati di training</block>
  <block id="b2ab615236e8c7812b0ab7dff59c552f" category="cell">13 giorni, 3 ore, 40 minuti e 11 secondi</block>
  <block id="0d7cda3e89555f27bf26cf0c0c4f4fed" category="paragraph">Nella tabella precedente, è possibile osservare che, utilizzando RAPIDS con Dask per distribuire l'elaborazione dei dati e modellare la formazione su più istanze GPU, il tempo di esecuzione è significativamente più breve rispetto all'elaborazione convenzionale di Pandas DataFrame con il training del modello scikit-Learn. Questo framework consente la scalabilità verticale e orizzontale nel cloud e on-premise in un cluster multi-GPU a più nodi.</block>
  <block id="fbd52cffa97d6ec5e0230516fc61f14c" category="inline-link-macro">Segue: Monitora Dask e RAPIDE con Prometheus e Grafana.</block>
  <block id="78117011d88a8971f2eadbeee6ac6474" category="paragraph"><block ref="78117011d88a8971f2eadbeee6ac6474" category="inline-link-macro-rx"></block></block>
  <block id="aa364e0963e38930007df2b60bdba067" category="doc">Salvataggio dei dati in un PersistentVolume con provisioning Trident</block>
  <block id="ef1fb51957f2aa894de5476a9a0112a2" category="paragraph">NetApp Trident è un progetto open source completamente supportato, progettato per aiutarti a soddisfare le sofisticate esigenze di persistenza delle tue applicazioni containerizzate. È possibile leggere e scrivere i dati su un volume di prestazioni (PV) Kubernetes con provisioning Trident, con il vantaggio aggiunto di tiering dei dati, crittografia, tecnologia Snapshot NetApp, conformità e performance elevate offerte dal software di gestione dei dati NetApp ONTAP.</block>
  <block id="a821f368daf439d909bfed3c8e95d4b9" category="section-title">Riutilizzo dei PVC in uno spazio dei nomi esistente</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link">Documentazione di NetApp Trident</block>
  <block id="15040fc521e7fa5e8ef42694ca89e53d" category="paragraph">Per i progetti ai più grandi, potrebbe essere più efficiente per diversi container leggere e scrivere i dati sullo stesso PV Kubernetes. Per riutilizzare un PVC (Persistent Volume Claim) Kubernetes, l'utente deve aver già creato un PVC. Vedere<block ref="5b6274adc29653ed1820027957bdb4e2" category="inline-link-rx"></block> Per informazioni dettagliate sulla creazione di un PVC. Ecco un esempio di riutilizzo di un PVC esistente:</block>
  <block id="743520c366f0d11ca817811dda85fcf1" category="paragraph">Eseguire il seguente comando per visualizzare lo stato del lavoro<block ref="0af7ab68caa77febc818c6ac2cfdbce2" prefix=" " category="inline-code"></block> per il progetto<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block>:</block>
  <block id="7d4c508442c775f946e3d9318b75b1a0" category="paragraph">Dovrebbe essere montato PV /tmp/pvc1mount su<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block> lavoro<block ref="0af7ab68caa77febc818c6ac2cfdbce2" prefix=" " category="inline-code"></block>. In questo modo, più container possono leggere dallo stesso volume, il che è utile quando ci sono più modelli concorrenti in fase di sviluppo o in produzione. Gli scienziati dei dati possono creare un insieme di modelli e quindi combinare i risultati delle previsioni con il voto a maggioranza o altre tecniche.</block>
  <block id="dae81aa45b8ce281aabbd1402afe277b" category="paragraph">Per accedere alla shell container, utilizzare quanto segue:</block>
  <block id="bc63da8fa87210da818596598e359427" category="paragraph">È quindi possibile controllare il volume montato e accedere ai dati all'interno del container.</block>
  <block id="fc180b17e3fccb2beb46854f71d31406" category="paragraph">Questa funzionalità di riutilizzo dei PVC funziona con i volumi NetApp FlexVol e NetApp ONTAP FlexGroup, consentendo ai data engineer di utilizzare opzioni di gestione dei dati più flessibili e solide per sfruttare il data fabric basato su NetApp.</block>
  <block id="2e203cb5454e63a32bcdb87dc9cb77ad" category="paragraph"><block ref="2e203cb5454e63a32bcdb87dc9cb77ad" category="inline-link-macro-rx"></block></block>
  <block id="96f5c57f6fea73d6692c5f8c2703e9b9" category="doc">NVA-1150-DESIGN: Guida alla progettazione dei sistemi Quantum StorNext con NetApp e-Series</block>
  <block id="5ee668b979e736471a8d46609abdc49b" category="paragraph">Questo documento fornisce informazioni dettagliate su come progettare una soluzione di file system parallelo StorNext con i sistemi storage NetApp e-Series. Questa soluzione copre l'array all-flash NetApp EF280, l'array NVMe all-flash NetApp EF300, l'array NVMe all-flash EF600 e il sistema ibrido NetApp E5760. Offre una caratterizzazione delle performance basata sul benchmark Frametest, uno strumento ampiamente utilizzato per i test nel settore dei media e dell'intrattenimento.</block>
  <block id="4f8b12df588cb1e82eb6d578f26c6c62" category="paragraph"><block ref="4f8b12df588cb1e82eb6d578f26c6c62" category="inline-link-macro-rx"></block></block>
  <block id="e88a70d67e9de42d391fd019f2d06484" category="summary">Per ulteriori informazioni sulle informazioni descritte in questo documento, consultare i seguenti documenti e siti Web.</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="doc">Ulteriori informazioni</block>
  <block id="b49efd5b259d6a3bceda1ebb8e34064a" category="list-text">Dataset: TuSimple</block>
  <block id="61554b11b65c50bf7a094a86d699c8d5" category="inline-link"><block ref="61554b11b65c50bf7a094a86d699c8d5" category="inline-link-rx"></block></block>
  <block id="b150fd9c1d7740c871626031a398c8a3" category="paragraph"><block ref="b150fd9c1d7740c871626031a398c8a3" category="inline-link-rx"></block></block>
  <block id="a3a3504f7b11916e352125a598e15797" category="list-text">Deep Learning Network Architecture: Rete neurale spaziale convoluzionale</block>
  <block id="6467a460cb421335f9f5b0523c38c9a6" category="inline-link"><block ref="6467a460cb421335f9f5b0523c38c9a6" category="inline-link-rx"></block></block>
  <block id="35527148b08f99f1d85797af833430dc" category="paragraph"><block ref="35527148b08f99f1d85797af833430dc" category="inline-link-rx"></block></block>
  <block id="cc1881adebe7ddf5b873966741a32ef1" category="list-text">Framework distribuito per il deep learning: Horovod</block>
  <block id="732f85d0d5eaa9222831dd5290518ff2" category="inline-link"><block ref="732f85d0d5eaa9222831dd5290518ff2" category="inline-link-rx"></block></block>
  <block id="655c281079d0281fcf4b8f2f08634c16" category="paragraph"><block ref="655c281079d0281fcf4b8f2f08634c16" category="inline-link-rx"></block></block>
  <block id="934b1fbd011b584c4878284f454f812e" category="list-text">ESEGUI: Soluzione di orchestrazione dei container ai: ESEGUI: Introduzione al prodotto ai</block>
  <block id="64b899832bfcad18bb426fb355a0d03b" category="inline-link"><block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="b78ec84f003a4d277e318031a163e191" category="paragraph"><block ref="b78ec84f003a4d277e318031a163e191" category="inline-link-rx"></block></block>
  <block id="275dbaaa3169640f82917075918df905" category="list-text">ESEGUI: Documentazione di installazione ai</block>
  <block id="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link"><block ref="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link-rx"></block></block>
  <block id="517046a8acf2e7fa61798debc5b6e25e" category="inline-link"><block ref="517046a8acf2e7fa61798debc5b6e25e" category="inline-link-rx"></block></block>
  <block id="b8b2e04f115b148d49a8cb477ed86af9" category="paragraph"><block ref="f03e58e4917966d9b82995c8ce69643b" category="inline-link-rx"></block><block ref="3530112fad5ba376549c9e0750df83f3" category="inline-link-rx"></block></block>
  <block id="8787c0bfc5af7ce34db56c9a5739f788" category="list-text">Invio di job in ESECUZIONE: Ai CLI</block>
  <block id="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link"><block ref="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link-rx"></block></block>
  <block id="ca4ef6cf830a9de78ea71279d0d5417c" category="paragraph"><block ref="ca4ef6cf830a9de78ea71279d0d5417c" category="inline-link-rx"></block></block>
  <block id="984fd97f526f8afe9d2472b0894b84c2" category="inline-link"><block ref="984fd97f526f8afe9d2472b0894b84c2" category="inline-link-rx"></block></block>
  <block id="65640a241681656a4410cd7184278c9b" category="paragraph"><block ref="65640a241681656a4410cd7184278c9b" category="inline-link-rx"></block></block>
  <block id="33a756969a35b0a9029bf2a2c10e6d67" category="list-text">Risorse cloud di Azure: Azure NetApp Files</block>
  <block id="99ac98f589f6b551211f31e86cb9a212" category="inline-link"><block ref="99ac98f589f6b551211f31e86cb9a212" category="inline-link-rx"></block></block>
  <block id="3085d4407b575d4a8938814c7db17d92" category="paragraph"><block ref="3085d4407b575d4a8938814c7db17d92" category="inline-link-rx"></block></block>
  <block id="21d0acc34f6416d6ebd8074617c57439" category="inline-link"><block ref="21d0acc34f6416d6ebd8074617c57439" category="inline-link-rx"></block></block>
  <block id="91c4b230ded9b13564b447ba71304aeb" category="paragraph"><block ref="91c4b230ded9b13564b447ba71304aeb" category="inline-link-rx"></block></block>
  <block id="d9d650693b25d0540fbb606b1d1fbe4e" category="list-text">SKU di Azure VM</block>
  <block id="08318cbecd61665ab1824d118c1029a5" category="inline-link"><block ref="08318cbecd61665ab1824d118c1029a5" category="inline-link-rx"></block></block>
  <block id="3e05fd8f7e2e0ac6116dd746a8823eaa" category="paragraph"><block ref="3e05fd8f7e2e0ac6116dd746a8823eaa" category="inline-link-rx"></block></block>
  <block id="b9a1a7c8f2194407b24183f7826d2e44" category="list-text">Macchine virtuali Azure con SKU GPU</block>
  <block id="6046df9266bb79e1d99f9c232c1835e3" category="inline-link"><block ref="6046df9266bb79e1d99f9c232c1835e3" category="inline-link-rx"></block></block>
  <block id="d0bf246853f6f35070f6a8231d468c87" category="paragraph"><block ref="d0bf246853f6f35070f6a8231d468c87" category="inline-link-rx"></block></block>
  <block id="43a545df8285ba2aba289a52824f250d" category="inline-link"><block ref="43a545df8285ba2aba289a52824f250d" category="inline-link-rx"></block></block>
  <block id="944823ac69152177e369bd5d9a61a02f" category="paragraph"><block ref="944823ac69152177e369bd5d9a61a02f" category="inline-link-rx"></block></block>
  <block id="a9359a0f51034e1b1972f7690fe03f71" category="list-text">Data fabric basato su NetApp</block>
  <block id="781262103885a96ffc9275431a7ef132" category="inline-link"><block ref="781262103885a96ffc9275431a7ef132" category="inline-link-rx"></block></block>
  <block id="93e35e3e458c1d81846aa83c346e240e" category="paragraph"><block ref="93e35e3e458c1d81846aa83c346e240e" category="inline-link-rx"></block></block>
  <block id="ecb81ab37e1d2a7ed6dfce3807622e3d" category="summary">Questa sezione fornisce dettagli sulla configurazione della piattaforma per l'esecuzione di training distribuiti di rilevamento di corsia su larga scala utilizzando L'orchestrator DI RUN ai.</block>
  <block id="0714a752696f8feed939bbf52a6214f7" category="doc">Lane Detection – formazione distribuita con RUN:ai</block>
  <block id="dbf10b854b8b7fc90297279e7ad0f745" category="paragraph">Questa sezione fornisce dettagli sulla configurazione della piattaforma per l'esecuzione del training distribuito di rilevamento della corsia su larga scala utilizzando L'ORCHESTRATOR DI intelligenza artificiale. Discutiamo dell'installazione di tutti gli elementi della soluzione e dell'esecuzione del lavoro di training distribuito sulla piattaforma suddetta. IL controllo della versione ML viene completato utilizzando NetApp SnapshotTM collegato a ESPERIMENTI DI RUN: Ai per ottenere la riproducibilità dei dati e dei modelli. IL controllo delle versioni DI ML svolge un ruolo cruciale nel monitoraggio dei modelli, nella condivisione del lavoro tra i membri del team, nella riproducibilità dei risultati, nel passaggio in produzione delle nuove versioni dei modelli e nella provenienza dei dati. NetApp ML version control (Snapshot) è in grado di acquisire versioni point-in-time dei dati, dei modelli addestrati e dei registri associati a ciascun esperimento. Grazie al supporto API completo, è facile da integrare con LA piattaforma DI ESECUZIONE: Ai; devi solo attivare un evento in base allo stato del training. Inoltre, è necessario acquisire lo stato dell'intero esperimento senza modificare nulla nel codice o nei container eseguiti su Kubernetes (K8s).</block>
  <block id="25d19977e35c6d286c5b051982ae3f3c" category="paragraph">Infine, questo report tecnico si conclude con la valutazione delle performance su più nodi abilitati alla GPU in AKS.</block>
  <block id="1987a7039dccb848f2e8ce693ba3faff" category="section-title">Training distribuito per il caso di utilizzo del rilevamento di corsia utilizzando il set di dati TuSimple</block>
  <block id="f75a7cb3d80e7be148c1ce86a4347011" category="paragraph">In questo report tecnico, viene eseguito un training distribuito sul set di dati TuSimple per il rilevamento della corsia. Horovod viene utilizzato nel codice di training per condurre training distribuiti su più nodi GPU contemporaneamente nel cluster Kubernetes tramite AKS. Il codice viene confezionato come immagini container per il download e l'elaborazione dei dati TuSimple. I dati elaborati vengono memorizzati su volumi persistenti allocati dal plug-in di NetApp Trident. Per il training, viene creata un'altra immagine container che utilizza i dati memorizzati nei volumi persistenti creati durante il download dei dati.</block>
  <block id="58b4798157820b4e4415d8136cf60fe9" category="paragraph">Per inviare i dati e il lavoro di training, utilizza RUN: Ai per orchestrare l'allocazione e la gestione delle risorse. ESEGUI: L'ai consente di eseguire operazioni MPI (message Passing Interface) necessarie per Horovod. Questo layout consente a più nodi GPU di comunicare tra loro per aggiornare i pesi di training dopo ogni mini batch di training. Consente inoltre di monitorare la formazione attraverso l'interfaccia utente e la CLI, semplificando il monitoraggio dei progressi degli esperimenti.</block>
  <block id="ecbeff08f5ec15c6952355b518d4ae02" category="paragraph">NetApp Snapshot è integrato nel codice di training e acquisisce lo stato dei dati e il modello formativo per ogni esperimento. Questa funzionalità consente di tenere traccia della versione dei dati e del codice utilizzati e del modello di formazione associato generato.</block>
  <block id="63addc90b28c066bd235c900fed65314" category="section-title">Installazione e configurazione di AKS</block>
  <block id="50f7d8213ee52350926ec407074e68f1" category="inline-link">Creare un cluster AKS</block>
  <block id="55b295c729173e8c0c745bb036b03270" category="paragraph">Per la configurazione e l'installazione del cluster AKS, visitare il sito Web all'indirizzo<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block>. Quindi, attenersi alla seguente serie di passaggi:</block>
  <block id="8f9d847fad9782b080de76b0161b1c45" category="list-text">Quando si seleziona il tipo di nodi (che si tratti di nodi di sistema (CPU) o di lavoro (GPU)), selezionare quanto segue:</block>
  <block id="957d1a35f975177c3fd161490f3e2d83" category="list-text">Aggiungere il nodo di sistema primario denominato<block ref="917718fb2e3dcf94043ea14d44580bc2" prefix=" " category="inline-code"></block> su<block ref="2ec023527b0bfb6c720d8dd19493ad0d" prefix=" " category="inline-code"></block> dimensione. Utilizzare i tre nodi predefiniti.</block>
  <block id="8853a13db2e2a03cb5b2f1186fbcd0a6" category="list-text">Aggiungi nodo di lavoro<block ref="2e7ef525fb562d2f68920b0bf6f58b81" prefix=" " category="inline-code"></block> con<block ref="801b9db365bdc8cd72301ec3fd4ed2ff" prefix=" " category="inline-code"></block> dimensioni del pool. Utilizzare almeno tre nodi per i nodi GPU.</block>
  <block id="5085043d6dea89934a2e516fc46f891a" category="paragraph"><block ref="5085043d6dea89934a2e516fc46f891a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="633b880bff72a9f1c1114df31dec55bf" category="admonition">L'implementazione richiede 10 minuti.</block>
  <block id="f55bb34768c41f91318fb57b85c1def9" category="inline-link">Strumenti di installazione</block>
  <block id="6369fc9d36c9d56cbebefdeccda5fbff" category="list-text">Al termine dell'implementazione, fare clic su Connect to Cluster (Connetti al cluster). Per connettersi al cluster AKS appena creato, installare il tool della riga di comando Kubernetes dall'ambiente locale (laptop/PC). Visitare il sito<block ref="bcd577f96ff7023ec6fd5c904f040896" category="inline-link-rx"></block> Per installarlo in base al sistema operativo in uso.</block>
  <block id="811c47e56617f97db3579bc32a9085c9" category="inline-link">Installare Azure CLI nell'ambiente locale</block>
  <block id="ea5d45554a3e9cb9cbc0ddea4c228b28" category="list-text"><block ref="2db79c584144175dd0bb69b6c7045fc9" category="inline-link-rx"></block>.</block>
  <block id="825ca3bff78c42ec87920dfbce105fae" category="list-text">Per accedere al cluster AKS dal terminale, immettere<block ref="f7ac81b64d50d201c173fb8dcf70f266" prefix=" " category="inline-code"></block> e inserire le credenziali.</block>
  <block id="3394029cd334ed00686c86c088d73c24" category="list-text">Eseguire i due comandi seguenti:</block>
  <block id="193937b265ce655417f00a79334d3937" category="list-text">Immettere questo comando nella riga di comando Azure:</block>
  <block id="cbf78d8bb0be543834c56e61560773b0" category="admonition">Se tutti e sei i nodi sono attivi e in esecuzione, il cluster AKS è pronto e connesso all'ambiente locale.</block>
  <block id="e8085ec7505cfe6f3cfbe2c2628386dc" category="paragraph"><block ref="e8085ec7505cfe6f3cfbe2c2628386dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="450cf7e7f8262fdaa3454c2e11aad687" category="paragraph">Per creare una subnet delegata per Azure NetApp Files, seguire questa serie di passaggi:</block>
  <block id="0ca30ab1eb5e523356720465eb7439c8" category="list-text">Accedere alle reti virtuali all'interno del portale Azure. Trova la tua rete virtuale appena creata. Dovrebbe avere un prefisso come aks-vnet, come mostrato qui. Fare clic sul nome della rete virtuale.</block>
  <block id="ce0c628aca3577055043c7f8364600d9" category="paragraph"><block ref="ce0c628aca3577055043c7f8364600d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="25157709e5a253560f5ec68b8262563c" category="list-text">Fare clic su subnet e selezionare +Subnet nella barra degli strumenti superiore.</block>
  <block id="d9bf5876b80dbf558587f06630e3915c" category="paragraph"><block ref="d9bf5876b80dbf558587f06630e3915c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a07ef5dbc59d5ba150de82d519fb4f8" category="list-text">Specificare un nome per la subnet, ad esempio<block ref="d2acea3c674306459e768a41444551ba" prefix=" " category="inline-code"></block> E sotto l'intestazione Subnet Delegation (delega subnet), selezionare Microsoft.NetApp/volumes. Non cambiare altro. Fare clic su OK.</block>
  <block id="a8ccea52e17d54aea1295a99ab4d5c2e" category="paragraph"><block ref="a8ccea52e17d54aea1295a99ab4d5c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d182b62071ada1a29e4f9c26487c1121" category="paragraph">I volumi Azure NetApp Files vengono allocati nel cluster di applicazioni e vengono utilizzati come dichiarazioni di volumi persistenti (PVC) in Kubernetes. A sua volta, questa allocazione ci offre la flessibilità di mappare i volumi a diversi servizi, sia che si trattino di notebook Jupyter, funzioni senza server e così via</block>
  <block id="a74ff852d3b3b8447b0306018a76c4f1" category="paragraph">Gli utenti dei servizi possono consumare lo storage dalla piattaforma in molti modi. I principali vantaggi di Azure NetApp Files sono:</block>
  <block id="a7c5a83cc4ccf14374e496bcbb4363f5" category="list-text">Offre agli utenti la possibilità di utilizzare le snapshot.</block>
  <block id="ea437fe76a4bba5bf335daccbbd24b50" category="list-text">Consente agli utenti di memorizzare grandi quantità di dati su volumi Azure NetApp Files.</block>
  <block id="cedebf66380d43f58c07dfb1d4d686a6" category="list-text">Ottenere i vantaggi in termini di performance dei volumi Azure NetApp Files quando si eseguono i modelli su grandi set di file.</block>
  <block id="75ab13308585f62c3cd57a246d0e0c64" category="section-title">Configurazione di Azure NetApp Files</block>
  <block id="8c060d9ae24c7bc4518e54cd5ed13098" category="inline-link">QuickStart: Configurazione di Azure NetApp Files e creazione di un volume NFS</block>
  <block id="fd01c32c80d631ed4bebff78fa83b23e" category="paragraph">Per completare la configurazione di Azure NetApp Files, è necessario configurarla come descritto in<block ref="2f4e63e538c7dd311b18db058621cef8" category="inline-link-rx"></block>.</block>
  <block id="e26f032bd6f7f5636860d6b94ac84859" category="paragraph">Tuttavia, è possibile omettere la procedura per creare un volume NFS per Azure NetApp Files, poiché si creeranno volumi tramite Trident. Prima di continuare, assicurarsi di disporre di:</block>
  <block id="e953b5e281d40c5db3cc047889eec4f2" category="inline-link">Registrato per Azure NetApp Files e per il provider di risorse NetApp (tramite la shell cloud di Azure)</block>
  <block id="3b46d13fb20fe6a92456f742b5732774" category="list-text"><block ref="527fb205c939c551ed93f597562513fb" category="inline-link-rx"></block>.</block>
  <block id="d0652e942d3d4b469179248d72ccaa5c" category="inline-link">Creato un account in Azure NetApp Files</block>
  <block id="82a51bbfec23ca7366c216813caeacc8" category="list-text"><block ref="874637dbfce24ba5a63adadd91968dc9" category="inline-link-rx"></block>.</block>
  <block id="02209b9e3a221b39bf0ce87641e7afc6" category="inline-link">Impostare un pool di capacità</block>
  <block id="7b4cb99ad8c150ff95b1a65d0f0524cc" category="list-text"><block ref="0fa33cef09dfad4c8795f42dd9dd5248" category="inline-link-rx"></block> (Minimo 4 TiB Standard o Premium a seconda delle esigenze).</block>
  <block id="1c7c9057bf4f7aee40c5a117c160c0fd" category="section-title">Peering della rete virtuale AKS e della rete virtuale Azure NetApp Files</block>
  <block id="998069ab494c49ade2cc77591c02d9fa" category="paragraph">Quindi, eseguire il peer della rete virtuale AKS con Azure NetApp Files VNET seguendo questa procedura:</block>
  <block id="bf12dce8dcc6febfeddec5ed2570e7d7" category="list-text">Nella casella di ricerca nella parte superiore del portale Azure, digitare virtual networks (reti virtuali).</block>
  <block id="3f961f79effdf0aa37042e1733ee53ef" category="list-text">Fare clic su VNET aks- vnet-name, quindi immettere Peerings nel campo di ricerca.</block>
  <block id="0249aa06ef3e10e8754106189b542be4" category="list-text">Fare clic su +Add (Aggiungi) e inserire le informazioni fornite nella tabella seguente:</block>
  <block id="6f16a5f8ff5d75ab84c018adacdfcbb7" category="cell">Campo</block>
  <block id="88645c17102d75583e93db9aa716b012" category="cell">Valore o descrizione</block>
  <block id="f80824cb9ab9f704542dec0c71c5f38b" category="cell">Nome del collegamento peering</block>
  <block id="5d43607a5a0ebb50f3ea9348485daa15" category="cell">aks-vnet-name_to_an</block>
  <block id="62912b52e584278e26870d9e5092e723" category="cell">SubscriptionID</block>
  <block id="7d97336a164d9ce685e88a121141b189" category="cell">Iscrizione a Azure NetApp Files VNET a cui stai eseguendo il peering</block>
  <block id="82a60e720574cf435dda0a03976e8323" category="cell">Partner di peering VNET</block>
  <block id="d2ade9376eb8b87db099330d20c4f180" category="cell">Azure NetApp Files VNET</block>
  <block id="5b92ad691782a9e4cc701e479c90997f" category="admonition">Lasciare tutte le sezioni non contrassegnate come predefinite</block>
  <block id="0e5883528161213f3edc02dd718e1693" category="list-text">Fare clic su ADD (AGGIUNGI) o su OK per aggiungere il peering alla rete virtuale.</block>
  <block id="12eee9bf8836d675f26602260016f7da" category="inline-link">Creare, modificare o eliminare un peering di rete virtuale</block>
  <block id="fa1f15d2aebd0592f338ea9f49e06377" category="paragraph">Per ulteriori informazioni, visitare il sito<block ref="610fa6db13a2eefe4a391b16732fbbf0" category="inline-link-rx"></block>.</block>
  <block id="91d2f55da5f23abbcf1a0656897d101b" category="paragraph">Trident è un progetto open-source che NetApp gestisce per lo storage persistente dei container delle applicazioni. Trident è stato implementato come un provisioning controller esterno che viene eseguito come pod stesso, monitorando i volumi e automatizzando completamente il processo di provisioning.</block>
  <block id="4088b2a65b2a3182209479dced5e78c5" category="paragraph">NetApp Trident consente un'integrazione perfetta con K8s creando e allegando volumi persistenti per l'archiviazione di set di dati di training e modelli di training. Questa funzionalità semplifica l'utilizzo di K8 da parte di data scientist e data engineer senza il fastidio di memorizzare e gestire manualmente i set di dati. Trident elimina inoltre la necessità per i data scientist di imparare a gestire nuove piattaforme dati, poiché integra le attività correlate alla gestione dei dati attraverso l'integrazione API logica.</block>
  <block id="77dc68d199719a4b8f5eba742ecb7056" category="paragraph">Per installare il software Trident, attenersi alla seguente procedura:</block>
  <block id="2f2e9ef9449e2f31756b1d3683a207b3" category="inline-link">Installare prima il timone</block>
  <block id="089f0e488d4e2b1a4b02d6d6b638c9d3" category="list-text"><block ref="b3c10ddb3b7f0e3e121ce123f60cc497" category="inline-link-rx"></block>.</block>
  <block id="e12559703ec38e80de7b94fecc84a043" category="list-text">Scaricare ed estrarre il programma di installazione di Trident 21.01.1.</block>
  <block id="8ad5650fb94bff45b328581838d836fd" category="list-text">Copia<block ref="c67fd1b99934afa248dfeb285a9a4191" prefix=" " category="inline-code"></block> a una directory del sistema<block ref="86657e3985b8aeae39f3d9136b5f3e58" prefix=" " category="inline-code"></block></block>
  <block id="6da8d48465deb31425595b33a9172acf" category="list-text">Installare Trident sul cluster K8s con Helm:</block>
  <block id="7b09729551ddb1a7445f559eb1186978" category="list-text">Cambiare la directory in Helm directory.</block>
  <block id="cea04f1ceb2ba2472ec50de3a03a689c" category="list-text">Verificare lo stato dei pod Trident nel modo consueto di K8s:</block>
  <block id="6ac3c5fc780260af91dd10523188e6fd" category="list-text">Se tutti i pod sono in funzione, Trident è installato e si è bene andare avanti.</block>
  <block id="7862dabe13bf66a99fcfd3a6b1af4d94" category="section-title">Configurare il back-end Azure NetApp Files e la classe di storage</block>
  <block id="7e98dce86779e84763b71398d851f7bb" category="paragraph">Per configurare il back-end Azure NetApp Files e la classe di storage, attenersi alla seguente procedura:</block>
  <block id="dadab4bead78e450739c0f56bad40cda" category="list-text">Tornare alla home directory.</block>
  <block id="65b8f7db2e9a3793e76d2ec3787f71fa" category="inline-link">repository di progetto</block>
  <block id="03636accad716972f761628ea21e43f6" category="list-text">Clonare il<block ref="2b240ffa21ddbdc99d1706dee4302f7e" category="inline-link-rx"></block><block ref="2277dab02c330ef055fe72a7776587ae" prefix=" " category="inline-code"></block>.</block>
  <block id="0ea725833b806058fe7810e6be91f9c0" category="list-text">Accedere alla<block ref="fb4dc0399a722eface234e077d9b496c" prefix=" " category="inline-code"></block> directory.</block>
  <block id="c51fa2034e7d5d97ec8c31248fc18e98" category="list-text">Creare un principio di servizio Azure (il principio di servizio è il modo in cui Trident comunica con Azure per accedere alle risorse Azure NetApp Files).</block>
  <block id="203565dfd87ac32927ce5a828d45babd" category="list-text">Creare il Trident<block ref="27bac05160742a70c80c3e1db9b39988" prefix=" " category="inline-code"></block> file.</block>
  <block id="d7e47f31bf1c921dd5e28ee7e6f5cd34" category="list-text">Utilizzando l'editor di testo preferito, completare i seguenti campi della tabella riportata di seguito all'interno di<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block> file.</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">Valore</block>
  <block id="8c443e170595ba0feac007ffb92cb49a" category="cell">SubscriptionID</block>
  <block id="deb6a9aaa10be6bb24feea6a3540128c" category="cell">Il tuo ID di abbonamento Azure</block>
  <block id="bc54592d6183695b841c6d1880ec0bf8" category="cell">ID tenant</block>
  <block id="b147f00fa948b22faa89aa8044904495" category="cell">Il tuo ID tenant Azure (dall'output di az ad sp nel passaggio precedente)</block>
  <block id="93c5bebdea9c94a0740fe6fd9bb250f0" category="cell">ID cliente</block>
  <block id="5760e6800c58c7dc9ee68efdc6db38de" category="cell">Il tuo appID (dall'output di az ad sp nel passaggio precedente)</block>
  <block id="2b53761249254ce6b502f521e5cc0683" category="cell">ClientSecret</block>
  <block id="0571f76a94493cb2020d6c3b7453a367" category="cell">La tua password (dall'output di az ad sp nel passaggio precedente)</block>
  <block id="25e6b7ea847b31b4f88b60acd65052db" category="paragraph">Il file dovrebbe essere simile al seguente esempio:</block>
  <block id="49356331b94221561b7751ae1f5343a9" category="list-text">Chiedere a Trident di creare il back-end Azure NetApp Files in<block ref="47cb44be55a0dffa15dfc900a4c687be" prefix=" " category="inline-code"></block> namespace, utilizzando<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block> come il file di configurazione come segue:</block>
  <block id="bd9c5e9bd5f130a6fbdbcaeb04656652" category="list-text">Creare la classe di storage:</block>
  <block id="a9fa0a3d8bf1bce76ef654f0a047b8fe" category="list-text">Gli utenti K8 eseguono il provisioning dei volumi utilizzando PVC che specificano una classe di storage in base al nome. Chiedere a K8s di creare una classe di storage<block ref="9df91c80149f52e48e8f845cbad1b55c" prefix=" " category="inline-code"></block> Questo farà riferimento al back-end Azure NetApp Files creato nel passaggio precedente utilizzando quanto segue:</block>
  <block id="5e121b263b32950e629eaf774c12da78" category="list-text">Verificare che la classe di storage venga creata utilizzando il seguente comando:</block>
  <block id="202ed88f7ec48eda708f6c062786f474" category="paragraph"><block ref="202ed88f7ec48eda708f6c062786f474" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72611a189b0331f709788d99912a1bd7" category="section-title">Implementare e configurare i componenti di snapshot dei volumi su AKS</block>
  <block id="3ea90db69187da57e9739e033add6801" category="paragraph">Se il cluster non viene fornito con i componenti di snapshot del volume corretti, è possibile installare manualmente questi componenti eseguendo i seguenti passaggi:</block>
  <block id="c3987ca9f11aad20ef5d2ae0dd30f9cb" category="admonition">AKS 1.18.14 non dispone di Snapshot Controller preinstallato.</block>
  <block id="312e34d756f6ef39f0bd74e2f844773f" category="list-text">Installare i CRD Snapshot Beta utilizzando i seguenti comandi:</block>
  <block id="529616f838a47cade6e5fac6f879ce5a" category="list-text">Installare Snapshot Controller utilizzando i seguenti documenti di GitHub:</block>
  <block id="90a2427d3a3145723cd2a130c5372865" category="inline-link">classe di snapshot del volume</block>
  <block id="8f2838f14b6a64dd466dc23bcf7e3c01" category="list-text">Impostare K8s<block ref="9431613e59ff5cc956e408e7f55906ef" prefix=" " category="inline-code"></block>Prima di creare uno snapshot di volume<block ref="cba124de563550c68e57cf9a6641a5d1" category="inline-link-rx"></block> deve essere configurato. Creare una classe di snapshot di volume per Azure NetApp Files e utilizzarla per ottenere IL controllo delle versioni ML utilizzando la tecnologia NetApp Snapshot. Creare<block ref="0c1b563c97a31c710fb1be0e355b42e2" prefix=" " category="inline-code"></block> e impostarlo sul valore predefinito `volumesnapshotclass `come tale:</block>
  <block id="adc3a39a071327998da9cc6708ef4fe8" category="paragraph"><block ref="adc3a39a071327998da9cc6708ef4fe8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="770bec683fa99c1a917babb074d95e66" category="list-text">Verificare che la classe di copia Snapshot del volume sia stata creata utilizzando il seguente comando:</block>
  <block id="99b5a364457d91999df6ca6488b800f2" category="paragraph"><block ref="99b5a364457d91999df6ca6488b800f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d9a6cca62c9095cbae70692ef82741c" category="section-title">ESEGUI:installazione ai</block>
  <block id="d1d2b81816d977b7a9d3480a495beda5" category="paragraph">Per installare RUN:ai, attenersi alla seguente procedura:</block>
  <block id="7899a1a12ecf76a5676a6d5ddb64842f" category="inline-link">Installare IL cluster RUN:ai su AKS</block>
  <block id="54437101a8cdfe297499d517331ced60" category="list-text"><block ref="400679f1b873ae4a832f018613d486cc" category="inline-link-rx"></block>.</block>
  <block id="5f854e827ba37f66f45f8e47643e23ea" category="list-text">Accedere a app.runai.ai, fare clic su Create New Project (Crea nuovo progetto) e assegnargli il nome di rilevamento della corsia. Verrà creato uno spazio dei nomi su un cluster K8s a partire da<block ref="26ea39e1cbc12bc8c37993198043ec7c" prefix=" " category="inline-code"></block>- seguito dal nome del progetto. In questo caso, lo spazio dei nomi creato sarà runai-lane-detection.</block>
  <block id="e699d582d1b58a9a23ebd74cab11d5bc" category="paragraph"><block ref="e699d582d1b58a9a23ebd74cab11d5bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="546524b2c8ed6fd083c9286159ebd55a" category="inline-link">INSTALLARE RUN:AI CLI</block>
  <block id="f3a9807f54199fd5dbad651af2ea853a" category="list-text"><block ref="6291ffcd5a23a3d0b996bc90930ef0b3" category="inline-link-rx"></block>.</block>
  <block id="08d1d73b27232763a82ef46a413779ce" category="list-text">Sul terminale, impostare il rilevamento di corsia come UN progetto di default RUN: Ai utilizzando il seguente comando:</block>
  <block id="0ca589f93fd9565aa5fc097fd66437ae" category="paragraph"><block ref="0ca589f93fd9565aa5fc097fd66437ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cd1a85dd18a7a0b8f1d07b4240fafcf" category="list-text">Creare ClusterRole e ClusterRoleBinding per lo spazio dei nomi del progetto (ad esempio,<block ref="ff4072c643ff862f118d673b2655bd00" prefix=" " category="inline-code"></block> quindi, l'account di servizio predefinito appartenente a.<block ref="13c89f25e4bc6da9c31044eb8fddf950" prefix=" " category="inline-code"></block> lo spazio dei nomi dispone dell'autorizzazione per eseguire le operazioni<block ref="2bbdf0e0d9e8bddf5f3f89a53a8e524f" prefix=" " category="inline-code"></block> operazioni durante l'esecuzione del processo:</block>
  <block id="351495b134e625df33dfb5230d6eab7b" category="list-text">Elencare gli spazi dei nomi per controllarli<block ref="13c89f25e4bc6da9c31044eb8fddf950" prefix=" " category="inline-code"></block> esiste utilizzando questo comando:</block>
  <block id="bd546162071f28fd50f8c977ac61149e" category="paragraph">L'output dovrebbe apparire come nell'esempio seguente:</block>
  <block id="8c33c9910dfecb6260489cd05f43b275" category="paragraph"><block ref="8c33c9910dfecb6260489cd05f43b275" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f23930532ba19f8970c6dcb4b6ad778f" category="list-text">Creare ClusterRole<block ref="1eddd02c8009227e14e36951541799be" prefix=" " category="inline-code"></block> E ClusterRoleBinding<block ref="1eddd02c8009227e14e36951541799be" prefix=" " category="inline-code"></block> utilizzando i seguenti comandi:</block>
  <block id="7e3ec6f763cd8a13380162aba60c47e0" category="section-title">Scaricare ed elaborare il set di dati TuSimple come lavoro RUN:ai</block>
  <block id="c0cc307d9f63d0a096f8d6e3193cd561" category="paragraph">Il processo per scaricare ed elaborare il set di dati TuSimple come UN processo DI ESECUZIONE: Ai è facoltativo. La procedura prevede i seguenti passaggi:</block>
  <block id="52eeaf7bac6d3e2111d129a11d0bafed" category="list-text">Creare e inviare l'immagine del docker o omettere questo passaggio se si desidera utilizzare un'immagine del docker esistente (ad esempio,<block ref="c545ab6370eda2ad54aefbe9cf39084c" prefix=" " category="inline-code"></block></block>
  <block id="0d5647db76048e129c1146a822abbdd8" category="list-text">Passare alla home directory:</block>
  <block id="02c403c221afbdccdc4f7182e2eb5cb7" category="list-text">Accedere alla directory dei dati del progetto<block ref="2277dab02c330ef055fe72a7776587ae" prefix=" " category="inline-code"></block>:</block>
  <block id="eed104c2f8af7c3526ec55b8cc69dde7" category="list-text">Modificare<block ref="40be60d1fc478ce6c2eeb49003834edf" prefix=" " category="inline-code"></block> shell script e modifica il repository di docker in base al tuo. Ad esempio, sostituire<block ref="c90c81f7ef628a8969142dee6550d8ef" prefix=" " category="inline-code"></block> con il nome del repository di docker. È anche possibile modificare il nome e IL TAG dell'immagine del docker (ad esempio<block ref="d9ff85f787933e1dd61935daa84a1bdf" prefix=" " category="inline-code"></block> e.<block ref="e4c2e8edac362acab7123654b9e73432" prefix=" " category="inline-code"></block>):</block>
  <block id="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="paragraph"><block ref="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed49e04589e6c9071bbd1af307f83a0" category="list-text">Eseguire lo script per creare l'immagine del docker e inserirla nel repository del docker utilizzando i seguenti comandi:</block>
  <block id="8ebf5e70d0ed304519c7c9b525d80af1" category="list-text">Inviare il lavoro DI ESECUZIONE: Ai per scaricare, estrarre, pre-elaborare e memorizzare il set di dati di rilevamento della corsia TuSimple in un<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block>, Creata dinamicamente da NetApp Trident:</block>
  <block id="050d58b165aef32cad86839521b721b2" category="list-text">Utilizzare i seguenti comandi per inviare LA SERIOGRAFIA: Al job:</block>
  <block id="83b4fb868b7505e293871c3e5accc98c" category="list-text">Inserire le informazioni dalla tabella seguente per inviare il job RUN:ai:</block>
  <block id="e50d72d773874b2be58530daec43900c" category="cell">-name</block>
  <block id="37e9bb74490b0ac510effff5a546f11d" category="cell">Nome del lavoro</block>
  <block id="5503ed8f71ae365eb6f5e8221562a0eb" category="cell">pvc</block>
  <block id="626299ff067d1e6a178beced1631ab43" category="cell">PVC del formato [StorageClassName]:Size:ContainerMountPath nell'invio del job di cui sopra, si sta creando un PVC basato su richiesta utilizzando Trident con azurenetappfile di classe storage. La capacità del volume persistente qui è di 100 Gi ed è montata in path /mnt.</block>
  <block id="0247d7fb481075907b9eb467cfe90e3a" category="cell">-immagine</block>
  <block id="b30f1ca8b35fd6ccab829a959f414a51" category="cell">Immagine Docker da utilizzare durante la creazione del contenitore per questo lavoro</block>
  <block id="22a55ba6c8590fa98f1b3234141f2848" category="paragraph"><block ref="22a55ba6c8590fa98f1b3234141f2848" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af270e479cd849e4a9cb6d17b76585ef" category="list-text">Elencare i job RUN:ai inviati.</block>
  <block id="f740410b6ea33d3ffc740140cc23a0e2" category="paragraph"><block ref="f740410b6ea33d3ffc740140cc23a0e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51869a860c4af748ec2815d406929a17" category="list-text">Controllare i log dei lavori inoltrati.</block>
  <block id="ab353387b0e5276e03aecae4cc95d150" category="paragraph"><block ref="ab353387b0e5276e03aecae4cc95d150" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d84dd51baa0cf15db0a639dbb6d5d8ee" category="list-text">Elencare<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block> creato. Utilizzare questo<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block> comando per la formazione nella fase successiva.</block>
  <block id="cc2e05fe54a847aee415a2deb0b7f13e" category="paragraph"><block ref="cc2e05fe54a847aee415a2deb0b7f13e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b20e4749f78095f0b9adf5c3cad36f81" category="list-text">Controllare il lavoro IN ESECUZIONE: Ai UI (o.<block ref="a008ed925fe48e20407afaf702b23152" prefix=" " category="inline-code"></block>).</block>
  <block id="ced39410c19f3968638fc81e16743f32" category="paragraph"><block ref="ced39410c19f3968638fc81e16743f32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3dee54cb181d3bfde644600fb15bbac4" category="section-title">Eseguire un training di rilevamento di corsia distribuito utilizzando Horovod</block>
  <block id="645e2c981858a720c673c6a782efd9ea" category="paragraph">L'esecuzione di un training di rilevamento di corsia distribuito con Horovod è un processo facoltativo. Tuttavia, di seguito sono riportati i passaggi:</block>
  <block id="04e568eec6dda4a0cfb1fc6680509d35" category="list-text">Creare e inviare l'immagine del docker o saltare questo passaggio se si desidera utilizzare l'immagine del docker esistente (ad esempio,<block ref="ff48b891d5ff0bac7c6319fafb5cd296" prefix=" " category="inline-code"></block></block>
  <block id="b01fdc5088b4a04549ed5e7cc71f898b" category="list-text">Passare alla home directory.</block>
  <block id="14e21ef8495bc1dd543db0aebbe06c5b" category="list-text">Accedere alla directory del progetto<block ref="3154c35109c9015233233f77dfc31bc7" prefix=" " category="inline-code"></block></block>
  <block id="0a27aa824e245e7b31f5f8d990636ead" category="list-text">Modificare il<block ref="40be60d1fc478ce6c2eeb49003834edf" prefix=" " category="inline-code"></block> shell script e modifica il repository di docker in base al tuo (ad esempio, sostituire<block ref="c90c81f7ef628a8969142dee6550d8ef" prefix=" " category="inline-code"></block> con il nome del repository del docker). È anche possibile modificare il nome e IL TAG dell'immagine del docker <block ref="40797c3457645b9820c9a3f42dbea93b" prefix="(" category="inline-code"></block> e.<block ref="dfddb1ffc29acf8914bca9a640b6362a" prefix=" " category="inline-code"></block>.</block>
  <block id="c9ce95c3d4cf96d5e894e4a834754cb6" category="paragraph"><block ref="c9ce95c3d4cf96d5e894e4a834754cb6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2776d43d1e635424496622f14cfd745c" category="list-text">Eseguire lo script per creare l'immagine del docker e passare al repository del docker.</block>
  <block id="b9bcfd06c5cdfc67a00ffe8a0c846318" category="list-text">Inviare la CORSA: Lavoro ai per l'esecuzione del training distribuito (MPI):</block>
  <block id="f3b76b64a9761cfb85f0ddc37d910fef" category="list-text">Utilizzo di submit of RUN: L'ai per la creazione automatica del PVC nella fase precedente (per il download dei dati) consente solo l'accesso RWO, che non consente a più pod o nodi di accedere allo stesso PVC per la formazione distribuita. Aggiornare la modalità di accesso a ReadWriteMany e utilizzare la patch Kubernetes per eseguire questa operazione.</block>
  <block id="2874172b683ddc4047fd63f29baf543d" category="list-text">Innanzitutto, ottenere il nome del volume del PVC eseguendo il seguente comando:</block>
  <block id="bcc0952c2970bfd6c85cd65050e00533" category="paragraph"><block ref="bcc0952c2970bfd6c85cd65050e00533" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64ac0e4e6343f4593e210b98f9c91de" category="list-text">Applicare la patch al volume e aggiornare la modalità di accesso a ReadWriteMany (sostituire il nome del volume con il proprio nel seguente comando):</block>
  <block id="7a9d347cf2f324e82478a9cf243448f7" category="list-text">Inviare la CORSA: Lavoro ai MPI per l'esecuzione del lavoro di training distribuito` utilizzando le informazioni della tabella seguente:</block>
  <block id="b068931cc450442b63f5b3d276ea4297" category="cell">nome</block>
  <block id="e4580c1854231c935f0cf2eb4609d97a" category="cell">Nome del lavoro di formazione distribuito</block>
  <block id="384dd16a327b7f16278642f008c27fab" category="cell">grande shm</block>
  <block id="fc9fed4d0a3cb207102499ba041f2603" category="cell">Montare un grande dispositivo /dev/shm si tratta di un file system condiviso montato sulla RAM e fornisce una memoria condivisa abbastanza grande per consentire a più lavoratori della CPU di elaborare e caricare batch nella RAM della CPU.</block>
  <block id="530968b205d33b3869aa32e2933fbfad" category="cell">processi</block>
  <block id="403e4aa48fedb1c5777ee913b2f2bedb" category="cell">Numero di processi di formazione distribuiti</block>
  <block id="0aa0be2a866411d9ff03515227454947" category="cell">gpu</block>
  <block id="031492a2d708ca774bd08c099eb4dd79" category="cell">Numero di GPU/processi da allocare per il processo in questo processo, esistono tre processi di lavoro GPU (--processi=3), ciascuno allocato con una singola GPU (--gpu 1)</block>
  <block id="642542e40351edbd731ebad352b31317" category="cell">pvc</block>
  <block id="c50723a53a74a682495f8c3810ce4a65" category="cell">Utilizza il volume persistente esistente (pvc-download-tusemplici-data-0) creato dal job precedente (download-tusemplici-data) e viene montato nel percorso /mnt</block>
  <block id="78805a221a988e79ef3f42d7c5bfd418" category="cell">immagine</block>
  <block id="8c236f63f205a50942b609a6d45734a7" category="cell">Definire le variabili di ambiente da impostare nel container</block>
  <block id="61dcf83940f915d0c5fe5b985eed7be8" category="cell">LAVORATORI_DI_UTILIZZO</block>
  <block id="f84e120605e14d9755a1ed2e8e03cea6" category="cell">Impostando l'argomento su true si attiva il caricamento dei dati multi-processo</block>
  <block id="90b186f5d2a6890e77373c8aa60461e7" category="cell">NUM_WORKERS</block>
  <block id="a10574eb8e119b847fb5ab95b788e723" category="cell">Numero di processi di lavoro del data loader</block>
  <block id="61c67ea819106ff81c08249014791d3b" category="cell">BATCH_SIZE</block>
  <block id="243f7fe32e2dbb7748c1a018fe60016e" category="cell">Dimensione del batch di training</block>
  <block id="d07f4474a5e5996da9b6e57abb250331" category="cell">VALORE_UTILIZZO</block>
  <block id="919bc92a851c1d3e2c467e844398b751" category="cell">L'impostazione dell'argomento su true consente la convalida</block>
  <block id="c4407b612c3b5e2c00c1b5522c686c84" category="cell">VAL_BATCH_SIZE</block>
  <block id="597765782da042e86019b4c919a86248" category="cell">Dimensione del batch di convalida</block>
  <block id="18e0d33045db50bb37e6f2fcd5c0b842" category="cell">ENABLE_SNAPSHOT</block>
  <block id="67c5deea68dff022b0f807ffb3bf56e2" category="cell">Impostando l'argomento su true, è possibile acquisire dati e snapshot dei modelli con formazione per scopi di versioning ML</block>
  <block id="cdd7dd1603420ef6c3efe7b264205137" category="cell">NOME_PVC</block>
  <block id="d95926771c9100db9ba3e3247c86a192" category="cell">Nome del pvc di cui eseguire un'istantanea. Nell'invio del job di cui sopra, si sta prendendo un'istantanea di pvc-download-tusSimple-data-0, che consiste di dataset e modelli addestrati</block>
  <block id="b302d66ab7f3f0c94236ff26c8ead4d9" category="inline-image-macro">Errore: Immagine grafica mancante</block>
  <block id="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="paragraph"><block ref="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3299ed00d03beff0cc2ebaf178a91786" category="list-text">Elencare il lavoro inoltrato.</block>
  <block id="2e593aa2ccf62807184e56a543d23e97" category="paragraph"><block ref="2e593aa2ccf62807184e56a543d23e97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82abe908a319245230ef0f3ec84c263f" category="list-text">Log dei lavori inoltrati:</block>
  <block id="dab56217fc48a1919fee48434a7c7204" category="paragraph"><block ref="dab56217fc48a1919fee48434a7c7204" category="inline-image-macro-rx" type="image"></block></block>
  <block id="981528b0e4cd4a19c56310c6b9c915ce" category="list-text">Controllare il lavoro di training in CORSO: Ai GUI (o app.runai.ai): RUN: Ai Dashboard, come mostrato nelle figure seguenti. La prima figura descrive in dettaglio tre GPU allocate per il lavoro di training distribuito su tre nodi su AKS e la seconda ESECUZIONE:job ai:</block>
  <block id="d8cbd4299e4baf5de5572bf6af32dd52" category="paragraph"><block ref="d8cbd4299e4baf5de5572bf6af32dd52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90fdc4068f0b660d1d6b102946986bd1" category="paragraph"><block ref="90fdc4068f0b660d1d6b102946986bd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9e8bb0b427c33dd6cf63d1a3a37c7022" category="list-text">Al termine del training, controlla la copia Snapshot di NetApp creata e collegata al lavoro RUN: Ai.</block>
  <block id="6c94f812a836696605e3e2b6bd5ca768" category="paragraph"><block ref="6c94f812a836696605e3e2b6bd5ca768" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4c0a1395081fc81855e465c493f4967" category="section-title">Ripristinare i dati dalla copia Snapshot di NetApp</block>
  <block id="ec8de1dcfce51c9d877901e2f6f5971e" category="paragraph">Per ripristinare i dati dalla copia Snapshot di NetApp, attenersi alla seguente procedura:</block>
  <block id="5adc4d7860e7ad0f78ada0bb1f0eaca6" category="list-text">Accedere alla directory del progetto<block ref="2277dab02c330ef055fe72a7776587ae" prefix=" " category="inline-code"></block>.</block>
  <block id="6344772f26907403fed713060f33b8f4" category="list-text">Modificare<block ref="a5fe5fd907cdc55a6a74bfd705214476" prefix=" " category="inline-code"></block> e aggiornare<block ref="d9d448f70687a1aa1f12b2f5ddaa4977" prefix=" " category="inline-code"></block><block ref="b068931cc450442b63f5b3d276ea4297" prefix=" " category="inline-code"></block> Nella copia Snapshot da cui si desidera ripristinare i dati. È anche possibile modificare il nome PVC in cui verranno ripristinati i dati, in questo esempio ITS<block ref="1fcd0a4cb780ecfc14fadd89d5ad8fd2" prefix=" " category="inline-code"></block>.</block>
  <block id="b3b5448c329ac882bc890a1be1a1b369" category="paragraph"><block ref="b3b5448c329ac882bc890a1be1a1b369" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f8efb3d1b86c88cfab193291776b6ad" category="list-text">Creare un nuovo PVC utilizzando<block ref="c6c5b510d872174c3b4e59ca4c66fd6e" prefix=" " category="inline-code"></block>.</block>
  <block id="34c7c2e95019754701182fe2ab194499" category="paragraph"><block ref="34c7c2e95019754701182fe2ab194499" category="inline-image-macro-rx" type="image"></block></block>
  <block id="070856555a817dbf9a4061542b2098ca" category="list-text">Se si desidera utilizzare i dati appena ripristinati per la formazione, l'invio del lavoro rimane lo stesso di prima; sostituire solo<block ref="cdd7dd1603420ef6c3efe7b264205137" prefix=" " category="inline-code"></block> con il ripristinato<block ref="cdd7dd1603420ef6c3efe7b264205137" prefix=" " category="inline-code"></block> quando si invia il lavoro di formazione, come indicato nei seguenti comandi:</block>
  <block id="e945ddc4d35a9c49a17bd00c53db05a6" category="section-title">Valutazione delle performance</block>
  <block id="3451b157ef07ae84bfaba5fb6639c1ba" category="paragraph">Per mostrare la scalabilità lineare della soluzione, sono stati eseguiti test delle performance per due scenari: Una GPU e tre GPU. L'allocazione della GPU, l'utilizzo della GPU e della memoria, diverse metriche a nodo singolo e a tre nodi sono state acquisite durante il training sul set di dati di rilevamento della corsia TuSimple. I dati vengono aumentati di cinque volte solo per analizzare l'utilizzo delle risorse durante i processi di training.</block>
  <block id="b8077d533d2f9918c47d330cbac4392d" category="inline-link-macro">Livelli di servizio Azure NetApp Files</block>
  <block id="da9b7dc2993c3c848d5d9a9a15806d8c" category="paragraph">La soluzione consente ai clienti di iniziare con un piccolo set di dati e poche GPU. Quando la quantità di dati e la domanda di GPU aumentano, i clienti possono scalare dinamicamente i terabyte nel Tier Standard e scalare rapidamente fino al Tier Premium per ottenere un throughput quattro volte superiore per terabyte senza spostare alcun dato. Questo processo viene spiegato ulteriormente nella sezione, <block ref="bdbab4daa7de478307acc7147c869853" category="inline-link-macro-rx"></block>.</block>
  <block id="090a231c840a0cb23aa29c8d1afc7832" category="paragraph">Il tempo di elaborazione su una GPU era di 12 ore e 45 minuti. Il tempo di elaborazione su tre GPU su tre nodi era di circa 4 ore e 30 minuti.</block>
  <block id="49eca64b9f03702167beb48ebd38587b" category="paragraph">Le figure mostrate nel resto di questo documento illustrano esempi di performance e scalabilità in base alle singole esigenze aziendali.</block>
  <block id="abfc10c2bc00a990735e6d27797295a8" category="paragraph">La figura seguente illustra l'allocazione e l'utilizzo della memoria di 1 GPU.</block>
  <block id="8d7e3abab70510c3f4636ff7bf953250" category="paragraph"><block ref="8d7e3abab70510c3f4636ff7bf953250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31a3d2def4927574922946c38f043c0b" category="paragraph">La figura seguente illustra l'utilizzo della GPU a nodo singolo.</block>
  <block id="58cf0f270760f08ac96254402d0696dc" category="paragraph"><block ref="58cf0f270760f08ac96254402d0696dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dcca9cfd87d9f2087d720ef187655cea" category="paragraph">La figura seguente illustra le dimensioni della memoria a nodo singolo (16 GB).</block>
  <block id="e22d39f2830d0f3e3944644d0f605d41" category="paragraph"><block ref="e22d39f2830d0f3e3944644d0f605d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="576c0843e21d5ee884a067aa7b6a1a40" category="paragraph">La figura seguente illustra il numero di GPU a nodo singolo (1).</block>
  <block id="ef855771be83c072ebaafc60d2d1933f" category="paragraph"><block ref="ef855771be83c072ebaafc60d2d1933f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a2c50f1b8fc86c36cc0df94dd14b46b9" category="paragraph">La figura seguente illustra l'allocazione della GPU a nodo singolo (%).</block>
  <block id="e295f84458327d01315b814d8deb2aea" category="paragraph"><block ref="e295f84458327d01315b814d8deb2aea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b2b7f256373eac14419bfec5b84b21" category="paragraph">La figura seguente illustra tre GPU su tre nodi: Allocazione e memoria delle GPU.</block>
  <block id="e763ef0e4b7cb9d022bf6db49319c570" category="paragraph"><block ref="e763ef0e4b7cb9d022bf6db49319c570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94ab4242b167972f7a9f0513ca772555" category="paragraph">La figura seguente illustra tre GPU in tre nodi utilizzati (%).</block>
  <block id="d786146ae56597413fa5be548126cda9" category="paragraph"><block ref="d786146ae56597413fa5be548126cda9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c31ecb239228cac5e96860d42f9a4d" category="paragraph">La figura seguente illustra tre GPU in tre nodi di utilizzo della memoria (%).</block>
  <block id="2224958fd5113068ac8a3b55a336661b" category="paragraph"><block ref="2224958fd5113068ac8a3b55a336661b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79f05e8f99917560625d1cf3f2d4fc5d" category="inline-link">livello di servizio</block>
  <block id="07c1fda2408980b5d53ea06ad3cc5ed1" category="paragraph">È possibile modificare il livello di servizio di un volume esistente spostando il volume in un altro pool di capacità che utilizza<block ref="bc9fbd5fd43d884f02abe6a6f9b51339" category="inline-link-rx"></block> si desidera per il volume. Questa modifica del livello di servizio esistente per il volume non richiede la migrazione dei dati. Inoltre, non influisce sull'accesso al volume.</block>
  <block id="5e2ff0b5dc3206032a81aa3aecb7c462" category="section-title">Modificare dinamicamente il livello di servizio di un volume</block>
  <block id="58e691ddc6184f73e5d6b513ca5a3c49" category="paragraph">Per modificare il livello di servizio di un volume, attenersi alla seguente procedura:</block>
  <block id="3f19b438418ed162387a3050b304c89b" category="list-text">Nella pagina Volumes (volumi), fare clic con il pulsante destro del mouse sul volume di cui si desidera modificare il livello di servizio. Selezionare Cambia pool.</block>
  <block id="5acf521dbc5099b2ec33a64efac89595" category="paragraph"><block ref="5acf521dbc5099b2ec33a64efac89595" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6533c4186062235d8b7f47e232e92597" category="list-text">Nella finestra Change Pool, selezionare il pool di capacità in cui si desidera spostare il volume. Quindi, fare clic su OK.</block>
  <block id="3f0874d07ce6ae728a6dcdda7903f9cd" category="paragraph"><block ref="3f0874d07ce6ae728a6dcdda7903f9cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb935c59f24539e0966b7ab5c761e862" category="section-title">Automatizzare la modifica del livello di servizio</block>
  <block id="1391028ed384c93fd59fd5a0097f9181" category="paragraph">La modifica dinamica del livello di servizio è ancora in Public Preview, ma non è attivata per impostazione predefinita. Per attivare questa funzione nell'abbonamento Azure, seguire la procedura descritta nel documento "<block ref="5c3671452d40598396b030d5c9c6dc27" category="inline-link-rx"></block>."</block>
  <block id="407443b5508c517acd825fbcddb7ab4c" category="inline-link">Volume netappfiles az: Gestione delle risorse dei volumi ANF (Azure NetApp Files)</block>
  <block id="1d3afb31c5d2a81fca940ae760671a1c" category="list-text">Per Azure è inoltre possibile utilizzare i seguenti comandi: CLI. Per ulteriori informazioni su come modificare le dimensioni del pool di Azure NetApp Files, visitare il sito<block ref="8b45caafcc8d758d5c37edb19f8a2761" category="inline-link-rx"></block>.</block>
  <block id="ebd5b070cb8457b94f1916baa92c3c7d" category="inline-link">Modifica del pool per un volume Azure NetApp Files</block>
  <block id="d5460fd5fbfbf643b9a4bc1d1de279d0" category="list-text">Il<block ref="2de1988ae552a465bf4f3a270c8403a4" prefix=" " category="inline-code"></block> Il cmdlet illustrato può modificare il pool di un volume Azure NetApp Files. Per ulteriori informazioni sulla modifica delle dimensioni del pool di volumi e di Azure PowerShell, visitare il sito Web<block ref="70c8d95cde8b63eae0d37a8b81a31482" category="inline-link-rx"></block>.</block>
  <block id="e59b92fc604ecde201ab865ddefca7c2" category="summary">In questa sezione vengono presentati i principali componenti di questa soluzione in maggiore dettaglio.</block>
  <block id="56cdae354d8e4efeaa936d576b919c49" category="paragraph"><block ref="56cdae354d8e4efeaa936d576b919c49" category="inline-link-macro-rx"></block></block>
  <block id="995049066ee0a46858d3a35e74f687fc" category="paragraph">I sistemi storage NetApp AFF consentono alle aziende di soddisfare i requisiti di storage Enterprise con performance leader del settore, flessibilità superiore, integrazione nel cloud e gestione dei dati Best-in-class. Progettati appositamente per la tecnologia flash, i sistemi AFF aiutano ad accelerare, gestire e proteggere i dati business-critical.</block>
  <block id="bd06e3e9a11cc16a8f389477f9ed6a95" category="paragraph">NetApp AFF A400 è un sistema di storage flash NVMe mid-range basato su hardware FAS2650 e supporti flash SSD.</block>
  <block id="9cdcb25bd8b8e9dd029f0c58f1c1ce14" category="inline-image-macro">Questa figura mostra la parte anteriore del controller dello storage NetApp AFF A400.</block>
  <block id="55f69aa150e5e2d9b4339594dbb70471" category="paragraph"><block ref="55f69aa150e5e2d9b4339594dbb70471" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4c41eb7420fce0589579f0f045df87" category="inline-image-macro">Questa figura mostra il retro del controller dello storage NetApp AFF A400.</block>
  <block id="e83035ebe127e618e86974c913d42589" category="paragraph"><block ref="e83035ebe127e618e86974c913d42589" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5062a65c6ae4cbe0c015396c4011a811" category="paragraph">Le caratteristiche del sistema storage midrange NetApp AFF A400 includono:</block>
  <block id="722f61060a76e673835749dd7040109c" category="list-text">Capacità effettiva massima: 702,7 PB</block>
  <block id="9b150a217729988c3dd54fdaf7b0f9b3" category="list-text">Scale-out massimo: 2-24 nodi (12 coppie ha)</block>
  <block id="ae3b033d221455bb2825ac51bee7200e" category="list-text">Supporto host FC da 25 GbE e 16 GB</block>
  <block id="e16f4e2b178ce47880c3556c501efea4" category="list-text">Connettività RDMA 100 GbE su RoCE (Converged Ethernet) agli shelf di storage di espansione NVMe</block>
  <block id="2f5979909b8c4a0d58f13de4881feaf1" category="list-text">Le porte RoCE da 100 GbE possono essere utilizzate per il collegamento alla rete host se gli shelf NVMe non sono collegati</block>
  <block id="dff1410020c1b676f56ee973acea57d3" category="list-text">Shelf di storage per l'espansione della connettività SAS a 12 Gbps</block>
  <block id="565637725a05c879995851c50d41275c" category="list-text">Disponibile in due configurazioni:</block>
  <block id="8e707b713d26c4b020eda98a37207373" category="list-text">Ethernet: 4 porte Ethernet da 25 GB (SFP28)</block>
  <block id="1d3c6ad9f15fc70a1cf63e449e90436a" category="list-text">Fibre Channel: 4 porte FC (SFP+) da 16 GB</block>
  <block id="6a2a811bcec501901ab6f8f94694d1b2" category="list-text">100% lettura casuale 8 KB @0,4 ms 400.000 IOPS</block>
  <block id="d3309961dfabc3043c3ea1878752450b" category="paragraph">Le funzionalità di NetApp AFF A250 per le implementazioni ai/ML entry-level includono:</block>
  <block id="68448ae40d26fce5bb74cd3bf75999c4" category="list-text">Capacità effettiva massima: 35 PB</block>
  <block id="83fa45e9cc2def5751527547e3c57b61" category="list-text">Scale-out massima: 2-24 nodi (12 coppie ha)</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">440.000 letture casuali IOPS @1 ms.</block>
  <block id="1283cfcd2651148a611c2c4b105458c3" category="list-text">Basato sull'ultima release di NetApp ONTAP ONTAP 9.8 o successiva</block>
  <block id="f31903137775862e1157677f447b0f52" category="list-text">Due porte Ethernet da 25 GB per ha e interconnessione cluster</block>
  <block id="f6c48fdc99c510156e0364e03a6fbd9e" category="paragraph">NetApp offre anche altri sistemi storage, come AFF A800 e AFF A700, che offrono performance e scalabilità superiori per implementazioni ai/ML su larga scala.</block>
  <block id="b2c0ed3ea756cb47f24ee9aef32e0f01" category="paragraph">ONTAP 9, l'ultima generazione di software per la gestione dello storage NetApp, consente alle aziende di modernizzare l'infrastruttura e passare a un data center predisposto per il cloud. Sfruttando le funzionalità di gestione dei dati leader del settore, ONTAP consente la gestione e la protezione dei dati con un singolo set di strumenti, indipendentemente dalla posizione dei dati. I dati possono anche essere spostati liberamente in qualsiasi punto: Edge, core o cloud. ONTAP 9 include numerose funzionalità che semplificano la gestione dei dati, accelerano e proteggono i dati critici e un'infrastruttura a prova di futuro su architetture di cloud ibrido.</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">La gestione dei dati è fondamentale per le operazioni IT aziendali, in modo da utilizzare le risorse appropriate per applicazioni e set di dati. ONTAP include le seguenti funzionalità per ottimizzare e semplificare le operazioni e ridurre il costo totale delle operazioni:</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">*Compattazione dei dati inline e deduplica estesa.* la compattazione dei dati riduce lo spazio sprecato all'interno dei blocchi di storage e la deduplica aumenta significativamente la capacità effettiva. Ciò vale per i dati memorizzati localmente e per i dati a più livelli nel cloud.</block>
  <block id="ddf38f965aeb6f6b5785254e6f143a09" category="list-text">*ONTAP FabricPool.* questa funzione esegue automaticamente il Tier dei dati cold su opzioni di cloud storage pubblico e privato, tra cui Amazon Web Services (AWS), Azure e storage a oggetti NetApp StorageGRID.</block>
  <block id="2a228ac6322b6d496b4cb0cf22cfbfe4" category="list-text">*Prestazioni e latenza ridotta.* ONTAP offre il throughput più elevato possibile con la latenza più bassa possibile.</block>
  <block id="cf4d3359e3cce4324a54d8e1864d2647" category="paragraph">ONTAP 9 aiuta a soddisfare le esigenze di business esigenti e in continua evoluzione:</block>
  <block id="99f4fd3a9ea4a861a7095bfe26937f28" category="list-text">*Scalabilità perfetta e operazioni senza interruzioni.* ONTAP supporta l'aggiunta senza interruzioni di capacità ai controller esistenti e ai cluster scale-out. I clienti possono eseguire l'upgrade alle tecnologie più recenti, come NVMe e 32GB FC, senza costose migrazioni dei dati o interruzioni.</block>
  <block id="0cee26e8172666a9085f957269fc4b64" category="list-text">*Connessione al cloud.* ONTAP è il software di gestione dello storage più connesso al cloud, con opzioni per lo storage software-defined (ONTAP Select) e le istanze native del cloud (NetApp Cloud Volumes Service) in tutti i cloud pubblici.</block>
  <block id="ba1e7aff40da44f3c5b86ba78a62e7d0" category="list-text">*Integrazione con applicazioni emergenti.* ONTAP offre servizi dati di livello Enterprise per piattaforme e applicazioni di prossima generazione come OpenStack, Hadoop e MongoDB utilizzando la stessa infrastruttura che supporta le applicazioni aziendali esistenti.</block>
  <block id="0fdd508a09442b5caa00e47bc0563112" category="section-title">NetApp FlexGroup Volumes</block>
  <block id="641653fdc449e0b1e30f3ee9d04182ab" category="paragraph">I set di dati del training sono in genere una raccolta di potenzialmente miliardi di file. I file possono includere testo, audio, video e altre forme di dati non strutturati che devono essere memorizzati ed elaborati per essere letti in parallelo. Il sistema di storage deve memorizzare molti file di piccole dimensioni e leggerli in parallelo per l'i/o sequenziale e casuale</block>
  <block id="e6ad1152aea2aa4f79a47e3b80410fce" category="paragraph">Un volume FlexGroup (la figura seguente) è un singolo namespace costituito da più volumi membri costitutivi gestiti e che agisce come un volume NetApp FlexVol per gli amministratori dello storage. I file in un volume FlexGroup vengono allocati a singoli volumi membri e non vengono sottoposti a striping tra volumi o nodi. Consentono le seguenti funzionalità:</block>
  <block id="381a99cae8c29b3b8fd64a207b811935" category="list-text">Fino a 20 petabyte di capacità e bassa latenza prevedibile per carichi di lavoro con metadati elevati</block>
  <block id="b0e05251a53a0118d23cd469db4b1903" category="list-text">Fino a 400 miliardi di file nello stesso spazio dei nomi</block>
  <block id="4eb6665794643a2afabf63f90ddbe4da" category="list-text">Operazioni parallelizzate nei carichi di lavoro NAS tra CPU, nodi, aggregati e volumi FlexVol costitutivi</block>
  <block id="19adba666d12642fc956c8a4c4607a66" category="inline-image-macro">"Questa immagine mostra una coppia ha di controller di storage contenenti molti volumi con file principali all'interno di un FlexGroup.</block>
  <block id="67243c21916276b166b8cad21f937c57" category="paragraph"><block ref="3998ac0cd0b54d5528002049c9fb6e1f" category="inline-image-macro-rx" type="image"></block>"</block>
  <block id="f52dbcd9b43086f1d2957e6eb89f4113" category="section-title">Portfolio Lenovo ThinkSystem</block>
  <block id="e76fa728781968dd4a707e2d3b1d8108" category="paragraph">I server Lenovo ThinkSystem sono dotati di hardware, software e servizi innovativi che risolvono le sfide attuali dei clienti e offrono un approccio di progettazione modulare e evolutivo, adatto allo scopo, per affrontare le sfide del futuro. Questi server si basano su tecnologie Best-in-class e standard di settore, unite a innovazioni Lenovo differenziate per offrire la massima flessibilità possibile nei server x86.</block>
  <block id="c5ac419e5467e7539d60c18be3da4b99" category="paragraph">I vantaggi principali dell'implementazione dei server Lenovo ThinkSystem includono:</block>
  <block id="c19629173ec04d03fae09e96ce30b98c" category="list-text">Design altamente scalabili e modulari in grado di crescere con il tuo business</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">Resilienza leader del settore per risparmiare ore di costosi downtime non pianificati</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">Tecnologie flash veloci per latenze inferiori, tempi di risposta più rapidi e gestione dei dati più intelligente in tempo reale</block>
  <block id="9ac34c98220e3dd285a7cd6c8679caeb" category="paragraph">Nell'area dell'ai, Lenovo sta adottando un approccio pratico per aiutare le aziende a comprendere e adottare i vantaggi di ML e ai per i propri carichi di lavoro. I clienti Lenovo possono esplorare e valutare le offerte Lenovo ai nei Lenovo ai Innovation Center per comprendere appieno il valore del loro caso di utilizzo specifico. Per migliorare il time-to-value, questo approccio incentrato sul cliente offre ai clienti prove di concetto per piattaforme di sviluppo di soluzioni pronte all'uso e ottimizzate per l'ai.</block>
  <block id="7cbc0e3d7cff391aa0e61b487dc29df1" category="section-title">Lenovo SR670 V2</block>
  <block id="5889950b76dcc45f10977523225c92a8" category="paragraph">Il server rack Lenovo ThinkSystem SR670 V2 offre performance ottimali per l'ai accelerato e l'HPC (high-performance computing). Con il supporto di un massimo di otto GPU, SR670 V2 è ideale per i requisiti di carico di lavoro intensivi a livello di calcolo di ML, DL e inferenza.</block>
  <block id="327669874a587f6f9336f608f83d451d" category="inline-image-macro">Questa immagine mostra tre configurazioni SR670. La prima mostra quattro GPU SXM con otto dischi HS da 2.5 pollici e 2 slot i/o PCIe. La seconda mostra quattro slot GPU doppi o otto slot GPU singoli e due slot i/o PCIe con otto dischi HS da 2.5" o quattro da 3.5". La terza mostra otto slot GPU a doppia larghezza con sei dischi EDSFF HS e due slot i/o PCIe.</block>
  <block id="f3ebf0cd9319acd4d10b09be0d9220c2" category="paragraph"><block ref="f3ebf0cd9319acd4d10b09be0d9220c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="85b1e2eb4bc61f3bdaea9a9f040eb3a0" category="paragraph">Con le più recenti CPU scalabili Intel Xeon che supportano GPU high-end (inclusa NVIDIA A100 80 GB PCIe 8x GPU), ThinkSystem SR670 V2 offre performance ottimizzate e accelerate per i carichi di lavoro ai e HPC.</block>
  <block id="d7ed5fdb2102567c3c051078e7c72e11" category="paragraph">Poiché più carichi di lavoro utilizzano le performance degli acceleratori, la domanda di densità GPU è aumentata. Settori come il retail, i servizi finanziari, l'energia e il settore sanitario stanno utilizzando le GPU per estrarre informazioni più approfondite e promuovere l'innovazione con LE tecniche ML, DL e Inference.</block>
  <block id="89a846b0823ae167964c8a02382225cf" category="paragraph">ThinkSystem SR670 V2 è una soluzione ottimizzata di livello Enterprise per l'implementazione di carichi di lavoro HPC e ai accelerati in produzione, massimizzando le performance del sistema mantenendo la densità del data center per i cluster di supercalcolo con piattaforme di prossima generazione.</block>
  <block id="9378d87a3787bb6ab3fe4605dd558aaf" category="paragraph">Altre funzionalità includono:</block>
  <block id="fe62ffc0b0188329f10e2bfc0c560ece" category="list-text">Supporto per i/o RDMA diretto GPU in cui gli adattatori di rete ad alta velocità sono collegati direttamente alle GPU per massimizzare le prestazioni i/O.</block>
  <block id="03e5fd8f257caa94eae847639e18b1a9" category="list-text">Supporto dello storage diretto GPU in cui i dischi NVMe sono collegati direttamente alle GPU per massimizzare le performance dello storage.</block>
  <block id="ad7857a40388167e99516cfe367478d5" category="paragraph">MLPerf è la suite di benchmark leader del settore per la valutazione delle performance ai. In questa convalida, abbiamo utilizzato il benchmark di classificazione delle immagini con MXNet, uno dei framework ai più diffusi. Lo script di training MXNet_benchmarking è stato utilizzato per promuovere il training ai. Lo script contiene implementazioni di diversi modelli convenzionali ed è progettato per essere il più veloce possibile. Può essere eseguito su una singola macchina o in modalità distribuita su più host.</block>
  <block id="26cb2cd90a9e0e03f63323eab13f117d" category="inline-link-macro">Successivo: Piano di test.</block>
  <block id="a29118c3c40b6309f6b6354a52631e91" category="paragraph"><block ref="a29118c3c40b6309f6b6354a52631e91" category="inline-link-macro-rx"></block></block>
  <block id="ff9caff469d56a572a569942ca24c8b4" category="list-text">Sistemi NVIDIA DGX</block>
  <block id="b69073c22b4269568fd577ea090ce638" category="list-text">Sistema NVIDIA DGX-1<block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="fe287c518b9b1345defadacdc6a9ecbf" category="list-text">NVIDIA V100 Tensor Core GPU<block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="d6a8716635a5681cde357a465953bc72" category="list-text">NVIDIA NGC<block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="11bdb18e1c5e7d1e4362c9d2f6956fc8" category="list-text">Soluzione per l'orchestrazione di container Run:ai</block>
  <block id="5afc85c81e76f427a293dd861e0109a3" category="list-text">Run:Introduzione al prodotto ai<block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="9acfbb098f0d9b45b5897b44ae347ee9" category="list-text">Esegui:documentazione di installazione ai<block ref="cb05a776556ca5a25aec417185ef6863" category="inline-link-rx"></block>
<block ref="b2e8533fae57aa9047d7731db51b6dfe" category="inline-link-rx"></block></block>
  <block id="b0d8a6d0eebdc42ac243c16f9137118d" category="list-text">Invio di job in Run:ai CLI<block ref="97ec6c214f99d7e6a39194a167aeecc8" category="inline-link-rx"></block>
<block ref="d75350381b5fda5cc9c9a1ce34c24299" category="inline-link-rx"></block></block>
  <block id="9bd35f4f3f6faa9e9330c54fd2086967" category="list-text">Allocazione delle frazioni GPU in Run:ai CLI<block ref="e343516de5fb56c6a0d652bcdfceaab7" category="inline-link-rx"></block></block>
  <block id="ddb27cb97146c8f5964eaf368feb4ce0" category="list-text">Report tecnico<block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="2273cd603e277bb35f96881a557b0608" category="list-text">Demo in formato breve<block ref="61e3673018126d9a106032d9ff691322" category="inline-link-rx"></block></block>
  <block id="45f26b752dfae88ec8c7def446162521" category="list-text">Repository di GitHub<block ref="f9a4909739179bedfa8ba1d225598979" category="inline-link-rx"></block></block>
  <block id="c36e36ff8b7edf8dd17781148ed57337" category="list-text">Scheda informativa su NetApp AFF Serie A.<block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="ffc4c8e8bc10afc438d9c590f44e3b51" category="list-text">NetApp Flash Advantage per All Flash FAS<block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="7843ce52c43038d88c2f54d85f3f764d" category="list-text">Raccolta di informazioni su ONTAP 9<block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="5f1b8a708e16776ca4372c71dc377653" category="list-text">Report tecnico NetApp ONTAP FlexGroup Volumes<block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="062d7e5979c653f33e03cb0aaeaec6e9" category="list-text">Guida alla progettazione di reti ONTAP ai con DGX-1 e Cisco<block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="59086e50189644b7c19947dfa68f8395" category="list-text">Guida all'implementazione di ONTAP ai con DGX-1 e Cisco Networking<block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="062afad089226e62b53e77ba2af24574" category="list-text">Guida alla progettazione di reti ONTAP ai con DGX-1 e Mellanox<block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="e6b737f0513721f0a8024f538058333e" category="list-text">Guida alla progettazione di ONTAP ai con DGX-2<block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="9c08a0abcced906f3225e86f61dd598c" category="paragraph"><block ref="9c08a0abcced906f3225e86f61dd598c" category="inline-link-macro-rx"></block></block>
  <block id="c5648cc9e6e76ab4aa041d71661d0288" category="list-text">Demo interattive 3D</block>
  <block id="26e071d5769be8e940617a0c8dd5c22d" category="inline-link">www.netapp.com/ai</block>
  <block id="9e22db1b830d668e86d5dc1b5c204555" category="paragraph"><block ref="9e22db1b830d668e86d5dc1b5c204555" category="inline-link-rx"></block></block>
  <block id="1fa584a3d1190f1a7fdded0c91412cac" category="list-text">Connettiti direttamente con uno specialista ai di NetApp</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="488d7301e5d1a52040c33186d7e11657" category="paragraph"><block ref="488d7301e5d1a52040c33186d7e11657" category="inline-link-rx"></block></block>
  <block id="787dd83fbbc162f0279e320ada1f7c0b" category="list-text">NVDIA base Command Platform with NetApp Solution Brief</block>
  <block id="5541299dd0999c42fcd24fd754001e38" category="inline-link"><block ref="5541299dd0999c42fcd24fd754001e38" category="inline-link-rx"></block></block>
  <block id="ac527e3c2b2d8a080840aa28c13b127b" category="paragraph"><block ref="ac527e3c2b2d8a080840aa28c13b127b" category="inline-link-rx"></block></block>
  <block id="465b9c508fba1d27d188eb21e0655293" category="list-text">Infografica sulle buone ragioni di NetApp per ai 10</block>
  <block id="75048e22ffd1c45ce07e6cae3170780a" category="inline-link"><block ref="75048e22ffd1c45ce07e6cae3170780a" category="inline-link-rx"></block></block>
  <block id="e2435a6f01dee5a11f6cd698a292183d" category="paragraph"><block ref="e2435a6f01dee5a11f6cd698a292183d" category="inline-link-rx"></block></block>
  <block id="66d4373905c5c7c0a3f51e5480d443b2" category="list-text">Ai in Healthcare: White paper sull'apprendimento approfondito per identificare le lesioni COVID-19 nelle scansioni TC polmonari</block>
  <block id="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link"><block ref="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link-rx"></block></block>
  <block id="d1e9d43080e6c2364ee86ac930ae1341" category="paragraph"><block ref="d1e9d43080e6c2364ee86ac930ae1341" category="inline-link-rx"></block></block>
  <block id="2ece031fbb30496ba2ec244a07557107" category="list-text">Ai in Healthcare: White paper sul monitoraggio dell'utilizzo della maschera facciale in ambito sanitario</block>
  <block id="aa895997d9bc7e84d90779885cb936b7" category="inline-link"><block ref="aa895997d9bc7e84d90779885cb936b7" category="inline-link-rx"></block></block>
  <block id="4ac3d75f4e132824f0fe3a418d42a9f9" category="paragraph"><block ref="4ac3d75f4e132824f0fe3a418d42a9f9" category="inline-link-rx"></block></block>
  <block id="ff11da2c36a9883c6eb658395f3de353" category="list-text">Ai in Healthcare: Report tecnico di imaging diagnostico</block>
  <block id="41575d740e0d837694e2fa66ce618124" category="inline-link"><block ref="41575d740e0d837694e2fa66ce618124" category="inline-link-rx"></block></block>
  <block id="61a15cd6b61d637fb54ae6ae99ae39d5" category="paragraph"><block ref="61a15cd6b61d637fb54ae6ae99ae39d5" category="inline-link-rx"></block></block>
  <block id="1527888e6b729290296c51cf9c3aeeec" category="list-text">Ai per il retail: Ai di NetApp Conversational con NVIDIA RIVA</block>
  <block id="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link"><block ref="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link-rx"></block></block>
  <block id="dc1f6c62d8de3b68ec946b66d053f5a7" category="paragraph"><block ref="dc1f6c62d8de3b68ec946b66d053f5a7" category="inline-link-rx"></block></block>
  <block id="2281741ceb773b1efc91b48b4e5e04fe" category="list-text">Analisi della soluzione ai di NetApp ONTAP</block>
  <block id="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link"><block ref="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link-rx"></block></block>
  <block id="a32cc63ad53dc74caf680b96a921ad3b" category="paragraph"><block ref="a32cc63ad53dc74caf680b96a921ad3b" category="inline-link-rx"></block></block>
  <block id="c6b4ec978259e83d537f6a179912448a" category="list-text">Descrizione della soluzione NetApp DataOps Toolkit</block>
  <block id="c50b3ec30c711b6233dd7753f12165d4" category="inline-link"><block ref="c50b3ec30c711b6233dd7753f12165d4" category="inline-link-rx"></block></block>
  <block id="a045bf4eb32fbbf6c351d4c3cbd5932c" category="paragraph"><block ref="a045bf4eb32fbbf6c351d4c3cbd5932c" category="inline-link-rx"></block></block>
  <block id="9399af78c2a9b2a197612e42bf8b8f79" category="list-text">Analisi della soluzione NetApp ai Control Plane</block>
  <block id="c771257beb97f479ebb6d342d91b61bd" category="inline-link"><block ref="c771257beb97f479ebb6d342d91b61bd" category="inline-link-rx"></block></block>
  <block id="ce6060d7bc79a57fdb337f6364f0e8a9" category="paragraph"><block ref="ce6060d7bc79a57fdb337f6364f0e8a9" category="inline-link-rx"></block></block>
  <block id="b6e1af8dc83073dfa46f061507b15586" category="list-text">EBook trasformare il settore con Data Drive ai</block>
  <block id="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link"><block ref="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link-rx"></block></block>
  <block id="195010aa6331d4b94de36f6aa5cf3fc7" category="paragraph"><block ref="195010aa6331d4b94de36f6aa5cf3fc7" category="inline-link-rx"></block></block>
  <block id="4dcaafba5ac7511b65c0f3a3688f8d81" category="list-text">Analisi della soluzione ai NetApp EF-Series</block>
  <block id="385bae1ac9580238d4ef22dad99878c3" category="inline-link"><block ref="385bae1ac9580238d4ef22dad99878c3" category="inline-link-rx"></block></block>
  <block id="5bbcd3b785c7ecb740b1302ea68fb4ff" category="paragraph"><block ref="5bbcd3b785c7ecb740b1302ea68fb4ff" category="inline-link-rx"></block></block>
  <block id="e72de1f0850154df8bf93fae76b2276d" category="list-text">Analisi della soluzione NetApp ai e Lenovo ThinkSystem for ai Inferencing</block>
  <block id="883d1d69b62bc20ea26446649b6c95b0" category="inline-link"><block ref="883d1d69b62bc20ea26446649b6c95b0" category="inline-link-rx"></block></block>
  <block id="74686a12110c0c39ad22ac2252bcb1a1" category="paragraph"><block ref="74686a12110c0c39ad22ac2252bcb1a1" category="inline-link-rx"></block></block>
  <block id="8954bee2812529847e7f3108185fc57d" category="list-text">Analisi della soluzione NetApp ai e Lenovo ThinkSystem per ai e ML Enterprise</block>
  <block id="f877ccffca68b901c2c61513c04dbf37" category="inline-link"><block ref="f877ccffca68b901c2c61513c04dbf37" category="inline-link-rx"></block></block>
  <block id="214ebd5c8513ce31087d4bf0cd12af76" category="paragraph"><block ref="214ebd5c8513ce31087d4bf0cd12af76" category="inline-link-rx"></block></block>
  <block id="7cbca96fc14ecadf4054303e98a81787" category="list-text">NetApp e NVIDIA – ridefinire le possibilità con i video ai</block>
  <block id="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link"><block ref="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link-rx"></block></block>
  <block id="c7531fbb829ae07f04aab76de6fad46c" category="paragraph"><block ref="c7531fbb829ae07f04aab76de6fad46c" category="inline-link-rx"></block></block>
  <block id="1a17b23dd49d997677e18c9b9fe29935" category="summary">Questa pagina descrive come monitorare Task utilizzando la dashboard nativa di Task Stream.</block>
  <block id="3268570ddd540695f3e92ff79d8f4684" category="doc">Monitorate la Task utilizzando la dashboard nativa dei Task Streams</block>
  <block id="1e80a6d70a902d1dae25d26917a5b490" category="inline-link-macro">Precedente: Caricare il giorno 15 in Dask e formare un modello di foresta casuale di Dask cuML.</block>
  <block id="3898f5ae37dfd830af10cdc128236b50" category="paragraph"><block ref="3898f5ae37dfd830af10cdc128236b50" category="inline-link-macro-rx"></block></block>
  <block id="9eeb55820f49a600fa229f23cfe9e5b5" category="inline-link">Scheduler distribuito di Dask</block>
  <block id="99b248c7005783fe2682ad82217e9a24" category="paragraph">Il<block ref="7df0d90bf997a373bfe85bbe10a2d2c8" category="inline-link-rx"></block> fornisce feedback live in due forme:</block>
  <block id="d8516bf5d94a38a1fa1d7a8c3b92dee7" category="list-text">Una dashboard interattiva contenente numerosi grafici e tabelle con informazioni in tempo reale</block>
  <block id="d22ebe91c5dc1499387785da997fbe7d" category="list-text">Barra di avanzamento adatta per l'utilizzo interattivo in console o notebook</block>
  <block id="6e35e4c1cc9332ebc8028df451bc4f06" category="paragraph">Nel nostro caso, la figura seguente mostra come è possibile monitorare l'avanzamento del task, inclusi i byte memorizzati, il Task Stream con una dettagliata suddivisione del numero di flussi e l'avanzamento in base ai nomi delle attività con le funzioni associate eseguite. Nel nostro caso, poiché abbiamo tre nodi di lavoro, ci sono tre blocchi principali di flusso e i codici colore indicano attività diverse all'interno di ogni flusso.</block>
  <block id="5743e70224503025dacaa77fae253c4f" category="paragraph"><block ref="5743e70224503025dacaa77fae253c4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a5c7a858f05434bf6637c3995959f49" category="paragraph">È possibile analizzare le singole attività ed esaminare il tempo di esecuzione in millisecondi o identificare eventuali ostacoli o ostacoli. Ad esempio, la figura seguente mostra i flussi di attività per la fase di adattamento del modello di foresta casuale. Le funzioni eseguite sono notevolmente più numerose, tra cui il chunk unico per l'elaborazione di DataFrame, _Construct_rf per l'adattamento della foresta casuale e così via. La maggior parte del tempo è stato dedicato alle operazioni DataFrame a causa delle grandi dimensioni (45 GB) di un giorno di dati provenienti dai Click Logs di Criteo.</block>
  <block id="816ff133aaa3d2f46ca0c7842f5fdaab" category="paragraph"><block ref="816ff133aaa3d2f46ca0c7842f5fdaab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5eca1492a19a4c24071ed91262666cf" category="inline-link-macro">Avanti: Confronto dei tempi di training.</block>
  <block id="d5d929f175d4a2062c661e45b9656f32" category="paragraph"><block ref="d5d929f175d4a2062c661e45b9656f32" category="inline-link-macro-rx"></block></block>
  <block id="1e92efa8f46c28a3c3a1c03ababfa7be" category="doc">Dimostrazione di NetApp Retail Assistant</block>
  <block id="bb07f1ff94c6f99bf48a403706bea4ca" category="paragraph">Abbiamo registrato un video dimostrativo di NetApp Retail Assistant (NARA). Fare clic su<block ref="c1305d6e7f2e06345748f63e36abba33" category="inline-link-rx"></block> per aprire la figura seguente e riprodurre la dimostrazione video.</block>
  <block id="088070f65f454d6b38e8e40e332e70a8" category="paragraph"><block ref="088070f65f454d6b38e8e40e332e70a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d81ccbd202a60c621000abca3f6f3de" category="inline-link-macro">Pagina successiva: Utilizza NetApp Cloud Sync per archiviare la cronologia delle conversazioni</block>
  <block id="a165baa9089720dc90e8baf16267821f" category="paragraph"><block ref="a165baa9089720dc90e8baf16267821f" category="inline-link-macro-rx"></block></block>
  <block id="6f7f6c0b1054487e622896990b1d6d55" category="doc">TR-4841: Sistema operativo ai per il cloud ibrido con caching dei dati</block>
  <block id="1b55e21d5b19a6ba57ae9bbd6f3a0630" category="paragraph">Rick Huang, David Arnette, NetApp Yochay Ettun, cnvrg.io</block>
  <block id="28d9fd6fa10254fdcc59aa182ae32dc9" category="paragraph">La crescita esplosiva dei dati e la crescita esponenziale di ML e ai sono convergenti per creare un'economia di zettabyte con sfide di sviluppo e implementazione uniche.</block>
  <block id="eb35f773ff882afb6d6d67613a4701ee" category="paragraph">Sebbene sia noto che i modelli ML sono affamati di dati e richiedono uno storage dei dati ad alte performance prossimale alle risorse di calcolo, in pratica non è così semplice implementare questo modello, soprattutto con il cloud ibrido e le istanze di calcolo elastiche. In genere, enormi quantità di dati vengono memorizzate in data Lake a basso costo, dove le risorse di calcolo ai dalle performance elevate, come le GPU, non possono accedervi in modo efficiente. Questo problema è aggravato in un'infrastruttura di cloud ibrido in cui alcuni carichi di lavoro operano nel cloud e alcuni si trovano on-premise o in un ambiente HPC completamente diverso.</block>
  <block id="2b8ab86ccf473cca225e50ddb8c47e25" category="paragraph">In questo documento, presentiamo una nuova soluzione che consente ai professionisti IT e ai data engineer di creare una piattaforma di cloud ai realmente ibrido con un data hub consapevole della topologia che consente ai data scientist di creare istantaneamente e automaticamente una cache dei propri set di dati in prossimità delle proprie risorse di calcolo. ovunque si trovino. Di conseguenza, non solo è possibile ottenere un training con modelli ad alte performance, ma si creano anche ulteriori benefici, tra cui la collaborazione di diversi professionisti dell'ai, che hanno accesso immediato a cache, versioni e linee di dati all'interno di un hub di versione del set di dati.</block>
  <block id="3bc3b194b0ef70e2e6ce113f819619c4" category="inline-link-macro">Pagina successiva: Panoramica del caso d'utilizzo e definizione del problema</block>
  <block id="3eb8a6b81400ec3a497fb59a7e6f4360" category="paragraph"><block ref="3eb8a6b81400ec3a497fb59a7e6f4360" category="inline-link-macro-rx"></block></block>
  <block id="3a607d0e3fa64fd7558e11352f751dd0" category="summary">La soluzione NetApp ai Control Plane non dipende da questo hardware specifico.</block>
  <block id="976cf3edd8adeff2e75cd7a9dd0dae21" category="paragraph">La soluzione NetApp ai Control Plane non dipende da questo hardware specifico. La soluzione è compatibile con qualsiasi appliance di storage fisico, istanza software-defined o servizio cloud NetApp, supportato da Trident. Ad esempio, un sistema di storage NetApp AFF, Azure NetApp Files, NetApp Cloud Volumes Service, un'istanza di storage NetApp ONTAP Select definita tramite software o un'istanza di NetApp Cloud Volumes ONTAP. Inoltre, la soluzione può essere implementata su qualsiasi cluster Kubernetes purché la versione di Kubernetes utilizzata sia supportata da Kubeflow e NetApp Trident. Per un elenco delle versioni di Kubernetes supportate da Kubeflow, vedere la<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>. Per un elenco delle versioni di Kubernetes supportate da Trident, vedere<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>. Per informazioni dettagliate sull'ambiente utilizzato per la convalida della soluzione, consultare le tabelle seguenti.</block>
  <block id="2e4fd4a404800f52299c132a3403dc72" category="cell">Componente dell'infrastruttura</block>
  <block id="4152ac69f367cb5f64dfbc247dd41db0" category="cell">Host di salto per l'implementazione</block>
  <block id="583a65df9db4119165f5ea0abaa50281" category="cell">MACCHINA VIRTUALE</block>
  <block id="204dd0a482d284a7fb87c908f713f9bd" category="cell">Ubuntu 20.04.2 LTS</block>
  <block id="f341fd2fe180518e152be2d6fb4ec20b" category="cell">Nodi master Kubernetes</block>
  <block id="a89c263b82f7c7f61c9b6c93080f8425" category="cell">Nodi di lavoro Kubernetes</block>
  <block id="76a7e6383604f84ace970ce86ba76a9f" category="cell">Kubernetes nodi di lavoro GPU</block>
  <block id="f89b34b046a8d6e3137c95861fa3cf8a" category="cell">NVIDIA DGX-1 (bare-metal)</block>
  <block id="eba551f3f972830c55b1c9bef15b5f26" category="cell">NVIDIA DGX OS 4.0.5 (basato su Ubuntu 18.04.2 LTS)</block>
  <block id="0911ffdbb76c891f964e39a07eb6b697" category="cell">1 coppia ha</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="cell">NetApp AFF A220</block>
  <block id="d1d73cf191d1afbd40e85644467cae8b" category="cell">NetApp ONTAP 9.7 P6</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">Componente software</block>
  <block id="47354877541923135499c38a6606138a" category="cell">2.0.1</block>
  <block id="9ba69bd971d430b368ce3f0286c8e77c" category="cell">Helm Chart di Apache Airflow</block>
  <block id="ecfa741d55b7b1a85bd61a2307877c8c" category="cell">8.0.8</block>
  <block id="fd99a7ef225418315b041ad631a5674c" category="cell">19.03.12</block>
  <block id="56765472680401499c79732468ba4340" category="cell">1.2</block>
  <block id="48d02190984e4f8526f99f9cd9550e08" category="cell">1.18.9</block>
  <block id="d58d49f83f534f5d71b20750bb7927c7" category="cell">21.01.2</block>
  <block id="7a04e1f765218bcbfc633ef331b312b8" category="inline-link-macro">61898cdfda</block>
  <block id="7855beff2fafbce2cf0df4d67f8dfed7" category="cell">Funzionalità di implementazione di Trident dalla filiale master al momento del commit <block ref="686ead03155c78694e1a59db0970fc1a" category="inline-link-macro-rx"></block>; Tutte le altre funzionalità dalla versione 21.03</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">Supporto</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link-macro">Contatta NetApp</block>
  <block id="a1773dfa99aa26853e90886d55e0d05a" category="paragraph">NetApp non offre supporto Enterprise per Apache Airflow, Docker, Kubeflow, Kubernetes o NVIDIA DeepOps. Se sei interessato a una soluzione completamente supportata con funzionalità simili alla soluzione NetApp ai Control Plane, <block ref="103a4ac9affe57bb7edb7796bfdeb684" category="inline-link-macro-rx"></block> Informazioni sulle soluzioni ai/ML completamente supportate che NetApp offre insieme ai partner.</block>
  <block id="26c21566450ecb01d82e6d0e3f7ef1a3" category="inline-link-macro">Pagina successiva: Implementazione di Kubernetes.</block>
  <block id="0635bed13bdc0ace58fec0264ac3d119" category="paragraph"><block ref="0635bed13bdc0ace58fec0264ac3d119" category="inline-link-macro-rx"></block></block>
  <block id="d6b1f830356956d1f4b73438f8604232" category="summary">NVIDIA ai Enterprise con NetApp e VMware - utilizza il software NVIDIA NGC - Setup</block>
  <block id="d0dad2e446397223579c27c4071bd112" category="inline-link-macro">Precedente: Utilizzo del software NVIDIA NGC.</block>
  <block id="149dec50621ec3639bea5fc28effa6cf" category="paragraph"><block ref="149dec50621ec3639bea5fc28effa6cf" category="inline-link-macro-rx"></block></block>
  <block id="7bb37c1d3fb64e908e6704f53b5fe4a8" category="paragraph">In questa sezione vengono descritte le operazioni di configurazione iniziali da eseguire per utilizzare il software NVIDIA NGC Enterprise in un ambiente NVIDIA ai Enterprise.</block>
  <block id="6641666d7bc2748bab0ac80cdec3a2a3" category="inline-link-macro">Setup iniziale</block>
  <block id="512338e48541699ec73dae999f67080a" category="paragraph">Prima di eseguire i passaggi descritti in questa sezione, si presuppone che il software host NVIDIA ai EnEnterprise sia già stato implementato seguendo le istruzioni riportate nella <block ref="a8e4d2617194ed990c0124f2cc8aee91" category="inline-link-macro-rx"></block> pagina.</block>
  <block id="c23799b3650257af14b8af5acb107354" category="section-title">Creare una VM ospite Ubuntu con vGPU</block>
  <block id="0271f6ade1f60c92c6548f0e5c440e4e" category="inline-link-macro">Guida all'implementazione di NVIDIA ai Enterprise</block>
  <block id="4be8ecb3320915437222a84e9761bcec" category="paragraph">Innanzitutto, è necessario creare una macchina virtuale guest Ubuntu 20.04 con vGPU. Per creare una macchina virtuale guest Ubuntu 20.04 con vGPU, seguire le istruzioni riportate nella <block ref="2009ba36309e23fc0bb68cec4d4a3e0d" category="inline-link-macro-rx"></block>.</block>
  <block id="70c95294a49e1475adbde86d8eae754e" category="section-title">Scaricare e installare il software NVIDIA Guest</block>
  <block id="6148d2809a69d7225df7c6dcc1b5f94f" category="inline-link-macro">NVIDIA ai Enterprise Quick Start Guide</block>
  <block id="8f3d19df984dedd40b9998136343e036" category="paragraph">Quindi, è necessario installare il software guest NVIDIA richiesto nella macchina virtuale guest creata al passaggio precedente. Per scaricare e installare il software guest NVIDIA richiesto nella macchina virtuale guest, seguire le istruzioni riportate nelle sezioni 5.1-5.4 della <block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>.</block>
  <block id="15186686bd7e9c36683658388b6865b0" category="admonition">Quando si eseguono le attività di verifica descritte nella sezione 5.4, potrebbe essere necessario utilizzare un tag di versione dell'immagine contenitore CUDA diverso poiché l'immagine contenitore CUDA è stata aggiornata dopo la scrittura della guida. Nella nostra convalida, abbiamo utilizzato "nvidia/cuda:11.0.3-base-ubuntu20.04".</block>
  <block id="f43e7f8a79b8984748fff81eeb0f8c5f" category="section-title">Scarica i container ai/Analytics Framework</block>
  <block id="939ac3b79a18fc027a13bea0aeebcd3c" category="paragraph">Quindi, devi scaricare le immagini container di ai o del framework di analisi necessarie da NVIDIA NGC in modo che siano disponibili all'interno della tua macchina virtuale guest. Per scaricare i container del framework all'interno della macchina virtuale guest, seguire le istruzioni riportate nella <block ref="7ea494a5b1819fa63a0ad0f42cf94b43" category="inline-link-macro-rx"></block>.</block>
  <block id="5a8b2b886d790892b5beca474e789276" category="section-title">Installare e configurare il NetApp DataOps Toolkit</block>
  <block id="a225239f36328db667324928281cd834" category="paragraph">Quindi, è necessario installare il NetApp DataOps Toolkit per ambienti tradizionali all'interno della macchina virtuale guest. Il toolkit NetApp DataOps può essere utilizzato per gestire volumi di dati scale-out sul sistema ONTAP direttamente dal terminale all'interno della macchina virtuale guest. Per installare il NetApp DataOps Toolkit nella macchina virtuale guest, eseguire le seguenti operazioni.</block>
  <block id="e0288a23fbe1bfdb5f5b06d39e315992" category="list-text">Installare il pip.</block>
  <block id="bb5f723fd408b79a93de1e726de66dd1" category="list-text">Disconnettersi dal terminale della macchina virtuale guest e quindi effettuare nuovamente l'accesso.</block>
  <block id="c456f18c285a54b87c3bc96f0ee32ebb" category="list-text">Configurare il NetApp DataOps Toolkit. Per completare questo passaggio, sono necessari i dettagli di accesso API per il sistema ONTAP. Potrebbe essere necessario ottenerli dall'amministratore dello storage.</block>
  <block id="defe5f6be79f86b85d956d3e53c7ac4d" category="section-title">Creare un modello di macchina virtuale guest</block>
  <block id="d5d979be97f5a76cf2676ef5a9c7f071" category="paragraph">Infine, è necessario creare un modello di macchina virtuale basato sulla macchina virtuale guest. Sarà possibile utilizzare questo modello per creare rapidamente macchine virtuali guest per l'utilizzo del software NVIDIA NGC.</block>
  <block id="fec1fe0b41ba3927cfb9ac7c0507a1f5" category="paragraph">Per creare un modello di macchina virtuale in base alla macchina virtuale guest, accedere a VMware vSphere, fare clic sul nome della macchina virtuale guest, scegliere "Clone", "Clone to Template...", quindi seguire la procedura guidata.</block>
  <block id="05e042a4870614727b5012704b95e5ec" category="paragraph"><block ref="05e042a4870614727b5012704b95e5ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ad90a409faffb6ba8eef6ec1658543c" category="inline-link-macro">Segue: Esempio di caso d'utilizzo - lavoro di training TensorFlow.</block>
  <block id="2dbc93dcf9e19b9e4c3cdac9786d0d7d" category="paragraph"><block ref="2dbc93dcf9e19b9e4c3cdac9786d0d7d" category="inline-link-macro-rx"></block></block>
  <block id="0e85d8fd0ce7acdba87f57325a14b3fb" category="summary">Come indicato nella sezione precedente, gli errori vengono propagati in tutta la pipeline ogni volta che vi sono due o più modelli di apprendimento automatico in esecuzione in sequenza. Per questa soluzione, il sentimento della frase è il fattore più importante nella misurazione del livello di rischio azionario dell'azienda. Il modello da voce a testo, sebbene essenziale per la pipeline, funge da unità di pre-elaborazione prima che i sentimenti possano essere previsti.</block>
  <block id="6700d3710d10e74d6e48f994b760d48b" category="doc">Risultati della convalida</block>
  <block id="ee4eec78ae095f539af53c130e976afa" category="inline-link-macro">Precedente: Implementazione dell'analisi del sentimento del centro di supporto.</block>
  <block id="ac96c8f3af95b93c2683c2124998e668" category="paragraph"><block ref="ac96c8f3af95b93c2683c2124998e668" category="inline-link-macro-rx"></block></block>
  <block id="2e10a4ae90aad11c07592a14fbf8c5c6" category="paragraph">Come indicato nella sezione precedente, gli errori vengono propagati in tutta la pipeline ogni volta che vi sono due o più modelli di apprendimento automatico in esecuzione in sequenza. Per questa soluzione, il sentimento della frase è il fattore più importante nella misurazione del livello di rischio azionario dell'azienda. Il modello da voce a testo, sebbene essenziale per la pipeline, funge da unità di pre-elaborazione prima che i sentimenti possano essere previsti. Ciò che conta realmente è la differenza di sentimento tra le frasi di verità e le frasi previste. Questo serve come proxy per il tasso di errore di parola (WER). La precisione del parlato-to-text è importante, ma il WER non viene utilizzato direttamente nella metrica finale della pipeline.</block>
  <block id="0fc4c7871adf5db8dd2b13fc4c381da8" category="paragraph">Queste metriche di sentimento possono essere calcolate per il punteggio F1, il richiamo e la precisione di ciascuna frase. I risultati possono quindi essere aggregati e visualizzati all'interno di una matrice di confusione, insieme agli intervalli di confidenza per ciascuna metrica.</block>
  <block id="66554c8f1474c5658d17e23710901f98" category="paragraph">Il vantaggio dell'utilizzo del transfer learning è un aumento delle performance del modello per una frazione dei requisiti dei dati, dei tempi di formazione e dei costi. I modelli perfezionati devono anche essere confrontati con le versioni di riferimento per garantire che l'apprendimento del trasferimento migliori le performance invece di comprometterle. In altre parole, il modello ottimizzato dovrebbe funzionare meglio sui dati del centro di supporto rispetto al modello preaddestrato.</block>
  <block id="6e979ee914c9401fddd049d16cdef66a" category="section-title">Valutazione della pipeline</block>
  <block id="7f109f66c71a1fd15436d1c413354c41" category="cell">Caso di test</block>
  <block id="e7f1ec3a5f35af805407a8a531eefb79" category="cell">Numero del test</block>
  <block id="6bf1af9a7f1b6dd6cca4b7434097ad94" category="cell">Metrica del sentimento della pipeline</block>
  <block id="beed3529b961c63b785104d7a17cf5f4" category="cell">Prerequisiti del test</block>
  <block id="c7320b1f70fd8a9831e530d17a82f34d" category="cell">Modelli ottimizzati per modelli di analisi del parlato-to-text e del sentimento</block>
  <block id="9d5b1bc6dcdedf0c8750e543fab75738" category="cell">Risultato previsto</block>
  <block id="74015a89b882f01e94433a9c1f1c904c" category="cell">La metrica del sentimento del modello ottimizzato offre prestazioni migliori rispetto al modello originale preaddestrato.</block>
  <block id="68d279a19e31962e0ab0b648f25c07ee" category="list-text">Calcola la metrica del sentimento per il modello di riferimento.</block>
  <block id="b6168629c9e5a47b0637aa362112642d" category="list-text">Calcola la metrica del sentimento per il modello ottimizzato.</block>
  <block id="97ae5da5f745d90cf815a206b3549e0a" category="list-text">Calcola la differenza tra queste metriche.</block>
  <block id="fc997f472d1b5e66aadb364e10c29f4f" category="list-text">Calcolare la media delle differenze tra tutte le frasi.</block>
  <block id="c6b3b1378b2e31169a4a1cd4c20691c8" category="inline-link-macro">Avanti: Video e demo.</block>
  <block id="6016219a0b0ad0bb3594f964b5e6396d" category="paragraph"><block ref="6016219a0b0ad0bb3594f964b5e6396d" category="inline-link-macro-rx"></block></block>
  <block id="4adfb8f589471885ed2256c4719146a6" category="doc">TR-4815: NetApp AFF A800 e Fujitsu Server PRIMERGY GX2570 M5 per i carichi di lavoro di training modello ai e ML</block>
  <block id="5f2ab39ba2f8133927b3b4608a712d5b" category="paragraph">David Arnette, NetApp Takashi Oishi, Fujitsu</block>
  <block id="62c32325e658b728843c4f250b5d1547" category="paragraph">Questa soluzione si concentra su un'architettura scale-out per implementare sistemi di intelligenza artificiale con sistemi storage NetApp e server Fujitsu. La soluzione è stata validata con benchmark di training MLperf v0.6 utilizzando server Fujitsu GX2570 e un sistema storage NetApp AFF A800.</block>
  <block id="d6f6c54736f64c202c28a1736214c268" category="paragraph"><block ref="d6f6c54736f64c202c28a1736214c268" category="inline-link-macro-rx"></block></block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">Mike Oglesby, Technical Marketing Engineer, NetApp</block>
  <block id="94a8512f59eafd68b470105fc3269fd4" category="list-text">Santosh Rao, Senior Technical Director di NetApp</block>
  <block id="17e1dd6389643aeecf567ba08bf1df2c" category="paragraph"><block ref="17e1dd6389643aeecf567ba08bf1df2c" category="inline-link-macro-rx"></block></block>
  <block id="be52c99c6345cb49ab79a79b9565c737" category="doc">TR-4785: Implementazione dell'ai con NetApp e-Series e BeeGFS</block>
  <block id="36f4667e440709d475f1c5db4ecae97e" category="paragraph">Nagalakshmi Raju, Daniel Landes, Nathan Swartz, Amine Bennani, NetApp</block>
  <block id="c74f37bd5e8951b2feda7d19b03326e9" category="paragraph">Le applicazioni di intelligenza artificiale (ai), machine learning (ML) e deep learning (DL) implicano grandi set di dati e calcoli elevati. Per eseguire con successo questi workload, è necessaria un'infrastruttura agile che consenta di scalare perfettamente i nodi di storage e di calcolo. Questo report include le fasi per l'esecuzione di un modello di training ai in una modalità distribuita, che consente una scalabilità perfetta dei nodi di calcolo e storage. Il report include anche diverse metriche delle performance per mostrare come una soluzione che combina lo storage NetApp e-Series con il file system parallelo BeeGFS offre una soluzione semplice, flessibile e conveniente per i carichi di lavoro ai.</block>
  <block id="2ca630161d7251bb59a9e458ddef241c" category="paragraph"><block ref="2ca630161d7251bb59a9e458ddef241c" category="inline-link-macro-rx"></block></block>
  <block id="f521e3eae9fd2145ce8aeede6602641d" category="summary">In questa sezione vengono descritte le considerazioni di progettazione relative ai diversi componenti di questa soluzione.</block>
  <block id="648bdcd0b9a0f83d7b068dbed3c21c07" category="doc">Considerazioni di progettazione</block>
  <block id="5b1c62f1e35074e19185d9341b492c54" category="inline-link-macro">Precedente: Architettura.</block>
  <block id="b180067c966e23ba80c92f3bb1bf6745" category="paragraph"><block ref="b180067c966e23ba80c92f3bb1bf6745" category="inline-link-macro-rx"></block></block>
  <block id="35ff22a5291df56d5075c29d8dc65044" category="section-title">Progettazione di rete e calcolo</block>
  <block id="49d41bdb2234e0a4330f0c9d7d03853a" category="paragraph">A seconda delle restrizioni sulla sicurezza dei dati, tutti i dati devono rimanere all'interno dell'infrastruttura del cliente o in un ambiente sicuro.</block>
  <block id="5a20c2b759137410d60f5ce368ca45d2" category="paragraph"><block ref="5a20c2b759137410d60f5ce368ca45d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d6e133bd239a98d559f693ee2ff5ecc" category="section-title">Progettazione dello storage</block>
  <block id="3051d856c7b26f6d385279d67a8a532b" category="paragraph">Il NetApp DataOps Toolkit funge da servizio principale per la gestione dei sistemi storage. DataOps Toolkit è una libreria Python che consente a sviluppatori, data scientist, ingegneri DevOps e data engineer di eseguire diverse attività di gestione dei dati, come il provisioning quasi istantaneo di un nuovo volume di dati o di un'area di lavoro JupyterLab, la clonazione quasi istantanea di un volume di dati o di un'area di lavoro JupyterLab, E lo snap-shoting quasi istantaneo di un volume di dati o di uno spazio di lavoro JupyterLab per la tracciabilità o il baselining. Questa libreria Python può funzionare come un'utility a riga di comando o una libreria di funzioni che possono essere importate in qualsiasi programma Python o Jupyter notebook.</block>
  <block id="6f9e8585e5f750b8ceb149639b1e25e6" category="section-title">Best practice RIVA</block>
  <block id="7ecab6bd65c2f169e987be2f59219357" category="inline-link">best practice per i dati</block>
  <block id="f51b8fa6c731ea53318149e50e826ddb" category="paragraph">NVIDIA offre diverse funzionalità generali<block ref="f6aee1daf7f2fd9cd207fcd26f08d8be" category="inline-link-rx"></block> Per utilizzare RIVA:</block>
  <block id="20430e77ba2ecbe15261761c8f4fa2c4" category="list-text">*Se possibile, utilizzare formati audio senza perdita di dati.* l'utilizzo di codec con perdita di dati come MP3 può ridurre la qualità.</block>
  <block id="8b3e389f067f32da1e1ab7df2b8d8155" category="list-text">*Aumentare i dati di training.* l'aggiunta di rumore di fondo ai dati di training audio può inizialmente ridurre la precisione e aumentare la robustezza.</block>
  <block id="b37d69a795b4d7bb6e0f28a42c3ef8ae" category="list-text">*Limitare la dimensione del vocabolario se si utilizza il testo scartato.* molte fonti online contengono messaggi o voci accessorie e parole non comuni. La rimozione di questi elementi può migliorare il modello linguistico.</block>
  <block id="6afe4c71ada39a70da349380efbad345" category="list-text">*Se possibile, utilizzare una frequenza di campionamento minima di 16 kHz.* tuttavia, provare a non ricampionare, perché in questo modo si riduce la qualità audio.</block>
  <block id="cab3977e4ad163e19ab6245a9b09f541" category="paragraph">Oltre a queste Best practice, i clienti devono dare la priorità alla raccolta di un set di dati campione rappresentativo con etichette accurate per ogni fase della pipeline. In altre parole, il set di dati di esempio dovrebbe riflettere in modo proporzionale le caratteristiche specificate esemplificate in un set di dati di destinazione. Allo stesso modo, gli annotatori dei set di dati hanno la responsabilità di bilanciare la precisione e la velocità dell'etichettatura in modo da massimizzare la qualità e la quantità dei dati. Ad esempio, questa soluzione di Support Center richiede file audio, testo etichettato ed etichette di sentimento. La natura sequenziale di questa soluzione significa che gli errori dall'inizio della pipeline vengono propagati fino alla fine Se i file audio sono di scarsa qualità, anche le trascrizioni di testo e le etichette di sentimento saranno.</block>
  <block id="0b6b65c9613285433178682e3550355c" category="paragraph">Questa propagazione degli errori si applica allo stesso modo ai modelli addestrati su questi dati. Se le previsioni del sentimento sono accurate al 100% ma il modello da voce a testo non funziona correttamente, la pipeline finale è limitata dalle trascrizioni audio-testo iniziali. È essenziale che gli sviluppatori considerino le performance di ciascun modello singolarmente e come un componente di una pipeline più ampia. In questo caso specifico, l'obiettivo finale è sviluppare una pipeline in grado di prevedere con precisione il sentimento. Pertanto, la metrica generale su cui valutare la pipeline è la precisione dei sentimenti, che la trascrizione vocale-testuale influisce direttamente.</block>
  <block id="f3b552e561f520013398b3be885a4420" category="paragraph"><block ref="f3b552e561f520013398b3be885a4420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac1ce31a9f2a1a3a478bb69589e180bd" category="paragraph">Il NetApp DataOps Toolkit integra la pipeline per il controllo della qualità dei dati attraverso l'utilizzo della sua tecnologia di cloning dei dati quasi istantanea. Ogni file etichettato deve essere valutato e confrontato con i file etichettati esistenti. La distribuzione di questi controlli di qualità nei vari sistemi di storage dei dati garantisce che questi controlli vengano eseguiti in modo rapido ed efficiente.</block>
  <block id="6d61a746e66a6545c5c9faf68668e013" category="inline-link-macro">Avanti: Implementazione dell'analisi del sentimento del centro di supporto.</block>
  <block id="58a113e09ecc7941870d9bcc2d2ee3df" category="paragraph"><block ref="58a113e09ecc7941870d9bcc2d2ee3df" category="inline-link-macro-rx"></block></block>
  <block id="e1196fc000d661461f32bcaab7319c6a" category="doc">Personalizza gli stati e i flussi per i casi d'utilizzo retail</block>
  <block id="1e3ecab57c1572b4a25412b1e395562a" category="paragraph">È possibile personalizzare gli stati e i flussi di Dialog Manager in base ai casi di utilizzo specifici. Nel nostro esempio di vendita al dettaglio, abbiamo i seguenti quattro file yaml per indirizzare la conversazione in base a diversi intenti.</block>
  <block id="608f6d7dfd7bc98630446f0c601cc730" category="paragraph">Se il seguente elenco di nomi di file e la descrizione di ciascun file:</block>
  <block id="77d10e2958e3d21f89adae8647e8d0d2" category="list-text"><block ref="ef7c28f5093b59a07761555c8914df26" prefix="" category="inline-code"></block>: Definisce i flussi e gli stati principali della conversazione e indirizza il flusso agli altri tre file yaml, se necessario.</block>
  <block id="96b445ea5c6b049dfc1250466b6bdf2e" category="list-text"><block ref="dfc9a806326d590aa4ccf49aa6909cda" prefix="" category="inline-code"></block>: Contiene stati relativi a domande al dettaglio o punti di interesse. Il sistema fornisce le informazioni del negozio più vicino o il prezzo di un dato articolo.</block>
  <block id="17a0ea5055e6be908d7e2f6f983aa471" category="list-text"><block ref="6e08d9d65c68d5f447f4fd239052c12e" prefix="" category="inline-code"></block>: Contiene gli stati relativi alle domande sul meteo. Se non è possibile determinare la posizione, il sistema pone una domanda di follow-up per chiarire.</block>
  <block id="ade7d8cc2b23f24add45c4096dd41795" category="list-text"><block ref="b7dc1d2ced2caa9352158983c5ffeda1" prefix="" category="inline-code"></block>: Gestisce i casi in cui gli intenti dell'utente non rientrano nei tre file yaml precedenti. Dopo aver visualizzato un messaggio di errore, il sistema torna ad accettare le domande dell'utente.le sezioni seguenti contengono le definizioni dettagliate per questi file yaml.</block>
  <block id="ef7c28f5093b59a07761555c8914df26" category="section-title">main_flow.yml</block>
  <block id="dfc9a806326d590aa4ccf49aa6909cda" category="section-title">retail_flow.yml</block>
  <block id="6e08d9d65c68d5f447f4fd239052c12e" category="section-title">weather_flow.yml</block>
  <block id="b7dc1d2ced2caa9352158983c5ffeda1" category="section-title">error_flow.yml</block>
  <block id="c6496825f1a87696b60935af9416283a" category="inline-link-macro">Successivo: Connettersi alle API di terze parti come motore di adempimento</block>
  <block id="3a9d38bca913120b9d3638cb194cd7e6" category="paragraph"><block ref="3a9d38bca913120b9d3638cb194cd7e6" category="inline-link-macro-rx"></block></block>
  <block id="3bb420314fa4b29837c4b0528524000f" category="section-title">Piano di controllo ai e ai di NetApp ONTAP</block>
  <block id="3cfbc3bac23f6bb9e7ebdc6deefeaf1d" category="paragraph">L'architettura NetApp ONTAP ai, sviluppata e verificata da NetApp e NVIDIA, è basata su sistemi NVIDIA DGX e sistemi storage connessi al cloud. Questa architettura di riferimento offre alle organizzazioni IT i seguenti vantaggi:</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">Offre una gamma di opzioni di storage per diverse performance e costi</block>
  <block id="6fa0f6cc1d5d12069641e73217a17be2" category="paragraph">NetApp ONTAP ai integra perfettamente i sistemi DGX e i sistemi storage NetApp AFF A800 con reti all'avanguardia. I sistemi NetApp ONTAP ai e DGX semplificano le implementazioni ai eliminando la complessità e le congetture di progettazione. I clienti possono iniziare a crescere in maniera ininterrotta e allo stesso tempo gestire in modo intelligente i dati dall'edge al core, fino al cloud e viceversa.</block>
  <block id="bdc094a519f73076386a8bf2948832a6" category="paragraph">NetApp ai Control Plane è una soluzione per la gestione di dati e esperimenti di ai, ML e deep learning (DL) per data scientist e data engineer. Man mano che le organizzazioni aumentano l'utilizzo dell'ai, devono affrontare molte sfide, tra cui la scalabilità dei workload e la disponibilità dei dati. NetApp ai Control Plane affronta queste sfide attraverso funzionalità, come la clonazione rapida di uno spazio dei nomi dei dati come faresti con un Git repo, e la definizione e l'implementazione di workflow di training ai che incorporano la creazione quasi istantanea di dati e linee di base dei modelli per la tracciabilità e il controllo delle versioni. Con NetApp ai Control Plane, puoi replicare perfettamente i dati tra siti e regioni e fornire rapidamente spazi di lavoro Jupyter notebook con accesso a set di dati di grandi dimensioni.</block>
  <block id="22101b8498dea1c2e2e35bd4868847a4" category="paragraph">Run:ai ha costruito la prima piattaforma di orchestrazione e virtualizzazione al mondo per l'infrastruttura ai. Astrando i carichi di lavoro dall'hardware sottostante, Run:ai crea un pool condiviso di risorse GPU che può essere sottoposto a provisioning dinamico, consentendo un'orchestrazione efficiente dei carichi di lavoro ai e un utilizzo ottimizzato delle GPU. I data scientist possono consumare senza problemi enormi quantità di energia GPU per migliorare e accelerare la ricerca, mentre i team IT mantengono un controllo centralizzato e cross-site e una visibilità in tempo reale su provisioning, accodamento e utilizzo delle risorse. La piattaforma Run:ai si basa su Kubernetes, consentendo una semplice integrazione con i flussi di lavoro IT e di data science esistenti.</block>
  <block id="ae00256db8d45ecdaf9c364a96821417" category="paragraph">La piattaforma Run:ai offre i seguenti vantaggi:</block>
  <block id="d472807c15e94ef6053e95521ff7e838" category="list-text">*Time-to-innovation più veloce.* utilizzando i meccanismi di pool di risorse Run:ai, accodamento e prioritizzazione insieme a un sistema storage NetApp, i ricercatori vengono rimossi dai problemi di gestione dell'infrastruttura e possono concentrarsi esclusivamente sulla scienza dei dati. Esegui: I clienti ai e NetApp aumentano la produttività eseguendo tutti i carichi di lavoro necessari senza colli di bottiglia della pipeline di dati o di calcolo.</block>
  <block id="2707d068deb9b46967615c70c806e0d8" category="list-text">*Maggiore produttività del team.* gli algoritmi Run:ai Fairness garantiscono che tutti gli utenti e i team ottenano la loro giusta quota di risorse. È possibile preimpostare le policy relative ai progetti prioritari e la piattaforma consente l'allocazione dinamica delle risorse da un utente o team all'altro, aiutando gli utenti a ottenere un accesso tempestivo alle risorse GPU più ambite.</block>
  <block id="faa5854c7e84507b88cba1c0ec1a9aaf" category="list-text">*Utilizzo migliorato della GPU.* il programma Run:ai Scheduler consente agli utenti di utilizzare facilmente GPU frazionali, GPU interi e nodi multipli di GPU per la formazione distribuita su Kubernetes. In questo modo, i carichi di lavoro ai vengono eseguiti in base alle tue esigenze, non alla capacità. I team di data science sono in grado di eseguire più esperimenti di ai sulla stessa infrastruttura.</block>
  <block id="d9533ea5c6cb975dff314dace88f2aa4" category="paragraph"><block ref="d9533ea5c6cb975dff314dace88f2aa4" category="inline-link-macro-rx"></block></block>
  <block id="4ed0a51bc1c995651eec6f50591eec1a" category="section-title">NetApp ONTAP ai e Cloud Sync</block>
  <block id="bff183f31dd9706bece9767f4388a819" category="paragraph">L'architettura NetApp ONTAP ai, basata su sistemi NVIDIA DGX e sistemi storage connessi al cloud, è stata sviluppata e verificata da NetApp e NVIDIA. Questa architettura di riferimento offre alle organizzazioni IT i seguenti vantaggi:</block>
  <block id="88acd7d612f76d7928b6b0448806e1ea" category="list-text">Offre una vasta gamma di opzioni di storage per diverse esigenze di performance e costi NetApp ONTAP ai integra perfettamente i sistemi DGX e i sistemi storage NetApp AFF A220 con networking all'avanguardia. I sistemi NetApp ONTAP ai e DGX semplificano le implementazioni ai eliminando la complessità e le congetture di progettazione. I clienti possono iniziare a crescere in maniera ininterrotta e allo stesso tempo gestire in modo intelligente i dati dall'edge al core, fino al cloud e viceversa.</block>
  <block id="69be3bc10a1ad78dbe823def1907c730" category="paragraph">NetApp Cloud Sync consente di spostare facilmente i dati su diversi protocolli, tra due condivisioni NFS, due condivisioni CIFS o una condivisione file e Amazon S3, Amazon Elastic file System (EFS) o Azure Blob Storage. Il funzionamento Active-Active consente di continuare a lavorare contemporaneamente con l'origine e la destinazione, sincronizzando in modo incrementale le modifiche dei dati quando necessario. Grazie alla possibilità di spostare e sincronizzare in modo incrementale i dati tra qualsiasi sistema di origine e di destinazione, on-premise o basato su cloud, Cloud Sync offre una vasta gamma di nuovi modi per utilizzare i dati. La migrazione dei dati tra sistemi on-premise, cloud on-boarding e migrazione del cloud o collaboration e analytics dei dati diventa facilmente realizzabile. La figura seguente mostra le fonti e le destinazioni disponibili.</block>
  <block id="1e01782ef13699818c9eb9eab796bffc" category="paragraph">Nei sistemi di intelligenza artificiale conversa, gli sviluppatori possono sfruttare Cloud Sync per archiviare la cronologia delle conversazioni dal cloud ai data center per consentire la formazione offline dei modelli NLP (Natural Language Processing). Attraverso modelli di training per riconoscere più intenti, il sistema di ai convergenti sarà meglio attrezzato per gestire domande più complesse da parte degli utenti finali.</block>
  <block id="45f2cdf50f8bb89b245e814009b4244c" category="section-title">Framework multimodale NVIDIA Jarvis</block>
  <block id="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="paragraph"><block ref="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ad66827309f61fd22dc58cbbb2f8273" category="inline-link">NVIDIA Jarvis</block>
  <block id="241d985aedf9124840f9adfa9496755d" category="paragraph"><block ref="9f89431954623c8e5c580e4350b427e7" category="inline-link-rx"></block> È un framework end-to-end per la creazione di servizi di ai conversivi. Include i seguenti servizi ottimizzati per GPU:</block>
  <block id="bb3e7af8136880e3a92118c172aed302" category="list-text">Riconoscimento vocale automatico (ASR)</block>
  <block id="3c07089a439435a2998f14ea97f90825" category="list-text">Comprensione del linguaggio naturale (NLU)</block>
  <block id="8375cc1d63ce172363c4ed9c3cddd508" category="list-text">Integrazione con servizi di adempimento specifici del dominio</block>
  <block id="84fb561f92aa70d5e118f429e98ee99b" category="list-text">Text-to-speech (TTS)</block>
  <block id="9478a4e1be70e1be0fdd56f3929bbdc2" category="list-text">I servizi basati su computer Vision (CV) Jarvis utilizzano modelli di deep learning all'avanguardia per affrontare il complesso e impegnativo compito dell'ai conversazionale in tempo reale. Per consentire un'interazione naturale e in tempo reale con un utente finale, i modelli devono completare il calcolo in meno di 300 millisecondi. Le interazioni naturali sono impegnative e richiedono un'integrazione sensoriale multimodale. Anche le pipeline dei modelli sono complesse e richiedono un coordinamento tra i servizi indicati sopra.</block>
  <block id="c29efa8b1d5c9d6d647a8ce72bef1b74" category="paragraph">Jarvis è un framework applicativo completamente accelerato per la creazione di servizi ai di conversazione multimodale che utilizzano una pipeline di deep learning end-to-end. Il framework Jarvis include modelli di ai conversazionali preformati, strumenti e servizi end-to-end ottimizzati per le attività vocali, di visione e NLU. Oltre ai servizi di intelligenza artificiale, Jarvis ti consente di unire contemporaneamente vision, audio e altri input dei sensori per offrire funzionalità come conversazioni multi-utente e multi-contesto in applicazioni come assistenti virtuali, diarizzazione multiutente e assistenti di call center.</block>
  <block id="dc3652fc64a2a6ea2a3cfd5c40443b16" category="paragraph"><block ref="4282ee73b9eecd67e90ed51f4f36b077" category="inline-link-rx"></block> È un toolkit Python open-source per la creazione, la formazione e la messa a punto di modelli di ai conversazionali allo stato dell'arte con accelerazione GPU utilizzando interfacce di programmazione applicativa (API) di facile utilizzo. NEMO esegue calcoli misti di precisione utilizzando core Tensor in GPU NVIDIA e può scalare facilmente fino a più GPU per offrire le migliori performance di training possibili. NEMO viene utilizzato per creare modelli per applicazioni ASR, NLP e TTS in tempo reale, come trascrizioni di videochiamate, assistenti video intelligenti e supporto automatizzato di call center in diversi mercati verticali del settore, tra cui settore sanitario, finanziario, retail e telecomunicazioni.</block>
  <block id="4e5ae683e2a399c166a1724b0aa6952e" category="paragraph">Abbiamo utilizzato NEMO per formare modelli che riconoscono intenti complessi dalle domande degli utenti nella cronologia delle conversazioni archiviate. Questo training estende le funzionalità dell'assistente virtuale al dettaglio oltre il supporto fornito da Jarvis.</block>
  <block id="053bc62e92a61e44afd338bcb27c422f" category="section-title">Riepilogo dei casi di utilizzo al dettaglio</block>
  <block id="8b6b761738b93e745ffa4f73dd233c08" category="paragraph">Utilizzando NVIDIA Jarvis, abbiamo creato un assistente virtuale al dettaglio che accetta l'input vocale o di testo e risponde a domande relative a meteo, punti di interesse e prezzi di inventario. Il sistema ai conversazionale è in grado di ricordare il flusso di conversazione, ad esempio, porre una domanda di follow-up se l'utente non specifica la posizione per il meteo o i punti di interesse. Il sistema riconosce anche entità complesse come "cibo tailandese" o "memoria per laptop". Comprende domande di linguaggio naturale come "pioverà la prossima settimana a Los Angeles?" Una dimostrazione dell'assistente virtuale per la vendita al dettaglio è disponibile in<block ref="0ba395e7fb59bace5ff35ab3c02ad737" category="inline-link-rx"></block>.</block>
  <block id="af8f881c5074e5e10cd7a34ccbaa9e57" category="paragraph"><block ref="af8f881c5074e5e10cd7a34ccbaa9e57" category="inline-link-macro-rx"></block></block>
  <block id="9dc7cfc5bd8fb85bad9fdab5cdded288" category="doc">Esegui:Installazione ai</block>
  <block id="c1b7d088e01f6ec6ec89bf69437e4bb1" category="paragraph">Per installare Run:ai, attenersi alla seguente procedura:</block>
  <block id="7ad0483bc07dbde29ffd404af83f8305" category="list-text">Installare il cluster Kubernetes utilizzando DeepOps e configurare la classe di storage predefinita di NetApp.</block>
  <block id="16d20d34f759cd25fd7486bbc4046a50" category="list-text">Preparare i nodi GPU:</block>
  <block id="d3eff3861b26ba61222bacaa41bc0fa7" category="list-text">Verificare che i driver NVIDIA siano installati sui nodi GPU.</block>
  <block id="3683aa7fe695a205b8e40e9589c94a2e" category="list-text">Verificare che<block ref="03550f513b5eb839088628d4a360b865" prefix=" " category="inline-code"></block> è installato e configurato come runtime predefinito di docker.</block>
  <block id="cef990020518a58fb1e70a90b5df80fe" category="list-text">Esecuzione dell'installazione:ai:</block>
  <block id="e2d6778a342979b567501f951e36118a" category="inline-link">Esegui: UI Admin ai</block>
  <block id="6fc7ea9b01c6028f691aac2aeac528f1" category="list-text">Accedere a.<block ref="668d940d94d02be49a88c4cfd2736fa9" category="inline-link-rx"></block> per creare il cluster.</block>
  <block id="fe8f08cfda6726e2dcc5d0b85ed2c67d" category="list-text">Scarica il creato<block ref="6b351eac623bdfae151b8db2b05a8131" prefix=" " category="inline-code"></block> file.</block>
  <block id="b428155da5c27d208abd6c179c7669d3" category="list-text">Applicare la configurazione dell'operatore al cluster Kubernetes.</block>
  <block id="fac4447e0ea2e4cd1a2d9e2fefeab694" category="list-text">Verificare l'installazione:</block>
  <block id="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link"><block ref="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link-rx"></block></block>
  <block id="2d14c64dc5dfa79a68cd6965fbf9e4b7" category="list-text">Passare a.<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>.</block>
  <block id="feb48a27d95fc7a7e0c6db496c54d2fa" category="list-text">Accedere alla dashboard Panoramica.</block>
  <block id="09fa3891e2b39bb62217c6d097310577" category="inline-link">Installazione di Run:ai su un cluster Kubernetes on-premise</block>
  <block id="45d7be937e1eddf966adaf68562966d4" category="inline-link">Installazione della CLI Run:ai</block>
  <block id="728f8fd776de1dc47f318473052286db" category="list-text">Verificare che il numero di GPU in alto a destra rifletta il numero previsto di GPU e che i nodi GPU siano tutti nell'elenco dei server.per ulteriori informazioni sull'implementazione di Run:ai, vedere<block ref="089aa48f8d7b3b135b035765dd1e17ba" category="inline-link-rx"></block> e.<block ref="f2f48a2074c9edc0c2dea174863a4f6e" category="inline-link-rx"></block>.</block>
  <block id="db9d1f740f050b1d20ab43a459bb225a" category="inline-link-macro">Avanti: Esegui dashboard e viste ai</block>
  <block id="c56b5d251d18e9b020f95696fef9f0b9" category="paragraph"><block ref="c56b5d251d18e9b020f95696fef9f0b9" category="inline-link-macro-rx"></block></block>
  <block id="d577549f9b3a229c338e203a433489f6" category="summary">In questa sezione viene descritto come eseguire il peer di AKS VNET a Azure NetApp Files VNET.</block>
  <block id="e61e6d340ad05dc2e1ad0982f6857d7d" category="doc">Peer AKS VNET e Azure NetApp Files VNET</block>
  <block id="1c45d541f316a23589217be5991b1545" category="inline-link-macro">Precedente: Creare una subnet delegata per Azure NetApp Files.</block>
  <block id="786730f8769009abf0bf6400157dd16b" category="paragraph"><block ref="786730f8769009abf0bf6400157dd16b" category="inline-link-macro-rx"></block></block>
  <block id="e6ef5f0946a89d073a8f360de1038061" category="paragraph">Per eseguire il peer di AKS VNET a Azure NetApp Files VNET, attenersi alla seguente procedura:</block>
  <block id="87c2d6c506d0bf65d2c5d773474f9c0f" category="list-text">Immettere Virtual Networks nel campo di ricerca.</block>
  <block id="7680f3bc49a836c67a8b0e7d2d9ccb44" category="list-text">Selezionare<block ref="c5d2d918f55de1b8309376bc0310c265" prefix=" " category="inline-code"></block> Fare clic su di esso e immettere Peerings nel campo di ricerca.</block>
  <block id="fc3bb6a018a8f599cab21678959f92b0" category="list-text">Fare clic su +Add (Aggiungi).</block>
  <block id="1991ef5bd8e165e42c56ccaefa2f640f" category="list-text">Immettere i seguenti descrittori:</block>
  <block id="51e5b9c0a583a9afbc2f998e622fd30d" category="list-text">Il nome del collegamento di peering è<block ref="5d43607a5a0ebb50f3ea9348485daa15" prefix=" " category="inline-code"></block>.</block>
  <block id="14ac6521e2758ba95fe7be9ca6a82cd1" category="list-text">SubscriptionID e Azure NetApp Files VNET come partner di peering VNET.</block>
  <block id="70b58cb057d859d4da9f17e43ffd238c" category="list-text">Lasciare tutte le sezioni senza asterisco con i valori predefiniti.</block>
  <block id="1bb250fbf1946dd1bd7ad228032f8803" category="list-text">Fare clic su Aggiungi.</block>
  <block id="50e3209c871e4867931ef51a9344a921" category="paragraph">Per ulteriori informazioni, vedere<block ref="f81943721c88f7efe9b8252470f9ea43" category="inline-link-rx"></block>.</block>
  <block id="fd3c95528aa9718948de8d4e38b2fa2c" category="inline-link-macro">A seguire: Installare Trident.</block>
  <block id="18337fe57049583a9c04a79f64a2088f" category="paragraph"><block ref="18337fe57049583a9c04a79f64a2088f" category="inline-link-macro-rx"></block></block>
  <block id="83c4efb371f86415987632c0baa2d086" category="doc">NVA-1156-DESIGN: NetApp EF-Series ai con sistemi NVIDIA DGX A100 e BeeGFS</block>
  <block id="ff50db1ba0f8ba4a103a810e1ceb2afc" category="paragraph">Abdel Sadek, Tim Chau, Joe McCormick e David Arnette, NetApp</block>
  <block id="1d78c2c26f50714898cd986ca8147756" category="paragraph">NVA-1156-DESIGN descrive un'architettura verificata di NetApp per i carichi di lavoro di machine learning (ML) e intelligenza artificiale (ai) che utilizzano i sistemi storage NetApp EF600 NVMe, il file system parallelo BeeGFS, i sistemi NVIDIA DGX A100 e gli switch IB NVIDIA Mellanox Quantum QM8700 a 200 Gbps. Questo design è dotato di InfiniBand (IB) a 200 Gbps per lo storage e il fabric di interconnessione del cluster di calcolo per offrire ai clienti un'architettura completamente basata su IB per carichi di lavoro dalle performance elevate. Questo documento include anche i risultati dei test di benchmark per l'architettura implementata.</block>
  <block id="2003f72965a4dbc9f31bdaa3da5deaa2" category="paragraph"><block ref="2003f72965a4dbc9f31bdaa3da5deaa2" category="inline-link-macro-rx"></block></block>
  <block id="1b85c0e7f381bd6f8c3150cafe56a9f0" category="paragraph">L'architettura NetApp ONTAP ai, basata su sistemi NVIDIA DGX e sistemi storage connessi al cloud. Questa architettura di riferimento offre alle organizzazioni IT i seguenti vantaggi:</block>
  <block id="bae698d3cdcc290d6a0048c7b786446c" category="list-text">Offre una vasta gamma di opzioni di storage per diverse performance e costi. NetApp ONTAP ai integra perfettamente i sistemi DGX e i sistemi storage NetApp AFF A800 con networking all'avanguardia. I sistemi NetApp ONTAP ai e DGX semplificano le implementazioni ai eliminando la complessità e le congetture di progettazione. I clienti possono iniziare a crescere in maniera ininterrotta e allo stesso tempo gestire in modo intelligente i dati dall'edge al core, fino al cloud e viceversa.</block>
  <block id="c729dcbcad9e1c72ae15d4b823e9f311" category="paragraph">NetApp ai Control Plane è una soluzione per la gestione di dati e esperimenti di ai, ML e deep learning (DL) per data scientist e data engineer. Man mano che le organizzazioni aumentano l'utilizzo dell'ai, devono affrontare molte sfide, tra cui la scalabilità dei workload e la disponibilità dei dati. Il piano di controllo ai di NetApp affronta queste sfide attraverso funzionalità, come la clonazione rapida di uno spazio dei nomi dei dati come faresti con Git repo e la definizione e l'implementazione di workflow di training ai che incorporano la creazione quasi istantanea di dati e linee di base dei modelli per la tracciabilità e il controllo delle versioni. Con NetApp ai Control Plane, puoi replicare perfettamente i dati tra siti e regioni e fornire rapidamente spazi di lavoro Jupyter notebook con accesso a set di dati di grandi dimensioni.</block>
  <block id="42cac0fcbbddfc99b31ff898d7902c83" category="inline-link-macro">Avanti: Esegui la piattaforma ai per l'orchestrazione del carico di lavoro ai</block>
  <block id="e3683938a3c34e6a7cf5b3896258e91e" category="paragraph"><block ref="a8dcbc617641d20db42fd66f3a42caae" category="inline-link-macro-rx"></block>.</block>
  <block id="3e22ed7172d7770cfa1457b7e70b2b06" category="doc">TR-4915: Spostamento dei dati con e-Series e BeeGFS per i flussi di lavoro di ai e analytics</block>
  <block id="b85127cc663f1e3f1a6a366bb2732406" category="paragraph">Cody Harryman e Ryan Rodine, NetApp</block>
  <block id="f75519c0654938719b5319e8d452e91a" category="paragraph">TR-4915 descrive come spostare i dati da qualsiasi repository di dati in un file system BeeGFS supportato dallo storage SAN NetApp e-Series. Per le applicazioni di intelligenza artificiale (ai) e machine learning (ML), i clienti potrebbero dover spostare regolarmente grandi set di dati che superano molti petabyte di dati nei cluster BeeGFS per lo sviluppo dei modelli. Questo documento spiega come ottenere questo risultato utilizzando i tool NetApp XCP e NetApp Cloud Sync.</block>
  <block id="68a03283d8017637709e60ab77052710" category="paragraph"><block ref="68a03283d8017637709e60ab77052710" category="inline-link-macro-rx"></block></block>
  <block id="b682eee68510f6de72c9f48b832fba3c" category="inline-link"><block ref="b682eee68510f6de72c9f48b832fba3c" category="inline-link-rx"></block></block>
  <block id="3e5d8230d86c09995fcd8e9ccf335813" category="list-text">Cnvrg.io (<block ref="0691e14f48847a7f13eaf800c0f5813a" category="inline-link-rx"></block>):</block>
  <block id="6536b07bf755c64528073e655a567c32" category="list-text">CORE Cnvrg (piattaforma ML gratuita)</block>
  <block id="0a16af2994c8e10c6c5976d774430a92" category="paragraph"><block ref="0a16af2994c8e10c6c5976d774430a92" category="inline-link-rx"></block></block>
  <block id="1b21ae34f592a7f2ca92d4a44122475d" category="list-text">Documenti Cnvrg</block>
  <block id="0730c44e9dc233c7fce5d95816294f52" category="inline-link"><block ref="0730c44e9dc233c7fce5d95816294f52" category="inline-link-rx"></block></block>
  <block id="f3a2f110576ed38849e70a6bb9794ae8" category="paragraph"><block ref="f3a2f110576ed38849e70a6bb9794ae8" category="inline-link-rx"></block></block>
  <block id="c7c082299876892b4274ecfb3c3f7bcd" category="list-text">Server NVIDIA DGX-1:</block>
  <block id="d2647f7d8e79758eea27c6cdcf636638" category="list-text">Server NVIDIA DGX-1</block>
  <block id="65d1be94e9f29dc4af77bef169d5be14" category="list-text">NVIDIA Tesla V100 Tensor Core GPU</block>
  <block id="64ba1593b4427fb62b53b007d4a1c26e" category="list-text">Sistemi NetApp AFF:</block>
  <block id="092940c9deac7c0f10a0ed36613c28c2" category="paragraph"><block ref="092940c9deac7c0f10a0ed36613c28c2" category="inline-link-rx"></block></block>
  <block id="b4199ce9c494dec10c6ee051ddb413e2" category="list-text">NetApp FlashAdvantage per AFF</block>
  <block id="1cb9a8619999ebc0a2d9c07624d76166" category="list-text">Matrice di interoperabilità NetApp:</block>
  <block id="d51c982ce98a1e197c234ea0b9a5e7d9" category="paragraph"><block ref="d51c982ce98a1e197c234ea0b9a5e7d9" category="inline-link-rx"></block></block>
  <block id="7a211d267d46c5b44662098f9234fcd0" category="list-text">Networking ai ONTAP:</block>
  <block id="b8a60c56690ddfc62bd735d0b212c396" category="list-text">Switch Cisco Nexus 3232C</block>
  <block id="926dc08a3a3a3946402bb1beab6545cc" category="list-text">Switch Mellanox Spectrum serie 2000</block>
  <block id="492f548658890a1d2495b8af5cebef8c" category="paragraph"><block ref="11ff6f8fb3928ea5c0863401e5e79d17" category="inline-link-rx"></block></block>
  <block id="edb7d6728a9813b505cb306367d453e3" category="list-text">DALI</block>
  <block id="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="paragraph"><block ref="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="inline-link-rx"></block></block>
  <block id="26909d0380bdba02e2fcf7f7157cd78b" category="list-text">Horovod: Framework di deep learning distribuito open-source di Uber per TensorFlow</block>
  <block id="3ffa9619031400d374ed5c0860d434ab" category="paragraph"><block ref="3ffa9619031400d374ed5c0860d434ab" category="inline-link-rx"></block></block>
  <block id="c9cbaff7c173f4b7bc923573ca753577" category="list-text">Abilitazione delle GPU nell'ecosistema di runtime container</block>
  <block id="b3a776c1e64d267ebe62a7bf45c6c1b7" category="paragraph"><block ref="b3a776c1e64d267ebe62a7bf45c6c1b7" category="inline-link-rx"></block></block>
  <block id="ccd09fd9430cf2df88a137dbec97676b" category="paragraph"><block ref="ccd09fd9430cf2df88a137dbec97676b" category="inline-link-rx"></block></block>
  <block id="22d149e351657eac5bd1db4934498bbe" category="list-text">Set di dati e benchmark:</block>
  <block id="717108fd0999828c4a6d8290d419733b" category="list-text">Set di dati per radiografia toracica NIH</block>
  <block id="4eb7427d14327fa86230f324870dc6b8" category="paragraph"><block ref="4eb7427d14327fa86230f324870dc6b8" category="inline-link-rx"></block></block>
  <block id="f249b6ce18772b83efb8a6e58ac09d47" category="list-text">Xiaosong Wang, Yifan Peng, le Lu, Zhiyong Lu, Mohammadhadi Bagheri, Ronald Summers, ChestX-ray8: Database dei raggi X del torace su scala ospedaliera e benchmark sulla classificazione e localizzazione con supervisione debole delle malattie toraciche comuni, IEEE CVPR, pp 3462-3471, 2017TR-4841-0620</block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">Questa sezione descrive le procedure di test utilizzate per validare questa soluzione.</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">Procedura di test</block>
  <block id="ed760d2dffd7d011a7870619f7884005" category="paragraph"><block ref="ed760d2dffd7d011a7870619f7884005" category="inline-link-macro-rx"></block></block>
  <block id="bff816e8e8ddbe2a3b705d92abba6627" category="paragraph">In questa convalida abbiamo utilizzato la seguente procedura di test.</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">Configurazione del sistema operativo e dell'inferenza ai</block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">codice</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">Per AFF C190, abbiamo utilizzato Ubuntu 18.04 con driver NVIDIA e docker con supporto per GPU NVIDIA e abbiamo utilizzato MLPerf<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> Disponibile come parte dell'invio di Lenovo a MLPerf Inference v0.7.</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">Per EF280, abbiamo utilizzato Ubuntu 20.04 con driver NVIDIA e docker con supporto per GPU NVIDIA e MLPerf<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> Disponibile come parte dell'invio di Lenovo a MLPerf Inference v1.1.</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">Per impostare l'inferenza ai, segui questi passaggi:</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">Scarica i set di dati che richiedono la registrazione, il set di convalida ImageNet 2012, il set di dati Criteo Terabyte e il set di training Brats 2019, quindi decomprimere i file.</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">Creare una directory di lavoro con almeno 1 TB e definire la variabile ambientale<block ref="597c05a331d3bca9b42845049a851c94" prefix=" " category="inline-code"></block> facendo riferimento alla directory.</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">È necessario condividere questa directory sullo storage condiviso per il caso di utilizzo dello storage di rete o sul disco locale durante il test con dati locali.</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">Esegui il make<block ref="ba8a3d8e03d727387e03ca6ef842d4c5" prefix=" " category="inline-code"></block> che crea e avvia il contenitore del docker per le attività di inferenza richieste.</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">I seguenti comandi vengono eseguiti tutti dall'interno del contenitore di docker in esecuzione:</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">Scarica i modelli ai preformati per le attività di inferenza MLPerf:<block ref="b59a4beb5c95f2e0e1fed56d89e16cf0" prefix=" " category="inline-code"></block></block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">Scarica altri set di dati scaricabili gratuitamente:<block ref="fd0245b042cdcee1ab8bd760c8b4bfbc" prefix=" " category="inline-code"></block></block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">Pre-elaborare i dati: Make<block ref="03275934d57d2ecfe9e68f7023f456ce" prefix=" " category="inline-code"></block></block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">Esecuzione:<block ref="be647e69451a82a2f326980291e0f781" prefix=" " category="inline-code"></block>.</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">Creazione di motori di inferenza ottimizzati per la GPU nei server di calcolo:<block ref="37496efe33254cb883b0705fde55fcc1" prefix=" " category="inline-code"></block></block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">Per eseguire i carichi di lavoro di inferenza, eseguire quanto segue (un comando):</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">L'inferenza ai è in esecuzione</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">Sono stati eseguiti tre tipi di esecuzione:</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">Inferenza ai su server singolo utilizzando lo storage locale</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">Inferenza ai su server singolo utilizzando lo storage di rete</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">Inferenza ai multi-server utilizzando lo storage di rete</block>
  <block id="697d202c2969580ba0434be04d39a929" category="paragraph"><block ref="697d202c2969580ba0434be04d39a929" category="inline-link-macro-rx"></block></block>
  <block id="6bee97571af49e4c38ff85a4abbbe0e9" category="summary">Questa sezione descrive le attività necessarie per completare la convalida.</block>
  <block id="c17e6835560e56c00184a993e1b0bfdb" category="paragraph"><block ref="c17e6835560e56c00184a993e1b0bfdb" category="inline-link-macro-rx"></block></block>
  <block id="df06a8aa3d194f798e70c253c55d915c" category="paragraph">Per eseguire le attività descritte in questa sezione, è necessario avere accesso a un host Linux o macOS con i seguenti strumenti installati e configurati:</block>
  <block id="c0ffe26d3756a5c964ff9bc591e1fc16" category="list-text">Kubernetl (configurato per l'accesso a un cluster Kubernetes esistente)</block>
  <block id="e436fe7c4ecfcca0f0327b41471955df" category="list-text">È possibile trovare le istruzioni di installazione e configurazione<block ref="f6d4f9e359e394de0cb3015a4518672c" category="inline-link-rx"></block>.</block>
  <block id="297924c1d3fec9d97f9a1f3b49ee0709" category="list-text">NetApp DataOps Toolkit per Kubernetes</block>
  <block id="e3e34254666d96b8967227676b54e135" category="list-text">È possibile trovare le istruzioni per l'installazione<block ref="9535953c30e005e9672e48b24a3ac733" category="inline-link-rx"></block>.</block>
  <block id="1a66086f406852b100e9d8f85d007b87" category="section-title">Scenario 1 – deduzione on-demand in JupyterLab</block>
  <block id="28876e2d40a33fcbc3630d7408b14046" category="list-text">Creare uno spazio dei nomi Kubernetes per i carichi di lavoro di inferenza ai/ML.</block>
  <block id="1464ad61957a8ed3db5f67edbc20cc41" category="list-text">Utilizza il NetApp DataOps Toolkit per eseguire il provisioning di un volume persistente per l'archiviazione dei dati su cui eseguire l'inferenza.</block>
  <block id="da33a6119aa0b49526bd284e9a865ed5" category="list-text">Utilizza il NetApp DataOps Toolkit per creare un nuovo spazio di lavoro JupyterLab. Montare il volume persistente creato nel passaggio precedente utilizzando<block ref="49477e975a03ac8fbc68aea44a67d49d" prefix=" " category="inline-code"></block> opzione. Allocare le GPU NVIDIA nell'area di lavoro secondo necessità utilizzando<block ref="dfc4755b60ee7dfab3c1e88693efd099" prefix=" " category="inline-code"></block> opzione.</block>
  <block id="810e88d69a6b7f454f24db3a25ba375a" category="paragraph">Nell'esempio seguente, il volume persistente<block ref="682303bbf677ac9a205caf2d086b33d3" prefix=" " category="inline-code"></block> È montato sul container dello spazio di lavoro JupyterLab all'indirizzo<block ref="a88bf20c35f897f8c2c3a03189e90c09" prefix=" " category="inline-code"></block>. Quando si utilizzano le immagini container ufficiali di Project Jupyter,<block ref="3b8e9b793a1a95056575343e279719df" prefix=" " category="inline-code"></block> Viene presentato come la directory di primo livello all'interno dell'interfaccia web di JupyterLab.</block>
  <block id="ecca64929aad192e0cdba66d89af6fc2" category="list-text">Accedere all'area di lavoro di JupyterLab utilizzando l'URL specificato nell'output di<block ref="d9eb9b67c69b49a1b002e09de33d9ed9" prefix=" " category="inline-code"></block> comando. La directory dei dati rappresenta il volume persistente montato nell'area di lavoro.</block>
  <block id="1f069f45990199d6afbe5926fb26f127" category="paragraph"><block ref="1f069f45990199d6afbe5926fb26f127" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5989087fa6f30a7b2ad79b3b28f4f68" category="list-text">Aprire<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block> directory e caricare i file su cui eseguire la deduzione. Quando i file vengono caricati nella directory dei dati, vengono memorizzati automaticamente sul volume persistente montato nell'area di lavoro. Per caricare i file, fare clic sull'icona Upload Files (carica file), come mostrato nell'immagine seguente.</block>
  <block id="f6d07c27f458648455903cf09530655f" category="paragraph"><block ref="f6d07c27f458648455903cf09530655f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6da42e23b9d4e193c2fb146b8189581" category="list-text">Tornare alla directory di livello superiore e creare un nuovo notebook.</block>
  <block id="59e51e40d73317a796f7d0b25d8fa003" category="paragraph"><block ref="59e51e40d73317a796f7d0b25d8fa003" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d6d5c0ae1c38484d2d4fd513ff80f90" category="list-text">Aggiungere il codice di deduzione al notebook. L'esempio seguente mostra il codice di deduzione per un caso d'uso di rilevamento dell'immagine.</block>
  <block id="901ae9d6148669912b400c6d2647bfbf" category="paragraph"><block ref="901ae9d6148669912b400c6d2647bfbf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f10850488ed018cdad31f8ac9e8bab" category="paragraph"><block ref="45f10850488ed018cdad31f8ac9e8bab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="296d40736553e2033f5cf8817174bc7c" category="list-text">Aggiungi l'offuscamento di Protopia al tuo codice di deduzione. Protopia collabora direttamente con i clienti per fornire documentazione specifica per il caso d'utilizzo e non rientra nell'ambito di questo report tecnico. Nell'esempio seguente viene illustrato il codice di deduzione per un caso di utilizzo del rilevamento dell'immagine con l'aggiunta dell'offuscamento di Protopia.</block>
  <block id="5a10342224477df560528e700989b536" category="paragraph"><block ref="5a10342224477df560528e700989b536" category="inline-image-macro-rx" type="image"></block></block>
  <block id="20f77c05fa583bdc62074b26870e07e7" category="paragraph"><block ref="20f77c05fa583bdc62074b26870e07e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5709eb5c3d3d4a700397ee447f9818" category="section-title">Scenario 2 – deduzione in batch su Kubernetes</block>
  <block id="77b69d61f1889c8321dce66f3c3e2e1a" category="list-text">Popolare il nuovo volume persistente con i dati su cui eseguire l'deduzione.</block>
  <block id="8b6983cc7986c7b0553983d8ab669289" category="inline-link">NetApp DataOps Toolkit S3 Data Mover</block>
  <block id="2933df0ebac7b47c349bd6bd7099fb90" category="paragraph">Esistono diversi metodi per caricare i dati su un PVC. Se i tuoi dati sono attualmente memorizzati in una piattaforma di storage a oggetti compatibile con S3, come NetApp StorageGRID o Amazon S3, puoi utilizzare<block ref="5d1617256d53e0547b237f3cf3fda5b0" category="inline-link-rx"></block>. Un altro metodo semplice consiste nel creare un'area di lavoro JupyterLab e quindi caricare i file attraverso l'interfaccia web di JupyterLab, come descritto nei passaggi da 3 a 5 della sezione "<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block>."</block>
  <block id="a62147e18dbac7ad5eab17791c371ad4" category="list-text">Creare un lavoro Kubernetes per l'attività di deduzione in batch. Nell'esempio seguente viene illustrato un processo di deduzione in batch per un caso d'uso di rilevamento dell'immagine. Questo lavoro esegue la deduzione su ogni immagine in un set di immagini e scrive le metriche di precisione di deduzione su stdout.</block>
  <block id="a883fb9f7bda67c6fbcab6dfb8f091ce" category="list-text">Verificare che il lavoro di deduzione sia stato completato correttamente.</block>
  <block id="590888c60942c47f5268c19f273109ee" category="list-text">Aggiungi l'offuscamento di Protopia al tuo lavoro di deduzione. È possibile trovare istruzioni specifiche per l'aggiunta di offuscamento Protopia direttamente da Protopia, che non rientra nell'ambito di questo report tecnico. Nell'esempio seguente viene illustrato un processo di deduzione in batch per un caso di utilizzo del rilevamento dei volti con offuscamento di Protopia aggiunto utilizzando un valore ALFA di 0.8. Questo lavoro applica l'offuscamento di Protopia prima di eseguire la deduzione per ogni immagine in un set di immagini e quindi scrive le metriche di precisione dell'inferenza su stdout.</block>
  <block id="7a1adb5cebbf78f3eddc08a64751149e" category="inline-link-macro">"Confronto della precisione delle conferenze".</block>
  <block id="da2c9dc305dff324654e67571156b295" category="paragraph">Abbiamo ripetuto questo passaggio per i valori ALFA 0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 0.9 e 0.95. I risultati sono riportati in <block ref="af158494e4986d64d04037857fed2d1c" category="inline-link-macro-rx"></block></block>
  <block id="76d6540fbdbbcd913fb6272a50d0e3f2" category="section-title">Scenario 3 – NVIDIA Triton Inference Server</block>
  <block id="c470d7124546c64e8539c39ced806428" category="list-text">Utilizza NetApp DataOps Toolkit per eseguire il provisioning di un volume persistente da utilizzare come repository di modelli per NVIDIA Triton Inference Server.</block>
  <block id="1ddcb92ade31c8fbd370001f9b29a7d9" category="inline-link">formato</block>
  <block id="898dfcda591317ac60dd8d6af3aff189" category="list-text">Memorizzare il modello sul nuovo volume persistente in un<block ref="2001a6caf72de652d98c6c64bc75a4e8" category="inline-link-rx"></block> Riconosciuto da NVIDIA Triton Inference Server.</block>
  <block id="6c21d87641bab7a6c49bc29065185e4f" category="paragraph">Esistono diversi metodi per caricare i dati su un PVC. Un metodo semplice consiste nel creare un'area di lavoro JupyterLab e quindi caricare i file attraverso l'interfaccia web di JupyterLab, come descritto nei passaggi da 3 a 5 in "<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block>. "</block>
  <block id="fc35606f82a544f9c79f09561d7a234d" category="list-text">Utilizza NetApp DataOps Toolkit per implementare una nuova istanza di NVIDIA Triton Inference Server.</block>
  <block id="27a920b35a8f949700a98b22803c70fc" category="list-text">Utilizzare un SDK del client Triton per eseguire un'attività di deduzione. Il seguente estratto di codice Python utilizza l'SDK del client Python di Triton per eseguire un'attività di deduzione per un caso di utilizzo del rilevamento dei volti. Questo esempio chiama l'API Triton e passa un'immagine per la deduzione. Il server di inferenza Triton riceve quindi la richiesta, richiama il modello e restituisce l'output di deduzione come parte dei risultati API.</block>
  <block id="7b5e296090a5d063fdbd3ebb69fc6547" category="list-text">Aggiungi l'offuscamento di Protopia al tuo codice di deduzione. È possibile trovare istruzioni specifiche per il caso d'utilizzo per aggiungere l'offuscamento Protopia direttamente da Protopia; tuttavia, questo processo non rientra nell'ambito di questo report tecnico. Nell'esempio seguente viene illustrato lo stesso codice Python mostrato nel precedente passaggio 5, ma con l'aggiunta dell'offuscamento di Protopia.</block>
  <block id="c3069165ee6fb9d5dde8d8472d8b4602" category="paragraph">Si noti che l'offuscamento Protopia viene applicato all'immagine prima che venga passata all'API Triton. Pertanto, l'immagine non offuscata non lascia mai la macchina locale. Solo l'immagine offuscata viene passata attraverso la rete. Questo flusso di lavoro è applicabile ai casi di utilizzo in cui i dati vengono raccolti all'interno di una zona attendibile, ma devono essere trasferiti all'esterno di tale zona attendibile per l'deduzione. Senza l'offuscamento di Protopia, non è possibile implementare questo tipo di workflow senza che i dati sensibili si allontanino dalla zona di fiducia.</block>
  <block id="38bb883cb543c747fc0f113099f5072d" category="inline-link-macro">Avanti: Confronto della precisione delle deduzione.</block>
  <block id="1f2c820475fbde991c6219936a645aea" category="paragraph"><block ref="1f2c820475fbde991c6219936a645aea" category="inline-link-macro-rx"></block></block>
  <block id="39cf3ca3e5dbe56d6eade7cbe3cc40e6" category="doc">Operazioni e attività Kubeflow di esempio</block>
  <block id="368c8f521d74a015b7a3e1a46c8847b1" category="paragraph">Questa sezione include esempi di varie operazioni e attività che è possibile eseguire utilizzando Kubeflow.</block>
  <block id="bdbf5a5e65f2cf7435dfcea294400b35" category="inline-link-macro">Successivo: Provisioning di un Jupyter notebook Workspace per l'utilizzo da parte di Data Scientist o Developer.</block>
  <block id="86e512bbf34bd396dd043a14ff2027ec" category="paragraph"><block ref="86e512bbf34bd396dd043a14ff2027ec" category="inline-link-macro-rx"></block></block>
  <block id="4b737f96f31f513a87adcf43b83ec3a1" category="summary">Questa pagina descrive i passaggi necessari per configurare il cluster AKS.</block>
  <block id="a81532d943508d42466c22d8d87bb4b8" category="doc">Installare e configurare il cluster AKS</block>
  <block id="ce3e1770b7ff86cfbc3a30a3e3ea87da" category="inline-link-macro">Precedente: Riepilogo del caso d'uso previsto con un click-through.</block>
  <block id="80bf56f9bff31f7459309b983fbf8116" category="paragraph"><block ref="80bf56f9bff31f7459309b983fbf8116" category="inline-link-macro-rx"></block></block>
  <block id="40e1cc9f8d9321cbe9c1ef090f926a2b" category="paragraph">Per installare e configurare il cluster AKS, consultare la pagina Web<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block> quindi completare i seguenti passaggi:</block>
  <block id="ad4af0825dd4979b7f48ae5ba031b23a" category="list-text">Quando si seleziona il tipo di nodo (nodi di sistema [CPU] o di lavoro [GPU]), selezionare quanto segue:</block>
  <block id="5a244a81080ee9fc08696fcbd45284e5" category="list-text">I nodi di sistema primari devono essere DS2v2 standard <block ref="917718fb2e3dcf94043ea14d44580bc2" prefix="(" category="inline-code"></block> tre nodi predefiniti).</block>
  <block id="f3449ebebbf547282aa0562015bd360d" category="list-text">Quindi, aggiungere il pool Standard_NC6s_v3 del nodo di lavoro (minimo tre nodi) per il gruppo di utenti (per i nodi GPU) denominato<block ref="2e7ef525fb562d2f68920b0bf6f58b81" prefix=" " category="inline-code"></block>.</block>
  <block id="d3d648c68589ef99efb6ad3ec15d1beb" category="paragraph"><block ref="d3d648c68589ef99efb6ad3ec15d1beb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2efc2b95642d4bcc76c710a3826225c" category="list-text">L'implementazione richiede da 5 a 10 minuti. Al termine, fare clic su Connect to Cluster (Connetti al cluster).</block>
  <block id="31797d7013400422e5d589ae3d91c79a" category="list-text">Per connettersi al cluster AKS appena creato, installare quanto segue dall'ambiente locale (laptop/pc):</block>
  <block id="87e009e80a344ecb598be4c4bbe01c79" category="inline-link">Istruzioni fornite per il sistema operativo in uso</block>
  <block id="13a6d4f4230d0a1569b719c15884d447" category="list-text">Lo strumento della riga di comando Kubernetes che utilizza<block ref="ad2337a31b7d16867fc954b03de661bd" category="inline-link-rx"></block></block>
  <block id="24a109d7bba4f8808eeb0bcf64d4357b" category="inline-link">Installare Azure CLI</block>
  <block id="7feed8a8a6c680e7beeca052b9fc9ed0" category="list-text">La CLI di Azure come descritto nel documento,<block ref="8e2043d81b680dba324c5a2abbee7b3f" category="inline-link-rx"></block></block>
  <block id="d33a4b8acf4001a4b35a2186fd020432" category="list-text">Per accedere al cluster AKS dal terminale, immettere<block ref="f7ac81b64d50d201c173fb8dcf70f266" prefix=" " category="inline-code"></block> e immettere le credenziali.</block>
  <block id="402ff6cff3671c1f49dc4af765835c14" category="list-text">Invio<block ref="33ba05f3df928c75694839078d97b2e4" prefix=" " category="inline-code"></block>.</block>
  <block id="4e5d89028ffbf65df6693ef1affd6573" category="list-text">Se tutti e sei i nodi sono attivi e in esecuzione, come illustrato nell'esempio seguente, il cluster AKS è pronto e connesso all'ambiente locale</block>
  <block id="6b935f22371497abfe5378d4446df0da" category="paragraph"><block ref="6b935f22371497abfe5378d4446df0da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e57b7e32f49f0297d6c7524d1da1b3c0" category="inline-link-macro">Quindi creare una subnet delegata per Azure NetApp Files.</block>
  <block id="46b5942a33ef6a130ca5fee3f6017bec" category="paragraph"><block ref="46b5942a33ef6a130ca5fee3f6017bec" category="inline-link-macro-rx"></block></block>
  <block id="1703cadf8e847114fb353feaaf03beb9" category="summary">Questa sezione include esempi di vari job dalle performance elevate che possono essere eseguiti quando Kubernetes viene implementato su un pod ai ONTAP.</block>
  <block id="639ce1b23959b4470d67802f0e5e412a" category="doc">Esempi di opportunità di lavoro ad alte performance per le implementazioni ai di ONTAP</block>
  <block id="b7cd12d2dd9ac8e3414514a02e5df6f4" category="inline-link-macro">Eseguire un carico di lavoro ai a nodo singolo.</block>
  <block id="6ee8519e7493385361c9afcfd675c8d0" category="paragraph"><block ref="6ee8519e7493385361c9afcfd675c8d0" category="inline-link-macro-rx"></block></block>
  <block id="8537de5688b6b855ec8b5465eca4e8f6" category="list-text">NVIDIA DGX Station, V100 GPU, GPU Cloud</block>
  <block id="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link"><block ref="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link-rx"></block></block>
  <block id="432a0462f3a215c89d6067d01ac9fee8" category="list-text">Stazione NVIDIA DGX<block ref="00e84bc2760804fd15a292583676639b" category="inline-link-rx"></block></block>
  <block id="a8135dcfdfd9c1074b55895b8d51f9be" category="list-text">NVIDIA V100 Tensor Core GPU<block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="f3e44b157fa7ead37042e8a6f3b14071" category="list-text">NVIDIA NGC<block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="944c1fe2317541350506cecb6131b857" category="inline-link"><block ref="944c1fe2317541350506cecb6131b857" category="inline-link-rx"></block></block>
  <block id="d3ceb6166da1ada512f22bc7832ec047" category="list-text">NVIDIA Jarvis<block ref="34ae4389dc7afcada801d63c08e322b9" category="inline-link-rx"></block></block>
  <block id="21ce987b6ba4d344f1427dc72d497669" category="inline-link"><block ref="21ce987b6ba4d344f1427dc72d497669" category="inline-link-rx"></block></block>
  <block id="7bf7a8db8c3809766aa2579c2eadf37d" category="list-text">Accesso anticipato a NVIDIA Jarvis<block ref="2daee9604c6a07f74e6776847d2ee61e" category="inline-link-rx"></block></block>
  <block id="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link"><block ref="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link-rx"></block></block>
  <block id="852c7bf0a8f3b30a5a001dbf642dbebe" category="list-text">NVIDIA NEMO<block ref="fa9e246f0ef36a285adacc70507ae974" category="inline-link-rx"></block></block>
  <block id="299a4717590cda2cfe1db321802b4995" category="inline-link"><block ref="299a4717590cda2cfe1db321802b4995" category="inline-link-rx"></block></block>
  <block id="dfc2ce4fd02d20052bebaa2e6b8cd029" category="list-text">Guida per sviluppatori<block ref="9940ba67713949ce4f2fc05d3a37bd8c" category="inline-link-rx"></block></block>
  <block id="5467c9d1c07a7d1786936650b3c2d52a" category="list-text">Scheda informativa su NetApp AFF Serie A.<block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="6bb399f406fc5ac4150ad21c6aa05ab2" category="list-text">NetApp Flash Advantage per All Flash FAS<block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="9415aef2732728cc097fbbc9ab96b2fe" category="list-text">Raccolta di informazioni su ONTAP 9<block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="d106dc348953acc0500f03a25379282e" category="list-text">Report tecnico NetApp ONTAP FlexGroup Volumes<block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="05dbc5885d3bec70d2317a4b51526d96" category="list-text">Guida alla progettazione di reti ONTAP ai con DGX-1 e Cisco<block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="af5797305db370f4f59d77bf7c73160b" category="list-text">Guida all'implementazione di ONTAP ai con DGX-1 e Cisco Networking<block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="f2345b2674d3976c091d4af042c36a8f" category="inline-link"><block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="f63c45f352478237d0d0fe7c5a26d6bf" category="list-text">Guida alla progettazione di reti ONTAP ai con DGX-1 e Mellanox<block ref="459df3a4bfb1f89f6920196001257745" category="inline-link-rx"></block></block>
  <block id="b38db7c217c396412f601b87dfc58a8c" category="inline-link"><block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="da8009e462fd2ec5eeb41b4cf3721f7a" category="list-text">Guida alla progettazione di ONTAP ai con DGX-2<block ref="86d70269673ee41c37a2673f7d3655ce" category="inline-link-rx"></block></block>
  <block id="fa752e98365b630341b8478c89a6757f" category="doc">Configurazione del cluster Kubernetes</block>
  <block id="f12c340e651d989970371432778f9be2" category="paragraph">Questa sezione è suddivisa in due parti, rispettivamente per l'implementazione in cloud e on-premise.</block>
  <block id="ee06675a624f2ec74e8b71b5a57f8f9e" category="section-title">Configurazione di Kubernetes per l'implementazione del cloud</block>
  <block id="b513a0297a0d2efdebed8ce18e2f1715" category="paragraph">Tramite NetApp Cloud Manager, è possibile definire la connessione al cluster Iguazio Kubernetes. Trident richiede l'accesso a più risorse nel cluster per rendere disponibile il volume.</block>
  <block id="2d5bc331cc722113dd483838e908804c" category="list-text">Per abilitare l'accesso, ottenere il file di configurazione di Kubernetes da uno dei nodi Iguazio. Il file si trova in<block ref="c94d2475115399d9803ef7d9f1fc7b59" prefix=" " category="inline-code"></block> Scaricare questo file sul desktop.</block>
  <block id="17c6b0de5b91c5c06a0d8173c89110d8" category="list-text">Accedere a Discover Cluster (rilevamento cluster) per eseguire la configurazione.</block>
  <block id="df37cca51036f4c5b59db211df5354bc" category="paragraph"><block ref="df37cca51036f4c5b59db211df5354bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b848e07dc3f62b4307419421d844f123" category="list-text">Caricare il file di configurazione di Kubernetes. Vedere la seguente immagine.</block>
  <block id="5bcc42d0a2624f1586064488c3484529" category="paragraph"><block ref="5bcc42d0a2624f1586064488c3484529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="63de24a45facebf9f65cb6578847f2b4" category="list-text">Implementare Trident e associare un volume al cluster. Vedere la seguente immagine per definire e assegnare un volume persistente al cluster Iguazio. Questo processo crea un volume persistente (PV) nel cluster Kubernetes di Iguazio. Prima di poterlo utilizzare, è necessario definire un PVC (Persistent Volume Claim).</block>
  <block id="8b69025b2efa1b2ccb917bc911d30ccd" category="section-title">Configurazione di Kubernetes per l'implementazione on-premise</block>
  <block id="5be8900878997a404baf02b07ff271c6" category="paragraph">Per l'installazione on-premise di NetApp Trident, vedere<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> per ulteriori informazioni. Dopo aver configurato il cluster Kubernetes e aver installato NetApp Trident, è possibile collegare Trident al cluster Iguazio per abilitare le funzionalità di gestione dei dati NetApp, come l'acquisizione di copie Snapshot dei dati e del modello.</block>
  <block id="50af1dc10d66589053fc82292fe61444" category="inline-link-macro">Avanti: Definire la richiesta di rimborso per volumi persistenti</block>
  <block id="bb0c0300eb362a15d2d6480d832ecfbe" category="paragraph"><block ref="bb0c0300eb362a15d2d6480d832ecfbe" category="inline-link-macro-rx"></block></block>
  <block id="34d54070f7d06f04159ffbc3d9a3e082" category="doc">Configurare l'ambiente di lavoro</block>
  <block id="8302b607de31151e5500de556070d9b9" category="paragraph">Copiare il<block ref="3a4f8d88ea1eac117f98223609194cb9" prefix=" " category="inline-code"></block><block ref="4931c948234bb20e1915f851691b340a" prefix=" " category="inline-code"></block> come<block ref="b35ae5135ebed26881b0747c3c36725d" prefix=" " category="inline-code"></block>. Aprire e modificare<block ref="b35ae5135ebed26881b0747c3c36725d" prefix=" " category="inline-code"></block>. Questo notebook imposta le variabili per le credenziali, le posizioni dei file e i driver di esecuzione.</block>
  <block id="3dc3cffc26096b89061a452cc7d16b6a" category="paragraph">Se si seguono le istruzioni riportate in precedenza, le uniche modifiche da apportare sono le seguenti:</block>
  <block id="26448fec50e405fb230427686eeb11f4" category="list-text">Ottieni questo valore dalla dashboard dei servizi Iguazio:<block ref="bed2ad53cc10d1f92b477fc7c1476348" prefix=" " category="inline-code"></block></block>
  <block id="837784ac15c5cac463a4d016bac63db1" category="paragraph">Esempio:<block ref="0ddf9a06edec7d150708463603b95f22" prefix=" " category="inline-code"></block></block>
  <block id="04dca9f72f7dfc6f87034c574f821a12" category="list-text">Cambiare<block ref="21232f297a57a5a743894a0e4a801fc3" prefix=" " category="inline-code"></block> Al tuo nome utente Iguazio:</block>
  <block id="b2dea33f1195135f6905b7dd0ee58713" category="paragraph"><block ref="0458c1c280a715ecb31b33b5269e101b" prefix="" category="inline-code"></block></block>
  <block id="0ddaf8f981ee966dc3533de490c7ee4e" category="paragraph">Di seguito sono riportati i dettagli di connessione del sistema ONTAP. Includere il nome del volume generato al momento dell'installazione di Trident. La seguente impostazione si intende per un cluster ONTAP on-premise:</block>
  <block id="dada97be0cb81e6518d92aa7112fa356" category="paragraph">La seguente impostazione è per Cloud Volumes ONTAP:</block>
  <block id="586d20125924bc57624aaacc07973d5a" category="section-title">Creare immagini base Docker</block>
  <block id="0ab24923db4855b821917446711104c9" category="paragraph">Tutto ciò di cui hai bisogno per creare una pipeline ML è incluso nella piattaforma Iguazio. Lo sviluppatore può definire le specifiche delle immagini Docker richieste per eseguire la pipeline ed eseguire la creazione dell'immagine da Jupyter notebook. Aprire il notebook<block ref="61dfd8901a62e0f1e23dd2f5029d2639" prefix=" " category="inline-code"></block> Ed eseguire tutte le celle.</block>
  <block id="3dc4e8abb0e99c6cf29451a16a891524" category="paragraph">Questo notebook crea due immagini che utilizziamo in pipeline.</block>
  <block id="5446cc82e4c165e2700af830f8428d63" category="list-text"><block ref="b636b23a5b442c01733e45c199c11f56" prefix="" category="inline-code"></block> Utilizzato per gestire le attività ML.</block>
  <block id="61145f9d17e187b69bc41525b10aafe6" category="paragraph"><block ref="61145f9d17e187b69bc41525b10aafe6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62e9956426227f62abc9692954a5ad39" category="list-text"><block ref="c59e60c5a3880eb8018ae68eaa70621c" prefix="" category="inline-code"></block>. Contiene utility per gestire le copie Snapshot di NetApp.</block>
  <block id="4050f795a12d7f83a545999c8a0d1905" category="paragraph"><block ref="4050f795a12d7f83a545999c8a0d1905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6677daf583d4c0cf5860927a024f278d" category="section-title">Esamina i singoli notebook Jupyter</block>
  <block id="6414e1c23e017075a375d3a531eab90c" category="paragraph">La tabella seguente elenca le librerie e i framework utilizzati per creare questo task. Tutti questi componenti sono stati completamente integrati con i controlli di sicurezza e accesso basati sui ruoli di Iguazio.</block>
  <block id="da292beca00e0b352eade7a070855fd3" category="cell">Librerie/Framework</block>
  <block id="124d604ba0d3fd8e3d31c821b2a332f5" category="cell">MLRun</block>
  <block id="1c1491d01d96c08951ae2ac55fadf443" category="cell">Gestito da Iguazio per consentire l'assemblaggio, l'esecuzione e il monitoraggio di una pipeline ML/ai.</block>
  <block id="a2580bd6e044f86f4e39be2f59ee91da" category="cell">Nuclio</block>
  <block id="2d753cbb7762fe25d15a2cda2ff84790" category="cell">Un framework di funzioni senza server integrato con Iguazio. Disponibile anche come progetto open-source gestito da Iguazio.</block>
  <block id="0bbee378f2697a1d0c184e76d2b206c6" category="cell">Un framework basato su Kubernetes per implementare la pipeline. Si tratta anche di un progetto open-source al quale Iguazio contribuisce. È integrato con Iguazio per una maggiore sicurezza e integrazione con il resto dell'infrastruttura.</block>
  <block id="849efb47ec760eb7c3c6b5848e740c3b" category="cell">Un registro Docker viene eseguito come servizio nella piattaforma Iguazio. È inoltre possibile modificare questa impostazione per connettersi al registro.</block>
  <block id="a38f73277b7341a709cf0cb57ebc4434" category="cell">NetApp Cloud Volumes</block>
  <block id="7279bb663993b77e219b4ca813326d77" category="cell">I volumi cloud eseguiti su AWS ci offrono l'accesso a grandi quantità di dati e la possibilità di eseguire copie Snapshot per la versione dei set di dati utilizzati per il training.</block>
  <block id="9953e13b783f3ad45d99187c955cb9f9" category="cell">Trident è un progetto open-source gestito da NetApp. Facilita l'integrazione con risorse di storage e calcolo in Kubernetes.</block>
  <block id="5fa4506d691373039fd2834939e582b3" category="paragraph">Abbiamo utilizzato diversi notebook per costruire LA pipeline ML. Ogni notebook può essere testato singolarmente prima di essere messo insieme nella pipeline. Ciascun notebook viene descritto singolarmente seguendo il flusso di implementazione di questa applicazione dimostrativa.</block>
  <block id="06a86c2506db8ef5fdac675c1352e3cf" category="paragraph">Il risultato desiderato è una pipeline che forma un modello basato su una copia Snapshot dei dati e implementa il modello per l'inferenza. Un diagramma a blocchi di una pipeline MLRun completa viene mostrato nell'immagine seguente.</block>
  <block id="1d79eb753e06f2122a118408a14d6c51" category="paragraph"><block ref="1d79eb753e06f2122a118408a14d6c51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51b666fe429f998144ea4f2ce818cd60" category="section-title">Implementare la funzione di generazione dei dati</block>
  <block id="034015442bf8bf34c0e7e8149d35dae6" category="paragraph">In questa sezione viene descritto come abbiamo utilizzato le funzioni senza server di Nuclio per generare i dati dei dispositivi di rete. Il caso di utilizzo viene adattato da un client Iguazio che ha implementato la pipeline e utilizzato i servizi Iguazio per monitorare e prevedere i guasti dei dispositivi di rete.</block>
  <block id="2d024dd4dc0601ff2e4d0b81fcaec60a" category="inline-link">Sito web di Nuclio</block>
  <block id="59009d367371847f2042c59338282f4b" category="paragraph">Abbiamo simulato i dati provenienti dai dispositivi di rete. Esecuzione del notebook Jupyter<block ref="c2d07e7698686359c0371f481d2cc628" prefix=" " category="inline-code"></block> Crea una funzione senza server che viene eseguita ogni 10 minuti e genera un file di parquet con nuovi dati. Per implementare la funzione, eseguire tutte le celle di questo notebook. Vedere<block ref="a9d48e85369982160b96d90770d878d1" category="inline-link-rx"></block> per esaminare eventuali componenti non familiari presenti in questo notebook.</block>
  <block id="fa0c06ebcd647f13ce81472307615ee3" category="paragraph">Una cella con il seguente commento viene ignorata durante la generazione della funzione. Si presume che ogni cella del notebook faccia parte della funzione. Importare il modulo Nuclio per attivarlo<block ref="85b0176bddfe93e918b8de4cb894780c" prefix=" " category="inline-code"></block>.</block>
  <block id="c2b253a6bc491b37027772dba5f0b4e7" category="paragraph">Nella specifica della funzione, abbiamo definito l'ambiente in cui viene eseguita la funzione, il modo in cui viene attivata e le risorse che utilizza.</block>
  <block id="95b0eb5f892f7b0bcb3ec7dbb9058c02" category="paragraph">Il<block ref="b73982aa3ac6ac19ba867eb2f5819797" prefix=" " category="inline-code"></block> La funzione viene richiamata dal framework Nuclio all'inizializzazione della funzione.</block>
  <block id="1aab9637db54631d95ec5901bfda0947" category="paragraph">Quando la funzione viene inizializzata, viene richiamato qualsiasi codice non presente in una funzione. Quando lo si richiama, viene eseguita una funzione di handler. È possibile modificare il nome del gestore e specificarlo nella specifica della funzione.</block>
  <block id="94be7a657ecb54ef7337030d9dd78b70" category="paragraph">È possibile verificare la funzione dal notebook prima dell'implementazione.</block>
  <block id="01237c05459839293bfcd5a3beb1364f" category="paragraph">La funzione può essere implementata dal notebook o da una pipeline ci/CD (adattando questo codice).</block>
  <block id="c697561ec27606d29683f7fc5fb3846d" category="section-title">Notebook Pipeline</block>
  <block id="83041c5547fb0ad965936febfc41508d" category="paragraph">Questi notebook non devono essere eseguiti singolarmente per questa configurazione. Questa è solo una recensione di ogni notebook. Li abbiamo invocati come parte della pipeline. Per eseguirli singolarmente, consultare la documentazione di MLRun per eseguirli come lavori Kubernetes.</block>
  <block id="c16b208e4ffb938f4008373dea5fb4ec" category="section-title">snap_cv.ipynb</block>
  <block id="eeb06194a969eee5616e56b449a99306" category="paragraph">Questo notebook gestisce le copie Cloud Volume Snapshot all'inizio della pipeline. Passa il nome del volume al contesto della pipeline. Questo notebook richiama uno script shell per gestire la copia Snapshot. Durante l'esecuzione nella pipeline, il contesto di esecuzione contiene variabili che consentono di individuare tutti i file necessari per l'esecuzione. Durante la scrittura di questo codice, lo sviluppatore non deve preoccuparsi della posizione del file nel contenitore che lo esegue. Come descritto in seguito, questa applicazione viene implementata con tutte le dipendenze, ed è la definizione dei parametri della pipeline che fornisce il contesto di esecuzione.</block>
  <block id="dc82b570ec10aa261c20bf4828af24c1" category="paragraph">La posizione della copia Snapshot creata viene inserita nel contesto MLRun per essere utilizzata dalle fasi della pipeline.</block>
  <block id="7f609b3599e86a8f1b83bde97709ba37" category="paragraph">I tre notebook successivi vengono eseguiti in parallelo.</block>
  <block id="d1839287f93e09936af234173d03d6b7" category="section-title">data-prep.ipynb</block>
  <block id="dbe6ca7c47e3dc8cbd3a4956e684b761" category="paragraph">Le metriche raw devono essere trasformate in funzionalità per consentire la formazione su modelli. Questo notebook legge le metriche raw dalla directory Snapshot e scrive le funzionalità per il training sui modelli nel volume NetApp.</block>
  <block id="dab65fbdf0ed5ce626558d99e83c618f" category="paragraph">Quando viene eseguito nel contesto della pipeline, l'input<block ref="6ca3f4659530db0c27f67623bd27b304" prefix=" " category="inline-code"></block> Contiene la posizione della copia Snapshot.</block>
  <block id="4636df8c7ba383c5f135c7ae8f2ef772" category="section-title">descripse.ipynb</block>
  <block id="43099d46867c7c0cc922fdd3e026d029" category="paragraph">Per visualizzare le metriche in entrata, implementiamo una fase di pipeline che fornisce grafici e grafici disponibili attraverso le interfacce utente Kubeflow e MLRun. Ogni esecuzione dispone di una propria versione di questo tool di visualizzazione.</block>
  <block id="7fd47125b80c0e6241052a47dcb41b98" category="section-title">deploy-feature-function.ipynb</block>
  <block id="684eb641c7a322c328f8ea91cd482b0d" category="paragraph">Monitoriamo continuamente le metriche alla ricerca di anomalie. Questo notebook crea una funzione senza server che genera le funzionalità necessarie per eseguire la previsione sulle metriche in entrata. Questo notebook richiama la creazione della funzione. Il codice funzione si trova nel notebook<block ref="ddc05946399cb9a8e617080738240288" prefix=" " category="inline-code"></block>. A questo scopo, utilizziamo lo stesso notebook come passaggio della pipeline.</block>
  <block id="1c475141d16ada0e53ddb14047963024" category="section-title">training.ipynb</block>
  <block id="43b6984a9b2a7863061833c96be2b851" category="paragraph">Dopo aver creato le funzionalità, avviamo il training sul modello. L'output di questa fase è il modello da utilizzare per l'deduzione. Raccogliamo inoltre statistiche per tenere traccia di ogni esecuzione (esperimento).</block>
  <block id="a6858cae929a8eed6e9c9d6cfa9befac" category="paragraph">Ad esempio, il comando seguente inserisce il punteggio di precisione nel contesto dell'esperimento. Questo valore è visibile in Kubeflow e MLRun.</block>
  <block id="9d1126b5d7690c0eb46dd7713822680e" category="section-title">deploy-inference-function.ipynb</block>
  <block id="827ebf8bb3ee1798b5394ecd2a8bb3ae" category="paragraph">L'ultima fase della pipeline consiste nell'implementare il modello come funzione senza server per deduzione continua. Questo notebook richiama la creazione della funzione senza server definita in<block ref="8484275272e5c25a4b20c092eaed5ed3" prefix=" " category="inline-code"></block>.</block>
  <block id="4d2c908b5247626d682903dc9527bd05" category="section-title">Esaminare e costruire la pipeline</block>
  <block id="6c8673acfb6249793bed69954ca16a9b" category="paragraph">La combinazione di eseguire tutti i notebook in una pipeline consente l'esecuzione continua di esperimenti per rivalutare l'accuratezza del modello rispetto alle nuove metriche. Aprire innanzitutto<block ref="0967a45abd189b49d2e7af9c1df9db9f" prefix=" " category="inline-code"></block> notebook. Ti illustreremo i dettagli che mostrano come NetApp e Iguazio semplificano l'implementazione di questa pipeline ML.</block>
  <block id="50d4decae4f0f08e83a1bd8342bd6ef1" category="paragraph">Utilizziamo MLRun per fornire contesto e gestire l'allocazione delle risorse in ogni fase della pipeline. Il servizio API MLRun viene eseguito nella piattaforma Iguazio ed è il punto di interazione con le risorse Kubernetes. Ogni sviluppatore non può richiedere direttamente le risorse; l'API gestisce le richieste e abilita i controlli di accesso.</block>
  <block id="c7c5ccf69a87e301b134dcfdf46ab307" category="paragraph">La pipeline può funzionare con volumi cloud NetApp e volumi on-premise. Questa dimostrazione è stata realizzata per utilizzare i volumi cloud, ma è possibile vedere nel codice l'opzione di esecuzione on-premise.</block>
  <block id="ce16d064e13fffda0ff2a07c50276f33" category="paragraph">La prima azione necessaria per trasformare un notebook Jupyter in un passo Kubeflow è trasformare il codice in una funzione. Una funzione ha tutte le specifiche richieste per eseguire il notebook. Quando scorri il notebook, puoi vedere che definiamo una funzione per ogni fase della pipeline.</block>
  <block id="8bbbd384e919f705f071525a96cdfaec" category="cell">Parte del notebook</block>
  <block id="5d75cd50687084d681964f5c6ee8a73a" category="cell">&lt;code_to_function&gt; (parte del modulo MLRun)</block>
  <block id="eef456f018469b2d403742d05e33a5dd" category="cell">Nome della funzione: Nome del progetto. utilizzato per organizzare tutti gli artefatti del progetto. Questo è visibile nell'interfaccia utente di MLRun. Gentile. In questo caso, un lavoro Kubernetes. Questo potrebbe essere Dask, mpi, sparkk8s e molto altro ancora. Per ulteriori informazioni, consulta la documentazione di MLRun. File. Il nome del notebook. Questa può anche essere una posizione in Git (HTTP).</block>
  <block id="d0161cbbc56081c803c919679b76b846" category="cell">Il nome dell'immagine Docker che stiamo utilizzando per questo passaggio. Abbiamo creato questo documento in precedenza con il notebook create-image.ipynb.</block>
  <block id="28bb8862d962b462f621d9098de311cd" category="cell">montaggi_volumi e volumi</block>
  <block id="a6841da965bfb59838d367b9fdc30a8c" category="cell">Dettagli per montare il NetApp Cloud Volume in fase di esecuzione.</block>
  <block id="5d9261bc63dfeef8d26c807e36a9daa4" category="paragraph">Definiamo anche i parametri per le fasi.</block>
  <block id="fcd242cd0d87d4de3be34f843180bdb0" category="paragraph">Una volta definita la funzione per tutti i passaggi, è possibile costruire la pipeline. Utilizziamo il<block ref="98dd4155c9c8287a5a8e1d92417d0a99" prefix=" " category="inline-code"></block> per definire questa definizione. La differenza tra l'utilizzo di MLRun e la creazione di codice da soli è la semplificazione e la riduzione del codice.</block>
  <block id="f02b57d2fbd61d7629e76438ba68f7a1" category="paragraph">Le funzioni che abbiamo definito vengono trasformate in componenti passo-passo utilizzando<block ref="6cebb60f71d9de65143ade7a8388e27a" prefix=" " category="inline-code"></block> Funzione di MLRun.</block>
  <block id="8859e75c5bfd3a8ea5a783296d71b795" category="section-title">Definizione della fase Snapshot</block>
  <block id="dabb827ac33da3a8d8a2384874221aab" category="paragraph">Avviare una funzione Snapshot, eseguire l'output e montare v3io come origine:</block>
  <block id="3225a10b07f1580f10dee4abc3779e6c" category="cell">Parametri</block>
  <block id="422ac26927e8ad3d6b30617226e26c2a" category="cell">NewTask</block>
  <block id="b954691c9a06ef7281bf4c836e7684f1" category="cell">NewTask è la definizione dell'esecuzione della funzione.</block>
  <block id="7871261404e7a8d93339696184b243b9" category="cell">(Modulo MLRun)</block>
  <block id="4522319a8fbbe0a85c82e604047dfe6c" category="cell">Gestore. Nome della funzione Python da richiamare. Abbiamo utilizzato il gestore dei nomi nel notebook, ma non è necessario. parametri. I parametri passati all'esecuzione. All'interno del codice, utilizziamo Context.get_param (‘PARAMETRO’) per ottenere i valori.</block>
  <block id="6cebb60f71d9de65143ade7a8388e27a" category="cell">as_step</block>
  <block id="070faabab806ce863279f5bd38452cc4" category="cell">Nome. Nome della fase della pipeline Kubeflow. output. Questi sono i valori che la procedura aggiunge al dizionario al completamento. Dai un'occhiata al notebook SNAP_cv.ipynb. mount_v3io(). In questo modo viene configurato il passo per montare /User per l'utente che esegue la pipeline.</block>
  <block id="a8aff967e1649a1c82ea607c881e8091" category="cell">input</block>
  <block id="6f1ba99c8ee685047e0fa3c32349a01f" category="cell">È possibile passare a un passo gli output di un passo precedente. In questo caso, snap.outputs['snapVolumeDetails'] è il nome della copia Snapshot creata nel passo SNAP.</block>
  <block id="a399d9e54dd5dc35c6b455d995702175" category="cell">out_path</block>
  <block id="026446ea82508e4c9f41609b3484b4cb" category="cell">Una posizione in cui posizionare gli artefatti che generano utilizzando il modulo MLRun log_Artifacts.</block>
  <block id="2fe8889e7fb9545ea383ff3c0451cabf" category="paragraph">Puoi correre<block ref="0967a45abd189b49d2e7af9c1df9db9f" prefix=" " category="inline-code"></block> dall'alto verso il basso. È quindi possibile accedere alla scheda Pipeline dalla dashboard di Iguazio per monitorare l'avanzamento, come mostrato nella scheda Pipeline della dashboard di Iguazio.</block>
  <block id="74dec5a93e3c1ccb06f26ebc6f9401fb" category="paragraph"><block ref="74dec5a93e3c1ccb06f26ebc6f9401fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f47db69a9e60b47a1c8f7800753f6b57" category="paragraph">Poiché abbiamo registrato la precisione delle fasi di training in ogni sessione, abbiamo una registrazione di accuratezza per ogni esperimento, come mostrato nella documentazione relativa alla precisione del training.</block>
  <block id="5bb7a1a5b810ce843cd4d41a7137ce26" category="paragraph"><block ref="5bb7a1a5b810ce843cd4d41a7137ce26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9ebd260b4ed60a239b8228fe68b2dbc" category="paragraph">Se si seleziona la fase Snapshot, è possibile visualizzare il nome della copia Snapshot utilizzata per eseguire questo esperimento.</block>
  <block id="1d231b2e1da6122607105ce52f87a763" category="paragraph"><block ref="1d231b2e1da6122607105ce52f87a763" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fc578a2d3b019d646da18c9172282dc" category="paragraph">La fase descritta presenta artefatti visivi per esplorare le metriche utilizzate. È possibile espandere per visualizzare il grafico completo come mostrato nell'immagine seguente.</block>
  <block id="ffb599ed438d33d337e7cca9a1fbaf07" category="paragraph"><block ref="ffb599ed438d33d337e7cca9a1fbaf07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89238f00748675db057567546f67c2c5" category="paragraph">Il database API di MLRun tiene traccia anche di input, output e artefatti per ogni esecuzione organizzata per progetto. Un esempio di input, output e artefatti per ciascuna seriografia può essere visualizzato nell'immagine seguente.</block>
  <block id="a8baa83f88edfb0fceafeda75819cb5f" category="paragraph"><block ref="a8baa83f88edfb0fceafeda75819cb5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c6050fe85d7b5528bc8356c88eab725" category="paragraph">Per ogni lavoro, memorizziamo ulteriori dettagli.</block>
  <block id="8683624a37c6626765321b5cc2f60954" category="paragraph"><block ref="8683624a37c6626765321b5cc2f60954" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f02f72c9470e67a8b3c5f9054b0a32c" category="inline-link">Sito MLRun GitHub</block>
  <block id="01661b1e0825da7434573266df1672e0" category="paragraph">In questo documento sono disponibili ulteriori informazioni su MLRun. Gli artefatti di al, inclusa la definizione delle fasi e delle funzioni, possono essere salvati nel database API, con versione e richiamati singolarmente o come progetto completo. I progetti possono anche essere salvati e inviati a Git per un utilizzo successivo. Ti invitiamo a scoprire di più su<block ref="92ae596fd8e402850e22f59a73ed3a44" category="inline-link-rx"></block>.</block>
  <block id="43486dfb907f148e40f3719f314caeb4" category="inline-link-macro">Avanti: Implementare Grafana Dashboard</block>
  <block id="0670d6ac4e77f5862afcc2fde43bcc72" category="paragraph"><block ref="0670d6ac4e77f5862afcc2fde43bcc72" category="inline-link-macro-rx"></block></block>
  <block id="84860cc77161e23e44eccd05430c00ea" category="doc">Invio di job in Run:ai CLI</block>
  <block id="68c9d249f35c91dfcc4a11e209ccbdba" category="paragraph">Questa sezione fornisce i dettagli sui comandi Run:ai di base che è possibile utilizzare per eseguire qualsiasi lavoro Kubernetes. È suddiviso in tre parti in base al tipo di carico di lavoro. I carichi di lavoro ai/ML/DL possono essere suddivisi in due tipi generici:</block>
  <block id="754edd5bae16b4a2ed8e6673821d3339" category="list-text">*Sessioni di training non presidiate*. Con questi tipi di carichi di lavoro, il data scientist prepara un carico di lavoro a esecuzione automatica e lo invia per l'esecuzione. Durante l'esecuzione, il cliente può esaminare i risultati. Questo tipo di carico di lavoro viene spesso utilizzato in produzione o quando lo sviluppo del modello si trova in una fase in cui non è richiesto alcun intervento umano.</block>
  <block id="fdfda155b7c1021ae5e73d2ab01c0129" category="list-text">*Sessioni di build interattive*. Con questi tipi di carichi di lavoro, il data scientist apre una sessione interattiva con Bash, Jupyter notebook, PyCharm remoto o IDE simili e accede direttamente alle risorse GPU. Abbiamo incluso un terzo scenario per l'esecuzione di workload interattivi con porte connesse per rivelare una porta interna all'utente del container.</block>
  <block id="6ec08732676824c58d76b0ecdc2aed24" category="section-title">Carichi di lavoro di training non presidiati</block>
  <block id="18cb2734d0533ff093ddcb1b3005e216" category="paragraph">Dopo aver impostato i progetti e allocato le GPU, è possibile eseguire qualsiasi carico di lavoro Kubernetes utilizzando il seguente comando nella riga di comando:</block>
  <block id="68e667063c4711033bbf6b7f8b312e1f" category="paragraph">Questo comando avvia un processo di training non assistito per il team-a con un'allocazione di una singola GPU. Il lavoro si basa su un'immagine del docker di esempio,<block ref="1f2da2a856d7277c86fd9f58e93ae507" prefix=" " category="inline-code"></block>. Abbiamo nominato il lavoro<block ref="b10f762d9445989813486accc082c6f1" prefix=" " category="inline-code"></block>. È quindi possibile monitorare l'avanzamento del lavoro eseguendo il seguente comando:</block>
  <block id="cbae10285b6d282e740369a59fd25aaf" category="paragraph">La figura seguente mostra il risultato di<block ref="cfd2ddb98fc396c2e8a48e9ad76dbb58" prefix=" " category="inline-code"></block> comando. Gli stati tipici che potrebbero essere visualizzati includono:</block>
  <block id="e749e4e3bf7ed6d5368f336ba6ceeead" category="list-text"><block ref="8627ca3ad23f4fb9adc6ba05047004c6" prefix="" category="inline-code"></block>. Il container del docker viene scaricato dal repository cloud.</block>
  <block id="f5231f23820da3ad520bb16a9dfe97a7" category="list-text"><block ref="2d13df6f8b5e4c5af9f87e0dc39df69d" prefix="" category="inline-code"></block>. Il lavoro è in attesa di essere pianificato.</block>
  <block id="411497b40a902afd2813d3c7af137ffb" category="list-text"><block ref="5bda814c4aedb126839228f1a3d92f09" prefix="" category="inline-code"></block>. Il processo è in esecuzione.</block>
  <block id="c0801feb8216aa6b36a769e14c3bc138" category="paragraph"><block ref="c0801feb8216aa6b36a769e14c3bc138" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4f5f0c8fb5ec5bccf18cfd167b1d3bc5" category="paragraph">Per ottenere uno stato aggiuntivo sul lavoro, eseguire il seguente comando:</block>
  <block id="db0b192c9c9b9885b435e466b9ac861c" category="paragraph">Per visualizzare i log del lavoro, eseguire<block ref="13be9f2fcfc2532531562b1e0c6dd431" prefix=" " category="inline-code"></block> comando:</block>
  <block id="280782f59c990a941b600c998427a52c" category="paragraph">In questo esempio, dovresti visualizzare il registro di una sessione DL in esecuzione, inclusi l'epoca di training corrente, l'ETA, il valore della funzione di perdita, l'accuratezza e il tempo trascorso per ogni fase.</block>
  <block id="848ad760ae00e3eca33445cd09cfdf34" category="paragraph">È possibile visualizzare lo stato del cluster nell'interfaccia utente Run:ai all'indirizzo<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>. In Dashboard &gt; Panoramica, è possibile monitorare l'utilizzo della GPU.</block>
  <block id="f899123d07ffe99c3d97952ae96017ed" category="paragraph">Per arrestare questo carico di lavoro, eseguire il seguente comando:</block>
  <block id="1f979b6140776c287d458036805ad8aa" category="inline-link">lancio di workload di training non presidiati</block>
  <block id="637552715214e8c0c87022bac459e824" category="paragraph">Questo comando interrompe il carico di lavoro del training. È possibile verificare questa azione eseguendo<block ref="cfd2ddb98fc396c2e8a48e9ad76dbb58" prefix=" " category="inline-code"></block> di nuovo. Per ulteriori informazioni, vedere<block ref="e5fbbc266c1fd3a9a029581f5747622d" category="inline-link-rx"></block>.</block>
  <block id="7afece97948db40e546138d81dd343e1" category="section-title">Workload di build interattivi</block>
  <block id="30330792601ba24e9ad5f4f5ee0d5151" category="paragraph">Dopo aver impostato i progetti e allocato le GPU, è possibile eseguire un carico di lavoro di build interattivo utilizzando il seguente comando dalla riga di comando:</block>
  <block id="ca57038d87e3f48eb98329e6fd449824" category="paragraph">Il lavoro si basa su un python immagine del docker di esempio. Abbiamo chiamato la creazione di job 1.</block>
  <block id="39fd96ce47a2aa757eb5cc98cd910730" category="admonition">Il<block ref="1f21ac5e64afff9d56d5047ace21ffd8" prefix=" " category="inline-code"></block> flag indica che il lavoro non ha inizio o fine È responsabilità del ricercatore chiudere il lavoro. L'amministratore può definire un limite di tempo per i lavori interattivi dopo il quale vengono terminati dal sistema.</block>
  <block id="d39d9c693980c2af510d4a58be6f2620" category="paragraph">Il<block ref="41edd6984c1a14599f6d54cd297a423e" prefix=" " category="inline-code"></block> Flag assegna una singola GPU a questo lavoro. Il comando e l'argomento forniti sono<block ref="f18e9c054b4fccbc27cd764cb472a213" prefix=" " category="inline-code"></block>. È necessario fornire un comando, altrimenti il container viene avviato e quindi chiuso immediatamente.</block>
  <block id="aedc6bf8e3cb52af4a660584c69353ca" category="paragraph">I seguenti comandi funzionano in modo simile ai comandi descritti in <block ref="a09c3ced87a580a4004dfa2429aba9c7" category="inline-xref-macro-rx"></block>:</block>
  <block id="1d2bac5ee25c12c0ee793df98c1b4d49" category="list-text"><block ref="cfd2ddb98fc396c2e8a48e9ad76dbb58" prefix="" category="inline-code"></block>: Mostra il nome, lo stato, l'età, il nodo, l'immagine, Progetto, utente e GPU per i lavori.</block>
  <block id="6b5b5fdb13c8b8af02a41b296af91a2e" category="list-text"><block ref="1051ced5efff9d2868a1edd38f951e6e" prefix="" category="inline-code"></block>: Visualizza lo stato aggiuntivo nella creazione del job 1.</block>
  <block id="9c1e129aa488b11d05275f016f42dda5" category="list-text"><block ref="624c1f4b1937b32c12cfa1346cb037f9" prefix="" category="inline-code"></block>: Interrompe la creazione interattiva del workload 1.per ottenere una shell bash nel container, utilizzare il seguente comando:</block>
  <block id="ac97b61bdc50cfc22ffd507de190d00c" category="paragraph">Questo fornisce una shell diretta nel computer. I data scientist possono quindi sviluppare o perfezionare i propri modelli all'interno del container.</block>
  <block id="c7fdd5fcf033fb9395c27ecbf2e54fc9" category="inline-link">avvio e utilizzo di workload di build interattivi</block>
  <block id="ff53dc42327d97c7410a6ac241222ffe" category="paragraph">È possibile visualizzare lo stato del cluster nell'interfaccia utente Run:ai all'indirizzo<block ref="29f2b88109b12c4db8e875d3f5ba7aae" category="inline-link-rx"></block>. Per ulteriori informazioni, vedere<block ref="f3d6ab8050b43c83f452779c7622ab1d" category="inline-link-rx"></block>.</block>
  <block id="1028c65994f7201e0f43b3bf5d3c6b41" category="section-title">Carichi di lavoro interattivi con porte connesse</block>
  <block id="7d05c708b92b4809bfe9bf66edf8f765" category="inline-link">Ingresso</block>
  <block id="34274fcc13408f06acfe43c4065c3f3b" category="paragraph">Come estensione dei carichi di lavoro di build interattivi, è possibile rivelare le porte interne all'utente del container quando si avvia un container con la CLI Run:ai. Questo è utile per ambienti cloud, per lavorare con i notebook Jupyter o per connettersi ad altri microservizi.<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> Consente l'accesso ai servizi Kubernetes dall'esterno del cluster Kubernetes. È possibile configurare l'accesso creando un insieme di regole che definiscono quali connessioni in entrata raggiungono i servizi.</block>
  <block id="e7f72a2c9a0cb7337eb00a3093f846da" category="paragraph">Per una migliore gestione dell'accesso esterno ai servizi in un cluster, si consiglia agli amministratori del cluster di eseguire l'installazione<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> E configurare LoadBalancer.</block>
  <block id="16d79943625573d5b80809fe2a7ddbdd" category="paragraph">Per utilizzare Ingress come tipo di servizio, eseguire il seguente comando per impostare il tipo di metodo e le porte durante l'invio del carico di lavoro:</block>
  <block id="79fcc0299f1a85ebab053926e2222bca" category="paragraph">Una volta avviato il container, eseguire<block ref="cfd2ddb98fc396c2e8a48e9ad76dbb58" prefix=" " category="inline-code"></block> per visualizzare<block ref="8d6518907bf83f7ae243a42bc2d2daba" prefix=" " category="inline-code"></block> Con cui accedere al Jupyter notebook. L'URL è composto dall'endpoint di ingresso, dal nome del processo e dalla porta. Ad esempio, vedere<block ref="0309fbe8f364c8f6dfe6f383da8c46c2" category="inline-link-rx"></block>.</block>
  <block id="451b08ed1bf6f7f0a8931cff52c4c45e" category="inline-link">lancio di un workload di build interattivo con porte connesse</block>
  <block id="b524842923f8cb1e38064fadc680893f" category="paragraph">Per ulteriori informazioni, vedere<block ref="414875add8a18a03ddddfb14fb1c47f4" category="inline-link-rx"></block>.</block>
  <block id="5bb97c2dd089da990a792356c72a6128" category="inline-link-macro">Successivo: Elevato utilizzo del cluster</block>
  <block id="8f87de13e6ff3dd2fc164bdb930759bb" category="paragraph"><block ref="8f87de13e6ff3dd2fc164bdb930759bb" category="inline-link-macro-rx"></block></block>
  <block id="45ce76bfe721ca13d37ca15fdbebd391" category="paragraph">Gli autori riconoscono con gratitudine i contributi che sono stati apportati a questo white paper dai nostri stimati colleghi di NVIDIA: Davide Onofrio, Alex Qi, Sicong Ji, Marty Jain e Robert Sohigian. Gli autori desiderano inoltre ringraziare i principali membri del team NetApp: Santosh Rao, David Arnette, Michael Oglesby, Brent Davis, Andy Sayare, Erik Mulder e Mike McNamara.</block>
  <block id="81fbc4247f2c3a990b090cef6b9ebe03" category="paragraph">Il nostro sincero apprezzamento e ringraziamento va a tutti questi individui, che hanno fornito informazioni e competenze che hanno contribuito enormemente alla creazione di questo documento.</block>
  <block id="bc2f62a5c14dc9d16f38cc32c304164c" category="paragraph"><block ref="bc2f62a5c14dc9d16f38cc32c304164c" category="inline-link-macro-rx"></block></block>
  <block id="8383a1cf96c028a0986b7371049c8495" category="doc">Riepilogo dei casi d'utilizzo della previsione di guasto dei dispositivi di rete</block>
  <block id="dea416ff04e558b0d76cce896b618880" category="paragraph">Questo caso di utilizzo si basa su un cliente Iguazio nello spazio delle telecomunicazioni in Asia. Con 100.000 clienti Enterprise e 125.000 eventi di interruzione della rete all'anno, era fondamentale prevedere e intraprendere azioni proattive per evitare che i guasti della rete influenzino i clienti. Questa soluzione ha fornito loro i seguenti vantaggi:</block>
  <block id="feb68271e6d14db0b1ff524f3eb47a27" category="list-text">Analisi predittiva dei guasti di rete</block>
  <block id="70e00676492bea584fb8e7d551515eb5" category="list-text">Integrazione con un sistema di ticketing</block>
  <block id="6de8d1444549249c0161228a7b7c1d27" category="list-text">Intraprendere azioni proattive per prevenire i guasti di rete come risultato di questa implementazione di Iguazio, il 60% dei guasti è stato prevenuto in modo proattivo.</block>
  <block id="fd80dbb606385d62c59605ec96147d3f" category="inline-link-macro">Pagina successiva: Panoramica dell'installazione</block>
  <block id="d31627f0c8fea1236773b2420ab9cd39" category="paragraph"><block ref="d31627f0c8fea1236773b2420ab9cd39" category="inline-link-macro-rx"></block></block>
  <block id="13e8f52d7e19f83d3e64003c58ea220b" category="doc">Implementazione dell'infrastruttura virtuale VMware su NetApp HCI con NDE (implementazione automatica)</block>
  <block id="2635318d9bf1ea76c73bfab7f3eeafb7" category="section-title">Prerequisiti per l'implementazione di NDE</block>
  <block id="f6ec2c1aa5118cb19e89af5a10ecb65c" category="inline-link">Elenco di controllo per i prerequisiti di NetApp HCI</block>
  <block id="2187fc20798cda55150d8c067fac10be" category="paragraph">Consultare<block ref="c760383d1767df51ab118e6ffc289894" category="inline-link-rx"></block> Per visualizzare i requisiti e i consigli per NetApp HCI prima di iniziare la distribuzione.</block>
  <block id="cd02d0868a7414dd1e76924b30b82b52" category="list-text">Configurazione e requisiti di rete e switch</block>
  <block id="1d8b6c167080876dff9ad2e74e70fecf" category="list-text">Preparare gli ID VLAN richiesti</block>
  <block id="17cec09f14c225b5f27dc73542e9077a" category="list-text">Configurazione dello switch</block>
  <block id="4d40082ed807aa2fb7e1d2f03921e4d4" category="list-text">Requisiti dell'indirizzo IP per NetApp HCI e VMware</block>
  <block id="2e8e4792043f43cb4b34a84b8dcd909b" category="list-text">DNS e requisiti di conservazione del tempo</block>
  <block id="829710d6ec2a8e59e7a69fb3537ec494" category="list-text">Preparazione finale</block>
  <block id="fb720b4ad7c03710e0e5771c9fb58b44" category="section-title">Esecuzione NDE</block>
  <block id="cf50c81e30d1d64fcb4992a9792abedb" category="paragraph">Prima di eseguire NDE, è necessario completare il rack e lo stack di tutti i componenti, la configurazione degli switch di rete e la verifica di tutti i prerequisiti. È possibile eseguire NDE collegandosi all'indirizzo di gestione di un singolo nodo di storage se si intende consentire a NDE di configurare automaticamente tutti gli indirizzi.</block>
  <block id="130c61c344b6fbf262b6f63818eab7e4" category="paragraph">NDE esegue le seguenti attività per portare online un sistema HCI:</block>
  <block id="d89f68a2ec388fe5d72fb6fe024a0176" category="list-text">Installa il nodo di storage (software NetApp Element) su almeno due nodi di storage.</block>
  <block id="f6f86c1086573c7daeb1f48535041576" category="list-text">Installa l'hypervisor VMware su un minimo di due nodi di calcolo.</block>
  <block id="0718265bec3e2ee6fc9d5e0773b5ff60" category="list-text">Installa VMware vCenter per gestire l'intero stack NetApp HCI.</block>
  <block id="e09575b9713329ebe2480dbf404b2b1b" category="list-text">Installa e configura il nodo di gestione dello storage NetApp (mNode) e NetApp Monitoring Agent.</block>
  <block id="dddc28f734d0bcb367638f51ef8b4dfa" category="admonition">Questa convalida utilizza NDE per configurare automaticamente tutti gli indirizzi. È inoltre possibile impostare DHCP nel proprio ambiente o assegnare manualmente gli indirizzi IP per ciascun nodo di storage e nodo di calcolo. Questi passaggi non sono trattati in questa guida.</block>
  <block id="dd9cd526f5753b79bda6de19f1a66fe9" category="paragraph">Come menzionato in precedenza, questa convalida utilizza una configurazione a due cavi per i nodi di calcolo.</block>
  <block id="32691d86c49e682187776e0262b732d7" category="paragraph">I passaggi dettagliati per l'NDE non sono trattati in questo documento.</block>
  <block id="968a3687be335c74374e73712c63e2e4" category="inline-link">Guida all'implementazione</block>
  <block id="8b6e1a3a9d21ff63520793416432cd56" category="paragraph">Per istruzioni dettagliate sul completamento dell'implementazione della piattaforma NetApp HCI di base, vedere<block ref="7742239770a3accee30f01673a1a43a5" category="inline-link-rx"></block>.</block>
  <block id="61ef02ded53524d506cd714c5821cd86" category="list-text">Una volta terminato NDE, accedere a vCenter e creare un Distributed Port Group<block ref="b792ce2538db0b838bb1f2cd727d3417" prefix=" " category="inline-code"></block> Per l'utilizzo della rete NFS da parte di ONTAP Select e dell'applicazione.</block>
  <block id="9fb27fdce8d8c70b2c7b741958c8ac6e" category="inline-link-macro">Pagina successiva: Configurare NetApp H615c (implementazione manuale)</block>
  <block id="6623698128b1c14d8639f2404306f783" category="paragraph"><block ref="6623698128b1c14d8639f2404306f783" category="inline-link-macro-rx"></block></block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">Questo documento segue il codice MLPerf Inference v0.7, il codice MLPerf Inference v1.1 e le regole. Abbiamo eseguito benchmark progettati per l'inferenza ai margini, come definito nelle tabelle presentate in questa sezione.</block>
  <block id="35e08a3e7b357a4284ef29b287063ae5" category="paragraph"><block ref="35e08a3e7b357a4284ef29b287063ae5" category="inline-link-macro-rx"></block></block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">regole</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">Questo documento segue l'inferenza MLPerf v0.7<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block>, MLPerf Inference v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block>, e.<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block>. Abbiamo eseguito benchmark MLPerf progettati per l'inferenza ai margini, come definito nella tabella seguente.</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">Area</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">Dimensione QSL</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">Qualità</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">Vincolo di latenza multi-stream</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">Visione</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">Classificazione delle immagini</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Resnet50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">ImageNet (224 x 224)</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">99% del 32° PQ</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50 ms.</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">Rilevamento di oggetti (grande)</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD- ResNet34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">COCO (1200 x 1200)</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66 ms.</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">Rilevamento di oggetti (piccolo)</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">SSD - MobileNetsv1</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">COCO (300 x 300)</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">Segmentazione delle immagini mediche</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">UNET 3D</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">Brat 2019 (224 x 224 x 160)</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">99% e 99.9% del 32° PQ</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">Discorso</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">Voce-testo</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">RNNT</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">Sviluppo di Librispeech-clean</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">Lingua</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">Elaborazione della lingua</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">Squadra v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">Nella tabella seguente sono illustrati gli scenari di benchmark Edge.</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">Scenari</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">Classificazione delle immagini</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">Single stream, offline, multistream</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">Single stream, offline</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="cell">Voce-testo</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">Abbiamo eseguito questi benchmark utilizzando l'architettura di storage di rete sviluppata in questa convalida e confrontato i risultati con quelli delle esecuzioni locali sugli edge server precedentemente inviati a MLPerf. Il confronto serve a determinare l'impatto dello storage condiviso sulle performance di inferenza.</block>
  <block id="50cbf9a915ce97c432035077add8a92f" category="paragraph"><block ref="50cbf9a915ce97c432035077add8a92f" category="inline-link-macro-rx"></block></block>
  <block id="7054aac0ed39fa340a2d8034700f7366" category="doc">NVA-1151-DESIGN: Guida alla progettazione dei sistemi NetApp ONTAP ai con NVIDIA DGX A100</block>
  <block id="329ecbed66c88e6c0c049d051ad6aa9a" category="paragraph">David Arnette e Sung-Han Lin, NetApp</block>
  <block id="d940dfad6ae514d8235749f5f5bf92ed" category="paragraph">NVA-1151-DESIGN descrive un'architettura verificata NetApp per l'apprendimento automatico e i carichi di lavoro di intelligenza artificiale che utilizzano i sistemi storage NetApp AFF A800, i sistemi NVIDIA DGX A100 e gli switch di rete NVIDIA Mellanox. Include anche i risultati dei test di benchmark per l'architettura implementata.</block>
  <block id="c3e7dfc3691f26701d35cccf4caf7151" category="paragraph"><block ref="c3e7dfc3691f26701d35cccf4caf7151" category="inline-link-macro-rx"></block></block>
  <block id="337f05fad2de58e4a8b74cb25536b52d" category="doc">Panoramica dell'installazione</block>
  <block id="666f45aef7a28ef5ba6e4bfb2f71bcee" category="section-title">Installazione di Iguazio</block>
  <block id="b681b0e4b3576aa1cd854e2b66c16dcd" category="paragraph">Iguazio può essere installato on-premise o su un cloud provider. Il provisioning può essere eseguito come servizio e gestito da Iguazio o dal cliente. In entrambi i casi, Iguazio fornisce un'applicazione di implementazione (Provazio) per implementare e gestire i cluster.</block>
  <block id="8334797b9b3383d4f48d98178b8845ea" category="inline-link">questa pagina</block>
  <block id="ade8a7efee71036d2ca57676a54b31e3" category="paragraph">Per l'installazione on-premise, fare riferimento a.<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> per la configurazione di calcolo, rete e storage. L'implementazione on-premise di Iguazio è fornita da Iguazio senza costi aggiuntivi per il cliente. Vedere<block ref="d273dd0a16e6003b56381a70823807f7" category="inline-link-rx"></block> Per le configurazioni dei server DNS e SMTP. La pagina di installazione di Provazio viene visualizzata come segue.</block>
  <block id="8e72dced5918c4009ff80044ba6f44db" category="paragraph"><block ref="8e72dced5918c4009ff80044ba6f44db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c16d8d5e717cd029389f76abddf769b7" category="inline-link-macro">Pagina successiva: Configurazione del cluster Kubernetes</block>
  <block id="1d42e0b2a8893ff00a35554162554936" category="paragraph"><block ref="1d42e0b2a8893ff00a35554162554936" category="inline-link-macro-rx"></block></block>
  <block id="8b6327b93d10679b1f412976af9d3bba" category="summary">Azure NetApp Files, RAPIDS e Dek accelerano e semplificano l'implementazione di CORSI DI formazione E elaborazione ML su larga scala, integrati con tool di orchestrazione come Docker e Kubernetes. Unificando la pipeline di dati end-to-end, questa soluzione riduce la latenza e la complessità inerenti a molti carichi di lavoro di calcolo avanzati, colmando efficacemente il divario tra sviluppo e operazioni.</block>
  <block id="7527b11aa1f9aa169a9d6103e9c4c417" category="paragraph">Azure NetApp Files, RAPIDS e Dak accelerano e semplificano l'implementazione dell'elaborazione E della formazione ML su larga scala integrandosi con strumenti di orchestrazione come Docker e Kubernetes. Unificando la pipeline di dati end-to-end, questa soluzione riduce la latenza e la complessità inerenti a molti carichi di lavoro di calcolo avanzati, colmando efficacemente il divario tra sviluppo e operazioni. I data scientist possono eseguire query su set di dati di grandi dimensioni e condividere in modo sicuro dati e modelli algoritmici con altri utenti durante la fase di training.</block>
  <block id="a93fc9ba708498e20819f22e22ecfa5c" category="paragraph">Creando un modello di training distribuito end-to-end e una pipeline di dati nel cloud, abbiamo dimostrato un miglioramento di due ordini di grandezza nel tempo totale di completamento del workflow rispetto a un approccio open-source convenzionale che non ha sfruttato i framework di elaborazione e di elaborazione dei dati accelerati dalla GPU.</block>
  <block id="fcceee9f9e65e4b0d089c6c433f6c191" category="paragraph">La combinazione di NetApp, Microsoft, framework di orchestrazione open-source e NVIDIA riunisce le più recenti tecnologie come servizi gestiti con grande flessibilità per accelerare l'adozione della tecnologia e migliorare il time-to-market per le nuove applicazioni ai/ML. Questi servizi avanzati vengono forniti in un ambiente cloud nativo che può essere facilmente trasferito per architetture di implementazione on-premise e ibride.</block>
  <block id="eee817389517c17ec810d52f22a8222d" category="paragraph"><block ref="eee817389517c17ec810d52f22a8222d" category="inline-link-macro-rx"></block></block>
  <block id="d68d11ee3f69a45d681f78c744cae498" category="summary">È possibile modificare il livello di servizio di un volume esistente spostando il volume in un altro pool di capacità che utilizza il livello di servizio desiderato per il volume. Questa soluzione consente ai clienti di iniziare con un piccolo set di dati e un piccolo numero di GPU nel Tier standard e scalare in orizzontale o in verticale fino al Tier Premium con l'aumentare della quantità di dati e GPU.</block>
  <block id="2fe5665064f07acc8afc830f911c09a5" category="doc">Livelli di performance Azure NetApp Files</block>
  <block id="d84e339c1d1265f11e2f217f8d04354a" category="inline-link-macro">Precedente: Impostare Dask con L'implementazione DI RAPIDS su AKS utilizzando Helm.</block>
  <block id="1be55e0d10ba600a3d66b1f73f978b9f" category="paragraph"><block ref="1be55e0d10ba600a3d66b1f73f978b9f" category="inline-link-macro-rx"></block></block>
  <block id="de524ca3fc83ef426bc329e1a8b712ea" category="paragraph">È possibile modificare il livello di servizio di un volume esistente spostando il volume in un altro pool di capacità che utilizza il livello di servizio desiderato per il volume. Questa soluzione consente ai clienti di iniziare con un piccolo set di dati e un piccolo numero di GPU nel Tier standard e scalare in orizzontale o in verticale fino al Tier Premium con l'aumentare della quantità di dati e GPU. Il livello Premium offre un throughput per terabyte quattro volte superiore rispetto al livello Standard e la scalabilità verticale viene eseguita senza dover spostare alcun dato per modificare il livello di servizio di un volume.</block>
  <block id="5f92df8a2ac38644ed8ba20e16791602" category="paragraph">Per modificare dinamicamente il livello di servizio di un volume, attenersi alla seguente procedura:</block>
  <block id="8c83c4957baac2f6fea18f9d77767e3a" category="paragraph"><block ref="8c83c4957baac2f6fea18f9d77767e3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21ec2eabbe87e02cad1b0d4279ea00a7" category="list-text">Nella finestra Change Pool, selezionare il pool di capacità in cui si desidera spostare il volume.</block>
  <block id="ef3a0105bad35ad4c385d92daf6496a6" category="paragraph"><block ref="ef3a0105bad35ad4c385d92daf6496a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d0ad44a1e563aaf9f5871e32535a6c" category="list-text">Fare clic su OK.</block>
  <block id="32ae33eea9c6b04002778d814c344fb5" category="section-title">Automatizza la modifica del Tier delle performance</block>
  <block id="1c9506694c5a6fe83d1a0389d1d24564" category="paragraph">Sono disponibili le seguenti opzioni per automatizzare le modifiche del Tier di performance:</block>
  <block id="54a3bcd89041e8f96766dcb598b15511" category="list-text">La modifica dinamica del livello di servizio è ancora in Public Preview (Anteprima pubblica) e non è attivata per impostazione predefinita. Per attivare questa funzione nell'abbonamento Azure, consultare la presente documentazione<block ref="773d4c9e90e7325c5fcf35857900af6e" category="inline-link-rx"></block>.</block>
  <block id="0b01c5f61940e864222c5b29615a7eeb" category="inline-link">documentazione per la modifica del pool di volumi</block>
  <block id="265eed4df59633a830c9da49505786fc" category="list-text">I comandi di modifica del pool di volumi Azure CLI sono forniti in<block ref="db78b725076ccf0203288c6620e52eb9" category="inline-link-rx"></block> e nel seguente esempio:</block>
  <block id="4455e376dc005ca0a99be0491b917ce7" category="inline-link">Set-AzNetAppFilesVolumePool cmdlet</block>
  <block id="a5bce2f378011f6036711869a5e8073b" category="list-text">PowerShell<block ref="45dc9ea5ce8eabd60a14674d792889e0" category="inline-link-rx"></block> Modifica il pool di un volume Azure NetApp Files e viene mostrato nell'esempio seguente:</block>
  <block id="b79b50d5bff47e3a668f266c7b9dbc7b" category="inline-link-macro">Avanti: Librerie per l'elaborazione dei dati e la formazione sui modelli.</block>
  <block id="edd770dcbb857ec8f0871955fb2f7d5d" category="paragraph"><block ref="edd770dcbb857ec8f0871955fb2f7d5d" category="inline-link-macro-rx"></block></block>
  <block id="54d7050762b4d8c4af04f27ce33f1f9b" category="summary">NVIDIA ai Enterprise con NetApp e VMware - Configurazione iniziale</block>
  <block id="232b44c6dbb39fe55ed3d2ae7953c0ce" category="paragraph"><block ref="232b44c6dbb39fe55ed3d2ae7953c0ce" category="inline-link-macro-rx"></block></block>
  <block id="cb8b0bf52601ee3b7c48b31850f1a45a" category="paragraph">In questa sezione vengono descritte le attività di configurazione iniziali che devono essere eseguite per utilizzare NVIDIA ai Enterprise con NetApp e VMware.</block>
  <block id="5600e01753ba1c962c6d52ee6f0bdc72" category="inline-link-macro">Matrice di supporto dei prodotti NVIDIA ai Enterprise</block>
  <block id="b46df8af05863c37f3cd1fd611e5d2d9" category="inline-link-macro">Documentazione sulle soluzioni NetApp e VMware</block>
  <block id="bf44a799ea99e6a60d34e10561a03e4e" category="paragraph">Prima di eseguire i passaggi descritti in questa sezione, si presuppone che siano già state implementate VMware vSphere e NetApp ONTAP. Fare riferimento a. <block ref="7fc42871bfcfe7310a97a725dca473d8" category="inline-link-macro-rx"></block> Per ulteriori informazioni sulle versioni di vSphere supportate. Fare riferimento a. <block ref="627bf2e2dbf74de3f0be812563fb3ec4" category="inline-link-macro-rx"></block> Per informazioni dettagliate sull'implementazione di VMware vSphere con NetApp ONTAP.</block>
  <block id="a067b320746c7952a2b152f5a3af42b4" category="section-title">Installare il software host NVIDIA ai Enterprise</block>
  <block id="ee9d732a57ce821e52e753e2b4bd4a84" category="paragraph">Per installare il software host NVIDIA ai EnEnterprise, seguire le istruzioni riportate nelle sezioni 1-4 del <block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>.</block>
  <block id="cd110cdaa9b8e3838ddcbc34234a5317" category="inline-link-macro">Pagina successiva: Utilizzo del software NVIDIA NGC.</block>
  <block id="4a2f52c7b89633749f7644b851cb7bc6" category="paragraph"><block ref="4a2f52c7b89633749f7644b851cb7bc6" category="inline-link-macro-rx"></block></block>
  <block id="b7c82ef45da5d640a92ce6fb8fb757b7" category="doc">NVA-1153-DESIGN: NetApp ONTAP ai con sistemi NVIDIA DGX A100 e switch Ethernet Mellanox Spectrum</block>
  <block id="7bfbd6c5c294b7f81d430bd31f53aea3" category="paragraph">NVA-1153-DESIGN descrive un'architettura verificata NetApp per i carichi di lavoro di apprendimento automatico (ML) e intelligenza artificiale (ai) che utilizzano i sistemi storage NetApp AFF A800, i sistemi NVIDIA DGX A100 e gli switch Ethernet NVIDIA Mellanox Spectrum SN3700V 200 GB. Questo design è dotato di RDMA over Converged Ethernet (RoCE) per il fabric di interconnessione del cluster di calcolo per offrire ai clienti un'architettura completamente basata su ethernet per carichi di lavoro dalle performance elevate. Questo documento include anche i risultati dei test di benchmark per l'architettura implementata.</block>
  <block id="3dbdc92d258dcfc8f4fb9e2723a77875" category="paragraph"><block ref="3dbdc92d258dcfc8f4fb9e2723a77875" category="inline-link-macro-rx"></block></block>
  <block id="4ac9fa791a6d1c7c97bbae134dd22586" category="paragraph">Un vero e proprio sistema di ai conversa si impegna in un dialogo umano, comprende il contesto e fornisce risposte intelligenti. Tali modelli di ai sono spesso enormi e altamente complessi. Con le GPU NVIDIA e lo storage NetApp, è possibile formare e ottimizzare modelli di linguaggio all'avanguardia per eseguire rapidamente l'inferenza. Si tratta di un importante passo avanti verso la fine del compromesso tra un modello di ai veloce e uno grande e complesso. I modelli di comprensione del linguaggio ottimizzati per la GPU possono essere integrati nelle applicazioni di ai per settori come l'assistenza sanitaria, la vendita al dettaglio e i servizi finanziari, alimentando assistenti vocali digitali avanzati in altoparlanti intelligenti e linee di assistenza clienti. Questi sistemi di ai convergenti di alta qualità consentono alle aziende di tutti i mercati verticali di fornire servizi personalizzati precedentemente irraggiungibili quando si impegnano con i clienti.</block>
  <block id="45d5663acc501eba25058f8956035e9a" category="paragraph">Jarvis consente l'implementazione di casi di utilizzo come assistenti virtuali, avatar digitali, Fusion del sensore multimodale (CV fuso con ASR/NLP/TTS) o qualsiasi caso di utilizzo autonomo ASR/NLP/TTS/CV, ad esempio la trascrizione. Abbiamo creato un assistente virtuale al dettaglio in grado di rispondere a domande relative a meteo, punti di interesse e prezzi dell'inventario. Abbiamo anche dimostrato come migliorare le capacità di comprensione del linguaggio naturale del sistema ai conversazionale archiviando la cronologia delle conversazioni utilizzando Cloud Sync e formando modelli NEMO su nuovi dati.</block>
  <block id="38a609a97a676f2cc28ccec3d3097d4b" category="paragraph"><block ref="38a609a97a676f2cc28ccec3d3097d4b" category="inline-link-macro-rx"></block></block>
  <block id="15977ebfd8c3685ca2d8911f74efcc2d" category="summary">Questa soluzione NetApp e Lenovo è un'architettura scale-out flessibile, ideale per l'accesso all'ai di medie imprese. Lo storage NetApp offre le stesse performance o migliori dello storage SSD locale e offre i seguenti vantaggi a data scientist, data engineer e decision maker IT.</block>
  <block id="632d8fd87d5999301cfd5bd0c0f29b5f" category="inline-link-macro">Precedente: Modifiche dell'architettura.</block>
  <block id="b145bbef70e5528880cc5abbbe8575cd" category="paragraph"><block ref="b145bbef70e5528880cc5abbbe8575cd" category="inline-link-macro-rx"></block></block>
  <block id="aa91666790d55bdaa993592c884df440" category="paragraph">La soluzione NetApp e Lenovo validata qui è un'architettura scale-out flessibile ideale per l'ingresso nell'ai di medie imprese. Lo storage NetApp offre le stesse performance o migliori dello storage SSD locale e offre i seguenti vantaggi a data scientist, data engineer e decision maker IT:</block>
  <block id="6127562591a3f60f8ac270d3967754dd" category="list-text">Calcolo e storage scalabili in maniera indipendente per ridurre al minimo i costi e migliorare l'utilizzo delle risorse.</block>
  <block id="74902bcc2ed17395305301b925afee3f" category="list-text">Workflow di sviluppo e implementazione ottimizzati grazie a snapshot e cloni integrati per spazi di lavoro degli utenti istantanei ed efficienti in termini di spazio, controllo delle versioni integrato e implementazione automatizzata.</block>
  <block id="42e2aaa2f651d8ad800a51f65a258f1e" category="list-text">Protezione dei dati di livello Enterprise per disaster recovery e continuità del business.</block>
  <block id="2ea563f362255807faae7242f06c9881" category="list-text">Karthikeyan Nagalingam, Technical Marketing Engineer, NetApp</block>
  <block id="cccf21ceeae034a9e54b62eb00d9b6b3" category="list-text">Jarrett Upton, Admin, ai Lab Systems, Lenovo</block>
  <block id="fdc944d7a0de8d8e3dfff03c6a0e03c6" category="list-text">Pagina del prodotto NetApp All Flash Array</block>
  <block id="d875955d78b62e4aff0847425410f79a" category="inline-link"><block ref="d875955d78b62e4aff0847425410f79a" category="inline-link-rx"></block></block>
  <block id="45f6f9585c85146b389a4f896653a5f9" category="paragraph"><block ref="45f6f9585c85146b389a4f896653a5f9" category="inline-link-rx"></block></block>
  <block id="ec5282877903d9d2aceb3db45b21da54" category="list-text">Pagina NetApp AFF A400</block>
  <block id="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link"><block ref="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link-rx"></block></block>
  <block id="04438df627d0343d17b2f6f307b489ed" category="paragraph"><block ref="04438df627d0343d17b2f6f307b489ed" category="inline-link-rx"></block></block>
  <block id="9d92155996555576a58d20e697fc2bd6" category="list-text">Pagina del prodotto software per la gestione dei dati NetApp ONTAP</block>
  <block id="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link"><block ref="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link-rx"></block></block>
  <block id="2f08744b4a39af375744e1fc4a15b53a" category="paragraph"><block ref="2f08744b4a39af375744e1fc4a15b53a" category="inline-link-rx"></block></block>
  <block id="45913847e0b47b72b60766711f7a8c21" category="inline-link"><block ref="45913847e0b47b72b60766711f7a8c21" category="inline-link-rx"></block></block>
  <block id="229469a202dbd3052c7b165bd55eda87" category="paragraph"><block ref="229469a202dbd3052c7b165bd55eda87" category="inline-link-rx"></block></block>
  <block id="dedba6b3261804ab1e5c2b75051c62ac" category="list-text">NVIDIA SMI (nvidia-smi)</block>
  <block id="f5800a0bf7fbf711d11868c2913c218f" category="inline-link"><block ref="f5800a0bf7fbf711d11868c2913c218f" category="inline-link-rx"></block></block>
  <block id="41299b529a1014318d5e7776b9f92ad1" category="paragraph"><block ref="41299b529a1014318d5e7776b9f92ad1" category="inline-link-rx"></block></block>
  <block id="cf2dfa7ef96d78d1f3ec76316e1481d0" category="cell">Febbraio 2020</block>
  <block id="54858f2e7ecb57a17b7c0be2dedfcd7b" category="cell">Release iniziale. Validazione per SR670 e AFF A220 con TensorFlow.</block>
  <block id="abb14d21829ba186172f6e1d0b64b55b" category="cell">Gennaio 2023</block>
  <block id="c04468d92a14823a475df983d69e5f9f" category="cell">Release aggiornata. Validazione per SR 670 V2 e AFF A400 con MXNet.</block>
  <block id="ca6d5ad374e3cf268dec341c0c398442" category="summary">In questa architettura, l'attenzione si concentra sulla parte più intensiva dal punto di vista computazionale del processo di training distribuito ai o di machine learning (ML) del rilevamento di corsia.</block>
  <block id="8cb13336dc020a2fb7bca9d4e940cc64" category="paragraph">In questa architettura, l'attenzione si concentra sulla parte più intensiva dal punto di vista computazionale del processo di training distribuito ai o di machine learning (ML) del rilevamento di corsia. Il rilevamento della corsia è una delle attività più importanti nella guida autonoma, che aiuta a guidare i veicoli attraverso la localizzazione delle linee di demarcazione della corsia. Componenti statici come le linee di demarcazione della corsia guidano il veicolo a guidare in autostrada in modo interattivo e sicuro.</block>
  <block id="0721542454dcaa77c97cd9c545d9063f" category="paragraph">Gli approcci convoluzionali basati sulla rete neurale (CNN) hanno portato la comprensione e la segmentazione della scena a un nuovo livello. Anche se non funziona bene per oggetti con strutture e zone lunghe che potrebbero essere occluse (ad esempio, poli, ombre sulla corsia e così via). La rete neurale convoluzionale spaziale (SCNN) generalizza la CNN a un livello spaziale ricco. Consente la propagazione delle informazioni tra neuroni nello stesso livello, il che lo rende più adatto per oggetti strutturati come corsie, pali o camion con occlusioni. Questa compatibilità è dovuta al fatto che le informazioni spaziali possono essere rafforzate e preservano uniformità e continuità.</block>
  <block id="df38a65c87631c9530cc3a6832ea7a7d" category="paragraph">Migliaia di immagini di scena devono essere iniettate nel sistema per consentire al modello di apprendere e distinguere i vari componenti del set di dati. Queste immagini includono condizioni meteo, diurne o notturne, strade a più corsie e altre condizioni di traffico.</block>
  <block id="f7759f002b4a60b5c837abb7f8936037" category="paragraph">Per la formazione, è necessario disporre di una buona qualità e quantità di dati. Una singola GPU o più GPU possono richiedere da giorni a settimane per completare il training. La formazione distribuita sui dati può accelerare il processo utilizzando GPU multiple e multinode. Horovod è un framework di questo tipo che garantisce la formazione distribuita, ma la lettura dei dati tra cluster di GPU potrebbe costituire un ostacolo. Azure NetApp Files offre un throughput ultraveloce e elevato e una latenza ridotta e sostenuta per fornire funzionalità scale-out/scale-up in modo che le GPU vengano sfruttate al meglio della loro capacità di calcolo. I nostri esperimenti hanno verificato che tutte le GPU nel cluster vengono utilizzate in media più del 96% per l'addestramento del rilevamento di corsia mediante SCNN.</block>
  <block id="0ca450eccdc7141b5e85e9e691a7f16b" category="paragraph">La scienza dei dati incorpora diverse discipline nell'IT e nel business, pertanto più persone fanno parte del nostro pubblico di riferimento:</block>
  <block id="8acb1f50d0ada4e1149c01a5aa15b9ce" category="list-text">Gli scienziati dei dati hanno bisogno della flessibilità necessaria per utilizzare gli strumenti e le librerie di loro scelta.</block>
  <block id="d0ba3808090644db73caeb23fcc2b17c" category="list-text">I data engineer devono sapere come i dati scorrono e dove risiedono.</block>
  <block id="22a8c99419dee54a28ed1e2355a6706b" category="list-text">Esperti di casi d'utilizzo per la guida autonoma.</block>
  <block id="18f66c4bad233033dabddf6ff1289eeb" category="list-text">Amministratori e architetti del cloud per configurare e gestire le risorse cloud (Azure).</block>
  <block id="4c9b6067f04f945e9247ecd00c22e328" category="list-text">Un tecnico DevOps ha bisogno dei tool per integrare le nuove applicazioni ai/ML nelle pipeline di integrazione continua e implementazione continua (ci/CD).</block>
  <block id="53720cf6403ac6b8a2402cce66c79d4f" category="list-text">Gli utenti aziendali desiderano avere accesso alle applicazioni ai/ML.</block>
  <block id="68dcdc6243e54c14b4c41c129d574c43" category="paragraph">In questo documento, descriviamo in che modo Azure NetApp Files, RUN: Ai e Microsoft Azure aiutano ciascuno di questi ruoli a portare valore al business.</block>
  <block id="8017303b9b2c96742151083f089fc51f" category="paragraph">In questa sezione vengono illustrati i requisiti tecnologici per il caso di utilizzo del rilevamento di corsia implementando una soluzione di training distribuita su larga scala che viene eseguita completamente nel cloud Azure. La figura seguente fornisce una panoramica dell'architettura della soluzione.</block>
  <block id="f17291da16ed3dd7b705548f16706120" category="paragraph">Gli elementi utilizzati in questa soluzione sono:</block>
  <block id="f28c5620810ae2a6961a1811277a7ff8" category="list-text">Servizio Azure Kubernetes (AKS)</block>
  <block id="03023f4a63d3d8f8ff86ff8246f75b9a" category="list-text">Azure Compute SKU con GPU NVIDIA</block>
  <block id="ae5ba69294a1b9feb03e6dd75395092c" category="list-text">ESECUZIONE: AI</block>
  <block id="951370659c41a55ac9f80ff19c2f4b26" category="paragraph">I collegamenti a tutti gli elementi menzionati sono elencati nella <block ref="c8b73068ae16e202922904f7ed452f8e" category="inline-link-macro-rx"></block> sezione.</block>
  <block id="00d9279819736707d2b224ec427a8aae" category="paragraph"><block ref="00d9279819736707d2b224ec427a8aae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6a2faff353ad4e74bf3ee92e5d8b9c6" category="section-title">Requisiti di risorse e servizi cloud</block>
  <block id="5b691a1a00c6c03be70e559f55ae4fef" category="paragraph">La seguente tabella elenca i componenti hardware necessari per implementare la soluzione. I componenti cloud utilizzati in qualsiasi implementazione della soluzione possono variare in base ai requisiti del cliente.</block>
  <block id="5f3bc5eb45e6b472bf3345d1036945e9" category="cell">AKS</block>
  <block id="55b8660903ebaaed924e945432fe269e" category="cell">Almeno tre nodi di sistema e tre nodi di lavoro GPU</block>
  <block id="3580a6b3e7ba0d55af17daee07244cbd" category="cell">Nodi di sistema delle SKU delle macchine virtuali (VM)</block>
  <block id="8f75b0af54b5e672a660f4f1f1557f18" category="cell">Tre Standard_DS2_v2</block>
  <block id="a6066b29e1c4603af2c5c46cf549f764" category="cell">Nodi di lavoro GPU SKU VM</block>
  <block id="6aa4bab72f83c0b68587ee208f2c9ab0" category="cell">Tre standard_NC6s_v3</block>
  <block id="3468e131592d70a22139936f3fb21403" category="cell">Tier standard da 4 TB</block>
  <block id="d9ae1ecd6158beb6acd24c9f59d0498e" category="paragraph">La seguente tabella elenca i componenti software necessari per implementare la soluzione. I componenti software utilizzati in qualsiasi implementazione della soluzione possono variare in base ai requisiti del cliente.</block>
  <block id="cb251883efe045266871b7dd15229644" category="cell">Versione o altre informazioni</block>
  <block id="bb451ae1fa5a629a0307949d38a60e2d" category="cell">AKS - versione di Kubernetes</block>
  <block id="13c5eaa211a3778d391d5c8f65b80234" category="cell">ESEGUI:AI CLI</block>
  <block id="89633b9d6f401377b6ece0682b92530a" category="cell">v2.2.25</block>
  <block id="4b138e2d1492b1e550d42348c65cbf82" category="cell">RUN:ai Orchestration Kubernetes Operator version</block>
  <block id="6db851ff24c4b893a85242e63bbea119" category="cell">1.0.109</block>
  <block id="4a7724061c17f8cf5be61a8adf4c170f" category="cell">0.21.2</block>
  <block id="44adee2c140fc723412bae93732e5993" category="cell">20.01.1</block>
  <block id="612edeb05f6d237e20f3d843d6e7eba4" category="paragraph">Le sezioni seguenti forniscono dettagli sull'installazione Run:ai, sugli scenari di test e sui risultati ottenuti in questa convalida.</block>
  <block id="2df14da3d7db15550e8eafc892e89d8e" category="paragraph">Abbiamo validato il funzionamento e le performance di questo sistema utilizzando tool di benchmark standard di settore, inclusi i benchmark TensorFlow. Il set di dati ImageNet è stato utilizzato per formare ResNet-50, un famoso modello DL della rete neurale convoluzionale (CNN) per la classificazione delle immagini. ResNet-50 offre un risultato di training accurato con un tempo di elaborazione più rapido, che ci ha consentito di gestire una domanda sufficiente sullo storage.</block>
  <block id="13bb3aa52565b3e3f517764c0e88c324" category="paragraph"><block ref="123704fec3ddad892d7c2ae5c4de301b" category="inline-link-macro-rx"></block>.</block>
  <block id="a8a1e11a906a27bd156606bf4717e8e8" category="summary">L'architettura di questa soluzione di Support Center si basa sugli strumenti predefiniti di NVIDIA e sul NetApp DataOps Toolkit. I tool NVIDIA vengono utilizzati per implementare rapidamente soluzioni ai ad alte performance utilizzando modelli e pipeline precostruiti. Il NetApp DataOps Toolkit semplifica varie attività di gestione dei dati per accelerare lo sviluppo.</block>
  <block id="d51083e81cbf0ec7828af24692206315" category="inline-link-macro">Precedente: Casi di utilizzo.</block>
  <block id="beff34f173af198016bee889c9f9ed7a" category="paragraph"><block ref="beff34f173af198016bee889c9f9ed7a" category="inline-link-macro-rx"></block></block>
  <block id="c779b37f861deb44744634dea201514f" category="inline-link-macro">NVIDIA RIVA</block>
  <block id="ccfdc9ae99a97b7a6b8ad83a329bcdc8" category="paragraph"><block ref="eb3a0fd60dc608626ce6d809beb18359" category="inline-link-macro-rx"></block> È un SDK con accelerazione GPU per la creazione di applicazioni ai converazionali multimodali che offrono performance in tempo reale sulle GPU. Il toolkit NVIDIA Train, Adapt, and Optimize (TAO) offre un modo più rapido e semplice per accelerare la formazione e creare rapidamente modelli di ai altamente accurati e performanti, specifici per il dominio.</block>
  <block id="600ff5755ecd6aa4213eb806162b679e" category="paragraph">Il NetApp DataOps Toolkit è una libreria Python che semplifica l'esecuzione di varie attività di gestione dei dati da parte di sviluppatori, data scientist, ingegneri DevOps e data engineer. Ciò include il provisioning quasi istantaneo di un nuovo volume di dati o di uno spazio di lavoro JupyterLab, la clonazione quasi istantanea di un volume di dati o di uno spazio di lavoro JupyterLab e lo snap-shoting quasi istantaneo di un volume di dati o di uno spazio di lavoro JupyterLab per la tracciabilità e la baselining.</block>
  <block id="2b0d957e4ad1bdfd446155ff5bb8a9b2" category="section-title">Diagramma architetturale</block>
  <block id="1c8bd88c9d2cb845c6c27915f4a3fe8e" category="paragraph">Il seguente diagramma illustra l'architettura della soluzione. Esistono tre categorie di ambiente principali: Cloud, core e edge. Ciascuna delle categorie può essere distribuita geograficamente. Ad esempio, il cloud contiene archivi di oggetti con file audio in bucket in diverse regioni, mentre il core potrebbe contenere data center collegati tramite una rete ad alta velocità o NetApp Cloud Sync. I nodi edge denotano le piattaforme di lavoro quotidiane dei singoli agenti umani, in cui sono disponibili strumenti di dashboard interattivi e microfoni per visualizzare il sentimento e raccogliere dati audio dalle conversazioni con i clienti.</block>
  <block id="be5acbec67071810913f6782071a73eb" category="inline-link-macro">Progettazione dello storage</block>
  <block id="5d103a663d28ddc9aa2af5f7b958e52c" category="inline-link">RIVA</block>
  <block id="cc7a5a83afae781789c3a002465500b5" category="inline-link">Toolkit Tao</block>
  <block id="9595827147dc1170c44979ae1fcabaa6" category="paragraph">Nei data center con accelerazione GPU, le aziende possono utilizzare NVIDIA<block ref="cfd3aefe24e0725c1b0424dd8b503dc1" category="inline-link-rx"></block> Framework per la creazione di applicazioni ai conversazionali, alle quali il<block ref="ccdd6931e40e98163a0ae3c3c3bfb185" category="inline-link-rx"></block> Si connette per il finetuning e la riqualificazione dei modelli utilizzando tecniche di trasferimento L-learning. Queste applicazioni di calcolo e i flussi di lavoro sono basati su<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>, Che offre le migliori funzionalità di gestione dei dati offerte da ONTAP. Il toolkit consente ai team di dati aziendali di prototipare rapidamente i propri modelli con dati strutturati e non strutturati associati tramite snapshot e cloni per tracciabilità, controllo delle versioni, test A/B, fornendo così sicurezza, governance, e conformità alle normative. Vedere la sezione <block ref="3f1432f6921bc0c51d34759cb0d748ab" category="inline-link-macro-rx"></block> per ulteriori dettagli.</block>
  <block id="816c3453eeba98af344f96d7eefe8834" category="paragraph">Questa soluzione dimostra l'elaborazione dei file audio, il training sul modello NLP, l'apprendimento del trasferimento e le fasi dettagliate della gestione dei dati. La pipeline end-to-end risultante genera un riepilogo dei sentimenti che viene visualizzato in tempo reale sui dashboard degli agenti di supporto umano.</block>
  <block id="b6fb1598d37d2537eed4160a485b790e" category="paragraph"><block ref="b6fb1598d37d2537eed4160a485b790e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d993b502abe38cef7c7256291e3ffa8e" category="paragraph">La seguente tabella elenca i componenti hardware necessari per implementare la soluzione. I componenti hardware utilizzati in una particolare implementazione della soluzione possono variare in base ai requisiti del cliente.</block>
  <block id="62519b55e4debcf57caf02c89620de61" category="cell">Test di latenza della risposta</block>
  <block id="b763dc0a5ffab97a986c74098214cae6" category="cell">Tempo (millisecondi)</block>
  <block id="08fa9c0a2e18301dd14e18c393fb4280" category="cell">Elaborazione dei dati</block>
  <block id="08db96f19d3c99c2b42fd180d9d81580" category="cell">Deduzione</block>
  <block id="212e6da10eee5f14935bd37b84fe9684" category="paragraph">Questi test dei tempi di risposta sono stati eseguiti su oltre 50,000 file audio in 560 conversazioni. Ogni file audio era di ~100 KB come MP3 e ~1 MB quando convertito in WAV. La fase di elaborazione dei dati converte gli MP3 in file WAV. I passaggi di inferenza convertono i file audio in testo ed estraggono un sentimento dal testo. Questi passaggi sono tutti indipendenti l'uno dall'altro e possono essere parallelizzati per accelerare il processo.</block>
  <block id="c18e24981c583441c6975f2116288cb7" category="paragraph">Tenendo conto della latenza del trasferimento dei dati tra gli archivi, i manager dovrebbero essere in grado di visualizzare gli aggiornamenti dell'analisi del sentimento in tempo reale entro un secondo dalla fine della frase.</block>
  <block id="1c4968697a5851a64ad0fbf1b594e919" category="section-title">Hardware NVIDIA RIVA</block>
  <block id="5a2ebfb8baa378cfcfcba58bbb1380c2" category="cell">Requisiti</block>
  <block id="4c8be35e5fe3d8471f378a69f74c0ab6" category="cell">Linux x86_64</block>
  <block id="4d240f00b5a82cfaaf594cdc72f552f3" category="cell">Memoria GPU (ASR)</block>
  <block id="3fa503e0bb3bf46423ef9176821a1f6c" category="cell">Modelli di streaming: ~5600 MB modelli senza streaming: ~3100 MB</block>
  <block id="6345afe417f42d9e0cf6a269bff00b4c" category="cell">Memoria GPU (NLP)</block>
  <block id="217941fb2e441b0bae1b5fec0b454c31" category="cell">~500 MB per modello BERT</block>
  <block id="7e04ebd38c78635d1f8aa53de0dde49b" category="section-title">Hardware NVIDIA TAO Toolkit</block>
  <block id="03282e46abfd7449ab38bb851caf2c8d" category="cell">RAM di sistema</block>
  <block id="edaf98e5dae9931cbd74a93b3dd93849" category="cell">32 GB</block>
  <block id="6ddfc451ef4f9a7613468cd288d2ab3e" category="cell">RAM GPU</block>
  <block id="2b55387dd066c5bac646ac61543d152d" category="cell">CPU</block>
  <block id="04911a799cc8712b473ed5a3cb2b8904" category="cell">8 core</block>
  <block id="52f9ec21735243ad9917cda3ca077d32" category="cell">GPU</block>
  <block id="fceec3562665d08f1dd24689f68f0f29" category="cell">NVIDIA (A100, V100 e RTX 30x0)</block>
  <block id="2f9289dfcac06a2ba95650d7e24ea9e8" category="cell">100 GB</block>
  <block id="19aa61315132dbea1d19c7aeeef5f5b2" category="section-title">Sistema storage flash</block>
  <block id="fd5487a1e906d6cd514dbbc16f17a489" category="paragraph">ONTAP 9.9, l'ultima generazione di software per la gestione dello storage NetApp, consente alle aziende di modernizzare l'infrastruttura e passare a un data center predisposto per il cloud. Sfruttando le funzionalità di gestione dei dati leader del settore, ONTAP consente la gestione e la protezione dei dati con un singolo set di strumenti, indipendentemente dalla posizione dei dati. Puoi anche spostare liberamente i dati ovunque siano necessari: Edge, core o cloud. ONTAP 9.9 include numerose funzionalità che semplificano la gestione dei dati, accelerano e proteggono i dati critici e abilitano le funzionalità dell'infrastruttura di nuova generazione nelle architetture di cloud ibrido.</block>
  <block id="78a2efe59d4ad6ad51556ea77f5fdec3" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> È un servizio NetApp per una sincronizzazione dei dati rapida e sicura che consente di trasferire file tra condivisioni di file NFS o SMB on-premise a una delle seguenti destinazioni:</block>
  <block id="df2c24964ca3e99761acc48b2c8a75c9" category="list-text">NetApp ONTAP S3</block>
  <block id="ddcf3699b41cd4c4ee5be4b9dd95c1e6" category="list-text">Amazon Simple Storage Service (Amazon S3)</block>
  <block id="8224436b00c48149c863f4b17219a19d" category="list-text">Amazon Elastic file System (Amazon EFS)</block>
  <block id="52745271323ee9ea30e3a37d0338d118" category="list-text">Azure Blob</block>
  <block id="833c2c211a541e50ad94433664e4b5c1" category="list-text">Storage Google Cloud</block>
  <block id="5446a6bee3301e1f52824fc0affa6299" category="list-text">Storage a oggetti IBM Cloud</block>
  <block id="1b238365e840da0711b49e8f646e2fdf" category="paragraph">Cloud Sync sposta i file dove servono in modo rapido e sicuro. Una volta trasferiti, i dati sono completamente disponibili per l'utilizzo sia sull'origine che sulla destinazione. Cloud Sync sincronizza continuamente i dati, in base alla pianificazione predefinita, spostando solo i delta, in modo da ridurre al minimo il tempo e il denaro speso per la replica dei dati. Cloud Sync è uno strumento SaaS (Software as a Service) semplice da configurare e utilizzare. I trasferimenti di dati attivati da Cloud Sync vengono eseguiti da broker di dati. Puoi implementare i data broker Cloud Sync in AWS, Azure, piattaforma cloud Google o on-premise.</block>
  <block id="a5c952f5be43013a024d778712474fbc" category="paragraph">La suite di storage a oggetti software-defined di StorageGRID supporta un'ampia gamma di casi di utilizzo in ambienti multi-cloud pubblici, privati e ibridi. Grazie alle innovazioni leader del settore, NetApp StorageGRID memorizza, protegge, protegge e preserva i dati non strutturati per un utilizzo multiuso, inclusa la gestione automatica del ciclo di vita per lunghi periodi di tempo. Per ulteriori informazioni, consultare<block ref="7660f0463c83c682b9f091117b07c3b3" category="inline-link-rx"></block> sito.</block>
  <block id="6ffce2da93d4b296032f30d7b2adea01" category="paragraph">La seguente tabella elenca i componenti software necessari per implementare questa soluzione. I componenti software utilizzati in una particolare implementazione della soluzione possono variare in base ai requisiti del cliente.</block>
  <block id="d20072ce64f4d9efd57e036d2b7c30ec" category="cell">Computer host</block>
  <block id="7915eebeca25d928212b5d457786a549" category="cell">RIVA (in precedenza JARVIS)</block>
  <block id="1bf6e69c18341244d990250bf5aa3ce0" category="cell">1.4.0</block>
  <block id="7a2cd4790985cbbb0b362dfe8e59d991" category="cell">TAO Toolkit (in precedenza Transfer Learning Toolkit)</block>
  <block id="55c82b601deae028c1c5e87fd820923d" category="cell">3.0</block>
  <block id="8bec4fb7fbc1430e393d3f41063748e7" category="cell">SISTEMA OPERATIVO DGX</block>
  <block id="1b13fe3d4acac980a061d9efb92000d5" category="cell">DOTK</block>
  <block id="d233662f9c26d1a06118c93ef2fd1de9" category="cell">2.0.0</block>
  <block id="76e535c7d7533499b0d86f60a0d15b84" category="section-title">Software NVIDIA RIVA</block>
  <block id="5d7bf724a19463b3251c61a94a446c4c" category="cell">&gt;19.02 (con nvidia-docker installato)&gt;=19.03 se non si utilizza DGX</block>
  <block id="3ff6010d41ffb33d6f0971a202e76ad7" category="cell">Driver NVIDIA</block>
  <block id="616120c1963dd46f2321dd37e823f8a0" category="cell">465.19.01+ 418.40+, 440.33+, 450.51+, 460.27+ per GPU Data Center</block>
  <block id="88f8128d405513d54a3e9831c73f87a0" category="cell">Sistema operativo container</block>
  <block id="73611f9a837b7a25dad3a9c5d1a98658" category="cell">Ubuntu 20.04</block>
  <block id="a26b47ba45087eadbeaa7c4802b3a8c8" category="cell">11.3.0</block>
  <block id="d92ef06e9564a9db573d075b4220057e" category="cell">CuBLAS</block>
  <block id="a8a364c27ce7406b7be591b4f973d5bb" category="cell">11.5.1.101</block>
  <block id="9bfd6cd63a5597c998aa2d96564f5c34" category="cell">CuDNN</block>
  <block id="15daa8f1432fd7e2b07f63097623dfab" category="cell">8.2.0.41</block>
  <block id="1ed15cc4178fd8ec4d845042a8f1ead0" category="cell">NCCL</block>
  <block id="f10585a0c5c8f535143471006baef867" category="cell">2.9.6</block>
  <block id="61918500e2bc645b2aea3f447086a8a5" category="cell">TensorRT</block>
  <block id="086934e5e95d3c797fc75f38fb3d086c" category="cell">7.2.3.4</block>
  <block id="d024876954df77538311467564f00917" category="cell">Server di inferenza Triton</block>
  <block id="2efc85a476098fde0ecbf8d81505b612" category="section-title">Software NVIDIA TAO Toolkit</block>
  <block id="cb6c22f673a55391483c7f040d8cf637" category="cell">Ubuntu 18.04 LTS</block>
  <block id="23eeeb4347bdd26bfc6b7ee9a3b755dd" category="cell">python</block>
  <block id="c80362c25c18981fcf433e78dda5de78" category="cell">&gt;=3.6.9</block>
  <block id="aec7ff22e2f74b581cffbfa59e63f347" category="cell">docker-ce</block>
  <block id="21ca3af3ea5e6a282911a64dbf5ced7a" category="cell">&gt;19.03.5</block>
  <block id="0cf76d9b00333f4396d0424ae164dd07" category="cell">API docker</block>
  <block id="ca2b7e7213f7ba5d4b3923e807af27df" category="cell">1.40</block>
  <block id="ad2f80b0463af47fcb7430e0e1789841" category="cell">nvidia-container-toolkit</block>
  <block id="12b58130c1d9383cf3bf63391bd04721" category="cell">&gt;1.3.0-1</block>
  <block id="cec57b9746d41fd1c1749d591dbd7baf" category="cell">nvidia-container-runtime</block>
  <block id="68b90d96e3d934d65890ff695d37f354" category="cell">3.4.0-1</block>
  <block id="f235b98dbe494fca328354abf0b52858" category="cell">nvidia-docker2</block>
  <block id="10439f6f665bce43173e2871a0b7bfc6" category="cell">2.5.0-1</block>
  <block id="fd3811d814e856dc6a43152673bb6753" category="cell">driver nvidia</block>
  <block id="06c61cdd8c93e750b3e0d4e2537416ea" category="cell">&gt;455</block>
  <block id="b6da1806d8ccb5327c3d80bbcfea4737" category="cell">python-pip</block>
  <block id="7b043cb99d00fe56df3fead569b1a4de" category="cell">&gt;21.06</block>
  <block id="3bdf92e45d10e51e2bdc2b16cf33f345" category="cell">nvidia-pyindex</block>
  <block id="9ca445b9db010a99239196af5ac3a8b9" category="cell">Ultima versione</block>
  <block id="cf87f69879c53ebf670ee8bd793ad7ba" category="section-title">Utilizza i dettagli del caso</block>
  <block id="7cb906d40b2e5bad2205a60ef8b6a019" category="list-text">Analisi del sentimento</block>
  <block id="52a38da70697d6c80e3b6a204f64263f" category="paragraph"><block ref="52a38da70697d6c80e3b6a204f64263f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8ff4a485cc084b2a4b5bb829cf18055" category="paragraph">Il caso d'utilizzo del parlato-to-text inizia con l'acquisizione di file audio per i centri di supporto. Questo audio viene quindi elaborato per adattarsi alla struttura richiesta DA RIVA. Se i file audio non sono già stati suddivisi nelle unità di analisi, è necessario eseguire questa operazione prima di passare l'audio a RIVA. Una volta elaborato, il file audio viene trasmesso al server RIVA come chiamata API. Il server utilizza uno dei numerosi modelli che ospita e restituisce una risposta. Questa voce-testo (parte del riconoscimento vocale automatico) restituisce una rappresentazione testuale dell'audio. Da qui, la pipeline passa alla parte di analisi del sentimento.</block>
  <block id="230007c23660d290efdea5586b1716aa" category="paragraph">Per l'analisi del sentimento, l'output di testo del riconoscimento vocale automatico funge da input per la classificazione del testo. Text Classification è il componente NVIDIA per la classificazione del testo in un numero qualsiasi di categorie. Le categorie di sentimento variano da positivo a negativo per le conversazioni del centro di supporto. Le performance dei modelli possono essere valutate utilizzando un set di holdout per determinare il successo della fase di fine tuning.</block>
  <block id="3390cebd79348bc76a1e5eb5f169bedf" category="paragraph"><block ref="3390cebd79348bc76a1e5eb5f169bedf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="952b3f5758e644ef2558d59d3aace0b1" category="inline-link">Catalogo NGC NVIDIA</block>
  <block id="4fa0a0d712258621946173068bf4f7e0" category="paragraph">Una pipeline simile viene utilizzata sia per l'analisi del parlato-to-text che per l'analisi del sentimento all'interno del toolkit TAO. La differenza principale è l'utilizzo di etichette necessarie per la messa a punto dei modelli. La pipeline TAO Toolkit inizia con l'elaborazione dei file di dati. Poi i modelli preformati (provenienti da<block ref="aaddb3bb47bcb0ca6e2a55cdce808e9b" category="inline-link-rx"></block>) vengono perfezionati utilizzando i dati del centro di supporto. I modelli perfezionati vengono valutati in base alle metriche di performance corrispondenti e, se sono più performanti dei modelli preformati, vengono implementati sul server RIVA.</block>
  <block id="587796d49571c1c4d5c89993d7ed01dd" category="inline-link-macro">Segue: Considerazioni di progettazione.</block>
  <block id="1165e49145cd3a7ebc2b75e325d8797a" category="paragraph"><block ref="1165e49145cd3a7ebc2b75e325d8797a" category="inline-link-macro-rx"></block></block>
  <block id="17a9b27c376a8a5f5e184b2ebce41164" category="summary">Una volta implementato tutto, esegui le inferenze sui nuovi dati. I modelli prevedono se un utente fa clic su un annuncio in base alle attività di navigazione. I risultati della previsione sono memorizzati in un cuDF di Dask. Puoi monitorare i risultati con Prometheus e visualizzarli nelle dashboard Grafana.</block>
  <block id="af4d0cbb3c6dcf4f3a5e831b08e40ace" category="doc">Monitoraggio di Dask e RAPIDE con Prometheus e Grafana</block>
  <block id="a5d741c60ca9280a87382bcc2667207c" category="inline-link-macro">Precedente: Confronto dei tempi di training.</block>
  <block id="8162cd02e2793715a1b14265f2bfb54b" category="paragraph"><block ref="8162cd02e2793715a1b14265f2bfb54b" category="inline-link-macro-rx"></block></block>
  <block id="23c1612202d19b502b3701f893fb2557" category="inline-link">RAPIDS ai Medium post</block>
  <block id="9fed5c9f0dab5b88ba96d45cf450079f" category="paragraph">Per ulteriori informazioni, consulta questa sezione<block ref="47200b727ab2088d205d11a973529202" category="inline-link-rx"></block>.</block>
  <block id="a5705f3e27851573a7eafd2a00a523b5" category="inline-link-macro">Pagina successiva: Creazione di versioni di set di dati e modelli con NetApp DataOps Toolkit.</block>
  <block id="db75fb5c1fef47405a8df61e726e3c66" category="paragraph"><block ref="db75fb5c1fef47405a8df61e726e3c66" category="inline-link-macro-rx"></block></block>
  <block id="fb1290be14b9bc3c64a2c3c9ace6c065" category="doc">Panoramica del caso d'utilizzo e Problem Statement</block>
  <block id="aa04a8198c7c60df7adcd6cd49bec6f8" category="paragraph">I set di dati e le versioni dei set di dati si trovano in genere in un data Lake, come lo storage basato su oggetti NetApp StorageGRID, che offre costi ridotti e altri vantaggi operativi. Gli scienziati dei dati estraggono questi set di dati e li progettano in più fasi per prepararli alla formazione con un modello specifico, spesso creando più versioni lungo il percorso. Come fase successiva, il data scientist deve scegliere risorse di calcolo ottimizzate (GPU, istanze di CPU high-end, un cluster on-premise e così via) per eseguire il modello. La figura seguente mostra la mancanza di prossimità del dataset in un ambiente di calcolo ML.</block>
  <block id="cc054601488581e80cc1d19c227126f6" category="paragraph"><block ref="cc054601488581e80cc1d19c227126f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88515fca547c502286d6f2a9081fc734" category="paragraph">Tuttavia, è necessario eseguire più esperimenti di training in parallelo in diversi ambienti di calcolo, ciascuno dei quali richiede il download del dataset dal data Lake, un processo costoso e lungo. La prossimità del set di dati all'ambiente di calcolo (in particolare per un cloud ibrido) non è garantita. Inoltre, gli altri membri del team che eseguono i propri esperimenti con lo stesso set di dati devono eseguire lo stesso arduo processo. Al di là dell'evidente rallentamento dell'accesso ai dati, le sfide includono il monitoraggio delle versioni dei set di dati, la condivisione dei set di dati, la collaborazione e la riproducibilità.</block>
  <block id="30b64502c0cb2f8a9bf951993e0abbac" category="section-title">Requisiti del cliente</block>
  <block id="5243f720d7e440d7746f03df97ef885f" category="paragraph">I requisiti dei clienti possono variare per ottenere esecuzioni ML dalle performance elevate utilizzando le risorse in modo efficiente; ad esempio, i clienti potrebbero richiedere quanto segue:</block>
  <block id="1735cf11ce0034dbb80c297fb204bc21" category="list-text">Accesso rapido ai set di dati da ogni istanza di calcolo che esegue il modello di training senza incorrere in costose complessità di download e accesso ai dati</block>
  <block id="80085a846f90523080cf086e66561d52" category="list-text">L'utilizzo di qualsiasi istanza di calcolo (GPU o CPU) nel cloud o on-premise senza preoccuparsi della posizione dei set di dati</block>
  <block id="de79912b1ab8764406a232888aab85e5" category="list-text">Maggiore efficienza e produttività grazie all'esecuzione di più esperimenti di training in parallelo con diverse risorse di calcolo sullo stesso set di dati senza ritardi e latenza dei dati non necessari</block>
  <block id="5211203793a223f02322b88b2e698a82" category="list-text">Costi delle istanze di calcolo ridotti al minimo</block>
  <block id="6a6fcee71b4e22ac6a4afdfdb5940b67" category="list-text">Riproducibilità migliorata grazie a tool per la conservazione dei record dei set di dati, della loro discendenza, delle versioni e di altri dettagli sui metadati</block>
  <block id="930d18875813298018f8364069441eee" category="list-text">Condivisione e collaborazione migliorate per consentire a qualsiasi membro autorizzato del team di accedere ai set di dati ed eseguire esperimenti</block>
  <block id="5f700d00ad72470694a5aa06cd515c8b" category="paragraph">Per implementare il caching dei set di dati con il software per la gestione dei dati NetApp ONTAP, i clienti devono eseguire le seguenti attività:</block>
  <block id="41fac0272180c0141b5cd7ad6ad85a44" category="list-text">Configurare e impostare lo storage NFS più vicino alle risorse di calcolo.</block>
  <block id="25a3a7ee3cfbb4afc291cd5b94dec000" category="list-text">Determinare il set di dati e la versione da memorizzare nella cache.</block>
  <block id="dbffd2a20c35c06fbb6ba0cd17e54ef6" category="list-text">Monitorare la memoria totale impegnata nei set di dati memorizzati nella cache e la quantità di storage NFS disponibile per ulteriori commit di cache (ad esempio, gestione della cache).</block>
  <block id="61d5e7050cbe037ad5adeaf246e6be19" category="list-text">Esaurire i set di dati nella cache se non sono stati utilizzati in un determinato periodo di tempo. L'impostazione predefinita è un giorno; sono disponibili altre opzioni di configurazione.</block>
  <block id="36691dc48fac4774974c970e3bfa1a7d" category="paragraph"><block ref="36691dc48fac4774974c970e3bfa1a7d" category="inline-link-macro-rx"></block></block>
  <block id="56dfbb2acffcc994819cbad5ec450617" category="paragraph">In questa sezione vengono illustrati i concetti e i componenti associati al caching dei dati in un workflow ML.</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="section-title">Apprendimento automatico</block>
  <block id="d3f18dede1775f82df24232095090253" category="paragraph">ML sta diventando rapidamente essenziale per molte aziende e organizzazioni in tutto il mondo. Pertanto, I team IT e DevOps devono ora affrontare la sfida della standardizzazione dei carichi DI lavoro ML e del provisioning di cloud, risorse di calcolo on-premise e ibride che supportano i flussi di lavoro dinamici e intensivi richiesti dai processi E dalle pipeline ML.</block>
  <block id="f71dfff263d05c18171dcf4b8c538ebf" category="section-title">Machine Learning e Kubernetes basati su container</block>
  <block id="002f314c3c41ffb741f8c91d2274af9a" category="paragraph">I container sono istanze isolate dello spazio utente eseguite su un kernel del sistema operativo host condiviso. L'adozione dei container è in rapida crescita. I container offrono molti degli stessi vantaggi offerti dalle macchine virtuali (VM) per il sandboxing delle applicazioni. Tuttavia, poiché l'hypervisor e i livelli del sistema operativo guest su cui si basano le macchine virtuali sono stati eliminati, i container sono molto più leggeri.</block>
  <block id="ce8bb3a31abf8bfcdcdacb34d96b010a" category="paragraph">I container consentono inoltre un efficiente packaging delle dipendenze delle applicazioni, dei tempi di esecuzione e così via direttamente con un'applicazione. Il formato di packaging dei container più comunemente utilizzato è Docker Container. Un'applicazione che è stata containerizzata nel formato Docker container può essere eseguita su qualsiasi computer in grado di eseguire i container Docker. Ciò è vero anche se le dipendenze dell'applicazione non sono presenti sul computer, perché tutte le dipendenze sono contenute nel container stesso. Per ulteriori informazioni, visitare il<block ref="5b5112034c22f544bc19c7a568afbfcb" category="inline-link-rx"></block>.</block>
  <block id="cfbe31a3e8ac3348240670510232ed8f" category="paragraph">Kubernetes, il popolare container orchestrator, consente agli scienziati dei dati di lanciare processi e pipeline flessibili e basati su container. Consente inoltre ai team dell'infrastruttura di gestire e monitorare i carichi DI lavoro ML in un singolo ambiente gestito e nativo del cloud. Per ulteriori informazioni, visitare il<block ref="45556eaecf73275e38fa694031a104a3" category="inline-link-rx"></block>.</block>
  <block id="371ac536e4099ad82f6080b713ce9647" category="paragraph">Cnvrg.io è un sistema operativo ai che trasforma il modo in cui le aziende gestiscono, scalano e accelerano l'ai e lo sviluppo di data science dalla ricerca alla produzione. La piattaforma code-first è costruita dai data scientist per i data scientist e offre flessibilità per l'esecuzione on-premise o nel cloud. Grazie alla gestione dei modelli, agli MLOps e alle soluzioni DI ML continuo, cnvrg.io porta la tecnologia top di gamma ai team di data science in modo che possano dedicare meno tempo a DevOps e concentrarsi sugli algoritmi più magici. Da quando si utilizza cnvrg.io, i team di diversi settori hanno ottenuto più modelli in produzione, con un conseguente aumento del valore di business.</block>
  <block id="ffb1d184fa3790eda48f1fc2d9c2f821" category="section-title">Meta-Scheduler cnvrg.io</block>
  <block id="55fdc117823776b1ebb2170b4adfadf6" category="paragraph">cnvrg. io ha un'architettura unica che consente A IT e ingegneri di collegare diverse risorse di calcolo allo stesso piano di controllo e di fare in modo che cnvrg.io gestisca i lavori ML in tutte le risorse. Ciò significa che può collegare più cluster Kubernetes on-premise, server VM e account cloud ed eseguire carichi DI lavoro ML su tutte le risorse, come mostrato nella figura seguente.</block>
  <block id="3c7fcf7e73eda18d7277b14914857f38" category="paragraph"><block ref="3c7fcf7e73eda18d7277b14914857f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cfff0196a077e92a8fe9326f97cb7fc5" category="section-title">Caching dei dati cnvrg.io</block>
  <block id="ad693e5ee82f0e0486a136821d0a0779" category="paragraph">cnvrg.io consente agli scienziati dei dati di definire le versioni dei set di dati hot e cold con la sua tecnologia di caching dei dati. Per impostazione predefinita, i set di dati vengono memorizzati in un database di storage a oggetti centralizzato. Quindi, i data scientist possono memorizzare nella cache una versione specifica dei dati sulla risorsa di calcolo selezionata per risparmiare tempo durante il download e quindi aumentare LO sviluppo E la produttività DI ML. I set di dati memorizzati nella cache e non utilizzati per alcuni giorni vengono cancellati automaticamente dal NFS selezionato. Il caching e la cancellazione della cache possono essere eseguiti con un singolo clic; non sono richiesti né processi di codifica, NÉ OPERAZIONI IT o DevOps.</block>
  <block id="42cf1b27f88752e1e98918981aa76e41" category="section-title">Flussi cnvrg.io e PIPELINE ML</block>
  <block id="1bc2ab6c98ec5b23a8a384861da1c6ca" category="paragraph">Cnvrg.io Flows è uno strumento per la creazione di pipeline ML di produzione. Ogni componente di un flusso è uno script/codice in esecuzione su un calcolo selezionato con un'immagine di base del docker. Questo design consente a data scientist e ingegneri di creare una singola pipeline che può essere eseguita sia on-premise che nel cloud. cnvrg.io garantisce lo spostamento di dati, parametri e artefatti tra i diversi componenti. Inoltre, ogni flusso viene monitorato e monitorato per ottenere una data science riproducibile al 100%.</block>
  <block id="87cd11047488d3aa87eb2829eeb02305" category="section-title">CORE cnvrg.io</block>
  <block id="526c8ebff3057ce85f47160f32e15556" category="paragraph">Cnvrg.io CORE è una piattaforma gratuita per la community di data science per aiutare i data scientist a concentrarsi maggiormente sulla data science e meno su DevOps. L'infrastruttura flessibile DI CORE offre ai data scientist il controllo di utilizzare qualsiasi linguaggio, framework ai o ambiente di calcolo, sia on-premise che nel cloud, in modo che possano fare ciò che fanno meglio, costruire algoritmi. Il CORE cnvrg.io può essere facilmente installato con un singolo comando su qualsiasi cluster Kubernetes.</block>
  <block id="f92894a2a2633c488de71d74ace474d7" category="paragraph">ONTAP ai è un'architettura di riferimento per data center per i carichi di lavoro ML e deep learning (DL) che utilizza i sistemi storage NetApp AFF e i sistemi NVIDIA DGX con GPU Tesla V100. ONTAP ai si basa sul protocollo file NFS standard di settore su Ethernet da 100 GB, offrendo ai clienti un'infrastruttura ML/DL dalle performance elevate che utilizza tecnologie standard per data center per ridurre l'overhead di implementazione e amministrazione. L'utilizzo di protocolli e reti standardizzati consente a ONTAP ai di integrarsi in ambienti di cloud ibrido mantenendo al contempo coerenza e semplicità operativa. Come soluzione di infrastruttura pre-validata, ONTAP ai riduce i tempi e i rischi di implementazione e riduce significativamente l'overhead amministrativo, consentendo ai clienti di ottenere un time-to-value più rapido.</block>
  <block id="c2148c4c14a795b271b67f662900da4e" category="paragraph">Trident è un orchestratore di storage open source sviluppato e gestito da NetApp che semplifica notevolmente la creazione, la gestione e il consumo dello storage persistente per i carichi di lavoro Kubernetes. Trident è un'applicazione nativa di Kubernetes che viene eseguita direttamente all'interno di un cluster Kubernetes. Con Trident, gli utenti di Kubernetes (sviluppatori, data scientist, amministratori di Kubernetes e così via) possono creare, gestire e interagire con volumi di storage persistenti nel formato standard di Kubernetes che già conoscono. Allo stesso tempo, possono sfruttare le funzionalità avanzate di gestione dei dati di NetApp e un data fabric basato sulla tecnologia NetApp. Trident astratta le complessità dello storage persistente e lo rende semplice da utilizzare. Per ulteriori informazioni, visitare il<block ref="c98bfcab9052a99136f8752a5ac8ed0b" category="inline-link-rx"></block>.</block>
  <block id="ecfefbd82f34239e668be7aac3762226" category="paragraph">NetApp StorageGRID è una piattaforma di storage a oggetti software-defined progettata per soddisfare queste esigenze fornendo uno storage semplice e simile al cloud a cui gli utenti possono accedere utilizzando il protocollo S3. StorageGRID è un sistema scale-out progettato per supportare più nodi nei siti connessi a Internet, indipendentemente dalla distanza. Con il motore intelligente delle policy di StorageGRID, gli utenti possono scegliere oggetti di erasure coding tra i siti per georesilienza o replica di oggetti tra siti remoti per ridurre al minimo la latenza di accesso WAN. StorageGRID offre un eccellente data Lake di storage a oggetti primario per il cloud privato in questa soluzione.</block>
  <block id="c060a6548f860aa739b76c0178ac7c5c" category="paragraph">Il software per la gestione dei dati NetApp Cloud Volumes ONTAP offre controllo, protezione ed efficienza ai dati degli utenti con la flessibilità dei provider di cloud pubblico, tra cui AWS, Google Cloud Platform e Microsoft Azure. Cloud Volumes ONTAP è un software per la gestione dei dati nativo del cloud basato sul software di storage NetApp ONTAP, che offre agli utenti una piattaforma di storage universale di livello superiore in grado di soddisfare le loro esigenze di dati nel cloud. La disponibilità dello stesso software di storage nel cloud e on-premise offre agli utenti il valore di un data fabric senza dover formare il personale IT in nuovi metodi per la gestione dei dati.</block>
  <block id="e16f1943a363dfa46a958bd450c2ecf8" category="paragraph">Per i clienti interessati ai modelli di implementazione del cloud ibrido, Cloud Volumes ONTAP è in grado di fornire le stesse funzionalità e performance leader di settore nella maggior parte dei cloud pubblici per offrire un'esperienza utente coerente e perfetta in qualsiasi ambiente.</block>
  <block id="2d52bcd2e896c32a66c9fe10fed38e0f" category="inline-link-macro">Pagina successiva: Requisiti hardware e software</block>
  <block id="82ac5cdab15b3954389238dddbc12168" category="paragraph"><block ref="82ac5cdab15b3954389238dddbc12168" category="inline-link-macro-rx"></block></block>
  <block id="729d72c073b607d370c067152cc53a10" category="doc">Risultati della convalida</block>
  <block id="25edd21a28cb2fca00ab6f30e47c6d79" category="paragraph">Per eseguire una richiesta di inferenza di esempio, attenersi alla seguente procedura:</block>
  <block id="cb11a85322b32a7615367d2523718b49" category="list-text">Ottenere una shell al container/pod client.</block>
  <block id="b489ec265fd981ff7aa78a7721bd3101" category="list-text">Eseguire una richiesta di inferenza di esempio.</block>
  <block id="15c5e1ffe753f0365f39e7b508ce5ae0" category="paragraph"><block ref="15c5e1ffe753f0365f39e7b508ce5ae0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5bf2ae3a2d0d1dd1e0740744c9ebb1b" category="paragraph">Questa richiesta di deduzione chiama<block ref="e8121e2c92eb0c17d4d331407502d266" prefix=" " category="inline-code"></block> modello utilizzato per il riconoscimento delle immagini. Altri client possono anche inviare richieste di deduzione contemporaneamente seguendo un approccio simile e richiamando il modello appropriato.</block>
  <block id="a301641e2c9595a0c9c39ee7986f7ca8" category="paragraph"><block ref="a301641e2c9595a0c9c39ee7986f7ca8" category="inline-link-macro-rx"></block></block>
  <block id="4c787c1632a0a940cb0b44706b1d24c6" category="summary">Questa sezione fornisce una panoramica dei vari componenti tecnici necessari per completare questa soluzione.</block>
  <block id="2c6beb1e15771dbe426409f9b5d4aaf9" category="inline-link-macro">Precedente: Aree di soluzione.</block>
  <block id="8a26bc3756fc01f4b929845a326e9b9d" category="paragraph"><block ref="8a26bc3756fc01f4b929845a326e9b9d" category="inline-link-macro-rx"></block></block>
  <block id="a6d48b22bcf266404bdb8c57102c14a4" category="section-title">Protopia</block>
  <block id="b2cbc1ff8afd6c872961a852572e1782" category="paragraph">Protopia ai offre una soluzione software-only senza invadenze per l'inferenza riservata nel mercato odierno. La soluzione Protopia offre una protezione senza pari per i servizi di inferenza riducendo al minimo l'esposizione delle informazioni sensibili. L'intelligenza artificiale viene alimentata solo nelle informazioni contenute nel record di dati che sono veramente essenziali per eseguire l'attività in corso e niente di più. La maggior parte delle attività di inferenza non utilizza tutte le informazioni presenti in ogni record di dati. Indipendentemente dal fatto che l'ai stia utilizzando immagini, voce, video o persino dati tabulari strutturati, Protopia offre solo ciò di cui ha bisogno il servizio di inferenza. La tecnologia brevettata core utilizza il rumore matematicamente curato per trasformare in modo stocoso i dati e raccogliere le informazioni non necessarie per un determinato servizio ML. Questa soluzione non maschera i dati, ma modifica la rappresentazione dei dati utilizzando un rumore casuale a cura.</block>
  <block id="46ce082967eab6fe2e33798614d50861" category="paragraph">La soluzione Protopia formula il problema di modificare la rappresentazione come metodo di massimizzazione delle perturbazioni basato su gradiente che conserva ancora le informazioni pertinenti nello spazio delle funzionalità di input rispetto alla funzionalità del modello. Questo processo di rilevamento viene eseguito come un passo di messa a punto al termine della formazione sul modello ML. Dopo che il pass genera automaticamente un set di distribuzioni di probabilità, una trasformazione dei dati a basso overhead applica campioni di rumore da queste distribuzioni ai dati, offuscandoli prima di passarli al modello per l'inferenza.</block>
  <block id="4fb9892dc0183c3142a3629cecc3104a" category="paragraph">L'architettura di riferimento NetApp ONTAP ai, basata su sistemi DGX A100 e sistemi storage connessi al cloud NetApp, è stata sviluppata e verificata da NetApp e NVIDIA. Offre alle organizzazioni IT un'architettura che offre i seguenti vantaggi:</block>
  <block id="988d7b305f79b990bbacdaed46f4b2bf" category="paragraph">ONTAP ai integra perfettamente i sistemi DGX A100 e i sistemi storage NetApp AFF A800 con reti all'avanguardia. ONTAP ai semplifica le implementazioni di ai eliminando la complessità e le congetture di progettazione. I clienti possono iniziare con poco e crescere senza interruzioni, gestendo in modo intelligente i dati dall'edge al core, fino al cloud e viceversa.</block>
  <block id="57e22b018aa5130ece9890cd6b45e779" category="paragraph">La figura seguente mostra diverse varianti della famiglia di soluzioni ai ONTAP con sistemi DGX A100. Le prestazioni del sistema AFF A800 sono verificate con un massimo di otto sistemi DGX A100. Aggiungendo coppie di controller storage al cluster ONTAP, l'architettura può scalare su più rack per supportare molti sistemi DGX A100 e petabyte di capacità storage con performance lineari. Questo approccio offre la flessibilità di modificare i rapporti calcolo-storage in modo indipendente in base alle dimensioni dei modelli DL utilizzati e alle metriche di performance richieste.</block>
  <block id="316a5094893ef1b058844a75c53aaf04" category="paragraph"><block ref="316a5094893ef1b058844a75c53aaf04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ecc164061fb57b585c892f0faa6f4dcf" category="inline-link">NVA-1153: NetApp ONTAP ai con sistemi NVIDIA DGX A100 e switch Ethernet Mellanox Spectrum.</block>
  <block id="3046083f382853b50c004323f2cda8f9" category="paragraph">Per ulteriori informazioni su ONTAP ai, vedere<block ref="2c1616ab9baa55036487e7ef75b3821d" category="inline-link-rx"></block></block>
  <block id="862dcadd0f2887701abaa60bf59d5aa5" category="paragraph">ONTAP 9.11, l'ultima generazione di software per la gestione dello storage NetApp, consente alle aziende di modernizzare l'infrastruttura e passare a un data center predisposto per il cloud. Sfruttando le funzionalità di gestione dei dati leader del settore, ONTAP consente la gestione e la protezione dei dati con un singolo set di strumenti, indipendentemente dalla posizione dei dati. Puoi anche spostare liberamente i dati ovunque siano necessari: Edge, core o cloud. ONTAP 9.11 include numerose funzionalità che semplificano la gestione dei dati, accelerano e proteggono i dati critici e abilitano le funzionalità dell'infrastruttura di nuova generazione nelle architetture di cloud ibrido.</block>
  <block id="94c4b42bd5bfaa12f328387b161a1686" category="paragraph">NetApp DataOps Toolkit è una libreria Python che consente a sviluppatori, data scientist, ingegneri DevOps e data engineer di eseguire facilmente varie attività di gestione dei dati, come il provisioning quasi istantaneo di un nuovo volume di dati o di un'area di lavoro JupyterLab, la clonazione quasi istantanea di un volume di dati o di un'area di lavoro JupyterLab, Snapshot quasi istantanee di un volume di dati o di uno spazio di lavoro JupyterLab per la tracciabilità o il baselining. Questa libreria Python può funzionare come un'utility a riga di comando o una libreria di funzioni che è possibile importare in qualsiasi programma Python o notebook Jupyter.</block>
  <block id="dea84e2e635ce73ddc479a38d5616c98" category="paragraph">NVIDIA Triton Inference Server è un software open-source per l'inferenza che aiuta a standardizzare l'implementazione e l'esecuzione del modello per offrire ai in produzione rapida e scalabile. Triton Inference Server ottimizza l'inferenza ai consentendo ai team di implementare, eseguire e scalare modelli di ai addestrati da qualsiasi framework su qualsiasi infrastruttura basata su GPU o CPU. Triton Inference Server supporta tutti i framework principali, come TensorFlow, NVIDIA TensorRT, PyTorch, MXNet, OpenVINO e così via. Triton si integra con Kubernetes per l'orchestrazione e la scalabilità che puoi utilizzare in tutte le principali piattaforme ai e Kubernetes del cloud pubblico. È inoltre integrato con molte soluzioni software MLOPS.</block>
  <block id="95b88f180e9eb5678e0f9ebac2cbe643" category="section-title">PyTorch</block>
  <block id="04f7f16178ab3e9bddfd0837b64d21a2" category="paragraph"><block ref="7b17fc2d2143dfdbd3bff6783f73e17c" category="inline-link-rx"></block> È un framework ML open-source. Si tratta di una libreria di tensore ottimizzata per il deep learning che utilizza GPU e CPU. Il pacchetto PyTorch contiene strutture di dati per i tensionatori multidimensionali che forniscono molte utility per la serializzazione efficiente dei tensionatori tra altre utili utility. Dispone inoltre di una controparte CUDA che consente di eseguire i calcoli del tensore su una GPU NVIDIA con funzionalità di calcolo. In questa convalida, utilizziamo la libreria OpenCV-Python (cv2) per validare il nostro modello, sfruttando al contempo i concetti di computer vision più intuitivi di Python.</block>
  <block id="377c9a91b43c5423691b5ce75db91350" category="section-title">NetApp Astra Control</block>
  <block id="eb75cc706ac8cc6c0f4cb17f4fb073dd" category="paragraph">La famiglia di prodotti NetApp Astra offre servizi di storage e gestione dei dati applicativa per le applicazioni Kubernetes on-premise e nel cloud pubblico, basati sulle tecnologie di storage e gestione dei dati di NetApp. Consente di eseguire facilmente il backup delle applicazioni Kubernetes, migrare i dati in un cluster diverso e creare istantaneamente cloni applicativi funzionanti. Se è necessario gestire le applicazioni Kubernetes in esecuzione in un cloud pubblico, consultare la documentazione per<block ref="6d442ad773e9d31651277931acd1583a" category="inline-link-rx"></block>. Astra Control Service è un servizio gestito da NetApp che fornisce la gestione dei dati applicativa dei cluster Kubernetes in Google Kubernetes Engine (GKE) e Azure Kubernetes Service (AKS).</block>
  <block id="545b3003eeeed3a05db492712188eaa8" category="paragraph">Astra<block ref="b792e70a7bbe82fe69049fd18abe3c18" category="inline-link-rx"></block> NetApp è uno storage dinamico open-source orchestrator per Docker e Kubernetes che semplifica la creazione, la gestione e il consumo dello storage persistente. Trident, un'applicazione nativa di Kubernetes, viene eseguita direttamente all'interno di un cluster Kubernetes. Trident consente ai clienti di implementare senza problemi le immagini dei container DL sullo storage NetApp e offre un'esperienza di livello Enterprise per le implementazioni dei container ai. Gli utenti di Kubernetes (sviluppatori ML, data scientist e così via) possono creare, gestire e automatizzare orchestrazione e cloning per sfruttare le funzionalità avanzate di gestione dei dati basate sulla tecnologia NetApp.</block>
  <block id="434636f83b39076d7f319707cddbd844" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> È un servizio NetApp per una sincronizzazione dei dati rapida e sicura. Sia che tu debba trasferire file tra condivisioni di file NFS o SMB on-premise, NetApp StorageGRID, NetApp ONTAP S3, NetApp Cloud Volumes Service, Azure NetApp Files, Amazon Simple Storage Service (Amazon S3), Amazon Elastic file System (Amazon EFS), Azure Blob, Google Cloud Storage, O IBM Cloud Object Storage, Cloud Sync sposta i file dove servono in modo rapido e sicuro. Una volta trasferiti, i dati sono completamente disponibili per l'utilizzo sia sull'origine che sulla destinazione. Cloud Sync sincronizza continuamente i dati in base alla pianificazione predefinita, spostando solo i delta, in modo da ridurre al minimo il tempo e il denaro speso per la replica dei dati. Cloud Sync è uno strumento software-as-a-service (SaaS) estremamente semplice da configurare e utilizzare. I trasferimenti di dati attivati da Cloud Sync vengono eseguiti da broker di dati. Puoi implementare i data broker Cloud Sync in AWS, Azure, piattaforma cloud Google o on-premise.</block>
  <block id="66b5cd4a3c9ce410ceb216447176b92c" category="section-title">NetApp Cloud Data Sense</block>
  <block id="37b37a18c5e4fe4e0985503adba1ee06" category="paragraph">Basato su potenti algoritmi ai, <block ref="41205542004b3a03df744ae454bd65c9" category="inline-link-rx"></block> offre controlli automatizzati e governance dei dati nell'intero data estate. Puoi individuare facilmente i risparmi sui costi, identificare i problemi di conformità e privacy e trovare opportunità di ottimizzazione. La dashboard Cloud Data Sense ti offre informazioni utili per identificare i dati duplicati per eliminare la ridondanza, mappare dati personali, non personali e sensibili e attivare avvisi per dati sensibili e anomalie.</block>
  <block id="b391770315ecce50e9dae3b6506d3513" category="inline-link-macro">Avanti: Piano di test e convalida.</block>
  <block id="d063081c0d1c6aff0b7c690b473d4045" category="paragraph"><block ref="d063081c0d1c6aff0b7c690b473d4045" category="inline-link-macro-rx"></block></block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">Questa sezione descrive le basi tecnologiche di questa soluzione ai.</block>
  <block id="42b507999e258502c07acce91c03de9f" category="paragraph"><block ref="42b507999e258502c07acce91c03de9f" category="inline-link-macro-rx"></block></block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">I sistemi storage NetApp AFF all'avanguardia consentono implementazioni di inferenza ai ai ai edge per soddisfare i requisiti di storage Enterprise con performance leader di settore, flessibilità superiore, integrazione nel cloud e gestione dei dati Best-in-class. Progettati appositamente per la tecnologia flash, i sistemi NetApp AFF aiutano ad accelerare, gestire e proteggere i dati business-critical.</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">I sistemi storage entry-level NetApp AFF sono basati su hardware FAS2750 e supporti flash SSD</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">Due controller in configurazione ha</block>
  <block id="7df12cd193e8452ed6fc45ca8bcd3771" category="paragraph"><block ref="7df12cd193e8452ed6fc45ca8bcd3771" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">I sistemi storage AFF C190 entry-level di NetApp supportano le seguenti funzionalità:</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">Un numero massimo di dischi SSD 24x 960 GB</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">Due possibili configurazioni:</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">Ethernet (10 GbE): 4 porte 10GBASE-T (RJ-45)</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">Unified (16 GB FC o 10 GbE): 4 porte UTA2 (Unified Target Adapter)</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">Capacità effettiva massima di 50,5 TB</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">Per i carichi di lavoro NAS, un singolo sistema AFF C190 entry-level supporta un throughput di 4,4 Gbps per letture sequenziali e 230 K IOPS per piccole letture casuali a latenze di 1 ms o inferiori.</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">NetApp offre anche altri sistemi storage entry-level che offrono performance e scalabilità superiori per implementazioni su larga scala. Per i carichi di lavoro NAS, un singolo sistema AFF A220 entry-level supporta:</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">Throughput di 6,2 Gbps per letture sequenziali</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">375.000 IOPS per piccole letture casuali con latenze di 1 ms o meno</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">Numero massimo di dischi SSD 144 x 960 GB, 3,8 TB o 7,6 TB</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">AFF A220 è in grado di scalare fino a un massimo di 1 PB di capacità effettiva</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="section-title">NetApp AFF A250</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">La capacità effettiva massima è di 35 PB con una scalabilità massima di 2-24 nodi (12 coppie ha)</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">Offre un aumento delle performance di ≥ 45% rispetto a AFF A220</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">Basato sull'ultima release di NetApp ONTAP: ONTAP 9.8</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">Sfrutta due porte Ethernet da 25 GB per l'interconnessione di ha e cluster</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">Sistemi NetApp e-Series EF</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">EF-Series è una famiglia di storage array SAN all-flash entry-level e mid-range in grado di accelerare l'accesso ai dati e di trarne valore più rapidamente con il software NetApp SANtricity. Questi sistemi offrono storage flash SAS e NVMe e offrono IOPS da convenienti a estremi, tempi di risposta inferiori a 100 microsecondi e larghezza di banda fino a 44 Gbps, il che li rende ideali per carichi di lavoro misti e applicazioni esigenti come l'inferenza ai e l'High Performance Computing (HPC).</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">La figura seguente mostra il sistema storage NetApp EF280.</block>
  <block id="51ffc2dfd09bb521be00106f197d1009" category="paragraph"><block ref="51ffc2dfd09bb521be00106f197d1009" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">NetApp EF280</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">Supporto FC 32 GB/16 GB, iSCSI 25 GB/10 GB e SAS 12 GB</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">La capacità effettiva massima è di 96 dischi per un totale di 1,5 PB</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">Throughput di 10 Gbps (letture sequenziali)</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">300.000 IOPS (letture casuali)</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">NetApp EF280 è l'array all-flash (AFA) più economico del portfolio NetApp</block>
  <block id="44114b1635cead15f56735bad0467251" category="section-title">NetApp EF300</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">24 unità SSD NVMe per una capacità totale di 367 TB</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">Opzioni di espansione per un totale di 240x HDD NL-SAS, 96x SSD SAS o una combinazione</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">100 GB di NVMe/IB, NVMe/RoCE, iSER/IB e SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">32 GB NVME/FC, FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">25 GB iSCSI</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20 Gbps (letture sequenziali)</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670.000 IOPS (letture casuali)</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">Scheda informativa sugli array all-flash NetApp EF-Series EF600, F300, EF570 e EF280</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">Per ulteriori informazioni, consultare<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block>.</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">ONTAP 9.8.1, l'ultima generazione di software per la gestione dello storage NetApp, consente alle aziende di modernizzare l'infrastruttura e passare a un data center cloud-ready. Sfruttando le funzionalità di gestione dei dati leader del settore, ONTAP consente la gestione e la protezione dei dati con un singolo set di strumenti, indipendentemente dalla posizione dei dati. Puoi anche spostare liberamente i dati ovunque siano necessari: Edge, core o cloud. ONTAP 9.8.1 include numerose funzionalità che semplificano la gestione dei dati, accelerano e proteggono i dati critici e abilitano le funzionalità dell'infrastruttura di nuova generazione nelle architetture di cloud ibrido.</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">*Qualità del servizio (AQoS) minima, massima e adattiva.* i controlli granulari della qualità del servizio (QoS) aiutano a mantenere i livelli di performance per le applicazioni critiche in ambienti altamente condivisi.</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">*NetApp FabricPool.* questa funzione offre il tiering automatico dei dati cold per le opzioni di cloud storage pubblico e privato, tra cui Amazon Web Services (AWS), Azure e la soluzione di storage NetApp StorageGRID. Per ulteriori informazioni su FabricPool, vedere <block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block>.</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">ONTAP 9 offre livelli superiori di performance e protezione dei dati ed estende queste funzionalità nei seguenti modi:</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">*Prestazioni e latenza ridotta.* ONTAP offre il throughput più elevato possibile con la latenza più bassa possibile.</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">*Crittografia dei volumi NetApp (NVE).* ONTAP offre crittografia nativa a livello di volume con supporto per la gestione delle chiavi integrata ed esterna.</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">*Multitenancy e autenticazione a più fattori.* ONTAP consente la condivisione delle risorse dell'infrastruttura con i massimi livelli di sicurezza.</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">ONTAP 9 aiuta a soddisfare le esigenze di business esigenti e in continua evoluzione con le seguenti funzionalità:</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">*Scalabilità perfetta e operazioni senza interruzioni.* ONTAP supporta l'aggiunta senza interruzioni di capacità ai controller esistenti e ai cluster scale-out. I clienti possono eseguire l'upgrade alle tecnologie più recenti, come NVMe e 32GB FC, senza costose migrazioni dei dati o interruzioni.</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">*Integrazione con applicazioni emergenti.* ONTAP offre servizi dati di livello Enterprise per piattaforme e applicazioni di prossima generazione, come veicoli autonomi, città intelligenti e Industry 4.0, utilizzando la stessa infrastruttura che supporta le applicazioni aziendali esistenti.</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">NetApp SANtricity</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">Scheda informativa sul software NetApp e-Series SANtricity</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">NetApp SANtricity è progettato per offrire performance, affidabilità e semplicità leader di settore agli array all-flash ibridi e EF-Series. Ottieni il massimo delle performance e dell'utilizzo degli array all-flash ibridi e EF-Series per applicazioni con carichi di lavoro elevati, tra cui analisi dei dati, videosorveglianza e backup e recovery. Con SANtricity, è possibile completare la modifica della configurazione, la manutenzione, l'espansione della capacità e altre attività mentre lo storage rimane online. SANtricity offre inoltre una protezione dei dati superiore, un monitoraggio proattivo e una sicurezza certificata, il tutto accessibile tramite l'interfaccia di System Manager, semplice da utilizzare e integrata. Per ulteriori informazioni, consultare<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block>.</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">Prestazioni ottimizzate</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">Il software SANtricity ottimizzato per le performance offre dati, con IOPS elevati, throughput elevato e bassa latenza, a tutte le applicazioni di analisi dei dati, videosorveglianza e backup. Accelera le performance per applicazioni a bassa latenza, IOPS elevati e applicazioni a elevata larghezza di banda e throughput elevato.</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">Massimizzare l'uptime</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">Completa tutte le tue attività di gestione mentre lo storage rimane online. Modificare le configurazioni, eseguire la manutenzione o espandere la capacità senza interrompere l'i/O. Ottieni un'affidabilità Best-in-class con funzionalità automatizzate, configurazione online, tecnologia all'avanguardia Dynamic Disk Pools (DPP) e molto altro ancora.</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">Resto facile</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">Il software SANtricity offre una protezione dei dati superiore, un monitoraggio proattivo e una sicurezza certificata, il tutto tramite l'interfaccia di System Manager, semplice da utilizzare e integrata. Semplifica le attività di gestione dello storage. Ottieni la flessibilità necessaria per il tuning avanzato di tutti i sistemi storage e-Series. Gestisci il tuo sistema NetApp e-Series, sempre e ovunque. La nostra interfaccia on-box basata sul web ottimizza il tuo workflow di gestione.</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block> NetApp è uno storage dinamico open-source orchestrator per Docker e Kubernetes che semplifica la creazione, la gestione e il consumo dello storage persistente. Trident, un'applicazione nativa di Kubernetes, viene eseguita direttamente all'interno di un cluster Kubernetes. Trident consente ai clienti di implementare senza problemi le immagini dei container DL sullo storage NetApp e offre un'esperienza di livello Enterprise per le implementazioni dei container ai. Gli utenti di Kubernetes (come sviluppatori ML e data scientist) possono creare, gestire e automatizzare orchestrazione e cloning per sfruttare le funzionalità avanzate di gestione dei dati di NetApp basate sulla tecnologia NetApp.</block>
  <block id="2d76806bea2175a1c575d37015a3621b" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> È un servizio NetApp per una sincronizzazione dei dati rapida e sicura. Sia che tu debba trasferire file tra condivisioni di file NFS o SMB on-premise, NetApp StorageGRID, NetApp ONTAP S3, NetApp Cloud Volumes Service, Azure NetApp Files, Amazon Simple Storage Service (Amazon S3), Amazon Elastic file System (Amazon EFS), Azure Blob, Google Cloud Storage, O IBM Cloud Object Storage, Cloud Sync sposta i file dove servono in modo rapido e sicuro. Una volta trasferiti, i dati sono completamente disponibili per l'utilizzo sia sull'origine che sulla destinazione. Cloud Sync sincronizza continuamente i dati, in base alla pianificazione predefinita, spostando solo i delta, in modo da ridurre al minimo il tempo e il denaro speso per la replica dei dati. Cloud Sync è uno strumento SaaS (Software as a Service) estremamente semplice da configurare e utilizzare. I trasferimenti di dati attivati da Cloud Sync vengono eseguiti da broker di dati. Puoi implementare i data broker Cloud Sync in AWS, Azure, piattaforma cloud Google o on-premise.</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">I vantaggi principali dell'implementazione dei server Lenovo ThinkSystem includono:</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">Design altamente scalabili e modulari per crescere insieme al tuo business</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">Nell'area dell'ai, Lenovo sta adottando un approccio pratico per aiutare le aziende a comprendere e adottare i vantaggi di ML e ai per i propri carichi di lavoro. I clienti Lenovo possono esplorare e valutare le offerte Lenovo ai nei Lenovo ai Innovation Center per comprendere appieno il valore del loro caso di utilizzo specifico. Per migliorare il time-to-value, questo approccio incentrato sul cliente offre ai clienti una prova di concetto per le piattaforme di sviluppo di soluzioni pronte all'uso e ottimizzate per l'ai.</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">L'edge computing consente di analizzare i dati provenienti dai dispositivi IoT all'edge della rete prima di inviarli al data center o al cloud. Lenovo ThinkSystem SE350, come illustrato nella figura seguente, è progettato per soddisfare i requisiti esclusivi di implementazione alla periferia della rete, con particolare attenzione a flessibilità, connettività, sicurezza e gestibilità remota in un fattore di forma compatto e rinforzato dal punto di vista ambientale.</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">Dotato del processore Intel Xeon D con la flessibilità di supportare l'accelerazione per i carichi di lavoro ai edge, il SE350 è costruito ad hoc per affrontare la sfida delle implementazioni dei server in una varietà di ambienti esterni al data center.</block>
  <block id="b739a166d96ffd72ac4d456012bfbe21" category="paragraph"><block ref="b739a166d96ffd72ac4d456012bfbe21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="paragraph"><block ref="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">MLPerf Inference v0.7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">MLPerf è la suite di benchmark leader del settore per la valutazione delle performance ai. Copre molte aree dell'ai applicata, tra cui classificazione delle immagini, rilevamento degli oggetti, imaging medico e NLP (Natural Language Processing). In questa convalida, abbiamo utilizzato i carichi di lavoro Inference v0.7, che è l'ultima iterazione dell'inferenza MLPerf al completamento di questa convalida. Il<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block> la suite include quattro nuovi benchmark per data center e sistemi edge:</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">*BERT.* rappresentazione del codificatore bidirezionale da Transformers (BERT) ottimizzata per la risposta alle domande utilizzando il set di dati della squadra.</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">*DLRM.* Deep Learning Recommendation Model (DLRM) è un modello di personalizzazione e raccomandazione che viene addestrato per ottimizzare i tassi di click-through (CTR).</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">*3D U-Net.* l'architettura 3D U-Net viene addestrata sul set di dati Brain Tumor Segmentation (Brats).</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">*RNN-T.* il trasduttore di rete neurale ricorrente (RNN-T) è un modello di riconoscimento vocale automatico (ASR) che viene addestrato su un sottoinsieme di LibriSpeech. I risultati e il codice dell'inferenza MLPerf sono pubblicamente disponibili e rilasciati sotto licenza Apache. MLPerf Inference dispone di una divisione Edge, che supporta i seguenti scenari:</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">*Single stream.* questo scenario imita i sistemi in cui la reattività è un fattore critico, come le query ai offline eseguite sugli smartphone. Le singole query vengono inviate al sistema e i tempi di risposta vengono registrati. come risultato viene riportata la latenza del 90° percentile di tutte le risposte.</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">*Multistream.* questo benchmark è per i sistemi che elaborano input da più sensori. Durante il test, le query vengono inviate a un intervallo di tempo fisso. Viene imposto un vincolo QoS (latenza massima consentita). Il test indica il numero di flussi che il sistema può elaborare rispettando il limite di QoS.</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">*Offline.* questo è lo scenario più semplice che copre le applicazioni di elaborazione in batch e la metrica è il throughput in campioni al secondo. Tutti i dati sono disponibili per il sistema e il benchmark misura il tempo necessario per elaborare tutti i campioni.</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="c953c121914b99f83398f20ab2160ed1" category="paragraph">Lenovo ha pubblicato i punteggi di inferenza MLPerf per SE350 con T4, il server utilizzato in questo documento. Vedere i risultati all'indirizzo<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block> Nella sezione "Edge, CLOSED Division" della voce 0.7-145.</block>
  <block id="91666b8460dc62d134fe80c31f05d28b" category="paragraph"><block ref="91666b8460dc62d134fe80c31f05d28b" category="inline-link-macro-rx"></block></block>
  <block id="0dff6955889d5634f0212efb574ef815" category="doc">Fare clic per valutare l'elaborazione dei dati di previsione e modellare la formazione</block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">Questa sezione descrive le configurazioni testate, l'infrastruttura di rete, il server SE350 e i dettagli relativi al provisioning dello storage.</block>
  <block id="7dffe110836fe412eac19d0f63cf5b5b" category="paragraph"><block ref="7dffe110836fe412eac19d0f63cf5b5b" category="inline-link-macro-rx"></block></block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">La seguente figura mostra la configurazione del test. Abbiamo utilizzato il sistema storage NetApp AFF C190 e due server Lenovo ThinkSystem SE350 (ciascuno con un acceleratore NVIDIA T4). Questi componenti sono collegati tramite uno switch di rete 10 GbE. Lo storage di rete contiene set di dati di convalida/test e modelli preformati. I server offrono funzionalità di calcolo e l'accesso allo storage avviene attraverso il protocollo NFS.</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">Questa sezione descrive le configurazioni testate, l'infrastruttura di rete, il server SE350 e i dettagli relativi al provisioning dello storage. La tabella seguente elenca i componenti di base per l'architettura della soluzione.</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">2 server SE350 ciascuno con una scheda NVIDIA T4 GPU</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">Ogni server contiene una CPU Intel Xeon D-2123IT con quattro core fisici a 2,20 GHz e 128 GB di RAM</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">Sistema storage entry-level NetApp AFF (coppia ha)</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">Software NetApp ONTAP 9</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">Un gruppo di interfacce per controller, con quattro indirizzi IP logici per i punti di montaggio</block>
  <block id="1a538c197da3186f1eba50d82572dc34" category="paragraph"><block ref="1a538c197da3186f1eba50d82572dc34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">La seguente tabella elenca la configurazione dello storage: AFF C190 con 2 RU, 24 slot per unità.</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">Aggregatesize</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">Volumesize (Volumesize)</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">Punto di montaggio del sistema operativo</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/Netappelenovo_ai_fg</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8,42TiB</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15 TB</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/netapp_lenovo_fg</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">La cartella /netappLenovo_ai_fg contiene i set di dati utilizzati per la convalida del modello.</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">La figura seguente mostra la configurazione del test. Abbiamo utilizzato il sistema storage NetApp EF280 e due server Lenovo ThinkSystem SE350 (ciascuno con un acceleratore NVIDIA T4). Questi componenti sono collegati tramite uno switch di rete 10 GbE. Lo storage di rete contiene set di dati di convalida/test e modelli preformati. I server offrono funzionalità di calcolo e l'accesso allo storage avviene attraverso il protocollo NFS.</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">La seguente tabella elenca la configurazione dello storage per EF280.</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">Gruppo di volumi</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">Volume</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">DDDP</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">Metodo di connessione</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">Volume 1</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16 TB</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">Da SE350-1 a LUN iSCSI 0</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">Volume 2</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">Da SE350-2 a LUN iSCSI 1</block>
  <block id="43fa57e4031b0f759153c9c9fa49e6ed" category="paragraph"><block ref="43fa57e4031b0f759153c9c9fa49e6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0fccd40a3886a1e5dc539059407586a0" category="inline-link-macro">Avanti: Procedura di test.</block>
  <block id="3bee5237e36a9a0dc60fd351ce904544" category="paragraph"><block ref="3bee5237e36a9a0dc60fd351ce904544" category="inline-link-macro-rx"></block></block>
  <block id="677b450634b1a6a563206526cb4d9075" category="doc">TR-4858: Soluzione di orchestrazione NetApp con Run:ai</block>
  <block id="0959ee1db60e15d1e8e42d1206ca6a19" category="paragraph">Rick Huang, David Arnette, Sung-Han Lin, NetApp Yaron Goldberg, Run:ai</block>
  <block id="c87cafeb37457343ef978bbf8cad88b5" category="paragraph">I sistemi storage NetApp AFF offrono performance estreme e funzionalità di gestione dei dati del cloud ibrido leader di settore. NetApp e Run:ai hanno collaborato per dimostrare le funzionalità esclusive della soluzione NetApp ONTAP ai per i carichi di lavoro di intelligenza artificiale (ai) e machine learning (ML) che offrono performance, affidabilità e supporto di livello Enterprise. Run:l'orchestrazione ai dei carichi di lavoro ai aggiunge una piattaforma di scheduling e utilizzo delle risorse basata su Kubernetes per aiutare i ricercatori a gestire e ottimizzare l'utilizzo della GPU. Insieme ai sistemi NVIDIA DGX, la soluzione combinata di NetApp, NVIDIA e Run:ai offre uno stack di infrastruttura costruito ad hoc per i carichi di lavoro ai aziendali. Questo report tecnico fornisce una guida direzionale ai clienti che sviluppano sistemi di ai conversazionali a supporto di vari casi di utilizzo e mercati verticali del settore. Include informazioni sull'implementazione di Run:ai e di un sistema storage NetApp AFF A800 e funge da architettura di riferimento per il modo più semplice per ottenere un'implementazione rapida e di successo delle iniziative ai.</block>
  <block id="cae36004793b7131e0fc2323f598e7bb" category="list-text">Architetti aziendali che progettano soluzioni per lo sviluppo di modelli ai e software per casi di utilizzo basati su Kubernetes, come i microservizi containerizzati</block>
  <block id="5d138e1f42e31fb645a3e3f5a8d37929" category="list-text">Data scientist alla ricerca di modi efficienti per raggiungere obiettivi di sviluppo dei modelli efficienti in un ambiente cluster con più team e progetti</block>
  <block id="0d43a0c7aeec219a746e836746c0b208" category="list-text">Data engineer responsabili della manutenzione e dell'esecuzione dei modelli di produzione</block>
  <block id="00d764d2e91381a99d6f2c7b108e7c8e" category="list-text">Decision maker e dirigenti IT e business leader che desiderano creare l'esperienza ottimale di utilizzo delle risorse cluster di Kubernetes e ottenere il più rapido time-to-market dalle iniziative di ai</block>
  <block id="29d90e44a805022079f5ad8bc748f89f" category="paragraph"><block ref="29d90e44a805022079f5ad8bc748f89f" category="inline-link-macro-rx"></block></block>
  <block id="1d91c2c04b7f73cb59edb799d095c75c" category="paragraph">Questo white paper offre linee guida per i clienti che sviluppano soluzioni di intelligenza artificiale conversa (ai) utilizzando il framework NVIDIA Jarvis e NetApp ONTAP ai e Cloud Sync per il retail e altri casi di utilizzo. Include informazioni sui flussi di lavoro di alto livello utilizzati per lo sviluppo di modelli NLP (Natural Language Processing) per assistenti virtuali, test case validati e risultati.</block>
  <block id="6d01d0026564c98aa0d6274cd39c586a" category="summary">Questo documento descrive una soluzione di progettazione validata in tre scenari diversi, con e senza offuscamento delle immagini, per preservare la privacy e implementare una soluzione di ai responsabile.</block>
  <block id="236e54165aafef697c2c82c667e05d36" category="doc">TR-4928: Ai responsabile e deduzione riservata - NetApp ai con Protopia Image e Data Transformation</block>
  <block id="0bbb7f0a0d464779fc0832c366f3a4e7" category="paragraph">Sathish Thyagarajan, Michael Oglesby, NetApp Byung Hoon Ahn, Jennifer Cwagenberg, Protopia</block>
  <block id="c110f3156d66710a207ebd7135164ec1" category="paragraph">Le interpretazioni visive sono diventate parte integrante della comunicazione con l'emergere dell'acquisizione e dell'elaborazione delle immagini. L'intelligenza artificiale (ai) nell'elaborazione di immagini digitali offre nuove opportunità di business, come nel campo medico per l'identificazione di tumori e altre malattie, nell'analisi visiva geospaziale per lo studio dei rischi ambientali, nel riconoscimento dei modelli, nell'elaborazione video per la lotta alla criminalità e così via. Tuttavia, questa opportunità comporta anche responsabilità straordinarie.</block>
  <block id="0159205b6d54375adfabd56a2258fcb9" category="paragraph">Più le organizzazioni prendono decisioni in mano all'ai, più accettano rischi legati alla privacy e alla sicurezza dei dati e a questioni legali, etiche e normative. L'intelligenza artificiale responsabile consente a aziende e organizzazioni governative di creare fiducia e governance che sono fondamentali per l'intelligenza artificiale su larga scala nelle grandi imprese. Questo documento descrive una soluzione di inferenza ai convalidata da NetApp in tre scenari diversi utilizzando le tecnologie di gestione dei dati NetApp con il software di offuscamento dei dati Protopia per privatizzare i dati sensibili e ridurre rischi e preoccupazioni etiche.</block>
  <block id="fade8b24490b0ba74a7ffa05d3f8631a" category="paragraph">Milioni di immagini vengono generate ogni giorno con diversi dispositivi digitali sia da consumatori che da aziende. La conseguente massiccia esplosione dei dati e del carico di lavoro di calcolo fa sì che le aziende si rivolgono alle piattaforme di cloud computing per scalabilità ed efficienza. Nel frattempo, i problemi di privacy relativi alle informazioni sensibili contenute nei dati delle immagini sorgono con il trasferimento a un cloud pubblico. La mancanza di garanzie di sicurezza e privacy diventa la principale barriera all'implementazione dei sistemi ai di elaborazione delle immagini.</block>
  <block id="e9ac7ec9dd27fe52477986ab1dccbcae" category="inline-link">diritto di cancellazione</block>
  <block id="49dca35d3e0662046425327194fd8965" category="inline-link">Legge sulla privacy</block>
  <block id="f615b294f87bd53494e01691ab95c654" category="paragraph">Inoltre, è disponibile la<block ref="ac9ac606204db63758cb1efd6e89e43e" category="inline-link-rx"></block> Dal GDPR, il diritto di un individuo di richiedere che un'organizzazione cancella tutti i propri dati personali. C'è anche il<block ref="fd57f794f9c27951b4a5b543db96bdb6" category="inline-link-rx"></block>, che stabilisce un codice di pratiche di informazione eque. Le immagini digitali come le fotografie possono costituire dati personali ai sensi del GDPR, che regola le modalità di raccolta, elaborazione e cancellazione dei dati. In caso contrario, la mancata conformità al GDPR potrebbe comportare multe elevate per la violazione delle conformità che possono danneggiare seriamente le organizzazioni. I principi di privacy sono tra le fondamenta dell'implementazione dell'ai responsabile che garantisce l'equità nelle previsioni del modello di apprendimento automatico (ML) e di apprendimento approfondito (DL) e riduce i rischi associati alla violazione della privacy o della conformità alle normative.</block>
  <block id="d365f4ef3ed2b414236f81df850880a3" category="paragraph">Questo documento descrive una soluzione di progettazione validata in tre scenari diversi, con e senza offuscamento delle immagini, per preservare la privacy e implementare una soluzione di ai responsabile:</block>
  <block id="bd12a6b0ed0be7808c1e30b1e360bee6" category="list-text">*Scenario 1.* deduzione on-demand nel notebook Jupyter.</block>
  <block id="bf93b5af78256f2e49d2c0351133b08d" category="list-text">*Scenario 2.* deduzione batch su Kubernetes.</block>
  <block id="d5a10e810e1d293a064388e4980bde15" category="list-text">*Scenario 3.* Server di inferenza NVIDIA Triton.</block>
  <block id="870f1cf4b101c66b438e8dd024f24118" category="paragraph">Per questa soluzione, utilizziamo Face Detection Data Set and Benchmark (FDDB), un set di dati delle regioni dei volti progettato per studiare il problema del rilevamento dei volti senza vincoli, in combinazione con il framework di apprendimento automatico PyTorch per l'implementazione di FaceBoxes. Questo set di dati contiene le annotazioni per 5171 volti in un set di 2845 immagini di varie risoluzioni. Inoltre, questo report tecnico presenta alcune delle aree di soluzione e i casi di utilizzo rilevanti raccolti dai clienti NetApp e dai tecnici sul campo nelle situazioni in cui questa soluzione è applicabile.</block>
  <block id="e28a169eb64ee1d32c878a26595922f0" category="paragraph">Questo report tecnico è destinato ai seguenti destinatari:</block>
  <block id="167e9693dfa764051f26b64ec22356a9" category="list-text">Business leader e architetti aziendali che desiderano progettare e implementare un'ai responsabile e affrontare i problemi di protezione dei dati e privacy relativi all'elaborazione delle immagini facciali negli spazi pubblici.</block>
  <block id="304e871b0b1ea55fe3e4f07ead7a7d42" category="list-text">Data scientist, data engineer, ricercatori ai/ machine learning (ML) e sviluppatori di sistemi ai/ML che mirano a proteggere e preservare la privacy.</block>
  <block id="dcf26996b3ab9f385a95f72c1d0a0dce" category="list-text">Architetti aziendali che progettano soluzioni di offuscamento dei dati per modelli e applicazioni ai/ML conformi agli standard normativi come GDPR, CCPA o il Privacy Act del Department of Defense (DoD) e organizzazioni governative.</block>
  <block id="bb6887ed7c7b07cbb7bd3ec71f951e6f" category="list-text">Data scientist e ingegneri ai alla ricerca di modi efficienti per implementare modelli di deduzione ai/ML/DL e deep learning (DL) in grado di proteggere le informazioni sensibili.</block>
  <block id="69adf8f52a6229e7062bda4b2b9679fb" category="paragraph">Questa soluzione è progettata per gestire carichi di lavoro ai di deduzione in batch e in tempo reale su grandi set di dati utilizzando la potenza di elaborazione delle GPU insieme alle CPU tradizionali. Questa convalida dimostra l'inferenza di conservazione della privacy per ML e la gestione ottimale dei dati richiesta per le organizzazioni che cercano implementazioni ai responsabili. Questa soluzione offre un'architettura adatta per una piattaforma Kubernetes a nodo singolo o multiplo per il cloud computing e l'edge interconnesso con NetApp ONTAP ai al core on-premise, il toolkit NetApp DataOps e il software di offuscamento Protopia utilizzando le interfacce Jupyter Lab e CLI. La figura seguente mostra una panoramica dell'architettura logica del data fabric basato su NetApp con DataOps Toolkit e Protopia.</block>
  <block id="950724ad73ee22fd3b76ae9570281f64" category="paragraph"><block ref="950724ad73ee22fd3b76ae9570281f64" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7dfea85fd355e4966805c3504348aa8b" category="paragraph">Il software di offuscamento Protopia viene eseguito perfettamente sul NetApp DataOps Toolkit e trasforma i dati prima di lasciare il server di storage.</block>
  <block id="3d68457cd44385c7acbd55eeda70e8f8" category="inline-link-macro">Successivo: Aree di soluzione.</block>
  <block id="55da59d3fe9630935dbd4fc25d52b939" category="paragraph"><block ref="55da59d3fe9630935dbd4fc25d52b939" category="inline-link-macro-rx"></block></block>
  <block id="f7235eb2146d800446cbbbac3a57548c" category="paragraph"><block ref="b1b09355c9538fe149372d3728c98bb1" category="inline-link-macro-rx"></block>.</block>
  <block id="837896d23c0eee81106906ab4cef7a6d" category="doc">TR-4799-DESIGN: Architettura di riferimento ai di NetApp ONTAP per carichi di lavoro a guida autonoma</block>
  <block id="63e3877ed0a830d2fb8beed8fffb2df4" category="paragraph">La famiglia di sistemi NVIDIA DGX è la prima piattaforma al mondo di intelligenza artificiale integrata (ai) costruita appositamente per l'ai aziendale. I sistemi storage NetApp AFF offrono performance estreme e funzionalità di gestione dei dati del cloud ibrido leader di settore. NetApp e NVIDIA hanno collaborato per creare l'architettura di riferimento ai di NetApp ONTAP per offrire ai clienti una soluzione chiavi in mano per supportare i carichi di lavoro di ai e machine learning (ML) con performance, affidabilità e supporto di livello Enterprise.</block>
  <block id="873b0fe1ee8adb4c5e6401e2fabf0734" category="paragraph"><block ref="873b0fe1ee8adb4c5e6401e2fabf0734" category="inline-link-macro-rx"></block></block>
  <block id="3642f282b12269091ab196a3aabf0858" category="summary">Esempio di operazioni Trident</block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">Questa sezione include esempi di varie operazioni che è possibile eseguire con Trident.</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="section-title">Importare un volume esistente</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="paragraph">Se nel sistema/piattaforma di storage NetApp sono presenti volumi che si desidera montare su container all'interno del cluster Kubernetes, ma che non sono legati ai PVC nel cluster, è necessario importare questi volumi. È possibile utilizzare la funzionalità di importazione dei volumi Trident per importare questi volumi.</block>
  <block id="4330c34147b36030c50afe1d04ec2213" category="paragraph">I comandi di esempio seguenti mostrano l'importazione dello stesso volume, denominato<block ref="716577bd9ec46fd219326b2aa7404103" prefix=" " category="inline-code"></block> Due volte, una per ogni backend Trident creato nell'esempio nella sezione <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, fase 1. L'importazione dello stesso volume due volte in questo modo consente di montare il volume (un volume FlexGroup esistente) più volte su diverse LIF, come descritto nella sezione <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, fase 1. Per ulteriori informazioni sui PVC, vedere<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>. Per ulteriori informazioni sulla funzionalità di importazione dei volumi, vedere<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">An<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> valore di<block ref="c24ad3d99a666c95edd149419c958ee0" prefix=" " category="inline-code"></block> È specificato nei file delle specifiche PVC di esempio. Per ulteriori informazioni su<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> vedere il campo<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>.</block>
  <block id="e6d82e60d43fe02e01930addfe670e8f" category="admonition">I nomi di backend specificati nei comandi di importazione di esempio riportati di seguito corrispondono ai backend creati nell'esempio della sezione <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, fase 1. I nomi StorageClass specificati nei seguenti file di definizione PVC di esempio corrispondono ai StorageClasses creati nell'esempio nella sezione <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>, fase 1.</block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="section-title">Provisioning di un nuovo volume</block>
  <block id="e149d2e1fdb31ad28f79dd3d2c7ee8ff" category="paragraph">È possibile utilizzare Trident per eseguire il provisioning di un nuovo volume sul sistema o sulla piattaforma di storage NetApp. I seguenti comandi di esempio mostrano il provisioning di un nuovo volume FlexVol. In questo esempio, il provisioning del volume viene eseguito utilizzando StorageClass creato nell'esempio della sezione <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>, punto 2.</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">An<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> valore di<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block> Viene specificato nel seguente file di definizione PVC di esempio. Per ulteriori informazioni su<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> vedere il campo<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>.</block>
  <block id="c515da31cebf8cf63b394c59f3f5f2c0" category="inline-link-macro">Pagina successiva: Esempio di panoramica delle implementazioni ai di ONTAP con prestazioni elevate.</block>
  <block id="5c11e6d83807487f2c41bd48dc524734" category="paragraph"><block ref="5c11e6d83807487f2c41bd48dc524734" category="inline-link-macro-rx"></block></block>
  <block id="00a9f41b5383bf6bcb5b7f6540d427b4" category="summary">Con gli attuali tool di modellazione pre-addestrati e all'avanguardia pubblicati da NVIDIA, AWS, Google e altri, una pipeline end-to-end con modelli complessi può ora essere messa in piedi e personalizzata con relativa facilità.</block>
  <block id="14e5cae1e8e56eca8add5bdcedfe2335" category="inline-link-macro">Precedente: Analisi del Support Center.</block>
  <block id="d39a6e05d58eb4f71cae7257dc52a1d0" category="paragraph"><block ref="d39a6e05d58eb4f71cae7257dc52a1d0" category="inline-link-macro-rx"></block></block>
  <block id="710217ef02bea8d1d76bc6fc0e7bc056" category="paragraph">A causa del numero di chiamate che questi centri di supporto elaborano, la valutazione delle performance delle chiamate potrebbe richiedere molto tempo se eseguita manualmente. I metodi tradizionali, come il conteggio delle parole e altri metodi, possono ottenere una certa automazione, ma questi metodi non acquisiscono aspetti più sfumati e contesto semantico del linguaggio dinamico. È possibile utilizzare tecniche di modellazione ai per eseguire alcune di queste analisi più sfumate in modo automatizzato. Inoltre, con gli attuali tool di modellazione pre-addestrati e all'avanguardia pubblicati da NVIDIA, AWS, Google e altri, una pipeline end-to-end con modelli complessi può ora essere messa in piedi e personalizzata con relativa facilità.</block>
  <block id="dd4541bcdb4728a1a380e825494f08e2" category="paragraph">Una pipeline end-to-end per l'analisi del sentimento del centro di supporto consente di acquisire file audio in tempo reale mentre i dipendenti conversano con i chiamanti. Quindi, questi file audio vengono elaborati per l'utilizzo nel componente voce-testo che li converte in un formato di testo. Ogni frase della conversazione riceve un'etichetta indicante il sentimento (positivo, negativo o neutro).</block>
  <block id="cfc9b6a29659e2208f66d876bd355200" category="paragraph">L'analisi del sentimento può fornire un aspetto essenziale delle conversazioni per la valutazione delle performance delle chiamate. Questi sentimenti aggiungono un ulteriore livello di profondità alle interazioni tra dipendenti e chiamanti. Il dashboard dedicato al sentimento assistito dall'ai offre ai manager un monitoraggio in tempo reale del sentimento all'interno di una conversazione, oltre a un'analisi retrospettiva delle chiamate passate del dipendente.</block>
  <block id="2357d01362feabb1716e49b27d23f9cf" category="inline-link">NVIDIA Maxine</block>
  <block id="a2415fcdba82ba111e08286b17d98943" category="paragraph">Esistono tool precostruiti che possono essere combinati in modi potenti per creare rapidamente una pipeline di ai end-to-end per risolvere questo problema. In questo caso, la libreria NVIDIA RIVA può essere utilizzata per eseguire le due attività in-series: Trascrizione audio e analisi del sentimento. Il primo è un algoritmo di elaborazione del segnale di apprendimento supervisionato e il secondo è un algoritmo di classificazione NLP di apprendimento supervisionato. Questi algoritmi pronti all'uso possono essere ottimizzati per qualsiasi caso di utilizzo pertinente con dati rilevanti per l'azienda utilizzando NVIDIA TAO Toolkit. Questo porta a soluzioni più accurate e potenti che vengono costruite solo per una frazione dei costi e delle risorse. I clienti possono incorporare<block ref="2aa9e1b3ec0ddf7f0bf09cdb2976222a" category="inline-link-rx"></block> Framework per applicazioni di videoconferenza accelerate dalla GPU nella progettazione del centro di supporto.</block>
  <block id="076dd41fe8ba902e5439b5ba07f330ee" category="paragraph">I seguenti casi di utilizzo sono alla base di questa soluzione. Entrambi i casi di utilizzo utilizzano il toolkit TAO per la messa a punto del modello e RIVA per l'implementazione del modello.</block>
  <block id="bc176e8f914533ec222bba678e13955f" category="paragraph">Per analizzare le interazioni del centro di supporto tra dipendenti e clienti, ogni conversazione con il cliente sotto forma di chiamate audio può essere eseguita attraverso la pipeline per estrarre sentimenti a livello di frase. Tali sentimenti possono quindi essere verificati da un essere umano per giustificare i sentimenti o modificarli in base alle necessità. I dati etichettati vengono quindi trasferiti nella fase di messa a punto per migliorare le previsioni del sentimento. Se esistono già dati di sentimento etichettati, è possibile accelerare la messa a punto del modello. In entrambi i casi, la pipeline è generalizzabile con altre soluzioni che richiedono l'acquisizione di audio e la classificazione delle frasi.</block>
  <block id="91fa9ce0e0cb723f35d6cc55f796be7e" category="paragraph"><block ref="91fa9ce0e0cb723f35d6cc55f796be7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8836d456396ee0865c317994c018a24b" category="paragraph">Gli output di ai sentiment vengono caricati su un database cloud esterno o su un sistema storage gestito dall'azienda. Gli output del sentimento vengono trasferiti da questo database più grande allo storage locale per l'utilizzo all'interno della dashboard che visualizza l'analisi del sentimento per i manager. La funzionalità principale del dashboard consiste nell'interfacciarsi con il dipendente del servizio clienti in tempo reale. I manager possono valutare e fornire un feedback sui dipendenti durante le loro chiamate con aggiornamenti in tempo reale del sentimento di ciascuna frase, nonché una revisione storica delle performance del dipendente o delle reazioni dei clienti.</block>
  <block id="586779135ffb596b1f1844ada64164b6" category="paragraph"><block ref="586779135ffb596b1f1844ada64164b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="539788a6fdaffc74393f282739bdd3e2" category="paragraph">Il <block ref="95472f01c3cd86dddef6619dbb9af815" category="inline-link-macro-rx"></block> Può continuare a gestire i sistemi di storage dei dati anche dopo che la pipeline di inferenza RIVA ha generato etichette di sentimento. Questi risultati ai possono essere caricati su un sistema storage gestito dal NetApp DataOps Toolkit. I sistemi di storage dei dati devono essere in grado di gestire centinaia di inserti e selezionare ogni minuto. Il sistema di storage dei dispositivi locali esegue query in tempo reale sull'ampio storage dei dati per l'estrazione. È inoltre possibile eseguire query sull'istanza di storage dei dati più grande per ottenere dati storici per migliorare ulteriormente l'esperienza del dashboard. Il NetApp DataOps Toolkit facilita entrambi questi utilizzi clonando rapidamente i dati e distribuirli in tutte le dashboard che li utilizzano.</block>
  <block id="679db67ee98260ef471da732862ed356" category="list-text">Responsabili dei dipendenti</block>
  <block id="7e6beec614d536589c47de8f77fa1b1a" category="list-text">Data engineer/data scientist</block>
  <block id="a2ce7e25564bee3c78076bcff87d1329" category="list-text">Amministratori IT (on-premise, cloud o ibridi)</block>
  <block id="8dcd09ac05ad9012a6ff01f7b5fc337b" category="paragraph">Tenere traccia dei sentimenti durante le conversazioni è uno strumento prezioso per valutare le performance dei dipendenti. Utilizzando la dashboard di ai, i manager possono vedere come dipendenti e chiamanti cambiano le proprie sensazioni in tempo reale, consentendo valutazioni live e sessioni di guida. Inoltre, le aziende possono ottenere preziose informazioni sui clienti dai clienti impegnati in conversazioni vocali, chat di testo e videoconferenze. Tali analisi dei clienti utilizzano le funzionalità di elaborazione multimodale su larga scala con modelli e flussi di lavoro ai moderni e all'avanguardia.</block>
  <block id="b7c29e65097b6ed45e464f6492ff670d" category="paragraph">Dal punto di vista dei dati, un gran numero di file audio viene elaborato quotidianamente dal centro di supporto. Il NetApp DataOps Toolkit facilita questa attività di gestione dei dati per la messa a punto periodica di modelli e dashboard di analisi del sentimento.</block>
  <block id="1da289b166db713f9283c5be78ef5b96" category="paragraph">Gli amministratori IT traggono vantaggio anche dal NetApp DataOps Toolkit, che consente loro di spostare rapidamente i dati tra ambienti di implementazione e produzione. Anche gli ambienti e i server NVIDIA devono essere gestiti e distribuiti per consentire l'inferenza in tempo reale.</block>
  <block id="7179915e029316714169ac136027ef31" category="paragraph"><block ref="7179915e029316714169ac136027ef31" category="inline-link-macro-rx"></block></block>
  <block id="d9ed812c8dd9083f1fb345425b8ce100" category="paragraph">Questa sezione contiene i dettagli del test per la sezione <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>.</block>
  <block id="c6e328a3639bc00374d81e681f89f609" category="cell">Jupyter</block>
  <block id="ff8bed43ac09b1148fc7648f5845f698" category="cell">1/4</block>
  <block id="37ce74088416f28dc9bb04355c2e5a28" category="cell">–</block>
  <block id="6408e079aefee9702aa00f77228dd941" category="cell">2/4</block>
  <block id="00833fac70036c049bd75443869cacb5" category="cell">Esegui:ai</block>
  <block id="d2313e844e73fe4a8f63d93f4df355fc" category="cell">Utilizzando tutta la quota</block>
  <block id="e4275e3860ed32f489dbb6a5d4a10f5f" category="cell">0.6/2</block>
  <block id="8457d97e0a0f74a5926d1dee27e53541" category="cell">GPU frazionale</block>
  <block id="975ca8804565c1a569450d61090b2743" category="cell">1/2</block>
  <block id="411472b1216ec08457e653eac42d7bbd" category="cell">Due in eccesso di quota</block>
  <block id="d310cb367d993fb6fb584b198a2fd72c" category="cell">0.5</block>
  <block id="76169512ef5ca1abe70b32c0993856af" category="cell">0.5/2</block>
  <block id="e85b79abfd76b7c13b1334d8d8c194a5" category="cell">0.3</block>
  <block id="5c2b079fc9750c2995852b8fb354aae3" category="cell">0.8/2</block>
  <block id="00fd1da21e8b4ef31d987665dc575099" category="cell">3/2</block>
  <block id="0375b76ff57435094e28e94015a5f052" category="cell">Uno sopra la quota</block>
  <block id="ecdb9acc2db02134680a9c49abe3e991" category="cell">4/8</block>
  <block id="30c006c71ada68e2273b128bc2e6831b" category="cell">Utilizzando metà della quota</block>
  <block id="36cf0dc9f04c54214fa577ec66ff53fc" category="paragraph">Struttura dei comandi:</block>
  <block id="7b3a4ccf5e0cc7918cd458f7e46b9c8e" category="paragraph">Sequenza di comandi effettiva utilizzata nel test:</block>
  <block id="478eb1c4e698b325048b6bccfb8974f6" category="cell">4/4 (quota soft/allocazione effettiva)</block>
  <block id="2df6f557cc57e6d4044b9611b1f56439" category="inline-link-macro">Elevato utilizzo del cluster con allocazione GPU over-uota</block>
  <block id="3667ebc7f28f59fc13bfcf314c67de05" category="paragraph">Vedere la sezione <block ref="dee5d16c649661a62d3a765af5b1a963" category="inline-link-macro-rx"></block> per discussioni sullo scenario di test.</block>
  <block id="ac8466404b94a669f51a3d2db2401cf0" category="inline-link-macro">Pagina successiva: Dettagli sui test per la Sezione 4.9</block>
  <block id="84b7d04f598931bc149a92c543d3146f" category="paragraph"><block ref="84b7d04f598931bc149a92c543d3146f" category="inline-link-macro-rx"></block></block>
  <block id="8fcbbd73e86fa0b56d72d6127c318c85" category="paragraph">La crescita esplosiva dei dati e la crescita esponenziale dell'apprendimento automatico (ML) e dell'intelligenza artificiale (ai) sono convergenti per creare una nuova economia con sfide di sviluppo e implementazione uniche. In genere, enormi quantità di dati vengono memorizzate in un data Lake a basso costo, dove le risorse di calcolo ai dalle performance elevate, come le GPU, non possono accedervi in modo efficiente. In questo report, presentiamo una nuova soluzione in cui i professionisti delle scienze dei dati implementano un data hub e, con un click, creano una cache di set di dati in prossimità delle risorse di calcolo, ovunque si trovino. Di conseguenza, i professionisti dell'ai possono eseguire più facilmente training su modelli dalle performance elevate grazie alla collaborazione avanzata resa possibile da un nuovo hub di versione del set di dati.</block>
  <block id="e4f8ad54c095217d5da72f9ba2ad87d4" category="summary">NVIDIA ai Enterprise con NetApp e VMware - utilizzo del software NVIDIA NGC - esempio di utilizzo - lavoro di training TensorFlow</block>
  <block id="b26247c1865d93ea590ef10d1150c2ae" category="doc">Esempio di caso d'utilizzo - lavoro di training TensorFlow</block>
  <block id="9e4efb6787f44fcab6b00e2afd36fcee" category="inline-link-macro">Precedente: Installazione.</block>
  <block id="fd157334647c1bdd933147dbf284f59e" category="paragraph"><block ref="fd157334647c1bdd933147dbf284f59e" category="inline-link-macro-rx"></block></block>
  <block id="ff35b7c65e31b6103dee61bd8d89ee4f" category="paragraph">Questa sezione descrive le attività da eseguire per eseguire un lavoro di training TensorFlow in un ambiente NVIDIA ai Enterprise.</block>
  <block id="cd33d31cec93ae54705bbc90e8ffbc09" category="paragraph">Prima di eseguire i passaggi descritti in questa sezione, si presuppone che sia già stato creato un modello di macchina virtuale guest seguendo le istruzioni riportate nella <block ref="8c165f1fe6ca595dd726d3af3dcdf541" category="inline-link-macro-rx"></block> pagina.</block>
  <block id="c8281ef65e7f967dfd74821eada0aed1" category="section-title">Creare una macchina virtuale guest dal modello</block>
  <block id="8f195db6a3d092a2d990de535475fb82" category="paragraph">Innanzitutto, è necessario creare una nuova macchina virtuale guest dal modello creato nella sezione precedente. Per creare una nuova macchina virtuale guest dal modello, accedere a VMware vSphere, fare clic sul nome del modello, scegliere 'Nuova macchina virtuale da questo modello...', quindi seguire la procedura guidata.</block>
  <block id="9739d298a43441a49ece0169468d720e" category="paragraph"><block ref="9739d298a43441a49ece0169468d720e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="229fea3a8aa56b262dc3dbb996d81052" category="section-title">Creare e montare un volume di dati</block>
  <block id="bbdc3bf8e16f6c828df2941c605e4ef3" category="paragraph">Quindi, è necessario creare un nuovo volume di dati su cui memorizzare il set di dati di training. È possibile creare rapidamente un nuovo volume di dati utilizzando il NetApp DataOps Toolkit. Il comando di esempio che segue mostra la creazione di un volume denominato 'imagenet' con una capacità di 2 TB.</block>
  <block id="bed0c39c2a853526e026bbd1d13b0a29" category="paragraph">Prima di poter popolare i dati nel volume di dati, è necessario montarli all'interno della macchina virtuale guest. È possibile montare rapidamente un volume di dati utilizzando il NetApp DataOps Toolkit. Il comando di esempio che segue mostra il mouse del volume creato nel passaggio precedente.</block>
  <block id="3418ebfa9c3ff38c1bfcd27521d4e641" category="section-title">Popolare il volume di dati</block>
  <block id="ec123d1ef57b0ab158b8c891c6b936da" category="paragraph">Una volta eseguito il provisioning e il montaggio del nuovo volume, è possibile recuperare il set di dati di training dalla posizione di origine e posizionarlo sul nuovo volume. In genere, ciò comporta il prelievo dei dati da un data Lake S3 o Hadoop e talvolta comporta l'aiuto di un data engineer.</block>
  <block id="d3e84e47f561be23742b30b8c3dd7d10" category="section-title">Eseguire il lavoro di training TensorFlow</block>
  <block id="f6a0596efc5c96edbcbffd2d19e48f41" category="paragraph">Ora, sei pronto per eseguire il tuo lavoro di training TensorFlow. Per eseguire il tuo lavoro di training TensorFlow, esegui le seguenti attività.</block>
  <block id="83c4072e784e0048974a7fbaef9e7567" category="list-text">Estrarre l'immagine del container NVIDIA NGC Enterprise TensorFlow.</block>
  <block id="26857c717c90aa9ca7c999304a47e6ad" category="list-text">Avviare un'istanza di NVIDIA NGC Enterprise TensorFlow Container. Utilizzare l'opzione '-v' per collegare il volume di dati al container.</block>
  <block id="c8dc137f2972d72ed031b7e9000c2b58" category="list-text">Esegui il tuo programma di training TensorFlow all'interno del container. Il comando di esempio che segue mostra l'esecuzione di un programma di training ResNet-50 di esempio incluso nell'immagine container.</block>
  <block id="5a71d5119829b5c78d377ad1aa8a90a8" category="inline-link-macro">Avanti: Dove trovare ulteriori informazioni.</block>
  <block id="d5ca60148a0675b3abb83565cbf886d7" category="paragraph"><block ref="d5ca60148a0675b3abb83565cbf886d7" category="inline-link-macro-rx"></block></block>
  <block id="52c7321ea4e3d5b264fdc8639a65e280" category="doc">Implementare Grafana Dashboard</block>
  <block id="c843fc0ceca9c58b409cab519799c125" category="paragraph">Una volta implementato tutto, eseguiamo le inferenze sui nuovi dati. I modelli prevedono guasti sulle apparecchiature di rete. I risultati della previsione vengono memorizzati in una tabella Iguazio TimeSeries. È possibile visualizzare i risultati con Grafana nella piattaforma integrata con la policy di sicurezza e accesso ai dati di Iguazio.</block>
  <block id="ae93e86067cc1d0e7bb1ec8fdca6fbc3" category="paragraph">È possibile implementare la dashboard importando il file JSON fornito nelle interfacce Grafana del cluster.</block>
  <block id="213977705fe35a4cb0cfc9365088fc87" category="list-text">Per verificare che il servizio Grafana sia in esecuzione, consultare la sezione servizi.</block>
  <block id="b426c25dbb35de6b9c6bff0b10b8bef9" category="paragraph"><block ref="b426c25dbb35de6b9c6bff0b10b8bef9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b6e0cc0a098260878a0e8fa4eb7766" category="list-text">Se non è presente, distribuire un'istanza dalla sezione servizi:</block>
  <block id="cd40a7a2e0a86f4a0283af5999a050db" category="list-text">Fare clic su nuovo servizio.</block>
  <block id="59c4bcb990174489660974167376a50a" category="list-text">Selezionare Grafana dall'elenco.</block>
  <block id="7e280ecf88737f34a1972ac94f9ae2a1" category="list-text">Accettare le impostazioni predefinite.</block>
  <block id="9e47b36567e5001dea59ffee81456737" category="list-text">Fare clic su Avanti.</block>
  <block id="4fa350b43dd079673b6fca4852841147" category="list-text">Inserire l'ID utente.</block>
  <block id="af81385be6cef15b54f8c8c126c0eab0" category="list-text">Fare clic su Salva servizio.</block>
  <block id="568c8b6f668936384414e470f9ddd939" category="list-text">Fare clic su Apply Changes (Applica modifiche) nella parte superiore.</block>
  <block id="b5be50b376063d6c3ffaa3be10d4a9d3" category="list-text">Per implementare la dashboard, scaricare il file<block ref="5399022d93458a73556ae80388186793" prefix=" " category="inline-code"></block> Tramite l'interfaccia Jupyter.</block>
  <block id="587b311a501585c3a1d9260d4f147990" category="paragraph"><block ref="587b311a501585c3a1d9260d4f147990" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ad16c6527a3abd13b6864b8b078586b" category="list-text">Aprire Grafana dalla sezione servizi e importare la dashboard.</block>
  <block id="0b78dd574d02d72071845d040fdde57c" category="paragraph"><block ref="0b78dd574d02d72071845d040fdde57c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3ce0bca8ff75db7ff2bbc3e76532b2" category="list-text">Fare clic su carica<block ref="b31ec5f19793e2b7103acd7336754a1c" prefix=" " category="inline-code"></block> E selezionare il file scaricato in precedenza <block ref="5399022d93458a73556ae80388186793" prefix="(" category="inline-code"></block>). La dashboard viene visualizzata al termine del caricamento.</block>
  <block id="7cd4d06091771aa3f16d2759a067e18c" category="paragraph"><block ref="7cd4d06091771aa3f16d2759a067e18c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0258dc4515b0e18ecd4b55651e27671" category="section-title">Implementare la funzione di pulizia</block>
  <block id="ff4bdefb3ddd7532393d08c8df14d786" category="paragraph">Quando si generano molti dati, è importante mantenere le cose pulite e organizzate. A tale scopo, implementare la funzione di pulizia con<block ref="11652556f686b20fd51b96992986630e" prefix=" " category="inline-code"></block> notebook.</block>
  <block id="6d0f7ccc9b17bcabb743cabdfb56e0da" category="paragraph">NetApp e Iguazio accelerano e semplificano l'implementazione delle applicazioni ai e ML creando framework essenziali come Kubeflow, Apache Spark e TensorFlow, oltre a tool di orchestrazione come Docker e Kubernetes. Unificando la pipeline di dati end-to-end, NetApp e Iguazio riducono la latenza e la complessità inerenti a molti carichi di lavoro di calcolo avanzati, colmando efficacemente il divario tra sviluppo e operazioni. I data scientist possono eseguire query su set di dati di grandi dimensioni e condividere in modo sicuro dati e modelli algoritmici con utenti autorizzati durante la fase di training. Dopo che i modelli containerizzati sono pronti per la produzione, è possibile spostarli facilmente dagli ambienti di sviluppo agli ambienti operativi.</block>
  <block id="daee7e425c63dff416cde0a8932a8483" category="paragraph"><block ref="daee7e425c63dff416cde0a8932a8483" category="inline-link-macro-rx"></block></block>
  <block id="57a499fcdd85136edfd1ee55dedd9675" category="summary">Questa soluzione segue il ciclo di vita di un'applicazione ai/ML. Iniziamo con il lavoro dei data scientist per definire le diverse fasi necessarie per preparare i dati e formare i modelli. Sfruttando RAPIDS su Dask, eseguiamo training distribuiti nel cluster Azure Kubernetes Service (AKS) per ridurre drasticamente i tempi di training rispetto all'approccio convenzionale di Python scikit-Learn. Per completare il ciclo completo, integriamo la pipeline con Azure NetApp Files.</block>
  <block id="e6fab630e7da86a500e1e3c51fa61a00" category="paragraph">Rick Huang, Verron Martina, Muneer Ahmad, NetApp</block>
  <block id="4c3816ce69205bc811aa89dbe9d09a1a" category="paragraph">Il lavoro di un data scientist dovrebbe essere incentrato sulla formazione e sulla messa a punto di modelli di apprendimento automatico (ML) e intelligenza artificiale (ai). Tuttavia, secondo una ricerca condotta da Google, i data scientist dedicano circa il 80% del loro tempo a capire come far funzionare i propri modelli con le applicazioni aziendali e a eseguirlo su larga scala.</block>
  <block id="a1451f6988178ae140f8da836d63a157" category="paragraph">Per gestire i progetti ai/ML end-to-end, è necessaria una maggiore comprensione dei componenti aziendali. Sebbene DevOps abbia assunto il controllo della definizione, dell'integrazione e dell'implementazione, questi tipi di componenti, le operazioni ML hanno come obiettivo un flusso simile che include i progetti ai/ML. Per avere un'idea di ciò che una pipeline ai/ML end-to-end tocca nell'azienda, consulta il seguente elenco di componenti richiesti:</block>
  <block id="ea2ef9b0d095bf991f4973633b485340" category="list-text">Database</block>
  <block id="3b18b13f059019d19211f8a9f36f7e4e" category="list-text">File system</block>
  <block id="d6c823008f20bbfce5f39b30ec9fa918" category="list-text">Pipeline ci/CD (Continuous Integration and Continuous Deployment)</block>
  <block id="24bea3d677b34d6aea9ff01417fd9d06" category="list-text">Ambiente di sviluppo integrato (IDE)</block>
  <block id="2fae32629d4ef4fc6341f1751b405e45" category="list-text">Sicurezza</block>
  <block id="bd0992d43bb2d0ca676184502e14754e" category="list-text">Policy di accesso ai dati</block>
  <block id="a9353b1bd1eeedb788a74090b5f8d0bc" category="list-text">Set di strumenti e librerie per le scienze dei dati</block>
  <block id="e6a53478c3fc5682c6f851672b3e7bc9" category="paragraph">Il mondo della scienza dei dati tocca diverse discipline nell'IT e nel business:</block>
  <block id="c12281f5ea7b17e370414efbf3f26c30" category="list-text">Un tecnico DevOps ha bisogno dei tool per integrare le nuove applicazioni ai/ML nelle pipeline ci/CD.</block>
  <block id="9ca78187997ba2a23a73c094256ae63f" category="list-text">Gli amministratori e gli architetti del cloud devono essere in grado di configurare e gestire le risorse di Azure.</block>
  <block id="060bc2911862b1ab8f6b4b77542434a2" category="paragraph">In questo report tecnico, descriviamo in che modo Azure NetApp Files, RAPIDS ai, DAK e Azure aiutano ciascuno di questi ruoli a portare valore al business.</block>
  <block id="ed8b6e047f5d4e844fe3e870c3fda4a3" category="paragraph">Azure NetApp Files offre diversi livelli di performance. I clienti possono iniziare con un Tier Standard, scalare e scalare fino a un Tier dalle performance elevate senza interruzioni, senza spostare alcun dato. Questa funzionalità consente agli scienziati dei dati di formare modelli su larga scala senza problemi di performance, evitando i silos di dati nel cluster, come mostrato nella figura seguente.</block>
  <block id="d4dc9019b6000fd12d9dc6b091fe3e26" category="paragraph"><block ref="d4dc9019b6000fd12d9dc6b091fe3e26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a20978df09e58f39953eb81f9368c2f2" category="paragraph"><block ref="a20978df09e58f39953eb81f9368c2f2" category="inline-link-macro-rx"></block></block>
  <block id="ae6f5747bf29f889c1d28208afab2a1a" category="doc">Implementazione dell'applicazione</block>
  <block id="cef52206f11ced919c8d0dd4b2c791a4" category="paragraph">Le sezioni seguenti descrivono come installare e implementare l'applicazione.</block>
  <block id="d0954433c0b62861850b87d9cba7599f" category="inline-link-macro">Avanti: Ottieni codice da GitHub</block>
  <block id="255a6bf7e1d34563f76daaf2b6cd6184" category="paragraph"><block ref="26e27ac56fb4c03c9632ab9bd4fc068b" category="inline-link-macro-rx"></block>.</block>
  <block id="2e52c56d063752bbfeda9c8f9d2fee41" category="summary">Questa pagina descrive le attività da completare per installare e configurare NetApp Trident nel cluster Kubernetes.</block>
  <block id="7c4090c7fa7a91e8c7fed182401dbf6b" category="doc">Implementazione e configurazione di NetApp Trident</block>
  <block id="e539ec743b02403b5ba74b884d117a5a" category="paragraph">Questa sezione descrive le attività da completare per installare e configurare NetApp Trident nel cluster Kubernetes.</block>
  <block id="5b8a88d59edea26637f628caefd05974" category="list-text">Hai già un cluster Kubernetes funzionante e stai eseguendo una versione di Kubernetes supportata da Trident. Per un elenco delle versioni supportate, vedere<block ref="77881c904b113f84b0f08c355b95174f" category="inline-link-rx"></block>.</block>
  <block id="14ede02439184c7c75e53410ffa40370" category="list-text">Disponete già di un'appliance di storage NetApp funzionante, di un'istanza software-defined o di un servizio di cloud storage supportato da Trident.</block>
  <block id="984b69562391cb8032fd50ded03a29a6" category="paragraph">Per installare e configurare NetApp Trident nel cluster Kubernetes, eseguire le seguenti attività dall'host di distribuzione jump:</block>
  <block id="07d8795f785e6495307106596d07402e" category="list-text">Implementare Trident utilizzando uno dei seguenti metodi:</block>
  <block id="040d3466a6f1c45ca2e523c9354dfdc7" category="inline-link">Istruzioni per l'implementazione di Trident</block>
  <block id="bb6989644edf59b8c5e0de0c25b6f8b6" category="list-text">Se hai utilizzato NVIDIA DeepOps per implementare il cluster Kubernetes, puoi anche utilizzare NVIDIA DeepOps per implementare Trident nel cluster Kubernetes. Per implementare Trident con DeepOps, seguire<block ref="77e542aaaac8c5d2482c94ca2d79c997" category="inline-link-rx"></block> Sul sito NVIDIA DeepOps GitHub.</block>
  <block id="b81146e6af95bf6e22cf57459890216f" category="inline-link">Back-end</block>
  <block id="f652904c3bfb48fb25a0a75f485f0ff6" category="inline-link">StorageClasses</block>
  <block id="05543563edfd7ed0348edd3b47280705" category="list-text">Se non hai utilizzato NVIDIA DeepOps per implementare il cluster Kubernetes o se preferisci semplicemente implementare Trident manualmente, puoi implementare Trident seguendo la<block ref="e119dd171387190517d77417752a581c" category="inline-link-rx"></block> Nella documentazione di Trident. Per ulteriori informazioni sulla configurazione, assicurarsi di creare almeno un backend Trident e almeno un StorageClass Kubernetes<block ref="9e44c6ae604c64be7a70b0384fa1cccd" category="inline-link-rx"></block> e.<block ref="336146b6899186b663ba5a7b38e8c39b" category="inline-link-rx"></block> Consulta le sottosezioni collegate nei documenti di NetApp.</block>
  <block id="7cfdcb466d040b6c8f9c85e9981b9652" category="inline-link-macro">Esempi di storaglasses Kubernetes per implementazioni ai ONTAP</block>
  <block id="180b707bbdd9c2fc8001a966c6c7d029" category="admonition">Se stai implementando la soluzione NetApp per il piano di controllo ai su un pod ai ONTAP, consulta <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block> Per alcuni esempi di diversi backend Trident che si desidera creare e. <block ref="d495c2f5a68f6923824470c0096419c8" category="inline-link-macro-rx"></block> Per alcuni esempi di diverse Kubernetes StorageClasses che potresti voler creare.</block>
  <block id="4fe6ae61b2ccf0bd553bc2c0f15cf803" category="inline-link-macro">Segue: Esempio di backend Trident per implementazioni ai ONTAP.</block>
  <block id="8de05380035e6d3c48105e0b80ca2e32" category="paragraph"><block ref="8de05380035e6d3c48105e0b80ca2e32" category="inline-link-macro-rx"></block></block>
  <block id="bd3114e9e2000f42e265a067e98b0d25" category="doc">Connettersi alle API di terze parti come motore di adempimento</block>
  <block id="1aea646cd3c044dd0758af18e73cfef3" category="paragraph">Abbiamo collegato le seguenti API di terze parti come motore di adempimento per rispondere alle domande:</block>
  <block id="94c494471216991658782a32f1e3ef37" category="inline-link">API di WeatherStack</block>
  <block id="f7eb24e530470f21243c27770bd2c549" category="list-text"><block ref="c8600f69e922164a09610e481537b92d" category="inline-link-rx"></block>: restituisce meteo, temperatura, pioggia e neve in una determinata posizione.</block>
  <block id="1c96228fa1453bf3f691d5081cbd6adb" category="inline-link">API Fusion di Yelp</block>
  <block id="55a3b552be8202b066ea237b831186f4" category="list-text"><block ref="8af0de0530d799485b6d6a2d146ab784" category="inline-link-rx"></block>: restituisce le informazioni del negozio più vicino in una determinata posizione.</block>
  <block id="114e8180b93cb1b21cd00067e446e5f0" category="inline-link">SDK di eBay Python</block>
  <block id="da6816adc86546982065d9aef78845e5" category="list-text"><block ref="3d046b40b6d382ee41dd02d3b6ab007c" category="inline-link-rx"></block>: restituisce il prezzo di un dato articolo.</block>
  <block id="3f7ba19f5b656e6cf8db9c69330a6d6e" category="inline-link-macro">Pagina successiva: Dimostrazione di NetApp Retail Assistant</block>
  <block id="23e96dc8693037c8fa1d7c0587a2d5eb" category="paragraph"><block ref="23e96dc8693037c8fa1d7c0587a2d5eb" category="inline-link-macro-rx"></block></block>
  <block id="21f937997adb0cac073e2458491f2c2f" category="list-text">Scaricare NVIDIA DeepOps seguendo le istruzioni sul<block ref="a94c3c17b923443c927cfa8fe7a2482a" category="inline-link-rx"></block> Sul sito NVIDIA DeepOps GitHub.</block>
  <block id="76ada3ea43b0e44772967793fe69b1bd" category="inline-link">Guida all'implementazione di Kubernetes</block>
  <block id="03628142cdc704dd6ffe5d7d13573999" category="list-text">Implementare Kubernetes nel cluster seguendo le istruzioni sul<block ref="cdf0a6d71dcbe898357c0e37010d30de" category="inline-link-rx"></block> Sul sito NVIDIA DeepOps GitHub.</block>
  <block id="2dfe8bb84d94f23030d91e315d7899bc" category="admonition">Affinché l'implementazione di DeepOps Kubernetes funzioni, lo stesso utente deve esistere su tutti i nodi master e worker di Kubernetes.</block>
  <block id="c6fff1434177c1b95244b5300314f730" category="paragraph">Se l'implementazione non riesce, modificare il valore di<block ref="66254ff5dfd1102c045888913b8e188d" prefix=" " category="inline-code"></block> a false in<block ref="399db550c3eadd49b7f0681bf65049a0" prefix=" " category="inline-code"></block> e ripetere il punto 2. Il<block ref="3d9043b4bfb5ecceda4eaf60e73c2655" prefix=" " category="inline-code"></block> attività, che viene eseguita solo quando il valore di<block ref="66254ff5dfd1102c045888913b8e188d" prefix=" " category="inline-code"></block> È vero, si basa sul modulo fetch Ansible, che presenta problemi noti di utilizzo della memoria. A volte, questi problemi di utilizzo della memoria possono causare un errore nell'attività. Se l'operazione non riesce a causa di un problema di memoria, il resto dell'operazione di implementazione non viene completata correttamente.</block>
  <block id="24e1fa4c913dcdc975e022f921d4d603" category="paragraph">Se l'implementazione viene completata correttamente dopo aver modificato il valore di<block ref="66254ff5dfd1102c045888913b8e188d" prefix=" " category="inline-code"></block> a.<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block>, quindi è necessario copiare manualmente<block ref="11afbd066a1d25fe61fdae1c673a278e" prefix=" " category="inline-code"></block> Da un nodo master Kubernetes all'host di salto per l'implementazione. È possibile trovare la posizione di<block ref="11afbd066a1d25fe61fdae1c673a278e" prefix=" " category="inline-code"></block> su un nodo master specifico eseguendo<block ref="c768a64827ad16455d7c655ea5ae91ff" prefix=" " category="inline-code"></block> comando direttamente su quel nodo.</block>
  <block id="a185054da23018c3578742c41141312b" category="inline-link-macro">Avanti: Implementazione di Cnvrg.io</block>
  <block id="c18b567a6a5397941715c30a00a97395" category="paragraph"><block ref="c18b567a6a5397941715c30a00a97395" category="inline-link-macro-rx"></block></block>
  <block id="716c8038f7ef1bc60bc3fe6c036e2d3b" category="doc">TR-4807: Architettura di riferimento ai di NetApp ONTAP per i carichi di lavoro dei servizi finanziari - progettazione della soluzione</block>
  <block id="a8b8bcca1cc81c47655f69efaea66280" category="paragraph">Karthikeyan Nagalingam, Sung-Han Lin, NetApp Jacci Cenci, NVIDIA</block>
  <block id="5e01fc0ba3a2133ea5de509bf81e119d" category="paragraph">Questa architettura di riferimento offre linee guida per i clienti che stanno costruendo un'infrastruttura di intelligenza artificiale utilizzando i sistemi NVIDIA DGX-1 e lo storage NetApp AFF per i casi di utilizzo del settore finanziario. Include informazioni sui flussi di lavoro di alto livello utilizzati per lo sviluppo di modelli di deep learning per i test case e i risultati dei servizi finanziari. Include anche consigli di dimensionamento per le implementazioni dei clienti.</block>
  <block id="96ac76dbb46fec3f4db7ec194dc52d2a" category="paragraph"><block ref="96ac76dbb46fec3f4db7ec194dc52d2a" category="inline-link-macro-rx"></block></block>
  <block id="922b9696b39b06f6a4d313569231a446" category="summary">NVIDIA ai Enterprise con NetApp e VMware - dove trovare ulteriori informazioni</block>
  <block id="77b8a01d0d63ff78898858cf688363c3" category="inline-link-macro">Precedente: Esempio di caso d'utilizzo - lavoro di training TensorFlow.</block>
  <block id="14b2e29c23cc5c2fbf0ecfe2c97d9919" category="paragraph"><block ref="14b2e29c23cc5c2fbf0ecfe2c97d9919" category="inline-link-macro-rx"></block></block>
  <block id="913e298a14c5b49185ced898ccea22bd" category="list-text">NVIDIA ai Enterprise con VMware</block>
  <block id="5fad8e8f46a27398d761d66b0cb3f138" category="paragraph"><block ref="b79ccae54733d96b388303db61e85c7c" category="inline-link-rx"></block>]</block>
  <block id="c85cb3eda6d429393778efbed7420a50" category="list-text">Bobby Oommen, Sr Manager, NetApp</block>
  <block id="c4321e9f60724f09a097b4d8b79c6e7b" category="list-text">Ramesh Isaac, System Administrator, NetApp</block>
  <block id="cf4995eac87d7ce5351e1043fe85683c" category="list-text">Roney Daniel, Technical Marketing Engineer, NetApp</block>
  <block id="48fe531f68f98f9f6afcf79da6d3b1b3" category="doc">TR-4834: Pipeline NetApp e Iguazio per MLRun</block>
  <block id="a0e5bba9c75f65c1d58c6a238316bd2b" category="paragraph">Rick Huang, David Arnette, NetApp Marcelo Litovsky, Iguazio</block>
  <block id="dd9508a891c15cc4bb34f03dc870ab6c" category="paragraph">Questo documento illustra i dettagli della pipeline MLRun che utilizza NetApp ONTAP ai, NetApp ai Control Plane, il software NetApp Cloud Volumes e la piattaforma per la scienza dei dati Iguazio. Abbiamo utilizzato la funzione senza server di Nuclio, i volumi persistenti di Kubernetes, i volumi cloud di NetApp, le copie Snapshot di NetApp, la dashboard di Grafana, E altri servizi sulla piattaforma Iguazio per creare una pipeline di dati end-to-end per la simulazione del rilevamento dei guasti di rete. Abbiamo integrato le tecnologie Iguazio e NetApp per consentire un'implementazione rapida dei modelli, la replica dei dati e le funzionalità di monitoraggio della produzione on-premise e nel cloud.</block>
  <block id="d431a0ad3e0e99cf99c08fda529884bd" category="paragraph">Il lavoro di un data scientist dovrebbe essere incentrato sulla formazione e sulla messa a punto di modelli di apprendimento automatico (ML) e intelligenza artificiale (ai). Tuttavia, secondo una ricerca condotta da Google, i data scientist trascorrono ~il 80% del loro tempo a capire come far funzionare i propri modelli con le applicazioni aziendali ed eseguirlo su larga scala, come mostrato nella seguente immagine che illustra lo sviluppo di modelli nel workflow ai/ML.</block>
  <block id="f08b641e59dba6d999dc1bc2085bcd2c" category="paragraph"><block ref="f08b641e59dba6d999dc1bc2085bcd2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eec0363d19df86d30ecefc2e44170fa" category="paragraph">Per gestire i progetti ai/ML end-to-end, è necessaria una maggiore comprensione dei componenti aziendali. Sebbene DevOps abbia assunto il controllo della definizione, dell'integrazione e dell'implementazione di questi tipi di componenti, le operazioni di apprendimento automatico hanno come obiettivo un flusso simile che include progetti ai/ML. Per avere un'idea di ciò che una pipeline ai/ML end-to-end tocca nell'azienda, consulta il seguente elenco di componenti richiesti:</block>
  <block id="52681719ec1296447ae0e357c4781415" category="list-text">Ambiente di sviluppo integrato (IDE)</block>
  <block id="2f0ff7df4fd6fa99bbf249af2ea4c3a5" category="paragraph">In questo documento, dimostreremo come la partnership tra NetApp e Iguazio semplifichi drasticamente lo sviluppo di una pipeline ai/ML end-to-end. Questa semplificazione accelera il time-to-market per tutte le applicazioni ai/ML.</block>
  <block id="253411380ba9cde08bcfafbd516ad585" category="paragraph">Il mondo della scienza dei dati tocca diverse discipline nel settore dell'informatica e del business.</block>
  <block id="f1a4e0eca545ebe9e3c32f1fde407410" category="list-text">Gli utenti aziendali desiderano avere accesso alle applicazioni ai/ML. Descriviamo in che modo NetApp e Iguazio aiutano ciascuno di questi ruoli a portare valore al business con le nostre piattaforme.</block>
  <block id="00cc9e5c959e62a9132baca479060db3" category="paragraph">Questa soluzione segue il ciclo di vita di un'applicazione ai/ML. Iniziamo con il lavoro dei data scientist per definire le diverse fasi necessarie per preparare i dati e formare e implementare i modelli. Seguiamo il lavoro necessario per creare una pipeline completa con la capacità di tenere traccia degli artefatti, sperimentare con l'esecuzione e implementare in Kubeflow. Per completare il ciclo completo, integriamo la pipeline con i volumi cloud di NetApp per abilitare il controllo delle versioni dei dati, come mostrato nell'immagine seguente.</block>
  <block id="ddd4a11ec23c52d3f0831809bc4d7c8f" category="paragraph"><block ref="ddd4a11ec23c52d3f0831809bc4d7c8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7c8cd7998e5c4a67923acf8580d94e2" category="inline-link-macro">Avanti: Panoramica sulla tecnologia</block>
  <block id="b9023dede6231d8f57593d31db930bf6" category="paragraph"><block ref="b9023dede6231d8f57593d31db930bf6" category="inline-link-macro-rx"></block></block>
  <block id="d7cd7846436814deb26b0df06d7a4b2a" category="summary">Per eseguire un processo ai e ML multinodo sincrono nel cluster Kubernetes, eseguire i task elencati in questa pagina sull'host di distribuzione jump. Questo processo consente di sfruttare i dati memorizzati su un volume NetApp e di utilizzare più GPU di quelle che un singolo nodo di lavoro può fornire.</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">Eseguire un carico di lavoro ai distribuito sincrono</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">Per eseguire un processo ai e ML multinodo sincrono nel cluster Kubernetes, eseguire le seguenti operazioni sull'host di distribuzione jump. Questo processo consente di sfruttare i dati memorizzati su un volume NetApp e di utilizzare più GPU di quelle che un singolo nodo di lavoro può fornire. Vedere la figura seguente per un'illustrazione di un lavoro di ai distribuito sincrono.</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">I lavori distribuiti sincroni possono contribuire ad aumentare la precisione delle performance e della formazione rispetto ai lavori distribuiti asincroni. Una discussione sui pro e contro dei lavori sincroni rispetto ai lavori asincroni non rientra nell'ambito di questo documento.</block>
  <block id="262523fcbe6eb0ec96ea58299e58f65c" category="paragraph"><block ref="262523fcbe6eb0ec96ea58299e58f65c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a9af10e4883efa64de927027b5b0ffa" category="list-text">I seguenti comandi di esempio mostrano la creazione di un worker che partecipa all'esecuzione distribuita sincrona dello stesso job di benchmark TensorFlow eseguito su un singolo nodo nell'esempio della sezione <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>. In questo esempio specifico, viene implementato solo un singolo worker perché il lavoro viene eseguito su due nodi di lavoro.</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">In questo esempio, l'implementazione di lavoro richiede otto GPU e può quindi essere eseguita su un singolo nodo di lavoro GPU che dispone di otto o più GPU. Se i nodi di lavoro GPU dispongono di più di otto GPU, per massimizzare le performance, è possibile aumentare questo numero in modo da essere uguale al numero di GPU presenti nei nodi di lavoro. Per ulteriori informazioni sulle implementazioni di Kubernetes, vedere<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block>.</block>
  <block id="bfe89db11adc9a38165e670f3062d398" category="paragraph">In questo esempio viene creata un'implementazione di Kubernetes perché questo specifico lavoratore containerizzato non viene mai completato da solo. Pertanto, non ha senso implementarlo utilizzando il costrutto di lavoro Kubernetes. Se il tuo lavoratore è stato progettato o scritto per essere completato da solo, potrebbe essere opportuno utilizzare il costrutto di lavoro per implementare il tuo lavoratore.</block>
  <block id="05bdf5435b916b7b205f448788324f2b" category="paragraph">Al pod specificato in questa specifica di implementazione di esempio viene assegnato un<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valore di<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>. Questo valore significa che il pod utilizza lo stack di rete del nodo di lavoro host invece dello stack di rete virtuale creato da Kubernetes per ciascun pod. Questa annotazione viene utilizzata in questo caso perché il carico di lavoro specifico si basa su Open MPI, NCCL e Horovod per eseguire il carico di lavoro in maniera sincrona e distribuita. Pertanto, richiede l'accesso allo stack di rete host. Una discussione su Open MPI, NCCL e Horovod non rientra nell'ambito di questo documento. Che sia o meno così<block ref="02cbe2b15bc778c7658250053bbc5a5c" prefix=" " category="inline-code"></block> l'annotazione è necessaria a seconda dei requisiti del carico di lavoro specifico che si sta eseguendo. Per ulteriori informazioni su<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> vedere il campo<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block>.</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">Verificare che l'implementazione worker creata al punto 1 sia stata avviata correttamente. I seguenti comandi di esempio confermano che è stato creato un singolo pod di lavoro per l'implementazione, come indicato nella definizione di implementazione, e che questo pod è attualmente in esecuzione su uno dei nodi di lavoro GPU.</block>
  <block id="3ba975f6a7389af18602f0e938bcc37b" category="list-text">Creare un lavoro Kubernetes per un master che inizia, partecipa e tiene traccia dell'esecuzione del lavoro sincrono a più nodi. I seguenti comandi di esempio creano un master che inizia, partecipa e tiene traccia dell'esecuzione distribuita sincrona dello stesso job di benchmark TensorFlow eseguito su un singolo nodo nell'esempio nella sezione <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>.</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">Questo processo master di esempio richiede otto GPU e può quindi essere eseguito su un singolo nodo di lavoro GPU che dispone di otto o più GPU. Se i nodi di lavoro GPU dispongono di più di otto GPU, per massimizzare le performance, è possibile aumentare questo numero in modo da essere uguale al numero di GPU presenti nei nodi di lavoro.</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">Al pod master specificato in questa definizione di lavoro di esempio viene assegnato un<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valore di<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>, proprio come al pod di lavoro è stato assegnato un<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valore di<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> nella fase 1. Per ulteriori informazioni sul motivo per cui questo valore è necessario, vedere il passaggio 1.</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">Verificare che il lavoro principale creato al punto 3 sia in esecuzione correttamente. Il seguente comando di esempio conferma che è stato creato un singolo pod master per il lavoro, come indicato nella definizione del lavoro, e che questo pod è attualmente in esecuzione su uno dei nodi di lavoro GPU. Inoltre, il pod di lavoro inizialmente visto al punto 1 è ancora in esecuzione e i pod master e di lavoro sono in esecuzione su nodi diversi.</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">Verificare che il lavoro principale creato al punto 3 sia stato completato correttamente. I seguenti comandi di esempio confermano che il lavoro è stato completato correttamente.</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">Eliminare l'implementazione dei lavoratori quando non è più necessaria. I seguenti comandi di esempio mostrano l'eliminazione dell'oggetto di implementazione worker creato nel passaggio 1.</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">Quando si elimina l'oggetto di implementazione worker, Kubernetes elimina automaticamente tutti i worker pod associati.</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">*Opzionale:* eliminare gli artefatti del job master. I seguenti comandi di esempio mostrano l'eliminazione dell'oggetto di lavoro master creato nel passaggio 3.</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">Quando si elimina l'oggetto di lavoro master, Kubernetes elimina automaticamente tutti i pod master associati.</block>
  <block id="256fbc599203bd1bd63bfe25b7a5b9ad" category="inline-link-macro">Avanti: Test delle performance.</block>
  <block id="35bb3345a07dfa439dd6936ea8f69faf" category="paragraph"><block ref="35bb3345a07dfa439dd6936ea8f69faf" category="inline-link-macro-rx"></block></block>
  <block id="19075a93ccd90f3ea7019f0572778b2a" category="summary">In questa pagina sono elencati i requisiti software necessari per questa soluzione.</block>
  <block id="440b940924209e1d417ef7c4ef9bce34" category="paragraph"><block ref="440b940924209e1d417ef7c4ef9bce34" category="inline-link-macro-rx"></block></block>
  <block id="793d18702a236e0e3b768917638f0ba2" category="paragraph">La seguente tabella elenca i requisiti software necessari per questa soluzione.</block>
  <block id="8ab697a4168b5fb33603a98d6bc9a436" category="cell">IMMAGINE del container RAPIDS e Dask</block>
  <block id="9ab6289633c326d69a377cbb29bd81a3" category="cell">Repository: "Rapidsai/rapidsai" Tag: 0.17-cuda11.0-runtime-ubuntu18.04</block>
  <block id="6e1b77cc3b83d87aaee751e2eaed5044" category="inline-link-macro">Successivo: Requisiti relativi alle risorse cloud.</block>
  <block id="58bc7690a5a3a5a1aa5dc70739fd0b53" category="paragraph"><block ref="58bc7690a5a3a5a1aa5dc70739fd0b53" category="inline-link-macro-rx"></block></block>
  <block id="34d110ef6b6b3684adfe9c791fce2f95" category="summary">Questa sezione descrive i passaggi dettagliati necessari per implementare questa soluzione.</block>
  <block id="e0673e67d0ae2470ff4a9a3a926792b0" category="doc">Implementazione dell'analisi del sentimento del centro di supporto</block>
  <block id="0c7ee1e6d81ae421558f2979d46adb5d" category="inline-link-macro">Precedente: Considerazioni di progettazione.</block>
  <block id="2e4639bc721df1da69c19fe5c10f5764" category="paragraph"><block ref="2e4639bc721df1da69c19fe5c10f5764" category="inline-link-macro-rx"></block></block>
  <block id="b23f4e3eb5ff4f900ba54c824bf7a676" category="paragraph">L'implementazione della soluzione comporta i seguenti componenti:</block>
  <block id="1b497bff4e1d2dff7f8855237612936b" category="list-text">Configurazione NGC</block>
  <block id="2dcf1afb8ed1445e4b167ef91fdd8a1b" category="list-text">Server NVIDIA RIVA</block>
  <block id="6894a1e922948fc0bc9cc96291183448" category="list-text">Toolkit NVIDIA TAO</block>
  <block id="3b498dd8feee94c2dbcb419be10d3b70" category="list-text">Esportare i modelli TAO in RIVA</block>
  <block id="534b37206d500ff97473ada660fb69d3" category="paragraph">Per eseguire l'implementazione, attenersi alla seguente procedura:</block>
  <block id="2f6c7bd50828792593b3aa4deff875cc" category="section-title">NetApp DataOps Toolkit: Analisi del sentimento del centro di supporto</block>
  <block id="3b84de14b99e2695fdfd099f56b254be" category="paragraph">Per utilizzare<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>, completare la seguente procedura:</block>
  <block id="d19523f192f664c9e34bf949d6f084c3" category="list-text">PIP installare il toolkit.</block>
  <block id="1fe6ae43439f5ccecf9883686d6b3784" category="list-text">Configurare la gestione dei dati</block>
  <block id="36b413e2c45a91e66db4aac6abd67ba1" category="section-title">Configurazione NGC: Analisi del sentimento del centro di supporto</block>
  <block id="e3ab64bcab09d9eb8219520405242267" category="inline-link">NVIDIA NGC</block>
  <block id="f526ba073cf7bc97c2b0d3bfe091e293" category="paragraph">Per configurare<block ref="5b4e29c9d8254a25bb1abc36cd17ca4c" category="inline-link-rx"></block>, completare la seguente procedura:</block>
  <block id="a485a457c113aa9f2f8096ac1ca500d7" category="list-text">Scarica NGC.</block>
  <block id="7438544460c4a4fdf0b70bb65bb03a92" category="list-text">Aggiungere la directory corrente al percorso.</block>
  <block id="4f1208b2473595e5f4c3118c13de0fcc" category="list-text">È necessario configurare l'interfaccia CLI NGC per l'utilizzo in modo da poter eseguire i comandi. Immettere il seguente comando, inclusa la chiave API quando richiesto.</block>
  <block id="5307692c5f99e57b8002a6a87f08c240" category="paragraph">Per i sistemi operativi che non sono basati su Linux, visitare il sito<block ref="481e32faa0c657434738f6f0a550651b" category="inline-link-rx"></block>.</block>
  <block id="326419ec6a380f68d7d15a373452bf35" category="section-title">Server NVIDIA RIVA: Analisi del sentimento del centro di supporto</block>
  <block id="92ed82a726e834b50a6863c8c4e9db4e" category="paragraph">Per configurare<block ref="fb85035785391c7c4b815d01de952f38" category="inline-link-rx"></block>, completare la seguente procedura:</block>
  <block id="a4fc5fd3d1cea05f031d5adc045dc1e0" category="list-text">Scarica I file RIVA da NGC.</block>
  <block id="5f2573d8cf9e274560d9a9b3eb2e1aaa" category="list-text">Inizializzare la configurazione DI RIVA <block ref="b57bfc797452f0a8f165771280704dc4" prefix="(" category="inline-code"></block>).</block>
  <block id="3b570ac682cfeffcdb2c7243afdbf285" category="list-text">Avviare IL server RIVA <block ref="9578e0f1e91365703f275dd0aa9dd913" prefix="(" category="inline-code"></block>).</block>
  <block id="d44d4e10378cce2928c99a4b49e45cea" category="list-text">Avviare IL client RIVA <block ref="98e192e15ed3b76551ab5ef8d11ef1e8" prefix="(" category="inline-code"></block>).</block>
  <block id="6846c1a17ddaf84e01f26ec51c151e78" category="inline-link">FFMPEG</block>
  <block id="22c9c751571566e0566c448194d9d64f" category="list-text">All'interno del client RIVA, installare la libreria di elaborazione audio (<block ref="3e294dfc4ee3a49adac5a070482274ce" category="inline-link-rx"></block>)</block>
  <block id="8637711b2ee1b94fe789bb28e88c4b61" category="list-text">Avviare<block ref="37a4c4b3ad3c3851ac5717bfd3104346" category="inline-link-rx"></block> server.</block>
  <block id="b57a5203a9fd3e877aacee6cba6bc9c8" category="list-text">Eseguire il notebook RIVA Inference Pipeline.</block>
  <block id="5dceab25ae38dae0d7ed3167abd32377" category="section-title">NVIDIA TAO Toolkit: Analisi del sentimento del centro di supporto</block>
  <block id="2418d4c7f6be40d5c9a50e4aecab1b27" category="paragraph">Per configurare NVIDIA TAO Toolkit, attenersi alla seguente procedura:</block>
  <block id="630eef78d15fd844ba4a38ea7f7a9c79" category="inline-link">ambiente virtuale</block>
  <block id="35fb58d5f90347e4f0c445b4968db5f6" category="list-text">Preparare e attivare un<block ref="3d97a4392c0af686650645d1371fa8ef" category="inline-link-rx"></block> Per TAO Toolkit.</block>
  <block id="0a80b2068950d6e04f34c0142a10e719" category="inline-link">pacchetti richiesti</block>
  <block id="40eb0bd8a87ab1b39e8f2ee5ea287a22" category="list-text">Installare<block ref="3646357cb54591ae95dd3b8f0889f0c2" category="inline-link-rx"></block>.</block>
  <block id="c0e95a7dacbc170e387c4e1a0fe41a0b" category="list-text">Estrarre manualmente l'immagine utilizzata durante l'addestramento e la messa a punto.</block>
  <block id="b5a6ae7c1df936b55910309efc466f01" category="list-text">Eseguire il notebook TAO fine-Tuning.</block>
  <block id="e6dda626093691f78b3127a8faa82b6e" category="section-title">Esportare i modelli TAO in RIVA: Analisi del sentimento del centro di supporto</block>
  <block id="6a358d81cb24a7e408b0339062f6bb92" category="inline-link">Modelli TAO Toolkit di RIVA</block>
  <block id="53ace4ba305859107cead3e5b0b53b8b" category="paragraph">Da utilizzare<block ref="ce50a5bf8eb35af9ad9bb322336ee3af" category="inline-link-rx"></block>, completare la seguente procedura:</block>
  <block id="08c3be8307b7659c6ad67ee4d9659d58" category="list-text">Salva i modelli nel notebook TAO fine-Tuning.</block>
  <block id="ac711bb6af28947dfa8b29512acb36e8" category="list-text">Copiare i modelli addestrati TAO nella directory dei modelli RIVA.</block>
  <block id="1317e1d8d20d5c44c680825aba2196e6" category="section-title">Blocchi stradali per l'implementazione</block>
  <block id="6e3da39922ebbd1a8a1a5a7238a89168" category="paragraph">Ecco alcuni elementi da tenere a mente durante lo sviluppo della soluzione:</block>
  <block id="47c0613abd5b97b67a94c2355692cf08" category="list-text">Il NetApp DataOps Toolkit viene installato per primo per garantire il funzionamento ottimale del sistema di storage dei dati.</block>
  <block id="943f803f8c6b4c6508bc97536a6d7b2b" category="list-text">NVIDIA NGC deve essere installata prima di ogni altra cosa perché autentica il download di immagini e modelli.</block>
  <block id="70367b72bfd96b5608a7c72ac3f983bf" category="list-text">RIVA deve essere installato prima del toolkit TAO. L'installazione DI RIVA configura il daemon del docker per estrarre le immagini in base alle necessità.</block>
  <block id="1ed7124aa68792cb6ce3049f6f1d4f7b" category="list-text">DGX e Docker devono disporre dell'accesso a Internet per scaricare i modelli.</block>
  <block id="de9b04ca3177b736c9f3cc74d62f5088" category="inline-link-macro">Successivo: Risultati della convalida.</block>
  <block id="3556370bb03d018998375ff0476db59a" category="paragraph"><block ref="3556370bb03d018998375ff0476db59a" category="inline-link-macro-rx"></block></block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">È possibile regolare l'impostazione utilizzata per la convalida in modo che si adatti ad altri casi di utilizzo.</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">Opzioni di dimensionamento dell'architettura</block>
  <block id="389a3124af7d4b9dc7165b05fd96a378" category="paragraph"><block ref="389a3124af7d4b9dc7165b05fd96a378" category="inline-link-macro-rx"></block></block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">Server di calcolo</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">Abbiamo utilizzato una CPU Intel Xeon D-2123IT, che è il livello più basso di CPU supportato in SE350, con quattro core fisici e TDP da 60 W. Anche se il server non supporta la sostituzione delle CPU, può essere ordinato con una CPU più potente. La CPU più alta supportata è Intel Xeon D-2183IT con 16 core, 100 W a 2,20 GHz. Ciò aumenta notevolmente la capacità di calcolo della CPU. Anche se la CPU non era un collo di bottiglia per l'esecuzione dei carichi di lavoro di inferenza, aiuta nell'elaborazione dei dati e in altre attività correlate all'inferenza. Attualmente, NVIDIA T4 è l'unica GPU disponibile per i casi di utilizzo edge; pertanto, attualmente, non è possibile aggiornare o eseguire il downgrade della GPU.</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">Storage condiviso</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">Per il test e la convalida, il sistema NetApp AFF C190, con una capacità di storage massima di 50,5 TB, un throughput di 4,4 Gbps per letture sequenziali e 230 K IOPS per letture casuali di piccole dimensioni, è stato utilizzato per lo scopo di questo documento ed è stato dimostrato adatto per i carichi di lavoro di inferenza edge.</block>
  <block id="bb33c803e43b816786d862bbbbf2c824" category="paragraph">Tuttavia, se si desidera una maggiore capacità di storage o velocità di rete superiori, è consigliabile utilizzare NetApp AFF A220 o.<block ref="03f94a30ec5c979321fdd9a1ba99a1c6" category="inline-link-rx"></block> sistemi storage. Inoltre, per la convalida della soluzione è stato utilizzato anche il sistema NetApp EF280, con una capacità massima di 1,5 PB e una larghezza di banda di 10 Gbps. Se preferisci una maggiore capacità di storage con una maggiore larghezza di banda,<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block> può essere utilizzato.</block>
  <block id="fdd5191dcc2e7fa6e2ec4d0618cf2a40" category="paragraph"><block ref="fdd5191dcc2e7fa6e2ec4d0618cf2a40" category="inline-link-macro-rx"></block></block>
  <block id="a41206687a4ac62c15fc883554a75883" category="summary">In questa sezione viene descritto l'ambiente di convalida della progettazione della soluzione.</block>
  <block id="172ddae93475d6ccf42e145bb593da46" category="inline-link-macro">Precedente: Piano di test e validazione.</block>
  <block id="9ea432ca0ec547aa219093f8f5f560cc" category="paragraph"><block ref="9ea432ca0ec547aa219093f8f5f560cc" category="inline-link-macro-rx"></block></block>
  <block id="0d013965bb31fe1cc0ba44ef3b846d09" category="paragraph">La seguente tabella descrive l'ambiente di convalida della progettazione della soluzione.</block>
  <block id="32f014d18e1f60596057834de2864322" category="cell">1.21.6</block>
  <block id="b0f69588db488e358ab3c85429ab6b3a" category="cell">Driver NetApp Astra Trident CSI</block>
  <block id="70e2b24f7d348efe6b30b41469d5070c" category="cell">2.3.0</block>
  <block id="099d96b4d8f70fb73f1d4661f98c337a" category="cell">21.11-py3</block>
  <block id="53e01217bc7db361f46a1f8e0e601655" category="paragraph"><block ref="53e01217bc7db361f46a1f8e0e601655" category="inline-link-macro-rx"></block></block>
  <block id="dca91c3343cc0ad062506cdd14eb7d41" category="summary">Le ultime novità del materiale collaterale sulle soluzioni di cloud ibrido, virtualizzazione desktop e container</block>
  <block id="120c02d2aa6cda1e3b75902fb4fc0b53" category="doc">Novità per le soluzioni di cloud ibrido, virtualizzazione desktop e container</block>
  <block id="07e257430bade6bc5bce1c2170c6fc0d" category="paragraph">Panoramica delle più recenti soluzioni e materiali di supporto per cloud ibrido, virtualizzazione desktop e container.</block>
  <block id="c1e392a90896851b3319d6075402fd4d" category="cell">*Cloud ibrido/privato*</block>
  <block id="c2240101c5a3a188541ce87c59265df9" category="cell"><block ref="c2240101c5a3a188541ce87c59265df9" category="inline-link-macro-rx"></block></block>
  <block id="fe72963b1d3021a9f6d8ae34414601c3" category="cell"><block ref="fe72963b1d3021a9f6d8ae34414601c3" category="inline-link-macro-rx"></block></block>
  <block id="4d066173d8401c92a19650e99dcaae5d" category="cell"><block ref="4d066173d8401c92a19650e99dcaae5d" category="inline-link-macro-rx"></block></block>
  <block id="8ef4e9c7260e8d314760329e07c618ae" category="cell">*Virtualizzazione*</block>
  <block id="2bdc87f51d413e6d2fa23dd26238501f" category="inline-link-macro">VMware vSphere per ONTAP</block>
  <block id="1f23e5de73e650f12cbafec55d8a98cd" category="cell"><block ref="1f23e5de73e650f12cbafec55d8a98cd" category="inline-link-macro-rx"></block></block>
  <block id="236122c6ab4c764632437a76fa95e5c0" category="cell">*Virtualizzazione desktop*</block>
  <block id="4b47c65474ab7fae9b08ddf38d598971" category="inline-link-macro">Cloud ibrido VDI con NetApp Virtual Desktop Service (VDS)</block>
  <block id="dea91bec9e85387a496bb2c228fc7dc3" category="cell"><block ref="dea91bec9e85387a496bb2c228fc7dc3" category="inline-link-macro-rx"></block></block>
  <block id="1ebfe0d8e53e3f7f2c37e8b3835c2adf" category="cell">*Container*</block>
  <block id="a32ca451a300bb4e3c6b19cb1592126a" category="inline-link-macro">DevOps con NetApp Astra</block>
  <block id="cb6bb56e7a1df42aff4aeae660a2df10" category="cell"><block ref="cb6bb56e7a1df42aff4aeae660a2df10" category="inline-link-macro-rx"></block></block>
  <block id="a0eaa75e3e2b8c6220db02697d4acf1f" category="cell"><block ref="a0eaa75e3e2b8c6220db02697d4acf1f" category="inline-link-macro-rx"></block></block>
  <block id="4105298f144b4b0e636460eede523df0" category="inline-link-macro">Installazione automatica di Astra Control Center tramite Ansible</block>
  <block id="64295ddd382f7876d307bac08ad539fe" category="cell"><block ref="64295ddd382f7876d307bac08ad539fe" category="inline-link-macro-rx"></block></block>
  <block id="bd6059cd679908cdb2d015167d51a3fe" category="cell"><block ref="bd6059cd679908cdb2d015167d51a3fe" category="inline-link-macro-rx"></block></block>
  <block id="6dc07ae6ad84b77b5d06f9d3fff5b819" category="cell"><block ref="6dc07ae6ad84b77b5d06f9d3fff5b819" category="inline-link-macro-rx"></block></block>
  <block id="e32276e1eed6ff0e76971afd985cea2d" category="cell"><block ref="e32276e1eed6ff0e76971afd985cea2d" category="inline-link-macro-rx"></block></block>
  <block id="306a916d056a0d0a4b898b9dca9692ee" category="inline-link-macro">NetApp Astra Control Center su Red Hat OpenShift</block>
  <block id="20c49a9a4d903fa259d4f8820b3755d2" category="cell"><block ref="20c49a9a4d903fa259d4f8820b3755d2" category="inline-link-macro-rx"></block></block>
  <block id="77697d49d0c6b79e2642435a36c8c1e0" category="cell"><block ref="77697d49d0c6b79e2642435a36c8c1e0" category="inline-link-macro-rx"></block></block>
  <block id="119ad672b0d69ab3f968877b6ec83dd3" category="cell"><block ref="119ad672b0d69ab3f968877b6ec83dd3" category="inline-link-macro-rx"></block></block>
  <block id="ad1cf94aab71c9962e22037ed60d41e9" category="cell"><block ref="ad1cf94aab71c9962e22037ed60d41e9" category="inline-link-macro-rx"></block></block>
  <block id="60f031c992a9c99aa5413bddb0ecc644" category="cell"><block ref="60f031c992a9c99aa5413bddb0ecc644" category="inline-link-macro-rx"></block></block>
  <block id="13a82ffd84cedcd28833f58d716b4c3c" category="cell"><block ref="13a82ffd84cedcd28833f58d716b4c3c" category="inline-link-macro-rx"></block></block>
  <block id="e6ba927c9d14295015e39be05cf54040" category="inline-link-macro">Multi-tenancy su Red Hat OpenShift con NetApp ONTAP</block>
  <block id="ab439bcac737f2565970fe2612976b75" category="cell"><block ref="ab439bcac737f2565970fe2612976b75" category="inline-link-macro-rx"></block></block>
  <block id="ad95c47343e102dc30ec33fa6f1ccc55" category="inline-link-macro">NVA-1160 - Red Hat OpenShift con NetApp</block>
  <block id="1043b5153afff839b84d714aa9127913" category="cell"><block ref="1043b5153afff839b84d714aa9127913" category="inline-link-macro-rx"></block></block>
  <block id="0fd00a19fb12bb899dfe7cefbcbbcb79" category="inline-link-macro">Installazione di NetApp Trident su Red Hat OpenShift – come risolvere il problema ‘toomanyrequests' di Docker!</block>
  <block id="43e5d9153d1fc4a35be5f57189605919" category="cell"><block ref="43e5d9153d1fc4a35be5f57189605919" category="inline-link-macro-rx"></block></block>
  <block id="da38226e07ff21f147182bb08be38f6f" category="inline-link-macro">Anthos su bare metal con NetApp</block>
  <block id="ac1da2af455fc001ba8b58af0e62d151" category="cell"><block ref="ac1da2af455fc001ba8b58af0e62d151" category="inline-link-macro-rx"></block></block>
  <block id="c94d29f1f4f8ef37e9d27f30b7d7c67d" category="summary">Le attività descritte in questa sezione devono essere completate on-premise per preparare l'ambiente di carico di lavoro del database del cloud ibrido SnapCenter.</block>
  <block id="f6a196d9d3a941e76765e4a9395630c4" category="doc">Prerequisiti on-premise</block>
  <block id="eac55cbc45bfe6b98b8847b3952de7d3" category="inline-link-macro">Precedente: Prerequisiti per la configurazione.</block>
  <block id="e63a288cc25b5c4127d3021b339c9f20" category="paragraph"><block ref="e63a288cc25b5c4127d3021b339c9f20" category="inline-link-macro-rx"></block></block>
  <block id="40931dcd4d9132545ec0faf2c5fb1b64" category="paragraph">Le seguenti attività devono essere completate on-premise per preparare l'ambiente di carico di lavoro del database del cloud ibrido SnapCenter.</block>
  <block id="79daf399b9626cde309801f41a1e2e14" category="section-title">Installazione e configurazione di SnapCenter</block>
  <block id="2607530756fefa4173e12cfcd5fbfb01" category="paragraph">Il tool NetApp SnapCenter è un'applicazione basata su Windows che in genere viene eseguita in un ambiente di dominio Windows, anche se è possibile implementare un gruppo di lavoro. Si basa su un'architettura a più livelli che include un server di gestione centralizzato (il server SnapCenter) e un plug-in SnapCenter sugli host del server di database per i carichi di lavoro del database. Ecco alcune considerazioni chiave per l'implementazione del cloud ibrido.</block>
  <block id="9f8c0bcd11d7afd1dd2ee818191cb914" category="list-text">*Implementazione ha o istanza singola.* l'implementazione ha fornisce ridondanza in caso di guasto di un singolo server di istanza SnapCenter.</block>
  <block id="1bfa2867d5aa49106efbf3ac752f3084" category="list-text">*Risoluzione del nome.* il DNS deve essere configurato sul server SnapCenter per risolvere tutti gli host di database e sulla SVM di storage per la ricerca in avanti e indietro. Il DNS deve essere configurato anche sui server di database per risolvere il server SnapCenter e la SVM di storage per la ricerca in avanti e in retromarcia.</block>
  <block id="41f54308d86c1d7b525475d6ead22892" category="list-text">*Configurazione RBAC (role-based access control).* per i carichi di lavoro di database misti, è possibile utilizzare RBAC per separare la responsabilità di gestione per diverse piattaforme di database, ad esempio un amministratore per database Oracle o un amministratore per SQL Server. Le autorizzazioni necessarie devono essere concesse all'utente amministratore del database.</block>
  <block id="5aee5dffd2e329652ec35995add763ae" category="list-text">*Attivare una strategia di backup basata su policy.* per garantire la coerenza e l'affidabilità del backup.</block>
  <block id="dde4790e572aa9d01cd58fcfd8498766" category="list-text">*Aprire le porte di rete necessarie sul firewall.* per consentire al server SnapCenter on-premise di comunicare con gli agenti installati nell'host del DB cloud.</block>
  <block id="e2962676531ebdcf62cb2a7b96042e77" category="list-text">*Le porte devono essere aperte per consentire il traffico SnapMirror tra cloud pubblico e on-premise.* il server SnapCenter si affida a SnapMirror di ONTAP per replicare i backup Snapshot in loco sulle SVM di storage CVO nel cloud.</block>
  <block id="549762060d7242346fa79f39cba51791" category="inline-link-macro">Workflow di installazione di SnapCenter</block>
  <block id="aec875397d57826c45f7072636026a07" category="paragraph">Dopo un'attenta pianificazione e valutazione della preinstallazione, fare clic su questa opzione <block ref="f44e9d032441cc842cad02c3aab57d84" category="inline-link-macro-rx"></block> Per informazioni dettagliate sull'installazione e la configurazione di SnapCenter.</block>
  <block id="df3fb602185c77a88bab186791d02636" category="section-title">Configurazione dello storage del server di database on-premise</block>
  <block id="f7f3a649be867b87ccb26789453199db" category="paragraph">Le performance dello storage giocano un ruolo importante nelle performance generali di database e applicazioni. Un layout dello storage ben progettato non solo può migliorare le performance del database, ma anche semplificare la gestione del backup e ripristino del database. Durante la definizione del layout dello storage, è necessario prendere in considerazione diversi fattori, tra cui la dimensione del database, il tasso di variazione dei dati previsti per il database e la frequenza con cui vengono eseguiti i backup.</block>
  <block id="8481231881c8e64b34aa3c7e29510a25" category="paragraph">Il collegamento diretto delle LUN di storage alla macchina virtuale guest tramite NFS o iSCSI per carichi di lavoro di database virtualizzati offre generalmente performance migliori rispetto allo storage allocato tramite VMDK. NetApp consiglia il layout dello storage per un database SQL Server di grandi dimensioni su LUN, illustrato nella figura seguente.</block>
  <block id="cc75f443d22e45e490468a8f20689d77" category="paragraph"><block ref="cc75f443d22e45e490468a8f20689d77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99aea05cf884bfdec230afa5250968b2" category="paragraph">La figura seguente mostra il layout di storage consigliato da NetApp per database SQL Server di piccole o medie dimensioni su LUN.</block>
  <block id="9fc72535f1113895818f8aa60ef773e7" category="paragraph"><block ref="9fc72535f1113895818f8aa60ef773e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ecde8f778d0dd0676f392793ce4382" category="admonition">La directory Log è dedicata a SnapCenter per eseguire il rollup del log delle transazioni per il ripristino del database. Per un database di grandi dimensioni, è possibile allocare più LUN a un volume per migliorare le performance.</block>
  <block id="ee9158729a15dbd90d166650ba285d0e" category="paragraph">Per i carichi di lavoro dei database Oracle, SnapCenter supporta ambienti di database supportati dallo storage ONTAP montato sull'host come dispositivi fisici o virtuali. È possibile ospitare l'intero database su uno o più dispositivi di storage in base alla criticità dell'ambiente. In genere, i clienti isolano i file di dati sullo storage dedicato da tutti gli altri file, ad esempio file di controllo, file di ripristino e file di log di archiviazione. In questo modo, gli amministratori possono eseguire rapidamente il ripristino (ONTAP single-file SnapRestore) o clonare un database critico di grandi dimensioni (scala di petabyte) utilizzando la tecnologia Snapshot in pochi secondi o minuti.</block>
  <block id="b31fbb7e1a6e863315e431fdf9c00db9" category="paragraph"><block ref="b31fbb7e1a6e863315e431fdf9c00db9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="959a3405dfdfb0469534f5276ffb8e5e" category="paragraph">Per i carichi di lavoro mission-critical sensibili alla latenza, è necessario implementare un volume di storage dedicato a diversi tipi di file Oracle per ottenere la migliore latenza possibile. Per un database di grandi dimensioni, è necessario allocare più LUN (NetApp consiglia fino a otto) per volume ai file di dati.</block>
  <block id="ac111cbcae2e9eaedafe418acc3a2cab" category="paragraph"><block ref="ac111cbcae2e9eaedafe418acc3a2cab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2702ce3d59ec94853fa030462b309f2f" category="paragraph">Per i database Oracle più piccoli, SnapCenter supporta layout di storage condivisi in cui è possibile ospitare più database o parte di un database sullo stesso volume di storage o LUN. Come esempio di questo layout, è possibile ospitare file di dati per tutti i database su un gruppo di dischi +DATA ASM o un gruppo di volumi. Il resto dei file (redo, log di archiviazione e file di controllo) può essere ospitato su un altro gruppo di dischi o un gruppo di volumi dedicato (LVM). Di seguito viene illustrato uno scenario di implementazione di questo tipo.</block>
  <block id="6c12e98a6e201f55836390c2a6232e5a" category="paragraph"><block ref="6c12e98a6e201f55836390c2a6232e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93cf45b97655292e0536b810cb248828" category="paragraph">Per facilitare il trasferimento dei database Oracle, il file binario Oracle deve essere installato su un LUN separato incluso nella normale policy di backup. In questo modo, in caso di trasferimento del database su un nuovo host server, lo stack Oracle può essere avviato per il ripristino senza potenziali problemi dovuti a un binario Oracle non sincronizzato.</block>
  <block id="1e69a4a8adec0842d1e110e970112268" category="section-title">Requisiti di licenza</block>
  <block id="7f59934b2c0edd33f0d981f3bc4d12e7" category="paragraph">SnapCenter è un software concesso in licenza da NetApp. Generalmente è incluso in una licenza ONTAP on-premise. Tuttavia, per l'implementazione del cloud ibrido, è necessaria anche una licenza cloud per SnapCenter per aggiungere CVO a SnapCenter come destinazione di replica dei dati di destinazione. Per ulteriori informazioni, consultare i seguenti collegamenti per la licenza basata sulla capacità standard di SnapCenter:</block>
  <block id="9e86ae6c96041e3cb31e88116102ee35" category="inline-link-macro">Licenze standard SnapCenter basate sulla capacità</block>
  <block id="a1d51b5b5f3258b40cbe392146bc8868" category="paragraph"><block ref="a1d51b5b5f3258b40cbe392146bc8868" category="inline-link-macro-rx"></block></block>
  <block id="85db56d490cdd7a31d40697ad1c9be3c" category="section-title">Networking e sicurezza</block>
  <block id="254215e6d18fb5582ba78464fa468553" category="paragraph">In un'operazione di database ibrido che richiede un database di produzione on-premise che sia burstable nel cloud per lo sviluppo/test e il disaster recovery, il networking e la sicurezza sono fattori importanti da prendere in considerazione durante la configurazione dell'ambiente e la connessione al cloud pubblico da un data center on-premise.</block>
  <block id="1e356fab450b44971b6cdbd1c25586b8" category="paragraph">I cloud pubblici in genere utilizzano un cloud privato virtuale (VPC) per isolare diversi utenti all'interno di una piattaforma di cloud pubblico. All'interno di un singolo VPC, la sicurezza viene controllata mediante misure come i gruppi di sicurezza configurabili in base alle esigenze dell'utente per il blocco di un VPC.</block>
  <block id="5192a6d33c7a0127a67cbd7e07801735" category="paragraph">La connettività dal data center on-premise al VPC può essere protetta attraverso un tunnel VPN. Sul gateway VPN, la sicurezza può essere potenziata utilizzando le regole NAT e firewall che bloccano i tentativi di stabilire connessioni di rete dagli host su Internet agli host all'interno del data center aziendale.</block>
  <block id="04a3995237c020c6a587d8a7723af6a6" category="paragraph">Per considerazioni relative a networking e sicurezza, consulta le regole CVO in entrata e in uscita per il tuo cloud pubblico preferito:</block>
  <block id="d15513a147fbd525b88805bee9ea17ea" category="inline-link-macro">Regole del gruppo di sicurezza per CVO - AWS</block>
  <block id="f8d1f085169118c4d407be16136389c6" category="list-text"><block ref="f8d1f085169118c4d407be16136389c6" category="inline-link-macro-rx"></block></block>
  <block id="39f48b44d100d16ed6e2b931111663b7" category="inline-link-macro">Regole del gruppo di sicurezza per CVO - Azure</block>
  <block id="bcde746324630d82052a4fc9861cfea6" category="list-text"><block ref="bcde746324630d82052a4fc9861cfea6" category="inline-link-macro-rx"></block></block>
  <block id="7b20c547f2fd113499deaa3c0e418282" category="inline-link-macro">Regole firewall per CVO - GCP</block>
  <block id="acde731d82a437ab33cb200791f7a197" category="list-text"><block ref="acde731d82a437ab33cb200791f7a197" category="inline-link-macro-rx"></block></block>
  <block id="d9446a69434b7c7fdec5c9e35d222834" category="section-title">Utilizzo di Ansible Automation per sincronizzare istanze di DB tra on-premise e cloud - opzionale</block>
  <block id="1c7c9b49a62ea0dc765d1439120cfc8f" category="paragraph">Per semplificare la gestione di un ambiente di database di cloud ibrido, NetApp consiglia, ma non richiede, di implementare un controller Ansible per automatizzare alcune attività di gestione, ad esempio mantenendo le istanze di calcolo on-premise e nel cloud sincronizzate. Questo è particolarmente importante perché un'istanza di calcolo fuori sincronizzazione nel cloud potrebbe rendere il database recuperato nel cloud soggetto a errori a causa di pacchetti del kernel mancanti e di altri problemi.</block>
  <block id="7468552c7fc3a7ca377b7fc2405a9940" category="paragraph">La funzionalità di automazione di un controller Ansible può anche essere utilizzata per aumentare il SnapCenter per determinate attività, come la rottura dell'istanza di SnapMirror per attivare la copia dei dati DR per la produzione.</block>
  <block id="6ac547919eb6ca11f5a8387eaf990843" category="inline-link-macro">RedHat/CentOS Ansible Controller Setup</block>
  <block id="c8e133fc33bbdb52f84b3532496f2ac8" category="inline-link-macro">Installazione di Ubuntu/Debian Ansible Controller</block>
  <block id="6f332c2f54a4d49478f9588c5cd6c57c" category="paragraph">Seguire queste istruzioni per configurare il nodo di controllo Ansible per le macchine RedHat o CentOS: <block ref="fedce547519117863322cfa54cc2ba7d" category="inline-link-macro-rx"></block>. Seguire queste istruzioni per configurare il nodo di controllo Ansible per le macchine Ubuntu o Debian: <block ref="1c50818f5fe40dbc8b2e05138d554fa4" category="inline-link-macro-rx"></block>.</block>
  <block id="d5316785c089f90464e8e683aadd02e1" category="inline-link-macro">Successivo: Cloud pubblico.</block>
  <block id="d09f79a080b121cb1acc181711b5d02a" category="paragraph"><block ref="d09f79a080b121cb1acc181711b5d02a" category="inline-link-macro-rx"></block></block>
  <block id="4db58285a0e634acd6843c40f7a6f4e0" category="paragraph">Per ulteriori informazioni sulle informazioni descritte in questo documento, fare riferimento ai seguenti collegamenti Web:</block>
  <block id="d53a72004974ee8431ee292856c0bba3" category="list-text">Architetture di soluzioni che utilizzano Azure NetApp Files</block>
  <block id="653ba0610595f0695c3ceb2c59afed59" category="inline-link"><block ref="653ba0610595f0695c3ceb2c59afed59" category="inline-link-rx"></block></block>
  <block id="d5ec9321fb49816034de6b296ef6baa2" category="paragraph"><block ref="d5ec9321fb49816034de6b296ef6baa2" category="inline-link-rx"></block></block>
  <block id="ba110408cece764b57b56f1129b3ba2e" category="list-text">Vantaggi dell'utilizzo di Azure NetApp Files per la distribuzione di SQL Server</block>
  <block id="62b5dbc436fc2540c46476bd8e484c11" category="inline-link"><block ref="62b5dbc436fc2540c46476bd8e484c11" category="inline-link-rx"></block></block>
  <block id="44594562b4f528fe8d864bd3f48ddff6" category="paragraph"><block ref="44594562b4f528fe8d864bd3f48ddff6" category="inline-link-rx"></block></block>
  <block id="7aa91f5f0414f1488ce2f5324e63d12e" category="list-text">Guida alla distribuzione di SQL Server su Azure con Azure NetApp Files</block>
  <block id="9021ea474df74856b145a78c58c35e05" category="inline-link"><block ref="9021ea474df74856b145a78c58c35e05" category="inline-link-rx"></block></block>
  <block id="52a5313d9aca117b5d167e6be79c5bc7" category="paragraph"><block ref="52a5313d9aca117b5d167e6be79c5bc7" category="inline-link-rx"></block></block>
  <block id="49217b0d4a68c88899c93d24203a34b4" category="list-text">Tolleranza agli errori, alta disponibilità e resilienza con Azure NetApp Files</block>
  <block id="9e5e063336d276080a054861016aadd8" category="inline-link"><block ref="9e5e063336d276080a054861016aadd8" category="inline-link-rx"></block></block>
  <block id="7ff89d0ad939652d37cbab9b6f420f65" category="paragraph"><block ref="7ff89d0ad939652d37cbab9b6f420f65" category="inline-link-rx"></block></block>
  <block id="d4c96dcd516adf0c5bde093b0b7b7255" category="summary">In questa pagina viene descritto il metodo automatizzato per l'implementazione di Oracle19c sullo storage NetApp ONTAP.</block>
  <block id="d798c6a829fee4b3d8316144e8769e91" category="paragraph">Le organizzazioni stanno automatizzando i propri ambienti per ottenere efficienze, accelerare le implementazioni e ridurre l'impegno manuale. I tool di gestione della configurazione come Ansible vengono utilizzati per ottimizzare le operazioni dei database aziendali. In questa soluzione, dimostreremo come utilizzare Ansible per automatizzare la protezione dei dati di Oracle con NetApp ONTAP. Consentendo agli amministratori dello storage, agli amministratori di sistema e ai DBA di configurare in modo rapido e coerente la replica dei dati in un data center offsite o nel cloud pubblico, otterrete i seguenti vantaggi:</block>
  <block id="5291cb8e681983247b899ce2364188f2" category="list-text">Elimina le complessità di progettazione e gli errori umani e implementa un'implementazione coerente e ripetibile e Best practice</block>
  <block id="1d4694b7ed077df8b2c51d4ef956ce0c" category="list-text">Riduzione dei tempi di configurazione della replica Intercluster, dell'istanza CVO e del ripristino dei database Oracle</block>
  <block id="a54e59b6b063d8a2bf18acffab877d09" category="list-text">Aumenta la produttività di amministratori di database, sistemi e amministratori dello storage</block>
  <block id="60bcf8682ddc3583a74e6cd2d95e1ccb" category="list-text">Fornisce un workflow di recovery del database per semplificare il test di uno scenario di DR.</block>
  <block id="7d85c5a5f016aefeda6b89687f1307bb" category="paragraph">NetApp offre ai clienti i moduli e i ruoli Ansible validati per accelerare l'implementazione, la configurazione e la gestione del ciclo di vita del tuo ambiente di database Oracle. Questa soluzione fornisce istruzioni e codice del playbook Ansible per aiutarti a:</block>
  <block id="7fa4d3428dbef9829f6325b288c071bc" category="section-title">On Prem to on premise Replication</block>
  <block id="911a9e8dd85bfeeba31c1ed049e41e1c" category="list-text">Creare Lifs di intercluster su origine e destinazione</block>
  <block id="2f4eb56dd9301fc33f559b4345b90eb3" category="list-text">Stabilire il peering di cluster e vserver</block>
  <block id="2b71f4136dce37491ef0f319f5d1fbd9" category="list-text">Creare e inizializzare SnapMirror dei volumi Oracle</block>
  <block id="20f4a46f5b12b0533f7a2268c4c2bf41" category="list-text">Creare una pianificazione di replica tramite AWX/Tower per file binari, database e registri Oracle</block>
  <block id="6ef1c2ae7c9ca61a54d88de28349a772" category="list-text">Ripristinare Oracle DB sulla destinazione e portare il database online</block>
  <block id="f4ec61d9ffa147f621f854609523a0fb" category="section-title">On Prem to CVO in AWS</block>
  <block id="3f155aa6a9345b3e25f3bb44ecccfc0a" category="list-text">Creare AWS Connector</block>
  <block id="1531cb3c2d4db27dcd3bfa2ad4711ec5" category="list-text">Creare un'istanza CVO in AWS</block>
  <block id="2f159b717f78e9925b219e87cbd20f9a" category="list-text">Aggiungere il cluster on-premise a Cloud Manager</block>
  <block id="df16a1e23dbbcc2f19f07ab1af741617" category="list-text">Creazione di lifs tra cluster sull'origine</block>
  <block id="950496934d91d07bb089d6ed0999b5a9" category="paragraph">Per ulteriori dettagli o per iniziare, consulta i video di panoramica riportati di seguito.</block>
  <block id="b923f56ad2a53fa1a3ca1160e48f141e" category="section-title">Implementazioni AWX/tower</block>
  <block id="d1f660bb2bff2f31a46c751115155999" category="list-text">Parte 1: Da definire</block>
  <block id="1ee2253d8fe666dbea54ab3648a62511" category="list-text">Parte 2: Da definire</block>
  <block id="68eff5f8d34b801d40ab55f098bc6478" category="inline-link-macro">qui per iniziare con la soluzione</block>
  <block id="e5dec240e8be4a30564a7e8ddc0d568a" category="list-text">Una volta pronti, fare clic su <block ref="a171481e1cde5211da297c03090cb7ce" category="inline-link-macro-rx"></block>.</block>
  <block id="a2810b66f557bf43f1c602ecfe7f52b1" category="summary">Il presente documento illustra un'implementazione in tempo reale di SQL Server Always on Availability Group (AOAG) su Azure NetApp Files sfruttando le macchine virtuali Azure.</block>
  <block id="0ecccb1d48727b6da357728efe7b6375" category="doc">TR-4897: SQL Server su Azure NetApp Files - Vista di implementazione reale</block>
  <block id="4eae423bbc6520b4a8fa4d0d4de28b8a" category="paragraph">Niyaz Mohamed, NetApp</block>
  <block id="8ae2b9aab28b6c00df7581f99f9211ef" category="paragraph">Le organizzazioni IT devono affrontare cambiamenti costanti. Secondo Gartner, entro il 2022 quasi il 75% di tutti i database richiederà uno storage basato sul cloud. In qualità di sistema di gestione di database relazionali leader del settore (RDBMS), Microsoft SQL Server è la scelta ideale per le applicazioni e le organizzazioni progettate per la piattaforma Windows che si affidano a SQL Server per qualsiasi cosa, dalla pianificazione delle risorse aziendali (ERP) all'analisi dei dati alla gestione dei contenuti. SQL Server ha contribuito a rivoluzionare il modo in cui le aziende gestiscono enormi set di dati e potenziano le loro applicazioni per soddisfare le esigenze di performance di query e schema.</block>
  <block id="eae371fd2d593d80849fab02c4e8b90b" category="paragraph">La maggior parte delle organizzazioni IT adotta un approccio basato sul cloud. I clienti in una fase di trasformazione valutano il loro attuale panorama IT e quindi migrano i workload dei database nel cloud in base a un esercizio di valutazione e scoperta. Alcuni fattori che spingono i clienti verso la migrazione del cloud includono flessibilità/burst, uscita dal data center, consolidamento del data center, scenari di fine ciclo di vita, fusioni, acquisizioni e così via. Il motivo della migrazione può variare in base a ciascuna organizzazione e alle rispettive priorità di business. Quando si passa al cloud, la scelta dello storage cloud giusto è molto importante per liberare la potenza dell'implementazione del cloud di database SQL Server.</block>
  <block id="f9468c81b3d59ac0030570c4f58e95f1" category="section-title">Caso d'utilizzo</block>
  <block id="cf8b0bda1e058c1f8383f434c4da9b71" category="paragraph">Lo spostamento di SQL Server in Azure e l'integrazione di SQL Server con la vasta gamma di funzionalità Platform-as-a-Service (PaaS) di Azure, come Azure Data Factory, Azure IoT Hub e Azure Machine Learning, creano un enorme valore di business per supportare la trasformazione digitale. L'adozione del cloud consente inoltre alla rispettiva business unit di concentrarsi sulla produttività e di offrire nuove funzionalità e miglioramenti più rapidamente (caso d'utilizzo DevTest) rispetto al modello CAPEX o ai modelli di cloud privato tradizionali. Il presente documento illustra un'implementazione in tempo reale di SQL Server Always on Availability Group (AOAG) su Azure NetApp Files sfruttando le macchine virtuali Azure.</block>
  <block id="239a02aaaf9289a3093f682835f65f88" category="paragraph">Azure NetApp Files offre storage di livello Enterprise con condivisioni di file continuamente disponibili. Le condivisioni continuamente disponibili sono richieste dai database di produzione di SQL Server sulla condivisione file SMB per garantire che il nodo abbia sempre accesso allo storage del database, anche durante scenari di interruzione come aggiornamenti o guasti del controller. Le condivisioni di file continuamente disponibili eliminano la necessità di replicare i dati tra nodi di storage. Azure NetApp Files utilizza lo scale-out SMB 3.0, gli handle persistenti e il failover trasparente per supportare operazioni senza interruzioni (NDOS) per eventi di downtime pianificati e non pianificati, incluse molte attività amministrative.</block>
  <block id="f47a858d79de9725a0d6881541748e9b" category="paragraph">Quando pianifichi le migrazioni nel cloud, dovresti sempre valutare l'approccio migliore da utilizzare. L'approccio più comune e semplice per la migrazione delle applicazioni è il rehosting (noto anche come Lift and Shift). Lo scenario di esempio fornito in questo documento utilizza il metodo di rehosting. SQL Server su macchine virtuali Azure con Azure NetApp Files consente di utilizzare versioni complete di SQL Server nel cloud senza dover gestire l'hardware on-premise. Le macchine virtuali (VM) di SQL Server semplificano inoltre i costi di licenza quando si paga a consumo e forniscono funzionalità di flessibilità e bursting per scenari di sviluppo, test e refresh delle proprietà.</block>
  <block id="f3b25b37995dab3a1b6c753dd74ca21e" category="summary">Questa sezione fornisce informazioni dettagliate sulla gestione dei database AWS RDS Custom per Oracle tramite l'interfaccia utente di SnapCenter come integrazione dell'interfaccia utente della console RDS di AWS.</block>
  <block id="d0dfaca5f0573d672a0f4dc66997c002" category="doc">Gestione dei database Oracle EC2 e FSX</block>
  <block id="39ebdf3133bce223758100b117a98e70" category="inline-link-macro">Precedente: Procedure di implementazione.</block>
  <block id="cac2d984db56d4f9cd9b1f85b3cf0c5c" category="paragraph"><block ref="cac2d984db56d4f9cd9b1f85b3cf0c5c" category="inline-link-macro-rx"></block></block>
  <block id="cf8b301cbf8aa698c578ff1f8e64ccc2" category="paragraph">Oltre alla console di gestione AWS EC2 e FSX, il nodo di controllo Ansible e lo strumento dell'interfaccia utente SnapCenter vengono implementati per la gestione del database in questo ambiente Oracle.</block>
  <block id="ab1b9a020f08729c00ecee14e5a3be69" category="paragraph">È possibile utilizzare un nodo di controllo Ansible per gestire la configurazione dell'ambiente Oracle, con aggiornamenti paralleli che mantengono sincronizzate le istanze primarie e di standby per gli aggiornamenti del kernel o delle patch. Failover, risincronizzazione e failback possono essere automatizzati con NetApp Automation Toolkit per archiviare la disponibilità e il ripristino rapido delle applicazioni con Ansible. Alcune attività di gestione del database ripetibili possono essere eseguite utilizzando un manuale per ridurre gli errori umani.</block>
  <block id="53bd53a68bce8fe697a7455feae3861b" category="inline-link-macro">Panoramica del plug-in SnapCenter per database Oracle</block>
  <block id="8dad283458f149f04a674f7c674818ed" category="paragraph">Il tool UI di SnapCenter consente di eseguire backup snapshot del database, recovery point-in-time, cloning del database e così via con il plug-in SnapCenter per database Oracle. Per ulteriori informazioni sulle funzionalità dei plug-in Oracle, vedere <block ref="053f091ffb001fc31a47d30bc3d11350" category="inline-link-macro-rx"></block>.</block>
  <block id="c165a519b858dc997da23262308d6463" category="paragraph">Le seguenti sezioni forniscono informazioni dettagliate su come le funzioni chiave della gestione del database Oracle vengono soddisfatte con l'interfaccia utente di SnapCenter:</block>
  <block id="95154aa7c50b812d3683b6995bed8771" category="list-text">Backup di snapshot del database</block>
  <block id="b055b8a9cd44d5f8e1fa330c20aa1dc3" category="list-text">Ripristino point-in-time del database</block>
  <block id="20f913ca57379280e5f37dce9cd0de61" category="list-text">Creazione di un clone del database</block>
  <block id="e724243c3ef9e2c58168b76f3f537412" category="paragraph">Il cloning del database crea una replica di un database primario su un host EC2 separato per il ripristino dei dati in caso di errore logico o danneggiamento dei dati e i cloni possono essere utilizzati anche per il test delle applicazioni, il debug, la convalida delle patch e così via.</block>
  <block id="418768c00fe9ab38a23d8417250d676b" category="section-title">Acquisizione di un'istantanea</block>
  <block id="c018c634b9245f8522eaf32d3fffaa7a" category="paragraph">Il backup di un database Oracle EC2/FSX viene eseguito regolarmente a intervalli configurati dall'utente. Un utente può anche eseguire un backup snapshot singolo in qualsiasi momento. Ciò vale sia per i backup snapshot completi del database che per i backup snapshot con solo log di archivio.</block>
  <block id="0a1758b0d7a64bf446ccd6c9ea2a559d" category="section-title">Acquisizione di un'istantanea completa del database</block>
  <block id="6aa82df330acc0ad1c1859bf7d19d8c6" category="paragraph">Un'istantanea completa del database include tutti i file Oracle, inclusi i file di dati, i file di controllo e i file di log dell'archivio.</block>
  <block id="71a81fc61b4bde806ab23dbb0dff87ab" category="list-text">Accedere all'interfaccia utente di SnapCenter e fare clic su risorse nel menu a sinistra. Dal menu a discesa View (Visualizza), passare alla vista Resource Group (Gruppo di risorse).</block>
  <block id="097f9e0f1d7d03a8b8db3110da618df1" category="paragraph"><block ref="097f9e0f1d7d03a8b8db3110da618df1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a16fe4e102f4f80c9a0ebe875e00921" category="list-text">Fare clic sul nome completo della risorsa di backup, quindi fare clic sull'icona Backup Now per avviare un backup add-hoc.</block>
  <block id="b157c6d0dbf1f6fc8e66e048cdf587dc" category="paragraph"><block ref="b157c6d0dbf1f6fc8e66e048cdf587dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c41836f211ec5f0aee4024039682c6d3" category="list-text">Fare clic su Backup, quindi confermare il backup per avviare un backup completo del database.</block>
  <block id="de38ecf82e29f57be2cb258095500ffc" category="paragraph"><block ref="de38ecf82e29f57be2cb258095500ffc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5114009902f821226811cd39b519e8ae" category="paragraph">Dalla visualizzazione delle risorse del database, aprire la pagina delle copie di backup gestite del database per verificare che il backup singolo sia stato completato correttamente. Un backup completo del database crea due snapshot: Una per il volume di dati e una per il volume di log.</block>
  <block id="23c2c3d9fc4ea06c4f1744caa77dd75f" category="paragraph"><block ref="23c2c3d9fc4ea06c4f1744caa77dd75f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc2bc8e691b80fc2b94cd487cd59a41e" category="section-title">Acquisizione di un'istantanea del log di archiviazione</block>
  <block id="c2a2cc866aaa30cb6344e65c853429a7" category="paragraph">Viene eseguita una snapshot del log di archiviazione solo per il volume del log di archiviazione Oracle.</block>
  <block id="973f07a93ca1636baa391407a84cb38b" category="list-text">Accedere all'interfaccia utente di SnapCenter e fare clic sulla scheda risorse nella barra dei menu a sinistra. Dal menu a discesa View (Visualizza), passare alla vista Resource Group (Gruppo di risorse).</block>
  <block id="47f0395291ce13022063147f4981f69f" category="list-text">Fare clic sul nome della risorsa di backup del registro, quindi fare clic sull'icona Backup Now per avviare un backup add-hoc per i registri di archiviazione.</block>
  <block id="1417f1fbdcb104994815efb345497300" category="paragraph"><block ref="1417f1fbdcb104994815efb345497300" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8ee5a2ad5f43fcd955b6b30854d2f98" category="list-text">Fare clic su Backup, quindi confermare il backup per avviare un backup del registro di archiviazione.</block>
  <block id="03cb3b3b0da0531d726d5e6b4af1920c" category="paragraph"><block ref="03cb3b3b0da0531d726d5e6b4af1920c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40cffcacb55d81916f38114aac845d4b" category="paragraph">Dalla visualizzazione delle risorse del database, aprire la pagina delle copie di backup gestite del database per verificare che il backup del registro di archiviazione una tantum sia stato completato correttamente. Un backup del registro di archiviazione crea uno snapshot per il volume di registro.</block>
  <block id="01422619a982004bea1ad1e237269525" category="paragraph"><block ref="01422619a982004bea1ad1e237269525" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e16045e122b02913b74ef1e8bd29d75c" category="section-title">Ripristino a un punto nel tempo</block>
  <block id="7d2260465121189e3f5aef56d1734e86" category="paragraph">Il ripristino basato su SnapCenter a un punto temporale viene eseguito sullo stesso host di istanza EC2. Per eseguire il ripristino, attenersi alla seguente procedura:</block>
  <block id="52443d446e6aa795d8e3a08e581684cb" category="list-text">Dalla scheda risorse SnapCenter &gt; visualizzazione database, fare clic sul nome del database per aprire il backup del database.</block>
  <block id="51d148134901f85184886bb72062b2a0" category="paragraph"><block ref="51d148134901f85184886bb72062b2a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bc3aa5bd0c870df97abdd69ef227826" category="list-text">Selezionare la copia di backup del database e il punto di tempo desiderato da ripristinare. Contrassegnare anche il numero SCN corrispondente al punto temporale. Il ripristino point-in-time può essere eseguito utilizzando Time o SCN.</block>
  <block id="f4a16324772958025bfa77d2ed8af61e" category="paragraph"><block ref="f4a16324772958025bfa77d2ed8af61e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acee7bbe553399023f78a7ac814d7a94" category="list-text">Evidenziare l'istantanea del volume di log e fare clic sul pulsante Mount (attiva) per montare il volume.</block>
  <block id="b068acd736c964d27b5833d30c220f7c" category="paragraph"><block ref="b068acd736c964d27b5833d30c220f7c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d06beb2a91e58c7e57367e901abc09fd" category="list-text">Scegliere l'istanza primaria di EC2 per montare il volume di log.</block>
  <block id="94bf51064baf8263a5c7e0d6dba0f38a" category="paragraph"><block ref="94bf51064baf8263a5c7e0d6dba0f38a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f83a9f884d94d22d3c52d510a051ac90" category="list-text">Verificare che il processo di montaggio sia stato completato correttamente. Controllare anche sull'host dell'istanza EC2 per vedere il volume di log montato e il percorso del punto di montaggio.</block>
  <block id="53044f6472847053eea58f6f40258b7c" category="paragraph"><block ref="01717ad5eefdb68ab0f128386310e509" category="inline-image-macro-rx" type="image"></block>
<block ref="684c418b818adf3876d8fd9877edd90f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12a7a64116d859fb64b3f841a43e6fac" category="list-text">Copiare i log di archiviazione dal volume di log montato alla directory del log di archiviazione corrente.</block>
  <block id="f57c6961965ccab84762e9b4bbdd72f0" category="list-text">Tornare alla scheda risorse SnapCenter &gt; pagina di backup del database, evidenziare la copia dello snapshot dei dati e fare clic sul pulsante Ripristina per avviare il flusso di lavoro di ripristino del database.</block>
  <block id="eb283dcbcce9c21f038d1985c87645da" category="paragraph"><block ref="eb283dcbcce9c21f038d1985c87645da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a08ce545f0f81946ee65326ff4608df" category="list-text">Selezionare "tutti i file di dati" e "Cambia stato del database se necessario per il ripristino e il ripristino", quindi fare clic su Avanti.</block>
  <block id="c53b030895e9cee782d7dfcea4a679ad" category="paragraph"><block ref="c53b030895e9cee782d7dfcea4a679ad" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e589c1295b0849053e2d8cc2bbf96a1e" category="list-text">Scegliere l'ambito di ripristino desiderato utilizzando SCN o Time. Invece di copiare i registri di archivio montati nella directory di log corrente come illustrato al punto 6, il percorso di log di archivio montato può essere elencato in "specificare le posizioni dei file di log di archivio esterni" per il ripristino.</block>
  <block id="12bfd26a9c7f1551fe3664e25975f022" category="paragraph"><block ref="12bfd26a9c7f1551fe3664e25975f022" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f3b533a6c9cd757a311b56318115bbe" category="list-text">Specificare una prescrizione facoltativa da eseguire, se necessario.</block>
  <block id="0c61f73092ad29b6a823f67f23872ffb" category="paragraph"><block ref="0c61f73092ad29b6a823f67f23872ffb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16a70e704c6e5104eff1adca9f951c36" category="list-text">Specificare un afterscript opzionale da eseguire, se necessario. Controllare il database aperto dopo il ripristino.</block>
  <block id="5e5add6f904fa1973ca9f5564c87bdab" category="paragraph"><block ref="5e5add6f904fa1973ca9f5564c87bdab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="975952869f93fd5cb45acf8a19b97834" category="list-text">Fornire un server SMTP e un indirizzo e-mail se è necessaria una notifica del processo.</block>
  <block id="125beea11cb628a2850a9c3b01628d3b" category="paragraph"><block ref="125beea11cb628a2850a9c3b01628d3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f92d4c842e7343ab2f69eac4e3561bc" category="list-text">Ripristinare il riepilogo del processo. Fare clic su Finish (fine) per avviare il processo di ripristino.</block>
  <block id="0dac703b5b68b8ce38eae7f7224a3de3" category="paragraph"><block ref="0dac703b5b68b8ce38eae7f7224a3de3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e783d4afe611873ddc32a5a59ff2078" category="list-text">Convalidare il ripristino da SnapCenter.</block>
  <block id="7cc0ed8d8b03fe709b0d004e75183201" category="paragraph"><block ref="7cc0ed8d8b03fe709b0d004e75183201" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a6e8e06b3f3e03bdb3391888df78e46" category="list-text">Convalidare il ripristino dall'host dell'istanza EC2.</block>
  <block id="06adcc9a574fcfaa717309c54d0fc7e9" category="paragraph"><block ref="06adcc9a574fcfaa717309c54d0fc7e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="983d6ea8d6962c3e0f9abef0c4c948f4" category="list-text">Per smontare il volume del registro di ripristino, eseguire le operazioni descritte al punto 4.</block>
  <block id="ca0c306ba98701576c42d241b48d4038" category="section-title">Creazione di un clone del database</block>
  <block id="a8bd304fe0995bcddba8dd93a8d447a6" category="paragraph">Nella sezione seguente viene illustrato come utilizzare il flusso di lavoro dei cloni di SnapCenter per creare un clone del database da un database primario a un'istanza EC2 di standby.</block>
  <block id="91956afde8e3bc7ac47e37b9821ca6f9" category="list-text">Eseguire un backup snapshot completo del database primario da SnapCenter utilizzando il gruppo di risorse di backup completo.</block>
  <block id="023d426483e83bc3abf204154e323eba" category="paragraph"><block ref="023d426483e83bc3abf204154e323eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b08a0a4966d6a40934f84e0367df5124" category="list-text">Dalla scheda risorse SnapCenter &gt; visualizzazione database, aprire la pagina Gestione backup database per il database principale dal quale deve essere creata la replica.</block>
  <block id="f14aaf01a42159b842a496f880063869" category="paragraph"><block ref="f14aaf01a42159b842a496f880063869" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b265d526ea8d86f13a3ee5b3df11ce5" category="list-text">Montare lo snapshot del volume di log eseguito al punto 4 sull'host di istanza EC2 di standby.</block>
  <block id="160b6f6b07db1490de7e1252e8f6ec84" category="paragraph"><block ref="074cfbf53cae79233eac44ac8a4aa5f8" category="inline-image-macro-rx" type="image"></block>
<block ref="a75c3f795382693108f8d772396f248b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="15c2865196d70f81dd791b3329d2604e" category="list-text">Evidenziare la copia snapshot da clonare per la replica e fare clic sul pulsante Clone (Copia) per avviare la procedura di cloning.</block>
  <block id="568f30b58394b2e0d4e795beb731c0eb" category="paragraph"><block ref="568f30b58394b2e0d4e795beb731c0eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ebc0e83f8e5d02518da0756a18aaab4" category="list-text">Modificare il nome della copia della replica in modo che sia diverso dal nome del database primario. Fare clic su Avanti.</block>
  <block id="b77619cc2b53d1b603e6051036b122b6" category="paragraph"><block ref="b77619cc2b53d1b603e6051036b122b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ba0975a31e144349d50f09393a5ca21" category="list-text">Impostare l'host clone sull'host EC2 di standby, accettare il nome predefinito e fare clic su Next (Avanti).</block>
  <block id="d39fd3bd4059fb775d174eef3e53919b" category="paragraph"><block ref="d39fd3bd4059fb775d174eef3e53919b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eeda8df21c3391dcc7a327cfec8f8704" category="list-text">Modificare le impostazioni home di Oracle in modo che corrispondano a quelle configurate per l'host del server Oracle di destinazione, quindi fare clic su Next (Avanti).</block>
  <block id="8cb5c7c55cf01620e1eaae0dd817ad2c" category="paragraph"><block ref="8cb5c7c55cf01620e1eaae0dd817ad2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f10b26890bad0f92387ad2c8efb9b532" category="list-text">Specificare un punto di ripristino utilizzando Time o SCN e il percorso del log di archiviazione montato.</block>
  <block id="9d2a5645a731a8a3af7ee677133ba312" category="paragraph"><block ref="9d2a5645a731a8a3af7ee677133ba312" category="inline-image-macro-rx" type="image"></block></block>
  <block id="684abeacd08eb59922d70d928ce47f45" category="list-text">Se necessario, inviare le impostazioni e-mail SMTP.</block>
  <block id="84bb684b488190f680f548303196f5b9" category="paragraph"><block ref="84bb684b488190f680f548303196f5b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2cc0c6ba26bdf7b30e39313a0ad4098" category="list-text">Clonare il riepilogo del processo e fare clic su fine per avviare il processo clone.</block>
  <block id="3461ca6663823ff26ef7d3121d8592c7" category="paragraph"><block ref="3461ca6663823ff26ef7d3121d8592c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5cd909b2ce2e22f0bb8734426ea9e9a" category="list-text">Convalidare il clone della replica esaminando il log del processo clone.</block>
  <block id="c6c9a361716f3695e5f582cbbaf857f6" category="paragraph"><block ref="c6c9a361716f3695e5f582cbbaf857f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66a858d0c53f7ecef6ff665372a428c5" category="paragraph">Il database clonato viene registrato immediatamente in SnapCenter.</block>
  <block id="8fc5846614431a858445f7c55fe6f8bf" category="paragraph"><block ref="8fc5846614431a858445f7c55fe6f8bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9b70fde27d9d03d393dc2fd619546988" category="list-text">Disattivare la modalità Oracle archive log. Accedere all'istanza EC2 come utente oracle ed eseguire il seguente comando:</block>
  <block id="ca1a9785bb111fcadc4527aae18f822d" category="admonition">Al posto delle copie di backup primarie di Oracle, è possibile creare un clone anche dalle copie di backup secondarie replicate sul cluster FSX di destinazione con le stesse procedure.</block>
  <block id="2a75f5115dab8b39875560a4d7252d2f" category="section-title">Failover HA in standby e risincronizzazione</block>
  <block id="f5bc6d05191457096f9da00e0fa56d40" category="paragraph">Il cluster Oracle ha in standby offre alta disponibilità in caso di guasto nel sito primario, nel livello di elaborazione o nello storage. Uno dei vantaggi significativi della soluzione è che un utente può testare e convalidare l'infrastruttura in qualsiasi momento o con qualsiasi frequenza. Il failover può essere simulato dall'utente o attivato da un guasto reale. I processi di failover sono identici e possono essere automatizzati per un rapido ripristino delle applicazioni.</block>
  <block id="6775249aa36196ee3d9c71774992f2c4" category="paragraph">Consultare il seguente elenco di procedure di failover:</block>
  <block id="eb171dc2d1f739dfee2e358326abd0e9" category="list-text">Per un failover simulato, eseguire un backup dello snapshot del registro per scaricare le transazioni più recenti nel sito di standby, come illustrato nella sezione <block ref="58f2fe5f16b910e6ad4f8b3f8679e256" category="inline-xref-macro-rx"></block>. Per un failover attivato da un guasto effettivo, gli ultimi dati ripristinabili vengono replicati nel sito di standby con l'ultimo backup del volume di log pianificato.</block>
  <block id="abdc57f5efdfeac30fe822d9eda2fc9f" category="list-text">Interrompere SnapMirror tra cluster FSX primario e di standby.</block>
  <block id="bd54ae4d51454c6a89990f066be03d35" category="list-text">Montare i volumi di database di standby replicati sull'host di istanza EC2 di standby.</block>
  <block id="588698147b1d63f4f9f6d78dd8d83595" category="list-text">Ricollegare il binario Oracle se il binario Oracle replicato viene utilizzato per il ripristino Oracle.</block>
  <block id="0f1ac3f743fcb2d14875c7a731c3d251" category="list-text">Ripristinare il database Oracle di standby nell'ultimo log di archiviazione disponibile.</block>
  <block id="ab933bdc7c043f4a3c977049791f0640" category="list-text">Aprire il database Oracle di standby per accedere all'applicazione e all'utente.</block>
  <block id="6928cb13e9136438c86e16b724b3b64f" category="list-text">Per un guasto effettivo del sito primario, il database Oracle di standby assume ora il ruolo del nuovo sito primario e i volumi del database possono essere utilizzati per ricostruire il sito primario guasto come nuovo sito di standby con il metodo SnapMirror inverso.</block>
  <block id="13e25eed8fa423975f854101e3be1e89" category="list-text">In caso di guasto primario simulato del sito per il test o la convalida, arrestare il database Oracle di standby dopo il completamento degli esercizi di test. Quindi, smontare i volumi di database in standby dall'host di istanza EC2 di standby e risincronizzare la replica dal sito primario al sito di standby.</block>
  <block id="c3fd0f78855e219b0fd44077ce74e7b5" category="paragraph">Queste procedure possono essere eseguite con il NetApp Automation Toolkit disponibile per il download sul sito pubblico di NetApp GitHub.</block>
  <block id="ba4d6e5d6eeea04cdc5a4f243b1e5dd8" category="paragraph">Leggere attentamente le istruzioni README prima di eseguire il test di configurazione e failover.</block>
  <block id="fefc87f11b675de356ca673f3a346ac7" category="inline-link-macro">Successivo: Migrazione del database.</block>
  <block id="8996ba3a1cc79692db90ae4be7ef8dd3" category="paragraph"><block ref="8996ba3a1cc79692db90ae4be7ef8dd3" category="inline-link-macro-rx"></block></block>
  <block id="012b603d852affe4779f095a5c59f0c5" category="summary">L'agilità del cloud pubblico, il time-to-value e i risparmi sui costi sono tutte proposte di valore significative per le aziende che adottano il cloud pubblico per lo sviluppo di applicazioni di database e le attività di test. Non esiste uno strumento migliore di SnapCenter per trasformare questo in realtà in una situazione di fretta. SnapCenter non solo può proteggere il database di produzione on-premise, ma può anche clonare rapidamente una copia per lo sviluppo di applicazioni o il test del codice nel cloud pubblico, consumando pochissimo spazio di storage aggiuntivo. Di seguito sono riportati i dettagli dei processi passo-passo che utilizzano lo strumento.</block>
  <block id="38da6679588aeb2754e14dd58994685e" category="doc">Workflow per sviluppo/test bursting nel cloud</block>
  <block id="5b9681a3caf5db6230c17718122074d3" category="inline-link-macro">Precedente: Introduzione al cloud pubblico AWS.</block>
  <block id="e9e59a2a982f81f5f964248f351b2446" category="paragraph"><block ref="e9e59a2a982f81f5f964248f351b2446" category="inline-link-macro-rx"></block></block>
  <block id="4d8a5b6bc9c43ab79e376d1aa4d83217" category="paragraph">L'agilità del cloud pubblico, il time-to-value e i risparmi sui costi sono tutte proposte di valore significative per le aziende che adottano il cloud pubblico per lo sviluppo e il test delle applicazioni di database. Non esiste uno strumento migliore di SnapCenter per trasformare questo in realtà. SnapCenter non solo può proteggere il database di produzione on-premise, ma può anche clonare rapidamente una copia per lo sviluppo di applicazioni o il test del codice nel cloud pubblico, consumando pochissimo storage aggiuntivo. Di seguito sono riportati i dettagli dei processi passo-passo per l'utilizzo di questo strumento.</block>
  <block id="b47b42841be2e173707ab5884714970b" category="section-title">Clonare un database Oracle per lo sviluppo/test da un backup di snapshot replicato</block>
  <block id="8d90529d1117b8d3781bd6781acf4e91" category="list-text">Accedere a SnapCenter con un ID utente per la gestione del database per Oracle. Accedere alla scheda risorse, che mostra i database Oracle protetti da SnapCenter.</block>
  <block id="a95ff2a2ae2905b0bb3bd0efa211a040" category="paragraph"><block ref="a95ff2a2ae2905b0bb3bd0efa211a040" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d539d2e9659870aa79747206fac4769" category="list-text">Fare clic sul nome del database on-premise desiderato per la topologia di backup e la vista dettagliata. Se è attivata una posizione replicata secondaria, vengono visualizzati i backup mirror collegati.</block>
  <block id="20111f4a74a9c065157aa13379000a73" category="paragraph"><block ref="20111f4a74a9c065157aa13379000a73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4a9c1f33e524696d6f3adebf89947bb" category="list-text">Per passare alla vista dei backup mirrorati, fare clic su Backup mirrorati. Vengono quindi visualizzati i backup dei mirror secondari.</block>
  <block id="e1cbaea95bcc154ccf9e8aece7fc73b3" category="paragraph"><block ref="e1cbaea95bcc154ccf9e8aece7fc73b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4726a244c3941457e8f62b49c83d35d1" category="list-text">Scegliere una copia di backup del database secondario mirrorata da clonare e determinare un punto di ripristino in base all'ora e al numero di modifica del sistema o in base alla SCN. In genere, il punto di ripristino deve essere sottoposto a un periodo di tempo inferiore rispetto al tempo di backup completo del database o alla data SCN da clonare. Dopo aver deciso un punto di ripristino, il backup del file di registro richiesto deve essere montato per il ripristino. Il backup del file di log deve essere montato sul server DB di destinazione in cui deve essere ospitato il database clone.</block>
  <block id="81d132cd1ae26e007bb608e5f8609288" category="paragraph"><block ref="81d132cd1ae26e007bb608e5f8609288" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2dc441031605bf54d78fde13b3efc3c" category="paragraph"><block ref="b2dc441031605bf54d78fde13b3efc3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22a17e5abcfc4b5e70ebdea098cd1891" category="admonition">Se la funzione di eliminazione dei log è attivata e il punto di ripristino viene esteso oltre l'ultima eliminazione dei log, potrebbe essere necessario montare più backup dei log di archiviazione.</block>
  <block id="e9606676533bbe916f4b4b6824eac195" category="list-text">Evidenziare la copia di backup completa del database da clonare, quindi fare clic sul pulsante clone per avviare il flusso di lavoro del clone del database.</block>
  <block id="48493c19ee97a291cd320501daf5c721" category="paragraph"><block ref="48493c19ee97a291cd320501daf5c721" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c06d82b497809fcc0fd06d00c6d91a5" category="list-text">Scegliere un SID DB clone appropriato per un database container completo o un clone CDB.</block>
  <block id="f6ee6a459784097119ec1eee6224152e" category="paragraph"><block ref="f6ee6a459784097119ec1eee6224152e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2c50a030b1c5313fca09568edf8c0f9" category="list-text">Selezionare l'host clone di destinazione nel cloud e le directory del file di dati, del file di controllo e del log di ripristino vengono create dal flusso di lavoro del clone.</block>
  <block id="323554a005f5e77dfaa765ea81e645be" category="paragraph"><block ref="323554a005f5e77dfaa765ea81e645be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="701f017aeafb71656cf2bc3a9bd34862" category="list-text">Il nome della credenziale Nessuno viene utilizzato per l'autenticazione basata sul sistema operativo, rendendo la porta del database irrilevante. Compilare i campi Oracle Home, Oracle OS User e Oracle OS Group appropriati, come configurati nel server DB clone di destinazione.</block>
  <block id="c5237b674d4a9cd38d44c5e546cc51d4" category="paragraph"><block ref="c5237b674d4a9cd38d44c5e546cc51d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26a911f3c85fc3c73d79253e65bf30e3" category="list-text">Specificare gli script da eseguire prima dell'operazione di clonazione. Cosa ancora più importante, il parametro dell'istanza del database può essere modificato o definito qui.</block>
  <block id="56774e452bc62021e52de3e3fea844a2" category="paragraph"><block ref="56774e452bc62021e52de3e3fea844a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09d7240367714707474d63a3a574222b" category="list-text">Specificare il punto di ripristino in base alla data e all'ora o alla SCN. Fino a quando Annulla ripristina il database fino ai log di archiviazione disponibili. Specificare la posizione del log di archiviazione esterno dall'host di destinazione in cui è montato il volume del log di archiviazione. Se il proprietario del server di destinazione Oracle è diverso dal server di produzione on-premise, verificare che la directory del log di archiviazione sia leggibile dal proprietario del server di destinazione Oracle.</block>
  <block id="6cb86841376102e5b8924f9909b8f570" category="paragraph"><block ref="6cb86841376102e5b8924f9909b8f570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70b171a9c984de6358afb3557fe84586" category="paragraph"><block ref="70b171a9c984de6358afb3557fe84586" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a752afaf144d06159ca3eec8bb23455f" category="list-text">Configurare il server SMTP per la notifica via email, se lo si desidera.</block>
  <block id="b30b70196320d22207ea0d5d95d2c841" category="paragraph"><block ref="b30b70196320d22207ea0d5d95d2c841" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0421be6f676ac1ddace9e39eeeb54f0f" category="list-text">Riepilogo dei cloni.</block>
  <block id="a930a442bf914f516109fbb28bf2fbd1" category="paragraph"><block ref="a930a442bf914f516109fbb28bf2fbd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69d929881b22cd699e243e2343bd707d" category="list-text">Dopo il cloning, è necessario eseguire la convalida per assicurarsi che il database clonato sia operativo. Alcune attività aggiuntive, come l'avvio del listener o la disattivazione della modalità di archiviazione del registro DB, possono essere eseguite sul database di sviluppo/test.</block>
  <block id="9991775de6f914e5a41601ba523e3193" category="paragraph"><block ref="9991775de6f914e5a41601ba523e3193" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58732c8d9b1293bb6666ef2284840fd3" category="section-title">Clonare un database SQL per lo sviluppo/test da un backup Snapshot replicato</block>
  <block id="605f2bb9d099f78e26260848db117df7" category="list-text">Accedere a SnapCenter con un ID utente per la gestione del database per SQL Server. Accedere alla scheda risorse, che mostra i database degli utenti SQL Server protetti da SnapCenter e un'istanza SQL di standby di destinazione nel cloud pubblico.</block>
  <block id="d238acd8e02d4df70c9b55828a4b8801" category="paragraph"><block ref="d238acd8e02d4df70c9b55828a4b8801" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39c34a717e197c67b1fc8d678db5815b" category="list-text">Fare clic sul nome del database utente SQL Server on-premise desiderato per la topologia dei backup e la vista dettagliata. Se è attivata una posizione replicata secondaria, vengono visualizzati i backup mirror collegati.</block>
  <block id="8c57a9d29ca9640330e03e6edca2b6e5" category="paragraph"><block ref="8c57a9d29ca9640330e03e6edca2b6e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a5910fa5df5b6482c00b15ae683eef0f" category="list-text">Passare alla vista dei backup mirrorati facendo clic su Backup mirrorati. Vengono quindi visualizzati i backup mirror secondari. Poiché SnapCenter esegue il backup del log delle transazioni di SQL Server su un'unità dedicata per il ripristino, vengono visualizzati solo i backup completi del database.</block>
  <block id="f8d3ed6786c765a87cec8464a574076a" category="paragraph"><block ref="f8d3ed6786c765a87cec8464a574076a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="368014bae8201ab49d2207a53c907069" category="list-text">Scegliere una copia di backup, quindi fare clic sul pulsante Clone (Copia) per avviare il flusso di lavoro Clone from Backup (Copia da backup).</block>
  <block id="87dbbaf733c71b9d4e0027ad4a85e709" category="paragraph"><block ref="87dbbaf733c71b9d4e0027ad4a85e709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75c22c861d423e3f3450da18d56f0599" category="paragraph"><block ref="75c22c861d423e3f3450da18d56f0599" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44258030a87117191bde6d62511ddb9a" category="list-text">Selezionare un server cloud come server clone di destinazione, nome istanza clone e nome database clone. Scegliere un punto di montaggio ad assegnazione automatica o un percorso del punto di montaggio definito dall'utente.</block>
  <block id="7841eed97c9a860bcb6a46b08ea08c11" category="paragraph"><block ref="7841eed97c9a860bcb6a46b08ea08c11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18145dc97ae06034ae9aafa8b98cb36e" category="list-text">Determinare un punto di ripristino in base all'ora di backup del registro o a una data e un'ora specifiche.</block>
  <block id="b2798123b4d42e447362355b510a424c" category="paragraph"><block ref="b2798123b4d42e447362355b510a424c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b9becceddf802cada91d9e2aa84ac5a" category="list-text">Specificare gli script opzionali da eseguire prima e dopo l'operazione di cloning.</block>
  <block id="adee0219db450497bd0f545df8d862c7" category="paragraph"><block ref="adee0219db450497bd0f545df8d862c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e41b01ffd717fd3d0b5788e608e50b52" category="list-text">Configurare un server SMTP se si desidera inviare una notifica via email.</block>
  <block id="9b758c550d5da3ecb44f04ae804293d4" category="paragraph"><block ref="9b758c550d5da3ecb44f04ae804293d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc89ae2ec0203249b8e60785a63ca258" category="list-text">Riepilogo dei cloni.</block>
  <block id="ab74d2d908acf5c3e01544cd4b871b73" category="paragraph"><block ref="ab74d2d908acf5c3e01544cd4b871b73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28725828580a55d904e8b2a39f377eb9" category="list-text">Monitorare lo stato del processo e verificare che il database utente desiderato sia stato collegato a un'istanza SQL di destinazione nel server clone cloud.</block>
  <block id="766259946fc034002a24d5f23655c73e" category="paragraph"><block ref="766259946fc034002a24d5f23655c73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d512bf68b17268adfe539f9722d869b4" category="section-title">Configurazione post-clone</block>
  <block id="50d9180ea26c89fbe6506d71d81d3fb1" category="list-text">Un database di produzione Oracle on-premise viene in genere eseguito in modalità di archiviazione dei log. Questa modalità non è necessaria per un database di sviluppo o test. Per disattivare la modalità di archiviazione dei log, accedere a Oracle DB come sysdba, eseguire un comando di modifica della modalità di log e avviare il database per l'accesso.</block>
  <block id="b205237d51ff9525496f4b2252942213" category="list-text">Configurare un listener Oracle o registrare il database appena clonato con un listener esistente per l'accesso dell'utente.</block>
  <block id="800699a04cdaa75b2219988799b0a048" category="list-text">Per SQL Server, modificare la modalità di log da Full a Easy in modo che il file di log di sviluppo/test di SQL Server possa essere facilmente ridotto quando si riempie il volume di log.</block>
  <block id="89e018d207fd292a4926870904035c18" category="section-title">Aggiornare il database dei cloni</block>
  <block id="d84550ba9a340ebf4fa6698dff5ba344" category="list-text">Eliminare i database clonati e ripulire l'ambiente del server DB cloud. Seguire quindi le procedure precedenti per clonare un nuovo database con nuovi dati. La clonazione di un nuovo database richiede solo pochi minuti.</block>
  <block id="1170d6f09309cb8dc382034a34680937" category="inline-link-macro">Aggiornare un clone</block>
  <block id="fef062eeb7771b01e620bb2460b1bf9a" category="list-text">Chiudere il database dei cloni, eseguire un comando di refresh dei cloni utilizzando la CLI. Per ulteriori informazioni, consultare la seguente documentazione SnapCenter: <block ref="1e4035dee07650c706f8f0714c384872" category="inline-link-macro-rx"></block>.</block>
  <block id="52320018ddc230fda7bdeccfda8b9f0a" category="section-title">Dove cercare aiuto?</block>
  <block id="2d6962c20ba37b34437afc30e6838e0d" category="inline-link-macro">La community di NetApp Solution Automation supporta il canale slack</block>
  <block id="7b88d7d11804db6b079e226a6f043ea7" category="paragraph">Se hai bisogno di aiuto per questa soluzione e per i casi d'utilizzo, partecipa a. <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> e cerca il canale di automazione della soluzione per inviare domande o domande.</block>
  <block id="e2a76301a4117f21d6192304aa650018" category="inline-link-macro">Successivo: Workflow di disaster recovery.</block>
  <block id="28a87ee64d4675e6c24cd960fe71d9bf" category="paragraph"><block ref="28a87ee64d4675e6c24cd960fe71d9bf" category="inline-link-macro-rx"></block></block>
  <block id="0f22160e43c900ef7426d8a19e9f482d" category="summary">Alcuni prerequisiti devono essere configurati sia on-premise che nel cloud prima dell'esecuzione dei carichi di lavoro del database del cloud ibrido. La sezione seguente fornisce un riepilogo generale di questo processo e i seguenti collegamenti forniscono ulteriori informazioni sulla configurazione di sistema necessaria.</block>
  <block id="1dad826770c4d2c619351c974f725b36" category="doc">Configurazione dei prerequisiti</block>
  <block id="ce38f65c711e7e3047c9350abe42c0c3" category="inline-link-macro">Precedente: Requisiti delle soluzioni.</block>
  <block id="d3fe0eebddd46d46399cb319c7219427" category="paragraph"><block ref="d3fe0eebddd46d46399cb319c7219427" category="inline-link-macro-rx"></block></block>
  <block id="4df40e141b0559f15db8f84f78aed013" category="section-title">On-premise</block>
  <block id="761883c0d5c55fba5b200ac8ac0d86e5" category="section-title">Cloud pubblico</block>
  <block id="1e094e6477be231098329b0096c7221f" category="list-text">Accesso a NetApp Cloud Central</block>
  <block id="b59e275c4ece2430dff67db92845ab7f" category="list-text">Accesso alla rete da un browser Web a diversi endpoint</block>
  <block id="37aa83a33297d9d16b4423be342598bb" category="list-text">Percorso di rete per un connettore</block>
  <block id="0d07862d67097acd517fe27c0de099d7" category="list-text">Permessi del cloud provider</block>
  <block id="203802866ac2835e79bd76c94a3761c2" category="list-text">Networking per singoli servizi</block>
  <block id="74c043a4451dd260729a23ce96aa1550" category="paragraph">Considerazioni importanti:</block>
  <block id="7aee27c83b5e3622c1d8cbd5c2098c60" category="list-text">Dove implementare Cloud Manager Connector?</block>
  <block id="43fd5c6fa3d9ba8a215c31f3bf0a9859" category="list-text">Dimensionamento e architettura di Cloud Volume ONTAP</block>
  <block id="7a0e00d70e3b0ff06476a52565f923c4" category="list-text">Nodo singolo o alta disponibilità?</block>
  <block id="2d0b46fff3ae203a435b167c7111b389" category="paragraph">I seguenti link forniscono ulteriori dettagli:</block>
  <block id="7146594a919f2b006b1b0911c7b6d7da" category="inline-link-macro">On-premise</block>
  <block id="cfd98f49422c4fba755a2ff74c55a4a0" category="paragraph"><block ref="cfd98f49422c4fba755a2ff74c55a4a0" category="inline-link-macro-rx"></block></block>
  <block id="704849d56e695ab8f9df0b106e0d7e33" category="inline-link-macro">Cloud pubblico</block>
  <block id="96e41b2b281ca4b71edf4ed16e46a2be" category="paragraph"><block ref="96e41b2b281ca4b71edf4ed16e46a2be" category="inline-link-macro-rx"></block></block>
  <block id="7c12725837ee75c4c0a9bbc14f99934d" category="inline-link-macro">Successivo: Prerequisiti on-premise.</block>
  <block id="bc57dd30a9059d494c9d76e4b0a9ce8f" category="paragraph"><block ref="bc57dd30a9059d494c9d76e4b0a9ce8f" category="inline-link-macro-rx"></block></block>
  <block id="9ce6d30135c2644ff34390c65af4061b" category="paragraph">Le organizzazioni stanno automatizzando i propri ambienti per ottenere efficienze, accelerare le implementazioni e ridurre l'impegno manuale. I tool di gestione della configurazione come Ansible vengono utilizzati per ottimizzare le operazioni dei database aziendali. In questa soluzione, dimostreremo come utilizzare Ansible per automatizzare il provisioning e la configurazione di Oracle 19c con NetApp ONTAP. Consentendo agli amministratori dello storage, agli amministratori di sistema e ai DBA di implementare in modo coerente e rapido nuovo storage, configurare server di database e installare il software Oracle 19c, otterrete i seguenti vantaggi:</block>
  <block id="a90516bf4597e04e1a97bd9cb37087d8" category="list-text">Riduzione dei tempi di provisioning dello storage, configurazione degli host DB e installazione di Oracle</block>
  <block id="d18d76441366273feb36bde890ad5e1c" category="list-text">Scalabilità di storage e database con facilità</block>
  <block id="547b893b7cd300d6a8335f5b179ad12e" category="list-text">Creare e configurare lo storage NFS ONTAP per il database Oracle</block>
  <block id="36bb01ec9f02292fb44b9f10f57ceae7" category="list-text">Installare Oracle 19c su RedHat Enterprise Linux 7/8 o Oracle Linux 7/8</block>
  <block id="548bf87c41c9d3bb76981decbd599c90" category="list-text">Configurare Oracle 19c sullo storage NFS ONTAP</block>
  <block id="ab81e47672e89830ec16c581f44cb23c" category="list-text">Parte 1: Introduzione, requisiti, dettagli di automazione e configurazione iniziale AWX/Tower</block>
  <block id="cf7bbd18f18fdc73ee49ffea888126c7" category="list-text">Parte 2: Variabili ed esecuzione del Playbook</block>
  <block id="f5e227cfa54c5693c512c6adf41a3772" category="section-title">Implementazione della CLI</block>
  <block id="0b8a09b5974336d1f5e510d18205c03c" category="list-text">Parte 1: Guida introduttiva, requisiti, dettagli di automazione e configurazione host di Ansible Control</block>
  <block id="c53dba1ad099d932b01eacd82bd500f2" category="doc">NVA-1155: Database Oracle 19c RAC su data center FlexPod con Cisco UCS e NetApp AFF A800 su FC - Guida alla progettazione e all'implementazione</block>
  <block id="547673676a9fdbc79f1364e749be4d0a" category="paragraph">Allen Cao, NetApp</block>
  <block id="ffaaa5a04a78a6ce5d807980dbf83e64" category="paragraph">Questa guida alla progettazione e all'implementazione dei database Oracle 19c RAC su FlexPod Datacenter con Cisco UCS e NetApp AFF A800 su FC fornisce dettagli sulla progettazione della soluzione e sui processi di implementazione passo-passo per l'hosting dei database Oracle RAC sulla più recente infrastruttura FlexPod Datacenter con Oracle Linux 8.2 Sistema operativo e kernel compatibile con Red Hat.</block>
  <block id="3b872d3a96131109e4700e3031e4b158" category="inline-link-macro">NVA-1155: Database Oracle 19c RAC su data center FlexPod con Cisco UCS e NetApp AFF A800 su FC</block>
  <block id="202f51b1cd08b9562681a95f87429702" category="paragraph"><block ref="202f51b1cd08b9562681a95f87429702" category="inline-link-macro-rx"></block></block>
  <block id="6e170e4c0b9eb50546a09aafc90dc157" category="doc">TR-4794: Database Oracle su NetApp EF-Series</block>
  <block id="9b6fc59469e9f5ee36cb85b08daacec3" category="paragraph">Mitch Blackburn, Ebin Kadavy, NetApp</block>
  <block id="fa8b4902d0c1e464dcf9256a434920ba" category="paragraph">TR-4794 è stato progettato per aiutare gli amministratori dello storage e i database a implementare con successo Oracle sullo storage NetApp EF-Series.</block>
  <block id="c6f1106d361e6595d08ff6340c004516" category="paragraph"><block ref="c6f1106d361e6595d08ff6340c004516" category="inline-link-macro-rx"></block></block>
  <block id="95adefbc130d345041c4487820a9ab16" category="summary">Le soluzioni per database aziendali NetApp sono un insieme di funzionalità tecnologiche e strategiche che dimostrano le funzionalità dello storage NetApp nei principali database aziendali.</block>
  <block id="e890f04973d00c3664a44f4cc586bb5d" category="doc">Soluzioni per database aziendali NetApp</block>
  <block id="b985336298cf9391b91c898572090625" category="summary">In questa sezione viene illustrata l'architettura di una soluzione per la distribuzione e la protezione dei dati del database Oracle con la macchina virtuale Azure e lo storage Azure NetApp Files.</block>
  <block id="fc6024ee9167308c3126789695e7353f" category="paragraph"><block ref="fc6024ee9167308c3126789695e7353f" category="inline-link-macro-rx"></block></block>
  <block id="91e17bfb5f535513b5320d68f6afe1fc" category="paragraph">Il seguente diagramma di architettura illustra un'implementazione di database Oracle altamente disponibile su istanze di macchine virtuali Azure e sullo storage Azure NetApp Files.</block>
  <block id="520c5c426000f1dbbd8ac385d5547603" category="paragraph">All'interno dell'ambiente, l'istanza di calcolo di Oracle viene implementata tramite una console di Azure Services VM. Dalla console sono disponibili diversi tipi di istanze di Azure. NetApp consiglia di implementare un'istanza di Azure VM orientata al database che soddisfi il carico di lavoro previsto.</block>
  <block id="9e20ded809aa2fa1bd072f48ceacfdd8" category="paragraph">Lo storage del database Oracle viene invece implementato con il servizio Azure NetApp Files disponibile dalla console Azure. I volumi binari, dati o log Oracle vengono successivamente presentati e montati su un host Linux di istanza di Azure VM.</block>
  <block id="6b5cae77dbc9c4b759bf654b117eb10b" category="inline-image-macro">Questa immagine mostra la relazione tra il sito principale, il sito di standby e il peering VNET di ciascuno di questi siti. Si tratta di quattro reti virtuali separate.</block>
  <block id="2246b51fdf61c77213e0ce37d743cd03" category="paragraph"><block ref="2246b51fdf61c77213e0ce37d743cd03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03aa17a1290e1122adecd07d53463cde" category="paragraph">Sotto molti aspetti, l'implementazione di Azure NetApp Files nel cloud Azure è molto simile a un'architettura per lo storage dei dati ONTAP on-premise con molte ridondanze integrate, come RAID e doppi controller. Per il disaster recovery, è possibile configurare un sito in standby in diverse regioni e sincronizzare il database con il sito primario utilizzando la replica a livello di applicazione (ad esempio, Oracle Data Guard).</block>
  <block id="6f1714a5ced243b141295d01d4038364" category="paragraph">Nella convalida dei test per l'implementazione e la protezione dei dati del database Oracle, il database Oracle viene implementato su una singola macchina virtuale Azure, come illustrato nel diagramma seguente:</block>
  <block id="fef3344ae2f384e724a169b6e9d90be7" category="inline-image-macro">Questa immagine mostra l'organizzazione di una singola macchina virtuale Azure con peering VNET per creare due reti virtuali separate.</block>
  <block id="f3699a22a9267b8e767816c81f821522" category="paragraph"><block ref="f3699a22a9267b8e767816c81f821522" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69cf5342936c24c9fac1c6529c4f825f" category="paragraph">L'ambiente Oracle Azure può essere gestito con un nodo controller Ansible per l'automazione utilizzando i toolkit forniti da NetApp per l'implementazione del database, il backup, il ripristino e la migrazione del database. Qualsiasi aggiornamento al kernel del sistema operativo dell'istanza di Oracle Azure VM o all'applicazione di patch Oracle può essere eseguito in parallelo per mantenere sincronizzati il primario e lo standby. Infatti, i toolkit iniziali possono essere facilmente espansi per eseguire le attività quotidiane di Oracle, se necessario. Per assistenza nella configurazione di un controller CLI Ansible, vedere <block ref="03bbd03f7d2552fa2076b42f86a04360" category="inline-link-macro-rx"></block> per iniziare.</block>
  <block id="149b87e0b981bcf1e3d652831c207e04" category="inline-link-macro">Avanti: Fattori da considerare.</block>
  <block id="0a9d288b4b8679857f2d7e7f0d5a63f6" category="paragraph"><block ref="0a9d288b4b8679857f2d7e7f0d5a63f6" category="inline-link-macro-rx"></block></block>
  <block id="9b64a6dfae1f3fa326b750c2790c79fe" category="summary">In questa sezione viene descritta la distribuzione in tempo reale di un database SQL in una configurazione AOAG utilizzando un volume SMB Azure NetApp Files.</block>
  <block id="5ca1071c67ab704b04ed27747f213551" category="doc">Progettazione di riferimento in tempo reale e di alto livello</block>
  <block id="bb0357d1c0b3b8ebd31a43c9b30f3745" category="list-text">Numero di nodi: 4</block>
  <block id="7f4f30d96e1d0a820a6962ad6ac994ee" category="list-text">Numero di database: 21</block>
  <block id="f28735e3e5e57049aa575b3f0ec83c61" category="list-text">Numero di gruppi di disponibilità: 4</block>
  <block id="96fb94ba9fad0b4452c212b21df61eab" category="list-text">Conservazione del backup: 7 giorni</block>
  <block id="a8d1485807d36562316fb8b2254bca57" category="list-text">Archivio di backup: 365 giorni</block>
  <block id="4afa49afd4ebc3638f3e000d65825370" category="admonition">L'implementazione di FCI con SQL Server su macchine virtuali Azure con una condivisione Azure NetApp Files offre un modello conveniente con una singola copia dei dati. Questa soluzione consente di evitare problemi di funzionamento dei file aggiuntivi se il percorso del file differisce dalla replica secondaria.</block>
  <block id="ab030ea777250278c4f110a497eeef88" category="paragraph"><block ref="ab030ea777250278c4f110a497eeef88" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4822d9597460a9166778308da312709c" category="paragraph">L'immagine seguente mostra i database all'interno di AOAG distribuiti tra i nodi.</block>
  <block id="af316199cc8e77dcbb6fb560cbc4c44c" category="paragraph"><block ref="af316199cc8e77dcbb6fb560cbc4c44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d22a890163762fcf7a4cb7605c29b7e6" category="section-title">Layout dei dati</block>
  <block id="35c33dd0c5565dbdba04dc2b313d7a2e" category="paragraph">I file di database utente (.mdf) e i file di log delle transazioni del database utente (.ldf) insieme a tempdb vengono memorizzati sullo stesso volume. Il livello di servizio è Ultra.</block>
  <block id="9b7d6479a15395afefc6d7f9e38a4f17" category="paragraph">La configurazione è composta da quattro nodi e quattro AGS. Tutti i 21 database (parte di Dynamic AX, SharePoint, RDS Connection broker e servizi di indicizzazione) sono memorizzati nei volumi Azure NetApp Files. I database sono bilanciati tra i nodi AOAG per utilizzare le risorse sui nodi in modo efficace. Quattro istanze D32 v3 vengono aggiunte in WSFC, che partecipa alla configurazione AOAG. Questi quattro nodi vengono forniti nella rete virtuale Azure e non vengono migrati da on-premise.</block>
  <block id="fcbd19b726fdd6160dfe2ab43f285a55" category="paragraph">*Note:*</block>
  <block id="09a10f0ab048cde1d7b704392ba05d9a" category="list-text">Se i log richiedono maggiori performance e throughput a seconda della natura dell'applicazione e delle query eseguite, i file di database possono essere posizionati al livello di servizio Premium e i log possono essere memorizzati al livello di servizio Ultra.</block>
  <block id="51368a236b969e288242f0b0b615cf74" category="list-text">Se i file tempdb sono stati posizionati su Azure NetApp Files, il volume Azure NetApp Files deve essere separato dai file di database dell'utente. Ecco un esempio di distribuzione dei file di database in AOAG.</block>
  <block id="2e66f3d288799e6f4235b883bb2f693c" category="list-text">Per conservare i vantaggi della protezione dei dati basata su copia Snapshot, NetApp consiglia di non combinare dati e dati di log nello stesso volume.</block>
  <block id="1452bcdb4aeb229a2c2e503f9bbba753" category="list-text">Un'operazione di aggiunta file eseguita sulla replica primaria potrebbe non riuscire nei database secondari se il percorso di un database secondario differisce dal percorso del database primario corrispondente. Questo può accadere se il percorso di condivisione è diverso sui nodi primario e secondario (a causa di diversi account di computer). Questo errore potrebbe causare la sospensione dei database secondari. Se non è possibile prevedere il modello di crescita o di performance e si prevede di aggiungere file in un secondo momento, un cluster di failover di SQL Server con Azure NetApp Files è una soluzione accettabile. Per la maggior parte delle implementazioni, Azure NetApp Files soddisfa i requisiti di performance.</block>
  <block id="19f59b74448f6a27519db281a44e4b12" category="section-title">Migrazione</block>
  <block id="cd6b4503e07d15cebc0842bb8da7b765" category="paragraph">Esistono diversi modi per migrare un database utente SQL Server on-premise su SQL Server in una macchina virtuale Azure. La migrazione può essere online o offline. Le opzioni scelte dipendono dalla versione di SQL Server, dai requisiti di business e dagli SLA definiti all'interno dell'organizzazione. Per ridurre al minimo i downtime durante il processo di migrazione del database, NetApp consiglia di utilizzare l'opzione AlwaysOn o l'opzione di replica transazionale. Se non è possibile utilizzare questi metodi, è possibile migrare il database manualmente.</block>
  <block id="2d4221f1ee93c102ca047daac1fba4a7" category="paragraph">L'approccio più semplice e testato per lo spostamento dei database tra le macchine è il backup e il ripristino. In genere, è possibile iniziare con un backup del database seguito da una copia del backup del database in Azure. È quindi possibile ripristinare il database. Per ottenere le migliori prestazioni di trasferimento dei dati, migrare i file di database nella macchina virtuale Azure utilizzando un file di backup compresso. La progettazione di alto livello a cui si fa riferimento in questo documento utilizza l'approccio di backup allo storage di file Azure con Azure file Sync e quindi il ripristino in Azure NetApp Files.</block>
  <block id="623f8382f97ee8df2d7af54439833812" category="admonition">Azure Migrate può essere utilizzato per rilevare, valutare e migrare i carichi di lavoro di SQL Server.</block>
  <block id="fbc25f1c70f1a9c133715cac6d66b21b" category="paragraph">Per eseguire una migrazione, attenersi alla seguente procedura di alto livello:</block>
  <block id="d807caa187d2fea33bab50ed1e1c79bb" category="list-text">In base alle tue esigenze, imposta la connettività.</block>
  <block id="59f59f1aebe4fc18ab054480b3a1098a" category="list-text">Eseguire un backup completo del database in una posizione di condivisione file on-premise.</block>
  <block id="4891d727582d5df766ee6737fe7fb761" category="list-text">Copia i file di backup in una condivisione file Azure con Azure file Sync.</block>
  <block id="135899cc34886eb6ce9baf7211d4adb5" category="list-text">Eseguire il provisioning della macchina virtuale con la versione desiderata di SQL Server.</block>
  <block id="fbef0b11b7ee9e0d709d3d1c6efbd4d4" category="list-text">Copiare i file di backup nella macchina virtuale utilizzando<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block> da un prompt dei comandi.</block>
  <block id="b9786aca69df61c5165147929b4ced89" category="list-text">Ripristinare i database completi su SQL Server su macchine virtuali Azure.</block>
  <block id="e937691d64dcb1188cbbcbcd83d87d2f" category="admonition">Il ripristino di 21 database richiede circa nove ore. Questo approccio è specifico di questo scenario. Tuttavia, è possibile utilizzare altre tecniche di migrazione elencate di seguito in base alla situazione e ai requisiti.</block>
  <block id="2b9d85faa379ef985ae3851810db1403" category="paragraph">Altre opzioni di migrazione per spostare i dati da un server SQL on-premise a Azure NetApp Files includono:</block>
  <block id="90248308f9c24bd3bf817ee129838603" category="list-text">Scollegare i file di dati e log, copiarli nello storage Azure Blob e allegarli a SQL Server nella macchina virtuale Azure con una condivisione file ANF montata dall'URL.</block>
  <block id="82ce70205698ed956d1fce48af1360c0" category="inline-link">Aggiunta guidata di Azure Replica</block>
  <block id="e5e07f1ff84f0082089e4fec71ed43a4" category="list-text">Se si utilizza l'implementazione on-premise di un gruppo di disponibilità always on, utilizzare il<block ref="aea558e3371e9956f5e03828309464a0" category="inline-link-rx"></block> Per creare una replica in Azure ed eseguire il failover.</block>
  <block id="eedc53c13a9992999dba36bda1b62255" category="inline-link">replica transazionale</block>
  <block id="47a43d904457c52da2918f290a0ae5cb" category="list-text">Utilizzare SQL Server<block ref="21bf5f41b40b598aae9dd55aa9dcb960" category="inline-link-rx"></block> Per configurare l'istanza di Azure SQL Server come abbonato, disattivare la replica e puntare gli utenti all'istanza del database Azure.</block>
  <block id="bf4614882fd1000329cfcb76f98f6c17" category="list-text">Spedire il disco rigido utilizzando il servizio di importazione/esportazione di Windows.</block>
  <block id="be062cdcabbb3055334e8f19b4bdf378" category="section-title">Backup e recovery</block>
  <block id="b855582b6472c4fbe2a5f606191e66d6" category="paragraph">Il backup e il ripristino sono un aspetto importante di qualsiasi implementazione di SQL Server. È obbligatorio disporre di una rete di sicurezza adeguata per il ripristino rapido da diversi scenari di perdita e guasto dei dati in combinazione con soluzioni ad alta disponibilità come AOAG. SQL Server Database Quiesce Tool, Azure Backup (streaming) o qualsiasi tool di backup di terze parti come CommVault può essere utilizzato per eseguire un backup coerente con l'applicazione dei database,</block>
  <block id="3896e1102f68b0bc974f324bb134f6e6" category="inline-link">Tool SCSQLAPI</block>
  <block id="e372173044ccba12657b2e3dbff1879b" category="paragraph">La tecnologia Snapshot di Azure NetApp Files consente di creare facilmente una copia point-in-time (PIT) dei database degli utenti senza influire sulle performance o sull'utilizzo della rete. Questa tecnologia consente inoltre di ripristinare una copia Snapshot in un nuovo volume o di ripristinare rapidamente il volume interessato allo stato in cui si trovava quando la copia Snapshot è stata creata utilizzando la funzione del volume di revert. Il processo di snapshot di Azure NetApp Files è molto rapido ed efficiente, consentendo backup giornalieri multipli, a differenza del backup in streaming offerto dal backup di Azure. Grazie alla possibilità di eseguire più copie Snapshot in un determinato giorno, i tempi di RPO e RTO possono essere notevolmente ridotti. Per aggiungere la coerenza dell'applicazione in modo che i dati siano intatti e correttamente trasferiti sul disco prima di eseguire la copia Snapshot, utilizzare lo strumento di silenziamento del database di SQL Server <block ref="b800e9e09a17fc5b41967404ec8e47ac" category="inline-link-rx"></block>; L'accesso a questo collegamento richiede le credenziali di accesso NetApp SSO). Questo strumento può essere eseguito da PowerShell, che mette in pausa il database di SQL Server e, a sua volta, può utilizzare la copia Snapshot dello storage coerente con l'applicazione per i backup.</block>
  <block id="04666a337d02195d17089298f5773f4c" category="paragraph">*Note: *</block>
  <block id="a4d5ac6087b7ce119cfe6b7ad4d77ee5" category="list-text">Lo strumento SCSQLAPI supporta solo le versioni 2016 e 2017 di SQL Server.</block>
  <block id="fdcb10d4c2db07cf930247a4f9898ec5" category="list-text">Lo strumento SCSQLAPI funziona solo con un database alla volta.</block>
  <block id="2f65ae42dc3aa8b735406a2d56ceb6fb" category="list-text">Isolare i file di ciascun database inserendoli in un volume Azure NetApp Files separato.</block>
  <block id="879351e17b2cd6d740ac0974e9ff8a5a" category="inline-link">Backup di Azure</block>
  <block id="794b24c8957eec03a1402459d32f6810" category="paragraph">A causa delle enormi limitazioni dell'API SCSQL,<block ref="10a72c6743c3c6714e03b5537ec15603" category="inline-link-rx"></block> È stato utilizzato per la protezione dei dati al fine di soddisfare i requisiti dello SLA. Offre un backup basato su flusso di SQL Server in esecuzione su macchine virtuali Azure e Azure NetApp Files. Azure Backup consente un RPO di 15 minuti con frequenti backup dei log e PIT Recovery fino a un secondo.</block>
  <block id="423e555c5ec3885f2bb5d9d2d6627f63" category="section-title">Monitoraggio</block>
  <block id="fe58430a0bb00057a08eed382c5d82b2" category="paragraph">Azure NetApp Files è integrato con Azure Monitor per i dati delle serie temporali e fornisce metriche sullo storage allocato, sull'utilizzo effettivo dello storage, sugli IOPS dei volumi, sul throughput, sui byte di lettura dei dischi al secondo, byte di scrittura del disco/sec, letture del disco/sec e scritture del disco/sec e latenza associata. Questi dati possono essere utilizzati per identificare i colli di bottiglia con avvisi ed eseguire controlli di integrità per verificare che la distribuzione di SQL Server sia in esecuzione in una configurazione ottimale.</block>
  <block id="48419e90c914ae5fa935283404de8a2a" category="paragraph">In questo HLD, ScienceLogic viene utilizzato per monitorare Azure NetApp Files esponendo le metriche utilizzando l'entità di servizio appropriata. L'immagine seguente è un esempio dell'opzione Azure NetApp Files Metric (metriche di riferimento).</block>
  <block id="2bede5da6907dcdcebc6a8f407f07467" category="paragraph"><block ref="2bede5da6907dcdcebc6a8f407f07467" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6fe292df6373534e554d5a7938bc3c3b" category="section-title">DevTest con cloni spessi</block>
  <block id="652f67778e6d02c7b5bfe46a3e579f7f" category="paragraph">Con Azure NetApp Files, è possibile creare copie istantanee dei database per testare le funzionalità che devono essere implementate utilizzando la struttura e il contenuto del database corrente durante i cicli di sviluppo delle applicazioni, per utilizzare gli strumenti di estrazione e manipolazione dei dati durante il popolamento dei data warehouse, oppure per ripristinare i dati cancellati o modificati per errore. Questo processo non implica la copia dei dati dai container Azure Blob, il che lo rende molto efficiente. Una volta ripristinato, il volume può essere utilizzato per le operazioni di lettura/scrittura, riducendo significativamente la convalida e il time-to-market. Questo deve essere utilizzato insieme a SCSQLAPI per garantire la coerenza delle applicazioni. Questo approccio offre un'ulteriore tecnica di ottimizzazione continua dei costi insieme a Azure NetApp Files che sfrutta l'opzione Ripristina nuovo volume.</block>
  <block id="e4665dd99280634e4b44ff82666fbb9f" category="list-text">Il volume creato dalla copia Snapshot utilizzando l'opzione Restore New Volume (Ripristina nuovo volume) consuma la capacità del pool di capacità.</block>
  <block id="0031911d8ba66a79d06b9819afd4f082" category="list-text">È possibile eliminare i volumi clonati utilizzando REST o Azure CLI per evitare costi aggiuntivi (nel caso in cui il pool di capacità debba essere aumentato).</block>
  <block id="cb4d46fdcb0881652013c495d90ae732" category="section-title">Opzioni di storage ibrido</block>
  <block id="e6a1767911a937e11cc1750fcc4256c3" category="paragraph">Sebbene NetApp consiglia di utilizzare lo stesso storage per tutti i nodi dei gruppi di disponibilità di SQL Server, esistono scenari in cui è possibile utilizzare più opzioni di storage. Questo scenario è possibile per Azure NetApp Files in cui un nodo in AOAG è connesso a una condivisione file SMB di Azure NetApp Files e il secondo nodo è connesso a un disco Premium di Azure. In questi casi, assicurarsi che la condivisione SMB di Azure NetApp Files conservi la copia principale dei database utente e che il disco Premium sia utilizzato come copia secondaria.</block>
  <block id="009d3d51226fdccd09052934b65100db" category="list-text">In tali implementazioni, per evitare problemi di failover, assicurarsi che la disponibilità continua sia attivata sul volume SMB. Senza attributi a disponibilità continua, il database può fallire in caso di manutenzione in background a livello di storage.</block>
  <block id="918e9d895272e6a326c6585e05ae4c08" category="list-text">Conservare la copia principale del database nella condivisione file SMB di Azure NetApp Files.</block>
  <block id="1a5c3601eda1cd38072323e418968743" category="section-title">Continuità del business</block>
  <block id="064ea84d2e6072b28bfd7a8b36aed3db" category="paragraph">Il disaster recovery è in genere un elemento secondario in qualsiasi implementazione. Tuttavia, il disaster recovery deve essere risolto durante la fase iniziale di progettazione e implementazione per evitare qualsiasi impatto sul business. Con Azure NetApp Files, è possibile utilizzare la funzionalità CRR (Cross-Region Replication) per replicare i dati del volume a livello di blocco nella regione associata, in modo da gestire eventuali interruzioni regionali impreviste. Il volume di destinazione abilitato per CRR può essere utilizzato per le operazioni di lettura, il che lo rende il candidato ideale per le simulazioni di disaster recovery. Inoltre, è possibile assegnare la destinazione CRR con il livello di servizio più basso (ad esempio, Standard) per ridurre il TCO complessivo. In caso di failover, la replica può essere interrotta, rendendo possibile la lettura/scrittura del rispettivo volume. Inoltre, è possibile modificare il livello di servizio del volume utilizzando la funzionalità del livello di servizio dinamico per ridurre significativamente i costi di disaster recovery. Si tratta di un'altra funzionalità esclusiva di Azure NetApp Files con replica a blocchi all'interno di Azure.</block>
  <block id="86258094262f66b30d10068d1d9c29d4" category="section-title">Archivio di copie Snapshot a lungo termine</block>
  <block id="65bd92a3b5fcfea7efeb973a0a2483d8" category="inline-link">AzCopy</block>
  <block id="e6bf440e9e7e787ce92e6f8661daf9e9" category="paragraph">Molte organizzazioni devono eseguire la conservazione a lungo termine dei dati snapshot dai file di database come requisito obbligatorio di conformità. Sebbene questo processo non venga utilizzato in questo HLD, può essere facilmente eseguito utilizzando un semplice script batch<block ref="f326c7b047cd071718d141dba06c550f" category="inline-link-rx"></block> Per copiare la directory di snapshot nel container Azure Blob. Lo script batch può essere attivato in base a una pianificazione specifica utilizzando le attività pianificate. Il processo è semplice e include i seguenti passaggi:</block>
  <block id="dfdc6514d824f948d82ee2ac6515603f" category="list-text">Scaricare il file eseguibile di AzCopy V10. Non c'è nulla da installare perché si tratta di un<block ref="98e83379d45538379c2ac4e47c3be81d" prefix=" " category="inline-code"></block> file.</block>
  <block id="5434519f37049a19d388fb3edabd08f7" category="list-text">Autorizzare AzCopy utilizzando un token SAS a livello di container con le autorizzazioni appropriate.</block>
  <block id="73facdc1e77927e1c0d4c2f66c6fedf9" category="list-text">Dopo l'autorizzazione di AzCopy, inizia il trasferimento dei dati.</block>
  <block id="a2c31034ac77c6ad0ce6dae2a7882d73" category="list-text">Nei file batch, assicurarsi di escapire i caratteri % visualizzati nei token SAS. Per eseguire questa operazione, aggiungere un carattere % aggiuntivo accanto ai caratteri % esistenti nella stringa del token SAS.</block>
  <block id="0eed577952fd376af1fa48aa241e3df7" category="inline-link">Trasferimento sicuro richiesto</block>
  <block id="b2f731ca364e7df30cd69650bdc19d46" category="list-text">Il<block ref="7e9be5c7f255e20f7f3a81046108dcad" category="inline-link-rx"></block> L'impostazione di un account di storage determina se la connessione a un account di storage è protetta con Transport Layer Security (TLS). Questa impostazione è attivata per impostazione predefinita. Il seguente esempio di script batch copia in modo ricorrente i dati dalla directory di copia Snapshot in un contenitore Blob designato:</block>
  <block id="f2c225fb316953652d9040f71e76717c" category="paragraph">Il seguente cmd di esempio viene eseguito in PowerShell:</block>
  <block id="e7cc24e4ddff469c6304653aea869597" category="list-text">Una funzionalità di backup simile per la conservazione a lungo termine sarà presto disponibile in Azure NetApp Files.</block>
  <block id="03930ecbc2c505278298d571631e23bb" category="list-text">Lo script batch può essere utilizzato in qualsiasi scenario che richieda la copia dei dati nel contenitore Blob di qualsiasi regione.</block>
  <block id="a39ae09f8be4327fc176cfeb76a0e366" category="section-title">Ottimizzazione dei costi</block>
  <block id="07ecdeff0f5a70968e882eb4ace6f576" category="paragraph">Con la risagomatura dei volumi e la modifica dinamica del livello di servizio, che è completamente trasparente per il database, Azure NetApp Files consente ottimizzazioni dei costi continue in Azure. Questa funzionalità viene ampiamente utilizzata in questo HLD per evitare l'overprovisioning di storage aggiuntivo per gestire i picchi dei carichi di lavoro.</block>
  <block id="bf511e8b678dd2ecee162930e6c8c9e6" category="paragraph">Il ridimensionamento del volume può essere eseguito facilmente creando una funzione Azure insieme ai registri degli avvisi di Azure.</block>
  <block id="6551468cb4811e7add616eea103efea9" category="doc">Procedura di implementazione passo-passo</block>
  <block id="c150393fd3b1bd9d801cbd062234f73d" category="section-title">Implementazione AWX/Tower Database Oracle 19c</block>
  <block id="32003b051ef9368756d1e9cd79796719" category="section-title">1. Creare l'inventario, il gruppo, gli host e le credenziali per il proprio ambiente</block>
  <block id="2c8b94d570dd5a63a27d112e32a1c799" category="paragraph">Questa sezione descrive la configurazione di inventario, gruppi, host e credenziali di accesso in AWX/Ansible Tower che preparano l'ambiente per l'utilizzo delle soluzioni automatizzate di NetApp.</block>
  <block id="af2c7dd4ecef5e42e9bc8f88213d51d9" category="list-text">Accedere a Resources → Inventories → Add e fare clic su Add Inventory (Aggiungi inventario).</block>
  <block id="56fc26ef1c8ae54dced3529eec65fa26" category="list-text">Fornire il nome e i dettagli dell'organizzazione, quindi fare clic su Save (Salva).</block>
  <block id="fe0981da08a8d2f4fed2006bafd9fb30" category="list-text">Nella pagina Inventories (inventari), fare clic sull'inventario creato.</block>
  <block id="3fa16e80574aff03c27de1253474a20f" category="list-text">Se sono presenti variabili di inventario, incollarle nel campo variabili.</block>
  <block id="65d119ae335d9e7c9c798b3e6db1b2d0" category="list-text">Accedere al sottomenu Groups (gruppi) e fare clic su Add (Aggiungi).</block>
  <block id="396641e01a7451ca821b5d7d1377b0c7" category="list-text">Fornire il nome del gruppo per ONTAP, incollare le variabili di gruppo (se presenti) e fare clic su Salva.</block>
  <block id="a4f13b6e4100f2d5db093eb54a3ffe0c" category="list-text">Ripetere la procedura per un altro gruppo per Oracle.</block>
  <block id="6f29f21d5f3e40494291fb357b9f4f73" category="list-text">Selezionare il gruppo ONTAP creato, accedere al sottomenu hosts e fare clic su Aggiungi nuovo host.</block>
  <block id="8d92ffd9d0d2b033d05731ec4af50af8" category="list-text">Fornire l'indirizzo IP dell'IP di gestione del cluster ONTAP, incollare le variabili host (se presenti) e fare clic su Salva.</block>
  <block id="f1254ecbe57ff98d850d541b8a1ab988" category="list-text">Questo processo deve essere ripetuto per l'IP/nome host di gestione del gruppo Oracle e degli host Oracle.</block>
  <block id="f11c5853bdca384314b28c9c59f2d6d0" category="list-text">Creare tipi di credenziale. Per le soluzioni che utilizzano ONTAP, è necessario configurare il tipo di credenziale in modo che corrisponda alle voci di nome utente e password.</block>
  <block id="c87e3da0a9f8d5eeacea4eac9bef80ea" category="list-text">Accedere a Administration → Credential Types (Amministrazione tipi di credenziali) e fare clic su Add (Aggiungi).</block>
  <block id="5f5a0974b600f86bd4e77595282fcf70" category="list-text">Incollare il seguente contenuto in Input Configuration (Configurazione input):</block>
  <block id="1616edbabbc3bbfd22afe144d1929386" category="list-text">Incollare il seguente contenuto nella configurazione dell'iniettore:</block>
  <block id="c4053f20c3fe50fe899484a64367439e" category="list-text">Configurare le credenziali.</block>
  <block id="41dcc8a8aaaa79a511ba0ab4e6bde225" category="list-text">Accedere a Resources → Credentials (risorse credenziali) e fare clic su Add (Aggiungi).</block>
  <block id="cc865c923bcb1c61acf9985311675b93" category="list-text">Immettere il nome e i dettagli dell'organizzazione per ONTAP.</block>
  <block id="ea314f484653e7f9f25144ea61d34888" category="list-text">Selezionare il tipo di credenziale personalizzato creato per ONTAP.</block>
  <block id="179cae6336461d9f165e8fa87146362a" category="list-text">In Dettagli tipo, immettere il nome utente, la password e la password vsadmin_password.</block>
  <block id="659fb4c811f1a73cf40492056e6d3c3f" category="list-text">Fare clic su Torna alla credenziale e fare clic su Aggiungi.</block>
  <block id="3b9c90c4bf202563a3cdeda5ec78fac2" category="list-text">Immettere il nome e i dettagli dell'organizzazione per Oracle.</block>
  <block id="9ef3fcc446a5f500717f9b5e9291bce4" category="list-text">Selezionare il tipo di credenziale Machine.</block>
  <block id="9fadc5c4eed350a8a1423628227dad59" category="list-text">In Dettagli tipo, immettere il nome utente e la password per gli host Oracle.</block>
  <block id="b4ca3125325138b1dbfc309e6bd67b80" category="list-text">Selezionare il metodo corretto di escalation dei privilegi e immettere il nome utente e la password.</block>
  <block id="51b04d83367483575e89740841d94262" category="section-title">2. Creare un progetto</block>
  <block id="e56fa1e2655db1bc7664a00295bd62a2" category="list-text">Accedere a risorse → progetti e fare clic su Aggiungi.</block>
  <block id="4096a1870a258e9d46585f08d4906f21" category="list-text">Selezionare Git nel campo Source Control Credential Type (tipo credenziale controllo origine).</block>
  <block id="784148c4a03cf22250dddc5756684e39" category="list-text">invio <block ref="4509731a8f0f86cf7d8a010739dfd7c5" category="inline-link-rx"></block> Come URL del controllo di origine.</block>
  <block id="99bc2ea435ea8ae0ed38ef3051a4350a" category="list-text">Potrebbe essere necessario sincronizzare il progetto occasionalmente quando il codice sorgente cambia.</block>
  <block id="14e017f358e18dd612a468713206093f" category="section-title">3. Configurare Oracle host_vars</block>
  <block id="05557c38b20e42173356b53f42c92152" category="paragraph">Le variabili definite in questa sezione vengono applicate a ogni singolo server e database Oracle.</block>
  <block id="ac886b852fd1b481e9c7e68c217b5e21" category="list-text">Inserire i parametri specifici dell'ambiente nel seguente modulo host Oracle incorporato o host_vars.</block>
  <block id="93be2ec6954884b83ac9df8117967949" category="admonition">Gli elementi in blu devono essere modificati in base all'ambiente in uso.</block>
  <block id="5bbe8264b4d6c6787657c66d4017c183" category="section-title">Config. VAR host</block>
  <block id="e1847b1a99378b07a0df71cf2baac5da" category="list-text">Inserire tutte le variabili nei campi blu.</block>
  <block id="741c92ab2429ff59927918c7a07ad9a5" category="list-text">Una volta completata l'immissione delle variabili, fare clic sul pulsante Copy (Copia) del modulo per copiare tutte le variabili da trasferire su AWX o Tower.</block>
  <block id="1e1ea51549ac2a644a3e965113c1d370" category="list-text">Tornare a AWX o Tower e andare a Resources → hosts, quindi selezionare e aprire la pagina di configurazione del server Oracle.</block>
  <block id="0d630b14098a793ac4586173286d0805" category="list-text">Nella scheda Dettagli, fare clic su Modifica e incollare le variabili copiate dal punto 1 nel campo variabili sotto la scheda YAML.</block>
  <block id="c6dca9e669d097298fc6059b27f96e09" category="list-text">Ripetere questa procedura per tutti i server Oracle aggiuntivi nel sistema.</block>
  <block id="7890327bd98d1ec932e453254511754d" category="section-title">4. Configurare le variabili globali</block>
  <block id="e5cac740ce6bd43e6ff83881e150d0f3" category="paragraph">Le variabili definite in questa sezione si applicano a tutti gli host Oracle, ai database e al cluster ONTAP.</block>
  <block id="87b55102ec2889891b0258253b739244" category="list-text">Inserire i parametri specifici dell'ambiente nel seguente formato vars o variabili globali incorporate.</block>
  <block id="d0db3f5a4a306cff20be4187b3ef3445" category="section-title">VARS</block>
  <block id="7d2a3c2ad9ee2eeb7547d205d30b9335" category="list-text">Inserire tutte le variabili nei campi blu.</block>
  <block id="099f04b51539ed973890f1d1af2d5063" category="list-text">Una volta completata l'immissione delle variabili, fare clic sul pulsante Copy (Copia) del modulo per copiare tutte le variabili da trasferire a AWX o Tower nel seguente modello di lavoro.</block>
  <block id="c807b1735c1915c52547b9f7e917b55d" category="section-title">5. Configurare e avviare il modello di lavoro.</block>
  <block id="b1171f0b44b8d9b11ac555972ebc8c3b" category="list-text">Creare il modello di lavoro.</block>
  <block id="c7fa74fb4cbaab9d336a8e55bf164684" category="list-text">Immettere il nome e la descrizione</block>
  <block id="3dcca032e3328f54206079a87830aa27" category="list-text">Selezionare il tipo di lavoro; Esegui consente di configurare il sistema in base a un playbook e Check esegue un'esecuzione a secco di un playbook senza configurare effettivamente il sistema.</block>
  <block id="daefcb84cec2b58089094a64cefb845f" category="list-text">Seleziona l'inventario, il progetto, il playbook e le credenziali corrispondenti per il playbook.</block>
  <block id="b01c6189ccdc531874f3442803680525" category="list-text">Selezionare all_playbook.yml come playbook predefinito da eseguire.</block>
  <block id="ce150ce9cfe145db199958e7cd2ecce0" category="list-text">Incollare le variabili globali copiate dal passaggio 4 nel campo Template Variables (variabili modello) nella scheda YAML.</block>
  <block id="e8f0426d97d09775fb78bdeb793b0b3e" category="list-text">Selezionare la casella prompt all'avvio nel campo Job Tags.</block>
  <block id="ad7ad1bbc416fda1f9518ff4004d891c" category="list-text">Quando richiesto all'avvio per Job Tags, digitare requirements_config. Potrebbe essere necessario fare clic sulla riga Create Job Tag sotto requirements_config per inserire il tag del processo.</block>
  <block id="b9ef793a3db3f07ed7dc808f4709c6ca" category="admonition">requirements_config garantisce di disporre delle librerie corrette per eseguire gli altri ruoli.</block>
  <block id="6ac039e55dcf8a249f5122b1fdbbf60e" category="list-text">Fare clic su Avanti, quindi su Avvia per avviare il processo.</block>
  <block id="06f392c8dfb4783859e67f16fed69bc7" category="list-text">Fare clic su View → Jobs (Visualizza lavori) per monitorare l'output e l'avanzamento del lavoro.</block>
  <block id="7f6a02c24592bd309f31b5a72a0f8d6d" category="list-text">Quando richiesto all'avvio per Job Tags, digitare ontap_config. Potrebbe essere necessario fare clic sulla riga Create "Job Tag" (Crea tag lavoro) sotto ontap_config per inserire il tag del lavoro.</block>
  <block id="18c003af9ed29d295877baabf7b42ce1" category="list-text">Fare clic su View → Jobs (Visualizza lavori) per monitorare l'output e l'avanzamento del lavoro</block>
  <block id="c0029d5cdcaae1ceef3bed244b3ab3c6" category="list-text">Una volta completato il ruolo ontap_CONFIG, eseguire nuovamente il processo per linux_CONFIG.</block>
  <block id="fc71758268fe1c3aba4b75df3ee0560f" category="list-text">Selezionare il modello desiderato, quindi fare clic su Launch (Avvia).</block>
  <block id="bbe073bafc2875db8b48e59284636931" category="list-text">Quando richiesto all'avvio per il tipo di tag del processo in linux_config, potrebbe essere necessario selezionare la riga Create "job tag" (Crea tag del processo) sotto linux_config per inserire il tag del processo.</block>
  <block id="bc43b7acafead2cdee67de733ae10b13" category="list-text">Selezionare Visualizza → lavori per monitorare l'output e l'avanzamento del lavoro.</block>
  <block id="e73718535637e07111f6a4925685c0bd" category="list-text">Una volta completato il ruolo linux_config, eseguire nuovamente il processo per oracle_config.</block>
  <block id="574f8726a5cc088da32ab84269c8e0f8" category="list-text">Accedere a risorse → modelli.</block>
  <block id="252b85bc679cb8ecdccbcd127c65b795" category="list-text">Quando richiesto all'avvio per Job Tags, digitare oracle_config. Potrebbe essere necessario selezionare la riga Create "Job Tag" (Crea tag lavoro) sotto oracle_config per inserire il tag lavoro.</block>
  <block id="6757805f64ddba2566927ece0d9f30e1" category="section-title">6. Implementare database aggiuntivi sullo stesso host Oracle</block>
  <block id="4edc1d4492ab93edbbb0a67c0c265b84" category="paragraph">La parte Oracle del playbook crea un singolo database container Oracle su un server Oracle per ogni esecuzione. Per creare ulteriori database container sullo stesso server, attenersi alla seguente procedura.</block>
  <block id="a12a0fa7fe728658376da87df04fa7c2" category="list-text">Rivedere le variabili host_vars.</block>
  <block id="ba52bf2d165115d60675d61a4b84b0c6" category="list-text">Tornare al passaggio 2 - Configurazione di Oracle host_vars.</block>
  <block id="ffcc6e6df9c3839334c063a9223c65b3" category="list-text">Modificare il SID Oracle con una stringa di denominazione diversa.</block>
  <block id="a936a5fabc881eb3591658385409dfb8" category="list-text">Modificare la porta del listener con un numero diverso.</block>
  <block id="d9fa63a6f267402d4cf6068165e04a38" category="list-text">Modificare la porta EM Express con un numero diverso se si installa EM Express.</block>
  <block id="23f5c9b4f57b3075f9890f1bc1896ebe" category="list-text">Copiare e incollare le variabili host riviste nel campo Oracle host Variables (variabili host Oracle) nella scheda host Configuration Detail (Dettagli configurazione host).</block>
  <block id="4d4426a703dd8227727fef5758b680d8" category="list-text">Avviare il modello di processo di implementazione con solo il tag oracle_config.</block>
  <block id="0dd197c8abd1f3c3607887dbc615148f" category="section-title">Convalidare l'installazione di Oracle</block>
  <block id="f673434da0f39c1b4366cbc45f67da8a" category="admonition">In questo modo verranno elencati i processi oracle se l'installazione è stata completata come previsto e oracle DB è stato avviato</block>
  <block id="91bcd024d07cb33293902b287b0cc68c" category="paragraph">[oracle@localhost ~] sqlplus / come sysdba</block>
  <block id="b95bce10ef504692a6d971d3a30ac8c4" category="paragraph">SQL*Plus: Release 19.0.0.0.0 - produzione giovedì 6 maggio 12:52:51 2021 versione 19.8.0.0.0</block>
  <block id="a2494ba30f29d91ff6876152fc693ab3" category="paragraph">Copyright (c) 1982, 2019, Oracle. Tutti i diritti riservati.</block>
  <block id="ce8b3f5af3f95d98bbbf478e4c37024f" category="paragraph">Connesso a: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - versione di produzione 19.8.0.0.0</block>
  <block id="28a359e505158300600d776ae9347cac" category="paragraph">SQL&gt;</block>
  <block id="63102463594ac5bd274343651065779d" category="paragraph">SQL&gt; selezionare name, log_mode dal database v€; NAME LOG_MODE -------- ------------ CDB2 ARCHIVELOG</block>
  <block id="7d8bf5a6b847068ff3c0eb0ca0892acf" category="paragraph">SQL&gt; mostra pdbs</block>
  <block id="33c7676f0bdcf42bed62c146feaf485c" category="paragraph">SQL&gt; col svrname form a30 SQL&gt; col dirname form a30 SQL&gt; selezionare svrname, dirname, nfsversion da v€dnfs_servers;</block>
  <block id="d6bee2dc52f5708cd8af49c1c263c714" category="paragraph">SVGA DIRNAME NFSVERSION -------------------------------------------------------------- ------------------------------------------------------------ ------------------ 172.21.126.200 /rhelora03_u02 NFSv3.0 172.21.126.200 /rhelora03_u03 NFSv3.0 172.21.126.200 /rhelora03_u01 NFSv3.0</block>
  <block id="ea12870da72347cdd45bc11ae4d603dc" category="paragraph">[oracle@localhost ~]@ sqlplus system//localhost:1523/cdb2_pdb1.cie.netapp.com</block>
  <block id="aff680efe40afd832819af131e324051" category="paragraph">SQL*Plus: Release 19.0.0.0.0 - produzione giovedì 6 maggio 13:19:57 2021 versione 19.8.0.0.0</block>
  <block id="6c3d252188792733323cf879b5d196cf" category="paragraph">Enter password: Last Successful login time: Mer May 05 2021 17:11:11 -04:00</block>
  <block id="531fea2bb939d7c35cad66fde1640511" category="paragraph">SQL&gt; show user is "SYSTEM" SQL&gt; show con_name con_NAME CDB2_PDB1</block>
  <block id="1b6a5f8b328d3175066895d7ff5ea576" category="inline-link-macro">La community di NetApp Solution Automation supporta il canale slack</block>
  <block id="12f178498803c606c23e7166dcefb0cb" category="paragraph">Se hai bisogno di aiuto con il toolkit, iscriviti a. <block ref="f1bb21e2ce6888d898ae31a2098245a1" category="inline-link-macro-rx"></block> e cerca il canale di automazione della soluzione per inviare domande o domande.</block>
  <block id="64899c745691f41e5b1dc01d3a4487d2" category="summary">In questa sezione vengono descritti i diversi problemi da tenere in considerazione quando si utilizza Azure NetApp Files con SQL Server nel cloud.</block>
  <block id="bb4695a70b92668f0a7927d04580db60" category="doc">Fattori da considerare</block>
  <block id="4dd91c7652639dacea041fe6033e2627" category="section-title">Performance delle macchine virtuali</block>
  <block id="e6ac657ee6eac68b739c5cc437863922" category="inline-link">ottimizzato per la memoria</block>
  <block id="68e5d4a238cdfe033afa141123484499" category="paragraph">La scelta delle dimensioni corrette delle macchine virtuali è importante per ottenere performance ottimali di un database relazionale in un cloud pubblico. Microsoft consiglia di continuare a utilizzare le stesse opzioni di ottimizzazione delle performance del database applicabili a SQL Server in ambienti server on-premise. Utilizzare<block ref="187f54af8632f4f6696d6052e8b74aec" category="inline-link-rx"></block> Dimensioni delle macchine virtuali per le migliori performance dei carichi di lavoro di SQL Server. Raccogliere i dati sulle performance dell'implementazione esistente per identificare l'utilizzo della RAM e della CPU, scegliendo le istanze giuste. La maggior parte delle implementazioni sceglie tra le serie D, e o M.</block>
  <block id="8b2db846b8ed65b2919d93a68b819a43" category="list-text">Per ottenere le migliori performance dei carichi di lavoro di SQL Server, utilizza dimensioni delle macchine virtuali ottimizzate per la memoria.</block>
  <block id="32a3b4d7b7e6cf1ecde48636119e0288" category="list-text">NetApp e Microsoft consigliano di identificare i requisiti di performance dello storage prima di scegliere il tipo di istanza con il rapporto memoria-Vcore appropriato. Ciò consente anche di selezionare un tipo di istanza inferiore con la larghezza di banda di rete corretta per superare i limiti di throughput dello storage della macchina virtuale.</block>
  <block id="0abdff1d9e33eca61c14ccafe8012cd5" category="section-title">Ridondanza delle macchine virtuali</block>
  <block id="9fecd525b2d9ad39ac38bbfc4d05ee17" category="inline-link">set di disponibilità</block>
  <block id="26075dbb6cfad683e0d9bd0d29c570b8" category="inline-link">zone di disponibilità</block>
  <block id="e936e004eab3eccfc1e7f46a3187dfd1" category="paragraph">Per aumentare la ridondanza e l'alta disponibilità, le VM di SQL Server devono essere uguali<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> o diverso<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>. Quando si creano macchine virtuali Azure, è necessario scegliere tra la configurazione dei set di disponibilità e le zone di disponibilità; una macchina virtuale Azure non può partecipare a entrambe.</block>
  <block id="94eeeae1e60f97a446e8c4f69d6d6f43" category="paragraph">Per l'alta disponibilità, la configurazione di SQL Server AOAG o Always on failover Cluster Instance (FCI) è l'opzione migliore. Per AOAG, questo comporta istanze multiple di SQL Server su macchine virtuali Azure in una rete virtuale. Se è richiesta una disponibilità elevata a livello di database, considerare la configurazione dei gruppi di disponibilità di SQL Server.</block>
  <block id="fa32aac4116ce1980c311f004157a133" category="paragraph">Microsoft SQL Server può essere implementato con una condivisione file SMB come opzione di storage. A partire da SQL Server 2012, database di sistema (master, modello, msdb o tempdb), Inoltre, i database degli utenti possono essere installati con il file server SMB (Server message Block) come opzione di storage. Questo vale sia per SQL Server standalone che per SQL Server FCI.</block>
  <block id="250548ef00796e6a203215b1d550bb0d" category="admonition">Lo storage di condivisione file per i database di SQL Server deve supportare proprietà a disponibilità continua. In questo modo si ottiene un accesso ininterrotto ai dati di file-share.</block>
  <block id="45a6af9c92529e3da9ccdbeae9d692ac" category="paragraph">Azure NetApp Files offre storage di file dalle performance elevate per soddisfare qualsiasi carico di lavoro impegnativo e riduce il TCO di SQL Server rispetto alle soluzioni di storage a blocchi. Con lo storage a blocchi, le macchine virtuali hanno imposto limiti di i/o e larghezza di banda per le operazioni su disco; i limiti di larghezza di banda della rete vengono applicati solo a fronte di Azure NetApp Files. In altre parole, non vengono applicati limiti di i/o a livello di macchina virtuale a Azure NetApp Files. Senza questi limiti di i/o, SQL Server in esecuzione su macchine virtuali più piccole collegate a Azure NetApp Files può funzionare e SQL Server in esecuzione su macchine virtuali molto più grandi. Azure NetApp Files riduce i costi di implementazione di SQL Server riducendo i costi di licenza software e di calcolo. Per un'analisi dettagliata dei costi e i vantaggi delle performance derivanti dall'utilizzo di Azure NetApp Files per la distribuzione di SQL Server, vedere<block ref="458fda910151e8d66385b2aabb6cd60e" category="inline-link-rx"></block>.</block>
  <block id="9d2b7eb8bc76e60b0d9cd237d67a34fb" category="paragraph">I vantaggi derivanti dall'utilizzo di Azure NetApp Files per SQL Server includono:</block>
  <block id="8ee22743237d82e9adc18a596977a138" category="list-text">L'utilizzo di Azure NetApp Files consente di utilizzare istanze più piccole, riducendo così i costi di calcolo.</block>
  <block id="3de639403ea86ae87a5883d359deb4ab" category="list-text">Azure NetApp Files riduce inoltre i costi di licenza del software, riducendo il TCO complessivo.</block>
  <block id="46790c8fe72176f6262b4b5531482ee5" category="list-text">La riformizzazione dei volumi e la funzionalità dinamica del livello di servizio ottimizzano i costi dimensionando i carichi di lavoro a stato stazionario ed evitando l'overprovisioning.</block>
  <block id="860d93b2ef30525111fa6440bf4d5bd7" category="list-text">Per aumentare la ridondanza e l'alta disponibilità, le VM di SQL Server devono essere uguali<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> o in modo diverso<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>. Prendere in considerazione i requisiti del percorso del file se sono necessari file di dati definiti dall'utente; in tal caso, selezionare SQL FCI su SQL AOAG.</block>
  <block id="c6fbfcd868e29e37e88eaeff82a7f430" category="inline-link">ANFSMB-b4ca.ANF.test SQLDB e ANFSMB-b4ca.ANF.test SQLDB</block>
  <block id="e2bed4e218692d056237b3ae3d24293c" category="list-text">È supportato il seguente percorso UNC:<block ref="cb8cdd6ee3ebeed12086142f1a66cc3e" category="inline-link-rx"></block>.</block>
  <block id="0b4d3828f5dae91cd27e48bffa786d91" category="list-text">Il percorso UNC di loopback non è supportato.</block>
  <block id="db3d2f4f54b992af225801eb51ea7387" category="list-text">Per il dimensionamento, utilizza i dati storici del tuo ambiente on-premise. Per i carichi di lavoro OLTP, abbina gli IOPS di destinazione con i requisiti di performance utilizzando carichi di lavoro a tempi medi e di picco, oltre ai contatori delle performance di lettura/sec dei dischi e di scritture/sec dei dischi. Per i carichi di lavoro di data warehouse e reporting, abbina il throughput di destinazione utilizzando carichi di lavoro a tempi medi e di picco e i byte di lettura del disco/sec e byte di scrittura del disco/sec. I valori medi possono essere utilizzati insieme alle funzionalità di risagomatura dei volumi.</block>
  <block id="da3259c6aa3dafdc8ca15c687022a5cd" category="section-title">Creare condivisioni continuamente disponibili</block>
  <block id="f7ee3eee4fa679986e37911272d13a29" category="inline-link">Creazione di una condivisione a disponibilità continua</block>
  <block id="de7d92d6f4ac1f140ac05886ec017f09" category="paragraph">Crea condivisioni continuamente disponibili con il portale Azure o Azure CLI. Nel portale, selezionare l'opzione della proprietà Enable Continuous Availability (attiva disponibilità continua). Per Azure CLI, specificare la condivisione come condivisione a disponibilità continua utilizzando<block ref="0be8c8a92e4fe4621be30aa11942bc4d" prefix=" " category="inline-code"></block> opzione impostata su<block ref="91da4c74e2fced40755d4d3997af3488" prefix=" " category="inline-code"></block>. Per ulteriori informazioni sulla creazione di un nuovo volume abilitato per la disponibilità continua, vedere<block ref="86e4b436e8054cc83fccec640f98e218" category="inline-link-rx"></block>.</block>
  <block id="9a3932b7bdfdbb892087fd595ec7acb9" category="list-text">Abilitare la disponibilità continua per il volume SMB come mostrato nell'immagine seguente.</block>
  <block id="c012fe8c05a3d9875a4f87cee09d1ca9" category="list-text">Se si utilizza un account di dominio non amministratore, assicurarsi che all'account sia stato assegnato il privilegio di protezione richiesto.</block>
  <block id="762783478495f0889d01a59db256f92c" category="list-text">Impostare le autorizzazioni appropriate a livello di condivisione e le autorizzazioni appropriate a livello di file.</block>
  <block id="bfb74db6a55528f52e8ecb83a507a043" category="inline-link">Converti i volumi SMB esistenti per utilizzare la disponibilità continua</block>
  <block id="3cad4a4fcd378074292bfc2ff45fd4ca" category="list-text">Non è possibile attivare una proprietà a disponibilità continua sui volumi SMB esistenti. Per convertire un volume esistente in modo da utilizzare una condivisione continuamente disponibile, utilizza la tecnologia NetApp Snapshot. Per ulteriori informazioni, vedere<block ref="25dc0603f84029cfd15a97a37903a54c" category="inline-link-rx"></block>.</block>
  <block id="015dd90c833178044ff327aee63f72ec" category="paragraph"><block ref="015dd90c833178044ff327aee63f72ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ee38206503545cf54ad072dee7f8ab1a" category="paragraph">Azure NetApp Files supporta tre livelli di servizio: Standard (16 Mbps per terabyte), Premium (64 MB per terabyte) e Ultra (128 MB per terabyte). Il provisioning delle giuste dimensioni del volume è importante per ottenere performance ottimali del carico di lavoro del database. Con Azure NetApp Files, le performance dei volumi e il limite di throughput si basano su una combinazione dei seguenti fattori:</block>
  <block id="b87f5218989e854f2889f939a4e2ec06" category="list-text">Il livello di servizio del pool di capacità a cui appartiene il volume</block>
  <block id="9320cce40e9ab4d677bfcc78eddc64d5" category="list-text">La quota assegnata al volume</block>
  <block id="2d98af90367bed299b95066a85be0a17" category="list-text">Il tipo di qualità del servizio (QoS) (automatico o manuale) del pool di capacità</block>
  <block id="a6f08c2897faaf4d449d71d87f473ff1" category="inline-link">Livelli di servizio per Azure NetApp Files</block>
  <block id="ac56170d8576092b90989d467f2d383e" category="paragraph">Per ulteriori informazioni, vedere<block ref="1e8ed0f384e427209ce2e9dfbaed249d" category="inline-link-rx"></block>.</block>
  <block id="79bcc7c0be7625b4b6b95ac8189ec45e" category="paragraph"><block ref="79bcc7c0be7625b4b6b95ac8189ec45e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">Convalida delle performance</block>
  <block id="af3948d0fe6860f3a865cd04abebc009" category="inline-link">Tool di benchmark dello storage (SB) di SQL Server</block>
  <block id="01384acc34d886b9383610a7494ca75a" category="paragraph">Come per qualsiasi implementazione, il test della macchina virtuale e dello storage è fondamentale. Per la convalida dello storage, strumenti come HammerDB, Apploader,<block ref="df8d6ca8d2831e94c0812b2b971f8958" category="inline-link-rx"></block>, O qualsiasi script personalizzato o FIO con il mix di lettura/scrittura appropriato. Tenere presente tuttavia che la maggior parte dei carichi di lavoro di SQL Server, anche i carichi di lavoro OLTP occupati, sono più vicini al 80%-90% in lettura e al 10%-20% in scrittura.</block>
  <block id="10fde396dd4a669ec17689dd7cf8b599" category="paragraph">Per mostrare le performance, è stato eseguito un rapido test su un volume utilizzando livelli di servizio premium. In questo test, le dimensioni del volume sono state aumentate da 100 GB a 2 TB in tempo reale senza alcuna interruzione dell'accesso alle applicazioni e senza alcuna migrazione dei dati.</block>
  <block id="6fab14b7b6a90422e865a3b09497edaa" category="paragraph"><block ref="6fab14b7b6a90422e865a3b09497edaa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eedfe317eed7692e9d95ba36177a80e9" category="paragraph">Ecco un altro esempio di test delle performance in tempo reale con HammerDB eseguito per l'implementazione trattata in questo documento. Per questo test, abbiamo utilizzato una piccola istanza con otto vCPU, un SSD Premium da 500 GB e un volume Azure NetApp Files SMB da 500 GB. HammerDB è stato configurato con 80 warehouse e otto utenti.</block>
  <block id="c365893719ad3de45f14fa9c19408eca" category="paragraph">Il grafico seguente mostra che Azure NetApp Files è stato in grado di offrire un numero di transazioni al minuto 2,6 volte superiore con una latenza 4 volte inferiore quando si utilizza un volume di dimensioni paragonabili (500 GB).</block>
  <block id="d50d666921da97fdc14e35f752474e41" category="paragraph">Un test aggiuntivo è stato eseguito ridimensionando in un'istanza più grande con 32x vCPU e un volume Azure NetApp Files da 16 TB. Si è verificato un aumento significativo delle transazioni al minuto con una latenza costante di 1 ms. HammerDB è stato configurato con 80 warehouse e 64 utenti per questo test.</block>
  <block id="3b38e0407e747349840c72259c5da930" category="paragraph"><block ref="3b38e0407e747349840c72259c5da930" category="inline-image-macro-rx" type="image"></block></block>
  <block id="892725223bbd64ebec595545eeaf8c28" category="paragraph">Azure NetApp Files consente di ridimensionare il volume in modo trasparente e senza interruzioni e di modificare i livelli di servizio senza downtime e senza alcun effetto sulle applicazioni. Si tratta di una funzionalità unica che consente una gestione dinamica dei costi che evita la necessità di eseguire il dimensionamento del database con metriche di picco. Puoi invece utilizzare carichi di lavoro a stato stazionario, evitando i costi iniziali. La risagomatura del volume e la modifica dinamica del livello di servizio consentono di regolare la larghezza di banda e il livello di servizio dei volumi Azure NetApp Files on-demand quasi istantaneamente senza interrompere l'i/o, mantenendo al contempo l'accesso ai dati.</block>
  <block id="44aaafbc17f2a4fcbd6d52e1c8ee0cae" category="paragraph">Le offerte PaaS di Azure, come LogicApp o le funzioni, possono essere utilizzate per ridimensionare facilmente il volume in base a un webhook specifico o a un trigger di regola di avviso per soddisfare le esigenze dei carichi di lavoro gestendo dinamicamente i costi.</block>
  <block id="d613d5e1ef7a7f52eed191ef1066a08a" category="paragraph">Ad esempio, si consideri un database che richiede 250 MBps per il funzionamento a stato stazionario; tuttavia, richiede anche un throughput di picco di 400 Mbps. In questo caso, l'implementazione deve essere eseguita con un volume da 4 TB all'interno del livello di servizio Premium per soddisfare i requisiti di performance stazionario. Per gestire il carico di lavoro di picco, aumentare le dimensioni del volume utilizzando le funzioni di Azure fino a 7 TB per quel periodo specifico, quindi ridurre il volume per rendere l'implementazione conveniente. Questa configurazione evita l'overprovisioning dello storage.</block>
  <block id="80d1c0ba73b8e2e8e0f305b42a776a1f" category="summary">La soluzione offre una panoramica e dettagli sull'implementazione e la protezione del database Oracle nello storage AWS FSX ONTAP e nell'istanza di calcolo EC2 con protocollo NFS e database Oracle configurati in riavvio standalone utilizzando asm come gestore di volume.</block>
  <block id="7e6f7643afec42d9c47efa933debef3e" category="paragraph">Allen Cao, Niyaz Mohamed, NetApp</block>
  <block id="418241bdca49e4aec92c0ff810e8e099" category="paragraph">ASM (Automatic Storage Management) è un noto gestore di volumi di storage Oracle utilizzato in molte installazioni Oracle. È anche la soluzione di gestione dello storage consigliata da Oracle. Offre un'alternativa ai tradizionali file system e ai volumi manager. A partire dalla versione 11g di Oracle, ASM è stato impacchettato con un'infrastruttura grid piuttosto che con un database. Di conseguenza, per utilizzare Oracle ASM per la gestione dello storage senza RAC, è necessario installare l'infrastruttura Oracle Grid in un server standalone, noto anche come Oracle Restart. In questo modo si aggiunge sicuramente una maggiore complessità in un'implementazione del database Oracle altrimenti più semplice. Tuttavia, come suggerisce il nome, quando Oracle viene implementato in modalità di riavvio, tutti i servizi Oracle guasti vengono riavviati dopo un riavvio dell'host senza l'intervento dell'utente, che fornisce un certo grado di alta disponibilità o funzionalità ha.</block>
  <block id="9c0bba5590ee70c0f934655cb253d4dd" category="paragraph">Oracle ASM viene generalmente implementato in FC, protocolli di storage iSCSI e lun come dispositivi di storage raw. Tuttavia, Oracle supporta anche la configurazione del protocollo ASM su NFS e del file system NFS. In questa documentazione, dimostreremo come implementare un database Oracle 19c con il protocollo NFS e Oracle ASM in un ambiente di storage Amazon FSX per ONTAP con istanze di calcolo EC2. Inoltre, dimostreremo come utilizzare il servizio NetApp SnapCenter attraverso la console NetApp BlueXP per eseguire il backup, il ripristino e la clonazione del database Oracle per lo sviluppo/test o altri casi di utilizzo per un funzionamento efficiente dello storage del database nel cloud pubblico AWS.</block>
  <block id="e60de72a8067fd05498b03b24d9f93e7" category="paragraph">Questa soluzione risolve i seguenti casi di utilizzo:</block>
  <block id="d8c9422483ecfd8d391fbc179e1ff90f" category="list-text">Implementazione di database Oracle in Amazon FSX per storage ONTAP e istanze di calcolo EC2 con NFS/ASM</block>
  <block id="86e62b62bb73c1d45af1018c5f546fa2" category="list-text">Test e convalida di un carico di lavoro Oracle nel cloud pubblico AWS con NFS/ASM</block>
  <block id="7776a288eb4d92068f227343e40955be" category="list-text">Test e convalida delle funzionalità di riavvio del database Oracle implementate in AWS</block>
  <block id="ef1e6887c579ba81dcedc3f4e3793cd2" category="section-title">Pubblico</block>
  <block id="82aa3e78c2089a2941fb745bb8c72f01" category="paragraph">Questa soluzione è destinata alle seguenti persone:</block>
  <block id="b1868e5a46a34f2e4894103a18fa6e75" category="list-text">Un DBA che desidera implementare Oracle in un cloud pubblico AWS con NFS/ASM.</block>
  <block id="53a21d50adb7cce93e4304c816d40c51" category="list-text">Un architetto di soluzioni di database che desidera testare i carichi di lavoro Oracle nel cloud pubblico AWS.</block>
  <block id="b316baf0d21d8e459e4220a2cf5102a5" category="list-text">L'amministratore dello storage che desidera implementare e gestire un database Oracle implementato nello storage AWS FSX.</block>
  <block id="6b41622d6a121d89a6342fe9ff47665c" category="list-text">Il proprietario dell'applicazione che desidera creare un database Oracle in AWS FSX/EC2.</block>
  <block id="d17a638ff086388dc5bfbe98528ccfab" category="section-title">Ambiente di test e convalida della soluzione</block>
  <block id="863fb5b3a3b3b63b57a387bab70de0a9" category="paragraph">Il test e la convalida di questa soluzione sono stati eseguiti in un ambiente AWS FSX e EC2 che potrebbe non corrispondere all'ambiente di implementazione finale. Per ulteriori informazioni, vedere la sezione <block ref="8ea96e516bccf9a47ca2d74131eb7519" category="inline-xref-macro-rx"></block>.</block>
  <block id="60eafe38e4de145948f4622ffcf3fecf" category="image-alt">Questa immagine fornisce un quadro dettagliato della configurazione di implementazione di Oracle nel cloud pubblico AWS con iSCSI e ASM.</block>
  <block id="34d0b9b49aa480630e91a3619ba7ffb2" category="section-title">Componenti hardware e software</block>
  <block id="958c530ea1ae0e18b942f8784148734c" category="cell">*Hardware*</block>
  <block id="a09dc18a1bff4fa8388afca4627d0911" category="cell">Storage FSX ONTAP</block>
  <block id="f90fb2d1bd04ce25f4b6a79bead231a3" category="cell">Versione corrente offerta da AWS</block>
  <block id="ceafc9f8393b625e8cce03cbeba6e867" category="cell">Un cluster FSX ha nello stesso VPC e nella stessa zona di disponibilità</block>
  <block id="6a79356b19d3b59e92b358357c5b9053" category="cell">Istanza EC2 per il calcolo</block>
  <block id="cc4def82629f09f253176dba801a85f0" category="cell">t2.xlarge/4vCPU/16G</block>
  <block id="0fcdacbce30d770260160f025dfa97ef" category="cell">Due istanze EC2 T2 xlarge EC2, una come server DB primario e l'altra come server DB clone</block>
  <block id="7eef23b11d6e87eee968a9bef33fd707" category="cell">*Software*</block>
  <block id="8b56d55f3caeb71ab2513c28fb1a52fc" category="cell">RedHat Linux</block>
  <block id="52359c9653f33c68cd1b454f7d05a27b" category="cell">RHEL-8.6.0_HVM-20220503-x86_64-2-Hourly2-GP2</block>
  <block id="fe6120dacb84838d71b1f43da1a3a514" category="cell">Implementazione dell'abbonamento a RedHat per il test</block>
  <block id="357401b243915afd7226703258f54f69" category="cell">Oracle Grid Infrastructure</block>
  <block id="8cbabca4a2c1b4268e8c216b1710182d" category="cell">Versione 19.18</block>
  <block id="4cd47afc935feac95110477afb324f6f" category="cell">Patch RU applicata p34762026_190000_Linux-x86-64.zip</block>
  <block id="a7c40910ade029baa6baa8b8e613db65" category="cell">Patch RU applicata p34765931_190000_Linux-x86-64.zip</block>
  <block id="a8b401bad03767cc28230a30d6556c5b" category="cell">Oracle OPatch</block>
  <block id="cc61533b1a42263eaadfd935441bb4b5" category="cell">Versione 12.2.0.1.36</block>
  <block id="8091f15fd8b9f1a609b3a98e8bcdda81" category="cell">Ultima patch p6880880_190000_Linux-x86-64.zip</block>
  <block id="fed6fa1f1b675c268f8b78258e2545a7" category="cell">Servizio SnapCenter</block>
  <block id="313d712dbc391a0b9d6dca3efe0d2608" category="cell">v2.3.1.2324</block>
  <block id="cd1aedf83959dd52fc058b9120f500e3" category="section-title">Fattori chiave per l'implementazione</block>
  <block id="b1a9b82f5c1b9e62aff87e622f684e76" category="list-text">*Istanze di calcolo EC2.* in questi test e convalide, abbiamo utilizzato un tipo di istanza AWS EC2 t2.xlarge per l'istanza di calcolo del database Oracle. NetApp consiglia di utilizzare un'istanza EC2 di tipo M5 come istanza di calcolo per Oracle nell'implementazione in produzione, poiché è ottimizzata per i carichi di lavoro del database. È necessario dimensionare l'istanza EC2 in modo appropriato in base al numero di vCPU e alla quantità di RAM in base ai requisiti effettivi del carico di lavoro.</block>
  <block id="11a64b78983fb952ba99933c98fc56df" category="list-text">*Implementazione di cluster ha storage FSX a singola o multi-zona.* in questi test e convalide, abbiamo implementato un cluster ha FSX in una singola zona di disponibilità AWS. Per l'implementazione in produzione, NetApp consiglia di implementare una coppia FSX ha in due diverse zone di disponibilità. Un cluster FSX ha viene fornito in maniera ininterrotta in una coppia ha con mirroring sincronizzato in una coppia di file system Active-passive per fornire ridondanza a livello di storage. L'implementazione multi-zona migliora ulteriormente l'alta disponibilità in caso di guasto in una singola zona AWS.</block>
  <block id="660a107d1d4a80542a6c11d9a1ed2db4" category="list-text">*Dimensionamento del cluster di storage FSX.* un file system di storage Amazon FSX per ONTAP fornisce fino a 160,000 IOPS SSD raw, throughput fino a 4 Gbps e una capacità massima di 192 TiB. Tuttavia, è possibile dimensionare il cluster in termini di IOPS con provisioning, throughput e limite di storage (minimo 1,024 GiB) in base ai requisiti effettivi al momento dell'implementazione. La capacità può essere regolata dinamicamente in tempo reale senza influire sulla disponibilità delle applicazioni.</block>
  <block id="6e5a8ef13e1f2826df29bb4025ed6544" category="list-text">*Layout dei dati e dei registri Oracle.* nei nostri test e convalide, abbiamo implementato due gruppi di dischi ASM rispettivamente per dati e registri. All'interno del gruppo di dischi asm +DATA, abbiamo eseguito il provisioning di quattro dischi in un punto di montaggio del file system NFS dati. All'interno del gruppo di dischi asm +LOGS, abbiamo eseguito il provisioning di due dischi in un punto di montaggio del file system NFS logs. Per l'implementazione di database di grandi dimensioni, è possibile creare gruppi di dischi ASM in modo che si estendano a più file system FSX con dischi NFS ASM distribuiti attraverso diversi punti di montaggio NFS ancorati ai file system FSX. Questa particolare configurazione è progettata per soddisfare il throughput del database con un throughput di 4 Gbps e il requisito di 160,000 IOPS SSD raw.</block>
  <block id="e2d21e7b1ae9a8e7d20087f0084bf01a" category="list-text">*Configurazione DNFS.* DNFS è integrato nel kernel Oracle e, quando Oracle viene distribuito sullo storage NFS, aumenta notevolmente le performance del database Oracle. DNFS viene inserito in un pacchetto binario Oracle, ma non viene attivato per impostazione predefinita. Deve essere attivato per qualsiasi implementazione di database Oracle su NFS. Per l'implementazione di più file system FSX per database di grandi dimensioni, è necessario configurare correttamente il percorso multiplo DNFS.</block>
  <block id="bc229d9916fc3cb8de0f67f3e5d86528" category="list-text">*Livello di ridondanza Oracle ASM da utilizzare per ciascun gruppo di dischi Oracle ASM creato.* poiché FSX esegue già il mirroring dello storage a livello di cluster FSX, è necessario<block ref="7ea763007de155a1d5ac7192d220c274" prefix=" " category="inline-code"></block> Utilizza ridondanza esterna, il che significa che l'opzione non consente a Oracle ASM di eseguire il mirroring del contenuto del gruppo di dischi. Ciò è particolarmente importante in quanto NFS per lo storage dei dati del database Oracle richiede un'opzione DI montaggio NFS RIGIDA, CHE NON è consigliabile per il mirroring dei contenuti ASM a livello Oracle.</block>
  <block id="e35fd1c687443b2da6a609bba53616b4" category="list-text">*Backup del database.* NetApp fornisce una versione SaaS del servizio software SnapCenter per il backup, il ripristino e il cloning del database nel cloud, disponibile tramite l'interfaccia utente della console NetApp BlueXP. NetApp consiglia di implementare un servizio di questo tipo per ottenere backup snapshot rapidi (in meno di un minuto), ripristino rapido (in pochi minuti) del database e cloning del database.</block>
  <block id="77e4d80ae2f4257081e17476b146608a" category="section-title">Implementazione della soluzione</block>
  <block id="2398118900b3388f97d9931571f1bbda" category="paragraph">La sezione seguente fornisce le procedure di implementazione passo-passo.</block>
  <block id="782bd8949cb40c80fd3f3126eccab35a" category="section-title">Prerequisiti per l'implementazione</block>
  <block id="fd10b9eacfe4eed8040bda8cae9ea050" category="paragraph">L'implementazione richiede i seguenti prerequisiti.</block>
  <block id="e7491272f69c8efda69a595782f44d45" category="list-text">È stato impostato un account AWS e sono stati creati i segmenti VPC e di rete necessari all'interno dell'account AWS.</block>
  <block id="f71558e9ad22e37a70099d8b5d8ac06c" category="inline-link-macro">Guida utente per istanze Linux</block>
  <block id="2cb106b524fea2beb3ee19372f04427b" category="list-text">Dalla console AWS EC2, è necessario implementare due istanze EC2 Linux, una come server Oracle DB primario e un server DB di destinazione clone alternativo opzionale. Per ulteriori informazioni sulla configurazione dell'ambiente, vedere il diagramma dell'architettura nella sezione precedente. Esaminare anche il <block ref="b75ecbbec453f67f58d497ccd97a8075" category="inline-link-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="3560913f6885261f7b64e7cfeea69eab" category="inline-link-macro">Creazione di FSX per file system ONTAP</block>
  <block id="11f86864c5928690c88625e77eb1a480" category="list-text">Dalla console AWS EC2, implementare Amazon FSX per cluster ha di storage ONTAP per ospitare i volumi di database Oracle. Se non si ha familiarità con l'implementazione dello storage FSX, consultare la documentazione <block ref="17d8b312d287f0afd6f44b3f25c4f20b" category="inline-link-macro-rx"></block> per istruzioni dettagliate.</block>
  <block id="dd303169f721e79331b3683ddafddcc1" category="list-text">I passaggi 2 e 3 possono essere eseguiti utilizzando il seguente toolkit di automazione Terraform, che crea un'istanza EC2 denominata<block ref="460dc55b5ffb0266f2c889b06ee73344" prefix=" " category="inline-code"></block> E un file system FSX denominato<block ref="8cbb7b3050d3c3aa08a529f429bc4555" prefix=" " category="inline-code"></block>. Prima dell'esecuzione, rivedere attentamente le istruzioni e modificare le variabili in base all'ambiente in uso.</block>
  <block id="0f7a8130eb652cd33a4fa9cdefc41cc6" category="admonition">Assicurarsi di aver allocato almeno 50 G nel volume root dell'istanza EC2 per avere spazio sufficiente per la fase dei file di installazione Oracle.</block>
  <block id="62ee860e3d0c08c6573d2e328543e8de" category="section-title">Configurazione del kernel dell'istanza EC2</block>
  <block id="f352a88dccea452ec98375dda0311257" category="paragraph">Con i prerequisiti forniti, accedere all'istanza EC2 come ec2-user e sudo to root user per configurare il kernel Linux per l'installazione di Oracle.</block>
  <block id="5a8cdca62a149c76be848350ba5cbfd0" category="list-text">Creare una directory di staging<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> e impostare<block ref="f1c1592588411002af340cbaedd6fc33" prefix=" " category="inline-code"></block> permesso.</block>
  <block id="e252f38e51fe6c121fdf68268f7365b7" category="list-text">Scaricare e preparare i file di installazione binari Oracle e gli altri file rpm richiesti su<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> directory.</block>
  <block id="2463a0e4e0f5e0cae480165d25c3d218" category="paragraph">Consultare il seguente elenco di file di installazione da indicare in<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> Sull'istanza EC2.</block>
  <block id="7b25ef659963c88fe23b78fc4712aabf" category="list-text">Installare Oracle 19c preinstallare RPM, che soddisfa la maggior parte dei requisiti di configurazione del kernel.</block>
  <block id="1527576f8dc9eea4d63eb05b809aaa52" category="list-text">Scaricare e installare il file mancante<block ref="d2e5af6ee2b267de9dac1b472a03adf3" prefix=" " category="inline-code"></block> In Linux 8.</block>
  <block id="b2371ec5566671ad5a4ad4a5ea6cba11" category="list-text">Da NetApp, scaricare e installare le utility host di NetApp.</block>
  <block id="b6e7702627b94eaa3030b577d6d705bc" category="list-text">Installare<block ref="c8dff58175a7ddfedf00d77953ef42dd" prefix=" " category="inline-code"></block>, Non disponibile nell'istanza EC2.</block>
  <block id="9a16a877dc258dab15fccea468433118" category="list-text">Installare la versione 1.8 di JDK aperta.</block>
  <block id="d953285f2eeac9b2766ac055d81bf48a" category="list-text">Installare nfs-utils.</block>
  <block id="8d5128c24aba40267289419650d61baf" category="list-text">Disattiva gli hugepage trasparenti nel sistema corrente.</block>
  <block id="0410d25eb8075ef0d6eb88ced58d20d0" category="paragraph">Aggiungere le seguenti righe in<block ref="08561da4afe8299be4016c92bfe83435" prefix=" " category="inline-code"></block> per disattivare<block ref="d78ade61a64b6a278ed6278e7cfd91f3" prefix=" " category="inline-code"></block> dopo il riavvio:</block>
  <block id="ac762383bc7427decd2147abbadaccaa" category="list-text">Disattiva selinux cambiando<block ref="cb42f4736bc8f64983eeffc1e0b4f44a" prefix=" " category="inline-code"></block> a.<block ref="52647e37ec523adfcaa3fec9bcef128e" prefix=" " category="inline-code"></block>. Per rendere effettiva la modifica, è necessario riavviare l'host.</block>
  <block id="2d1601e142ebdb74931ee9a254b65262" category="list-text">Aggiungere le seguenti righe a.<block ref="8b5eec1c5f63341b700263cc37cbae02" prefix=" " category="inline-code"></block> per impostare il limite del descrittore di file e la dimensione dello stack senza virgolette<block ref="fcc3d7489d15ef49dbbf735234234cf7" prefix=" " category="inline-code"></block>.</block>
  <block id="03c10a897f1e18c6adaea250b9f30f19" category="inline-link-macro">Come si alloca la memoria per lavorare come spazio di swap in un'istanza Amazon EC2 utilizzando un file di swap?</block>
  <block id="410eaf64cdfb52cb0921ea732490d0db" category="list-text">Aggiungere spazio di swap all'istanza EC2 seguendo questa istruzione: <block ref="53c9867a131506eab4afe1a1678bb974" category="inline-link-macro-rx"></block> La quantità esatta di spazio da aggiungere dipende dalle dimensioni della RAM fino a 16 G.</block>
  <block id="d5dbcd1ace089fec7f75fa03e884cb93" category="list-text">Aggiungere il gruppo ASM da utilizzare per il gruppo sysasm asm</block>
  <block id="f7b4c2e912a168f005ed7cc2b4799c08" category="list-text">Modificare l'utente oracle per aggiungere ASM come gruppo secondario (l'utente oracle dovrebbe essere stato creato dopo l'installazione di RPM preinstallata da Oracle).</block>
  <block id="8d3a75a7cdef66372dcf58e6278bba70" category="list-text">Riavviare l'istanza EC2.</block>
  <block id="04c0abfa4d590dbcf8140c900090b7d4" category="section-title">Provisioning ed esportazione di volumi NFS da montare sull'host dell'istanza EC2</block>
  <block id="35e176617d52dd956b8015d8ca19c32d" category="paragraph">Provisioning di tre volumi dalla riga di comando tramite login al cluster FSX tramite ssh come utente fsxadmin con IP di gestione del cluster FSX per ospitare file binari, dati e log del database Oracle.</block>
  <block id="c848cfd9c04d86e7b9919e11add79f6c" category="list-text">Accedere al cluster FSX tramite SSH come utente fsxadmin.</block>
  <block id="eff24d82c422927b06fd0cacd430b653" category="list-text">Eseguire il seguente comando per creare un volume per il binario Oracle.</block>
  <block id="569cffa50e6428a06bffa2e19d12e0e3" category="list-text">Eseguire il seguente comando per creare un volume per i dati Oracle.</block>
  <block id="9985026df910c788cb47555f7d72a68e" category="list-text">Eseguire il seguente comando per creare un volume per i registri Oracle.</block>
  <block id="a245b068ccb33c4feb57be67c4c4929e" category="list-text">Convalidare i volumi DB creati.</block>
  <block id="3208f25d37711dd9ffc43d93ada2a3cc" category="paragraph">Si prevede che ciò restituisca:</block>
  <block id="35c1914e41e83f92dd8779f5708f3224" category="section-title">Configurazione dello storage del database</block>
  <block id="47d78479fc855bd2f99f02fb94118789" category="paragraph">A questo punto, importare e configurare lo storage FSX per l'infrastruttura grid Oracle e l'installazione del database sull'host dell'istanza EC2.</block>
  <block id="aa218771b85a8ecc41cc249ba90ea5f8" category="list-text">Accedere all'istanza EC2 tramite SSH come ec2-user con la chiave SSH e l'indirizzo IP dell'istanza EC2.</block>
  <block id="f6a4694211343b15651db8fdd5f16222" category="list-text">Creare la directory /u01 per montare il file system binario Oracle</block>
  <block id="aabf104e3877a3141576892889ebcfd2" category="list-text">Montare il volume binario su<block ref="a8946fa5f211c5345e3610710e471cb4" prefix=" " category="inline-code"></block>, Modificato con l'indirizzo IP LIF NFS FSX. Se hai implementato il cluster FSX tramite il toolkit di automazione NetApp, l'indirizzo IP lif NFS del server di storage virtuale FSX verrà elencato nell'output alla fine dell'esecuzione del provisioning delle risorse. In caso contrario, può essere recuperato dall'interfaccia utente della console AWS FSX.</block>
  <block id="6dc5f678e8b8446afe039edff2864ef0" category="list-text">Cambiare<block ref="a8946fa5f211c5345e3610710e471cb4" prefix=" " category="inline-code"></block> Montare la proprietà dei punti all'utente Oracle e al gruppo primario associato.</block>
  <block id="6e5bf17d6cb7ff829494e09654c5fdc2" category="list-text">Creare la directory /oradata per montare il file system di dati Oracle</block>
  <block id="41096b5d68af7d413deac705db2e3bab" category="list-text">Montare il volume di dati su<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block>, Modificato con l'indirizzo IP LIF NFS FSX</block>
  <block id="90231d3bb492c7fb529e3500cdcef778" category="list-text">Cambiare<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> Montare la proprietà dei punti all'utente Oracle e al gruppo primario associato.</block>
  <block id="fbe05a889a0659f00644b0c25e984066" category="list-text">Creare la directory /oralogs per montare il file system Oracle logs</block>
  <block id="0e94479bef4fdce94a31a913e4a90ea4" category="list-text">Montare il volume di log su<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block>, Modificato con l'indirizzo IP LIF NFS FSX</block>
  <block id="cd48bd706e8c70912f675dc9f17a75be" category="list-text">Cambiare<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block> Montare la proprietà dei punti all'utente Oracle e al gruppo primario associato.</block>
  <block id="419b15da0e06224d0919aaf7cf7c0394" category="list-text">Aggiungere un punto di montaggio a.<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block>.</block>
  <block id="4f86d8e0be25b09fa4c4f087139fcd0d" category="paragraph">Aggiungere la seguente riga.</block>
  <block id="06b5412c6ada2efb7e05e7a7454e34df" category="list-text">sudo per l'utente oracle, creare cartelle asm per memorizzare i file di disco asm</block>
  <block id="f6ebe7eea328062998e8b597d1de48e4" category="list-text">In qualità di utente oracle, creare file di dischi dati asm e modificare il numero in modo che corrisponda alle dimensioni del disco con le dimensioni del blocco.</block>
  <block id="3abcbe76f32bdac63b7e132c5d06ccb4" category="list-text">Come utente root, modificare l'autorizzazione del file del disco dati su 640</block>
  <block id="9b424f5bec397927a45cc70947221c7d" category="list-text">IN QUALITÀ di utente oracle, creare file di dischi di log asm, modificarli in Conteggio in modo che corrispondano alle dimensioni del disco con le dimensioni del blocco.</block>
  <block id="dbd66f2c49aae90d1e55e84df32a83da" category="list-text">In qualità di utente root, modificare l'autorizzazione del file del disco di log in 640</block>
  <block id="71d434c6aec8c195bc1cd610cf2aadf7" category="list-text">Riavviare l'host dell'istanza EC2.</block>
  <block id="3cadabe14e57cb049891c97e754906d7" category="section-title">Installazione dell'infrastruttura grid Oracle</block>
  <block id="2ba967266d1ac37f6ee2c138c7a219f1" category="list-text">Accedere all'istanza EC2 come ec2-user tramite SSH e abilitare l'autenticazione della password senza commenti<block ref="cd94e87e5216cd088acdc4de0e9c30f1" prefix=" " category="inline-code"></block> e poi commentando<block ref="f18918133cfc22e041baab71b051c41f" prefix=" " category="inline-code"></block>.</block>
  <block id="f919e378a236907726426311e1222ca5" category="list-text">Riavviare il servizio sshd.</block>
  <block id="886890ea240491bd5c7fbf2ad26038e0" category="list-text">Reimpostare la password utente Oracle.</block>
  <block id="312dbdb4917346c5535b58edeb72d5d8" category="list-text">Accedere come utente proprietario del software Oracle Restart (oracle). Creare una directory Oracle come segue:</block>
  <block id="2fce107e9da63a27050a1b7738518797" category="list-text">Modificare l'impostazione delle autorizzazioni per la directory.</block>
  <block id="de76f7d30e13c7b0fac443a1b582500b" category="list-text">Creare una home directory grid e modificarla.</block>
  <block id="ca3eab9cf7a8f03f19d82f95a9ccebc0" category="list-text">Decomprimere i file di installazione della griglia.</block>
  <block id="4cb0c768cefd4361adc66dd3dfac2ad8" category="list-text">Dalla pagina iniziale della griglia, eliminare<block ref="29b6fb214b3224ca10c7261aa01e44b5" prefix=" " category="inline-code"></block> directory.</block>
  <block id="572656c141066b10c23d5205e70be53b" category="list-text">Dalla pagina iniziale della griglia, copia<block ref="63628571f2dfaeb6f0a0a676290e6e82" prefix=" " category="inline-code"></block> a grid_home, quindi decomprimerlo.</block>
  <block id="5d940bd40ee32694345bce5774d5c678" category="list-text">Da Grid home, revisionare<block ref="ef8657f0a0a00af93ba7f1c8885339ca" prefix=" " category="inline-code"></block>, annullare il commento e sostituire<block ref="bb7738211dd8eb3dbadf4cc63ae8eb8a" prefix=" " category="inline-code"></block> con<block ref="b2affc1a941fe7e5e65933911250249c" prefix=" " category="inline-code"></block>.</block>
  <block id="e4dae708382daa7f76913b9e5b686a1c" category="list-text">Preparare un<block ref="77d9f4d56c58834c8dacf6d0cb94e085" prefix=" " category="inline-code"></block> file per l'installazione automatica e inserire il file rsp in<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> directory. Il file rsp deve riguardare le sezioni A, B e G con le seguenti informazioni:</block>
  <block id="196c642f2925757377d21779d79ba748" category="list-text">Accedere all'istanza EC2 come utente root.</block>
  <block id="3e6c5f0c8e9c1310879c66839bb0f8d5" category="list-text">Installare<block ref="a27b4e2b8f4a0b0419894dfeac36419e" prefix=" " category="inline-code"></block>.</block>
  <block id="9817d9ff96af960709b8094b73294545" category="list-text">Accedere all'istanza EC2 come utente Oracle ed estrarre la patch in<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> cartella.</block>
  <block id="5fa683f35265bf7469d9de8c3afc1f42" category="list-text">Da Grid home /u01/app/oracle/product/19.0.0/grid e in qualità di utente oracle, avviare<block ref="30c950549715985c6b7c7cd6990d0f4b" prefix=" " category="inline-code"></block> per l'installazione dell'infrastruttura grid.</block>
  <block id="5de6732dda1e7bccbd8e8b367ad248dd" category="paragraph">Ignorare gli avvisi relativi ai gruppi errati per l'infrastruttura grid. Stiamo utilizzando un singolo utente Oracle per gestire Oracle Restart, quindi questo è previsto.</block>
  <block id="26f36488ec442bab2ba0cda087d435eb" category="list-text">Come utente root, eseguire i seguenti script:</block>
  <block id="7dff0a250c79eafa071ee2d5713b7123" category="list-text">In qualità di utente Oracle, eseguire il seguente comando per completare la configurazione:</block>
  <block id="3f2a67de0c5824d878c62c0bc347e09b" category="list-text">In qualità di utente Oracle, creare il gruppo di dischi DEI LOG.</block>
  <block id="f71fbb7ff86224d636aac5f9bb42f27d" category="list-text">In qualità di utente Oracle, convalidare i servizi Grid dopo la configurazione dell'installazione.</block>
  <block id="b7e3e332087b6a041c83ce22cce9043c" category="section-title">Installazione del database Oracle</block>
  <block id="9250c441cd32cef9ac89c4aaea3311e2" category="list-text">Accedere come utente Oracle e annullare l'impostazione<block ref="88ee3ad336791517a935931e1e50382a" prefix=" " category="inline-code"></block> e.<block ref="1548c2f12948ef1485a923f5891a3489" prefix=" " category="inline-code"></block> se è impostato.</block>
  <block id="9c1b98a904b357f470c8d87cf837d8cf" category="list-text">Creare la home directory Oracle DB e modificarla.</block>
  <block id="74d5f0f080c7e7c4f0011e6b16a1072f" category="list-text">Decomprimere i file di installazione di Oracle DB.</block>
  <block id="1fdd02c9779c06712368af7ed65c00dd" category="list-text">Dalla home page del database, eliminare<block ref="29b6fb214b3224ca10c7261aa01e44b5" prefix=" " category="inline-code"></block> directory.</block>
  <block id="948ac6ddaa5b19c62366a04abf60547d" category="list-text">Da DB home, copia<block ref="63628571f2dfaeb6f0a0a676290e6e82" prefix=" " category="inline-code"></block> a.<block ref="22f5bd75d60d3065afc99a50bc98d9ae" prefix=" " category="inline-code"></block>e quindi decomprimerlo.</block>
  <block id="d86c0eec890e4216540c2b834f6339f5" category="list-text">Da DB home, revisionare<block ref="ef8657f0a0a00af93ba7f1c8885339ca" prefix=" " category="inline-code"></block>, e rimuovere i commenti e sostituire<block ref="bb7738211dd8eb3dbadf4cc63ae8eb8a" prefix=" " category="inline-code"></block> con<block ref="b2affc1a941fe7e5e65933911250249c" prefix=" " category="inline-code"></block>.</block>
  <block id="95233719931805924ded9cd671e036df" category="list-text">Dal<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> Decomprimere la patch DB 19.18 RU.</block>
  <block id="0181cf4258f052eaf2d48f78cd4fed7b" category="list-text">Preparare il file rsp di installazione automatica del DB in<block ref="2d9ffa0a3db25b02bcd0091245449764" prefix=" " category="inline-code"></block> directory con i seguenti valori:</block>
  <block id="bdae34f2df30f19488bd87890188b905" category="list-text">Da db1 home /u01/app/oracle/product/19.0.0/db1, eseguire l'installazione automatica del DB solo software.</block>
  <block id="f9db0d5335309d4958e09e8149d7de4d" category="list-text">Come utente root, eseguire<block ref="08030ad08b2b991d61b424afd8828758" prefix=" " category="inline-code"></block> script dopo l'installazione solo software.</block>
  <block id="2bba715ff3b85da75ce86da55f5d9173" category="list-text">In qualità di utente Oracle, creare il<block ref="c170c347c737b82ad62c48db1f7bff3c" prefix=" " category="inline-code"></block> file con le seguenti voci:</block>
  <block id="a6774a54a715f893108bd2d2bc05062e" category="admonition">Impostare la memoria totale in base alla memoria disponibile nell'host dell'istanza EC2. Oracle alloca il 75% di<block ref="834709f36a11a38a80fe0dc57054ec20" prefix=" " category="inline-code"></block> Alla SGA dell'istanza del DB o alla cache del buffer.</block>
  <block id="c96739fe831515243fc940e9ee867ea3" category="list-text">In qualità di utente Oracle, Lauch DB Creation with dbca.</block>
  <block id="2a00dbe4c39e81805212ab123d0995df" category="list-text">In qualità di utente Oracle, convalidare i servizi Oracle Restart ha dopo la creazione del DB.</block>
  <block id="05472424b7ce7bd118009f6cde3a0614" category="list-text">Impostare l'utente Oracle<block ref="9e0037ad71166970bde5f910189cc94a" prefix=" " category="inline-code"></block>.</block>
  <block id="cadaa91ab9001028d3a153b4325f10a5" category="list-text">Aggiungere le seguenti voci:</block>
  <block id="ab5f5bab123b3441fc9c838b46ff1150" category="list-text">Convalidare il CDB/PDB creato.</block>
  <block id="c8c683d0737e702e38c962f83ab25c3f" category="list-text">In qualità di utente oracle, passare alla home directory del database Oracle /u01/app/oracle/product/19.0.0/db1 e attivare DNFS</block>
  <block id="f60c53adcb933554319040836143101b" category="list-text">Configurare il file oranfstab in ORACLE_HOME</block>
  <block id="e3821eca2ea743978a8041832aa25596" category="list-text">In qualità di utente oracle, accedere al database da sqlplus e impostare la dimensione e la posizione di ripristino del database sul gruppo di dischi +LOGS.</block>
  <block id="78f987fb432bce81eba18cab51620826" category="list-text">Attivare la modalità di log di archiviazione e riavviare l'istanza di Oracle DB</block>
  <block id="2311b19efeffe5f795b74cc4dddf6246" category="list-text">Convalidare la modalità di log del DB e DNFS dopo il riavvio dell'istanza</block>
  <block id="db852220e8f70b72373f5e4a21bd9a45" category="list-text">Validare Oracle ASM</block>
  <block id="4d3617697efd9a8201cb07f5e610e306" category="section-title">Opzione di implementazione automatica</block>
  <block id="3809b24192da05cb9bdf6fc7f86ce5d6" category="paragraph">NetApp rilascerà un toolkit di implementazione della soluzione completamente automatizzato con Ansible per facilitare l'implementazione di questa soluzione. Verificare nuovamente la disponibilità del toolkit. Una volta rilasciato, verrà pubblicato un link qui.</block>
  <block id="6cf7e59477fa5c8722c79a0910c40cd8" category="section-title">Backup, ripristino e clonazione del database Oracle con il servizio SnapCenter</block>
  <block id="a0c9cf73752e72933d08cadbcdf8c05a" category="inline-link-macro">Servizi SnapCenter per Oracle</block>
  <block id="916b48729c536f6a12c2122673bc394a" category="paragraph">Vedere <block ref="3e99507ec3d2036a04c899dadd6c66e9" category="inline-link-macro-rx"></block> Per ulteriori informazioni su backup, ripristino e clonazione del database Oracle con la console NetApp BlueXP.</block>
  <block id="aa5a3d07c03024007dadc921fdbe67cb" category="paragraph">Per ulteriori informazioni sulle informazioni descritte in questo documento, consultare i seguenti documenti e/o siti Web:</block>
  <block id="5424ed1a1b4c4815e1d1676f23aa1da4" category="list-text">Installazione di Oracle Grid Infrastructure per un server standalone con un'installazione di un nuovo database</block>
  <block id="a7410994d191ba6c350f0f764df86934" category="inline-link-macro"><block ref="a7410994d191ba6c350f0f764df86934" category="inline-link-rx"></block></block>
  <block id="094328bca120efd3d6fba90d69b806f8" category="paragraph"><block ref="094328bca120efd3d6fba90d69b806f8" category="inline-link-macro-rx"></block></block>
  <block id="8ae84196c6f373ef488c40b0b95e030d" category="list-text">Installazione e configurazione del database Oracle mediante i file di risposta</block>
  <block id="ee622e67d0075e37fff43bbf337e98b2" category="inline-link-macro"><block ref="ee622e67d0075e37fff43bbf337e98b2" category="inline-link-rx"></block></block>
  <block id="2d94d091f5afb89e4f1aab002cef14a3" category="paragraph"><block ref="2d94d091f5afb89e4f1aab002cef14a3" category="inline-link-macro-rx"></block></block>
  <block id="73bc97f640d8c1cae3fa624183216b41" category="inline-link-macro"><block ref="73bc97f640d8c1cae3fa624183216b41" category="inline-link-rx"></block></block>
  <block id="40285fa8e3dc4d66bfadb679f67dfde6" category="paragraph"><block ref="40285fa8e3dc4d66bfadb679f67dfde6" category="inline-link-macro-rx"></block></block>
  <block id="c421d122321bec48d6b30858f4e7b515" category="list-text">Amazon EC2</block>
  <block id="68253b5715937494905ba0cb9db91d2e" category="inline-link-macro"><block ref="be48c1546d351a5e48dcf4f28738754b" category="inline-link-rx"></block></block>
  <block id="6dcfba5adaa9302bd59dd5a601b947a2" category="paragraph"><block ref="95bfcff1050e9160bb2bd645993e8c18" category="inline-link-macro-rx"></block></block>
  <block id="d0bb28dcc0cc1b523a41bbb46875db9e" category="summary">Prima di installare Cloud Manager Connector e Cloud Volumes ONTAP e configurare SnapMirror, è necessario eseguire alcune operazioni di preparazione per il nostro ambiente cloud. In questa pagina vengono descritte le operazioni da eseguire e le considerazioni da tenere in considerazione durante l'implementazione di Cloud Volumes ONTAP.</block>
  <block id="8c6fb9ece3bad11d3e76d1344d9ed9ab" category="doc">Prerequisiti per il cloud pubblico</block>
  <block id="ac7eeb8ecebe00daa1fdf4fd06cc46de" category="inline-link-macro">Precedente: Prerequisiti on-premise.</block>
  <block id="70ba5e430ac8eade85f8e01e51412fe4" category="paragraph"><block ref="70ba5e430ac8eade85f8e01e51412fe4" category="inline-link-macro-rx"></block></block>
  <block id="5a2798d22185b0e40ea502bbbb171d38" category="section-title">Elenco di controllo dei prerequisiti per l'implementazione di Cloud Manager e Cloud Volumes ONTAP</block>
  <block id="d2ed5c7ede8a1ce9d218ec60b0f03935" category="list-text">Percorso di rete per un connettore</block>
  <block id="c4d5e1cbdfc47a0fdcb4a1a9dddd9e17" category="inline-link">documentazione cloud</block>
  <block id="1a22a3f7b690b2ec8919c8806633fb26" category="paragraph">Per ulteriori informazioni su ciò di cui hai bisogno per iniziare, visita il nostro<block ref="247d95fa755d21bb8790cc6d7a2fc412" category="inline-link-rx"></block>.</block>
  <block id="ea61e2c2ff507048203824add1eb7c21" category="section-title">Considerazioni</block>
  <block id="176ca67b83510a1281a4cfc749a3543a" category="section-title">1. Che cos'è un connettore Cloud Manager?</block>
  <block id="1681641037afae45bd6074dcde9eed00" category="paragraph">Nella maggior parte dei casi, un amministratore dell'account Cloud Central deve implementare un connettore nel cloud o nella rete on-premise. Il connettore consente a Cloud Manager di gestire risorse e processi all'interno del tuo ambiente di cloud pubblico.</block>
  <block id="8a78be5d168f00b24bf1625de3d5409c" category="paragraph">Per ulteriori informazioni sui connettori, visita il nostro<block ref="f39c14bbbbdd46ca70a63fb06046c789" category="inline-link-rx"></block>.</block>
  <block id="fcc2bf38b8157a22b5fc6975b7054acc" category="section-title">2. Dimensionamento e architettura Cloud Volumes ONTAP</block>
  <block id="1c09b5154aa1f43cb9ebcbd6fea5eadc" category="paragraph">Durante l'implementazione di Cloud Volumes ONTAP, è possibile scegliere un pacchetto predefinito o la creazione di una propria configurazione. Sebbene molti di questi valori possano essere modificati in seguito senza interruzioni, è necessario prendere alcune decisioni chiave prima dell'implementazione in base ai carichi di lavoro da implementare nel cloud.</block>
  <block id="331ce28903aee0b30cd3c94e5483edf5" category="inline-link">Tool di dimensionamento CVO</block>
  <block id="acaed5d74e38e1779b3831dcf51c7600" category="paragraph">Ogni cloud provider dispone di diverse opzioni per l'implementazione e quasi tutti i workload hanno proprietà esclusive. NetApp dispone di un<block ref="6a71e7e42ab9335484c5530029f79b92" category="inline-link-rx"></block> questo può aiutare a dimensionare correttamente le implementazioni in base a capacità e performance, ma è stato costruito attorno ad alcuni concetti di base che vale la pena considerare:</block>
  <block id="145c90afb7955854f2371e9decf3de9b" category="list-text">Capacità richiesta</block>
  <block id="f1521b662bf51f1af6c2d38bd610afae" category="list-text">Funzionalità di rete della macchina virtuale cloud</block>
  <block id="f75d8ba5edc8017382d5df68baf9e30f" category="list-text">Caratteristiche delle performance dello storage cloud</block>
  <block id="af9d66ea3132fcfeb46b85557bc1af1b" category="paragraph">La chiave è pianificare una configurazione che non solo soddisfi gli attuali requisiti di capacità e performance, ma che guardi anche alla crescita futura. Questo è generalmente noto come spazio di crescita della capacità e spazio di crescita delle performance.</block>
  <block id="180f0326dff3a03aecf5e184943d108a" category="paragraph">Per ulteriori informazioni, leggere la documentazione relativa alla pianificazione corretta per<block ref="af5d70b69c3436f8bcf6f7b9579c4e83" category="inline-link-rx"></block>,<block ref="c2e85b51d3015b4c720388e64a3de23e" category="inline-link-rx"></block>, e.<block ref="b1068926334a08925797774f64291db4" category="inline-link-rx"></block>.</block>
  <block id="c50ea1f0c6dcf02fbdd39e1e6b5befc2" category="section-title">3. Nodo singolo o alta disponibilità?</block>
  <block id="eadb13b9c72271dbf16967e78059fea4" category="paragraph">In tutti i cloud, è possibile implementare CVO in un singolo nodo o in una coppia ad alta disponibilità in cluster con due nodi. A seconda del caso di utilizzo, è possibile implementare un singolo nodo per risparmiare sui costi o una coppia ha per fornire ulteriore disponibilità e ridondanza.</block>
  <block id="9cbd119b18cd836b6020fcfd3bfbe37f" category="paragraph">Per un caso di utilizzo di DR o per lo storage temporaneo in fase di spinning per lo sviluppo e il test, i nodi singoli sono comuni poiché l'impatto di un'interruzione improvvisa dell'infrastruttura o di un'interruzione dell'infrastruttura è inferiore. Tuttavia, per qualsiasi caso di utilizzo in produzione, quando i dati si trovano in una sola posizione o quando il dataset deve avere maggiore ridondanza e disponibilità, si consiglia un'alta disponibilità.</block>
  <block id="83d2ad0cda1f71c52878284cc7c1f713" category="paragraph">Per ulteriori informazioni sull'architettura della versione ad alta disponibilità di ogni cloud, consulta la documentazione per<block ref="4344469628657b2a6a0d147e5e6fbc9a" category="inline-link-rx"></block>,<block ref="28a8305eced80cb5b1351f5cffb268ae" category="inline-link-rx"></block> e.<block ref="1b945d178a8347e94e5c5456dc9e6db8" category="inline-link-rx"></block>.</block>
  <block id="f0d106c1997a933ecb53ee88e83670e7" category="inline-link-macro">Avanti: Panoramica introduttiva.</block>
  <block id="fd43d07d375b44f30fde6995279b9265" category="paragraph"><block ref="fd43d07d375b44f30fde6995279b9265" category="inline-link-macro-rx"></block></block>
  <block id="cffc2899d8dda4926e6563cef4e76608" category="summary">Questa sezione fornisce dettagli sui fattori da prendere in considerazione durante l'implementazione del database Oracle su macchine virtuali Azure e storage Azure NetApp Files.</block>
  <block id="c53749244d982efb6aa5653328227c2a" category="doc">Fattori da considerare per l'implementazione del database Oracle</block>
  <block id="072a1cb4963593f78b428b4c9a0dcc4f" category="inline-link-macro">Precedente: Architettura della soluzione.</block>
  <block id="3cc4738ed2ec2e682ab2002688fa632b" category="paragraph"><block ref="3cc4738ed2ec2e682ab2002688fa632b" category="inline-link-macro-rx"></block></block>
  <block id="96f819dcc02d1203a3923ddad366ff4b" category="paragraph">Un cloud pubblico offre molte scelte per il calcolo e lo storage e l'utilizzo del tipo corretto di istanza di calcolo e motore di storage è un buon punto di partenza per l'implementazione del database. È inoltre necessario selezionare configurazioni di calcolo e storage ottimizzate per i database Oracle.</block>
  <block id="1a6a6241c0105da34f664d1e12534598" category="paragraph">Nelle sezioni seguenti vengono descritte le considerazioni principali relative all'implementazione di un database Oracle nel cloud pubblico Azure su un'istanza di macchina virtuale Azure con storage Azure NetApp Files.</block>
  <block id="c2b3b1e82aa97a133f0f6bbc12843085" category="section-title">Tipo e dimensionamento delle macchine virtuali</block>
  <block id="4ca9712a9cd82ea80c8e225977fae1bb" category="inline-link-macro">Dimensioni delle macchine virtuali in Azure</block>
  <block id="7c4a17715675ccfa7ce507eea6098318" category="paragraph">La scelta del tipo e delle dimensioni delle macchine virtuali corrette è importante per ottenere performance ottimali di un database relazionale in un cloud pubblico. Una macchina virtuale Azure offre una vasta gamma di istanze di calcolo che possono essere utilizzate per ospitare i carichi di lavoro dei database Oracle. Consultare la documentazione Microsoft <block ref="d854faa84ea41d8819c42ca3741a3561" category="inline-link-macro-rx"></block> Per diversi tipi di macchine virtuali Azure e il loro dimensionamento. In generale, NetApp consiglia di utilizzare una macchina virtuale Azure generica per l'implementazione di database Oracle di piccole e medie dimensioni. Per l'implementazione di database Oracle più grandi, è appropriata una macchina virtuale Azure ottimizzata per la memoria. Con una maggiore quantità di RAM disponibile, è possibile configurare una cache Oracle SGA o Smart flash più grande per ridurre l'i/o fisico, migliorando a sua volta le performance del database.</block>
  <block id="84942a15b69259aab0ff7c2620afcaf6" category="inline-link-macro">TR-4780: Database Oracle su Microsoft Azure</block>
  <block id="760a7b6c1bd4f6ebab6918d42feb4825" category="paragraph">Azure NetApp Files funziona come montaggio NFS collegato a una macchina virtuale Azure, che offre un throughput più elevato e supera il limite di throughput delle macchine virtuali ottimizzato per lo storage con lo storage locale. Pertanto, l'esecuzione di Oracle su Azure NetApp Files potrebbe ridurre il numero di core delle CPU e i costi di licenza. Vedere <block ref="b46cbe9b7b18b9ff8101a014c206465f" category="inline-link-macro-rx"></block>, Sezione 7 - come funziona Oracle Licensing?</block>
  <block id="71b93ac808ac25bb511ebcbb028e32e8" category="paragraph">Altri fattori da considerare includono:</block>
  <block id="592bc946b588ad0e83c05f528895bcc8" category="list-text">Scegliere la combinazione di vCPU e RAM corretta in base alle caratteristiche del carico di lavoro. Con l'aumentare delle dimensioni della RAM sulla macchina virtuale, aumenta anche il numero di core della vCPU. A un certo punto dovrebbe esserci un saldo, in quanto le tariffe di licenza Oracle vengono addebitate sul numero di core vCPU.</block>
  <block id="fb9844eb7ee0ff341d6f7066f78918ff" category="list-text">Aggiungere spazio di swap a una macchina virtuale. L'implementazione predefinita di Azure VM non crea uno spazio di swap, che non è ottimale per un database.</block>
  <block id="81afc696937e3786d5701212de79c536" category="section-title">Performance Azure NetApp Files</block>
  <block id="c7bc5faed38f5284386f25a6fc3a5752" category="paragraph">I volumi Azure NetApp Files vengono allocati da un pool di capacità che il cliente deve fornire nel proprio account di storage Azure NetApp Files. Ciascun pool di capacità viene assegnato come segue:</block>
  <block id="3af20f4cec87eac026d0990a8a3f4169" category="list-text">A un livello di servizio che definisce la capacità complessiva delle performance.</block>
  <block id="dd1fb66595c069d1b267fb8ca87e46eb" category="list-text">La capacità di storage o il tiering inizialmente forniti per quel pool di capacità. Un livello di qualità del servizio (QoS) che definisce il throughput massimo complessivo per ogni spazio sottoposto a provisioning.</block>
  <block id="9dc50220b7e70511b5aeebb862346fad" category="paragraph">Il livello di servizio e la capacità di storage inizialmente fornita determinano il livello di performance per un particolare volume di database Oracle.</block>
  <block id="59b8b6b998c3c0fcd2f1b107a68c290a" category="section-title">1. Livelli di servizio per Azure NetApp Files</block>
  <block id="f02ad1a8080bf1b50f8a15cb346ed483" category="paragraph">Azure NetApp Files supporta tre livelli di servizio: Ultra, Premium e Standard.</block>
  <block id="3eec40f71dc46b07f32031c9703968ec" category="list-text">*Ultra storage.* questo Tier fornisce fino a 128 MiBps di throughput per 1 TiB di quota di volume assegnata.</block>
  <block id="1b0fa75a1e8b815e03fb38f8a90d2a73" category="list-text">*Premium storage.* questo Tier fornisce fino a 64 MiBps di throughput per 1 TiB di quota di volume assegnata.</block>
  <block id="00792f6ec40d3e2833834d90802a7aa5" category="list-text">*Storage standard.* questo Tier fornisce fino a 16 MiBps di throughput per 1 TiB di quota di volume assegnata.</block>
  <block id="7a720602d11a97fd37964c9979e2f1a5" category="section-title">2. Pool di capacità e qualità del servizio</block>
  <block id="36ac84521252c58a4238292bf0c21d92" category="paragraph">Ciascuno dei livelli di servizio desiderati ha un costo associato per la capacità di provisioning e include un livello di qualità del servizio (QoS) che definisce il throughput massimo complessivo per lo spazio di provisioning.</block>
  <block id="7a93db9cf06fd65415faf241927e2087" category="paragraph">Ad esempio, un pool a capacità singola con provisioning di 10TiB con livello di servizio premium fornisce un throughput globale disponibile per tutti i volumi in questo pool di capacità di 10x 64 MBps, quindi 640 MBps con 40,000 (16K) IOPS o 80,000 (8K) IOPS.</block>
  <block id="18dc8b2cbfb938a0ba32c141664fba0e" category="paragraph">La dimensione minima del pool di capacità è 4 TiB. È possibile modificare le dimensioni di un pool di capacità in incrementi di 1 TiB in risposta alle modifiche dei requisiti dei workload per gestire le esigenze e i costi dello storage.</block>
  <block id="8a26494cf7b0c3c3ca7cd38e89c068eb" category="section-title">3. Calcolare il livello di servizio in un volume di database</block>
  <block id="9ce59559a0b99338ee0bad0c153c961a" category="paragraph">Il limite di throughput per un volume di database Oracle è determinato da una combinazione dei seguenti fattori: Il livello di servizio del pool di capacità a cui appartiene il volume e la quota assegnata al volume.</block>
  <block id="b87e1c6e437216fc2d3719c3dad93cb8" category="paragraph">Il seguente diagramma mostra come viene calcolato il limite di throughput per un volume di database Oracle.</block>
  <block id="1624b6f83446cd1719c94bae28cbbeb7" category="inline-image-macro">Questa immagine mostra l'equazione applicata ai tre livelli di capacità per determinare il throughput lordo.</block>
  <block id="4d06f88a6f007c9821ac2ea5741860c5" category="paragraph"><block ref="4d06f88a6f007c9821ac2ea5741860c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ce3321601c29c87cb29ae9817843b8d" category="paragraph">Nell'esempio 1, a un volume proveniente da un pool di capacità con il Tier di storage Premium assegnato a 2 TiB di quota viene assegnato un limite di throughput di 128 MiBps (2TiB * 64 MiBps). Questo scenario si applica indipendentemente dalle dimensioni del pool di capacità o dal consumo effettivo del volume.</block>
  <block id="69da5d3e48cc26414a9177d843bd55d9" category="paragraph">Nell'esempio 2, a un volume proveniente da un pool di capacità con il Tier di storage Premium a cui viene assegnato 100 GiB di quota viene assegnato un limite di throughput di 6,25 MiBps (0,09765625TiB * 64 MiBps). Questo scenario si applica indipendentemente dalle dimensioni del pool di capacità o dal consumo effettivo del volume.</block>
  <block id="def2c2ae4fa72ee296eada07b44a0cc9" category="paragraph">Tenere presente che le dimensioni minime del volume sono di 100 GiB.</block>
  <block id="d4d5d0e2fb33dadfad4435489bd718a4" category="section-title">Layout e impostazioni dello storage</block>
  <block id="0fe994abd6c200feb672e77242fe9fcb" category="paragraph">NetApp consiglia il seguente layout di storage:</block>
  <block id="78ad659ec79d8ee9e7432271167d18d3" category="list-text">Per database di piccole dimensioni, utilizzando il layout di un singolo volume per tutti i file Oracle.</block>
  <block id="51672f1f7a65c28f28e5e113376309bd" category="inline-image-macro">Questa immagine mostra tre database (DB1, DB2 e DB3) contenenti ciascuno datafile, log di ripristino, log di archiviazione e file di controllo all'interno di un singolo pool di capacità.</block>
  <block id="6dab61143f0fe37930fbd783e5c57c81" category="paragraph"><block ref="6dab61143f0fe37930fbd783e5c57c81" category="inline-image-macro-rx" type="image"></block></block>
  <block id="816445ad7ba016a8c0be293c985f068b" category="list-text">Per i database di grandi dimensioni, il layout di volume consigliato è costituito da più volumi: Uno per i dati Oracle e un file di controllo duplicato e uno per il log attivo Oracle, il log archiviato e il file di controllo. NetApp consiglia vivamente di allocare un volume per il file binario Oracle anziché per il disco locale in modo che il database possa essere trasferito su un nuovo host e ripristinato rapidamente.</block>
  <block id="955db4ecf8716abf17a3ea3f8e113671" category="inline-image-macro">Questa immagine mostra due database con due volumi ciascuno. Il primo volume contiene i file di dati, mentre il secondo volume di ogni database contiene i log di ripristino, i log di archiviazione e i file di controllo. Il tutto in un singolo pool di capacità.</block>
  <block id="7432b939dcc290776a34b2e9610a2775" category="paragraph"><block ref="7432b939dcc290776a34b2e9610a2775" category="inline-image-macro-rx" type="image"></block></block>
  <block id="10edbbba4e4c39fc161aeac9fbb88aef" category="section-title">Configurazione NFS</block>
  <block id="efeaafaa286e164985a0c325f0727cf1" category="paragraph">Linux, il sistema operativo più comune, include funzionalità NFS native. Oracle offre un client NFS (DNFS) integrato in modo nativo in Oracle. Oracle DNFS ignora la cache del sistema operativo e consente l'elaborazione parallela per migliorare le performance del database. Oracle supporta NFSv3 da oltre 20 anni e NFSv4 è supportato con Oracle 12.1.0.2 e versioni successive.</block>
  <block id="be5ef2ba2540e077db09ca784b1ac18f" category="paragraph">Utilizzando DNFS (disponibile a partire da Oracle 11g), un database Oracle in esecuzione su una macchina virtuale Azure può gestire una quantità di i/o significativamente maggiore rispetto al client NFS nativo. L'implementazione automatica di Oracle utilizzando il toolkit di automazione NetApp configura automaticamente DNFS su NFSv3.</block>
  <block id="632bf0b812e05925eff22d7d0a7677c2" category="paragraph">Il seguente diagramma illustra il benchmark SLOB su Azure NetApp Files con Oracle DNFS.</block>
  <block id="08826656fd88155bdfaebbb292320e33" category="inline-image-macro">Questo grafico dimostra in modo significativo che DNFS migliora la latenza del file sequenziale DB (ms) su KNFS.</block>
  <block id="258bafba486e8ac35578ed4c5fff8ab1" category="paragraph"><block ref="258bafba486e8ac35578ed4c5fff8ab1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b7570eaa12a3e472e9d0cbac6631d57" category="paragraph">Altri fattori da considerare:</block>
  <block id="6841f6ce9d9a2af93222223df564ca34" category="list-text">Le tabelle degli slot TCP sono l'equivalente NFS della profondità della coda HBA (host-bus-adapter). Queste tabelle controllano il numero di operazioni NFS che possono essere in sospeso in qualsiasi momento. Il valore predefinito è di solito 16, che è troppo basso per ottenere prestazioni ottimali. Il problema opposto si verifica sui kernel Linux più recenti, che possono aumentare automaticamente il limite della tabella degli slot TCP a un livello che satura il server NFS con le richieste.</block>
  <block id="24019b0d54b5da3a46b400c6a6dfee77" category="paragraph">Per ottenere performance ottimali e prevenire problemi di performance, regolare i parametri del kernel che controllano le tabelle degli slot TCP su 128.</block>
  <block id="754e164c2de7ed1f02667d5f74297a0e" category="list-text">La seguente tabella fornisce le opzioni di montaggio NFS consigliate per una singola istanza di Linux NFSv3.</block>
  <block id="fa7abb28d1b83f9ee23d95aff1d3123b" category="inline-image-macro">Questa tabella mostra le opzioni di montaggio NFS dettagliate per i seguenti tipi di file, file di controllo, file di dati, log di ripristino, ORACLE_HOME, E ORACLE_BASE.</block>
  <block id="082aad17dee7d03a3d502a422c1a8c53" category="paragraph"><block ref="082aad17dee7d03a3d502a422c1a8c53" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4492ef7005cdef278b0b767179a1ecb9" category="admonition">Prima di utilizzare DNFS, verificare che siano installate le patch descritte in Oracle Doc 1495104.1. A partire da Oracle 12c, DNFS include il supporto per NFSv3, NFSv4 e NFSv4.1. Le policy di supporto NetApp coprono v3 e v4 per tutti i client, ma al momento della stesura del presente documento, NFSv4.1 non è supportato per l'utilizzo con Oracle DNFS.</block>
  <block id="72db8e2a11aee3fd6b5ea401c9adcbd6" category="inline-link-macro">Avanti: Procedure di implementazione.</block>
  <block id="b71b592b003a6232eebe484a1736be7a" category="paragraph"><block ref="b71b592b003a6232eebe484a1736be7a" category="inline-link-macro-rx"></block></block>
  <block id="8a1d7e9120e3db2795bd53b504018b4e" category="summary">Questo white paper illustra e convalida una soluzione per il database Oracle RDS ha e DR personalizzato di AWS, sfruttando il servizio di storage AWS FSX in un'implementazione con zone a disponibilità multipla.</block>
  <block id="0c55b956af322a2409f5dd75af116fee" category="doc">WP-7357: Introduzione alle Best practice per l'implementazione di database Oracle su EC2 e FSX</block>
  <block id="b4c8c277e19db14e178b1060214b896e" category="paragraph">Allen Cao, Niyaz Mohamed, Jeffrey Steiner, NetApp</block>
  <block id="6848412b0f30d614f7e0bcd903cac052" category="paragraph">Molti database Oracle aziendali mission-critical sono ancora ospitati on-premise e molte aziende stanno cercando di migrare questi database Oracle in un cloud pubblico. Spesso, questi database Oracle sono incentrati sulle applicazioni e richiedono quindi configurazioni specifiche per l'utente, una funzionalità che non è presente in molte offerte di cloud pubblico database-as-a-service. Pertanto, l'attuale panorama dei database richiede una soluzione di database Oracle basata sul cloud pubblico, costruita da un servizio di calcolo e storage scalabile e dalle performance elevate, in grado di soddisfare requisiti unici. Le istanze di calcolo AWS EC2 e il servizio di storage AWS FSX potrebbero essere i pezzi mancanti di questo puzzle che puoi sfruttare per creare e migrare i carichi di lavoro di database Oracle mission-critical in un cloud pubblico.</block>
  <block id="37b7c86d51875922e0a9f122a670aa62" category="paragraph">Amazon Elastic Compute Cloud (Amazon EC2) è un servizio Web che offre capacità di calcolo sicura e ridimensionabile nel cloud. È progettato per semplificare il cloud computing su scala web per le aziende. La semplice interfaccia web-service Amazon EC2 ti consente di ottenere e configurare la capacità con un minimo attrito. Ti offre il controllo completo delle risorse di calcolo e ti consente di eseguire il comprovato ambiente di calcolo di Amazon.</block>
  <block id="c9550c9d9c1b379ad427d739b5c69f00" category="paragraph">Amazon FSX per ONTAP è un servizio di storage AWS che utilizza lo storage di file e blocchi ONTAP NetApp leader del settore, che espone NFS, SMB e iSCSI. Con un motore di storage così potente, non è mai stato così facile trasferire le applicazioni di database Oracle mission-critical su AWS con tempi di risposta inferiori al millisecondo, più Gbps di throughput e oltre 100,000 IOPS per istanza di database. Inoltre, il servizio di storage FSX è dotato di funzionalità di replica nativa che consente di migrare facilmente il database Oracle on-premise su AWS o di replicare il database Oracle mission-critical in un'area di disponibilità AWS secondaria per ha o DR.</block>
  <block id="b3f95d0186b2e4989ad81f07a21d72c5" category="paragraph">L'obiettivo di questa documentazione è fornire procedure, procedure e Best practice dettagliate su come implementare e configurare un database Oracle con storage FSX e un'istanza EC2 che offra performance simili a quelle di un sistema on-premise. NetApp fornisce inoltre un toolkit di automazione che automatizza la maggior parte delle attività richieste per l'implementazione, la configurazione e la gestione del carico di lavoro del database Oracle nel cloud pubblico AWS.</block>
  <block id="eef7539c8eab25bfe5c089aab85ec418" category="paragraph">Per ulteriori informazioni sulla soluzione e sul caso d'utilizzo, guarda il seguente video introduttivo:</block>
  <block id="0df1fe5dfbca17caa87c91ffea49223a" category="inline-link-macro">Modernizza il tuo database Oracle con il cloud ibrido in AWS e FSX ONTAP, parte 1 - caso d'utilizzo e architettura della soluzione</block>
  <block id="adf8d1fc36b4704904a6251fde19535e" category="paragraph"><block ref="bab032e290776958656c886d774a2bf6" category="inline-link-macro-rx"></block></block>
  <block id="d31314285161c777a09609cc4fb2d07a" category="inline-link-macro">Avanti: Architettura delle soluzioni.</block>
  <block id="15d62938aed0de1248a55c07bc0c547c" category="paragraph"><block ref="15d62938aed0de1248a55c07bc0c547c" category="inline-link-macro-rx"></block></block>
  <block id="87561d435f6cd79a59659b543d2991ca" category="summary">In questa sezione viene illustrata un'architettura della soluzione di implementazione personalizzata di RDS Oracle con storage Oracle RDS e FSX ONTAP personalizzato.</block>
  <block id="c739a7ae4891c6665d1f2f715d2efa3f" category="paragraph"><block ref="c739a7ae4891c6665d1f2f715d2efa3f" category="inline-link-macro-rx"></block></block>
  <block id="ca449b8ca808c6d325abf6b1a047318c" category="paragraph">Il seguente diagramma dell'architettura illustra un'implementazione di database Oracle altamente disponibile su un'istanza AWS EC2 con il servizio di storage FSX. È possibile configurare uno schema di implementazione simile, ma con lo standby in una regione diversa, per il disaster recovery.</block>
  <block id="312f941d9e8f224f54ae372016e8f35a" category="paragraph">All'interno dell'ambiente, l'istanza di calcolo Oracle viene implementata tramite una console di istanze AWS EC2. Dalla console sono disponibili diversi tipi di istanze EC2. NetApp consiglia di implementare un tipo di istanza EC2 orientata al database, ad esempio un'immagine m5 Ami con RedHat Enterprise Linux 8 e fino a 10 Gps di larghezza di banda della rete.</block>
  <block id="228488653f80c4dfe7bd79d5f9634ea4" category="paragraph">Lo storage del database Oracle sui volumi FSX, invece, viene implementato con la console AWS FSX o CLI. I volumi binari, dati o log Oracle vengono successivamente presentati e montati su un host Linux di istanza EC2. A ogni volume di dati o log possono essere allocate più LUN in base al protocollo di storage sottostante utilizzato.</block>
  <block id="830579b4d0c33e9e4fa1f11c61cb73a7" category="inline-image-macro">Questa immagine mostra un diagramma dell'architettura di esempio che include il cluster ha primario - il cluster ha in standby - nodi di gestione - e i nodi di connessione correlati.</block>
  <block id="73793421735093db194ae82163f894b3" category="paragraph"><block ref="73793421735093db194ae82163f894b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e3d0f7ae75ed6e0e3b522ecc7cac710b" category="paragraph">Un cluster di storage FSX è progettato con doppia ridondanza, in modo che i cluster di storage primario e di standby siano implementati in due diverse zone di disponibilità. I volumi di database vengono replicati da un cluster FSX primario a un cluster FSX di standby a un intervallo configurabile dall'utente per tutti i volumi binari, di dati e di log Oracle.</block>
  <block id="0008c12bed67fcf1f82ece8ff10b5c81" category="paragraph">Questo ambiente Oracle ad alta disponibilità viene gestito con un nodo controller Ansible e un server di backup SnapCenter e uno strumento di interfaccia utente. L'installazione, la configurazione e la replica di Oracle sono automatizzate utilizzando i toolkit basati su Ansible Playbook. Qualsiasi aggiornamento del sistema operativo del kernel dell'istanza Oracle EC2 o patch Oracle può essere eseguito in parallelo per mantenere sincronizzati il primario e lo standby. Infatti, la configurazione iniziale dell'automazione può essere facilmente espansa per eseguire alcune attività Oracle quotidiane ripetitive, se necessario.</block>
  <block id="be571c48040d6c3bf764ba40188888d2" category="paragraph">SnapCenter offre flussi di lavoro per il ripristino point-in-time del database Oracle o per la clonazione del database nelle zone primarie o di standby, se necessario. Tramite l'interfaccia utente di SnapCenter, è possibile configurare il backup e la replica del database Oracle sullo storage FSX in standby per l'alta disponibilità o il disaster recovery in base agli obiettivi RTO o RPO.</block>
  <block id="be22c0b35f58a932be14c9e55b163ac4" category="paragraph">La soluzione offre un processo alternativo che offre funzionalità simili a quelle offerte dall'implementazione di Oracle RAC e Data Guard.</block>
  <block id="1332f9ef53fc751a6087660a11f07ba6" category="paragraph"><block ref="1332f9ef53fc751a6087660a11f07ba6" category="inline-link-macro-rx"></block></block>
  <block id="1572d96530c843cddbe2d0a8b47abf8a" category="summary">Questa guida alle Best practice fornisce dettagli su una soluzione per l'implementazione e la protezione del database Oracle su Azure NetApp file storage e Azure VM.</block>
  <block id="2e0520fcae6cb49914d2308fbaf4e1a8" category="doc">TR-4954: Implementazione e protezione di database Oracle su Azure NetApp Files</block>
  <block id="8705d70129ca2e423b28fad13ebb5bf5" category="paragraph">Autore: Allen Cao, Niyaz Mohamed, NetApp</block>
  <block id="b2bd5134cf9b573edd93cbfe6ee4559d" category="paragraph">Molti database aziendali Oracle mission-critical sono ancora ospitati on-premise e molte aziende stanno cercando di migrare questi database Oracle in un cloud pubblico. Spesso, questi database Oracle sono incentrati sulle applicazioni e richiedono quindi configurazioni specifiche per l'utente, una funzionalità che non è presente in molte offerte di cloud pubblico database-as-a-service. Pertanto, l'attuale panorama dei database richiede una soluzione di database Oracle basata sul cloud pubblico, costruita da un servizio di calcolo e storage scalabile e dalle performance elevate, in grado di soddisfare requisiti unici. Le istanze di calcolo delle macchine virtuali Azure e il servizio di storage Azure NetApp Files potrebbero essere i pezzi mancanti di questo puzzle che puoi sfruttare per creare e migrare i carichi di lavoro di database Oracle mission-critical in un cloud pubblico.</block>
  <block id="ca1f43ed95dcff37918897f15b054794" category="section-title">Azure Virtual Machine</block>
  <block id="a58dc8965e4de69beb97a33a5a1935ea" category="paragraph">Le macchine virtuali Azure sono uno dei diversi tipi di risorse di calcolo scalabili e on-demand offerte da Azure. In genere, è possibile scegliere una macchina virtuale quando si ha bisogno di un maggiore controllo sull'ambiente di calcolo rispetto alle altre scelte. Le macchine virtuali Azure offrono un modo semplice e rapido per creare un computer con configurazioni specifiche necessarie per eseguire il database Oracle, sia per i carichi di lavoro a elaborazione che per quelli a uso intensivo di memoria. Le macchine virtuali di una rete virtuale Azure possono essere facilmente connesse alla rete aziendale, ad esempio attraverso un tunnel VPN protetto.</block>
  <block id="8f53b5241aa3284f9058318dcbc2504d" category="section-title">Azure NetApp Files (ANF)</block>
  <block id="466d154dd31c873c4a2fd7113dc6b818" category="paragraph">Azure NetApp Files è un servizio Microsoft completamente gestito che consente di trasferire il carico di lavoro del database nel cloud in modo più rapido e sicuro che mai. È stato progettato per soddisfare i requisiti fondamentali dell'esecuzione di carichi di lavoro dalle performance elevate come i database Oracle nel cloud e offre livelli di performance che riflettono la gamma reale di richieste IOPS, bassa latenza, alta disponibilità, elevata durata, gestibilità su larga scala, backup, recovery e cloning rapidi ed efficienti. Queste funzionalità sono possibili perché Azure NetApp Files si basa su sistemi ONTAP fisici all-flash NetApp in esecuzione nell'ambiente del data center Azure. Azure NetApp Files è completamente integrato nei controller di dominio e nel portale Azure e i clienti possono utilizzare la stessa comoda interfaccia grafica e le stesse API per la creazione e la gestione di file condivisi come con qualsiasi altro oggetto Azure. Con Azure NetApp file, puoi liberare tutte le funzionalità di Azure senza rischi, costi o tempi aggiuntivi e affidarti all'unico file service aziendale nativo di Azure.</block>
  <block id="30106aaa3e986f62cbb327f935569bca" category="inline-link-macro">Database Oracle su Microsoft Azure</block>
  <block id="bdb41d103336edebf957f48add0f3554" category="inline-link-macro">Automazione NetApp</block>
  <block id="c2add34b573ef3798dd7c5b8972c008a" category="paragraph">Questa documentazione descrive in dettaglio come implementare, configurare e proteggere un database Oracle con una macchina virtuale Azure e un servizio di storage Azure NetApp Files che offrono performance e durata simili a quelle di un sistema on-premise. Per informazioni sulle Best practice, vedere TR-4780 <block ref="43d70d3cb7600babfb5820086b5480b6" category="inline-link-macro-rx"></block>. Cosa ancora più importante, NetApp fornisce anche toolkit di automazione che automatizzano la maggior parte delle attività richieste per l'implementazione, la configurazione, la protezione dei dati, la migrazione e la gestione del carico di lavoro del database Oracle nel cloud pubblico Azure. I toolkit di automazione sono disponibili per il download sul sito GitHub pubblico di NetApp: <block ref="1b9adaed0e4ba13a6d8f6edc7ab8f2d8" category="inline-link-macro-rx"></block>.</block>
  <block id="3d7dbc3eeea5e87b5d14c9f00c66dd47" category="paragraph"><block ref="3d7dbc3eeea5e87b5d14c9f00c66dd47" category="inline-link-macro-rx"></block></block>
  <block id="7d34df46082e5771e092eb8736597ee0" category="summary">In questa sezione vengono descritte le procedure di implementazione del database personalizzato Oracle RDS con lo storage FSX.</block>
  <block id="4020b36b638694a9834cb01b53b25ffe" category="doc">Procedure di implementazione Oracle passo per passo su AWS EC2 e FSX</block>
  <block id="ef081c8f35bca2da08c6dbdd6f48a6cd" category="paragraph"><block ref="ef081c8f35bca2da08c6dbdd6f48a6cd" category="inline-link-macro-rx"></block></block>
  <block id="f70ec60e40ece5900605229a28081b13" category="section-title">Implementare un'istanza EC2 Linux per Oracle tramite la console EC2</block>
  <block id="03d6d2463e27b63c2d7f7ad0e62697af" category="paragraph">Se non hai ancora utilizzato AWS, devi prima configurare un ambiente AWS. La scheda Documentation (documentazione) nella landing page del sito Web di AWS fornisce collegamenti alle istruzioni EC2 su come implementare un'istanza di Linux EC2 che può essere utilizzata per ospitare il database Oracle tramite la console AWS EC2. La sezione seguente è un riepilogo di questi passaggi. Per ulteriori informazioni, consultare la documentazione specifica di AWS EC2 collegata.</block>
  <block id="e1fc23220db46fe659667702f62b75e4" category="section-title">Configurazione dell'ambiente AWS EC2</block>
  <block id="6d0669826a2bd6e9eb35ea7e89cbe3f4" category="paragraph">È necessario creare un account AWS per fornire le risorse necessarie per eseguire l'ambiente Oracle sul servizio EC2 e FSX. La seguente documentazione AWS fornisce i dettagli necessari:</block>
  <block id="2966cbe914210fb4f4a3e5fe6adf4762" category="inline-link-macro">Configurare per l'utilizzo di Amazon EC2</block>
  <block id="1e4a01fe43fb3542c08649e20440f5f1" category="list-text"><block ref="1e4a01fe43fb3542c08649e20440f5f1" category="inline-link-macro-rx"></block></block>
  <block id="df6ca3590d3bec198846463f0ef1c6a8" category="paragraph">Argomenti chiave:</block>
  <block id="74122bb32fc969b565a8b132d4178581" category="list-text">Iscriviti ad AWS.</block>
  <block id="fe536eddec5cc1d661347011844ba132" category="list-text">Creare una coppia di chiavi.</block>
  <block id="6582688edf89986f408a52095794f65b" category="list-text">Creare un gruppo di sicurezza.</block>
  <block id="c78747962ae12e635749aa6b08a4da09" category="section-title">Attivazione di più zone di disponibilità negli attributi degli account AWS</block>
  <block id="2d5ade6857f59cf6d198344d5049da40" category="paragraph">Per una configurazione Oracle ad alta disponibilità come illustrato nel diagramma dell'architettura, è necessario abilitare almeno quattro zone di disponibilità in una regione. Le zone di disponibilità multiple possono anche essere situate in diverse regioni per soddisfare le distanze richieste per il disaster recovery.</block>
  <block id="b6067af8a0645a7009ccfb45c5271f1e" category="paragraph"><block ref="b6067af8a0645a7009ccfb45c5271f1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8faa9e48d0380a023114890a62861d0f" category="section-title">Creazione e connessione a un'istanza EC2 per l'hosting del database Oracle</block>
  <block id="82499151e189f9313aa1450e912f4ffd" category="inline-link-macro">Inizia a utilizzare le istanze di Amazon EC2 Linux</block>
  <block id="822fd31d54c32c4886e9010d12a8dce7" category="paragraph">Vedere il tutorial <block ref="6d0a9d65d170226042c573685041d5e9" category="inline-link-macro-rx"></block> per procedure di implementazione passo-passo e best practice.</block>
  <block id="a15c0d1773407cc677a49f4cc169a63c" category="list-text">Panoramica.</block>
  <block id="4d99c712f714ff14ae3b251667dda4b2" category="list-text">Prerequisiti.</block>
  <block id="67b035efef4b92412bb7a8a903121da6" category="list-text">Fase 1: Avviare un'istanza.</block>
  <block id="6640566c783363c8a66fe226c2a7227b" category="list-text">Fase 2: Connettersi all'istanza.</block>
  <block id="c271b00c470f8a1fb17c05dc6092d9af" category="list-text">Fase 3: Ripulire l'istanza.</block>
  <block id="9e0cd4f11314aeaa31fce7e3f5960c4c" category="paragraph">Le seguenti schermate mostrano l'implementazione di un'istanza di Linux di tipo m5 con la console EC2 per l'esecuzione di Oracle.</block>
  <block id="993b6250c7c69b01670a8165c0cf949d" category="list-text">Dalla dashboard EC2, fare clic sul pulsante giallo Launch Instance (Avvia istanza) per avviare il flusso di lavoro di implementazione dell'istanza EC2.</block>
  <block id="37266a1d594801e15c8f2a455a3ea854" category="paragraph"><block ref="37266a1d594801e15c8f2a455a3ea854" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71a4046454ceb8a1793ee0cfa14dc581" category="list-text">Nella fase 1, selezionare "Red Hat Enterprise Linux 8 (HVM), tipo di volume SSD - ami-0b0af3577fe5e3532 (x86 a 64 bit) / ami-01fc429821bf1f4b4 (ARM a 64 bit)".</block>
  <block id="755d0918a7bfcbc1b7541acd1235598e" category="paragraph"><block ref="755d0918a7bfcbc1b7541acd1235598e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5956dcc5f6331fe980094b6ddba4650c" category="list-text">Nella fase 2, selezionare un tipo di istanza m5 con l'allocazione di CPU e memoria appropriata in base al carico di lavoro del database Oracle. Fare clic su "Avanti: Configura dettagli istanza".</block>
  <block id="55898408b090c35ed97aede8b9893299" category="paragraph"><block ref="55898408b090c35ed97aede8b9893299" category="inline-image-macro-rx" type="image"></block></block>
  <block id="302a3b9b8b1d7dfc842dbfcaa5468b1a" category="list-text">Nella fase 3, scegliere il VPC e la subnet in cui collocare l'istanza e abilitare l'assegnazione IP pubblica. Fare clic su "Next: Add Storage" (Avanti: Aggiungi storage).</block>
  <block id="86ec5cd603e5f7341f3f213d5b660cbb" category="paragraph"><block ref="86ec5cd603e5f7341f3f213d5b660cbb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e421be5ecc966b1d156d7f0a6f81716a" category="list-text">Nella fase 4, allocare spazio sufficiente per il disco root. Potrebbe essere necessario lo spazio per aggiungere uno swap. Per impostazione predefinita, l'istanza EC2 assegna zero spazio di swap, che non è ottimale per l'esecuzione di Oracle.</block>
  <block id="5246bec51cd11bdee5a098fd3d3d5909" category="paragraph"><block ref="5246bec51cd11bdee5a098fd3d3d5909" category="inline-image-macro-rx" type="image"></block></block>
  <block id="843f8ce7ab50f800b312d3d109724de6" category="list-text">Nella fase 5, aggiungere un tag per l'identificazione dell'esempio, se necessario.</block>
  <block id="30a97756451355fd7db0bfd07cc6f667" category="paragraph"><block ref="30a97756451355fd7db0bfd07cc6f667" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3ab3dbfdf3bf87e86423bcf042be111" category="list-text">Nella fase 6, selezionare un gruppo di sicurezza esistente o crearne uno nuovo con il criterio in entrata e in uscita desiderato per l'istanza.</block>
  <block id="bdeb5b41f7c9bee78d1e7264990c0a27" category="paragraph"><block ref="bdeb5b41f7c9bee78d1e7264990c0a27" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6232d41ab5791353e400740b1c677c4b" category="list-text">Nella fase 7, esaminare il riepilogo della configurazione dell'istanza e fare clic su Launch (Avvia) per avviare la distribuzione dell'istanza. Viene richiesto di creare una coppia di chiavi o di selezionare una coppia di chiavi per accedere all'istanza.</block>
  <block id="fdd8bffe3363802212b12c3b1a7626da" category="paragraph"><block ref="8dc5efc0ebc99dc3e7017ef07cffd6c3" category="inline-image-macro-rx" type="image"></block>
<block ref="ea979786416bbc8ec09d933e3d57cfc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="640d800543e4acd4be5582f719fe45e6" category="list-text">Accedere all'istanza EC2 utilizzando una coppia di chiavi SSH. Apportare le modifiche necessarie al nome della chiave e all'indirizzo IP dell'istanza.</block>
  <block id="69321a8301f0cb7557529f92163852a6" category="paragraph">È necessario creare due istanze EC2 come server Oracle primario e di standby nella zona di disponibilità designata, come illustrato nel diagramma dell'architettura.</block>
  <block id="de55d86dd430c134cc875c8122ebfd71" category="section-title">Provisioning di FSX per file system ONTAP per lo storage di database Oracle</block>
  <block id="2a0b48da85066bd283380f9313f9cd2f" category="paragraph">L'implementazione dell'istanza EC2 assegna un volume root EBS per il sistema operativo. FSX per file system ONTAP fornisce volumi di storage per database Oracle, inclusi volumi binari, dati e log Oracle. È possibile eseguire il provisioning dei volumi NFS dello storage FSX dalla console AWS FSX o dall'installazione di Oracle e l'automazione della configurazione che assegna i volumi come l'utente configura in un file di parametri di automazione.</block>
  <block id="db188150cd7e1fbc9cfd2bc034c7b4bb" category="inline-link">Gestione di FSX per file system ONTAP</block>
  <block id="3b46f3b2334f11bf806517b04969429a" category="paragraph">Si fa riferimento alla presente documentazione<block ref="eea1efb396f41a443a43d43b53db120b" category="inline-link-rx"></block> Per la creazione di file system FSX per ONTAP.</block>
  <block id="f992b6bed702bc01496187fcaec0b8c6" category="paragraph">Considerazioni principali:</block>
  <block id="c6d0abeaa6d014ec6632e6b8493487d2" category="list-text">Capacità dello storage SSD. Minimo 1024 GiB, massimo 192 TIB.</block>
  <block id="2b410cef067f8cb6a53d05ad2271439b" category="list-text">IOPS SSD con provisioning. In base ai requisiti dei carichi di lavoro, un massimo di 80,000 IOPS SSD per file system.</block>
  <block id="3ab61d0f90da3f61b5741ceb5eb191cc" category="list-text">Capacità di throughput.</block>
  <block id="94412c99e275ca9b650dc655a6e69119" category="list-text">Impostare la password di amministratore fsxadmin/vsadmin. Necessario per l'automazione della configurazione FSX.</block>
  <block id="c9de3d23d86cd04ff4ebf9b1458d70c4" category="list-text">Backup e manutenzione. Disattivare i backup giornalieri automatici; il backup dello storage del database viene eseguito tramite la pianificazione SnapCenter.</block>
  <block id="b2ad37d85471ba4bcaf2c2141b1a576d" category="list-text">Recuperare l'indirizzo IP di gestione SVM e gli indirizzi di accesso specifici del protocollo dalla pagina dei dettagli SVM. Necessario per l'automazione della configurazione FSX.</block>
  <block id="da6dd59d1114c8c42782cf7be16609b7" category="paragraph"><block ref="da6dd59d1114c8c42782cf7be16609b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="15d09dd6ced339d4022eb28264e99543" category="paragraph">Per la configurazione di un cluster ha FSX primario o di standby, consultare le seguenti procedure passo-passo.</block>
  <block id="b2232ae7fcc8b0c89d7c5f62a079a0f9" category="list-text">Dalla console FSX, fare clic su Create file System (Crea file system) per avviare il flusso di lavoro di provisioning FSX.</block>
  <block id="97a3753a6b826d3f7027a60fbc138cac" category="paragraph"><block ref="97a3753a6b826d3f7027a60fbc138cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8863368642c82b76b987f6f94659021d" category="list-text">Selezionare Amazon FSX per NetApp ONTAP. Quindi fare clic su Next (Avanti).</block>
  <block id="064467bccc8ccdcdddef0abbcb9694e0" category="paragraph"><block ref="064467bccc8ccdcdddef0abbcb9694e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4912f49d35e15fbe2d9881db397feb" category="list-text">Selezionare Standard Create (Crea standard) e, in file System Details (Dettagli file system), assegnare un nome al file system, Multi-AZ ha. In base al carico di lavoro del database, scegli IOPS automatici o con provisioning utente fino a 80,000 IOPS SSD. Lo storage FSX viene fornito con caching NVMe fino a 2 TiB al back-end in grado di offrire IOPS misurati ancora più elevati.</block>
  <block id="989e0e2825ffa339331f1712bf630fb4" category="paragraph"><block ref="989e0e2825ffa339331f1712bf630fb4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="463daf4dcf56c33aa1c738fb16d15a27" category="list-text">Nella sezione Network &amp; Security (rete e sicurezza), selezionare VPC, il gruppo di protezione e le subnet. Questi devono essere creati prima dell'implementazione di FSX. In base al ruolo del cluster FSX (primario o standby), posizionare i nodi di storage FSX nelle zone appropriate.</block>
  <block id="3e99b854fb0db94f93ca0ee83bec339a" category="paragraph"><block ref="3e99b854fb0db94f93ca0ee83bec339a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="461a86bccdfc4b32cbc62af43ea97bb3" category="list-text">Nella sezione Security &amp; Encryption (sicurezza e crittografia), accettare l'impostazione predefinita e immettere la password fsxadmin.</block>
  <block id="82d80f8b6e156fcc9a64215b60433630" category="paragraph"><block ref="82d80f8b6e156fcc9a64215b60433630" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e500f789aeb2255be7988000eaff0e8" category="list-text">Immettere il nome SVM e la password vsadmin.</block>
  <block id="84f414cec0c77118741eb2dde6127c3b" category="paragraph"><block ref="84f414cec0c77118741eb2dde6127c3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="979fcc33806fd9594ae032fb4fe33c03" category="list-text">Lasciare vuota la configurazione del volume; a questo punto non è necessario creare un volume.</block>
  <block id="9cc80fc34e28347ad7a346e723ff34ac" category="paragraph"><block ref="9cc80fc34e28347ad7a346e723ff34ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18c8eecfeb7f2ef5acbe5fe3fc1eb398" category="list-text">Esaminare la pagina Summary (Riepilogo) e fare clic su Create file System (Crea file system) per completare il provisioning del file system FSX.</block>
  <block id="992da039cb86b69379ac2a507ea018b2" category="paragraph"><block ref="992da039cb86b69379ac2a507ea018b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edbcb61873336784ce88a841052fa45e" category="section-title">Provisioning dei volumi di database per il database Oracle</block>
  <block id="2dd5d229a6d07b62ae8943394f3a9a05" category="inline-link-macro">Gestione di FSX per volumi ONTAP - creazione di un volume</block>
  <block id="846568a6ddb0b9c5539e3bffbecefada" category="paragraph">Vedere <block ref="031a801f4fdac5974fa88d05f1809883" category="inline-link-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="ca3a40f13fd000ce8baf0adbf73ee561" category="list-text">Dimensionamento appropriato dei volumi di database.</block>
  <block id="383e4b0acf358da05802b9571408fa27" category="list-text">Disattivazione del criterio di tiering del pool di capacità per la configurazione delle performance.</block>
  <block id="086994099a77453bffc426910b6c783b" category="list-text">Abilitazione di Oracle DNFS per i volumi di storage NFS.</block>
  <block id="814d7476ebeabfd3208ed0432cb5ea38" category="list-text">Impostazione di percorsi multipli per i volumi di storage iSCSI.</block>
  <block id="398cf8d5f0d4c7da2b945809849b5105" category="section-title">Creare un volume di database dalla console FSX</block>
  <block id="6afbf36a53c717018bd3d99a6d735c98" category="paragraph">Dalla console AWS FSX è possibile creare tre volumi per lo storage dei file di database Oracle: Uno per il file binario Oracle, uno per i dati Oracle e uno per il log Oracle. Assicurarsi che il nome del volume corrisponda al nome host Oracle (definito nel file hosts nel toolkit di automazione) per un'identificazione corretta. In questo esempio, utilizziamo db1 come nome host EC2 Oracle invece di un tipico nome host basato su indirizzo IP per un'istanza EC2.</block>
  <block id="a732ebfc126f02de82d9e2cb4cba3b30" category="paragraph"><block ref="680b0ab2cf542daf748f396bdb970bee" category="inline-image-macro-rx" type="image"></block>
<block ref="7cf576b202936b23771e87094082b21e" category="inline-image-macro-rx" type="image"></block>
<block ref="9a3c4da48152c48ddee14308524b2023" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05980643a3cf9b987fd426669d474257" category="admonition">La creazione di LUN iSCSI non è attualmente supportata dalla console FSX. Per l'implementazione di LUN iSCSI per Oracle, è possibile creare volumi e LUN utilizzando l'automazione per ONTAP con il toolkit di automazione NetApp.</block>
  <block id="09ee5fa03999e48e0789df07dd602d40" category="section-title">Installare e configurare Oracle su un'istanza EC2 con volumi di database FSX</block>
  <block id="9f92271be71e4bc6eb96033a9ca6d798" category="paragraph">Il team di automazione di NetApp fornisce un kit di automazione per eseguire l'installazione e la configurazione di Oracle sulle istanze EC2 in base alle Best practice. La versione corrente del kit di automazione supporta Oracle 19c su NFS con la patch 19.8 RU predefinita. Il kit di automazione può essere facilmente adattato ad altre patch RU, se necessario.</block>
  <block id="61790d4e19b846282d97e8ceb58e84e0" category="section-title">Preparare un controller Ansible per eseguire l'automazione</block>
  <block id="20f3b4bca246eb128d1c7a63ca954276" category="paragraph">Seguire le istruzioni nella sezione "<block ref="9331131dd8a4a5b5cf5956c248324151" category="inline-xref-macro-rx"></block>" Per eseguire il provisioning di una piccola istanza EC2 Linux per eseguire il controller Ansible. Invece di utilizzare RedHat, Amazon Linux t2.Large con 2vCPU e 8G RAM dovrebbe essere sufficiente.</block>
  <block id="6d42906c67a4432124b27f032f56e4dc" category="section-title">Recuperare il toolkit per l'automazione dell'implementazione NetApp Oracle</block>
  <block id="7beb3cf1c62df8d836bddc0d2b6a3e57" category="paragraph">Accedere all'istanza del controller Ansible EC2 fornita dal passaggio 1 come ec2-user e dalla home directory ec2-user, eseguire il<block ref="aebfab4ae394171a00d2e86fff2ff38b" prefix=" " category="inline-code"></block> comando per clonare una copia del codice di automazione.</block>
  <block id="49130c144c12238cfeca4888e29fbef6" category="section-title">Esegui l'implementazione automatizzata di Oracle 19c utilizzando il toolkit di automazione</block>
  <block id="0e6b1c16527d2792d391c578bbf12efe" category="inline-link-macro">Implementazione CLI Database Oracle 19c</block>
  <block id="ad5d9ee07a5238092f01b66ae1b4ecca" category="paragraph">Vedere queste istruzioni dettagliate <block ref="1d838bac5e7032e3241598fe6496fbd6" category="inline-link-macro-rx"></block> Per implementare Oracle 19c con automazione CLI. La sintassi dei comandi per l'esecuzione di Playbook è leggermente cambiata perché si utilizza una coppia di chiavi SSH invece di una password per l'autenticazione dell'accesso all'host. Il seguente elenco è un riepilogo di alto livello:</block>
  <block id="dc8e3956f25fc431225feacc016616b5" category="list-text">Per impostazione predefinita, un'istanza EC2 utilizza una coppia di chiavi SSH per l'autenticazione dell'accesso. Dalle directory principali di automazione del controller Ansible<block ref="4a1bfa90833e8fe6c82ca6f61f31d147" prefix=" " category="inline-code"></block>, e.<block ref="a1d1fcb426260f0fdb7febffa690e21c" prefix=" " category="inline-code"></block>, Eseguire una copia della chiave SSH<block ref="956c187b3d0c7dcff5b113900e032874" prefix=" " category="inline-code"></block> Per l'host Oracle implementato nella fase "<block ref="9331131dd8a4a5b5cf5956c248324151" category="inline-xref-macro-rx"></block>."</block>
  <block id="9391c5feaa671121befe114951f00442" category="list-text">Accedere all'host DB dell'istanza EC2 come ec2-user e installare la libreria python3.</block>
  <block id="85e9698f3736149506cd49ab88086364" category="list-text">Creare uno spazio di swap di 16 G dal disco root. Per impostazione predefinita, un'istanza EC2 crea spazio di swap nullo. Seguire questa documentazione AWS: <block ref="53c9867a131506eab4afe1a1678bb974" category="inline-link-macro-rx"></block>.</block>
  <block id="be82130abf6bfa8956a5648b39ad4aa8" category="list-text">Tornare al controller Ansible <block ref="e97a9e3bee0cbfb89ba75f3695725fba" prefix="(" category="inline-code"></block>), ed eseguire il playbook pre-clone con i requisiti appropriati e.<block ref="7ee7ce51db32cbf806a0c21c648f4c2b" prefix=" " category="inline-code"></block> tag.</block>
  <block id="83e233b8fca25fb162266daf344246e4" category="list-text">Passare a.<block ref="127b3ddd6eac38dd05a00b88b9348ff5" prefix=" " category="inline-code"></block> Leggere il file README e popolare il file globale<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> file con i parametri globali pertinenti.</block>
  <block id="aed4b8eabfef5056093412d8609b5b9a" category="list-text">Compilare il campo<block ref="caa6779553864dba00727ae27752b182" prefix=" " category="inline-code"></block> file con i relativi parametri in<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> directory.</block>
  <block id="4b8d8efa08e1060a3db2c7693c4de645" category="list-text">Eseguire il playbook per Linux e premere Invio quando viene richiesta la password vsadmin.</block>
  <block id="4d552f393608513441eb151998098b4a" category="list-text">Eseguire il playbook per Oracle e premere invio quando viene richiesta la password vsadmin.</block>
  <block id="af392a54b9a2464fdd334372589f1a39" category="paragraph">Se necessario, modificare il bit di autorizzazione nel file della chiave SSH in 400. Modificare l'host Oracle <block ref="e15cba2a55d1c830968665125de5abf6" prefix="(" category="inline-code"></block> in<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> File) indirizzo IP all'indirizzo pubblico dell'istanza EC2.</block>
  <block id="ac52b3f8d77eb6814ddf5c761b019c22" category="section-title">Impostazione di SnapMirror tra cluster FSX ha primario e di standby</block>
  <block id="3798adb983c6ffabbcf459359d5ddd4c" category="paragraph">Per l'alta disponibilità e il disaster recovery, è possibile configurare la replica di SnapMirror tra il cluster di storage FSX primario e quello di standby. A differenza di altri servizi di cloud storage, FSX consente all'utente di controllare e gestire la replica dello storage a una frequenza e un throughput di replica desiderati. Consente inoltre agli utenti di testare ha/DR senza alcun effetto sulla disponibilità.</block>
  <block id="5414f0571ab88c4269ee945ce4291f65" category="paragraph">La seguente procedura illustra come impostare la replica tra un cluster di storage FSX primario e uno di standby.</block>
  <block id="006c42f009ead3331b1f69ac1979609d" category="list-text">Configurare il peering del cluster primario e di standby. Accedere al cluster primario come utente fsxadmin ed eseguire il seguente comando. Questo processo di creazione reciproco esegue il comando create sul cluster primario e sul cluster di standby. Sostituire<block ref="33c864f25bec561bad1458ab06ec3177" prefix=" " category="inline-code"></block> con il nome appropriato per il proprio ambiente.</block>
  <block id="c725d46c724a573eb994f08a1f309eec" category="list-text">Impostare il peering di VServer tra il cluster primario e quello di standby. Accedere al cluster primario come utente vsadmin ed eseguire il seguente comando. Sostituire<block ref="f826cd2f4a01fe594ea3f06fc8e9a764" prefix=" " category="inline-code"></block>,<block ref="73483be5a30a2604d22183209c74149e" prefix=" " category="inline-code"></block>,<block ref="33c864f25bec561bad1458ab06ec3177" prefix=" " category="inline-code"></block> con i nomi appropriati per il proprio ambiente.</block>
  <block id="91ba2ff3a22b9830c626441ad69c84ce" category="list-text">Verificare che i peering del cluster e del vserver siano impostati correttamente.</block>
  <block id="7b39dc0f7648c038ec8ac59504316d0e" category="paragraph"><block ref="7b39dc0f7648c038ec8ac59504316d0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4cb6743e20f6b87b419d9386d784acc" category="list-text">Creare volumi NFS di destinazione nel cluster FSX di standby per ogni volume di origine nel cluster FSX primario. Sostituire il nome del volume in base all'ambiente in uso.</block>
  <block id="8f65518a43c3a1ba084510438fa2d7d3" category="list-text">È inoltre possibile creare volumi e LUN iSCSI per il file binario Oracle, i dati Oracle e il log Oracle, se il protocollo iSCSI viene utilizzato per l'accesso ai dati. Lasciare circa il 10% di spazio libero nei volumi per le snapshot.</block>
  <block id="43aea99cd4b66a7a2f8efdc090e3a5ad" category="paragraph">Vol create -volume dr_db1_log -aggregate aggr1 -size 250G -state online -policy default -unix-permissions ---rwxr-xr-x -type RW</block>
  <block id="18274474e00c13f064a0b4df0b516185" category="list-text">Per le LUN iSCSI, creare il mapping per l'iniziatore host Oracle per ogni LUN, utilizzando il LUN binario come esempio. Sostituire l'igroup con un nome appropriato per l'ambiente e incrementare il lun-id per ogni LUN aggiuntivo.</block>
  <block id="0c2c0f6ddcbbbf39434893162abce545" category="list-text">Creare una relazione SnapMirror tra il volume del database primario e quello di standby. Sostituire il nome SVM appropriato per il proprio ambiente.s.</block>
  <block id="a25539ee33148e6d4880b87e1378cafe" category="paragraph">Questa configurazione di SnapMirror può essere automatizzata con un NetApp Automation Toolkit per i volumi di database NFS. Il toolkit è disponibile per il download dal sito GitHub pubblico di NetApp.</block>
  <block id="f9f129d1122f9209f8f27fa07a5ee4b2" category="paragraph">Leggere attentamente le istruzioni di README prima di eseguire il test di configurazione e failover.</block>
  <block id="03b2167f2383aa796f361c5c1c689a49" category="admonition">La replica del binario Oracle dal cluster primario a quello in standby potrebbe avere implicazioni di licenza Oracle. Per ulteriori chiarimenti, contattare il proprio rappresentante di licenza Oracle. In alternativa, è possibile installare e configurare Oracle al momento del ripristino e del failover.</block>
  <block id="fa697481d9c5655bd57d6ee69f0e9f07" category="section-title">Implementazione di SnapCenter</block>
  <block id="3f4b23cd1391b97e8a33f3973471103b" category="section-title">Installazione di SnapCenter</block>
  <block id="4c88778182d61374292e3c4ad43ae50e" category="inline-link-macro">Installazione del server SnapCenter</block>
  <block id="282e73196d7c89bb5ec3820592ecee7c" category="paragraph">Segui <block ref="9cac1dd5d049b670d2cd847d9e42d30c" category="inline-link-macro-rx"></block> Per installare il server SnapCenter. La presente documentazione descrive come installare un server SnapCenter standalone. Una versione SaaS di SnapCenter è in fase di revisione beta e potrebbe essere disponibile a breve. Se necessario, rivolgiti al tuo rappresentante NetApp per verificare la disponibilità.</block>
  <block id="a4c2182f79a7834db47fccf9c264332d" category="section-title">Configurare il plug-in SnapCenter per l'host EC2 Oracle</block>
  <block id="8d0edf4e55e8bc1a96862466762dcdd6" category="list-text">Dopo l'installazione automatica di SnapCenter, accedere a SnapCenter come utente amministrativo per l'host Windows su cui è installato il server SnapCenter.</block>
  <block id="27ee26e15e1da051ff520bf3f87f2a03" category="paragraph"><block ref="27ee26e15e1da051ff520bf3f87f2a03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4af2386526da94f1d101d825c0a623e0" category="list-text">Dal menu a sinistra, fare clic su Impostazioni, quindi su credenziale e nuovo per aggiungere le credenziali utente ec2 per l'installazione del plug-in SnapCenter.</block>
  <block id="252932f5140410e8d8795c4236e41b47" category="paragraph"><block ref="252932f5140410e8d8795c4236e41b47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37fc637fcb7f9b2e4336350dd7d4775e" category="list-text">Reimpostare la password ec2-user e attivare l'autenticazione SSH della password modificando il<block ref="07b421e5f5e0300b1a0fd6cc22745306" prefix=" " category="inline-code"></block> File sull'host dell'istanza EC2.</block>
  <block id="c1e0ecc2d0f187a040af9ef1e783314d" category="list-text">Verificare che la casella di controllo "Usa privilegi sudo" sia selezionata. È sufficiente reimpostare la password ec2-user nel passaggio precedente.</block>
  <block id="cc57c2c5394de6466406382d198ba244" category="paragraph"><block ref="cc57c2c5394de6466406382d198ba244" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3326cea52418b74168243fb56340785" category="list-text">Aggiungere il nome del server SnapCenter e l'indirizzo IP al file host dell'istanza EC2 per la risoluzione dei nomi.</block>
  <block id="59c8e627359bc3d4ce92126cbb1356cc" category="list-text">Sull'host Windows del server SnapCenter, aggiungere l'indirizzo IP dell'host dell'istanza EC2 al file host di Windows<block ref="803976de87f6862821bd3c4d94e0ff2b" prefix=" " category="inline-code"></block>.</block>
  <block id="4f91fe76ef9595ef98ee3b0c06a43160" category="list-text">Nel menu a sinistra, selezionare host &gt; host gestiti, quindi fare clic su Aggiungi per aggiungere l'host dell'istanza EC2 a SnapCenter.</block>
  <block id="a5714b50c71edc910f423bfdc433d799" category="paragraph"><block ref="a5714b50c71edc910f423bfdc433d799" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb20727c22e9cab381fd0cd7e817ab85" category="paragraph">Controllare Oracle Database e, prima di inviare, fare clic su More Options (altre opzioni).</block>
  <block id="7fab569defa89099ea4c5d28723e2031" category="paragraph"><block ref="7fab569defa89099ea4c5d28723e2031" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e249b54031e8a30915659857356cab" category="paragraph">Selezionare Ignora controlli preinstallazione. Confermare l'omissione dei controlli di preinstallazione, quindi fare clic su Invia dopo il salvataggio.</block>
  <block id="3d82631a68b3ec0960761342005b2eca" category="paragraph"><block ref="3d82631a68b3ec0960761342005b2eca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d66b31e61ce12ed5022484588882f5f" category="paragraph">Viene richiesto di confermare l'impronta digitale, quindi fare clic su Conferma e Invia.</block>
  <block id="795d864d6ec7d5ca3d8c36c9a83bba6e" category="paragraph"><block ref="795d864d6ec7d5ca3d8c36c9a83bba6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99177ab734274d9f5f703761e4b2deef" category="paragraph">Una volta completata la configurazione del plug-in, lo stato generale dell'host gestito viene visualizzato come in esecuzione.</block>
  <block id="1fa50503e60bc51f7dea31d9e91c9c20" category="paragraph"><block ref="1fa50503e60bc51f7dea31d9e91c9c20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="112fdeb0eaa93f627cf0effc06f49c76" category="section-title">Configurare i criteri di backup per il database Oracle</block>
  <block id="c615eed91e2ab578525394d0ff0138d9" category="inline-link-macro">Impostare il criterio di backup del database in SnapCenter</block>
  <block id="30baaa9bedea395f88f6183eda043198" category="paragraph">Fare riferimento a questa sezione <block ref="5b001af64dcc5050a16c7369f5f2fae2" category="inline-link-macro-rx"></block> Per informazioni dettagliate sulla configurazione della policy di backup del database Oracle.</block>
  <block id="6bfb2a8edb5f9cfb06059a588dda9cc0" category="paragraph">In genere, è necessario creare una policy per il backup completo del database Oracle Snapshot e una policy per il backup dello snapshot Oracle con solo log di archiviazione.</block>
  <block id="708ae75a87a6997af6838bc2e5149a28" category="admonition">È possibile attivare la funzione di eliminazione dei log di archiviazione Oracle nel criterio di backup per controllare lo spazio di archiviazione dei log. Selezionare "Update SnapMirror after creating a local Snapshot copy" (Aggiorna SnapMirror dopo la creazione di una copia Snapshot locale) in "Select Secondary Replication Option" (Seleziona opzione di replica secondaria) per replicare in una posizione di standby per ha o DR</block>
  <block id="acea2698961ae21a708203b9a9b86b94" category="section-title">Configurare il backup e la pianificazione del database Oracle</block>
  <block id="56f3e355b3a4359c9a0808d978ca484c" category="paragraph">Il backup del database in SnapCenter è configurabile dall'utente e può essere impostato singolarmente o come gruppo in un gruppo di risorse. L'intervallo di backup dipende dagli obiettivi RTO e RPO. NetApp consiglia di eseguire un backup completo del database ogni poche ore e di archiviare il backup del log con una frequenza maggiore, ad esempio 10-15 minuti, per un ripristino rapido.</block>
  <block id="8ecb914dad4186dafb38268be6fc8a1f" category="inline-link-macro">Implementare policy di backup per proteggere il database</block>
  <block id="cd6290f31cba79c826366f0927d0dc94" category="paragraph">Fare riferimento alla sezione Oracle di <block ref="6d8b99fb2ff81ed91f5551e33542f4f8" category="inline-link-macro-rx"></block> per una procedura dettagliata per l'implementazione della policy di backup creata nella sezione <block ref="f2afcb5a9b8ad2d8fe33e91cb4edb80f" category="inline-xref-macro-rx"></block> e per la pianificazione dei processi di backup.</block>
  <block id="b47b1d2e2c373fd6c07f22a130e90a41" category="paragraph">L'immagine seguente mostra un esempio dei gruppi di risorse configurati per il backup di un database Oracle.</block>
  <block id="9736ab13cec4c0e5ba0c09476a101fb2" category="paragraph"><block ref="9736ab13cec4c0e5ba0c09476a101fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2d9cc2beb2b12bdad529e6d42551092" category="inline-link-macro">Avanti: Gestione del database.</block>
  <block id="454fb11269c81c93532752028abffbcd" category="paragraph"><block ref="454fb11269c81c93532752028abffbcd" category="inline-link-macro-rx"></block></block>
  <block id="a23b0f6840eece1bcfc1a2ce047e740e" category="doc">TR-3633: Database Oracle su ONTAP</block>
  <block id="3b1f454fff17aa123534722dc8b6870b" category="paragraph">Jeffrey Steiner, NetApp</block>
  <block id="bb00932088674136830625fe37741beb" category="paragraph">Consultare <block ref="d0d24196afeacb93f8904954168bf8db" category="inline-link-macro-rx"></block> Per determinare se l'ambiente, le configurazioni e le versioni specificate in TR-3633 supportano il proprio ambiente.</block>
  <block id="8b742cda768ff35bcc87798d5c8efcf1" category="paragraph"><block ref="8b742cda768ff35bcc87798d5c8efcf1" category="inline-link-macro-rx"></block></block>
  <block id="0679a51ae3a4071a6bd3dedbe97fd329" category="summary">In questa pagina viene descritto il metodo automatizzato per l'implementazione della protezione dei dati Oracle sullo storage NetApp ONTAP.</block>
  <block id="cb59b87e00d11222bfd9159d0d23836f" category="doc">Per iniziare</block>
  <block id="22e3bbd761fbb7ae69b8035eb12f222d" category="paragraph">Questa soluzione è stata progettata per essere eseguita in un ambiente AWX/Tower.</block>
  <block id="008ba800d97cb969def651e93f0d93fb" category="section-title">AWX/Tower</block>
  <block id="a481f1841043d60245f18522a86731b1" category="paragraph">Per gli ambienti AWX/tower, viene fornita una guida alla creazione di un inventario della gestione del cluster ONTAP e del server Oracle (IP e nomi host), alla creazione di credenziali, alla configurazione di un progetto che estrae il codice Ansible da NetApp Automation Github e al modello di lavoro che avvia l'automazione.</block>
  <block id="ad5310e9dcd8f367be2b92490488d86d" category="list-text">La soluzione è stata progettata per essere eseguita in uno scenario di cloud privato (da on-premise a on-premise) e in un cloud ibrido (da on-premise a cloud pubblico Cloud Volumes ONTAP [CVO])</block>
  <block id="5055de7b9d28f88e537f99f34959c80c" category="list-text">Compilare le variabili specifiche del proprio ambiente, quindi copiarle e incollarle nei campi Extra Vars del modello di lavoro.</block>
  <block id="d116f375db402ba471f519c0a4df15dc" category="list-text">Una volta aggiunti i var aggiuntivi al modello di lavoro, è possibile avviare l'automazione.</block>
  <block id="4d0c05180ba83e5c8a9bbac094c365e2" category="list-text">L'automazione viene eseguita in tre fasi (Setup, Replication Schedule for Oracle binaries, Database, Logs e Replication Schedule solo per i registri) e una quarta fase per il ripristino del database in un sito DR.</block>
  <block id="936c99ed52ca08a052ebf611285dd998" category="inline-link-macro">Raccogliere i prerequisiti per le implementazioni CVO e Connector</block>
  <block id="ec329a9106131eb9bf99b0f9e67b0564" category="list-text">Per istruzioni dettagliate su come ottenere le chiavi e i token necessari per la visita CVO Data Protection <block ref="e21f73de51752f791cddc773d1f38740" category="inline-link-macro-rx"></block></block>
  <block id="13716f12996b882bb4c7e0bd84c7c128" category="open-title">&lt;strong class="big"&gt; oN-&lt;/strong&gt; &lt;strong&gt;|&lt;/strong&gt;</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">Ambiente</block>
  <block id="9d5cfca4ad04b54536e5ad15210f7dc2" category="cell">*Ambiente Ansible*</block>
  <block id="3f0733e14ebf265f0abf4b32371043ac" category="cell">Ansible v.2.10 e versioni successive</block>
  <block id="3c91a74236fab100f024452f6df13b5e" category="cell">Python 3</block>
  <block id="215b38d177939de20bbb7b7913ce32c1" category="cell">Librerie Python - netapp-lib - xmltodict - jmespath</block>
  <block id="d911b17f4f4cdcca62a04ad77aa9403d" category="cell">*ONTAP*</block>
  <block id="72bd33cc372377848ab3bb360deb365e" category="cell">ONTAP versione 9.8 +</block>
  <block id="10aadda84b1b1da26c3757dfdb59379d" category="cell">Due aggregati di dati</block>
  <block id="9f998f9668ffe69c62d78760d1c531f0" category="cell">VLAN NFS e ifgrp create</block>
  <block id="ba5f343281b90f0408008806c66bce86" category="cell">*Server Oracle*</block>
  <block id="6f1de5f0d7966ebf5f8d255fe28ebffe" category="cell">RHEL 7/8</block>
  <block id="aa596da3b79631d86c0d35e1c4b03aac" category="cell">Oracle Linux 7/8</block>
  <block id="814e8f57514db6134b6ffcd7a4ce20a6" category="cell">Interfacce di rete per NFS, gestione pubblica e opzionale</block>
  <block id="3ca63226b942aff3abcf62934a91e382" category="cell">Ambiente Oracle esistente on-source e sistema operativo Linux equivalente a destinazione (sito DR o cloud pubblico)</block>
  <block id="6114118ecf4e8d86a2e7c80bfab462f6" category="open-title">&lt;strong class="big"&gt; &lt;/strong&gt;</block>
  <block id="675b1e5a01195fa5d419962701704b96" category="cell">Impostare lo spazio di swap appropriato sull'istanza Oracle EC2, per impostazione predefinita alcune istanze EC2 sono implementate con 0 swap</block>
  <block id="2f960df807c8ad51e74c447149eb2033" category="cell">*Cloud Manager/AWS*</block>
  <block id="571f37fae4494df03321c2abe1fcc053" category="cell">Chiave segreta/accesso AWS</block>
  <block id="7a5be8c4513f3bd0696db24a6bd977f4" category="cell">NetApp Cloud Manager</block>
  <block id="99e55608ac5f1697eb6804aaf586af09" category="cell">Token di aggiornamento di NetApp Cloud Manager</block>
  <block id="ae9205dab0c26cca7762be5149a93923" category="section-title">Dettagli sull'automazione</block>
  <block id="ba0676e7ae183e2c0bbd54261818154f" category="paragraph">Questa implementazione automatica è progettata con un singolo playbook Ansible che consiste di tre ruoli separati. I ruoli sono per le configurazioni ONTAP, Linux e Oracle. La seguente tabella descrive le attività automatizzate.</block>
  <block id="3f9ec2a23fee1cafeb1a700de677caac" category="cell">Playbook</block>
  <block id="1f959110c5104b300b1a3d5fe3ee80dc" category="cell">*ontap_setup*</block>
  <block id="c0563eda0fb9d63778efe04a13a5d744" category="cell">Verifica preliminare dell'ambiente ONTAP</block>
  <block id="b7ed1e5c864a764f83f035d7f4f774ee" category="cell">Creazione di LIF Intercluster sul cluster di origine (OPZIONALE)</block>
  <block id="73ddb5848c16203494697871a4e993cd" category="cell">Creazione di LIF Intercluster sul cluster di destinazione (OPZIONALE)</block>
  <block id="04a35ce053d611d390fc192544fa4899" category="cell">Creazione del peering di cluster e SVM</block>
  <block id="4605aea1d05aa2979e72d73dd2c51773" category="cell">Creazione di SnapMirror di destinazione e inizializzazione dei volumi Oracle designati</block>
  <block id="0dd4c7b6672d8937b6eb899b454fb7fe" category="cell">*ora_replication_cg*</block>
  <block id="7187aaa97acef94360159347d76a84c9" category="cell">Abilitare la modalità di backup per ogni database in /etc/oratab</block>
  <block id="f9198142d6e5690166713858ae8a0cdd" category="cell">Snapshot dei volumi Oracle Binary e Database</block>
  <block id="23ba14a0a5cf33c38faec5b66fff712e" category="cell">SnapMirror aggiornato</block>
  <block id="114debcae141b96db77c72e8a1e8fadb" category="cell">Disattivare la modalità di backup per ogni database in /etc/oratab</block>
  <block id="682094861a79bcba0e0ab2e193198762" category="cell">*ora_replication_log*</block>
  <block id="1d03ae98454d1c807318a1e29a4e2736" category="cell">Cambiare il log corrente per ogni database in /etc/oratab</block>
  <block id="47e4696811eedec695f727189503e8df" category="cell">Snapshot del volume Oracle Log</block>
  <block id="86836efae3e3d868a96ae69bcbc987ba" category="cell">*ora_recovery*</block>
  <block id="6ceab4515ef4144abed0f0ce5ed3038f" category="cell">Interrompere SnapMirror</block>
  <block id="a6066c717f63ac99226b48abb4cf1d85" category="cell">Abilitare NFS e creare un percorso di giunzione per i volumi Oracle sulla destinazione</block>
  <block id="aa46cdc29b66725a1180f57d02f0cee3" category="cell">Configurare l'host Oracle DR</block>
  <block id="dea9253f9b15f57a0c2161848a3c27a3" category="cell">Montare e verificare i volumi Oracle</block>
  <block id="ee95819ff53983a149759d555a93ba4b" category="cell">Ripristinare e avviare il database Oracle</block>
  <block id="5a6b57bc1fdf2f0e1259ed22f1d027a4" category="cell">*cvo_setup*</block>
  <block id="331c87cd495ffdc9cd55d8b3935a75f5" category="cell">Verifica preliminare dell'ambiente</block>
  <block id="5f17c8d8d95282db12506044ba4d6ab9" category="cell">AWS Configure/AWS Access Key ID/Secret Key/Default Region</block>
  <block id="cef449920fe163cdd74231266cbdf23d" category="cell">Creazione del ruolo AWS</block>
  <block id="85a4bcbc96cde90931ad369de96535b2" category="cell">Creazione dell'istanza di NetApp Cloud Manager Connector in AWS</block>
  <block id="abe14752834b641e86064c7214f6719c" category="cell">Creazione dell'istanza CVO (Cloud Volumes ONTAP) in AWS</block>
  <block id="c2a9449cd3b0ae879520f450b65b1621" category="cell">Aggiungere il cluster ONTAP di origine on-premise a NetApp Cloud Manager</block>
  <block id="fbb54d6efa6ca64af90fbe2289812be8" category="cell">Abilitare NFS e creare un percorso di giunzione per i volumi Oracle sul CVO di destinazione</block>
  <block id="bf60025632dd0c4a2cf35e8b33e80619" category="section-title">Parametri predefiniti</block>
  <block id="3ef6389d9b9aacdce331793dd2a96ce8" category="paragraph">Per semplificare l'automazione, abbiamo preimpostato molti parametri Oracle richiesti con valori predefiniti. In genere non è necessario modificare i parametri predefiniti per la maggior parte delle implementazioni. Un utente più avanzato può apportare modifiche ai parametri predefiniti con cautela. I parametri predefiniti si trovano in ogni cartella di ruoli nella directory dei valori predefiniti.</block>
  <block id="794df3791a8c800841516007427a2aa3" category="section-title">Licenza</block>
  <block id="19adadc497199e16f07f9744d43b2899" category="paragraph">Leggere le informazioni sulla licenza come indicato nel repository Github. Accedendo, scaricando, installando o utilizzando il contenuto di questo repository, l'utente accetta i termini della licenza stabilita <block ref="07d15b3b85718d883b437fb3739e59a7" category="inline-link-macro-rx"></block>.</block>
  <block id="87d624bc8a7f555a711e7214ee002eec" category="paragraph">Si noti che esistono alcune limitazioni relative alla produzione e/o alla condivisione di qualsiasi opera derivata con il contenuto di questo repository. Leggere attentamente i termini del <block ref="49480c711afcff6aca610d8294731030" category="inline-link-macro-rx"></block> prima di utilizzare il contenuto. Se non si accettano tutti i termini, non accedere, scaricare o utilizzare il contenuto di questo repository.</block>
  <block id="a98d844e94ad28c8e0fb089e005d6b9f" category="inline-link-macro">Qui per le procedure AWX/Tower dettagliate</block>
  <block id="7e599865fd1cdad0e26add5715f65267" category="paragraph">Una volta pronti, fare clic su <block ref="d28bc5520349bb0598caaa5132432326" category="inline-link-macro-rx"></block>.</block>
  <block id="6845898fa7e9ec1fa3b8934d8e91b0c1" category="summary">La soluzione offre una panoramica e dettagli su backup, ripristino e clonazione di database Oracle utilizzando NetApp SnapCenter SaaS utilizzando la console BlueXP.</block>
  <block id="9caa022ffa5eb0757a1a86c936148e7f" category="doc">TR-4964: Backup, ripristino e clonazione di database Oracle con i servizi SnapCenter</block>
  <block id="8ae5c33b293249b4befae60cdc1d6364" category="paragraph">I servizi SnapCenter sono la versione SaaS del classico tool di interfaccia utente per la gestione dei database SnapCenter disponibile tramite la console di gestione del cloud NetApp BlueXP. È parte integrante dell'offerta NetApp di cloud-backup e protezione dei dati per database come Oracle e HANA in esecuzione su cloud storage NetApp. Questo servizio basato su SaaS semplifica l'implementazione di un server standalone SnapCenter tradizionale, che in genere richiede un server Windows che opera in un ambiente di dominio Windows.</block>
  <block id="05530a14144f96daea2a6f96bb61b38b" category="paragraph">In questa documentazione, illustreremo come configurare i servizi SnapCenter per il backup, il ripristino e la clonazione dei database Oracle distribuiti su Amazon FSX per lo storage ONTAP e le istanze di calcolo EC2. Sebbene sia molto più semplice da configurare e utilizzare, i servizi SnapCenter offrono funzionalità chiave disponibili nel tool precedente dell'interfaccia utente di SnapCenter.</block>
  <block id="d47397f53e6c7682397a8f8688daddcc" category="list-text">Backup del database con snapshot per i database Oracle ospitati in Amazon FSX per ONTAP</block>
  <block id="403ca933973134cbaf8f9354830b4d9c" category="list-text">Ripristino del database Oracle in caso di guasto</block>
  <block id="6f2d8b46ec98e47be22d4747b82a02d2" category="list-text">Clonazione rapida ed efficiente in termini di storage dei database primari per un ambiente di sviluppo/test o altri casi di utilizzo</block>
  <block id="de98fb1438e12380191eaa97d6c6b90d" category="paragraph">Questa soluzione è destinata ai seguenti destinatari:</block>
  <block id="bdc080d1f53262a817a1472a559d75dd" category="list-text">Il DBA che gestisce i database Oracle in esecuzione su Amazon FSX per lo storage ONTAP</block>
  <block id="d6e066caa1ab2a9ead96779ac0a95670" category="list-text">Il Solution architect che è interessato a testare il backup, il ripristino e la clonazione del database Oracle nel cloud AWS pubblico</block>
  <block id="3e05bb0c3eae0733dd3f5b6eda0da89e" category="list-text">L'amministratore dello storage che supporta e gestisce Amazon FSX per lo storage ONTAP</block>
  <block id="e55870c74749ffe7a1d8b4c1a9cb5b60" category="list-text">Il proprietario dell'applicazione che possiede applicazioni distribuite su Amazon FSX per lo storage ONTAP</block>
  <block id="a9bed64bc676f536e10a189728888614" category="image-alt">Questa immagine fornisce un'immagine dettagliata del Cloud Backup for Application all'interno della console BlueXP, inclusi l'interfaccia utente, il connettore e le risorse gestite.</block>
  <block id="ccd967b78d046cba29272c0823500e3f" category="paragraph">Questa immagine fornisce un'immagine dettagliata di Cloud Backup for Application all'interno della console BlueXP, che include l'interfaccia utente, il connettore e le risorse gestite.</block>
  <block id="6f4cd1b0523380b825fa78ec70975a14" category="cell">Due istanze EC2 T2 xlarge EC2, una come server DB primario e l'altra come server DB clone</block>
  <block id="86fae68c14c723bf36942c2c83e8a847" category="list-text">*Il connettore deve essere implementato nello stesso VPC del database e FSX.* quando possibile, il connettore deve essere implementato nello stesso AWS VPC, che consente la connettività allo storage FSX e all'istanza di calcolo EC2.</block>
  <block id="f4c5cbc76886ee4d3b06a979e007f04c" category="list-text">*Una policy IAM AWS creata per SnapCenter Connector.* la policy in formato JSON è disponibile nella documentazione dettagliata del servizio SnapCenter. Quando si avvia la distribuzione di Connector con la console BlueXP, viene richiesto di impostare i prerequisiti. Il criterio deve essere assegnato all'account utente AWS proprietario del connettore.</block>
  <block id="9a4e5feb06bb2dae4e8b115b6528fb7d" category="list-text">*La chiave di accesso dell'account AWS e la coppia di chiavi SSH create nell'account AWS.* la coppia di chiavi SSH viene assegnata all'utente ec2 per l'accesso all'host del connettore e l'implementazione di un plug-in del database nell'host del server DB EC2. La chiave di accesso concede l'autorizzazione per il provisioning del connettore richiesto.</block>
  <block id="e59f5f07f322e64b80fa8264dd4389e7" category="list-text">*Una credenziale aggiunta all'impostazione della console BlueXP.* per aggiungere Amazon FSX per ONTAP all'ambiente di lavoro BlueXP, una credenziale che concede le autorizzazioni per accedere ad Amazon FSX per ONTAP dalla console BlueXP viene impostata nell'impostazione della console BlueXP.</block>
  <block id="7d3fac201e712c335b848cf4411e68e0" category="list-text">*Plug-in SnapCenter implementato nell'host dell'istanza del database EC2.* i servizi SnapCenter effettuano chiamate API eseguite dal plug-in SnapCenter sull'host dell'istanza del database EC2. È necessario implementarlo prima di configurare i servizi.</block>
  <block id="16d04337973f389d2f7da86eac115afd" category="paragraph">È disponibile un'ampia documentazione NetApp con un ambito più ampio per aiutarti a proteggere i dati delle applicazioni native del cloud. L'obiettivo di questa documentazione è fornire procedure passo-passo che coprano l'implementazione del servizio SnapCenter con la console BlueXP per proteggere il database Oracle distribuito su Amazon FSX per ONTAP e un'istanza di calcolo EC2. Questo documento contiene alcuni dettagli che potrebbero non essere presenti nelle istruzioni più generali.</block>
  <block id="20c4c0cc24d7fc086bd9c72220d4827f" category="paragraph">Per iniziare, attenersi alla seguente procedura:</block>
  <block id="eb5668f5c3459c84cc715cf197e7c91a" category="inline-link-macro">Proteggi i dati delle tue applicazioni native nel cloud</block>
  <block id="fba4ab9f47a6aa18ae1b02fb3d8f6db1" category="list-text">Leggere le istruzioni generali <block ref="ac041fb7031b2bcbcb203adcabf84a4f" category="inline-link-macro-rx"></block> E le sezioni relative a Oracle e Amazon FSX per ONTAP.</block>
  <block id="f2f7f5c9af8a75d22b9aca95d23faad9" category="list-text">Guarda il video seguente.</block>
  <block id="80478dbd4349cfca50f458d912a95795" category="section-title">Prerequisiti per l'implementazione del servizio SnapCenter</block>
  <block id="ee260886ab2b6b27905543032620ac6f" category="list-text">Un server database Oracle primario su un'istanza EC2 con un database Oracle completamente implementato e in esecuzione.</block>
  <block id="d7ab5019b6e4c888e46cb145fb2d5fc4" category="list-text">Un cluster Amazon FSX per ONTAP implementato in AWS che ospita il database sopra indicato.</block>
  <block id="0191527f1e188e7a6d18289a5ac9c936" category="list-text">Un server di database opzionale su un'istanza EC2 che può essere utilizzato per testare la clonazione di un database Oracle su un host alternativo allo scopo di supportare un carico di lavoro di sviluppo/test o qualsiasi caso di utilizzo che richieda un set di dati completo del database Oracle di produzione.</block>
  <block id="ab12a73272bb7f9d19f02c65ce057f61" category="inline-link-macro">Implementazione e protezione di database Oracle in AWS FSX/EC2 con iSCSI/ASM</block>
  <block id="58580b46e10b35944b7405415499a369" category="list-text">Se hai bisogno di aiuto per soddisfare i prerequisiti sopra indicati per l'implementazione del database Oracle su Amazon FSX per ONTAP e istanze di calcolo EC2, consulta <block ref="84dfb8b43ed6d356540ab11fdb4b0e89" category="inline-link-macro-rx"></block>.</block>
  <block id="b8b1139d652a0eeb20f8d04852ac0ff4" category="section-title">Preparazione al BlueXP</block>
  <block id="87d337785ad5798c5ccb41300628991a" category="list-text">Utilizzare il link <block ref="f796c57cbc184209dde3e35268bc382f" category="inline-link-macro-rx"></block> Per iscriversi all'accesso alla console BlueXP.</block>
  <block id="398c495b453cb83c96b3fd0cda544bd5" category="list-text">Per configurare BlueXP in modo da gestire le risorse cloud AWS come Amazon FSX per ONTAP, dovresti già avere un account AWS configurato. È quindi possibile accedere all'account AWS per creare un criterio IAM per concedere l'accesso al servizio SnapCenter a un account AWS da utilizzare per l'implementazione del connettore.</block>
  <block id="ead8f2b206d64f3dc022b5aff7ebf5ef" category="inline-image-macro">Schermata che mostra questo passaggio nella GUI.</block>
  <block id="f6d580bf790e26134ef61bf9d6fe18fe" category="paragraph"><block ref="f6d580bf790e26134ef61bf9d6fe18fe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72c085381ac33d4812eff61d168042a4" category="paragraph">Il criterio deve essere configurato con una stringa JSON disponibile all'avvio del provisioning del connettore e viene richiesto di ricordare che è stata creata e concessa una policy IAM a un account AWS utilizzato per l'implementazione del connettore.</block>
  <block id="a54002868f2640fbd1fc4f9adc7d9df8" category="list-text">Sono inoltre necessari il VPC AWS, una chiave e i segreti per l'account AWS, una chiave SSH per l'accesso EC2, un gruppo di sicurezza e così via, pronti per il provisioning del connettore.</block>
  <block id="43e23d889dea00cd09a68857a66540a2" category="section-title">Implementare un connettore per i servizi SnapCenter</block>
  <block id="6e557be0e45c40d783bbd8866f9a399d" category="list-text">Accedere alla console BlueXP. Per un account condiviso, è consigliabile creare un singolo spazio di lavoro facendo clic su *account* &gt; *Manage account* &gt; *Workspace* per aggiungere un nuovo spazio di lavoro.</block>
  <block id="ff983eb1cf4195dbceed01ba6d95f4bd" category="paragraph"><block ref="ff983eb1cf4195dbceed01ba6d95f4bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c47cec29fcf0d8e782f2c91ad12914b4" category="list-text">Fare clic su *Add a Connector* (Aggiungi un connettore) per avviare il flusso di lavoro di provisioning del connettore.</block>
  <block id="06daec2780fc4a5c0089241439b6abc4" category="paragraph"><block ref="06daec2780fc4a5c0089241439b6abc4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bb78288dc7f5beb506e79a3af8041de" category="list-text">Scegli il tuo cloud provider (in questo caso, *Amazon Web Services*).</block>
  <block id="8087e08b633357d4802bcc914799e1e0" category="paragraph"><block ref="8087e08b633357d4802bcc914799e1e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="06a5177c61e31798acfdd25d766ef121" category="list-text">Ignorare i passaggi *Permission*, *Authentication* e *Networking* se sono già stati configurati nell'account AWS. In caso contrario, è necessario configurarli prima di procedere. Da qui, è possibile recuperare anche le autorizzazioni per il criterio AWS a cui si fa riferimento nella sezione precedente "<block ref="2204dd011c923b13eaa19e758c798231" category="inline-xref-macro-rx"></block>."</block>
  <block id="79463376ddcde3119f1d61ab3e8ace01" category="paragraph"><block ref="79463376ddcde3119f1d61ab3e8ace01" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d3aa90e294a5c6f1393c075c038193c2" category="list-text">Inserire la chiave di accesso e la chiave segreta per l'autenticazione dell'account AWS.</block>
  <block id="6a45e1d81bff2e550eac67a6a5fa7cbf" category="paragraph"><block ref="6a45e1d81bff2e550eac67a6a5fa7cbf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="712e596a90ac38ed31c6d4d55347a559" category="list-text">Assegnare un nome all'istanza del connettore e selezionare *Crea ruolo* in *Dettagli*.</block>
  <block id="98c5e6a562ea83f6e395b91667156df3" category="paragraph"><block ref="98c5e6a562ea83f6e395b91667156df3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a195a46dbd792968c9fcafd533a33b51" category="list-text">Configurare la rete con la coppia di chiavi VPC, subnet e SSH appropriata per l'accesso EC2.</block>
  <block id="fde599fe1b1ccfb7275d4e17f0b4fc17" category="paragraph"><block ref="fde599fe1b1ccfb7275d4e17f0b4fc17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1509007123cad8688bdef6b265c409ce" category="list-text">Impostare il gruppo di protezione per il connettore.</block>
  <block id="e3d2711238be85fe0acd7b353cb0571c" category="paragraph"><block ref="e3d2711238be85fe0acd7b353cb0571c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f067570884442aa68da666583a8530cc" category="list-text">Esaminare la pagina di riepilogo e fare clic su *Aggiungi* per avviare la creazione del connettore. In genere occorrono circa 10 minuti per completare l'implementazione. Una volta completata l'operazione, l'istanza del connettore viene visualizzata nella dashboard di AWS EC2.</block>
  <block id="165138d0d406e2c17d45e777fc26ebc5" category="paragraph"><block ref="165138d0d406e2c17d45e777fc26ebc5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="96e8e4df8b3ca0b4eec3a79081f69a5f" category="inline-link-macro">Implementare il plug-in utilizzando lo script e aggiungere l'host dall'interfaccia utente utilizzando l'opzione manuale</block>
  <block id="bb7fc4f6e011b0abf2d72151ba43d448" category="list-text">Una volta implementato il connettore, accedere all'host EC2 del connettore come ec2-user con una chiave SSH per installare il plug-in SnapCenter seguendo queste istruzioni: <block ref="4d36f47e6f1b893c6ddd7262bda1c9b4" category="inline-link-macro-rx"></block>.</block>
  <block id="bb46d1e3b94fe670b59ad65582cc45d9" category="section-title">Configurazione dei servizi SnapCenter</block>
  <block id="c874496d8de4031470108dc34d998d2c" category="paragraph">Con il connettore implementato, i servizi SnapCenter possono essere configurati con la seguente procedura:</block>
  <block id="3ecf7d7cbb172543fe0f740496cfb9b0" category="list-text">Da *My Working Environment* fare clic su *Add Working Environment* (Aggiungi ambiente di lavoro) per scoprire FSX implementato in AWS.</block>
  <block id="537b713708147506a182f9e62348c997" category="paragraph"><block ref="537b713708147506a182f9e62348c997" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4daeb16c1a9b1a0d173181068ef06541" category="list-text">Scegliere *Amazon Web Services* come posizione.</block>
  <block id="25949fd8842fc6d4e2a3d0e74bbc18d9" category="paragraph"><block ref="25949fd8842fc6d4e2a3d0e74bbc18d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="beb3aca877ee917cc965b653f4f954c2" category="list-text">Fai clic su *Scopri esistente* accanto a *Amazon FSX per ONTAP*.</block>
  <block id="669e7983bcf1791e42789eb5557823c1" category="paragraph"><block ref="669e7983bcf1791e42789eb5557823c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="818214abd1c968ef46c7d7ffea09d9cf" category="list-text">Selezionare le credenziali che forniscono a BlueXP le autorizzazioni necessarie per gestire FSX per ONTAP. Se non sono state aggiunte credenziali, è possibile aggiungerle dal menu *Settings* (Impostazioni) nell'angolo superiore destro della console BlueXP.</block>
  <block id="2dd86f2e91e85ccea46f244108988758" category="paragraph"><block ref="2dd86f2e91e85ccea46f244108988758" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1c90af5467bb4ade93f516a477fab6ce" category="list-text">Scegliere la regione AWS in cui viene implementato Amazon FSX per ONTAP, selezionare il cluster FSX che ospita il database Oracle e fare clic su Aggiungi.</block>
  <block id="39accbdb3a3b52363e35c6bd0a5768d8" category="paragraph"><block ref="39accbdb3a3b52363e35c6bd0a5768d8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6a9497923f20e49ad508a714878556d" category="list-text">L'istanza scoperta di Amazon FSX per ONTAP viene ora visualizzata nell'ambiente di lavoro.</block>
  <block id="b996189c5d6c6476140b17331222eaf4" category="paragraph"><block ref="b996189c5d6c6476140b17331222eaf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5abed4635dac308091151770538f31f6" category="list-text">È possibile accedere al cluster FSX con le credenziali dell'account fsxadmin.</block>
  <block id="a0297da6f92a68d1492ecdf77c4949fb" category="paragraph"><block ref="a0297da6f92a68d1492ecdf77c4949fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72788f45d9fca0c46cf26a1728176b48" category="list-text">Dopo aver effettuato l'accesso ad Amazon FSX per ONTAP, esaminare le informazioni di storage del database (ad esempio i volumi del database).</block>
  <block id="8a51384a3ecf5b098e9facdac7fd4742" category="paragraph"><block ref="8a51384a3ecf5b098e9facdac7fd4742" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04353f9112bb1b7ff1621abd8ff0ef5b" category="list-text">Dalla barra laterale sinistra della console, passare il mouse sull'icona di protezione, quindi fare clic su *protezione* &gt; *applicazioni* per aprire la pagina di avvio delle applicazioni. Fare clic su *Scopri applicazioni*.</block>
  <block id="c174305d25dc1c3ea7e6fd64534c302d" category="paragraph"><block ref="c174305d25dc1c3ea7e6fd64534c302d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="598fd5b506ddf6b5a73368a488fa16c0" category="list-text">Selezionare *Cloud Native* come tipo di origine dell'applicazione.</block>
  <block id="4645a6f0abb4aa3edf2172708fd672e0" category="paragraph"><block ref="4645a6f0abb4aa3edf2172708fd672e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bfcedcc06ce70b69b0c25371a7b68359" category="list-text">Scegliere *Oracle* come tipo di applicazione.</block>
  <block id="d90ff0259aa21df9ff992d15f1efcbd2" category="paragraph"><block ref="d90ff0259aa21df9ff992d15f1efcbd2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6cbdf0cef43778a4cfb3432da64609c7" category="list-text">Fornire i dettagli dell'host dell'istanza Oracle EC2 per aggiungere un host. Selezionare questa casella per confermare che il plug-in per Oracle sull'host è stato installato, poiché il plug-in viene implementato dopo il provisioning del connettore.</block>
  <block id="932a85fd3682f29ed640be5455be6e1d" category="paragraph"><block ref="932a85fd3682f29ed640be5455be6e1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99674e4e12f2b87ea13d459f88886121" category="list-text">Individuare l'host Oracle EC2 e aggiungerlo a *applicazioni*; tutti i database sull'host vengono rilevati e visualizzati nella pagina. Il database *Protection Status* viene visualizzato come *UnProtected* (non protetto).</block>
  <block id="a91f39c3d22fe697afbaa8e861c6f1e1" category="paragraph"><block ref="a91f39c3d22fe697afbaa8e861c6f1e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9958dec2bab238d2e917ab477e6687a5" category="paragraph">Questa operazione completa la configurazione iniziale dei servizi SnapCenter per Oracle. Nelle tre sezioni successive di questo documento vengono descritte le operazioni di backup, ripristino e clonazione del database Oracle.</block>
  <block id="7f7c0dda9cb78e17432e91abc3c9a290" category="section-title">Backup del database Oracle</block>
  <block id="d243d925299e4128a453e9d54b57e25d" category="list-text">Fare clic sui tre punti accanto al database *Protection Status* (Stato protezione), quindi fare clic su *Polices* (Criteri) per visualizzare i criteri di protezione predefiniti del database che è possibile applicare per proteggere i database Oracle.</block>
  <block id="f5ec19f9ff10edc4aa6fc1c116c6b23e" category="paragraph"><block ref="f5ec19f9ff10edc4aa6fc1c116c6b23e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b95d24dbc11f9b34c6cf18b07dcf3f7" category="list-text">È inoltre possibile creare policy personalizzate con una frequenza di backup personalizzata e una finestra di conservazione dei dati di backup.</block>
  <block id="dd06e85eab955d6e3843bf0f5c71961c" category="paragraph"><block ref="dd06e85eab955d6e3843bf0f5c71961c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44fa14fc437558bfdfce0d0ac643d1e2" category="list-text">Quando si è soddisfatti della configurazione dei criteri, è possibile assegnare i criteri scelti per proteggere il database.</block>
  <block id="2bf8224a90f863c821d826f3501d5c0a" category="paragraph"><block ref="2bf8224a90f863c821d826f3501d5c0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4861abebdaa3d58ada4e621adac79010" category="list-text">Scegliere il criterio da assegnare al database.</block>
  <block id="c6f05663d6855c56941461ecc27d6b12" category="paragraph"><block ref="c6f05663d6855c56941461ecc27d6b12" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da1635fa4036afa9fa39c868740e8560" category="list-text">Una volta applicato il criterio, lo stato di protezione del database è cambiato in *Protected* con un segno di spunta verde.</block>
  <block id="0d63626c21bc3f6eaeff860db7839e8e" category="paragraph"><block ref="0d63626c21bc3f6eaeff860db7839e8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7474327f9583bb0f2aa4aa276aa11e53" category="list-text">Il backup del database viene eseguito in base a una pianificazione predefinita. È inoltre possibile eseguire un backup on-demand one-off, come illustrato di seguito.</block>
  <block id="3adad6846dd8bf1ff91c627d2f4bea27" category="paragraph"><block ref="3adad6846dd8bf1ff91c627d2f4bea27" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7ba3fa48656ab6088ca8f9f4c64578f" category="list-text">I dettagli dei backup del database possono essere visualizzati facendo clic su *View Details* (Visualizza dettagli) dall'elenco dei menu. Tra cui nome, tipo di backup, SCN e data di backup. Un set di backup copre un'istantanea sia per il volume di dati che per il volume di log. Lo snapshot di un volume di log viene eseguito subito dopo lo snapshot di un volume di database. È possibile applicare un filtro se si cerca un backup particolare in un elenco lungo.</block>
  <block id="c76057368e5767af8f13e84e53b3194f" category="paragraph"><block ref="c76057368e5767af8f13e84e53b3194f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fd0ba63e6574c7326fb2e810b4537e0" category="section-title">Ripristino e ripristino del database Oracle</block>
  <block id="d747acf93ee8abac3afd574a32b975fe" category="list-text">Per un ripristino del database, scegliere il backup corretto, in base al tempo di backup o SCN. Fare clic sui tre punti del backup dei dati del database, quindi fare clic su *Restore* (Ripristina) per avviare il ripristino e il ripristino del database.</block>
  <block id="7331f40ac7ceea61fa15e6868eba99e7" category="paragraph"><block ref="7331f40ac7ceea61fa15e6868eba99e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ced09bd050d5fa98df8a41ef04173e0" category="list-text">Scegliere l'impostazione di ripristino. Se dopo il backup non è cambiato nulla nella struttura fisica del database (ad esempio l'aggiunta di un file di dati o di un gruppo di dischi), è possibile utilizzare l'opzione *Force in Place restore* (Ripristino forzato in posizione), che in genere è più veloce. In caso contrario, non selezionare questa casella.</block>
  <block id="2684b5e65a8e3b537bd594678549bc4e" category="paragraph"><block ref="2684b5e65a8e3b537bd594678549bc4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d58c0a59c722f81b5e2d0f77ffc4e126" category="list-text">Esaminare e avviare il ripristino e il ripristino del database.</block>
  <block id="9ab34ce0349fd7db7573bad83c07a487" category="paragraph"><block ref="9ab34ce0349fd7db7573bad83c07a487" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e370cf26e04645138a40a3379e743fb7" category="list-text">Dalla scheda *Job Monitoring*, è possibile visualizzare lo stato del processo di ripristino e tutti i dettagli durante l'esecuzione.</block>
  <block id="e9214106e8bbcaae5a214e937af349e6" category="paragraph"><block ref="e9214106e8bbcaae5a214e937af349e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd84eda02c29b3672e3476ed8c8be12d" category="paragraph"><block ref="bd84eda02c29b3672e3476ed8c8be12d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9dc2f50af584776a2ecc51a0ebcdded2" category="section-title">Clone del database Oracle</block>
  <block id="35526fc92bd49edc3a11a0affafeae3b" category="paragraph">Per clonare un database, avviare il flusso di lavoro dei cloni dalla stessa pagina dei dettagli di backup del database.</block>
  <block id="71f8cd32cfa279d796f673879629f671" category="list-text">Selezionare la copia di backup del database corretta, fare clic sui tre punti per visualizzare il menu e scegliere l'opzione *Clone*.</block>
  <block id="b858b9fa0a1f0db13263cc0c2cc5cf3d" category="paragraph"><block ref="b858b9fa0a1f0db13263cc0c2cc5cf3d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d552bd00a2d8ed3e1872a0f795180b9f" category="list-text">Selezionare l'opzione *Basic* se non è necessario modificare i parametri del database clonati.</block>
  <block id="867de7ff195f530db4a1e5643a75c689" category="paragraph"><block ref="867de7ff195f530db4a1e5643a75c689" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90b931da49f7db8ce97de89c2b7ea8d5" category="list-text">In alternativa, selezionare *Specification file*, che consente di scaricare il file init corrente, apportare modifiche e quindi caricarlo nuovamente nel lavoro.</block>
  <block id="f89a131e2cb4beb2f5dc697ac61b460f" category="paragraph"><block ref="f89a131e2cb4beb2f5dc697ac61b460f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b9252d48a9fcf8c03ec68f357e943a" category="list-text">Esaminare e avviare il lavoro.</block>
  <block id="77281e34749b6599332dd1416b12f533" category="paragraph"><block ref="77281e34749b6599332dd1416b12f533" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d388d0f32172ebe7aea2c3eeae0dfc4" category="list-text">Controllare lo stato del lavoro di clonazione dalla scheda *Job Monitoring*.</block>
  <block id="827b60b27e967d900114ade1f31eed53" category="paragraph"><block ref="827b60b27e967d900114ade1f31eed53" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e0fb0a8b932b4f05d487ea8a5748901" category="list-text">Convalidare il database clonato sull'host dell'istanza EC2.</block>
  <block id="d139cf7562ab53c3922d5a0a6804786c" category="paragraph"><block ref="d139cf7562ab53c3922d5a0a6804786c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6cfa4396db779261100202ab3f0ffdcd" category="paragraph"><block ref="6cfa4396db779261100202ab3f0ffdcd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f12aeeed0f164c86af69a57fddb01689" category="list-text">Configurare e amministrare BlueXP</block>
  <block id="74e12c8bec754bf4a9feb44c8cada2dc" category="inline-link-macro"><block ref="74e12c8bec754bf4a9feb44c8cada2dc" category="inline-link-rx"></block></block>
  <block id="54d1b98b8cdfd12e2afc7f08278645ba" category="paragraph"><block ref="54d1b98b8cdfd12e2afc7f08278645ba" category="inline-link-macro-rx"></block></block>
  <block id="846099e77083903f32f72c0e2156c3c5" category="list-text">Documentazione di Cloud Backup</block>
  <block id="ed133d2d4bade971a41aae35897a0bd2" category="inline-link-macro"><block ref="ed133d2d4bade971a41aae35897a0bd2" category="inline-link-rx"></block></block>
  <block id="21af149e524c5f7a8eb5e23197309e60" category="paragraph"><block ref="21af149e524c5f7a8eb5e23197309e60" category="inline-link-macro-rx"></block></block>
  <block id="046c9e52934c311f81497ca664d86a24" category="doc">TR-4764: Best practice per Microsoft SQL Server con NetApp EF-Series</block>
  <block id="d9cd8ac988f5ea26e28a2da5f3485ff9" category="paragraph">Mitch Blackburn, Pat Sinthusan, NetApp</block>
  <block id="9db08b91ae68a77b71af230b40b31325" category="paragraph">Questa guida alle Best practice ha lo scopo di aiutare gli amministratori dello storage e i database a implementare con successo Microsoft SQL Server sullo storage NetApp EF-Series.</block>
  <block id="730874cec0e792d7ebad5a796a90b3be" category="paragraph"><block ref="730874cec0e792d7ebad5a796a90b3be" category="inline-link-macro-rx"></block></block>
  <block id="ff9d8653752bd48bb6b73cf97f207af1" category="summary">Soluzioni di database per il cloud ibrido con workflow di DR SnapCenter</block>
  <block id="ac2e8778240cb518ee14b1defbf55765" category="doc">Workflow di disaster recovery</block>
  <block id="461887ca64f2d60da58c130a00656a96" category="inline-link-macro">Precedente: Workflow per sviluppo/test bursting nel cloud.</block>
  <block id="b8499237e1a42a05b5306219f80b35ba" category="paragraph"><block ref="b8499237e1a42a05b5306219f80b35ba" category="inline-link-macro-rx"></block></block>
  <block id="8e84608bd62584b2f262d60fd734714f" category="paragraph">Le aziende hanno adottato il cloud pubblico come risorsa e destinazione praticabili per il disaster recovery. SnapCenter rende questo processo il più possibile perfetto. Questo flusso di lavoro di disaster recovery è molto simile al flusso di lavoro dei cloni, ma il ripristino del database viene eseguito attraverso l'ultimo log disponibile replicato nel cloud per ripristinare tutte le transazioni di business possibili. Tuttavia, sono disponibili ulteriori fasi di pre-configurazione e post-configurazione specifiche per il disaster recovery.</block>
  <block id="e230d95c57c5534b3e90b93fddbcb1c9" category="section-title">Clonare un database di produzione Oracle on-premise nel cloud per il DR</block>
  <block id="db9517755259859dbae095126c803544" category="list-text">Per verificare che il ripristino del clone venga eseguito attraverso l'ultimo log disponibile, abbiamo creato una piccola tabella di test e inserito una riga. I dati del test vengono ripristinati dopo un ripristino completo dell'ultimo registro disponibile.</block>
  <block id="39f00f2f1a95739a075844dcffac1441" category="paragraph"><block ref="39f00f2f1a95739a075844dcffac1441" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fd1337293be82f7472d90bc35f51e90" category="list-text">Accedere a SnapCenter come ID utente per la gestione del database per Oracle. Accedere alla scheda risorse, che mostra i database Oracle protetti da SnapCenter.</block>
  <block id="1ddb1f7854ac534473544de627fc5289" category="paragraph"><block ref="1ddb1f7854ac534473544de627fc5289" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e795ef17ab8e08159909afe558c32a1c" category="list-text">Selezionare il gruppo di risorse del registro Oracle e fare clic su Backup Now (Esegui backup ora) per eseguire manualmente un backup del registro Oracle per scaricare l'ultima transazione verso la destinazione nel cloud. In un vero scenario di DR, l'ultima transazione ripristinabile dipende dalla frequenza di replica del volume del log del database nel cloud, che a sua volta dipende dalla policy RTO o RPO dell'azienda.</block>
  <block id="e3ea77c81b6559a6984aee62074951ec" category="paragraph"><block ref="e3ea77c81b6559a6984aee62074951ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44d1c907c1d5302eb896d76cae9b5e7f" category="paragraph"><block ref="44d1c907c1d5302eb896d76cae9b5e7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d77575716b9cd49ab1453e367c405abe" category="admonition">SnapMirror asincrono perde i dati che non l'hanno fatto alla destinazione cloud nell'intervallo di backup del registro del database in uno scenario di disaster recovery. Per ridurre al minimo la perdita di dati, è possibile pianificare backup dei log più frequenti. Tuttavia, esiste un limite alla frequenza di backup dei log tecnicamente raggiungibile.</block>
  <block id="c684c2587fa959f3df40953faab1c1a1" category="list-text">Selezionare l'ultimo backup del registro in Secondary Mirror Backup(s) (Backup mirror secondario) e montare il backup del registro.</block>
  <block id="4d27921136b62a393650eec8f38c5a39" category="paragraph"><block ref="4d27921136b62a393650eec8f38c5a39" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6784de36878125b88feb4c3192d2aa3d" category="paragraph"><block ref="6784de36878125b88feb4c3192d2aa3d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fbfa0a2a63c1090863dedb14664d443c" category="list-text">Selezionare l'ultimo backup completo del database e fare clic su Clone (Clona) per avviare il flusso di lavoro dei cloni.</block>
  <block id="ecafa568fe2f36fee38130d0f80eeafc" category="paragraph"><block ref="ecafa568fe2f36fee38130d0f80eeafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3aa765536eeb5bd55823afbb43c9efdc" category="list-text">Selezionare un ID DB clone univoco sull'host.</block>
  <block id="6d4d1ea488e25d46cd7824491f3f98fb" category="paragraph"><block ref="6d4d1ea488e25d46cd7824491f3f98fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d57d235b31b66e982ae6d433fa33948e" category="list-text">Eseguire il provisioning di un volume di log e montarlo sul server DR di destinazione per l'area di ripristino flash Oracle e i registri online.</block>
  <block id="4ef6ef644cc7510226d8d150ce9cfe73" category="paragraph"><block ref="4ef6ef644cc7510226d8d150ce9cfe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d5730b3167534121e5ac4fcdf84cf1f" category="paragraph"><block ref="4d5730b3167534121e5ac4fcdf84cf1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6142419cbd2b279a240db52011ea3cab" category="admonition">La procedura di clonazione Oracle non crea un volume di log, che deve essere fornito sul server DR prima della clonazione.</block>
  <block id="b20da77a777ef0a84d95f447b254387c" category="list-text">Selezionare l'host clone di destinazione e la posizione in cui inserire i file di dati, i file di controllo e i log di ripristino.</block>
  <block id="326062662ffdb461c61b5ddfc54974bc" category="paragraph"><block ref="326062662ffdb461c61b5ddfc54974bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b126b14adfdc04f12e6a00531155f4a" category="list-text">Selezionare le credenziali per il clone. Inserire i dettagli della configurazione Oracle home sul server di destinazione.</block>
  <block id="ee4a9d80953ee6db29e5577ef13327ba" category="paragraph"><block ref="ee4a9d80953ee6db29e5577ef13327ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c76f59dc52686a71eb5917bbcabfa212" category="list-text">Specificare gli script da eseguire prima della clonazione. Se necessario, è possibile regolare i parametri del database.</block>
  <block id="31b131b08153ae34a96d1e17fa891e1f" category="paragraph"><block ref="31b131b08153ae34a96d1e17fa891e1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7018f70f78c5e3154b2620e31167c12e" category="list-text">Selezionare l'opzione di ripristino fino a quando non viene eseguita l'opzione Cancel (Annulla), in modo che il ripristino venga eseguito attraverso tutti i log di archivio disponibili per recuperare l'ultima transazione replicata nella posizione del cloud secondario.</block>
  <block id="57fa7fef5a8266470204775391a701d3" category="paragraph"><block ref="57fa7fef5a8266470204775391a701d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6233d74c8f9820a1029624d60ab66049" category="list-text">Configurare il server SMTP per la notifica via email, se necessario.</block>
  <block id="a563132424d4d3d255697521a0446bc9" category="paragraph"><block ref="a563132424d4d3d255697521a0446bc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99a0cd00abfa258b121d480ce7d27e63" category="list-text">Riepilogo dei cloni DR.</block>
  <block id="0f66818ccf8a8dd3d6491b9bcf74c02e" category="paragraph"><block ref="0f66818ccf8a8dd3d6491b9bcf74c02e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4ff014e6bff5ee06349d607c14fcf9e" category="list-text">I DBS clonati vengono registrati con SnapCenter subito dopo il completamento del clone e sono quindi disponibili per la protezione del backup.</block>
  <block id="18eac7477ab0c6038ec443444677a1eb" category="paragraph"><block ref="18eac7477ab0c6038ec443444677a1eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22d74aee547ad10d104f875521cfa6d7" category="section-title">Convalida e configurazione dei cloni post-DR per Oracle</block>
  <block id="9d58cce71d4c85948ccecfea105367ed" category="list-text">Convalida l'ultima transazione di test che è stata scaricata, replicata e ripristinata nella posizione DR nel cloud.</block>
  <block id="1db3ba1f62cbb82a66232de851bad3ce" category="paragraph"><block ref="1db3ba1f62cbb82a66232de851bad3ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61b3573abc722a493f53ed27503f7eff" category="list-text">Configurare l'area di ripristino della flash.</block>
  <block id="71ca9fe67f8c3826e171fb227af4f666" category="paragraph"><block ref="71ca9fe67f8c3826e171fb227af4f666" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4005d553f013abc53c6a1a65aed1d65f" category="list-text">Configurare il listener Oracle per l'accesso degli utenti.</block>
  <block id="0c79c2a9e4fd1ea908a63d58f1f44917" category="list-text">Separare il volume clonato dal volume di origine replicato.</block>
  <block id="42e82bb35283d9f2e2b444419f518667" category="list-text">Eseguire la replica inversa dal cloud a on-premise e ricostruire il server di database on-premise guasto.</block>
  <block id="4ce2420dd00dd0b543e2e51bf7c1c135" category="admonition">La suddivisione dei cloni può comportare un utilizzo temporaneo dello spazio di storage molto più elevato del normale funzionamento. Tuttavia, dopo la ricostruzione del server DB on-premise, è possibile liberare spazio aggiuntivo.</block>
  <block id="0e70133bb418f4025b82a6a35301e209" category="section-title">Clonare un database di produzione SQL on-premise nel cloud per il DR</block>
  <block id="32bfa00a92b9f85d791a43f6d70a35cd" category="list-text">Allo stesso modo, per verificare che il ripristino del clone SQL sia stato eseguito attraverso l'ultimo log disponibile, abbiamo creato una piccola tabella di test e inserito una riga. I dati del test vengono ripristinati dopo un ripristino completo dell'ultimo registro disponibile.</block>
  <block id="321bd96e83b00fcd04bfcc72ec4564ff" category="paragraph"><block ref="321bd96e83b00fcd04bfcc72ec4564ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3b7f1fcf93afdd055ec19e230b54347" category="list-text">Accedere a SnapCenter con un ID utente per la gestione del database per SQL Server. Accedere alla scheda Resources (risorse), che mostra il gruppo di risorse di protezione di SQL Server.</block>
  <block id="c9673e38d22c239c3b46259620b7b190" category="paragraph"><block ref="c9673e38d22c239c3b46259620b7b190" category="inline-image-macro-rx" type="image"></block></block>
  <block id="608bfa3334f97023b71f6b7a04742bd6" category="list-text">Eseguire manualmente un backup del log per svuotare l'ultima transazione da replicare sullo storage secondario nel cloud pubblico.</block>
  <block id="94ca8d0daf1445cae1bbc5a13d7b0c42" category="paragraph"><block ref="94ca8d0daf1445cae1bbc5a13d7b0c42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b9ced1d8d8e91eb2606cb7d0932fa4" category="list-text">Selezionare l'ultimo backup completo di SQL Server per il clone.</block>
  <block id="f93fa51d605a26ef233b6fb9c5489266" category="paragraph"><block ref="f93fa51d605a26ef233b6fb9c5489266" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82efcc579f2220a65dbe5cdd64f47253" category="list-text">Impostare l'impostazione del clone, ad esempio Clone Server, Clone Instance, Clone Name e mount. Il percorso di storage secondario in cui viene eseguita la clonazione viene popolato automaticamente.</block>
  <block id="bb5bdefa03845f9483d1e3fcf8d3b40f" category="paragraph"><block ref="bb5bdefa03845f9483d1e3fcf8d3b40f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d84ecf0ed314694d6e3ad9b2a96a198" category="list-text">Selezionare tutti i backup del registro da applicare.</block>
  <block id="79284af3915a1bc3e4d4d3993acd9042" category="paragraph"><block ref="79284af3915a1bc3e4d4d3993acd9042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f68fbd76be71ebe267aa207f7bef25f" category="list-text">Specificare eventuali script opzionali da eseguire prima o dopo la clonazione.</block>
  <block id="1f29cf99c49ef1910181e451424c3796" category="paragraph"><block ref="1f29cf99c49ef1910181e451424c3796" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ac43ede08a0b7154673a619b979f17d" category="list-text">Specificare un server SMTP se si desidera inviare una notifica via e-mail.</block>
  <block id="e8aa5b543b67c22f0a2a205562794787" category="paragraph"><block ref="e8aa5b543b67c22f0a2a205562794787" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7338d3af995c4a281de85493129cc18" category="list-text">Riepilogo dei cloni DR. I database clonati vengono immediatamente registrati con SnapCenter e sono disponibili per la protezione del backup.</block>
  <block id="332fb27e1cc349fc79252fbfc5de6ad0" category="paragraph"><block ref="332fb27e1cc349fc79252fbfc5de6ad0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8be7490bb89f986a83768e6a71d78ee8" category="paragraph"><block ref="8be7490bb89f986a83768e6a71d78ee8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f01a56e31a650c5bb83408b5238270e" category="section-title">Convalida e configurazione dei cloni post-DR per SQL</block>
  <block id="029640b7bf09578f05703e407e99b8d7" category="list-text">Monitorare lo stato del lavoro clone.</block>
  <block id="d5f350d5580b71105a1718557ce88137" category="paragraph"><block ref="d5f350d5580b71105a1718557ce88137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68236fcee9bee8dbdc1c54b7b2d84b34" category="list-text">Verificare che l'ultima transazione sia stata replicata e ripristinata con tutti i cloni dei file di log e il ripristino.</block>
  <block id="3ebb58ab28579acf2742808bf95fc07e" category="paragraph"><block ref="3ebb58ab28579acf2742808bf95fc07e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50159c53d6f87eb33c314abd9f0bd28f" category="list-text">Configurare una nuova directory di log di SnapCenter sul server DR per il backup del log di SQL Server.</block>
  <block id="50f8c30e062c542679b96127a844db6a" category="paragraph">Se hai bisogno di aiuto per questa soluzione e per i casi d'utilizzo, partecipa al <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> e cerca il canale di automazione della soluzione per inviare domande o domande.</block>
  <block id="3282bd4b5c29b5e9be65469e592bba18" category="doc">Modernizzazione dell'ambiente Microsoft SQL Server</block>
  <block id="69015d285622bbd074d7bccf4ea12670" category="paragraph">Ottimizza le operazioni e libera la potenza dei tuoi dati, on-premise o nel cloud.</block>
  <block id="b5b095487ccabae138c7872353cadbe6" category="paragraph"><block ref="b5b095487ccabae138c7872353cadbe6" category="inline-link-macro-rx"></block></block>
  <block id="86d943d0743178f4b51317bf89a99ff7" category="summary">La soluzione offre una panoramica e dettagli sull'implementazione e la protezione del database Oracle nello storage AWS FSX ONTAP e nell'istanza di calcolo EC2 con protocollo iSCSI e database Oracle configurati in un riavvio standalone utilizzando asm come volume manager.</block>
  <block id="4f3c9d31ccf189b3cb7f494f26684484" category="doc">TR-4965: Implementazione e protezione del database Oracle in AWS FSX/EC2 con iSCSI/ASM</block>
  <block id="47a7a6100cb8ee47f5b0126bacce0e8f" category="paragraph">In questa documentazione, dimostreremo come implementare un database Oracle con il protocollo iSCSI e Oracle ASM in un ambiente di storage Amazon FSX per ONTAP con istanze di calcolo EC2. Inoltre, dimostreremo come utilizzare il servizio NetApp SnapCenter attraverso la console NetApp BlueXP per eseguire il backup, il ripristino e la clonazione del database Oracle per lo sviluppo/test o altri casi di utilizzo per un funzionamento efficiente dello storage del database nel cloud pubblico AWS.</block>
  <block id="2dda300300a9a8c69d259bcce9dff4f3" category="list-text">Implementazione di database Oracle in Amazon FSX per storage ONTAP e istanze di calcolo EC2 con iSCSI/ASM</block>
  <block id="a47b73991317ed980de57441ff2ec0b0" category="list-text">Test e convalida di un carico di lavoro Oracle nel cloud AWS pubblico con iSCSI/ASM</block>
  <block id="c7940228c5d339083ac147fb2a5041de" category="list-text">Un DBA che desidera implementare Oracle in un cloud pubblico AWS con iSCSI/ASM.</block>
  <block id="0907de49479565aae7dd2f8a84ef2915" category="list-text">*Layout dei dati e dei registri Oracle.* nei nostri test e convalide, abbiamo implementato due gruppi di dischi ASM rispettivamente per dati e registri. All'interno del gruppo di dischi +DATA asm, abbiamo eseguito il provisioning di quattro LUN in un volume di dati. All'interno del gruppo di dischi asm +LOGS, sono stati forniti due LUN in un volume di log. In generale, più LUN disposti all'interno di un volume Amazon FSX per ONTAP offrono performance migliori.</block>
  <block id="511a515ed4428c1ca16462485a26f4fc" category="list-text">*Configurazione iSCSI.* il server del database dell'istanza EC2 si connette allo storage FSX con il protocollo iSCSI. Le istanze EC2 vengono generalmente implementate con una singola interfaccia di rete o ENI. La singola interfaccia NIC trasporta traffico sia iSCSI che applicativo. È importante valutare il requisito di throughput i/o del database Oracle analizzando attentamente il report AWR di Oracle per scegliere un'istanza di calcolo EC2 appropriata che soddisfi i requisiti di throughput del traffico di applicazioni e iSCSI. NetApp consiglia inoltre di allocare quattro connessioni iSCSI a entrambi gli endpoint iSCSI FSX con multipath correttamente configurato.</block>
  <block id="db1de135a2e3ba870a8f80ce78d2d05e" category="list-text">*Livello di ridondanza Oracle ASM da utilizzare per ciascun gruppo di dischi Oracle ASM creato.* poiché FSX esegue già il mirroring dello storage a livello di cluster FSX, è necessario utilizzare la ridondanza esterna, il che significa che l'opzione non consente a Oracle ASM di eseguire il mirroring del contenuto del gruppo di dischi.</block>
  <block id="1684a037c41a5a896a961b99be3d79c7" category="list-text">Installare gli utils iSCSI Initiator.</block>
  <block id="c9d53c5d17f956afae2225c70107de12" category="list-text">Installare<block ref="4c17da57a03262c55ed7eaf9b11476b4" prefix=" " category="inline-code"></block>.</block>
  <block id="390748df672cba58066187eedd5aae0e" category="list-text">Installare<block ref="a3938eeca32dce6ca3908d2eae163c75" prefix=" " category="inline-code"></block>.</block>
  <block id="c9f7be60d92cf42de8f14f5ab8547971" category="list-text">Cambiare<block ref="b7e6d8bff01730e41b7d91437e6a25d0" prefix=" " category="inline-code"></block> in<block ref="c30b27a1b058924e30212c72bb553665" prefix=" " category="inline-code"></block> file di configurazione da 120 a 5 secondi.</block>
  <block id="bca8f765f0293b09679dd10ece969e68" category="list-text">Attivare e avviare il servizio iSCSI sull'istanza EC2.</block>
  <block id="3cb574654986fcf318668b4bf3313724" category="list-text">Recuperare l'indirizzo iSCSI Initiator da utilizzare per la mappatura LUN del database.</block>
  <block id="64014fc61a9016f43a5537d6da141cc1" category="section-title">Eseguire il provisioning e il mapping di volumi di database e LUN all'host dell'istanza EC2</block>
  <block id="cc70e928fff63a76ca8cf30a05d95a80" category="list-text">Creare un LUN binario all'interno del volume binario del database.</block>
  <block id="dc4301dd6be2058cb9d1a1e3408388eb" category="list-text">Creare LUN di dati all'interno del volume di dati del database.</block>
  <block id="49cf66e4521ade9e7ffc2aae313ee978" category="list-text">Creare LUN di log all'interno del volume di log del database.</block>
  <block id="3e408df5c51ac33acd5978f1f48cab19" category="list-text">Creare un igroup per l'istanza EC2 con l'iniziatore recuperato dal passaggio 14 della configurazione del kernel EC2 di cui sopra.</block>
  <block id="ceed9a3dd22f247b70bb6774943f9284" category="list-text">Mappare le LUN all'igroup creato in precedenza. Incrementare l'ID LUN in modo sequenziale per ogni LUN aggiuntivo all'interno di un volume.</block>
  <block id="18519dc23f47343cf516e789bf2e818b" category="list-text">Convalidare la mappatura del LUN.</block>
  <block id="a7939166c08e8ac6da1530309825a401" category="list-text">Individuare gli endpoint iSCSI FSX utilizzando l'indirizzo IP iSCSI SVM. Quindi passare all'indirizzo del portale specifico dell'ambiente.</block>
  <block id="1bc103d13645d8a07f4a05f2eee064f8" category="list-text">Stabilire sessioni iSCSI accedendo a ciascuna destinazione.</block>
  <block id="fc5113f60b8b0390133d7abda7290515" category="paragraph">L'output previsto dal comando è:</block>
  <block id="c541a8df6ddefee9ae370e31bf1109cc" category="list-text">Visualizzare e convalidare un elenco di sessioni iSCSI attive.</block>
  <block id="efe44c0a293be7b9e3d17291e1bd0fce" category="paragraph">Restituire le sessioni iSCSI.</block>
  <block id="e4a8008161f8d488131b8bf10831bf6c" category="list-text">Verificare che i LUN siano stati importati nell'host.</block>
  <block id="f467f5c5010c383146b412ebc7d2a967" category="paragraph">In questo modo si otterrà un elenco di LUN Oracle da FSX.</block>
  <block id="08b7a2f63e8caee3c8d0f32a3d9dd5ea" category="list-text">Configurare<block ref="9ac80d53ede05256c28cf9e043eb423c" prefix=" " category="inline-code"></block> file con le seguenti voci predefinite e blacklist.</block>
  <block id="794a654f60052714db9eba2a7ff4b608" category="list-text">Avviare il servizio multipath.</block>
  <block id="65b4cea56e6d27de22dc85622fe6a7fb" category="paragraph">Ora i dispositivi multipath vengono visualizzati in<block ref="9c9f766701f811ef6f170c7a3453c53f" prefix=" " category="inline-code"></block> directory.</block>
  <block id="d282577e5b16ee7f17ce7cd0f718be4c" category="list-text">Accedere al cluster FSX come utente fsxadmin tramite SSH per recuperare il numero seriale-esadecimale per ogni LUN che inizia con 6c574xxx..., il numero ESADECIMALE inizia con 3600a0980, che è l'ID vendor AWS.</block>
  <block id="2720e08c2a6367757e2dc57afee1620c" category="paragraph">e tornare come segue:</block>
  <block id="ecf2aff9ad02b9026ff22f4fc6a68e73" category="list-text">Aggiornare<block ref="bacd7d75ae434c4a777b1baef0e31f36" prefix=" " category="inline-code"></block> file per aggiungere un nome di facile utilizzo per la periferica multipath.</block>
  <block id="75104fff60881baaf37dcb441594f8a1" category="paragraph">con le seguenti voci:</block>
  <block id="e73e686392436f1038dd926c4a775f24" category="list-text">Riavviare il servizio multipath per verificare che i dispositivi siano presenti in<block ref="9c9f766701f811ef6f170c7a3453c53f" prefix=" " category="inline-code"></block> Sono stati modificati in nomi LUN rispetto agli ID seriali-esadecimali.</block>
  <block id="5f9e8fcf665ea0cca4e1c6eea45645e4" category="paragraph">Controllare<block ref="9c9f766701f811ef6f170c7a3453c53f" prefix=" " category="inline-code"></block> per tornare come segue:</block>
  <block id="6f6e08574875efd99672521b7c49bd5f" category="list-text">Partizionare il LUN binario con una singola partizione primaria.</block>
  <block id="d90e8b8ea181e08e8bf690f2c3143681" category="list-text">Formattare il LUN binario partizionato con un file system XFS.</block>
  <block id="999ccfc779bcbed2a3561bff37f884d1" category="list-text">Montare il LUN binario su<block ref="a8946fa5f211c5345e3610710e471cb4" prefix=" " category="inline-code"></block>.</block>
  <block id="22e45c04a42f3d5d2b9ca76b19445949" category="list-text">Cambiare<block ref="a8946fa5f211c5345e3610710e471cb4" prefix=" " category="inline-code"></block> Montare la proprietà dei punti all'utente Oracle e al gruppo primario associato.</block>
  <block id="a7d5cd359d07f4d25f07c14cac7c892f" category="list-text">Individuare l'UUI del LUN binario.</block>
  <block id="b79f3809b435063f1d43819c9baaf816" category="admonition">È importante montare il binario solo con UUID e con l'opzione nofail per evitare possibili problemi di blocco root durante il riavvio dell'istanza EC2.</block>
  <block id="ad7b51bb9b820412dddd78b34ccf36ea" category="list-text">In qualità di utente root, aggiungere la regola udev per i dispositivi Oracle.</block>
  <block id="8e7c7ff83f0da1eceabb8c7fbb255de4" category="paragraph">Includere le seguenti voci:</block>
  <block id="d347f5dbb8625ab56eb3b8ad0f1ed6ca" category="list-text">Come utente root, ricaricare le regole udev.</block>
  <block id="967abd537fdc45fbfc59ee4d5fbd70d2" category="list-text">Come utente root, attivare le regole udev.</block>
  <block id="aeead6d2d9990fef69ffefd2efd88b90" category="list-text">Come utente root, ricaricare multipath.</block>
  <block id="72eab9d7fc33889fd5bf6a85943c4e4a" category="list-text">Accedere all'istanza EC2 come utente root e impostarla<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> e.<block ref="456a3c82b7208b5c2a000597b1330564" prefix=" " category="inline-code"></block>.</block>
  <block id="d134d418859128801ec294cd10bcbd8e" category="list-text">Eseguire il provisioning dei dispositivi disco per l'utilizzo con il driver di filtro ASM Oracle.</block>
  <block id="cfdbf231484c64b98bc4f3569cd7b324" category="list-text">Annulla impostazione<block ref="c0c2c8394b04a929ffc60091aa1f72ca" prefix=" " category="inline-code"></block>.</block>
  <block id="ada113db66e2b1b6ed982918830cd12e" category="list-text">Come utente root, ricaricare il multipath.</block>
  <block id="f9ba171dd47a8cef31bac8aa17eeb44d" category="list-text">Convalidare lo stato del driver del filtro ASM.</block>
  <block id="561a4d93b7f68977bd06286fa019a254" category="list-text">Impostare la posizione di ripristino del DB sul gruppo di dischi +LOGS.</block>
  <block id="a0b58d032d36bf0801e5ca3a2aa515d9" category="list-text">Accedere al database con sqlplus e attivare la modalità di registrazione archivio.</block>
  <block id="0a31d377857a1d2e24f8e85950a44aac" category="paragraph">Questa operazione completa la versione 19.18 di Oracle 19c Riavvia la distribuzione su un'istanza di calcolo Amazon FSX per ONTAP ed EC2. Se lo si desidera, NetApp consiglia di spostare il file di controllo Oracle e i file di log online nel gruppo di dischi +LOGS.</block>
  <block id="90a0d380974aa73acb8330f1ff9a7930" category="summary">Questa sezione fornisce dettagli sui fattori da prendere in considerazione durante la migrazione del database Oracle da un'istanza on-premise a un'istanza AWS EC2 e allo storage FSX.</block>
  <block id="895a8d39dd9ae7fe795349bdbc3f05dc" category="doc">Migrazione del database dal cloud on-premise al cloud pubblico</block>
  <block id="64d625665f42751b8036cb9a6403a0fe" category="inline-link-macro">Precedente: Gestione del database.</block>
  <block id="69dd1b6ab585f33a36445376492ea8de" category="paragraph"><block ref="69dd1b6ab585f33a36445376492ea8de" category="inline-link-macro-rx"></block></block>
  <block id="373ae4e24c2daa280a4a5aca82dd3818" category="paragraph">La migrazione dei database è un'impresa impegnativa in ogni modo. La migrazione di un database Oracle da on-premise a cloud non fa eccezione.</block>
  <block id="d1e968e04e34c971d41e644820094cef" category="paragraph">Le sezioni seguenti forniscono i fattori chiave da prendere in considerazione durante la migrazione dei database Oracle al cloud pubblico AWS con la piattaforma di calcolo AWS EC2 e storage FSX.</block>
  <block id="84639b5fb3b348e6a053dde95414e039" category="section-title">Lo storage ONTAP è disponibile on-premise</block>
  <block id="3c2e1436532e8615aa8fdb7bb7432f80" category="paragraph">Se il database Oracle on-premise si trova su un array di storage ONTAP, è più semplice configurare la replica per la migrazione del database utilizzando la tecnologia NetApp SnapMirror integrata nello storage AWS FSX ONTAP. Il processo di migrazione può essere orchestrato utilizzando la console NetApp BlueXP.</block>
  <block id="df2111c23e70fa013a85041e1415639e" category="list-text">Creare un'istanza EC2 di calcolo di destinazione che corrisponda all'istanza on-premise.</block>
  <block id="1931f75e563d3dc9ee112e9b4ebd66b7" category="list-text">Eseguire il provisioning di volumi di database corrispondenti e di dimensioni uguali dalla console FSX.</block>
  <block id="98201e355445ae8a2eff3b7c33132cc6" category="list-text">Montare i volumi del database FSX sull'istanza EC2.</block>
  <block id="53fad15133e494dc37bbd0494b8f3a6c" category="list-text">Impostare la replica di SnapMirror tra i volumi di database on-premise nei volumi di database FSX di destinazione. La sincronizzazione iniziale potrebbe richiedere del tempo per spostare i dati di origine primari, ma gli eventuali aggiornamenti incrementali successivi sono molto più rapidi.</block>
  <block id="ed7c233990ddaa2e7103a9f5b77ee3de" category="list-text">Al momento dello switchover, chiudere l'applicazione principale per interrompere tutte le transazioni. Dall'interfaccia Oracle sqlplus CLI, eseguire uno switch Oracle online log e consentire a SnapMirror Sync di trasferire l'ultimo log archiviato nel volume di destinazione.</block>
  <block id="8da4f0ed2ee5c7e68c3fe9ec3dde280e" category="list-text">Suddividere i volumi mirrorati, eseguire il ripristino Oracle alla destinazione e richiamare il database per il servizio.</block>
  <block id="6efd103fd0a488a3d023523ab6377e4e" category="list-text">Puntare le applicazioni verso il database Oracle nel cloud.</block>
  <block id="094ef1326e70f1212e06a1b5d65d2922" category="paragraph">Il seguente video mostra come migrare un database Oracle da on-premise ad AWS FSX/EC2 utilizzando la console NetApp BlueXP e la replica SnapMirror.</block>
  <block id="0ed0689d68d30d32584025a19c85c9e1" category="inline-link-macro">Migrazione di database Oracle da on-premise a FSX/EC2 tramite SnapMirror e BlueXP</block>
  <block id="86afa353cad293784396216eab80ee52" category="section-title">Lo storage ONTAP non è disponibile on-premise</block>
  <block id="c11080183211191097c120f87656c802" category="paragraph">Se il database Oracle on-premise è ospitato su storage di terze parti diverso da ONTAP, la migrazione del database si basa sul ripristino di una copia di backup del database Oracle. È necessario riprodurre il log di archiviazione per renderlo aggiornato prima di passare alla modalità di commutazione.</block>
  <block id="722283478873a13974c4b1b6ea967a40" category="paragraph">AWS S3 può essere utilizzato come area di storage di staging per lo spostamento e la migrazione del database. Per questo metodo, fare riferimento ai seguenti passaggi:</block>
  <block id="9312555163563ac6b35994e42f15d009" category="list-text">Eseguire il provisioning di una nuova istanza EC2 corrispondente, paragonabile all'istanza on-premise.</block>
  <block id="8705a6dedde3ea188c113bda4fe97c14" category="list-text">Eseguire il provisioning di volumi di database uguali dallo storage FSX e montare i volumi sull'istanza EC2.</block>
  <block id="6aeff6e3d9f2f107fa5584191966f816" category="list-text">Creare una copia di backup Oracle a livello di disco.</block>
  <block id="0f90c0c06dae8f50c3f93d33a7547df2" category="list-text">Spostare la copia di backup sullo storage AWS S3.</block>
  <block id="d8fd670e7724b3db99919ea02cd762cc" category="list-text">Ricreare il file di controllo Oracle e ripristinare e ripristinare il database estraendo i dati e il log di archiviazione dallo storage S3.</block>
  <block id="c4a99d505e8ebe4d5f04ae86d2a724b7" category="list-text">Sincronizzare il database Oracle di destinazione con il database di origine on-premise.</block>
  <block id="3bac7326688b384ce82c7c9807cae4b7" category="list-text">Al momento dello switchover, arrestare l'applicazione e il database Oracle di origine. Copia gli ultimi log di archiviazione e applicali al database Oracle di destinazione per aggiornarli.</block>
  <block id="98cf6a7f87338026b5b95afee91d5676" category="list-text">Avviare il database di destinazione per l'accesso degli utenti.</block>
  <block id="021e473c3a779caff7d794ce36c8ef68" category="list-text">Reindirizzare l'applicazione al database di destinazione per completare lo switchover.</block>
  <block id="e54801d4a4497c3566a98c0ef4ec6f18" category="section-title">Migrare i database Oracle on-premise su AWS FSX/EC2 utilizzando il trasferimento di PDB con la massima disponibilità</block>
  <block id="16d584a60d17de3de7cd0dcc0828fee9" category="paragraph">Questo approccio di migrazione è più adatto ai database Oracle già implementati nel modello multitenant PDB/CDB e lo storage ONTAP non è disponibile on-premise. Il metodo di trasferimento dei dati PDB utilizza la tecnologia di clonazione a caldo di Oracle PDB per spostare i dati PDB tra un CDB di origine e un CDB di destinazione, riducendo al minimo l'interruzione del servizio.</block>
  <block id="c5bd16be343bf2e5a3c081284c6c799b" category="paragraph">Innanzitutto, creare CDB in AWS FSX/EC2 con storage sufficiente per ospitare PDB da migrare da on-premise. È possibile riallocare più PDB on-premise uno alla volta.</block>
  <block id="d7acbe14b605ece64e94636c2ac85151" category="inline-link-macro">Conversione di una singola istanza non CDB in una PDB in una CDB multi-tenant</block>
  <block id="a6c9ea7b4477a21ac635b1db86abae5e" category="list-text">Se il database on-premise viene implementato in una singola istanza piuttosto che nel modello di PDB/CDB multi-tenant, seguire le istruzioni in <block ref="1a6a40cd2cc4844be72d5fbe9fd5f1e6" category="inline-link-macro-rx"></block> Per convertire la singola istanza in PDB/CDB multi-tenant. Quindi, seguire la fase successiva per migrare il PDB convertito in CDB in AWS FSX/EC2.</block>
  <block id="92c29ab4b5bfbc6de30e29363bc9aea7" category="inline-link-macro">Migrare i database Oracle on-premise nel cloud con il trasferimento dei dati PDB</block>
  <block id="522ca40aa0d528d119dec226eb9719b8" category="list-text">Se il database on-premise è già implementato nel modello PDB/CDB multitenant, seguire le istruzioni in <block ref="02137814e079cdfea8552a492195c829" category="inline-link-macro-rx"></block> per eseguire la migrazione.</block>
  <block id="499d7c245aad786a568d21227b5b65d8" category="paragraph">Il seguente video mostra come è possibile migrare un database Oracle (PDB) su FSX/EC2 utilizzando il trasferimento PDB con la massima disponibilità.</block>
  <block id="c0d2cea4b49d55201605052121b68ca7" category="inline-link-macro">Migrazione on-premise di Oracle PDB a AWS CDB con la massima disponibilità</block>
  <block id="e3d2de69302b3f20931015cece4526e4" category="paragraph"><block ref="5deefe7b3e78f7f08541c2e7b5b56e54" category="inline-link-macro-rx"></block></block>
  <block id="5eae2f4290a9e1f77061f80c6c015bc6" category="admonition">Sebbene le istruzioni dei passaggi 1 e 2 siano illustrate nel contesto del cloud pubblico Azure, le procedure sono applicabili al cloud AWS senza alcuna modifica.</block>
  <block id="41099d15ad008ac11d04538ef8e57575" category="paragraph">Il team NetApp Solutions Automation fornisce un toolkit per la migrazione in grado di facilitare la migrazione del database Oracle dal cloud AWS on-premise. Utilizzare il seguente comando per scaricare il toolkit di migrazione del database Oracle per il trasferimento di PDB.</block>
  <block id="40640c0c34d4427f5d18b9ca476e3158" category="summary">Questa pagina descrive la protezione automatica dei dati di Oracle19c sullo storage NetApp ONTAP.</block>
  <block id="261e91a1afdfe1123497b1b9ba5ab3e1" category="section-title">Protezione dei dati Oracle AWX/Tower</block>
  <block id="544348a8f04b16faced725115db5b6f3" category="section-title">Crea l'inventario, il gruppo, gli host e le credenziali per il tuo ambiente</block>
  <block id="db2b28449b6d868d910cd53527934988" category="list-text">Fornire il nome oracle per il primo gruppo e fare clic su Save (Salva).</block>
  <block id="200e1fa09608b23de5cd04d22d3a5bdb" category="list-text">Ripetere la procedura per un secondo gruppo denominato dr_oracle.</block>
  <block id="1e29c17b60e9145858da82263315e402" category="list-text">Selezionare il gruppo oracle creato, accedere al sottomenu hosts e fare clic su Add New host (Aggiungi nuovo host).</block>
  <block id="250d5368537e295251f9ccf63f950087" category="list-text">Fornire l'indirizzo IP dell'IP di gestione dell'host Oracle di origine e fare clic su Save (Salva).</block>
  <block id="22dcd973cf7a10ed9d03c5b959e65807" category="list-text">Questo processo deve essere ripetuto per il gruppo dr_oracle e deve essere aggiunto l'IP/nome host di gestione dell'host DR/destinazione Oracle.</block>
  <block id="1a4eca6a53be80f21117669b80a5dbc8" category="admonition">Di seguito sono riportate le istruzioni per la creazione dei tipi di credenziale e delle credenziali on-premise con ONTAP o CVO su AWS.</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="open-title">On-Prem</block>
  <block id="50d33cb309a9ea4bacb0a5541498b670" category="list-text">Creare tipi di credenziale. Per le soluzioni che utilizzano ONTAP, è necessario configurare il tipo di credenziale in modo che corrisponda alle voci di nome utente e password.</block>
  <block id="c048e95ab07253cc1cb87bef130c410b" category="list-text">Incollare il seguente contenuto in Injector Configuration (Configurazione iniettore), quindi fare clic su Save (Salva):</block>
  <block id="9302fe5c60a983a24bb8787c00db4862" category="list-text">Crea credenziale per ONTAP</block>
  <block id="0a0aab79fb5a20fa5f830947226ef87c" category="list-text">Immettere il nome e i dettagli dell'organizzazione per le credenziali ONTAP</block>
  <block id="81999e930ad44af27e84682c3ea1e750" category="list-text">Selezionare il tipo di credenziale creato nel passaggio precedente.</block>
  <block id="1546222d368538c25b5704b5fcf160f5" category="list-text">In Dettagli tipo, immettere il nome utente e la password per i cluster di origine e di destinazione.</block>
  <block id="c4be718383c8ca0aa17633d911fc38fd" category="list-text">Fare clic su Salva</block>
  <block id="39f6f9fe82cbf0c0970d13b6a043ad84" category="list-text">Crea credenziale per Oracle</block>
  <block id="30d4be106e7fb63befec4c8c7c815ad0" category="list-text">Immettere il nome e i dettagli dell'organizzazione per Oracle</block>
  <block id="61d6c643401e4a602f3c8b4b6fc0a93c" category="list-text">Ripetere la procedura se necessario per una credenziale diversa per l'host dr_oracle.</block>
  <block id="f7fc367b5de87581ac78fc80805439af" category="open-title">CVO</block>
  <block id="61efb6ce79debd57f1e5eb28b08f94ba" category="list-text">Creare tipi di credenziale. Per le soluzioni che coinvolgono ONTAP, devi configurare il tipo di credenziale in modo che corrisponda alle voci di nome utente e password, aggiungeremo anche le voci per Cloud Central e AWS.</block>
  <block id="b95cd128bfca5d5c9181a46d0392c360" category="list-text">Incollare il seguente contenuto in Injector Configuration (Configurazione iniettore) e fare clic su Save (Salva):</block>
  <block id="75f3f97810b5eef177a5355b86dabfd0" category="list-text">Crea credenziale per ONTAP/CVO/AWS</block>
  <block id="68085bee9e04417d4d9e74101a357a22" category="list-text">In Dettagli tipo, immettere il nome utente e la password per i cluster di origine e CVO, Cloud Central/Manager, AWS Access/Secret Key e Cloud Central Refresh Token.</block>
  <block id="922922f515b0ac072e20128999512b50" category="list-text">Crea credenziale per Oracle (origine)</block>
  <block id="7ebca140d5dcaa006aeda44b19cfc52e" category="list-text">Immettere il nome e i dettagli dell'organizzazione per l'host Oracle</block>
  <block id="ca530facf78f2112c60ee838d85b9b5b" category="list-text">Crea credenziale per destinazione Oracle</block>
  <block id="063e8368b0de123266b00f2c88e317fb" category="list-text">Inserire il nome e i dettagli dell'organizzazione dell'host Oracle DR</block>
  <block id="0d28c8cc8415971cf2cd02507176bf94" category="list-text">In Dettagli tipo, immettere il nome utente (ec2-user o se è stato modificato dall'impostazione predefinita) e la chiave privata SSH</block>
  <block id="cb8f433dfb62a17f7a02f4d7a8839b1c" category="list-text">Selezionare il metodo corretto di escalation dei privilegi (sudo) e immettere il nome utente e la password, se necessario.</block>
  <block id="be86ca474df5e14056bc0f20d2cdb767" category="section-title">Creare un progetto</block>
  <block id="791ef966f9be349751448b9066bdd8fa" category="list-text">invio <block ref="1881636a0f344e587cc2202e2db4c5ac" category="inline-link-rx"></block> Come URL del controllo di origine.</block>
  <block id="d02a79fb6f05358e16f9d9cf02288ac3" category="section-title">Configurare le variabili globali</block>
  <block id="3506caa5fe966a4676faac2993bc1431" category="section-title">Playbook per l'automazione</block>
  <block id="285a3bb8fb6f692046facadb3c0984cf" category="paragraph">È necessario eseguire quattro playbook separati.</block>
  <block id="37472723bc7712fedddee6d02e29228d" category="list-text">Playbook per la configurazione del tuo ambiente, on-premise o CVO.</block>
  <block id="5138c89250c5086accf2d1a5961c9b17" category="list-text">Playbook per la replica di file binari e database Oracle in base a una pianificazione</block>
  <block id="3e552d6e5b2c316c63eb1fc2081d42a8" category="list-text">Playbook per la replica dei registri Oracle in base a una pianificazione</block>
  <block id="33f4f1514dc2ceb963af16685f4de58c" category="list-text">Playbook per il ripristino del database su un host di destinazione</block>
  <block id="17ae7167fac3c2364c6ad7b58819a920" category="open-title">Setup ONTAP/CVO</block>
  <block id="cc335cb73dc47f7a9b404288e3b4330f" category="paragraph">Configurazione ONTAP e CVO</block>
  <block id="0676783b7d49061bfb23deb83b2d2f82" category="paragraph">*Configurare e avviare il modello di lavoro.*</block>
  <block id="6bc14a28f101e9d80ecc643ef13ef7fb" category="list-text">Immettere il nome ONTAP/CVO Setup</block>
  <block id="a7244f663b97629084f004e6c89b4a75" category="list-text">Selezionare il tipo di lavoro; Esegui consente di configurare il sistema in base a una guida.</block>
  <block id="57344b3bd58c0e451513e303e45d49b7" category="list-text">Selezionare il playbook ontap_setup.yml per un ambiente on-Prem oppure selezionare cvo_setup.yml per la replica su un'istanza CVO.</block>
  <block id="41c1d72990c270d0221458749497c3e6" category="admonition">Utilizzeremo questo modello e lo copieremo per gli altri playbook.</block>
  <block id="16f928d0ebd67060f6b3b2abf0481928" category="open-title">Replica per volumi binari e database</block>
  <block id="ea490901c403ce2b2a89f80227d0fb90" category="paragraph">Pianificazione del manuale di replica binario e database</block>
  <block id="2c777d857235f251004d6d8d70c9751d" category="list-text">Copiare il modello di lavoro creato in precedenza.</block>
  <block id="1eb977b1f69b531db931e9c62c1a0de9" category="list-text">Individuare il modello di installazione di ONTAP/CVO e fare clic con il pulsante destro del mouse su Copy Template (Copia modello)</block>
  <block id="3c96e57d33780bedfb652def025f39de" category="list-text">Fare clic su Edit Template (Modifica modello) nel modello copiato e modificare il nome in Binary and Database Replication Playbook (Playbook di replica binario e database).</block>
  <block id="b07fb736e8c17cea7e9e3753e7a67fd1" category="list-text">Mantenere lo stesso inventario, progetto e credenziali per il modello.</block>
  <block id="f42c6e71dcb07b403b8393d5ab7f7fe4" category="list-text">Selezionare ora_Replication_cg.yml come manuale da eseguire.</block>
  <block id="69fa06239fd734936aac1af5250c7f57" category="list-text">Le variabili rimarranno le stesse, ma l'IP del cluster CVO dovrà essere impostato nella variabile dst_cluster_ip.</block>
  <block id="ec7445bbcbadd1f11fe1bc3e5e56eef9" category="list-text">Pianificare il modello di lavoro.</block>
  <block id="ce0d20e65f0354847807516cbcc696f6" category="list-text">Fare clic sul modello Playbook di replica binario e database, quindi fare clic su Pianificazioni nella parte superiore del set di opzioni.</block>
  <block id="d9a6405dc4a6cd71f6d77c749070a5e6" category="list-text">Fare clic su Add (Aggiungi), add Name Schedule (Aggiungi pianificazione nome) per la replica binaria e del database, scegliere la data/ora di inizio all'inizio dell'ora, scegliere il fuso orario locale e la frequenza di esecuzione. La frequenza di esecuzione sarà spesso la replica di SnapMirror verrà aggiornata.</block>
  <block id="2dc4dec75c83aeb010419dc2a02da40b" category="admonition">Verrà creata una pianificazione separata per la replica del volume Log, in modo che possa essere replicata con cadenza più frequente.</block>
  <block id="b723f9a72bec39ac17d89e51ff0ba336" category="open-title">Replica per i volumi di log</block>
  <block id="47373f46adef617d17665b0b94be8f67" category="paragraph">Pianificazione del Playbook di replica del registro</block>
  <block id="048f2ee27b8617cb0e13b6a0b7da956f" category="list-text">Fare clic su Edit Template (Modifica modello) sul modello copiato e modificare il nome in Log Replication Playbook (Playbook replica registro).</block>
  <block id="d4a86123c8e623e35eaa51ab9583e03b" category="list-text">Selezionare ora_Replication_logs.yml come manuale da eseguire.</block>
  <block id="d6e504930da1d0732ea4162514a38e8e" category="list-text">Fare clic sul modello Log Replication Playbook, quindi fare clic su Schedules (Pianificazioni) nella parte superiore del set di opzioni.</block>
  <block id="1c03188c731004905466903c2eb763c4" category="list-text">Fare clic su Add (Aggiungi), Add Name Schedule (Aggiungi pianificazione nome) per Log Replication (replica registro), scegliere Start date/time (Data/ora di inizio) all'inizio dell'ora, scegliere il fuso orario locale e la frequenza di esecuzione. La frequenza di esecuzione sarà spesso la replica di SnapMirror verrà aggiornata.</block>
  <block id="d23bfe090a9fd09613c7a6573f619c02" category="admonition">Si consiglia di impostare la pianificazione del registro per l'aggiornamento ogni ora, in modo da garantire il ripristino dell'ultimo aggiornamento orario.</block>
  <block id="f76dbca531ab83300165aacf97e1b7ff" category="open-title">Ripristinare e ripristinare il database</block>
  <block id="8e43fbf8e210fdbb3e1d59ca59cde628" category="list-text">Fare clic su Edit Template (Modifica modello) sul modello copiato e modificare il nome in Restore and Recovery Playbook (Guida per il ripristino e il ripristino).</block>
  <block id="42f2159b893bbf4b6bf098ba9a026a1c" category="list-text">Selezionare ora_recovery.yml come manuale da eseguire.</block>
  <block id="0a3fe9b740fe79971ae2379eaec4822c" category="admonition">Questo manuale non verrà eseguito fino a quando non si sarà pronti a ripristinare il database nel sito remoto.</block>
  <block id="ba985cf3c812e3ba064fedc7353bbb77" category="section-title">Ripristino del database Oracle</block>
  <block id="b8a177e5fd059f33473cad4d1d073d38" category="list-text">Produzione on-premise i volumi di dati dei database Oracle sono protetti tramite la replica di NetApp SnapMirror su un cluster ONTAP ridondante nel data center secondario o su Cloud Volume ONTAP nel cloud pubblico. In un ambiente di disaster recovery completamente configurato, le istanze di calcolo del recovery nel data center secondario o nel cloud pubblico sono in standby e pronte per il ripristino del database di produzione in caso di disastro. Le istanze di calcolo in standby vengono mantenute in sincronia con le istanze on-premise eseguendo aggiornamenti di paraellel sulla patch del kernel del sistema operativo o aggiornando in un passo di blocco.</block>
  <block id="57d8ad774cb4fef3d53ee8836bfee761" category="list-text">In questa soluzione dimostrata, il volume binario Oracle viene replicato sulla destinazione e montato sull'istanza di destinazione per richiamare lo stack software Oracle. Questo approccio per il ripristino di Oracle ha un vantaggio rispetto a una nuova installazione di Oracle all'ultimo momento in cui si è verificato un disastro. Garantisce che l'installazione di Oracle sia completamente sincronizzata con l'installazione del software di produzione on-premise, con i livelli di patch e così via Tuttavia, questo potrebbe avere o meno ulteriori implicazioni di licenza software per il volume binario Oracle replicato nel sito di recovery, a seconda di come è strutturato il licensing software con Oracle. Si consiglia all'utente di verificare con il proprio personale addetto alle licenze software per valutare il potenziale requisito di licenza Oracle prima di decidere di utilizzare lo stesso approccio.</block>
  <block id="74eaa493ffed695592003e0844d93c46" category="list-text">L'host Oracle di standby nella destinazione viene configurato con le configurazioni dei prerequisiti Oracle.</block>
  <block id="0be4357ac224d44b11800179b23eb202" category="list-text">Gli SnapMirror sono rotti e i volumi sono resi scrivibili e montati sull'host Oracle di standby.</block>
  <block id="69504b415e8aad20e18beca0de96ab6a" category="list-text">Il modulo di ripristino Oracle esegue le seguenti attività per il ripristino e l'avvio di Oracle nel sito di ripristino dopo che tutti i volumi DB sono stati montati nell'istanza di calcolo in standby.</block>
  <block id="5e52a9563e31960cdf02c7b83e6495e7" category="list-text">Sincronizza il file di controllo: Abbiamo implementato file di controllo Oracle duplicati su diversi volumi di database per proteggere file di controllo critici del database. Uno si trova sul volume di dati e l'altro sul volume di log. Poiché i volumi di dati e log vengono replicati con frequenza diversa, al momento del ripristino non saranno sincronizzati.</block>
  <block id="26b9a788a0ef0527f25f68892b364d19" category="list-text">Relink Oracle binary: Poiché il binario Oracle viene trasferito in un nuovo host, è necessario un relink.</block>
  <block id="b66ad18a7982f7c233e9d0af2f867856" category="list-text">Ripristino del database Oracle: Il meccanismo di recovery recupera l'ultimo numero di modifica del sistema nell'ultimo log archiviato disponibile nel volume di log Oracle dal file di controllo e ripristina il database Oracle per recuperare tutte le transazioni aziendali che sono state replicate nel sito di DR al momento dell'errore. Il database viene quindi avviato in una nuova incarnazione per portare avanti le connessioni utente e le transazioni di business nel sito di recovery.</block>
  <block id="861503fb33ea04fecb13449e713e8ac6" category="admonition">Prima di eseguire il playbook di ripristino, assicurarsi di disporre di quanto segue: Assicurarsi che venga copiato su /etc/oratab e /etc/orainst.loc dall'host Oracle di origine all'host di destinazione</block>
  <block id="def8ebf26c2dec5f6af5a00893fae037" category="paragraph">Questa soluzione è stata progettata per essere eseguita in un ambiente AWX/Tower o da CLI su un host di controllo Ansible.</block>
  <block id="8ca0a52cf9938328875e0a8803ae71dd" category="list-text">Il modello di lavoro viene eseguito in tre fasi specificando i tag per ontap_CONFIG, linux_CONFIG e oracle_CONFIG.</block>
  <block id="da3d0d670ace8a327170aa25ee29f272" category="section-title">CLI tramite l'host di controllo Ansible</block>
  <block id="8c649830ad367719c501f8fc9ba4d387" category="inline-link-macro">fare clic qui per istruzioni dettagliate</block>
  <block id="d2068521e0b773365643b7537a1caa7f" category="list-text">Per configurare l'host Linux in modo che sia possibile utilizzarlo come host di controllo Ansible<block ref="27248a019dbeee842c240071693b6fb8" category="inline-link-macro-rx"></block></block>
  <block id="28e934ddab7714830f8afe8d3b641dc9" category="list-text">Una volta configurato l'host di controllo Ansible, è possibile clonare il repository Ansible Automation.</block>
  <block id="f667be8dac02593d217a02ac5bfb18de" category="list-text">Modificare il file hosts con gli IP e/o i nomi host della gestione del cluster ONTAP e degli IP di gestione del server Oracle.</block>
  <block id="95bd15e6b4a109de659c54c331c06284" category="list-text">Compilare le variabili specifiche dell'ambiente, quindi copiarle e incollarle in<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> file.</block>
  <block id="ca548be3e5f238d32286d43dc4c89f7b" category="list-text">Ogni host Oracle dispone di un file variabile identificato dal relativo nome host che contiene variabili specifiche dell'host.</block>
  <block id="87192ebbcab92216d25fd694a282971d" category="list-text">Una volta completati tutti i file variabili, è possibile eseguire il playbook in tre fasi specificando i tag per<block ref="0aadb2735557202c6ab978c489e2b6e9" prefix=" " category="inline-code"></block>,<block ref="7ee7ce51db32cbf806a0c21c648f4c2b" prefix=" " category="inline-code"></block>, e.<block ref="b656a5ae2d7a83cf0ead9c81fb96ec17" prefix=" " category="inline-code"></block>.</block>
  <block id="eebc1357e7d1e88ed4e4908d5ae86c0b" category="cell">Host AWX/Tower o Linux come host di controllo Ansible</block>
  <block id="0a928fe81d89083ed303ea3d9f1af8c9" category="cell">ONTAP versione 9.3 - 9.7</block>
  <block id="515f291f3ecc550c5d13cf31fadba91d" category="cell">File di installazione Oracle sui server Oracle</block>
  <block id="9bb642814808cd0cab510ddfb9e5969c" category="cell">*ontap_config*</block>
  <block id="79b814c8267c6b7822e78ab4624db8e0" category="cell">Creazione di SVM basate su NFS per Oracle</block>
  <block id="0c981d6164da0d8e69cdb199966316b0" category="cell">Creazione di policy di esportazione</block>
  <block id="99179ac01bbb0236fc540871377c55c4" category="cell">Creazione di volumi per Oracle</block>
  <block id="db738705829d97db1e287ad8ea9e5400" category="cell">Creazione di LIF NFS</block>
  <block id="089c4c184b079d771501d8ceb0f3bb05" category="cell">*linux_config*</block>
  <block id="3ea572544d30a39d236496578f980d13" category="cell">Creare punti di montaggio e montare volumi NFS</block>
  <block id="db6c0f994cc39fbf66d58eea6c627e6a" category="cell">Verificare i montaggi NFS</block>
  <block id="6a882e7966e7869ab1d2112a0b1c0074" category="cell">Configurazione specifica del sistema operativo</block>
  <block id="6e6d41d1398fafd8809de20e831c9ce3" category="cell">Creare directory Oracle</block>
  <block id="6f965a5d44e1653dac9825f465f71c84" category="cell">Configurare gli hugepage</block>
  <block id="be577868fe0712b7bbb6d5cb5eae613c" category="cell">Disattiva SELinux e il daemon del firewall</block>
  <block id="bb6f16330211bf24baa83db38b11e4a9" category="cell">Attivare e avviare il servizio chronyd</block>
  <block id="e9e5cefa281d2c696aac82ef9c756f51" category="cell">aumentare il limite massimo del descrittore di file</block>
  <block id="a4acc779f882208c081f943aedfeab5c" category="cell">Creare il file di sessione pam.d.</block>
  <block id="d03021f9e02b9fa9ebac591ad4bfea08" category="cell">*oracle_config*</block>
  <block id="5e706781d4bf141c80e249a244179235" category="cell">Installazione del software Oracle</block>
  <block id="1a98fce6d77de1126bf3cb8247747621" category="cell">Creare un listener Oracle</block>
  <block id="841df7bfbef212936073c6d261d4dba9" category="cell">Creare database Oracle</block>
  <block id="845a6e024025bb13aafdc167511e5e7d" category="cell">Configurazione dell'ambiente Oracle</block>
  <block id="666113957f940ba4319b4f0d9c3e86c0" category="cell">Salva stato PDB</block>
  <block id="264bca6ddd5a16346460d9c21e8f926d" category="cell">Attivare la modalità di archiviazione delle istanze</block>
  <block id="620ca5ae835411d2031ca0fdbbbe61a1" category="cell">Abilitare il client DNFS</block>
  <block id="4d7e6c9b84f6f86cf4817262ad424eeb" category="cell">Abilitare l'avvio e lo spegnimento automatici del database tra i riavvii del sistema operativo</block>
  <block id="ebda2606845855cc07ce0ce15ecf8a00" category="paragraph">Per semplificare l'automazione, abbiamo preimpostato molti parametri di implementazione Oracle richiesti con valori predefiniti. In genere non è necessario modificare i parametri predefiniti per la maggior parte delle implementazioni. Un utente più avanzato può apportare modifiche ai parametri predefiniti con cautela. I parametri predefiniti si trovano in ogni cartella di ruoli nella directory dei valori predefiniti.</block>
  <block id="452eff11ca6d680a279a3e81b8dc8974" category="section-title">Istruzioni per l'implementazione</block>
  <block id="1cf7ad9cd74067dd3f4aee3c1690ea32" category="paragraph">Prima di iniziare, scaricare i seguenti file di installazione e patch Oracle e inserirli in<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> Directory con accesso in lettura, scrittura ed esecuzione per tutti gli utenti su ciascun server DB da implementare. Le attività di automazione cercano i file di installazione denominati in quella particolare directory per l'installazione e la configurazione di Oracle.</block>
  <block id="5abe869dd828ac1e4527f07db79841a8" category="inline-link-macro">Qui per le procedure di implementazione AWX/Tower dettagliate</block>
  <block id="c3bcf861ccc9247a7c0a9b4749747e4e" category="inline-link-macro">Qui per l'implementazione della CLI</block>
  <block id="f867ea86471dd6849f2c840cf13d1536" category="paragraph">Una volta pronti, fare clic su <block ref="0ecf76284fbf596cdd030af085c16a3b" category="inline-link-macro-rx"></block> oppure <block ref="42cd9508ebf775e8df0efba80be76af7" category="inline-link-macro-rx"></block>.</block>
  <block id="f53cfd73e0994740413d578c9dd6b36e" category="doc">TR-4923: Server SQL su AWS EC2 con Amazon FSX per NetApp ONTAP</block>
  <block id="9aeea85747c176482897f26600d172d0" category="paragraph">Autori: Pat Sinthusan e Niyaz Mohamed, NetApp</block>
  <block id="8bd093418d226733e085e856bd9165c8" category="paragraph">Molte aziende che desiderano migrare le applicazioni da on-premise a cloud scoprono che lo sforzo è ostacolato dalle differenze nelle funzionalità offerte dai sistemi di storage on-premise e dai servizi di cloud storage. Questo divario ha reso la migrazione delle applicazioni aziendali come Microsoft SQL Server molto più problematica. In particolare, le lacune nei servizi necessari per eseguire un'applicazione aziendale, come ad esempio solide snapshot, funzionalità di efficienza dello storage, alta disponibilità, affidabilità e performance costanti, hanno costretto i clienti a fare compromessi di progettazione o a rinunciare alla migrazione delle applicazioni. Con FSX per NetApp ONTAP, i clienti non devono più scendere a compromessi. FSX per NetApp ONTAP è un servizio AWS nativo (di prima parte) venduto, supportato, fatturato e completamente gestito da AWS. Utilizza la potenza di NetApp ONTAP per fornire le stesse funzionalità di storage e gestione dei dati di livello Enterprise che NetApp ha fornito on-premise per trent'anni in AWS come servizio gestito.</block>
  <block id="f3eec26de1c09022af7c97255f0dfee6" category="inline-link">ONTAP AWS FSX</block>
  <block id="a2f7f68476a76b6aa359589e4d201707" category="paragraph">Con SQL Server sulle istanze EC2, gli amministratori di database possono accedere e personalizzare il proprio ambiente di database e il sistema operativo sottostante. Un SQL Server sull'istanza EC2 in combinazione con<block ref="3f737fd84a60fb425fdcdb5cf9a593da" category="inline-link-rx"></block> per memorizzare i file di database, consente performance elevate, gestione dei dati e un percorso di migrazione semplice e semplice utilizzando la replica a livello di blocco. Pertanto, è possibile eseguire il database complesso su AWS VPC con un semplice approccio "lift-and-shift", meno clic e nessuna conversione dello schema.</block>
  <block id="cf79d59896c29cc7579cf75220c25c95" category="section-title">Vantaggi dell'utilizzo di Amazon FSX per NetApp ONTAP con SQL Server</block>
  <block id="8908df00453997edbfc759829ecdf0d8" category="paragraph">Amazon FSX per NetApp ONTAP è il file storage ideale per le implementazioni di SQL Server in AWS. I vantaggi includono:</block>
  <block id="7b699f0e1a60e419ed7d9173339aa3f5" category="list-text">Performance elevate e throughput costanti con bassa latenza</block>
  <block id="8a34b0f2109dd0aad0c0c9976717cdd3" category="list-text">Caching intelligente con cache NVMe per migliorare le performance</block>
  <block id="b10e27f9d68e001b8aa9369c8d308a8c" category="list-text">Dimensionamento flessibile per aumentare o ridurre capacità, throughput e IOPS in tempo reale</block>
  <block id="169fee7c17564fc51aa8d2e77bcc1ce0" category="list-text">Replica efficiente dei blocchi on-premise-to-AWS</block>
  <block id="fd140f04c5bc5f51aff3ea5e1619abaf" category="list-text">L'utilizzo di iSCSI, un protocollo noto per l'ambiente di database</block>
  <block id="e2c00a563e0219fd93fa6f24606dee33" category="list-text">Funzionalità di efficienza dello storage come thin provisioning e cloni a impatto zero</block>
  <block id="4ac0316f1ba409d5cd9684222f9f8ada" category="list-text">Riduzione dei tempi di backup da ore a minuti, con conseguente riduzione dell'RTO</block>
  <block id="e3168d8a4383357a37460afad2f8878d" category="list-text">Backup granulare e ripristino di database SQL con l'intuitiva interfaccia utente di NetApp SnapCenter</block>
  <block id="935da11069e36e124602b7e23a73ee06" category="list-text">Possibilità di eseguire più migrazioni di test prima della migrazione effettiva</block>
  <block id="15173984ed0ff615a3f0d55c8cd12291" category="list-text">Riduzione dei downtime durante la migrazione e superamento delle sfide di migrazione con copia a livello di file o i/O.</block>
  <block id="0de5f8d5cf18757efac074c02f16a0bb" category="list-text">Riduzione del MTTR individuando la causa principale dopo una release importante o un aggiornamento delle patch</block>
  <block id="1a8e2e4ef765d6c61c4652659fb151ac" category="paragraph">L'implementazione di database SQL Server su FSX ONTAP con il protocollo iSCSI, come comunemente utilizzato on-premise, offre un ambiente di storage ideale per database con performance superiori, efficienza dello storage e funzionalità di gestione dei dati. Utilizzando più sessioni iSCSI, presupponendo una dimensione del working set pari al 5%, l'adattamento di una Flash cache offre oltre 100.000 IOPS con il servizio FSX ONTAP. Questa configurazione offre un controllo completo delle performance per le applicazioni più esigenti. SQL Server in esecuzione su istanze EC2 più piccole connesse a FSX per ONTAP può eseguire le stesse prestazioni di SQL Server in esecuzione su un'istanza EC2 molto più grande, perché vengono applicati solo limiti di larghezza di banda di rete a fronte di FSX per ONTAP. La riduzione delle dimensioni delle istanze riduce anche i costi di calcolo, offrendo un'implementazione ottimizzata per il TCO. La combinazione di SQL con iSCSI, SMB3.0 e condivisioni di disponibilità continua multicanale su FSX per ONTAP offre grandi vantaggi per i carichi di lavoro SQL.</block>
  <block id="135b308ed83c53f1516b7c754566d1c4" category="section-title">Prima di iniziare</block>
  <block id="365a329d23604298414064b1bd2dba2f" category="paragraph">La combinazione di Amazon FSX per NetApp ONTAP e SQL Server su istanza EC2 consente la creazione di design di storage di database di livello Enterprise in grado di soddisfare i requisiti applicativi più esigenti di oggi. Per ottimizzare entrambe le tecnologie, è fondamentale comprendere i modelli e le caratteristiche di i/o di SQL Server. Un layout di storage ben progettato per un database SQL Server supporta le performance di SQL Server e la gestione dell'infrastruttura SQL Server. Un buon layout dello storage consente inoltre di avere successo nell'implementazione iniziale e di far crescere l'ambiente nel tempo con la crescita del business.</block>
  <block id="800d285a5a8ca10451f7ace50ac40de5" category="paragraph">Prima di completare la procedura descritta in questo documento, è necessario disporre dei seguenti prerequisiti:</block>
  <block id="69a7abd5a400936f0e1a89910dfa0ba1" category="list-text">Un account AWS</block>
  <block id="bfa061c0e7fe048c571ab15bc8d211a4" category="list-text">Ruoli IAM appropriati per il provisioning di EC2 e FSX per ONTAP</block>
  <block id="a76b04166db341ceee35b584673698e9" category="list-text">Un dominio Windows Active Directory su EC2</block>
  <block id="3084927119ae63d45676d527dfb4a882" category="list-text">Tutti i nodi di SQL Server devono essere in grado di comunicare tra loro</block>
  <block id="b1ada0ca0559fff335d482de393b4c70" category="list-text">Assicurarsi che la risoluzione DNS funzioni e che i nomi host possano essere risolti. In caso contrario, utilizzare la voce del file host.</block>
  <block id="8413178222467ef68eb68a0644f11c42" category="list-text">Conoscenza generale dell'installazione di SQL Server</block>
  <block id="9c69c1668eca3541f0576cdc7fc730f0" category="paragraph">Inoltre, fare riferimento alle Best practice NetApp per gli ambienti SQL Server per garantire la migliore configurazione dello storage.</block>
  <block id="49c805233b94175c188c58ebf681a2b9" category="example-title">Configurazioni Best practice per ambienti SQL Server su EC2</block>
  <block id="d1d9da06ca1cde6106fef737b522df6e" category="paragraph">Con FSX ONTAP, procurarsi lo storage è l'attività più semplice e può essere eseguita aggiornando il file system. Questo semplice processo consente l'ottimizzazione dinamica dei costi e delle performance in base alle esigenze, aiuta a bilanciare il carico di lavoro SQL ed è anche un ottimo elemento di supporto per il thin provisioning. Il thin provisioning di FSX ONTAP è progettato per presentare più storage logico alle istanze EC2 che eseguono SQL Server rispetto a quanto previsto nel file system. Invece di allocare lo spazio in anticipo, lo spazio di storage viene allocato dinamicamente a ciascun volume o LUN durante la scrittura dei dati. Nella maggior parte delle configurazioni, lo spazio libero viene liberato anche quando i dati nel volume o nel LUN vengono cancellati (e non vengono conservati da alcuna copia Snapshot). La tabella seguente fornisce le impostazioni di configurazione per l'allocazione dinamica dello storage.</block>
  <block id="51ac4bf63a0c6a9cefa7ba69b4154ef1" category="cell">Impostazione</block>
  <block id="db1bfba30dab4f1ed4a13cc586837f1b" category="cell">Nessuno (impostazione predefinita)</block>
  <block id="f6445fd89b0b2c67f0304765c4c9a760" category="cell">Prenotazione LUN</block>
  <block id="f1e0735081bab920eff76b08a4600c76" category="cell">fractional_reserve</block>
  <block id="856ee920f3261cadbc1c3fc52171d071" category="cell">0% (impostazione predefinita)</block>
  <block id="99c0f62171e34b4ab6a79265f038e3af" category="cell">snap_reserve</block>
  <block id="a85c04491cb5bbcb534dc50b65b97530" category="cell">Eliminazione automatica</block>
  <block id="4ec86a7059e3d1002a06c51cbec9ad47" category="cell">volume / oldest_first</block>
  <block id="7c68df7d17c446f99304ee1dc1498bfc" category="cell">Dimensionamento automatico</block>
  <block id="521c36a31c2762741cf0f8890cbe05e3" category="cell">Acceso</block>
  <block id="902c737cbaa1a86889c41fec210c805f" category="cell">prova_prima</block>
  <block id="f4c25546f220bb5d07f94244c9303967" category="cell">Crescita automatica</block>
  <block id="43c4c1dbc452be91829f25ee32c2a956" category="cell">Policy di tiering dei volumi</block>
  <block id="6d576caa9862f6db0177dfaff7abb095" category="cell">Solo Snapshot</block>
  <block id="4c0abf2d4c54820b8d33061abaf30759" category="cell">Policy di Snapshot</block>
  <block id="e08a486f204620eff1a08fc926316c68" category="paragraph">Con questa configurazione, la dimensione totale dei volumi può essere superiore allo storage effettivo disponibile nel file system. Se le LUN o le copie Snapshot richiedono più spazio di quello disponibile nel volume, i volumi aumentano automaticamente, occupando più spazio dal file system contenente. La funzione di crescita automatica consente a FSX ONTAP di aumentare automaticamente le dimensioni del volume fino alle dimensioni massime predeterminate. Per supportare la crescita automatica del volume, deve essere disponibile spazio nel file system contenente. Pertanto, con la funzione di crescita automatica attivata, è necessario monitorare lo spazio libero nel file system contenente e aggiornare il file system quando necessario.</block>
  <block id="82373a2016779f9c20fdc0d8b48101a7" category="inline-link">allocazione dello spazio</block>
  <block id="0126eb1acda2ac795726d8bc5fe76a98" category="paragraph">Insieme a questo, impostare<block ref="9d6ca3a9a42127525354c85d54adc465" category="inline-link-rx"></block> Opzione on LUN (LUN) su Enabled (attivato) in modo che FSX ONTAP notifichi all'host EC2 quando il volume ha esaurito lo spazio e il LUN nel volume non può accettare scritture. Inoltre, questa opzione consente a FSX per ONTAP di recuperare automaticamente lo spazio quando il server SQL sull'host EC2 elimina i dati. Per impostazione predefinita, l'opzione di allocazione dello spazio è disattivata.</block>
  <block id="afa7be61df3527a5c4b5b7369729dfbc" category="admonition">Se viene creata una LUN riservata allo spazio in un volume non garantito, la LUN si comporta come una LUN non riservata allo spazio. Questo perché un volume non garantito non dispone di spazio da allocare al LUN; il volume stesso può allocare spazio solo quando viene scritto, a causa della sua garanzia di assenza.</block>
  <block id="cf18df2432b44bda18f67ef6fc93e36f" category="paragraph">Con questa configurazione, gli amministratori di FSX ONTAP possono in genere dimensionare il volume in modo che debbano gestire e monitorare lo spazio utilizzato nel LUN sul lato host e nel file system.</block>
  <block id="3e5fc395bc0727ee4a5d50bf7852e11e" category="admonition">NetApp consiglia di utilizzare un file system separato per i carichi di lavoro di SQL Server. Se il file system viene utilizzato per più applicazioni, monitorare l'utilizzo dello spazio del file system e dei volumi all'interno del file system per assicurarsi che i volumi non siano in concorrenza con lo spazio disponibile.</block>
  <block id="9bc03cfd47c7deb1375b7e700fba9c1a" category="admonition">Le copie Snapshot utilizzate per creare volumi FlexClone non vengono eliminate dall'opzione di eliminazione automatica.</block>
  <block id="20292bb9591bce95b16e6ee1415023d3" category="admonition">L'overcommitment dello storage deve essere attentamente considerato e gestito per un'applicazione mission-critical come SQL Server per la quale non è possibile tollerare anche un'interruzione minima. In tal caso, è meglio monitorare le tendenze di consumo dello storage per determinare quanto, se presenti, l'impegno in eccesso sia accettabile.</block>
  <block id="cd47dd01745339787e4c7300389401f2" category="cell">Best Practice</block>
  <block id="fbaad71632f1f86a6aec0eb25bf981d7" category="list-text">Per ottenere performance di storage ottimali, è possibile eseguire il provisioning della capacità del file system fino a 1,35 volte più grande rispetto all'utilizzo totale del database.</block>
  <block id="e2ec94309dce197f199c6e60cd3070eb" category="list-text">Quando si utilizza il thin provisioning, è necessario un monitoraggio appropriato, accompagnato da un piano d'azione efficace, per evitare il downtime delle applicazioni.</block>
  <block id="d7fbab8fe0fe681c9e815507bcdf85c8" category="list-text">Assicurati di impostare gli avvisi di Cloudwatch e di altri strumenti di monitoraggio in modo che le persone vengano contattate con il tempo necessario per reagire quando lo storage viene riempito.</block>
  <block id="626a89ea253e84625436538e7249e94d" category="section-title">Configurare lo storage per SQL Server e implementare SnapCenter per le operazioni di backup, ripristino e clonazione</block>
  <block id="0a1c2236044192334a3fb3bbc0ab0dcd" category="paragraph">Per eseguire operazioni SQL Server con SnapCenter, è necessario innanzitutto creare volumi e LUN per SQL Server.</block>
  <block id="0cf06bf086c162ff9027bab7f6f36c93" category="example-title">Creare volumi e LUN per SQL Server</block>
  <block id="ff6ef44023084895f5f22aaf568ee0e3" category="paragraph">Per creare volumi e LUN per SQL Server, attenersi alla seguente procedura:</block>
  <block id="0165fcfd32879eacf541aadf086338d2" category="list-text">Aprire la console Amazon FSX all'indirizzo<block ref="977f5adc4374191d0e48b9c0a8830158" category="inline-link-rx"></block></block>
  <block id="1e33ad7579c798ce6033c144ac99b840" category="list-text">Creare un file system Amazon FSX per NetApp ONTAP utilizzando l'opzione di creazione standard nel metodo di creazione. In questo modo è possibile definire le credenziali FSxadmin e vsadmin.</block>
  <block id="a83755c47ff9159637d0666c65d8c544" category="paragraph"><block ref="a83755c47ff9159637d0666c65d8c544" category="inline-image-macro-rx" type="image"></block></block>
  <block id="269452df07db5e5d5fb10125ef2dfc42" category="list-text">Specificare la password per fsxadmin.</block>
  <block id="0939c7e9185662b3e54503cb12415c7a" category="paragraph"><block ref="0939c7e9185662b3e54503cb12415c7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dea5db34596930d023317e03284777e1" category="list-text">Specificare la password per le SVM.</block>
  <block id="d2b251088e201058dd19119478e04523" category="paragraph"><block ref="d2b251088e201058dd19119478e04523" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5a504f8d9fd87dc54c0f8a370eed579" category="inline-link">Creazione di un volume su FSX per NetApp ONTAP</block>
  <block id="d0ff5f8be38ac60d217f9c007a52da0e" category="list-text">Creare i volumi seguendo la procedura indicata nella<block ref="1146addad8000a8f0f70de9ea1e5f637" category="inline-link-rx"></block>.</block>
  <block id="c2ffe02d76c4f089648f1647b43e4ee5" category="cell">Best practice</block>
  <block id="17288ccd1a2a55fccc24e084bec74a89" category="list-text">Disattivare le pianificazioni delle copie Snapshot dello storage e le policy di conservazione. Utilizzare invece NetApp SnapCenter per coordinare le copie Snapshot dei dati e dei volumi di log di SQL Server.</block>
  <block id="c5023b4b04bc0ddc3d77e81fee7d99bb" category="list-text">Configurare i database su LUN individuali su volumi separati per sfruttare la funzionalità di ripristino rapida e granulare.</block>
  <block id="6cb174042332f6d15cedab79c1f88bac" category="list-text">Posizionare i file di dati utente (.mdf) su volumi separati perché si tratta di carichi di lavoro di lettura/scrittura casuali. È comune creare backup del log delle transazioni con maggiore frequenza rispetto ai backup del database. Per questo motivo, posizionare i file di log delle transazioni (.ldf) su un volume separato dai file di dati, in modo che sia possibile creare pianificazioni di backup indipendenti per ciascuno di essi. Questa separazione isola inoltre l'i/o di scrittura sequenziale dei file di log dall'i/o di lettura/scrittura casuale dei file di dati e migliora significativamente le prestazioni di SQL Server.</block>
  <block id="0588cef8958d83f61aed452f853f5852" category="list-text">Tempdb è un database di sistema utilizzato da Microsoft SQL Server come area di lavoro temporanea, in particolare per le operazioni DBCC CHECKDB i/o intensive. Pertanto, posizionare questo database su un volume dedicato. In ambienti di grandi dimensioni in cui il numero di volumi rappresenta una sfida, è possibile consolidare il tempdb in un numero inferiore di volumi e memorizzarlo nello stesso volume degli altri database di sistema dopo un'attenta pianificazione. La protezione dei dati per tempdb non è una priorità elevata perché questo database viene ricreato ogni volta che Microsoft SQL Server viene riavviato.</block>
  <block id="0f33b537ada1b2dcb95880741120d7b6" category="list-text">Utilizzare il seguente comando SSH per creare volumi:</block>
  <block id="4272c7e0323a62da36a59d8db2457c11" category="list-text">Avviare il servizio iSCSI con PowerShell utilizzando privilegi elevati nei server Windows.</block>
  <block id="91d0d079f1c5a2183c1012cd2c2e59ab" category="list-text">Installare multipath-io con PowerShell utilizzando privilegi elevati nei server Windows.</block>
  <block id="4dee8d84e86540a5c4c302b3d75c32bc" category="list-text">Individuare il nome di Windows Initiator con PowerShell utilizzando privilegi elevati nei server Windows.</block>
  <block id="13aca4cbeddb191f6e28fc3dc5b50aca" category="paragraph"><block ref="13aca4cbeddb191f6e28fc3dc5b50aca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1fcce0650c7bce1532fc57b6af299dba" category="list-text">Connettersi alle macchine virtuali di storage (SVM) utilizzando PuTTY e creare un iGroup.</block>
  <block id="a260444f9f7265e7da0cffa861246e93" category="list-text">Utilizzare il seguente comando SSH per creare LUN:</block>
  <block id="0bf39861d87235a7c094d3de2e3a8840" category="paragraph"><block ref="0bf39861d87235a7c094d3de2e3a8840" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52f5ef787d84b4ec1b5183cffdef5b56" category="list-text">Per ottenere l'allineamento i/o con lo schema di partizione del sistema operativo, utilizzare Windows_2008 come tipo di LUN consigliato. Fare riferimento a.<block ref="ff5fd3b71f5cd8b1a4e2fe23ad6d92ae" category="inline-link-rx"></block> per ulteriori informazioni.</block>
  <block id="4f10474fd5677d7f5caee5944cfd1a79" category="list-text">Utilizzare il seguente comando SSH per mappare i LUN appena creati.</block>
  <block id="e9cb77a7f24ef618789f32ace120d069" category="paragraph"><block ref="e9cb77a7f24ef618789f32ace120d069" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0108f548c7bfba3ca19e227db2ad81d9" category="list-text">Per un disco condiviso che utilizza il cluster di failover di Windows, eseguire un comando SSH per mappare lo stesso LUN all'igroup che appartiene a tutti i server che fanno parte del cluster di failover di Windows.</block>
  <block id="88c4f29ad54bd37fb1b7a1491b7af990" category="list-text">Connessione di Windows Server a una SVM con una destinazione iSCSI. Individuare l'indirizzo IP di destinazione da AWS Portal.</block>
  <block id="547003177db44afb512e9939c282d6c9" category="paragraph"><block ref="547003177db44afb512e9939c282d6c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df9eaa73034109b21c143e8c209823c2" category="list-text">Da Server Manager (Gestione server) e dal menu Tools (Strumenti), selezionare iSCSI Initiator (iniziatore iSCSI). Selezionare la scheda Discovery (rilevamento), quindi Discover Portal (Scopri portale). Fornire l'indirizzo IP iSCSI indicato nella fase precedente e selezionare Advanced (Avanzate). Da Local Adapter, selezionare Microsoft iSCSI Initiator. Da Initiator IP (IP iniziatore), selezionare l'IP del server. Quindi selezionare OK per chiudere tutte le finestre.</block>
  <block id="076e00306637258d0363c74566eb915d" category="paragraph"><block ref="076e00306637258d0363c74566eb915d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd432f2fc3bb1fab0023bf42f7b4108" category="list-text">Ripetere il punto 12 per il secondo IP iSCSI da SVM.</block>
  <block id="5648333e8838336553b385e488639863" category="list-text">Selezionare la scheda *targets*, selezionare *Connect* e selezionare *Enable muti-path*.</block>
  <block id="4bff8ed7bd736139029b8aa4f639ccd9" category="paragraph"><block ref="4bff8ed7bd736139029b8aa4f639ccd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f94de8933712f5d52ca62caf7fef6eb5" category="list-text">Per ottenere performance ottimali, aggiungere altre sessioni; NetApp consiglia di creare cinque sessioni iSCSI. Selezionare *Proprietà *&gt; *Aggiungi sessione *&gt; *Avanzate* e ripetere il punto 12.</block>
  <block id="5636fa6e8685f1da20bf9489bcadc782" category="paragraph"><block ref="5636fa6e8685f1da20bf9489bcadc782" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c762aaec425b12667f2a575012e48905" category="list-text">Configurare cinque sessioni iSCSI per interfaccia di destinazione per ottenere performance ottimali.</block>
  <block id="72a53f90bcbaa031cad1c79575c53094" category="list-text">Configurare una policy di round robin per ottenere le migliori performance iSCSI complessive.</block>
  <block id="168b03d713c83578e3c90be8e0a76a8e" category="list-text">Assicurarsi che la dimensione dell'unità di allocazione sia impostata su 64K per le partizioni durante la formattazione dei LUN</block>
  <block id="a196b0bfd5261a81ff3d40a2043f792c" category="list-text">Eseguire il seguente comando PowerShell per assicurarsi che la sessione iSCSI sia persistente.</block>
  <block id="58fbf35d4173787943d2fe31aed43341" category="paragraph"><block ref="58fbf35d4173787943d2fe31aed43341" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22ae84abced8e9e1236160d982616772" category="list-text">Inizializzare i dischi con il seguente comando PowerShell.</block>
  <block id="ac47df449db0c31d1ba6117a1dd19765" category="paragraph"><block ref="ac47df449db0c31d1ba6117a1dd19765" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b1e9edc2d6e907049df14a10a6fcc404" category="list-text">Eseguire i comandi Create Partition (Crea partizione) e Format Disk (Formatta disco) con PowerShell.</block>
  <block id="79484e9f2e5f0589c78f273edd80759f" category="paragraph">È possibile automatizzare la creazione di volumi e LUN utilizzando lo script PowerShell dell'Appendice B. I LUN possono essere creati anche utilizzando SnapCenter.</block>
  <block id="d05ae24753b4098046ae8369c5618b97" category="paragraph">Una volta definiti i volumi e le LUN, è necessario configurare SnapCenter per eseguire le operazioni del database.</block>
  <block id="6309043436d4e7e5bad9a81c89ff15e4" category="example-title">Panoramica di SnapCenter</block>
  <block id="419a08c6fdce80a29b8f8aeb7524f0e2" category="paragraph">NetApp SnapCenter è un software per la protezione dei dati di prossima generazione per le applicazioni Enterprise Tier-1. SnapCenter, con la sua interfaccia di gestione con singolo pannello di controllo, automatizza e semplifica i processi manuali, complessi e lunghi associati al backup, al ripristino e alla clonazione di più database e altri carichi di lavoro applicativi. SnapCenter sfrutta le tecnologie NetApp, tra cui NetApp Snapshots, NetApp SnapMirror, SnapRestore e NetApp FlexClone. Questa integrazione consente alle organizzazioni IT di scalare la propria infrastruttura storage, soddisfare gli impegni SLA sempre più rigorosi e migliorare la produttività degli amministratori in tutta l'azienda.</block>
  <block id="aa7c84b8a1ac7c27cbd3e14740e96214" category="example-title">Requisiti del server SnapCenter</block>
  <block id="4ee08603c9fd8ece4f670310954cdde6" category="paragraph">La seguente tabella elenca i requisiti minimi per l'installazione del server e del plug-in SnapCenter.</block>
  <block id="05bbb43b3d923283e0b6ffafd088f41f" category="cell">Componenti</block>
  <block id="9b97b7bd5e0a87be7bf218224ada83cf" category="cell">Requisito</block>
  <block id="44e5a606cb3fbfaed79ce8eb853ed886" category="paragraph">Numero minimo di CPU</block>
  <block id="ea54f01387bc5362f6e287ba66d656a8" category="paragraph">Quattro core/vCPU</block>
  <block id="99880291d6a6b72b928a1847a6135c88" category="paragraph">Minimo: 8 GB consigliati: 32 GB</block>
  <block id="96e1506a8b72a455b990ffe403eea2cf" category="paragraph">Spazio di storage</block>
  <block id="39b4c2fc16a74430850f1b767f816bdd" category="paragraph">Spazio minimo per l'installazione: 10 GB di spazio minimo per il repository: 10 GB</block>
  <block id="2e71b3fb71d89f18906d4807a6011e20" category="cell">Sistema operativo supportato</block>
  <block id="00aae0645113cb861020a7a42ded48c2" category="list-text">Windows Server 2012</block>
  <block id="96bc7f42979153694e05a6a2b867772e" category="list-text">Windows Server 2012 R2</block>
  <block id="ed590cb2453f0683b64cb528f78610a2" category="list-text">Windows Server 2016</block>
  <block id="31f8757839909e87266f2b53482c86ef" category="list-text">Windows Server 2019</block>
  <block id="7c01fa88a74580e7e4f62ca6bfe7ee83" category="cell">Pacchetti software</block>
  <block id="aab81d3c2e898a19cf0f270cdb285a21" category="list-text">.NET 4.5.2 o versione successiva</block>
  <block id="43de0ba571a51d1adc60e6d05ecf8d70" category="list-text">Windows Management Framework (WMF) 4.0 o versione successiva</block>
  <block id="fd6133b32592ca288e63c1b1257f656d" category="list-text">PowerShell 4.0 o versione successiva</block>
  <block id="a19fb58a9ea7e8409b13e971960fdbf8" category="paragraph">Per informazioni sulla compatibilità delle versioni, consultare<block ref="b7322bec4509d45107de6de43ca1f517" category="inline-link-rx"></block>.</block>
  <block id="00324c8ea6b2abc68414748e587e15ec" category="example-title">Layout dello storage del database</block>
  <block id="a02dce187534c84aa16d8849406a60eb" category="paragraph">La figura seguente illustra alcune considerazioni relative alla creazione del layout di storage del database Microsoft SQL Server durante il backup con SnapCenter.</block>
  <block id="4c246b141980a6574bc7f111fe7abef7" category="paragraph"><block ref="4c246b141980a6574bc7f111fe7abef7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ebfae4b9e090c4988616a73ffc71415e" category="list-text">Posizionare i database con query i/o intensive o con database di grandi dimensioni (ad esempio, 500 GB o più) su un volume separato per un ripristino più rapido. Il backup di questo volume deve essere eseguito anche da processi separati.</block>
  <block id="4916b57b0128fd5a0a4300f0a8763292" category="list-text">Consolidamento di database di piccole e medie dimensioni meno critici o con meno requisiti di i/o in un singolo volume. Il backup di un gran numero di database che risiedono nello stesso volume comporta un minor numero di copie Snapshot che devono essere mantenute. È inoltre consigliabile consolidare le istanze di Microsoft SQL Server per utilizzare gli stessi volumi per controllare il numero di copie Snapshot di backup eseguite.</block>
  <block id="8db6b23eddd61aa572ca93a39703d4a8" category="list-text">Creare LUN separati per memorizzare file di testo completi e file correlati allo streaming di file.</block>
  <block id="cb11fd215e0c541cb65535e582b9b273" category="list-text">Assegnare LUN separati per host per memorizzare i backup dei log di Microsoft SQL Server.</block>
  <block id="48b8325fd70d83c2d4e99987e23b07ef" category="list-text">I database di sistema che memorizzano la configurazione dei metadati del server di database e i dettagli del lavoro non vengono aggiornati frequentemente. Posizionare i database/tempdb di sistema in dischi o LUN separati. Non collocare i database di sistema nello stesso volume dei database dell'utente. I database degli utenti hanno criteri di backup diversi e la frequenza del backup del database degli utenti non è la stessa per i database di sistema.</block>
  <block id="1be01a12dc77b3099b16d258c12db3f9" category="list-text">Per l'installazione di Microsoft SQL Server Availability Group, posizionare i file di dati e di log per le repliche in una struttura di cartelle identica su tutti i nodi.</block>
  <block id="a586cfc38b79b6539a9723b4d2f5af66" category="paragraph">Oltre ai vantaggi in termini di performance derivanti dalla separazione del layout del database utente in diversi volumi, il database influisce in modo significativo anche sul tempo necessario per il backup e il ripristino. La presenza di volumi separati per i file di dati e log migliora significativamente il tempo di ripristino rispetto a un volume che ospita più file di dati utente. Allo stesso modo, i database degli utenti con un'applicazione con elevato utilizzo di i/o sono soggetti a un aumento dei tempi di backup. Una spiegazione più dettagliata sulle procedure di backup e ripristino è fornita più avanti in questo documento.</block>
  <block id="7f3611c256fabe67e4d74a6c70cfe9c5" category="admonition">A partire da SQL Server 2012 (11.x), database di sistema (Master, Model, MSDB e TempDB), I database utente di Database Engine possono essere installati con un file server SMB come opzione di storage. Questo vale per le installazioni standalone di cluster di failover di SQL Server e SQL Server. Questo consente di utilizzare FSX per ONTAP con tutte le sue funzionalità di performance e gestione dei dati, tra cui capacità dei volumi, scalabilità delle performance e funzionalità di protezione dei dati, di cui può usufruire SQL Server. Le condivisioni utilizzate dai server applicazioni devono essere configurate con il set di proprietà Continuously Available e il volume deve essere creato con lo stile di protezione NTFS. NetApp SnapCenter non può essere utilizzato con database collocati su condivisioni SMB da FSX per ONTAP.</block>
  <block id="9e45010900186b3cbbe04f954a6f3562" category="admonition">Per i database SQL Server che non utilizzano SnapCenter per eseguire i backup, Microsoft consiglia di posizionare i file di dati e di log su dischi separati. Per le applicazioni che aggiornano e richiedono contemporaneamente i dati, il file di log è intensivo in scrittura e il file di dati (a seconda dell'applicazione) è intensivo in lettura/scrittura. Per il recupero dei dati, il file di log non è necessario. Pertanto, le richieste di dati possono essere soddisfatte dal file di dati posto sul proprio disco.</block>
  <block id="41a264a984b034248073a80093913e60" category="admonition">Quando si crea un nuovo database, Microsoft consiglia di specificare unità separate per i dati e i registri. Per spostare i file dopo la creazione del database, il database deve essere portato offline. Per ulteriori consigli Microsoft, consulta l'articolo posizionare i file di dati e di registro su unità separate.</block>
  <block id="f4ea2029dd0e694cde33838315883930" category="example-title">Installazione e configurazione di SnapCenter</block>
  <block id="d39d360863f3fda3c5d615dc978e14ae" category="inline-link">Installare il server SnapCenter</block>
  <block id="1155d165aa176b6275b67036497cd8e6" category="inline-link">Installazione del plug-in SnapCenter per Microsoft SQL Server</block>
  <block id="067f687182a68fccec4a3840e67fc889" category="paragraph">Seguire la<block ref="4144149cc24a91f915be2d3b14f23c22" category="inline-link-rx"></block> e.<block ref="7e24f6ba39e2c63512c07f20cb1a71c0" category="inline-link-rx"></block> Per installare e configurare SnapCenter.</block>
  <block id="3ab2ad2898088a813669db2948590562" category="paragraph">Dopo aver installato SnapCenter, completare la seguente procedura per configurarlo.</block>
  <block id="dd0c654d5a8ede80984b9526335bddc9" category="list-text">Per impostare le credenziali, selezionare *Impostazioni* &gt; *nuovo*, quindi immettere le informazioni sulle credenziali.</block>
  <block id="ffe0bbfc2c08a0b0e98b92bee5d7a653" category="paragraph"><block ref="ffe0bbfc2c08a0b0e98b92bee5d7a653" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c790771cb60de4cb4a7212e8db25bf3c" category="list-text">Aggiungere il sistema di storage selezionando sistemi di storage &gt; nuovo e fornire l'FSX appropriato per le informazioni di storage ONTAP.</block>
  <block id="28e78cc4b0ec3be7790fc763323de0f6" category="paragraph"><block ref="28e78cc4b0ec3be7790fc763323de0f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0e0b904d3c7826b806c48118543142c" category="list-text">Aggiungere gli host selezionando *hosts* &gt; *Add*, quindi fornire le informazioni sull'host. SnapCenter installa automaticamente il plug-in di Windows e SQL Server. Questo processo potrebbe richiedere del tempo.</block>
  <block id="0f2c351522362209f5160c4794708c97" category="paragraph"><block ref="0f2c351522362209f5160c4794708c97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23dd2805cf2d7b26334d0678ab4e99b4" category="paragraph">Una volta installati tutti i plug-in, è necessario configurare la directory di log. Questa è la posizione in cui risiede il backup del log delle transazioni. È possibile configurare la directory del registro selezionando l'host, quindi configurando la directory del registro.</block>
  <block id="5c5fb88ff793d01c8b1a283f1ee88749" category="admonition">SnapCenter utilizza una directory del log host per memorizzare i dati di backup del log delle transazioni. Si tratta di un'operazione a livello di host e istanza. Ogni host SQL Server utilizzato da SnapCenter deve disporre di una directory del registro host configurata per eseguire i backup del registro. SnapCenter dispone di un repository di database, pertanto i metadati relativi alle operazioni di backup, ripristino o clonazione vengono memorizzati in un repository di database centrale.</block>
  <block id="0fc057cb39ba1a444dbc365c0161d31f" category="paragraph">La dimensione della directory del log host viene calcolata come segue:</block>
  <block id="e067558831f8381f0970051292e0a02a" category="paragraph">Dimensione della directory del log host = ((dimensione del database di sistema + (dimensione massima del LDF del DB × tasso di cambiamento giornaliero del log %)) × (conservazione delle copie Snapshot) ÷ (1 – spazio di overhead del LUN %)</block>
  <block id="1b5bc043867e6da78577571c1070e56a" category="paragraph">La formula di dimensionamento della directory del log host presuppone quanto segue:</block>
  <block id="fa7afec3a90f55ad9aea3b76f336302f" category="list-text">Backup del database di sistema che non include il database tempdb</block>
  <block id="f550013c290c4a21af7974f7440d758a" category="list-text">Uno spazio di overhead del LUN del 10%: Consente di creare una directory di log host su un volume dedicato o su un LUN. La quantità di dati nella directory del registro host dipende dalle dimensioni dei backup e dal numero di giorni in cui i backup vengono conservati.</block>
  <block id="83924e370463c681c401f53e2b4b3f2d" category="paragraph"><block ref="83924e370463c681c401f53e2b4b3f2d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd9dfb7fc6f502e70f86a8c1f2d66aa1" category="paragraph">Se il provisioning dei LUN è già stato eseguito, è possibile selezionare il punto di montaggio per rappresentare la directory del registro host.</block>
  <block id="db38f16eb9374dba4590f05c202fa4a5" category="paragraph"><block ref="db38f16eb9374dba4590f05c202fa4a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a708f2af7ec6f7c7ae489cca832c811" category="paragraph">Ora è possibile eseguire operazioni di backup, ripristino e clonazione per SQL Server.</block>
  <block id="7bfeafaf85908b711b618c069c66e99c" category="example-title">Database di backup con SnapCenter</block>
  <block id="fc197cb26aec21d091eb6791c0d7cbff" category="paragraph">Dopo aver inserito il database e i file di log nelle LUN ONTAP FSX, è possibile utilizzare SnapCenter per eseguire il backup dei database. I seguenti processi vengono utilizzati per creare un backup completo.</block>
  <block id="f52f437d3282493fd1855bba366c482a" category="list-text">In termini di SnapCenter, è possibile identificare RPO come frequenza di backup, ad esempio, con quale frequenza si desidera pianificare il backup in modo da ridurre la perdita di dati fino a pochi minuti. SnapCenter consente di pianificare i backup ogni cinque minuti. Tuttavia, potrebbero verificarsi alcuni casi in cui un backup potrebbe non essere completato entro cinque minuti durante i periodi di picco delle transazioni o quando il tasso di cambiamento dei dati è maggiore nel tempo specificato. Una Best practice consiste nel pianificare backup frequenti del log delle transazioni invece di backup completi.</block>
  <block id="7b99ea666dfc26516833c088400741e6" category="list-text">Esistono numerosi approcci per gestire l'RPO e l'RTO. Un'alternativa a questo approccio al backup consiste nell'avere policy di backup separate per dati e log con intervalli diversi. Ad esempio, da SnapCenter, pianifica backup dei log a intervalli di 15 minuti e backup dei dati a intervalli di 6 ore.</block>
  <block id="14b0febccc904523871b9498c72ab705" category="list-text">Utilizzare un gruppo di risorse per una configurazione di backup per l'ottimizzazione Snapshot e il numero di lavori da gestire.</block>
  <block id="45be64dc5372d4c03684e301633c794c" category="list-text">Selezionare *risorse*, quindi selezionare *Microsoft SQL Server *dal menu a discesa in alto a sinistra. Selezionare *Aggiorna risorse*.</block>
  <block id="94cc612f3fcbd977b78ea3b7a422c531" category="paragraph"><block ref="94cc612f3fcbd977b78ea3b7a422c531" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b8d60492f611ef339bf79fdbeb56dda" category="list-text">Selezionare il database di cui eseguire il backup, quindi selezionare *Avanti* e (*+*) per aggiungere il criterio, se non ne è stato creato uno. Seguire la *New SQL Server Backup Policy* per creare un nuovo criterio.</block>
  <block id="d99e4391045a563d9d1d2d78ddd2417a" category="paragraph"><block ref="d99e4391045a563d9d1d2d78ddd2417a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89f2e11b6c9317605c01622834d4853d" category="list-text">Se necessario, selezionare il server di verifica. Questo server è il server che SnapCenter esegue DBCC CHECKDB dopo la creazione di un backup completo. Fare clic su *Avanti* per la notifica, quindi selezionare *Riepilogo* per la revisione. Dopo la revisione, fare clic su *fine*.</block>
  <block id="fc2d6f88564b6e12fc40b19f28b7420d" category="paragraph"><block ref="fc2d6f88564b6e12fc40b19f28b7420d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="919295932fd1084fb39c4a1be23b37ed" category="list-text">Fare clic su *Backup Now* per verificare il backup. Nelle finestre a comparsa, selezionare *Backup*.</block>
  <block id="93598d1ad688123817fda7d22fa0ac82" category="paragraph"><block ref="93598d1ad688123817fda7d22fa0ac82" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9c738a74e68034a98f4a38a1b41ef2d4" category="list-text">Selezionare *Monitor* per verificare che il backup sia stato completato.</block>
  <block id="710fa04917c218b834664e1f0d37a48c" category="paragraph"><block ref="710fa04917c218b834664e1f0d37a48c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67459542a38abe56e00d4512bb475f05" category="list-text">Eseguire il backup del log delle transazioni da SnapCenter in modo che durante il processo di ripristino, SnapCenter possa leggere tutti i file di backup e ripristinarli automaticamente in sequenza.</block>
  <block id="54d8d459dfb725a307f3bb54495de3e3" category="list-text">Se per il backup vengono utilizzati prodotti di terze parti, selezionare Copia backup in SnapCenter per evitare problemi di sequenza di log e verificare la funzionalità di ripristino prima di passare alla produzione.</block>
  <block id="83b7215bcd7cc73d11f34b95b4026718" category="example-title">Ripristinare il database con SnapCenter</block>
  <block id="7172cc34c1510c3891870c7c009c94e1" category="paragraph">Uno dei principali vantaggi dell'utilizzo di FSX ONTAP con SQL Server su EC2 è la capacità di eseguire un ripristino rapido e granulare a ogni livello di database.</block>
  <block id="5afcacb3783eeead2b5317d1c455b3bc" category="paragraph">Completare i seguenti passaggi per ripristinare un singolo database a un punto specifico o fino al minuto con SnapCenter.</block>
  <block id="a028f8b44f91b1338df98ed3237d093a" category="list-text">Selezionare Resources (risorse), quindi selezionare il database che si desidera ripristinare.</block>
  <block id="b5f8165159678d41fab115d5a8f013d2" category="paragraph"><block ref="b5f8165159678d41fab115d5a8f013d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb395b310e199ca7ef6b36360302bc50" category="list-text">Selezionare il nome del backup da cui deve essere ripristinato il database, quindi selezionare Restore (Ripristina).</block>
  <block id="e99d25ac3998e8701f51a1990c8d8785" category="list-text">Seguire le finestre a comparsa *Restore* per ripristinare il database.</block>
  <block id="8bdb6d6fe719d2506b9b5f86bda88b43" category="list-text">Selezionare *Monitor* per verificare che il processo di ripristino abbia esito positivo.</block>
  <block id="e445e84ca78cd7f21cdd70356d211583" category="paragraph"><block ref="e445e84ca78cd7f21cdd70356d211583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459c0a4ca065bbbedc6304d4c6903cc5" category="example-title">Considerazioni per un'istanza con un elevato numero di database di piccole o grandi dimensioni</block>
  <block id="0be8a2d7e2996a1641824fa4250d2fd3" category="paragraph">SnapCenter può eseguire il backup di un gran numero di database importanti in un'istanza o in un gruppo di istanze all'interno di un gruppo di risorse. La dimensione di un database non è il fattore principale nel tempo di backup. La durata di un backup può variare a seconda del numero di LUN per volume, del carico su Microsoft SQL Server, del numero totale di database per istanza e, in particolare, della larghezza di banda e dell'utilizzo di i/O. Durante la configurazione del criterio per eseguire il backup dei database da un'istanza o da un gruppo di risorse, NetApp consiglia di limitare a 100 il numero massimo di database di cui è stato eseguito il backup per copia Snapshot per host. Assicurarsi che il numero totale di copie Snapshot non superi il limite di 1,023 copie.</block>
  <block id="33f3c567c61942e461392756abce64dc" category="paragraph">NetApp consiglia inoltre di limitare i processi di backup eseguiti in parallelo raggruppando il numero di database invece di creare più processi per ogni database o istanza. Per ottenere prestazioni ottimali della durata del backup, ridurre il numero di processi di backup a un numero che può eseguire il backup di circa 100 database alla volta.</block>
  <block id="ea2e6af969539b040884e9a2ec1fcb49" category="paragraph">Come accennato in precedenza, l'utilizzo di i/o è un fattore importante nel processo di backup. Il processo di backup deve attendere fino al completamento di tutte le operazioni di i/o su un database. I database con operazioni di i/o altamente intensive devono essere posticipati a un altro tempo di backup o devono essere isolati da altri processi di backup per evitare di influenzare altre risorse all'interno dello stesso gruppo di risorse di cui si desidera eseguire il backup.</block>
  <block id="e5ad8f936997e1328b1b169bf5c6cc8b" category="paragraph">Per un ambiente con sei host Microsoft SQL Server che ospitano 200 database per istanza, presupponendo quattro LUN per host e un LUN per volume creato, impostare la policy di backup completa con il numero massimo di database di cui è stato eseguito il backup per copia Snapshot su 100. Duecento database su ciascuna istanza sono disposti come 200 file di dati distribuiti in parti uguali su due LUN e 200 file di log sono distribuiti in parti uguali su due LUN, ovvero 100 file per LUN per volume.</block>
  <block id="7804dbf4b7a37ec699db9a31f21bbea7" category="paragraph">Pianificare tre processi di backup creando tre gruppi di risorse, ciascuno raggruppando due istanze che includono un totale di 400 database.</block>
  <block id="e2ba702320599667af2b18f0fad307e0" category="paragraph">L'esecuzione di tutti e tre i processi di backup in parallelo esegue il backup di 1,200 database contemporaneamente. A seconda del carico sul server e dell'utilizzo di i/o, l'ora di inizio e di fine di ogni istanza può variare. In questo caso, viene creato un totale di 24 copie Snapshot.</block>
  <block id="2d0d5c636161f9ca31c8ffbfa5ee5d7c" category="paragraph">Oltre al backup completo, NetApp consiglia di configurare un backup del log delle transazioni per i database critici. Assicurarsi che la proprietà del database sia impostata sul modello di ripristino completo.</block>
  <block id="aac1148375449745ddbbe1709a2375f5" category="list-text">Non includere il database tempdb in un backup perché i dati in esso contenuti sono temporanei. Posizionare tempdb su una LUN o una condivisione SMB che si trova in un volume di sistema storage in cui non verranno create copie Snapshot.</block>
  <block id="16c5de1581b82a1f8657a3a98ac8fd34" category="list-text">Un'istanza di Microsoft SQL Server con un'applicazione che richiede elevati livelli di i/o deve essere isolata in un processo di backup diverso per ridurre i tempi di backup complessivi per altre risorse.</block>
  <block id="a9a558ac49f24a2b078812205f07179c" category="list-text">Limitare il set di database di cui eseguire il backup simultaneo a circa 100 e sfalsare il set rimanente di backup del database per evitare un processo simultaneo.</block>
  <block id="68086c26b8c1644dfe6ea7d6fb859641" category="list-text">Utilizzare il nome dell'istanza di Microsoft SQL Server nel gruppo di risorse invece di più database, perché ogni volta che vengono creati nuovi database nell'istanza di Microsoft SQL Server, SnapCenter considera automaticamente un nuovo database per il backup.</block>
  <block id="5e5d80c17369e70061349fffb43b0aa8" category="list-text">Se si modifica la configurazione del database, ad esempio cambiando il modello di ripristino del database con il modello di ripristino completo, eseguire immediatamente un backup per consentire operazioni di ripristino aggiornate.</block>
  <block id="3dce7613a0d76dcf6fcb8e1daf396bbb" category="list-text">SnapCenter non è in grado di ripristinare i backup del log delle transazioni creati al di fuori di SnapCenter.</block>
  <block id="0007de7aba408b88984eb8eb18044303" category="list-text">Quando si clonano volumi FlexVol, assicurarsi di disporre di spazio sufficiente per i metadati del clone.</block>
  <block id="9416a94214ef699335d78087cd9f12c6" category="list-text">Quando si ripristinano i database, assicurarsi che sul volume sia disponibile spazio sufficiente.</block>
  <block id="86e3f69ee9647210c14858984e2649ef" category="list-text">Creare una policy separata per gestire ed eseguire il backup dei database di sistema almeno una volta alla settimana.</block>
  <block id="330337562cd623f5deb5908d4e8af736" category="example-title">Clonazione di database con SnapCenter</block>
  <block id="0a6bfc2082e52dc96430a6b7c0dfc7e7" category="paragraph">Per ripristinare un database in un'altra posizione in un ambiente di sviluppo o test o per creare una copia a scopo di analisi aziendale, la Best practice di NetApp consiste nel sfruttare la metodologia di cloning per creare una copia del database sulla stessa istanza o su un'istanza alternativa.</block>
  <block id="0f462cc9e20017ed0597a6a199f57035" category="paragraph">La clonazione di database da 500 GB su un disco iSCSI ospitato in un ambiente FSX per ONTAP richiede in genere meno di cinque minuti. Una volta completata la clonazione, l'utente può eseguire tutte le operazioni di lettura/scrittura necessarie sul database clonato. La maggior parte del tempo viene utilizzata per la scansione dei dischi (diskpart). La procedura di cloning di NetApp richiede in genere meno di 2 minuti, indipendentemente dalle dimensioni dei database.</block>
  <block id="886ef20e3049a00bc0d9a1c734bb90da" category="paragraph">La clonazione di un database può essere eseguita con il metodo dual: È possibile creare un clone dall'ultimo backup oppure utilizzare la gestione del ciclo di vita dei cloni attraverso la quale è possibile rendere disponibile l'ultima copia sull'istanza secondaria.</block>
  <block id="870999fc556eadefd7740857b96209c3" category="paragraph">SnapCenter consente di montare la copia clone sul disco richiesto per mantenere il formato della struttura di cartelle sull'istanza secondaria e continuare a pianificare i processi di backup.</block>
  <block id="b2face8e1d4561b0ed5b594bfc4c0063" category="example-title">Clonare i database con il nuovo nome del database nella stessa istanza</block>
  <block id="4a3135e25926365f40a59fd88af69a44" category="paragraph">Per clonare i database con il nuovo nome del database nella stessa istanza di SQL Server in esecuzione su EC2, è possibile utilizzare i seguenti passaggi:</block>
  <block id="4655b3c9fecfc4d22a59068929be2bec" category="list-text">Selezionare Resources (risorse), quindi il database da clonare.</block>
  <block id="944b75c61851b0ebc427a8aedc83d6f3" category="list-text">Selezionare il nome del backup che si desidera clonare e selezionare Clone (Clona).</block>
  <block id="83d2194c2b06657769054af057f16b0a" category="list-text">Seguire le istruzioni del clone dalle finestre di backup per completare il processo.</block>
  <block id="8fb624c33e03c9d016909a11c669125d" category="list-text">Selezionare Monitor per assicurarsi che la clonazione sia stata completata.</block>
  <block id="0b075fd84c4c4a47346b99d43f9260be" category="example-title">Clonare i database nella nuova istanza di SQL Server in esecuzione su EC2</block>
  <block id="9451e65c3b1fc3fc6cf89a3fc9cf3cfd" category="paragraph">La seguente procedura viene utilizzata per clonare i database nella nuova istanza di SQL Server in esecuzione su EC2:</block>
  <block id="479cb4cd4ee76801e360aa03ddc20a3a" category="list-text">Creare un nuovo SQL Server su EC2 nello stesso VPC.</block>
  <block id="163733cab5060ba4621bb642ba3870a0" category="list-text">Abilitare il protocollo iSCSI e MPIO, quindi configurare la connessione iSCSI a FSX per ONTAP seguendo i passaggi 3 e 4 della sezione "creazione di volumi e LUN per SQL Server".</block>
  <block id="918269b8806c56ca4a0910482994e142" category="list-text">Aggiungere un nuovo SQL Server su EC2 in SnapCenter seguendo il passaggio 3 della sezione "Installazione e configurazione di SnapCenter".</block>
  <block id="e7130318e065eddd45ec86565b727731" category="list-text">Selezionare Resource &gt; View Instance (risorsa &gt; Visualizza istanza), quindi Refresh Resource (Aggiorna risorsa).</block>
  <block id="8be42b1e845c00bcb04c11269072f895" category="list-text">Selezionare risorse, quindi il database che si desidera clonare.</block>
  <block id="459801927d3c0bd5ddec9c1513f213ec" category="list-text">Selezionare il nome del backup che si desidera clonare, quindi selezionare Clone (Clona).</block>
  <block id="030603235fe06c85ee75276379fe5baa" category="paragraph"><block ref="030603235fe06c85ee75276379fe5baa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45d50db35e68c1259b414779e24fdbf5" category="list-text">Seguire le istruzioni Clone from Backup fornendo la nuova istanza di SQL Server su EC2 e il nome dell'istanza per completare il processo di clonazione.</block>
  <block id="78c549c0e0fcfc0dd6bb0c2e3a09a79f" category="paragraph"><block ref="78c549c0e0fcfc0dd6bb0c2e3a09a79f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="785e5e204bcb101e73976a8c3ad22887" category="paragraph">Per ulteriori informazioni su questo processo, guarda il seguente video:</block>
  <block id="20606e28a0d567be1dabd5cf50a2dc3b" category="section-title">Appendici</block>
  <block id="16dfbb688028526582ec31ab802b9589" category="example-title">Appendice A: File YAML da utilizzare nel modello di formazione cloud</block>
  <block id="4c76ae47de51751cc57a4033d14f2f2a" category="paragraph">Il seguente file .yaml può essere utilizzato con Cloud Formation Template in AWS Console.</block>
  <block id="76f249edcff2b74fcc17020455372f1b" category="inline-link"><block ref="76f249edcff2b74fcc17020455372f1b" category="inline-link-rx"></block></block>
  <block id="57ea11aec1064892e5db378204f829c4" category="list-text"><block ref="57ea11aec1064892e5db378204f829c4" category="inline-link-rx"></block></block>
  <block id="f6d8279768d195862ae69a3df8dd51ab" category="inline-link">Questo link GitHub</block>
  <block id="4d39c6875a330594fc8521c48cadd7f6" category="paragraph">Per automatizzare la creazione di LUN ISCSI e l'installazione di NetApp SnapCenter con PowerShell, clonare il repo da<block ref="445e758235a70998ddfcd1531f3ae35b" category="inline-link-rx"></block>.</block>
  <block id="00867e5f5ae22280c11a2626b65e657b" category="example-title">Appendice B: Script PowerShell per il provisioning di volumi e LUN</block>
  <block id="0826ee2b94a579e02e80bfcdf26c5648" category="paragraph">Il seguente script viene utilizzato per eseguire il provisioning di volumi e LUN e per impostare iSCSI in base alle istruzioni fornite in precedenza. Esistono due script PowerShell:</block>
  <block id="81e24f41fbaff249c9819985065173e3" category="list-text"><block ref="2a9a99327bbfb47d37ee76307e959506" prefix="" category="inline-code"></block></block>
  <block id="2ca8201f2a50e4aec0e5ba21f6afed4d" category="list-text"><block ref="d78c8f4fe63dbe3ffd666bbbaf054cd7" prefix="" category="inline-code"></block></block>
  <block id="6385631c0b330c166b540183cec5af78" category="paragraph">Eseguire il file<block ref="d2dd03515102971189549a37cb42eb14" prefix=" " category="inline-code"></block> il primo e il secondo script vengono eseguite automaticamente dopo il riavvio del server. Questi script PowerShell possono essere rimossi dopo essere stati eseguiti a causa dell'accesso alle credenziali alla SVM.</block>
  <block id="d82c21a48349085e4fd93fb6712e3789" category="inline-link"><block ref="d82c21a48349085e4fd93fb6712e3789" category="inline-link-rx"></block></block>
  <block id="c745303ee8000be162517c239783af70" category="paragraph"><block ref="c745303ee8000be162517c239783af70" category="inline-link-rx"></block></block>
  <block id="c6e485d51bc9da63bcac29189dac0f3c" category="list-text">Introduzione a FSX per NetApp ONTAP</block>
  <block id="90572737558e59a2ecdd4618af07d6f3" category="inline-link"><block ref="90572737558e59a2ecdd4618af07d6f3" category="inline-link-rx"></block></block>
  <block id="7545caf3d97477d3c569d56c512074fa" category="paragraph"><block ref="7545caf3d97477d3c569d56c512074fa" category="inline-link-rx"></block></block>
  <block id="ad65cae8cf2bbd15ac77769974a440ce" category="list-text">Panoramica dell'interfaccia SnapCenter</block>
  <block id="59cbc11e5ccd87939e1b70af73ec1f01" category="inline-link"><block ref="c0a7623803fcfb4ac66342d4ae76ffff" category="inline-link-rx"></block></block>
  <block id="7ab2e91ecb30982855aa0dde8b78a361" category="paragraph"><block ref="89ba280df4e8c5cfd9bcd0f8c80d8ba5" category="inline-link-rx"></block></block>
  <block id="1bdf7559e69b81c007496a063e71bca0" category="list-text">Visualizzare le opzioni del riquadro di navigazione di SnapCenter</block>
  <block id="6d5097a2c320359a8d212d07ea067dac" category="inline-link"><block ref="6d5097a2c320359a8d212d07ea067dac" category="inline-link-rx"></block></block>
  <block id="e0ae39eeb7c7d78d56a1292229d1277a" category="paragraph"><block ref="e0ae39eeb7c7d78d56a1292229d1277a" category="inline-link-rx"></block></block>
  <block id="d29a9430434c2654cce06036a4a478b2" category="list-text">Installare il plug-in di SnapCenter 4.0 per SQL Server</block>
  <block id="520419781af4d13a8b33c054a304985b" category="inline-link"><block ref="520419781af4d13a8b33c054a304985b" category="inline-link-rx"></block></block>
  <block id="c2580a05e81a19c4b782e51932415e30" category="paragraph"><block ref="c2580a05e81a19c4b782e51932415e30" category="inline-link-rx"></block></block>
  <block id="f781a682aea107fb2cdda3a0c1fd3ac5" category="list-text">Come eseguire il backup e il ripristino dei database utilizzando il plug-in di SnapCenter</block>
  <block id="285a27614fdeee7f22969646d33edc95" category="inline-link"><block ref="285a27614fdeee7f22969646d33edc95" category="inline-link-rx"></block></block>
  <block id="e1685ff793f13bbd2956f2156b0d5a67" category="paragraph"><block ref="e1685ff793f13bbd2956f2156b0d5a67" category="inline-link-rx"></block></block>
  <block id="c8e300ff66d94fe7668ff8d5d5e7f1c3" category="list-text">Come clonare un database utilizzando SnapCenter con il plug-in di SQL Server</block>
  <block id="e482c7b116916a3d87aba2ab1365190b" category="inline-link"><block ref="e482c7b116916a3d87aba2ab1365190b" category="inline-link-rx"></block></block>
  <block id="b916fd292760d6ae01e337bf2a132edb" category="paragraph"><block ref="b916fd292760d6ae01e337bf2a132edb" category="inline-link-rx"></block></block>
  <block id="ac9bef0f960e3a46befd2d06b223b61d" category="summary">In questa sezione viene illustrata una tipica architettura di cloud ibrido per le operazioni di sviluppo/test e DR.</block>
  <block id="fece52c505c48f2979e3fa0c8b6bd8bc" category="paragraph"><block ref="fece52c505c48f2979e3fa0c8b6bd8bc" category="inline-link-macro-rx"></block></block>
  <block id="4085a97aa705c0122bbcec0c84dd97d3" category="paragraph">Il seguente diagramma dell'architettura illustra un'implementazione tipica del funzionamento del database aziendale in un cloud ibrido per le operazioni di sviluppo/test e disaster recovery.</block>
  <block id="acb339f710a626679c374df5b90c5416" category="paragraph"><block ref="acb339f710a626679c374df5b90c5416" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cdc302c6d83b60c8ec7ad0b550e55a8" category="paragraph">Nelle normali operazioni di business, i volumi di database sincronizzati nel cloud possono essere clonati e montati su istanze di database di sviluppo/test per lo sviluppo o il test delle applicazioni. In caso di guasto, i volumi di database sincronizzati nel cloud possono essere attivati per il disaster recovery.</block>
  <block id="fbfd3304757c668454a7bdd10f9de200" category="inline-link-macro">Successivo: Requisiti delle soluzioni.</block>
  <block id="ae3b1bce66c4c75d8abf9828ec9f2608" category="paragraph"><block ref="ae3b1bce66c4c75d8abf9828ec9f2608" category="inline-link-macro-rx"></block></block>
  <block id="653a98af1c9a004c51b4e7358f06db9a" category="summary">La soluzione offre una panoramica e dettagli sull'implementazione del database PostgreSQL e sull'installazione ha/DR, failover e risync basati sulla tecnologia SnapMirror di NetApp integrata nell'offerta di storage FSX ONTAP e nel toolkit di automazione Ansible di NetApp in AWS.</block>
  <block id="e5f44d648a9d8c4db4e2b580d3370fbf" category="doc">TR-4956: Implementazione automatizzata di alta disponibilità PostgreSQL e disaster recovery in AWS FSX/EC2</block>
  <block id="03784a7c5600d29113972955e602a944" category="inline-link-macro">MOTORI DB</block>
  <block id="1d8f1bdc206db1d9edd9fa46f02aa08c" category="paragraph">PostgreSQL è un database open-source ampiamente utilizzato, classificato al quarto posto tra i primi dieci motori di database più diffusi <block ref="6e2d0e5987102894082cbdb135303e4d" category="inline-link-macro-rx"></block>. Da un lato, PostgreSQL deriva la sua popolarità dal suo modello open-source senza licenza, pur possedendo funzionalità sofisticate. D'altro canto, poiché è open source, mancano indicazioni dettagliate sull'implementazione di database di livello produzione nell'area dell'alta disponibilità e del disaster recovery (ha/DR), in particolare nel cloud pubblico. In generale, può essere difficile configurare un tipico sistema ha/DR PostgreSQL con standby a caldo e a caldo, replica in streaming e così via. Il test dell'ambiente ha/DR promuovendo il sito di standby e quindi il ritorno al primario può interrompere la produzione. Esistono problemi di performance ben documentati sul primario quando i carichi di lavoro di lettura vengono implementati nello streaming hot standby.</block>
  <block id="3ba3cda3d91af072810327bfd691205c" category="paragraph">In questa documentazione, dimostreremo come eliminare una soluzione di streaming ha/DR PostgreSQL a livello di applicazione e creare una soluzione ha/DR PostgreSQL basata sullo storage AWS FSX ONTAP e sulle istanze di calcolo EC2 utilizzando la replica a livello di storage. La soluzione crea un sistema più semplice e paragonabile e offre risultati equivalenti rispetto alla replica in streaming a livello di applicazione PostgreSQL tradizionale per ha/DR.</block>
  <block id="e2543d0568626be8ab6adad9d9a78652" category="paragraph">Questa soluzione si basa su una tecnologia di replica a livello di storage NetApp SnapMirror collaudata e matura, disponibile nello storage cloud FSX ONTAP nativo di AWS per PostgreSQL ha/DR. È semplice da implementare con un toolkit di automazione fornito dal team delle soluzioni NetApp. Offre funzionalità simili eliminando la complessità e il trascinamento delle performance sul sito primario con la soluzione ha/DR basata su streaming a livello applicativo. La soluzione può essere facilmente implementata e testata senza influire sul sito primario attivo.</block>
  <block id="f67bd3c0833b1d6bf90bb26a55f0a9ce" category="list-text">Implementazione ha/DR di livello produzione per PostgreSQL nel cloud AWS pubblico</block>
  <block id="420a5f3809172bb0dc9d501758fe94d2" category="list-text">Test e convalida di un carico di lavoro PostgreSQL nel cloud AWS pubblico</block>
  <block id="c9d6a5076f52c5abce5f2003446ab211" category="list-text">Test e convalida di una strategia ha/DR PostgreSQL basata sulla tecnologia di replica SnapMirror di NetApp</block>
  <block id="4a7bde15fa2753ce507cef621fd789b2" category="list-text">Il DBA interessato all'implementazione di PostgreSQL con ha/DR nel cloud AWS pubblico.</block>
  <block id="c5e04df584e0992a5dbdae10d89ded97" category="list-text">L'architetto della soluzione di database che è interessato a testare i workload PostgreSQL nel cloud pubblico AWS.</block>
  <block id="ba083ee91407315383bac538162833ff" category="list-text">L'amministratore dello storage interessato all'implementazione e alla gestione delle istanze PostgreSQL distribuite nello storage AWS FSX.</block>
  <block id="73ad058c671f3e1e105d92585f5ece7a" category="list-text">Il proprietario dell'applicazione interessato a creare un ambiente PostgreSQL in AWS FSX/EC2.</block>
  <block id="bfa420253f0a67626a51ce1fa045944c" category="image-alt">Questa immagine fornisce un quadro dettagliato dell'organizzazione della soluzione di cloud ibrido PostgreSQL, inclusi il lato on-premise e il sito AWS.</block>
  <block id="011fedf4050817b8826f95a53d9555b2" category="cell">Versione corrente</block>
  <block id="0b70cdec9293f5625e5aaae9cdd38526" category="cell">Due coppie FSX ha nello stesso VPC e nella stessa zona di disponibilità dei cluster ha primari e di standby</block>
  <block id="e3d6d4b94f9415561957f8c22f5fea2e" category="cell">Due EC2 T2 xlarge come istanze di calcolo primarie e di standby</block>
  <block id="3008feb4272787858d4d27f7e8acb08b" category="cell">Controller Ansible</block>
  <block id="26b9568eac10de69d574b84626735921" category="cell">CentOS VM/4vCPU/8G on-premise</block>
  <block id="7f151fffe66dad0021b1918085977654" category="cell">Una macchina virtuale per ospitare il controller di automazione Ansible on-premise o nel cloud</block>
  <block id="8003cafa06ec27e11cb235ec9544ef74" category="cell">CentOS Linux</block>
  <block id="04cd32c57cf3229ae9374fc80cd50d96" category="cell">CentOS Linux release 8.2.2004 (Core)</block>
  <block id="63b6df5ba9d257bb0f6fbda5541d9171" category="cell">Hosting del controller Ansible implementato in laboratori on-premise</block>
  <block id="399bd1ee587245ecac6f39beaa99886f" category="cell">PostgreSQL</block>
  <block id="a3c20b719830dc5fda947c7b6f3e42be" category="cell">Versione 14.5</block>
  <block id="f8c3d3a84c62eb07a1009aacdc46a50f" category="cell">L'automazione estrae l'ultima versione disponibile di PostgreSQL dal postgresql.ora yum repo</block>
  <block id="202351f581b52c61061d29151c81d061" category="cell">Versione 2.10.3</block>
  <block id="d222003898249e4a560d569acb0b5563" category="cell">Prerequisiti per le raccolte e le librerie richieste installate con il manuale dei requisiti</block>
  <block id="b062352f67359ac6729601c60a9a57a2" category="list-text">*Backup, ripristino e ripristino del database PostgreSQL.* Un database PostgreSQL supporta una serie di metodi di backup, ad esempio un backup logico con pg_dump, un backup fisico online con pg_basebackup o un comando di backup del sistema operativo di livello inferiore e snapshot coerenti a livello di storage. Questa soluzione utilizza le snapshot dei gruppi di coerenza NetApp per i dati del database PostgreSQL e il backup, ripristino e ripristino dei volumi WAL nel sito di standby. Le snapshot dei volumi del gruppo di coerenza NetApp sequenziali i/o man mano che vengono scritte nello storage e proteggono l'integrità dei file di dati del database.</block>
  <block id="a28c157802547f294e145f164007d752" category="list-text">*Istanze di calcolo EC2.* in questi test e convalide, abbiamo utilizzato il tipo di istanza AWS EC2 t2.xlarge per l'istanza di calcolo del database PostgreSQL. NetApp consiglia di utilizzare un'istanza EC2 di tipo M5 come istanza di calcolo per PostgreSQL in fase di implementazione, poiché è ottimizzata per i carichi di lavoro del database. L'istanza di calcolo in standby deve sempre essere implementata nella stessa zona del file system passivo (standby) implementato per il cluster FSX ha.</block>
  <block id="d7aed04148f8b6ba1b91a7ed84d3fd10" category="list-text">*Implementazione di cluster ha storage FSX a singola o multi-zona.* in questi test e convalide, abbiamo implementato un cluster ha FSX in una singola zona di disponibilità AWS. Per l'implementazione in produzione, NetApp consiglia di implementare una coppia FSX ha in due diverse zone di disponibilità. Una coppia ha in standby per il disaster recovery per la business continuity può essere impostata in una regione diversa se è richiesta una distanza specifica tra il primario e lo standby. Un cluster FSX ha viene fornito in maniera ininterrotta in una coppia ha con mirroring sincronizzato in una coppia di file system Active-passive per fornire ridondanza a livello di storage.</block>
  <block id="c6f1f46bc7e80b73e6d77a7f862e0625" category="list-text">*Posizionamento dei dati e dei log di PostgreSQL.* le implementazioni tipiche di PostgreSQL condividono la stessa directory principale o volumi per i file di dati e di log. Nei test e nelle convalide, abbiamo separato i dati PostgreSQL e i log in due volumi separati per le performance. Nella directory dei dati viene utilizzato un soft link per indicare la directory di log o il volume che ospita i log WAL di PostgreSQL e i log WAL archiviati.</block>
  <block id="6e6dddb70c24cf218d0163faa3fb6a8f" category="list-text">*Timer di ritardo all'avvio del servizio PostgreSQL.* questa soluzione utilizza volumi montati su NFS per memorizzare il file di database PostgreSQL e i file di log WAL. Durante il riavvio di un host di database, il servizio PostgreSQL potrebbe tentare di avviarsi mentre il volume non è montato. Ciò comporta un errore di avvio del servizio di database. Per un corretto avvio del database PostgreSQL, è necessario un timer di 10 - 15 secondi.</block>
  <block id="ee79ca09fee704e63d972baa3c1319a2" category="list-text">*RPO/RTO per la business continuity.* la replica dei dati FSX dal primario allo standby per il DR si basa su ASYNC, il che significa che l'RPO dipende dalla frequenza dei backup Snapshot e della replica SnapMirror. Una maggiore frequenza di copia Snapshot e replica SnapMirror riduce l'RPO. Di conseguenza, esiste un equilibrio tra la potenziale perdita di dati in caso di disastro e il costo incrementale dello storage. Abbiamo stabilito che la copia Snapshot e la replica SnapMirror possono essere implementate a intervalli di soli 5 minuti per RPO, mentre PostgreSQL può in genere essere ripristinato nel sito di standby del DR in meno di un minuto per RTO.</block>
  <block id="cbeb123cc0c2c950a65a0c39f8412dc4" category="list-text">*Backup del database.* dopo l'implementazione o la migrazione di un database PostgreSQL nello storage AWS FSX da un data center on-premises, i dati vengono sottoposti a mirroring con sincronizzazione automatica nella coppia FSX ha per la protezione. I dati vengono ulteriormente protetti con un sito di standby replicato in caso di disastro. Per la conservazione a lungo termine del backup o la protezione dei dati, NetApp consiglia di utilizzare l'utilità PostgreSQL pg_basebackup integrata per eseguire un backup completo del database che può essere trasferito sullo storage BLOB S3.</block>
  <block id="d2598d7d09e212cad1231cd233c5f7dc" category="paragraph">L'implementazione di questa soluzione può essere completata automaticamente utilizzando il toolkit di automazione basato su Ansible di NetApp seguendo le istruzioni dettagliate riportate di seguito.</block>
  <block id="7cfbd2a753781ece3080a48b0a56dad2" category="inline-link-macro">na_postgresql_aws_deploy_hadr</block>
  <block id="fce91619a13ef0fd71e3ffe1da6b5724" category="list-text">Leggere le istruzioni del toolkit di automazione readme.MD <block ref="139722adb31b9bbcb8f923b221d78595" category="inline-link-macro-rx"></block>.</block>
  <block id="9a1c6815d4b1e7dc53acf5a926ab662e" category="list-text">Guarda il video seguente.</block>
  <block id="c73ece4b7be6bb88143afe096ded59aa" category="list-text">Configurare i file dei parametri richiesti <block ref="85cf4e6d42a71e693fd780c8b29accdd" prefix="(" category="inline-code"></block>,<block ref="0c83664bfb17d8d2c0bbc3551297e488" prefix=" " category="inline-code"></block>,<block ref="cb8e25d5e6251a20afadf4c5f4b626bb" prefix=" " category="inline-code"></block>) immettendo i parametri specifici dell'utente nel modello nelle relative sezioni. Quindi, utilizzare il pulsante Copy per copiare i file sull'host del controller Ansible.</block>
  <block id="00aaa5ff8fbd0841ab311f7d9b1e4e78" category="section-title">Prerequisiti per l'implementazione automatica</block>
  <block id="eb03aa8f939650517c1c56a6d0b9ad2f" category="list-text">Dalla console AWS EC2, è necessario implementare due istanze EC2 Linux, una come server primario PostgreSQL DB sul primario e una sul sito di DR di standby. Per la ridondanza di calcolo nei siti DR primari e di standby, implementare due istanze EC2 Linux aggiuntive come server PostgreSQL DB in standby. Per ulteriori informazioni sulla configurazione dell'ambiente, vedere il diagramma dell'architettura nella sezione precedente. Esaminare anche il <block ref="32934851360be4fd00506586c2cbc221" category="inline-link-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="933d3e5f984811b21da2922f3deb56c4" category="list-text">Dalla console AWS EC2, implementare due cluster ha di storage FSX ONTAP per ospitare i volumi di database PostgreSQL. Se non si ha familiarità con l'implementazione dello storage FSX, consultare la documentazione <block ref="d73b8b529985c5c89147bd81cb29dbfb" category="inline-link-macro-rx"></block> per istruzioni dettagliate.</block>
  <block id="7053a216e34d0f83be18a65f22ce62ce" category="list-text">Creare una macchina virtuale CentOS Linux per ospitare il controller Ansible. Il controller Ansible può essere collocato on-premise o nel cloud AWS. Se si trova on-premise, è necessario disporre della connettività SSH per VPC, istanze EC2 Linux e cluster di storage FSX.</block>
  <block id="d1186b859105640e1dc347ae7b714afa" category="list-text">Impostare il controller Ansible come descritto nella sezione "impostazione del nodo di controllo Ansible per le implementazioni CLI su RHEL/CentOS" dalla risorsa <block ref="a9149ecc8f33f363a4eae3089d5c6cb7" category="inline-link-macro-rx"></block>.</block>
  <block id="007fa0067fff9abdcd3e5b9ce9f20c06" category="list-text">Clonare una copia del toolkit di automazione dal sito pubblico NetApp GitHub.</block>
  <block id="0ca21e6da2c89e765706d9a77f412898" category="list-text">Dalla directory root del toolkit, eseguire i playbook prerequisiti per installare le raccolte e le librerie richieste per il controller Ansible.</block>
  <block id="df40cb16c4a24c991c143fbddeedd0bc" category="list-text">Recuperare i parametri dell'istanza EC2 FSX richiesti per il file di variabili host DB<block ref="ea858a411f1af6150f14b84176148712" prefix=" " category="inline-code"></block> e il file delle variabili globali<block ref="cb8e25d5e6251a20afadf4c5f4b626bb" prefix=" " category="inline-code"></block> configurazione.</block>
  <block id="57c7844b0a299340cf9b625ce4a0745a" category="section-title">Configurare il file hosts</block>
  <block id="ed578fbfbec5634c4fa508cde5bc4e85" category="paragraph">Inserire i nomi host delle istanze primaria di FSX ONTAP per la gestione del cluster e EC2 nel file hosts.</block>
  <block id="6ef214427ca7b42201d0b0508f56df98" category="section-title">Configurare il file host_name.yml nella cartella host_vars</block>
  <block id="6967d323b85203ba993572c1cd814dc1" category="paragraph">Inserire i parametri appropriati per il sistema nei campi sottolineati in blu, quindi copiare e incollare le voci in<block ref="caa6779553864dba00727ae27752b182" prefix=" " category="inline-code"></block> Nel controller Ansible<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> cartella.</block>
  <block id="77ac1da2cd356e327eb4bfc4c5a21bcc" category="section-title">Configurare il file globale fsx_vars.yml nella cartella vars</block>
  <block id="7876ddba2c3af67cbee2b37f64072428" category="paragraph">Inserire i parametri appropriati per il sistema nei campi sottolineati in blu, quindi copiare e incollare le voci in<block ref="cb8e25d5e6251a20afadf4c5f4b626bb" prefix=" " category="inline-code"></block> File sull'host del controller Ansible.</block>
  <block id="d56625a35762821798a2f3dd55ead05d" category="section-title">Implementazione PostgreSQL e configurazione ha/DR</block>
  <block id="943a124028d8f011631df765453640dc" category="paragraph">Le seguenti attività implementano il servizio del server DB PostgreSQL e inizializzano il database nel sito primario sull'host del server DB EC2 primario. Un host del server DB EC2 primario in standby viene quindi configurato nel sito di standby. Infine, la replica del volume DB viene configurata dal cluster FSX del sito primario al cluster FSX del sito di standby per il disaster recovery.</block>
  <block id="08f6dd070ef1adfcbe3d7f3c70b08905" category="list-text">Creare volumi DB sul cluster FSX primario e impostare postgresql sull'host dell'istanza EC2 primario.</block>
  <block id="bf22091495c9a041dcbdba3a97795095" category="list-text">Impostare l'host di istanza EC2 DR di standby.</block>
  <block id="f2dd18dfc82378171d01bdd3f956bc6f" category="list-text">Impostare il peering del cluster FSX ONTAP e la replica del volume del database.</block>
  <block id="d681aef28cf1f863d0683a6896f12995" category="list-text">Consolida i passaggi precedenti in un'implementazione PostgreSQL e un'installazione ha/DR in un'unica fase.</block>
  <block id="fe217a2e30a79cebc71db6d5cb676a71" category="list-text">Per configurare un host PostgreSQL DB di standby sul sito primario o in standby, commentare tutti gli altri server nella sezione del file hosts [dr_postgresql] ed eseguire il playbook postgresql_standby_setup.yml con il rispettivo host di destinazione (come ad esempio psql_01ps o istanza di calcolo EC2 di standby sul sito primario). Assicurarsi che un file di parametri host, ad esempio<block ref="7c0f59fa275836ef9c4f28bec839acca" prefix=" " category="inline-code"></block> è configurato in<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> directory.</block>
  <block id="d3ecdce9695eacdb90ec80fa276865d4" category="section-title">Backup e replica dello snapshot del database PostgreSQL su un sito in standby</block>
  <block id="3b320790a7f864b473e3baa86de785fe" category="paragraph">Il backup e la replica dello snapshot del database PostgreSQL nel sito di standby possono essere controllati ed eseguiti sul controller Ansible con un intervallo definito dall'utente. Abbiamo convalidato che l'intervallo può essere di soli 5 minuti. Pertanto, in caso di guasto nel sito primario, si verificano 5 minuti di potenziale perdita di dati se il guasto si verifica immediatamente prima del successivo backup di snapshot pianificato.</block>
  <block id="421057a9fa982de2a1c1f79f5f03d750" category="section-title">Failover al sito di standby per DR</block>
  <block id="6ddcc779c247e4adb5b5a56a34edd75d" category="paragraph">Per testare il sistema ha/DR PostgreSQL come esercizio di DR, eseguire il failover e il ripristino del database PostgreSQL sull'istanza primaria di standby EC2 DB sul sito di standby eseguendo il seguente manuale. In uno scenario di disaster recovery, eseguire lo stesso per un failover effettivo al sito di DR.</block>
  <block id="724a617bc1dcc9b26fedb732f63a569d" category="section-title">Risincronizzare volumi DB replicati dopo il test di failover</block>
  <block id="6a08e960bd12a4fcddfd08082fbece4b" category="paragraph">Eseguire la risincronizzazione dopo il test di failover per ristabilire la replica SnapMirror del volume di database.</block>
  <block id="145966bc8e38b26c384abaf4e450f6a7" category="section-title">Failover dal server DB EC2 primario al server DB EC2 in standby a causa di un guasto dell'istanza di calcolo EC2</block>
  <block id="32d16eeba786f125b3c1e4750ad34e08" category="paragraph">NetApp consiglia di eseguire il failover manuale o di utilizzare cluster-ware del sistema operativo ben consolidati che potrebbero richiedere una licenza.</block>
  <block id="0a6f7f4424be62bd8f9208328496eeaf" category="inline-link-macro"><block ref="0a6f7f4424be62bd8f9208328496eeaf" category="inline-link-rx"></block></block>
  <block id="b898d8d538a4529dfdb2b8bf025323c2" category="paragraph"><block ref="b898d8d538a4529dfdb2b8bf025323c2" category="inline-link-macro-rx"></block></block>
  <block id="a73e5c65844b18c49122a8a79ef3fa65" category="doc">Procedure di implementazione Oracle dettagliate su Azure VM e Azure NetApp Files</block>
  <block id="f8de11946f5850d6f1597a7cf5fc2234" category="inline-link-macro">Precedente: Fattori da considerare.</block>
  <block id="e9704920b930163220a6e7564d7d680e" category="paragraph"><block ref="e9704920b930163220a6e7564d7d680e" category="inline-link-macro-rx"></block></block>
  <block id="cf2fb9f52eae11aaa1b6818cc22ade30" category="section-title">Implementare una macchina virtuale Azure con ANF per Oracle tramite la console del portale Azure</block>
  <block id="5e89dc82cb54763baa7cece42e7c3189" category="paragraph">Se non hai ancora utilizzato Azure, devi prima configurare un ambiente di account Azure. Ciò include la registrazione dell'organizzazione per l'utilizzo di Azure Active Directory. La sezione seguente è un riepilogo di questi passaggi. Per ulteriori informazioni, consulta la documentazione specifica di Linked Azure.</block>
  <block id="c743c9c56cd6cc2acf874405ef178af3" category="section-title">Creare e utilizzare risorse Azure</block>
  <block id="cc59653114a0ca329e90c87f8de8f2da" category="paragraph">Una volta configurato l'ambiente Azure e creato un account associato a un abbonamento, è possibile accedere al portale Azure con l'account per creare le risorse necessarie per eseguire Oracle.</block>
  <block id="4848dfd418cc69fdc8a92da472ac41b8" category="section-title">1. Creare una rete virtuale o VNET</block>
  <block id="dd587303db328c6fc30f15fbf133eade" category="paragraph">Azure Virtual Network (VNET) è l'elemento fondamentale della tua rete privata in Azure. VNET consente a molti tipi di risorse Azure, come le macchine virtuali Azure (VM), di comunicare in modo sicuro tra loro, Internet e reti on-premise. Prima di eseguire il provisioning di una macchina virtuale Azure, è necessario configurare una VNET (in cui viene implementata una macchina virtuale).</block>
  <block id="2b9029fce84bbf7056c94e4b86015679" category="inline-link-macro">Creare una rete virtuale utilizzando il portale Azure</block>
  <block id="698a842fc17e080abbf6b6796628879b" category="paragraph">Vedere <block ref="f497c9708f9505977884a23053323735" category="inline-link-macro-rx"></block> Per creare un VNET.</block>
  <block id="66d98f4e89afee6dc557332b0e9ebe43" category="section-title">2. Creare un account di storage NetApp e un pool di capacità per ANF</block>
  <block id="fecd60b0aedf111caefb4cf98b8d7be5" category="paragraph">In questo scenario di implementazione, il provisioning di un sistema operativo Azure VM viene eseguito utilizzando il normale storage Azure, ma i volumi ANF vengono forniti per eseguire il database Oracle tramite NFS. Innanzitutto, è necessario creare un account di storage NetApp e un pool di capacità per ospitare i volumi di storage.</block>
  <block id="76dc01e3f39d83b88a3d3ad36c338654" category="inline-link-macro">Configurare Azure NetApp Files e creare un volume NFS</block>
  <block id="8a57d5f988c678cd141c2f704e110472" category="paragraph">Vedere <block ref="2337ae471c0cc5402cdba65ad3b4dc78" category="inline-link-macro-rx"></block> Per impostare un pool di capacità ANF.</block>
  <block id="ed39ba49be7769bdf483ae876d88cdff" category="section-title">3. Provisioning di Azure VM per Oracle</block>
  <block id="acb4908e71af4ce0945c90f9039d0fc2" category="paragraph">In base al carico di lavoro, determinare il tipo di Azure VM necessario e le dimensioni della VM vCPU e della RAM da implementare per Oracle. Quindi, dalla console di Azure, fare clic sull'icona della macchina virtuale per avviare il flusso di lavoro di implementazione della macchina virtuale.</block>
  <block id="20d1e12ba2a72916f3917e44ff29b40a" category="list-text">Dalla pagina di Azure VM, fare clic su *Create*, quindi scegliere *Azure virtual machine*.</block>
  <block id="94f088d23454b3c408a17cfff3cb8989" category="inline-image-macro">Questa schermata mostra l'elenco delle macchine virtuali Azure disponibili.</block>
  <block id="e28fc410c2020dcbd93af60f3d700d99" category="paragraph"><block ref="e28fc410c2020dcbd93af60f3d700d99" category="inline-image-macro-rx" type="image"></block></block>
  <block id="78ba4b8df4acae5536f056217b16c353" category="list-text">Scegliere l'ID di abbonamento per l'implementazione, quindi scegliere il gruppo di risorse, la regione, il nome host, l'immagine della macchina virtuale, le dimensioni, e metodo di autenticazione. Accedere alla pagina disco.</block>
  <block id="cbbcba216ab68f94c8fab62d9c907a00" category="inline-image-macro">Questa schermata mostra l'input per la pagina Create a Virtual Machine (Crea una macchina virtuale).</block>
  <block id="825d4c0973e48f04ab75cc30df85bbdc" category="inline-image-macro">Questa schermata mostra l'input aggiuntivo per la pagina Create a Virtual Machine (Crea una macchina virtuale).</block>
  <block id="84982a7e7b9cc89bde9621d68800978e" category="paragraph"><block ref="a493253d19b28a6711494154a3160350" category="inline-image-macro-rx" type="image"></block>
<block ref="81b338659efc8df55ae98546f396c5b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c435f9a03a03e7cff44b06c9efafa31" category="list-text">Scegliere *SSD premium* per la ridondanza locale del sistema operativo e lasciare vuoto il disco dati perché i dischi dati sono montati dallo storage ANF. Accedere alla pagina rete.</block>
  <block id="04faa74bfe9ea34a9831d24d039dc159" category="inline-image-macro">Questa schermata mostra l'input per la pagina Create a Virtual Machine Disks (Crea dischi macchina virtuale).</block>
  <block id="2e21daafaa3607d62dda1a3411975b12" category="paragraph"><block ref="2e21daafaa3607d62dda1a3411975b12" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9c5742f2bffff7dd4a50e578bfb093b" category="list-text">Scegliere VNET e subnet. Assegnare un IP pubblico per l'accesso alle macchine virtuali esterne. Quindi andare alla pagina Management (Gestione).</block>
  <block id="0c0077e9a9d4700a64e70d30e9d110df" category="inline-image-macro">Questa schermata mostra ulteriori input per la pagina Create a Virtual Machine (Crea una macchina virtuale).</block>
  <block id="4aea6dbf72aa0b36bd98ced95acebcbd" category="paragraph"><block ref="4aea6dbf72aa0b36bd98ced95acebcbd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d5e4bb7568c6e8fb6a1f49aea08e975" category="list-text">Mantenere tutte le impostazioni predefinite per la gestione e passare alla pagina Avanzate.</block>
  <block id="45291c6293e8de1084c3b8de71bfe120" category="inline-image-macro">Questa schermata mostra l'input per la pagina Create a Virtual Machine Management (Crea una macchina virtuale).</block>
  <block id="b031dac11379aafec2eb9832f71648ba" category="paragraph"><block ref="b031dac11379aafec2eb9832f71648ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22b5d3beb0289dfe21618d5664538321" category="list-text">Mantenere tutte le impostazioni predefinite per la pagina Advanced (Avanzate), a meno che non sia necessario personalizzare una macchina virtuale dopo la distribuzione con script personalizzati. Quindi andare alla pagina Tag.</block>
  <block id="1a911a2f1237ad150a29236bcfe044a0" category="inline-image-macro">Questa schermata mostra l'input per la pagina Create a Virtual Machine Advanced (Crea una macchina virtuale avanzata).</block>
  <block id="00d8612fb98dc237476c6ecd9e0f52c9" category="paragraph"><block ref="00d8612fb98dc237476c6ecd9e0f52c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46dfe2059392afeb84a872afb7cd09d5" category="list-text">Aggiungere un tag per la macchina virtuale, se lo si desidera. Quindi, accedere alla pagina Review + create (Rivedi e crea).</block>
  <block id="85e3843de649be49b63e3b04c6887bcd" category="inline-image-macro">Questa schermata mostra l'input per la pagina Create a Virtual Machine Tags (Crea tag macchina virtuale).</block>
  <block id="ddeecdecd575fb71cf4e83d7f09717bc" category="paragraph"><block ref="ddeecdecd575fb71cf4e83d7f09717bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57a6346e9ebfe8164361d5e2facffb62" category="list-text">Il flusso di lavoro di implementazione esegue una convalida sulla configurazione e, se la convalida ha esito positivo, fare clic su *Create* (Crea) per creare la macchina virtuale.</block>
  <block id="dec1fd75845506029d8751bb7979c797" category="inline-image-macro">"Questa schermata mostra l'input per la pagina di revisione e creazione di una macchina virtuale".</block>
  <block id="786b4cd98c208b72f71277850831c1aa" category="paragraph"><block ref="786b4cd98c208b72f71277850831c1aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c18c3fe2e695bda0cb8b3e7ecccbdc4e" category="section-title">4. Provisioning di volumi di database ANF per Oracle</block>
  <block id="f162c2b2b89920293c1f24ac435c520e" category="paragraph">È necessario creare tre volumi NFS per un pool di capacità ANF rispettivamente per i volumi binari, dati e log Oracle.</block>
  <block id="09d8c19d5844128b31e1fa195808b215" category="list-text">Dalla console Azure, sotto l'elenco dei servizi Azure, fare clic su Azure NetApp Files (Apri) per aprire un flusso di lavoro per la creazione di un volume. Se si dispone di più account storage ANF, fare clic sull'account da cui si desidera eseguire il provisioning dei volumi.</block>
  <block id="733cf6b848c8e38a49b4b604225141a5" category="inline-image-macro">Questa schermata mostra la pagina Azure Services, con ANF evidenziato.</block>
  <block id="cc553796f259bc80d8c801687c0c1cd0" category="paragraph"><block ref="cc553796f259bc80d8c801687c0c1cd0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8972cd5a80e6e385a27023ce45537a9" category="list-text">Nell'account storage NetApp, fare clic su *Volumes*, quindi su *Add volume* per creare nuovi volumi Oracle.</block>
  <block id="c8ce9170654447aba6747494e61bf3a2" category="inline-image-macro">Questa schermata mostra la schermata iniziale di un account storage NetApp.</block>
  <block id="b0d2d575f2aee1703b6e2896d43b72f9" category="inline-image-macro">Questa schermata mostra i volumi disponibili per l'account storage NetApp.</block>
  <block id="3371cc932d04403ab2cd0788634d63e5" category="paragraph"><block ref="7266705f76a6cb3a106c34a6e8dc5540" category="inline-image-macro-rx" type="image"></block>
<block ref="f59831fbf7eaa0d216e8685698d0c55b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbeaec71dc2b8275a14b23283d51cc04" category="list-text">Come buona pratica, identificare i volumi Oracle con il nome host della macchina virtuale come prefisso e quindi il punto di montaggio sull'host, come u01 per il binario Oracle, u02 per i dati Oracle e u03 per il registro Oracle. Scegliere lo stesso VNET per il volume della macchina virtuale. Fare clic su *Avanti: Protocollo&gt;*.</block>
  <block id="ce4ff1bdb6d954e6967a7c241ff89518" category="inline-image-macro">Schermata di creazione del volume.</block>
  <block id="bacf4983022360caacd6f75352136f59" category="paragraph"><block ref="bacf4983022360caacd6f75352136f59" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b50bdcda066df8ed373847c60bc2f546" category="list-text">Scegliere il protocollo NFS, aggiungere l'indirizzo IP dell'host Oracle al client consentito e rimuovere il criterio predefinito che consente l'accesso a tutti gli indirizzi IP 0.0.0.0/0. Quindi fare clic su *Avanti: Tag&gt;*.</block>
  <block id="f8bc211f91c2b350b268959a57418393" category="inline-image-macro">Protocol input (immissione protocollo) nella schermata Volume Creation (creazione volume).</block>
  <block id="8ac138d8c4a217ce018b45be622db1ed" category="paragraph"><block ref="8ac138d8c4a217ce018b45be622db1ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fffcdc9cd5233d4718046c8f6d19c80b" category="list-text">Aggiungere un tag di volume, se lo si desidera. Quindi fare clic su *Review + Create&gt;* (Rivedi + Crea).</block>
  <block id="05864b350d713935d13966f3c8fcbcd7" category="inline-image-macro">Immissione dei tag nella schermata Volume Creation (creazione volume).</block>
  <block id="9bead8568a27fcf83faf41e77f52b246" category="paragraph"><block ref="9bead8568a27fcf83faf41e77f52b246" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e574c0c875926f1fe654026995f3543" category="list-text">Se la convalida ha esito positivo, fare clic su *Create* (Crea) per creare il volume.</block>
  <block id="4a585922412f050ac4a7fbcc34a2655b" category="inline-image-macro">Esaminare e creare la fase della schermata Volume Creation (creazione volume).</block>
  <block id="e9c713f1ad3a3f0b14801d722fb77f16" category="paragraph"><block ref="e9c713f1ad3a3f0b14801d722fb77f16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d2dbc217706d8bb1248bc209e0ab9da" category="section-title">Installare e configurare Oracle su Azure VM con ANF</block>
  <block id="7beaf3d9487c79b7245a1d9ae42d46aa" category="paragraph">Il team delle soluzioni NetApp ha creato molti toolkit di automazione basati su Ansible per aiutarti a implementare Oracle in Azure senza problemi. Seguire questi passaggi per implementare Oracle su una macchina virtuale Azure.</block>
  <block id="0c782f45b1de4e6d016eafeeb60d286f" category="section-title">Configurare un controller Ansible</block>
  <block id="58a105c56c05508f7233082bc282a654" category="paragraph">Se non è stato configurato un controller Ansible, vedere <block ref="03bbd03f7d2552fa2076b42f86a04360" category="inline-link-macro-rx"></block>, Che contiene istruzioni dettagliate su come configurare un controller Ansible.</block>
  <block id="ce9ef6052d2c6ac4b97c01049ee4ec2b" category="section-title">Ottieni il toolkit per l'automazione dell'implementazione Oracle</block>
  <block id="52eae91ee8ea917bc73df6d9f1792469" category="paragraph">Clonare una copia del toolkit di implementazione Oracle nella home directory con l'ID utente utilizzato per accedere al controller Ansible.</block>
  <block id="19cd6e3dfb797a7325548b346dc358f1" category="section-title">Eseguire il toolkit con la configurazione</block>
  <block id="aa98393908153ea46a2cef869e7dd100" category="paragraph">Vedere <block ref="e7ab084e08308da08da1b2dd8151530b" category="inline-link-macro-rx"></block> Per eseguire il manuale con la CLI. È possibile ignorare la parte ONTAP della configurazione delle variabili nel file VAR globale quando si creano volumi di database dalla console Azure anziché dalla CLI.</block>
  <block id="24e16cc700e2ced028e529370af380e1" category="admonition">Il toolkit predefinito implementa Oracle 19c con RU 19.8. Può essere facilmente adattato a qualsiasi altro livello di patch con lievi modifiche di configurazione predefinite. Inoltre, i file di log attivi predefiniti del database seme vengono implementati nel volume di dati. Se sono necessari file di log attivi sul volume di log, è necessario riallocarli dopo la distribuzione iniziale. Se necessario, contatta il team delle soluzioni NetApp.</block>
  <block id="dd52a71d2066e527d28efdbd46784e07" category="section-title">Configura lo strumento di backup AzAcSnap per snapshot coerenti con l'applicazione per Oracle</block>
  <block id="211e60df4f320c617afaa9a96f62758f" category="paragraph">Azure Application-coerenti Snapshot Tool (AzAcSnap) è uno strumento a riga di comando che consente la protezione dei dati per database di terze parti gestendo tutte le orchestrazione necessarie per inserirli in uno stato coerente con l'applicazione prima di eseguire uno snapshot di storage. Quindi, riporta questi database a uno stato operativo. NetApp consiglia di installare lo strumento sull'host del server di database. Consultare le seguenti procedure di installazione e configurazione.</block>
  <block id="40390144ce134a2e38bfef9f590f867b" category="section-title">Installare lo strumento AzAcSnap</block>
  <block id="c2d834909e264a2f3bf3d3facd27740b" category="inline-link-macro">Il programma di installazione di AzArcSnap</block>
  <block id="aed9be57adbc2906c27b7f325e1322aa" category="list-text">Scarica la versione più recente di <block ref="696590d44d21e9b71649cae0895a0bca" category="inline-link-macro-rx"></block>.</block>
  <block id="243004130aa732bde904924170fa2e5c" category="list-text">Copiare il programma di installazione automatica scaricato nel sistema di destinazione.</block>
  <block id="1aa45c54511185e4e2043ee91e8969bc" category="list-text">Eseguire il programma di installazione automatica come utente root con l'opzione di installazione predefinita. Se necessario, rendere il file eseguibile utilizzando<block ref="48c01707d676030dd223de543c6beb09" prefix=" " category="inline-code"></block> comando.</block>
  <block id="483944250a0e1f955ad6fec7c6578bde" category="section-title">Configurare la connettività Oracle</block>
  <block id="b6f7df8a3ada5b45cee3400740b83c9a" category="paragraph">Gli strumenti di snapshot comunicano con il database Oracle e richiedono un utente del database con le autorizzazioni appropriate per attivare o disattivare la modalità di backup.</block>
  <block id="6cd11918e51f60b6ce021e9d56c9e74a" category="section-title">1. Configurare l'utente del database AzAcSnap</block>
  <block id="84fe6666ea577b7ede5c61912d97705e" category="paragraph">Gli esempi seguenti mostrano la configurazione dell'utente del database Oracle e l'utilizzo di sqlplus per la comunicazione con il database Oracle. I comandi di esempio configurano un utente (AZACSNAP) nel database Oracle e modificano l'indirizzo IP, i nomi utente e le password in base alle esigenze.</block>
  <block id="342df2b2fb63c81cdd53e5e7bc5d00b9" category="list-text">Dall'installazione del database Oracle, avviare sqlplus per accedere al database.</block>
  <block id="ab0840eee4ba613870ae404c907c1948" category="list-text">Creare l'utente.</block>
  <block id="e90b9dc19df07f784e3fc408169077df" category="list-text">Concedere le autorizzazioni dell'utente. In questo esempio viene impostata l'autorizzazione per l'utente AZACSNAP per attivare la modalità di backup del database.</block>
  <block id="f508d634fc1aa5df7fed84e6b58afce9" category="list-text">Impostare la scadenza predefinita della password dell'utente su Unlimited.</block>
  <block id="bc5fff092e99ce3d1966b94061cb5953" category="list-text">Convalidare la connettività azacsnap per il database.</block>
  <block id="8e0d0fb1cb3a50066ecd397700dfd22e" category="section-title">2. Configurare azacsnap utente Linux per l'accesso DB con Oracle wallet</block>
  <block id="7140a904f4b795616fdc3c3efbdcd066" category="paragraph">L'installazione predefinita di AzAcSnap crea un utente del sistema operativo azacsnap. Il suo ambiente shell Bash deve essere configurato per l'accesso al database Oracle con la password memorizzata in un portafoglio Oracle.</block>
  <block id="c54cf7bb99b0e669ce6dc05ec8272470" category="list-text">Come utente root, eseguire<block ref="760381f8107a856bc583301b7b272917" prefix=" " category="inline-code"></block> Per identificare le variabili ORACLE_HOME e ORACLE_SID sull'host.</block>
  <block id="2a4941dc3f20c8f34a09b066691e66a5" category="list-text">Aggiungere LE variabili ORACLE_HOME, ORACLE_SID, TNS_ADMIN e PATH al profilo bash dell'utente azacsnap. Modificare le variabili in base alle necessità.</block>
  <block id="e3c85fad3d30c470aac355430e98dc21" category="list-text">Come utente Linux azacsnap, creare il portafoglio. Viene richiesta la password del portafoglio.</block>
  <block id="83617bd12022f2dd9ba94816c7e56670" category="list-text">Aggiungere le credenziali della stringa di connessione a Oracle Wallet. Nel seguente comando di esempio, AZACSNAP è la ConnectString utilizzata da AzAcSnap, azacsnap è l'utente database Oracle e AzPasswd1 è la password database dell'utente Oracle. Viene nuovamente richiesta la password del portafoglio.</block>
  <block id="02f08719de6240015b4e67725107792a" category="list-text">Creare il<block ref="9de875b13677cf9b036a438bf9aedf5c" prefix=" " category="inline-code"></block> file. Nel seguente comando di esempio, L'HOST deve essere impostato sull'indirizzo IP del database Oracle e il SID del server deve essere impostato sul SID del database Oracle.</block>
  <block id="0eec77cc5ed96c42afb08c83ea3f1e3b" category="list-text">Creare il<block ref="0501c2d94325e267bf15055591fb8157" prefix=" " category="inline-code"></block> file.</block>
  <block id="cafefcc0e796f3e73bc39de23dfc6b68" category="list-text">Verificare l'accesso Oracle utilizzando il portafoglio.</block>
  <block id="5fe36f3a6d3cc4a34d1f045b7cd14ac3" category="paragraph">L'output previsto dal comando:</block>
  <block id="54eb020b97d7e8a9f56d67e93754e270" category="section-title">Configurare la connettività ANF</block>
  <block id="8c9356aaf30e863db064ba22b7d4b204" category="paragraph">Questa sezione spiega come abilitare la comunicazione con Azure NetApp Files (con una macchina virtuale).</block>
  <block id="d78964ac0334c0f69ef24aada9864028" category="list-text">All'interno di una sessione di Azure Cloud Shell, assicurarsi di aver effettuato l'accesso all'abbonamento che si desidera associare all'entità del servizio per impostazione predefinita.</block>
  <block id="8611ff0fcccf2f05ff0dbde909379c14" category="list-text">Se l'abbonamento non è corretto, utilizzare il seguente comando:</block>
  <block id="2d66e076b40e24c73ffa7a1704d985db" category="list-text">Creare un'entità di servizio utilizzando la CLI di Azure come nell'esempio seguente:</block>
  <block id="707cc085819c641d15b9ea2b3b13cb53" category="paragraph">Output previsto:</block>
  <block id="c51a1e8c830ed4f63c489347dbcce1a7" category="list-text">Tagliare e incollare il contenuto di output in un file chiamato<block ref="b50999884a39c5efe8da46cd87acfeb2" prefix=" " category="inline-code"></block> Memorizzato nella directory utente di Linux azacsnap user bin e sicuro il file con le autorizzazioni di sistema appropriate.</block>
  <block id="211f39ae9cd979a9f01bb800eca0b832" category="admonition">Assicurarsi che il formato del file JSON sia esattamente come descritto sopra, in particolare con gli URL racchiusi tra virgolette doppie (").</block>
  <block id="c1f6adfa882cba0dbd256d4909ac588c" category="section-title">Completare la configurazione dello strumento AzAcSnap</block>
  <block id="e0e7b63ff02eb3221940162934949dd0" category="paragraph">Per configurare e testare gli strumenti di snapshot, procedere come segue. Dopo aver eseguito correttamente i test, è possibile eseguire la prima snapshot di storage coerente con il database.</block>
  <block id="fe615094ac9bb468d26149280e3769d7" category="list-text">Passare all'account utente di Snapshot.</block>
  <block id="4ef9af49185e683998d060aa71c30e2b" category="list-text">Modificare la posizione dei comandi.</block>
  <block id="412d274adbc3fc7cb51ab315d7a77f82" category="list-text">Configurare un file di dettagli per il backup dello storage. In questo modo viene creato un<block ref="8ed8c6bfea85d72bc4a36772490109c7" prefix=" " category="inline-code"></block> file di configurazione.</block>
  <block id="d4c18f094b4959d27f52ee2a9709a6b9" category="paragraph">L'output previsto con tre volumi Oracle:</block>
  <block id="72b0a1cda785576a979ca4ee2e3c8c62" category="list-text">In qualità di utente di azacsnap Linux, eseguire il comando di test azacsnap per un backup Oracle.</block>
  <block id="7be23e8f29bfc799fd8fbcdc55fe0e77" category="list-text">Eseguire il primo backup dello snapshot.</block>
  <block id="42481f217667e9b11be3ea64c971056a" category="inline-link-macro">Avanti: Protezione del database.</block>
  <block id="d39c73ea41fa36408b518637e929e754" category="paragraph"><block ref="d39c73ea41fa36408b518637e929e754" category="inline-link-macro-rx"></block></block>
  <block id="32800a2387c1d841d80eab97ff7205c2" category="summary">Questa sezione fornisce dettagli sui fattori da considerare quando si implementa il database Oracle su istanze AWS EC2 e storage FSX.</block>
  <block id="0dd9b4b69c30ae87b4322df28758dc18" category="paragraph"><block ref="0dd9b4b69c30ae87b4322df28758dc18" category="inline-link-macro-rx"></block></block>
  <block id="e958329ac331abb8419551328745ce28" category="paragraph">Nelle sezioni seguenti vengono descritte le considerazioni principali relative all'implementazione del database Oracle in un cloud pubblico AWS su un'istanza EC2 con storage FSX.</block>
  <block id="af9adf45d47438d70bedeea4353827c3" category="paragraph">La scelta delle dimensioni corrette delle macchine virtuali è importante per ottenere performance ottimali di un database relazionale in un cloud pubblico. Per ottenere performance migliori, NetApp consiglia di utilizzare un'istanza della serie EC2 M5 per l'implementazione Oracle, ottimizzata per i carichi di lavoro del database. Lo stesso tipo di istanza viene utilizzato anche per alimentare un'istanza RDS per Oracle di AWS.</block>
  <block id="1dbc89cff7796dd99cbe9338453d04d7" category="list-text">Scegliere la combinazione di vCPU e RAM corretta in base alle caratteristiche del carico di lavoro.</block>
  <block id="ff1a938ecebc5237c31b8f5d9a9b87ce" category="list-text">Aggiungere spazio di swap a una macchina virtuale. La distribuzione dell'istanza EC2 predefinita non crea uno spazio di swap, che non è ottimale per un database.</block>
  <block id="c1b542506bceb69c76148851e217c49f" category="list-text">Per lo storage NFS, il layout del volume consigliato è di tre volumi: Uno per il binario Oracle, uno per i dati Oracle e un file di controllo duplicato e uno per il log attivo Oracle, il log archiviato e il file di controllo.</block>
  <block id="02833700de6eac537733ce81ef6352a3" category="paragraph"><block ref="02833700de6eac537733ce81ef6352a3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fc828f321000aae204feb1f0f945893" category="list-text">Per lo storage iSCSI, il layout del volume consigliato è di tre volumi: Uno per il binario Oracle, uno per i dati Oracle e un file di controllo duplicato e uno per il log attivo Oracle, il log archiviato e il file di controllo. Tuttavia, ogni volume di dati e log dovrebbe contenere idealmente quattro LUN. I LUN sono idealmente bilanciati sui nodi del cluster ha.</block>
  <block id="cddd034875839504dacaa29e5dca803f" category="paragraph"><block ref="cddd034875839504dacaa29e5dca803f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b7810ed5b0bbb3acf153d353ac803a51" category="list-text">Per gli IOPS e il throughput dello storage, è possibile scegliere la soglia per gli IOPS e il throughput forniti per il cluster di storage FSX e questi parametri possono essere regolati in modo immediato in qualsiasi momento del cambiamento del carico di lavoro.</block>
  <block id="c5493cd0fe001da987655ad852808dc7" category="list-text">L'impostazione di IOPS automatico è di tre IOPS per GiB di capacità di storage allocata o di storage definito dall'utente fino a 80,000.</block>
  <block id="6524d7ff1096fc6a10590b6d1f7163b6" category="list-text">Il livello di throughput viene incrementato come segue: 128, 256, 512, 1024, 2045 Mbps.</block>
  <block id="bc4bb24d5e702fb79be623b84e7cf47e" category="inline-link-macro">Performance di Amazon FSX per NetApp ONTAP</block>
  <block id="b59267e60b3253fa9c2edeed17c1340f" category="paragraph">Esaminare <block ref="a572b0e55a3a15b7b3460602e8714ba1" category="inline-link-macro-rx"></block> Documentazione per il dimensionamento di throughput e IOPS.</block>
  <block id="4865c175ece72354a657ed5ee2b256eb" category="paragraph">Linux, il sistema operativo più comune, include funzionalità NFS native. Oracle offre il client NFS (DNFS) diretto integrato in modo nativo in Oracle. Oracle supporta NFSv3 da oltre 20 anni. DNFS è supportato con NFSv3 con tutte le versioni di Oracle. NFSv4 è supportato con tutti i sistemi operativi che seguono lo standard NFSv4. Il supporto DNFS per NFSv4 richiede Oracle 12.1.0.2 o superiore. NFSv4.1 richiede un supporto specifico per il sistema operativo. Per informazioni sui sistemi operativi supportati, consultare lo strumento matrice di interoperabilità NetApp (IMT). Il supporto DNFS per NFSv4.1 richiede Oracle versione 19.3.0.0 o successiva.</block>
  <block id="a3f8d7c738bb455d9c0506663213b244" category="paragraph">L'implementazione automatica di Oracle utilizzando il toolkit di automazione NetApp configura automaticamente DNFS su NFSv3.</block>
  <block id="5a749fcdd97cee211c5fea00babe8691" category="paragraph">Per ottenere performance ottimali e prevenire problemi di performance, regolare i parametri del kernel che controllano le tabelle degli slot TCP su 128.</block>
  <block id="dcd7ebfa96f217f8d20c58a185a48531" category="list-text">La seguente tabella fornisce le opzioni di montaggio NFS consigliate per Linux NFSv3 - istanza singola.</block>
  <block id="4780ee7b64d0ec83e06977206e8a35b5" category="paragraph"><block ref="4780ee7b64d0ec83e06977206e8a35b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5088352a7b028bc873f55b1b666d7cd8" category="admonition">Prima di utilizzare DNFS, verificare che siano installate le patch descritte in Oracle Doc 1495104.1. La matrice di supporto NetApp per NFSv3 e NFSv4 non include sistemi operativi specifici. Sono supportati tutti i sistemi operativi che rispettano l'RFC. Quando si cerca il supporto NFSv3 o NFSv4 nel IMT online, non selezionare un sistema operativo specifico perché non viene visualizzata alcuna corrispondenza. Tutti i sistemi operativi sono implicitamente supportati dalla policy generale.</block>
  <block id="2fe1fc26875d6d38f4b15a3a03d498fb" category="paragraph">Come indicato nell'architettura della soluzione, ha si basa sulla replica a livello di storage. Pertanto, l'avvio e la disponibilità di Oracle dipendono dalla rapidità con cui è possibile aumentare e ripristinare il calcolo e lo storage. Vedere i seguenti fattori chiave:</block>
  <block id="137bc4c57a9561d086601728a3db1a90" category="list-text">Disporre di un'istanza di calcolo in standby pronta e sincronizzata con l'istanza primaria tramite l'aggiornamento parallelo di Ansible su entrambi gli host.</block>
  <block id="d653e9032c9904901af96f496db98a3e" category="list-text">Replicare il volume binario dal primario per scopi di standby in modo che non sia necessario installare Oracle all'ultimo minuto e capire cosa deve essere installato e patchato.</block>
  <block id="77991416cd2e0bfc66a77d32e3fbb45a" category="list-text">La frequenza di replica determina la velocità di ripristino del database Oracle per rendere disponibile il servizio. Esiste un compromesso tra la frequenza di replica e il consumo dello storage.</block>
  <block id="0797ee9bca14d1064492a93ac7cc7fa1" category="list-text">Sfrutta l'automazione per rendere il ripristino e il passaggio in standby rapido e privo di errori umani. NetApp fornisce un toolkit di automazione a questo scopo.</block>
  <block id="0a076fda3d30e9959f9332ce7c42445c" category="paragraph"><block ref="0a076fda3d30e9959f9332ce7c42445c" category="inline-link-macro-rx"></block></block>
  <block id="ebcadd0d5b1096e72d18133b1e0e3098" category="doc">TR-4467: SAP con Microsoft SQL Server su Windows - Best practice con NetApp Clustered Data ONTAP e SnapCenter</block>
  <block id="611a4a6b98272a717f8e1f6bf5ba787b" category="paragraph">Marco Schoen, NetApp</block>
  <block id="dbd408dfbba42c9529974244acc200aa" category="paragraph">TR-4467 offre a clienti e partner le Best practice per l'implementazione di Clustered NetApp Data ONTAP a supporto delle soluzioni SAP Business Suite eseguite in un ambiente Microsoft SQL Server su Windows.</block>
  <block id="d90b6dfa1c90883fc207f3309f98b1bf" category="paragraph"><block ref="d90b6dfa1c90883fc207f3309f98b1bf" category="inline-link-macro-rx"></block></block>
  <block id="8f7280c86689be0a39cdf74aa673040d" category="summary">Questa soluzione è progettata in un ambiente di cloud ibrido per supportare i database di produzione on-premise che possono esplodere in tutti i cloud pubblici più diffusi per le operazioni di sviluppo/test e disaster recovery.</block>
  <block id="132f2888eb2cfdeef2730212f50c53e3" category="doc">Requisiti SnapCenter</block>
  <block id="e2a7d0854ef572e10255339732bb005d" category="inline-link-macro">Precedente: Architettura delle soluzioni.</block>
  <block id="b10927905ed5379ba0d73333abdbe06d" category="paragraph"><block ref="b10927905ed5379ba0d73333abdbe06d" category="inline-link-macro-rx"></block></block>
  <block id="6546814199e52492fa0efe5fbff08d5a" category="paragraph">Questa soluzione supporta tutti i database attualmente supportati da SnapCenter, anche se qui vengono dimostrati solo i database Oracle e SQL Server. Questa soluzione è validata con carichi di lavoro di database virtualizzati, sebbene siano supportati anche i carichi di lavoro bare-metal.</block>
  <block id="185b108b21dccef917f415be6026c91c" category="paragraph">Supponiamo che i server di database in produzione siano ospitati on-premise con volumi DB presentati agli host DB da un cluster di storage ONTAP. Il software SnapCenter viene installato on-premise per il backup del database e la replica dei dati nel cloud. Un controller Ansible è consigliato ma non richiesto per l'automazione dell'implementazione del database o per la sincronizzazione della configurazione del kernel e del database del sistema operativo con un'istanza di DR di standby o istanze di sviluppo/test nel cloud pubblico.</block>
  <block id="47099d9ea153f8abfa5b6b70da253b3a" category="cell">*On-premise*</block>
  <block id="d36407241494bfc1e84614ad1b0dd6a4" category="cell">Qualsiasi database e versione supportati da SnapCenter</block>
  <block id="8c8c8ca7a4093a1210412a3a5e5ad55f" category="cell">SnapCenter v4.4 o superiore</block>
  <block id="9d9ebf67dab68c3c892de99e981039cf" category="cell">Ansible v2.09 o superiore</block>
  <block id="62dd4f48e99b13c8a00fbaba684f9592" category="cell">Cluster ONTAP 9.x</block>
  <block id="d0fdc58e1e05d6cbc8b1beb072bfa235" category="cell">LIF intercluster configurati</block>
  <block id="7135df562bcb25bfdf20e4317b923b88" category="cell">Connettività da on-premise a un VPC cloud (VPN, interconnessione e così via)</block>
  <block id="8c27863f5ffd0e66a9304eaca2e47fde" category="cell">Porte di rete aperte - ssh 22 - tcp 8145, 8146, 10000, 11104, 11105</block>
  <block id="bcb9f3419f724f768e30956a4427261d" category="cell">*Cloud - AWS*</block>
  <block id="61c90d44785278f980592f082ef500f1" category="inline-link">Connettore Cloud Manager</block>
  <block id="97bc5062dceccb6827b1e3f0522035f0" category="cell"><block ref="97bc5062dceccb6827b1e3f0522035f0" category="inline-link-rx"></block></block>
  <block id="2f077494ceff1f33085c5b163c3673b3" category="cell"><block ref="2f077494ceff1f33085c5b163c3673b3" category="inline-link-rx"></block></block>
  <block id="59b2c9424963f98d73ec69c59dde54cb" category="cell">Corrispondenza delle istanze DB OS EC2 con quelle on-premise</block>
  <block id="e26786a16da88ee829ab76c48fd3b003" category="cell">*Cloud - Azure*</block>
  <block id="c2f8674b07907f393b67a3f9e98d3d56" category="cell"><block ref="c2f8674b07907f393b67a3f9e98d3d56" category="inline-link-rx"></block></block>
  <block id="a8dd724647657a383eb37fd8775ec1a9" category="cell"><block ref="a8dd724647657a383eb37fd8775ec1a9" category="inline-link-rx"></block></block>
  <block id="8bede1f0e559918be01f0646b75b4257" category="cell">Abbinamento delle macchine virtuali DB OS Azure alle macchine virtuali on-premise</block>
  <block id="b2a454fb4ff03b84162c59d674fdae25" category="cell">*Cloud - GCP*</block>
  <block id="af072236983e991ab34e773871b10236" category="cell"><block ref="af072236983e991ab34e773871b10236" category="inline-link-rx"></block></block>
  <block id="499477cf7953707f63a1b1313c8c065a" category="cell"><block ref="499477cf7953707f63a1b1313c8c065a" category="inline-link-rx"></block></block>
  <block id="2900c5e1ee191606f20d007194e70edf" category="cell">Corrispondenza delle istanze di DB OS Google Compute Engine con quelle on-premise</block>
  <block id="126b29c0beff0884077277115103a374" category="inline-link-macro">Pagina successiva: Prerequisiti per la configurazione.</block>
  <block id="a6d027dea0e97ba248528210d36e5475" category="paragraph"><block ref="a6d027dea0e97ba248528210d36e5475" category="inline-link-macro-rx"></block></block>
  <block id="467bda78c0e1adcc5ed650843fbfbdf5" category="summary">Questa sezione descrive il processo di implementazione di Cloud Manager e Cloud Volumes ONTAP in AWS.</block>
  <block id="298a4809d5445df75b6c4a9fb94074a4" category="doc">Introduzione al cloud pubblico AWS</block>
  <block id="b8f5ff8c1ae69fa5befe459d3f34b68a" category="inline-link-macro">Precedente: Introduzione on-premise.</block>
  <block id="19f84106226ff97c314f55dd621bbd98" category="paragraph"><block ref="19f84106226ff97c314f55dd621bbd98" category="inline-link-macro-rx"></block></block>
  <block id="8a3f037eef48de78bfe13d14e3d7cdfa" category="section-title">Cloud pubblico AWS</block>
  <block id="87aa698992e009d04733c9906225592c" category="admonition">Per semplificare la procedura, abbiamo creato questo documento sulla base di un'implementazione in AWS. Tuttavia, il processo è molto simile per Azure e GCP.</block>
  <block id="39845311263ccad04c0d4f0b9aa9d4c6" category="section-title">1. Controllo prima del volo</block>
  <block id="12ed93944854c12caa37886d620f16db" category="paragraph">Prima dell'implementazione, assicurarsi che l'infrastruttura sia in uso per consentire l'implementazione nella fase successiva. Ciò include quanto segue:</block>
  <block id="c6368ae044df0f7bb26ed60afda5c591" category="list-text">Account AWS</block>
  <block id="4019c185756035c18c03fabfccd7d4b2" category="list-text">VPC nella tua regione di scelta</block>
  <block id="fca5d2fece6e360f78dff4573ba04a20" category="list-text">Subnet con accesso a Internet pubblico</block>
  <block id="e3e5c3dadc3e70d536645a3be9744f79" category="list-text">Autorizzazioni per aggiungere ruoli IAM all'account AWS</block>
  <block id="bd5c82fb0e0371a168f609848b11e92a" category="list-text">Chiave segreta e chiave di accesso per l'utente AWS</block>
  <block id="c3d1ff3c88148b2246bb0972916da82a" category="section-title">2. Fasi per implementare Cloud Manager e Cloud Volumes ONTAP in AWS</block>
  <block id="6d0eb695a99109617b806676e9610075" category="inline-link">Documentazione cloud di NetApp</block>
  <block id="593581e466784760a050bceaea5e0c48" category="admonition">Esistono molti metodi per implementare Cloud Manager e Cloud Volumes ONTAP; questo metodo è il più semplice ma richiede la maggior parte delle autorizzazioni. Se questo metodo non è appropriato per l'ambiente AWS in uso, consultare<block ref="97a20614f8c0e53f461a9353634e5e51" category="inline-link-rx"></block>.</block>
  <block id="bb3e779fdf877143137572122cf424e3" category="section-title">Implementare Cloud Manager Connector</block>
  <block id="49fc376ed35249f3841846ede4dab884" category="inline-link">NetApp Cloud Central</block>
  <block id="4c6e32ff373dc3ce5b49202f92f01b08" category="list-text">Selezionare<block ref="143fea272f01f72dbdc942451156df21" category="inline-link-rx"></block> ed effettuare l'accesso o l'iscrizione.</block>
  <block id="356cf5e12d635c19d987b1b195ff5a40" category="paragraph"><block ref="356cf5e12d635c19d987b1b195ff5a40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2300b8579a8761e452d89a2af6636b7d" category="list-text">Dopo aver effettuato l'accesso, si dovrebbe essere portati a Canvas.</block>
  <block id="af93b0b88e1db5f3aa229d2336fedb3c" category="paragraph"><block ref="af93b0b88e1db5f3aa229d2336fedb3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3fbf2c408ce86ff3403990e7e32dcb3" category="list-text">Fai clic su "Aggiungi ambiente di lavoro" e scegli Cloud Volumes ONTAP in AWS. In questo caso, è anche possibile scegliere se implementare un sistema a nodo singolo o una coppia ad alta disponibilità. Ho scelto di implementare una coppia ad alta disponibilità.</block>
  <block id="bb18ff1ebac7ea2039aa297469c76b76" category="paragraph"><block ref="bb18ff1ebac7ea2039aa297469c76b76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="016aa0c0a7322975ec4b8eeac805f2c0" category="list-text">Se non è stato creato alcun connettore, viene visualizzata una finestra a comparsa che richiede di creare un connettore.</block>
  <block id="a05691eb0d806668c3796d3d6fe01157" category="paragraph"><block ref="a05691eb0d806668c3796d3d6fe01157" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fc3362a0d8ab63cc8fa21bbd0fb07db" category="list-text">Fare clic su Avvia, quindi scegliere AWS.</block>
  <block id="55f5adc74d49945abd7798742f307124" category="paragraph"><block ref="55f5adc74d49945abd7798742f307124" category="inline-image-macro-rx" type="image"></block></block>
  <block id="deae4c054bb3102bbf634b14534da9bf" category="inline-link">Pagina delle policy di NetApp</block>
  <block id="651d429a2b6cfcd93f6adb1d4825a214" category="list-text">Inserire la chiave segreta e la chiave di accesso. Assicurarsi che l'utente disponga delle autorizzazioni corrette descritte in<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block>.</block>
  <block id="94497191b0b0c6d05a2df7d2175e87f5" category="paragraph"><block ref="94497191b0b0c6d05a2df7d2175e87f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8d59b60a74630e45f83fd3c48207b47" category="list-text">Assegnare un nome al connettore e utilizzare un ruolo predefinito come descritto in<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block> Oppure chiedi a Cloud Manager di creare il tuo ruolo.</block>
  <block id="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="paragraph"><block ref="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02d395705fb063ad8d33d8c83c856e6f" category="list-text">Fornire le informazioni di rete necessarie per implementare il connettore. Verificare che l'accesso a Internet in uscita sia attivato:</block>
  <block id="8215126360cbe5d8f5566c7ffc8cf224" category="list-text">Fornire al connettore un indirizzo IP pubblico</block>
  <block id="22adb619c008bfd7495288573093ae44" category="list-text">Fornire al connettore un proxy da utilizzare</block>
  <block id="58a149795bbe86e4e0d4ab8f10413219" category="list-text">Fornire al connettore un percorso verso Internet pubblico attraverso un gateway Internet</block>
  <block id="5908ad1cf5bd748238e305dd5fc52fac" category="paragraph"><block ref="5908ad1cf5bd748238e305dd5fc52fac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c58ebc9f032dc8d2e5c4f522cedbe0b" category="list-text">Fornire la comunicazione con il connettore tramite SSH, HTTP e HTTPS fornendo un gruppo di protezione o creando un nuovo gruppo di protezione. È stato attivato l'accesso al connettore solo dall'indirizzo IP.</block>
  <block id="1d39d9c13f50dd25f7e54173c87c633a" category="paragraph"><block ref="1d39d9c13f50dd25f7e54173c87c633a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb444cfaba774437ecdbbb95856d94cd" category="list-text">Esaminare le informazioni nella pagina di riepilogo e fare clic su Add (Aggiungi) per implementare il connettore.</block>
  <block id="5576df68e3720f55e585e7e091d5b9e3" category="paragraph"><block ref="5576df68e3720f55e585e7e091d5b9e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4255ace47c9ad7f2907c18df7512bb9f" category="list-text">Il connettore viene ora implementato utilizzando uno stack di formazione cloud. Puoi monitorarne i progressi da Cloud Manager o tramite AWS.</block>
  <block id="ff7fb4bedc0d09880f85d9745ec258a5" category="paragraph"><block ref="ff7fb4bedc0d09880f85d9745ec258a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca320cc147e2b9fac2dd7379e91012b6" category="list-text">Una volta completata l'implementazione, viene visualizzata una pagina di successo.</block>
  <block id="f5bbadf1ed57058e80e27764684e6314" category="paragraph"><block ref="f5bbadf1ed57058e80e27764684e6314" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6382283fd45b13b5c983745731fec990" category="section-title">Implementare Cloud Volumes ONTAP</block>
  <block id="5fe90897c7135ba3020c4a397f55adb6" category="list-text">Selezionare AWS e il tipo di implementazione in base ai requisiti.</block>
  <block id="63b636f2002a2e7b7c2e2420cd64ff73" category="paragraph"><block ref="63b636f2002a2e7b7c2e2420cd64ff73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf1300c5621fdebe8c1a70fade44f3b" category="list-text">Se non è stato assegnato alcun abbonamento e si desidera effettuare l'acquisto con PAYGO, scegliere Modifica credenziali.</block>
  <block id="b893bded7e1bd3419a443758a8ef410f" category="paragraph"><block ref="b893bded7e1bd3419a443758a8ef410f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88eb84b1a8f0417c9de6e1202125df56" category="list-text">Scegliere Aggiungi abbonamento.</block>
  <block id="0b5d3e3d1a9347ff4a7395d09208a8f4" category="paragraph"><block ref="0b5d3e3d1a9347ff4a7395d09208a8f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="052208bafdfe08bc8f0735a78226e541" category="list-text">Scegliere il tipo di contratto a cui si desidera sottoscrivere. Ho scelto il pay-as-you-go.</block>
  <block id="4d5ab1ed0682fe644e831558598d4638" category="paragraph"><block ref="4d5ab1ed0682fe644e831558598d4638" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65577508f7897e730adb501d0db73913" category="list-text">Si viene reindirizzati ad AWS; scegliere continua per iscriversi.</block>
  <block id="ac33260d1e06f504f1dcac229aeb269c" category="paragraph"><block ref="ac33260d1e06f504f1dcac229aeb269c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="439c4fb23c120f0a99894c630cedaabd" category="list-text">Iscriviti e verrai reindirizzato a NetApp Cloud Central. Se sei già iscritto e non ricevi il reindirizzamento, scegli il link "Clicca qui".</block>
  <block id="a90c8b1fc04a41aff490fd2b269f5932" category="paragraph"><block ref="a90c8b1fc04a41aff490fd2b269f5932" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14b9e98d2b57da92c29826ce7de32c32" category="list-text">Verrai reindirizzato a Cloud Central dove devi assegnare un nome all'abbonamento e assegnarlo al tuo account Cloud Central.</block>
  <block id="c89376fd9624f6ebda7959df6176ef34" category="paragraph"><block ref="c89376fd9624f6ebda7959df6176ef34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4508f5994d1b34ff85cd1e8a1884d6c1" category="list-text">Una volta completata la stampa, viene visualizzata una pagina con un segno di spunta. Tornare alla scheda Cloud Manager.</block>
  <block id="2b206bbd8f3b20e3282b660a356d90be" category="paragraph"><block ref="2b206bbd8f3b20e3282b660a356d90be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3294e5fb9ec1c42cde7ebf9b206c583" category="list-text">L'abbonamento viene ora visualizzato in Cloud Central. Fare clic su Apply (Applica) per continuare.</block>
  <block id="37ce5c33a55d907edabe632c39a2707c" category="paragraph"><block ref="37ce5c33a55d907edabe632c39a2707c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7927b068a5dddb4852b2e7dc256544" category="list-text">Inserire i dettagli dell'ambiente di lavoro, ad esempio:</block>
  <block id="0dbae4d42c7a0db53e2eb32adee12892" category="list-text">Nome del cluster</block>
  <block id="0c191ee206a91460fd94e2ff976a38e7" category="list-text">Password del cluster</block>
  <block id="53aa18427d1e2c7b7113c668561a62d2" category="list-text">Tag AWS (opzionale)</block>
  <block id="d3b6ff1e8c6317d132d3a5e974f1374c" category="paragraph"><block ref="d3b6ff1e8c6317d132d3a5e974f1374c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fb5b261ae3a3581304a283ef70a5246" category="inline-link">Homepage di NetApp Cloud</block>
  <block id="e7b29c75e71a48483734401322ef6e92" category="list-text">Scegliere i servizi aggiuntivi che si desidera implementare. Per ulteriori informazioni su questi servizi, visitare il<block ref="1bb1213784e04e4f47d06f252d1ba164" category="inline-link-rx"></block>.</block>
  <block id="88e71a2c19d98c79d2ed51a753c8a4c2" category="paragraph"><block ref="88e71a2c19d98c79d2ed51a753c8a4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0dffa77d5644a3816ba69e24ce813ff" category="list-text">Scegliere se eseguire l'implementazione in più zone di disponibilità (si recuperano tre subnet, ciascuna in un AZ diverso) o in una singola zona di disponibilità. Ho scelto più AZS.</block>
  <block id="6e4a3fe2b0629dae504d8e727147f709" category="paragraph"><block ref="6e4a3fe2b0629dae504d8e727147f709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b889b7255c34e7f230e392668605860" category="list-text">Scegliere la regione, il VPC e il gruppo di sicurezza in cui implementare il cluster. In questa sezione, vengono assegnate anche le zone di disponibilità per nodo (e mediatore) e le subnet occupate.</block>
  <block id="9ad68c9f72863557931a8569462bff52" category="paragraph"><block ref="9ad68c9f72863557931a8569462bff52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be43ebbf5380089f153e4f1b13e35e6f" category="list-text">Scegliere i metodi di connessione per i nodi e il mediatore.</block>
  <block id="8bf6da8b537127466c4421c1ae3169be" category="paragraph"><block ref="8bf6da8b537127466c4421c1ae3169be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="204bd52e1d13052712299779cf041df6" category="admonition">Il mediatore richiede la comunicazione con le API AWS. Non è richiesto un indirizzo IP pubblico, purché le API siano raggiungibili dopo l'implementazione dell'istanza EC2 del mediatore.</block>
  <block id="52fade87431f9acc43b7bf6e4c5fd2f1" category="inline-link">Documentazione sul cloud di NetApp</block>
  <block id="0c79e4a46253eeb94ba6b8218928aa99" category="list-text">Gli indirizzi IP mobili vengono utilizzati per consentire l'accesso ai vari indirizzi IP utilizzati da Cloud Volumes ONTAP, inclusi gli IP di gestione del cluster e di erogazione dei dati. Devono essere indirizzi non ancora instradabili all'interno della rete e aggiunti alle tabelle di routing nell'ambiente AWS. Questi sono necessari per abilitare indirizzi IP coerenti per una coppia ha durante il failover. Ulteriori informazioni sugli indirizzi IP mobili sono disponibili nella<block ref="72cde540b4f97efa19e071f729439801" category="inline-link-rx"></block>.</block>
  <block id="fd4a46ceddfb2402b7e37177af575e04" category="paragraph"><block ref="fd4a46ceddfb2402b7e37177af575e04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95ca6b5e9b64aed9132a6be07d061f3b" category="list-text">Selezionare le tabelle di routing a cui aggiungere gli indirizzi IP mobili. Queste tabelle di routing vengono utilizzate dai client per comunicare con Cloud Volumes ONTAP.</block>
  <block id="3453ab81a2f04d5c39ae750fb79ece2a" category="paragraph"><block ref="3453ab81a2f04d5c39ae750fb79ece2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af918e519f9c0db1ed5ab4fd4b6e9e05" category="list-text">Scegliere se attivare la crittografia gestita AWS o AWS KMS per crittografare i dischi root, boot e dati ONTAP.</block>
  <block id="058eaefa711702bd45c5f6650cf01e4c" category="paragraph"><block ref="058eaefa711702bd45c5f6650cf01e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01bd54fa77587425fca4a6c352309b5c" category="list-text">Scegli il tuo modello di licenza. Se non sai quale scegliere, contatta il tuo rappresentante NetApp.</block>
  <block id="e5e49184799594a9fa690c9122eb883e" category="paragraph"><block ref="e5e49184799594a9fa690c9122eb883e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04110b24d1459a6e21e35ad976a8f10e" category="list-text">Selezionare la configurazione più adatta al caso d'utilizzo. Ciò è correlato alle considerazioni sul dimensionamento trattate nella pagina dei prerequisiti.</block>
  <block id="e19584159c9c3791a9e3c462cb0aa451" category="paragraph"><block ref="e19584159c9c3791a9e3c462cb0aa451" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ed47788a525c6d08246bfa2f90922da" category="list-text">Se si desidera, creare un volume. Questo non è necessario, perché le fasi successive utilizzano SnapMirror, che crea i volumi per noi.</block>
  <block id="01da9401385484b72ba9c016ac6c19ab" category="paragraph"><block ref="01da9401385484b72ba9c016ac6c19ab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76011f95c4e1b3f68fa5829dab0fb786" category="list-text">Esaminare le selezioni effettuate e spuntare le caselle per verificare che Cloud Manager implementa le risorse nel proprio ambiente AWS. Quando si è pronti, fare clic su Go (Vai).</block>
  <block id="7b78e746aa55ffe6fee1f3e0b65b8cca" category="paragraph"><block ref="7b78e746aa55ffe6fee1f3e0b65b8cca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13b7f009673a469e5482a96832be1473" category="list-text">Cloud Volumes ONTAP avvia ora il processo di implementazione. Cloud Manager utilizza le API AWS e gli stack di formazione del cloud per implementare Cloud Volumes ONTAP. Quindi, configura il sistema in base alle tue specifiche, offrendo un sistema pronto all'uso che può essere utilizzato immediatamente. I tempi di questo processo variano a seconda delle selezioni effettuate.</block>
  <block id="11d15d8a4bb9195b48d5010fa30fa547" category="paragraph"><block ref="11d15d8a4bb9195b48d5010fa30fa547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e63d2329924bb302fb012e7916b3614" category="list-text">È possibile monitorare l'avanzamento passando alla Timeline.</block>
  <block id="77405312cc4c1e96d3f7f796e838bf89" category="paragraph"><block ref="77405312cc4c1e96d3f7f796e838bf89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b4df7cc92b3ee31f5d95082a78c7903" category="list-text">La cronologia funge da audit di tutte le azioni eseguite in Cloud Manager. È possibile visualizzare tutte le chiamate API effettuate da Cloud Manager durante la configurazione di AWS e del cluster ONTAP. Questo può essere utilizzato in modo efficace anche per risolvere qualsiasi problema che si deve affrontare.</block>
  <block id="8c17e020c76595308d57605fa71dc7af" category="paragraph"><block ref="8c17e020c76595308d57605fa71dc7af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c5674ad1910f0a25455fdeb0f3f097a" category="list-text">Una volta completata l'implementazione, il cluster CVO viene visualizzato sul Canvas, che corrisponde alla capacità corrente. Il cluster ONTAP nello stato attuale è completamente configurato per consentire un'esperienza reale e immediata.</block>
  <block id="db044bc640be9fc8227b7ada891f279d" category="paragraph"><block ref="db044bc640be9fc8227b7ada891f279d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28d2e01957d5845ff59688f17bd34339" category="section-title">Configurare SnapMirror da on-premise a cloud</block>
  <block id="081494b1a178710486921a42e2bdfa87" category="paragraph">Ora che hai implementato un sistema ONTAP di origine e un sistema ONTAP di destinazione, puoi replicare volumi contenenti dati di database nel cloud.</block>
  <block id="cb3269c2496a99fb03bebe82b6a3e4bc" category="inline-link">Matrice di compatibilità di SnapMirror</block>
  <block id="46aad6288d89ba29f38b4742bf018aca" category="paragraph">Per una guida sulle versioni compatibili di ONTAP per SnapMirror, consultare<block ref="f75a4f2138bf92eb17ef87cad85a9e34" category="inline-link-rx"></block>.</block>
  <block id="36c5350a8474f2212fecc811eb77df57" category="list-text">Fare clic sul sistema ONTAP di origine (on-premise) e trascinarlo nella destinazione, selezionare Replication &gt; Enable (Replica &gt; attiva) oppure selezionare Replication &gt; Menu &gt; Replicate (Replica &gt; Menu &gt; Replica).</block>
  <block id="5dbe69ec28d70286f46385336e96d003" category="paragraph"><block ref="5dbe69ec28d70286f46385336e96d003" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8771a8fdaa9e84a7eef7540edcca5f40" category="paragraph">Selezionare Enable (attiva).</block>
  <block id="ac21962f3f0ae9f9c17b26196452f903" category="paragraph"><block ref="ac21962f3f0ae9f9c17b26196452f903" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6a8dc55f6f333187a100f6ed328bdc0" category="paragraph">O Opzioni.</block>
  <block id="949fa0a5e194cf44c9e08903cb914566" category="paragraph"><block ref="949fa0a5e194cf44c9e08903cb914566" category="inline-image-macro-rx" type="image"></block></block>
  <block id="066bf779660ad446aa9b0d4021c4bf40" category="paragraph">Replicare.</block>
  <block id="deafbb4908c633cb93a7f7e76b31da08" category="paragraph"><block ref="deafbb4908c633cb93a7f7e76b31da08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a803b2a55429f981d25fbb8da94aef7" category="list-text">Se non è stato trascinato, scegliere il cluster di destinazione in cui replicare.</block>
  <block id="630e74180bc1b6c0c0c866d5478ff029" category="paragraph"><block ref="630e74180bc1b6c0c0c866d5478ff029" category="inline-image-macro-rx" type="image"></block></block>
  <block id="761124dc5e0730086556a7d33d43418c" category="list-text">Scegliere il volume che si desidera replicare. Abbiamo replicato i dati e tutti i volumi di log.</block>
  <block id="7bec2596a51a0d4a808a37dec9e6c540" category="paragraph"><block ref="7bec2596a51a0d4a808a37dec9e6c540" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bde4e8497f5ecaef866c0f049aada776" category="list-text">Scegliere il tipo di disco di destinazione e il criterio di tiering. Per il disaster recovery, consigliamo un SSD come tipo di disco e per mantenere il tiering dei dati. Il tiering dei dati tiering i dati mirrorati in storage a oggetti a basso costo e consente di risparmiare denaro sui dischi locali. Quando si rompe la relazione o si clonano i volumi, i dati utilizzano lo storage locale veloce.</block>
  <block id="a7d9908d0f610b3db167c894d109d1ec" category="paragraph"><block ref="a7d9908d0f610b3db167c894d109d1ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52f06f2f09c024b69ef3944a8cd78ad9" category="list-text">Selezionare il nome del volume di destinazione scelto<block ref="47456946fa180c1578446a0fa28fca75" prefix=" " category="inline-code"></block>.</block>
  <block id="6f8ba85bc89d216799431f124e48b25f" category="paragraph"><block ref="6f8ba85bc89d216799431f124e48b25f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2882a0dbc1a6ad74198ac2cb6316870d" category="list-text">Selezionare la velocità di trasferimento massima per la replica. Ciò consente di risparmiare larghezza di banda se si dispone di una connessione a bassa larghezza di banda al cloud, ad esempio una VPN.</block>
  <block id="041263f562a9058ae414685962469951" category="paragraph"><block ref="041263f562a9058ae414685962469951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f81dd66e0f0847d4cb1d2d12fadcc2f3" category="list-text">Definire il criterio di replica. Abbiamo scelto un Mirror, che prende i dataset più recenti e li replica nel volume di destinazione. Puoi anche scegliere una policy diversa in base ai tuoi requisiti.</block>
  <block id="d0b86e2934c870915aaa77674d1d79d7" category="paragraph"><block ref="d0b86e2934c870915aaa77674d1d79d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4db5384e8d04b01ff24a9178b3efaf6a" category="list-text">Scegliere la pianificazione per l'attivazione della replica. NetApp consiglia di impostare una pianificazione "giornaliera" di per il volume di dati e una pianificazione "oraria" per i volumi di log, sebbene sia possibile modificarla in base ai requisiti.</block>
  <block id="c6715d4de4d68a1f8eb9cb8acb63b097" category="paragraph"><block ref="c6715d4de4d68a1f8eb9cb8acb63b097" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02e3a269661e3c96a86a075872a1b269" category="list-text">Esaminare le informazioni immesse, fare clic su Go (Vai) per attivare il peer del cluster e il peer SVM (se si tratta della prima replica tra i due cluster), quindi implementare e inizializzare la relazione SnapMirror.</block>
  <block id="75c2d297cd7282b30ce0400170110307" category="paragraph"><block ref="75c2d297cd7282b30ce0400170110307" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c160366cab97ee8f1a35416d1294ddb" category="list-text">Continuare questa procedura per i volumi di dati e i volumi di log.</block>
  <block id="64853c47f4f907262466c1e5ad154c8c" category="list-text">Per controllare tutte le relazioni, accedere alla scheda Replication (Replica) in Cloud Manager. Qui puoi gestire le tue relazioni e verificare il loro stato.</block>
  <block id="641e620fe8c714d7381775d20a707726" category="paragraph"><block ref="641e620fe8c714d7381775d20a707726" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c88bec52f9e24233a78b6a90efa32ec6" category="list-text">Una volta replicati tutti i volumi, si è in uno stato stabile e si è pronti per passare ai flussi di lavoro di disaster recovery e di sviluppo/test.</block>
  <block id="86fb3ee49ae2f8c0ee121c551a8f08c2" category="section-title">3. Implementare l'istanza di calcolo EC2 per il carico di lavoro del database</block>
  <block id="91ba52045df2b9244f28270482f749c9" category="inline-link">Tipo di istanza EC2</block>
  <block id="33aaa72e62140af9cecb2c48f836b84b" category="paragraph">AWS ha preconfigurato istanze di calcolo EC2 per diversi carichi di lavoro. La scelta del tipo di istanza determina il numero di core della CPU, la capacità della memoria, il tipo e la capacità di storage e le performance di rete. Per i casi di utilizzo, ad eccezione della partizione del sistema operativo, lo storage principale per eseguire il carico di lavoro del database viene allocato da CVO o dal motore di storage FSX ONTAP. Pertanto, i fattori principali da considerare sono la scelta dei core della CPU, la memoria e il livello di performance di rete. I tipi di istanze tipiche di AWS EC2 sono disponibili qui:<block ref="9334d5b9e602c5921b4f295f6041489b" category="inline-link-rx"></block>.</block>
  <block id="0af43c3d809d6e56a6a7a0d1ed039bbc" category="section-title">Dimensionamento dell'istanza di calcolo</block>
  <block id="0b6e77aedd6bd733f979314fef2a98d7" category="list-text">Selezionare il tipo di istanza corretto in base al carico di lavoro richiesto. I fattori da considerare includono il numero di transazioni di business da supportare, il numero di utenti simultanei, il dimensionamento dei set di dati e così via.</block>
  <block id="ed4b68006572e288530a2152f7fbe5fe" category="list-text">L'implementazione dell'istanza EC2 può essere avviata tramite il dashboard EC2. Le procedure di implementazione esulano dall'ambito di questa soluzione. Vedere<block ref="3a5862dd365e3998013717e9cf118a9a" category="inline-link-rx"></block> per ulteriori informazioni.</block>
  <block id="708991723f71fa1bd7b8081be442552c" category="section-title">Configurazione dell'istanza di Linux per il carico di lavoro Oracle</block>
  <block id="5c17b7d75ff16063f772234e1ea8eeb1" category="paragraph">Questa sezione contiene ulteriori passaggi di configurazione dopo la distribuzione di un'istanza EC2 Linux.</block>
  <block id="39d786446455bb2b3017b793805fc902" category="list-text">Aggiungere un'istanza di standby Oracle al server DNS per la risoluzione dei nomi all'interno del dominio di gestione SnapCenter.</block>
  <block id="385a2a4f5305fe5ce8017f18fb7eabd4" category="list-text">Aggiungere un ID utente di gestione Linux come credenziali del sistema operativo SnapCenter con autorizzazioni sudo senza password. Attivare l'ID con l'autenticazione della password SSH sull'istanza EC2. (Per impostazione predefinita, l'autenticazione della password SSH e il sudo senza password sono disattivati sulle istanze EC2).</block>
  <block id="a2b4677d7a72840a78373c600441681a" category="list-text">Configurare l'installazione di Oracle in modo che corrisponda all'installazione Oracle on-premise, ad esempio patch del sistema operativo, versioni e patch di Oracle e così via.</block>
  <block id="66b65364302a847feb2630bfd7974256" category="inline-link">Implementazione automatizzata di Oracle 19c</block>
  <block id="fa470598a181c1ed905bace243e46aa3" category="list-text">I ruoli di automazione Ansible DB di NetApp possono essere sfruttati per configurare le istanze EC2 per i casi di utilizzo di sviluppo/test di database e disaster recovery. Il codice di automazione può essere scaricato dal sito GitHub pubblico di NetApp:<block ref="437f8b44ff65600fb5697e9d369a0c54" category="inline-link-rx"></block>. L'obiettivo è quello di installare e configurare uno stack software di database su un'istanza EC2 in modo che corrisponda alle configurazioni del sistema operativo e del database on-premise.</block>
  <block id="97875b4799caf4c948118e7b4776c9fb" category="section-title">Configurazione dell'istanza di Windows per il carico di lavoro di SQL Server</block>
  <block id="c63751cfdcf8c0b4e26635a47c7f0d97" category="paragraph">In questa sezione sono elencati ulteriori passaggi di configurazione dopo la distribuzione iniziale di un'istanza di EC2 Windows.</block>
  <block id="5f44e6a78874f9f49acae3caa71cc14d" category="list-text">Recuperare la password dell'amministratore di Windows per accedere a un'istanza tramite RDP.</block>
  <block id="eabafc642b0901afd6622ab0f19d9ef0" category="list-text">Disattivare il firewall Windows, unire l'host al dominio Windows SnapCenter e aggiungere l'istanza al server DNS per la risoluzione dei nomi.</block>
  <block id="08bf2d7ff3ac9ab37cfa8dc449b3c8da" category="list-text">Eseguire il provisioning di un volume di log di SnapCenter per memorizzare i file di log di SQL Server.</block>
  <block id="f97ac9d1946c873247af15165559b47a" category="list-text">Configurare iSCSI sull'host Windows per montare il volume e formattare il disco.</block>
  <block id="6c2a9c611f48cae767f6ebea6fca0457" category="inline-link">Automazione NetApp</block>
  <block id="6dea6226167bd38268de4c4d948d72de" category="list-text">Ancora una volta, molte delle attività precedenti possono essere automatizzate con la soluzione di automazione NetApp per SQL Server. Consulta il sito GitHub pubblico di automazione di NetApp per i ruoli e le soluzioni pubblicati di recente:<block ref="8cafb3a3b1222d318fcd262791229701" category="inline-link-rx"></block>.</block>
  <block id="752c08adf364adb2721c9a373759f8f6" category="inline-link-macro">Segue: Workflow per lo sviluppo/test di bursting nel cloud.</block>
  <block id="4e3fc3c2eb04754fcac9e4e23b6de054" category="paragraph"><block ref="4e3fc3c2eb04754fcac9e4e23b6de054" category="inline-link-macro-rx"></block></block>
  <block id="e48febb9ce9511ad6a07eb2feefcf987" category="doc">TR-4951: Backup e ripristino per Microsoft SQL Server su AWS FSX per ONTAP</block>
  <block id="89801e66cf61a843ac015db626c0ecde" category="paragraph">Autore: Niyaz Mohammed, Carine Ngwekwe - NetApp Solutions Engineering</block>
  <block id="a5ddf739ea634e933770ce212cd12b29" category="paragraph">Questo documento illustra i passaggi necessari per eseguire il backup e il ripristino di Microsoft SQL Server su AWS FSX per ONTAP con SnapCenter. Sono incluse le seguenti informazioni:</block>
  <block id="5bf8a1308ebd487796bd4db12222cf4a" category="list-text">Configurazione di NetApp SnapCenter</block>
  <block id="ecc57313124902e4c42227ae61bb9bf1" category="list-text">Operazioni di backup di SnapCenter</block>
  <block id="d939d79ed61dbf23169c4f7badcc1788" category="list-text">Operazione di backup per un database FCI</block>
  <block id="cb9f91cd2f1ab77ae604d05be34c3d59" category="list-text">Operazione di backup per più database</block>
  <block id="6be8f3086a30e59e908d53eb620b51dd" category="list-text">Ripristino e ripristino</block>
  <block id="9fa83b367c23a5d2579b5aebdddebe77" category="section-title">Configurazione SnapCenter</block>
  <block id="f979bf3f98ebe58fd55555efea856e3f" category="paragraph">Per la configurazione di SnapCenter e la protezione delle risorse di Microsoft SQL Server, è necessario eseguire le seguenti operazioni. Ciascuna delle seguenti fasi è illustrata in dettaglio nelle sezioni seguenti.</block>
  <block id="7c1e7491c7e3588e56a0b05940cc2840" category="list-text">Configurare le credenziali sysadmin per l'utente di backup e ripristino di SQL Server.</block>
  <block id="d6442b5b8ad78236b2966fc5c1191c1e" category="list-text">Configurare le impostazioni di storage. Fornire credenziale di gestione dei servizi Web Amazon (AWS) per accedere alle macchine virtuali storage (SVM) ONTAP di Amazon FSX per NetApp da SnapCenter.</block>
  <block id="bf1e7185f6bb09e0f2b1527acbbb47df" category="list-text">Aggiungere un host SQL Server a SnapCenter. Implementare e installare i plug-in SnapCenter richiesti.</block>
  <block id="1e5b163165e28d2c04a5c2cc25406fa0" category="list-text">Configurare i criteri. Definire il tipo di operazione di backup, la conservazione e la replica di backup Snapshot opzionale.</block>
  <block id="7839511c8247bb78354925ce2771284a" category="list-text">Configurare e proteggere il database Microsoft SQL Server.</block>
  <block id="1719e3b1afdebd05d1f71b0881a7083c" category="section-title">Interfaccia utente SnapCenter appena installata</block>
  <block id="97504cb249856d98431bd413caeb43ce" category="paragraph">Configurare le credenziali per il backup di SQL Server e ripristinare l'utente con diritti sysadmin.</block>
  <block id="cdff526b5e5a4339e5ad188cb61b446f" category="paragraph"><block ref="cdff526b5e5a4339e5ad188cb61b446f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a8b4eaab7153d620e4be3372cee492d" category="paragraph">NetApp consiglia di utilizzare RBAC (Role-Based Access Control) per delegare le funzionalità di gestione e protezione dei dati a singoli utenti attraverso gli host SnapCenter e Window. L'utente deve avere accesso a SQL Server che ospita il database. Per più host, il nome utente e la password devono essere identici tra i vari host. Inoltre, per consentire a SnapCenter di distribuire il plug-in richiesto sugli host SQL Server, è necessario registrare le informazioni di dominio per SnapCenter per convalidare le credenziali e gli host.</block>
  <block id="2f5eb1bcad8467d8b1a3a761e7a52e7c" category="paragraph">Espandere le sezioni seguenti per visualizzare le istruzioni dettagliate su come completare ciascun passaggio.</block>
  <block id="36bc52aaebad43ec3e49ed9a0efacd43" category="example-title">Aggiungere le credenziali</block>
  <block id="994e670ad871a1a1a8968ef47fce1bd2" category="paragraph">Accedere a *Impostazioni*, selezionare *credenziali* e fare clic su (*+*).</block>
  <block id="9816a3711fba5a6da62899f4fa6ce522" category="paragraph"><block ref="9816a3711fba5a6da62899f4fa6ce522" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ef34a5260859bfffb6bf580955ffb1e" category="paragraph">Il nuovo utente deve disporre dei diritti di amministratore sull'host di SQL Server.</block>
  <block id="bcd04483b0b1e054777058931ef7d117" category="paragraph"><block ref="bcd04483b0b1e054777058931ef7d117" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d25223f4065ca21361aff2e7cdc61203" category="example-title">Configurare lo storage</block>
  <block id="8d4520cc707d4607fe5abe132aecdbf2" category="paragraph">Per configurare lo storage in SnapCenter, attenersi alla seguente procedura:</block>
  <block id="17b1ba0b70ebf5f6fcfd2f39e760ac1c" category="list-text">Nell'interfaccia utente di SnapCenter, selezionare *sistemi di storage*. Esistono due tipi di storage, *SVM ONTAP* e *cluster ONTAP*. Per impostazione predefinita, il tipo di storage è *SVM ONTAP*.</block>
  <block id="84bf89b0b19fc811dad7c11f9b65802e" category="list-text">Fare clic su (*+*) per aggiungere le informazioni sul sistema di storage.</block>
  <block id="09710a8bb6b2b53186f42bcfb4cdf2d7" category="paragraph"><block ref="09710a8bb6b2b53186f42bcfb4cdf2d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="517cf06d127b73ca2104c46eedc40e4e" category="list-text">Fornire l'endpoint *FSX per la gestione ONTAP*.</block>
  <block id="ecbf2692688ddd1d8cffae4eb2adae87" category="paragraph"><block ref="ecbf2692688ddd1d8cffae4eb2adae87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c99ac5cbe66f4968da17288cff14037" category="list-text">La SVM è ora configurata in SnapCenter.</block>
  <block id="193ab9cc10d32956324c73a0aad32ece" category="paragraph"><block ref="193ab9cc10d32956324c73a0aad32ece" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f4cf5450244ae3361ec7b130b139860" category="example-title">Aggiungere un host SQL Server a SnapCenter</block>
  <block id="865ea603dd93a3a23cc7e80825b29624" category="paragraph">Per aggiungere un host SQL Server, attenersi alla seguente procedura:</block>
  <block id="e14bea01dc3a10ca47f216a08f68fa85" category="list-text">Dalla scheda host, fare clic su (*+*) per aggiungere l'host Microsoft SQL Server.</block>
  <block id="f2a1bec0c1120023662a8abe57c12c35" category="paragraph"><block ref="f2a1bec0c1120023662a8abe57c12c35" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c802780a0f54f5e4f22e25de9fa33be" category="list-text">Fornire il nome di dominio completo (FQDN) o l'indirizzo IP dell'host remoto.</block>
  <block id="fb62a23910339f3168b6b89b4e0f77b7" category="admonition">Le credenziali vengono popolate per impostazione predefinita.</block>
  <block id="65d9345f77faaa3bf7bb8031bb92f814" category="list-text">Selezionare l'opzione Microsoft Windows e Microsoft SQL Server, quindi inviare.</block>
  <block id="42a8898b70e0495a43f4df86d0f689cd" category="paragraph"><block ref="42a8898b70e0495a43f4df86d0f689cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53b2d796e625fe393f84e48a5c6c6e91" category="paragraph">I pacchetti di SQL Server sono installati.</block>
  <block id="b7778c4b2da8a542de9529435e8ec22a" category="paragraph"><block ref="b7778c4b2da8a542de9529435e8ec22a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af3617c8e674a62860e153751b1b62d8" category="list-text">Al termine dell'installazione, accedere alla scheda *risorsa* per verificare la presenza di tutti i volumi iSCSI FSX per ONTAP.</block>
  <block id="c919f693c37c2d168175e649e14c3293" category="paragraph"><block ref="c919f693c37c2d168175e649e14c3293" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b83af25a71030e8f59b11202c70c1a4" category="example-title">Configurare la directory del registro</block>
  <block id="144931b7282f9d86fce2e97aa69aa046" category="paragraph">Per configurare una directory del registro host, attenersi alla seguente procedura:</block>
  <block id="089f0c00b86bab7c6ce3e455e39b4111" category="list-text">Fare clic sulla casella di controllo. Viene visualizzata una nuova scheda.</block>
  <block id="a4ce6f0dbf75e4ef516f57614792a907" category="paragraph"><block ref="a4ce6f0dbf75e4ef516f57614792a907" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57fab4c72318fea3bba8b3c321098ab3" category="list-text">Fare clic sul collegamento *configure log directory*.</block>
  <block id="d6c8cb16951a3c787db9f20c0fb09057" category="paragraph"><block ref="d6c8cb16951a3c787db9f20c0fb09057" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1b06cca5c441f86e0c4ad342dc4949c5" category="list-text">Selezionare l'unità per la directory del log host e la directory del log dell'istanza FCI. Fare clic su *Save* (Salva). Ripetere la stessa procedura per il secondo nodo del cluster. Chiudere la finestra.</block>
  <block id="24519841c3d33e14f5bb7d209d673a35" category="paragraph"><block ref="24519841c3d33e14f5bb7d209d673a35" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c36dc3499eaa7955922477da928c37d" category="paragraph">L'host si trova ora in uno stato di esecuzione.</block>
  <block id="820630e9a1c808068eda3661f49042cf" category="paragraph"><block ref="820630e9a1c808068eda3661f49042cf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21ff17f2a463836d33f1c25b922e2aad" category="list-text">Dalla scheda *risorse*, abbiamo tutti i server e i database.</block>
  <block id="076c245e9e02588c21d76bd30de179dd" category="paragraph"><block ref="076c245e9e02588c21d76bd30de179dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e2457547c492c6001e30b828b6540e" category="section-title">Configurare un criterio di backup</block>
  <block id="febe42e6f9b7fb03483725eb94b7dc4f" category="paragraph">Un criterio di backup è un insieme di regole che regolano la gestione, la pianificazione e la conservazione del backup. Aiuta con il tipo e la frequenza di backup in base allo SLA della tua azienda.</block>
  <block id="e28ebacaa4299d5022a9ce52d607c076" category="example-title">Configurare l'operazione di backup per un database FCI</block>
  <block id="41cc72961a6c592ec36223498c3bd705" category="paragraph">Per configurare un criterio di backup per un database FCI, attenersi alla seguente procedura:</block>
  <block id="55e9263abc7e93fbc1274424af911693" category="list-text">Vai a *Impostazioni* e seleziona *Criteri* in alto a sinistra. Quindi fare clic su *nuovo*.</block>
  <block id="adf5449547fda2e595556e9d231a2066" category="paragraph"><block ref="adf5449547fda2e595556e9d231a2066" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00f0ce22eac68a6bd05a1b0f221c4870" category="list-text">Immettere il nome e la descrizione del criterio. Fare clic su *Avanti*.</block>
  <block id="f2eb0a484f9105201d7b6af1e010db00" category="paragraph"><block ref="f2eb0a484f9105201d7b6af1e010db00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55efa7fad4afc963d783654da41300bf" category="list-text">Selezionare *Backup completo* come tipo di backup.</block>
  <block id="23b0ad9ad1f66315e2659ed3b39e490e" category="paragraph"><block ref="23b0ad9ad1f66315e2659ed3b39e490e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8270c99b48ebbc3928233b0365c4aeef" category="list-text">Selezionare la frequenza di pianificazione (in base allo SLA aziendale). Fare clic su *Avanti*.</block>
  <block id="24207525bc0e567d54fbd4c12e87169e" category="paragraph"><block ref="24207525bc0e567d54fbd4c12e87169e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="de3ec07218c2ba18d85a3130b6583520" category="list-text">Configurare le impostazioni di conservazione per il backup.</block>
  <block id="b05832e4c7bab22b79bc5802800a0dab" category="paragraph"><block ref="b05832e4c7bab22b79bc5802800a0dab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e0b22898b3d80ad22f4aec2ecdb63d6" category="list-text">Configurare le opzioni di replica.</block>
  <block id="14b05e91fa711b3a9719853be184206c" category="paragraph"><block ref="14b05e91fa711b3a9719853be184206c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44ea4d24c42b8fec22a7b9816f31e892" category="list-text">Specificare uno script di esecuzione da eseguire prima e dopo l'esecuzione di un processo di backup (se presente).</block>
  <block id="eac922e5175c542119573b500882c077" category="paragraph"><block ref="eac922e5175c542119573b500882c077" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b94cb3e0f4abcd010f6711fe214e35a" category="list-text">Eseguire la verifica in base alla pianificazione del backup.</block>
  <block id="4608b019002a2c4ec256372aa8480a1a" category="paragraph"><block ref="4608b019002a2c4ec256372aa8480a1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbfa414efc5d445675fd9077ba0c56b3" category="list-text">La pagina *Summary* fornisce i dettagli della policy di backup. Gli eventuali errori possono essere corretti qui.</block>
  <block id="b8b8dbdb6cb7e67fa35e47b550da474f" category="paragraph"><block ref="b8b8dbdb6cb7e67fa35e47b550da474f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8e93df919756b105bc83306d032d098" category="section-title">Configurare e proteggere il database di MSSQL Server</block>
  <block id="27db30e5a59f8be2fcb99cf63599a91c" category="list-text">Impostare la data di inizio e la data di scadenza del criterio di backup.</block>
  <block id="34dd0aa3564bb913360badbaaaa83faa" category="paragraph"><block ref="34dd0aa3564bb913360badbaaaa83faa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="db43ab486fbd21378315f50453a84170" category="list-text">Definire la pianificazione del backup. A tale scopo, fare clic su (*+*) per configurare una pianificazione. Inserire la data *inizio* e *scadenza*. Impostare l'ora in base allo SLA dell'azienda.</block>
  <block id="f27c76657d54395e925b36cbee1be886" category="paragraph"><block ref="f27c76657d54395e925b36cbee1be886" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cae5bd999deab910421c886467a77f95" category="list-text">Configurare il server di verifica. Dal menu a discesa, selezionare il server.</block>
  <block id="1984132ea5425099c6b2573e487c3814" category="paragraph"><block ref="1984132ea5425099c6b2573e487c3814" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eafe5ed3ae193bf0df0699f63047967c" category="list-text">Confermare la pianificazione configurata facendo clic sul segno più e confermare.</block>
  <block id="acbb9c633debb26a3e087f175b289654" category="list-text">Fornire informazioni per la notifica via email. Fare clic su *Avanti*.</block>
  <block id="6da5c045f179e9f4b7f9a93a743e59bb" category="paragraph"><block ref="6da5c045f179e9f4b7f9a93a743e59bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12c3e31e09364bc821b8b38bfe3fa90b" category="paragraph">Il riepilogo dei criteri di backup per il database di SQL Server è ora configurato.</block>
  <block id="2da07f989d7b3e93f17cf4dc6237a9ff" category="paragraph"><block ref="2da07f989d7b3e93f17cf4dc6237a9ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f93a0490c2398c42ac8bc4c8027da25b" category="paragraph">Per creare backup di SQL Server on-demand, attenersi alla seguente procedura:</block>
  <block id="a27b159fa260ee860202b1a37efb3a24" category="list-text">Dalla vista *Resource*, selezionare la risorsa e selezionare *Backup now*.</block>
  <block id="1d8d5b0070c26adc7cbd7d50e2ad9bd4" category="paragraph"><block ref="1d8d5b0070c26adc7cbd7d50e2ad9bd4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8ebbd547f5d127b496961a116deba1b" category="list-text">Nella finestra di dialogo *Backup*, fare clic su *Backup*.</block>
  <block id="ec9b7af4f9e32bbcc3462f3f0651d17e" category="paragraph"><block ref="ec9b7af4f9e32bbcc3462f3f0651d17e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28a70f29b174bb67f6ba18c34afe8917" category="list-text">Viene visualizzata una schermata di conferma. Fare clic su *Sì* per confermare.</block>
  <block id="aa3b467bd6d728ef126ee24085996989" category="paragraph"><block ref="aa3b467bd6d728ef126ee24085996989" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f8452076484ec284c5858e0a7826acc" category="section-title">Monitorare il processo di backup</block>
  <block id="3c171063c0a7e42fe17578dc53e1a362" category="list-text">Dalla scheda *Monitor*, fare clic sul lavoro e selezionare *Dettagli* a destra per visualizzare i lavori.</block>
  <block id="0a5505b752196a5d3967276a8e020bec" category="paragraph"><block ref="0a5505b752196a5d3967276a8e020bec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a78488fda38cb0f6c33d06d8774309cb" category="paragraph"><block ref="a78488fda38cb0f6c33d06d8774309cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="187d97d7f4855a2e10ce27f378db96dd" category="paragraph">Una volta completato il backup, viene visualizzata una nuova voce nella vista topologia.</block>
  <block id="134678acd20d853075ff197c7c9c3fcb" category="paragraph">Per configurare un criterio di backup per più database di SQL Server, creare i criteri del gruppo di risorse completando la seguente procedura:</block>
  <block id="95fea20057274bffe889a463c6617053" category="list-text">Nella scheda *risorse* del menu *Visualizza*, passare a un gruppo di risorse utilizzando il menu a discesa.</block>
  <block id="5179400c083eea1a5c874c9ced10a4f3" category="paragraph"><block ref="5179400c083eea1a5c874c9ced10a4f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d30ce7f1b8370331622f388e31ba9fd" category="list-text">Fare clic su (*+*) per visualizzare un nuovo gruppo di risorse.</block>
  <block id="29b5c325b4a3721982a139efeaa22354" category="paragraph"><block ref="29b5c325b4a3721982a139efeaa22354" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2267ba30d8bc4b2cb24be81ba224b9a0" category="list-text">Fornire un nome e un tag. Fare clic su *Avanti*.</block>
  <block id="49a74a15bbe124a186a4b3154b4d2b61" category="paragraph"><block ref="49a74a15bbe124a186a4b3154b4d2b61" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71128d86107d5d3be141764b52ec6e0a" category="list-text">Aggiungere risorse al gruppo di risorse:</block>
  <block id="6938eb21ffd3468679899baee35fc02c" category="list-text">*Host.* selezionare il server dal menu a discesa che ospita il database.</block>
  <block id="d9cab3ec910c4d091f194a6fbe1ce649" category="list-text">*Tipo di risorsa.* dal menu a discesa, selezionare *Database*.</block>
  <block id="9d00adb9ff02c740bad1655a08befbc8" category="list-text">*Istanza di SQL Server.* selezionare il server.</block>
  <block id="e5b057829741e7d66ccb84dd34659d15" category="paragraph"><block ref="e5b057829741e7d66ccb84dd34659d15" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52cbd1487d8eb5aca62ae227f26154cd" category="paragraph">Per impostazione predefinita, l'opzione *opzione* Auto seleziona tutte le risorse dallo stesso volume di storage*. Deselezionare l'opzione e selezionare solo i database da aggiungere al gruppo di risorse, fare clic sulla freccia per aggiungere e fare clic su *Avanti*.</block>
  <block id="a390f1ac44166070ca9168d6db494a3c" category="paragraph"><block ref="a390f1ac44166070ca9168d6db494a3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bc914d30c298d5a1be5b17d60f91d32" category="list-text">Nei criteri, fare clic su (*+*).</block>
  <block id="c8012ccb0cf9aea5ab3d75c5946839bc" category="paragraph"><block ref="c8012ccb0cf9aea5ab3d75c5946839bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0503c62843919fd6d77d98333ddc0d46" category="list-text">Immettere il nome del criterio del gruppo di risorse.</block>
  <block id="773774cec41f86cf7c812856bb5532f4" category="paragraph"><block ref="773774cec41f86cf7c812856bb5532f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="84c7b78e63b4d35a0da59b9c1547859f" category="list-text">Selezionare *Backup completo* e la frequenza di pianificazione in base allo SLA aziendale.</block>
  <block id="439033b0e525dcfb01f503bce465bab7" category="paragraph"><block ref="439033b0e525dcfb01f503bce465bab7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3d3f39805e6cab1e0c8e41e3a8045d4" category="list-text">Configurare le impostazioni di conservazione.</block>
  <block id="b33d774bbfed75c94879fc316e7bcd21" category="paragraph"><block ref="b33d774bbfed75c94879fc316e7bcd21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d3b49aed2989d78ff906ce8d5d3dd65" category="paragraph"><block ref="0d3b49aed2989d78ff906ce8d5d3dd65" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b438cf4e498dc0e4f65b8cf167949153" category="list-text">Configurare gli script da eseguire prima di eseguire un backup. Fare clic su *Avanti*.</block>
  <block id="cf4f12ed143c80bc6af35a01c1fe98be" category="paragraph"><block ref="cf4f12ed143c80bc6af35a01c1fe98be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6504e635a92d1b0a8c52749c309ce7f6" category="list-text">Confermare la verifica per le seguenti pianificazioni di backup.</block>
  <block id="30f1d3b33a552e64394acbb9a8039813" category="paragraph"><block ref="30f1d3b33a552e64394acbb9a8039813" category="inline-image-macro-rx" type="image"></block></block>
  <block id="06919ef230a779cfc26a7b40e58c155f" category="list-text">Nella pagina *Riepilogo*, verificare le informazioni e fare clic su *fine*.</block>
  <block id="6ec4de8e33fceb0e3382dbba9a3e7fef" category="paragraph"><block ref="6ec4de8e33fceb0e3382dbba9a3e7fef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03db038251d30409b163cac10e15fb64" category="section-title">Configurare e proteggere più database SQL Server</block>
  <block id="60d1f006544fc2635c785f35a2bb75fa" category="list-text">Fare clic sul segno (*+*) per configurare la data di inizio e la data di scadenza.</block>
  <block id="90a0be0d18aa1385f7d629b041ec3586" category="paragraph"><block ref="90a0be0d18aa1385f7d629b041ec3586" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1709dfd12096305753ee7705ead06515" category="list-text">Impostare l'ora.</block>
  <block id="abce8a42e2fe798102907c89873652ff" category="paragraph"><block ref="abce8a42e2fe798102907c89873652ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="34af8b580bd3f78a0594fd1a6ed33f72" category="paragraph"><block ref="34af8b580bd3f78a0594fd1a6ed33f72" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1dc4c7af7fe0f51e864695931afcc5d" category="list-text">Dalla scheda *verifica*, selezionare il server, configurare la pianificazione e fare clic su *Avanti*.</block>
  <block id="0a04449841d608c1b828876aade9dd57" category="paragraph"><block ref="0a04449841d608c1b828876aade9dd57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b91c4ea39a59e7c5891197a3b275c62c" category="list-text">Configurare le notifiche per l'invio di un'e-mail.</block>
  <block id="c9d11c4594f1660f0438901255de824c" category="paragraph"><block ref="c9d11c4594f1660f0438901255de824c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="017b37b38c310ea0d90dccec6f86d049" category="paragraph">Il criterio è ora configurato per il backup di più database SQL Server.</block>
  <block id="7a6908a4518e7d0a99f7991bcede071d" category="paragraph"><block ref="7a6908a4518e7d0a99f7991bcede071d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86b13e5f17a2bd60ebf403962a656abb" category="section-title">Attivare il backup on-demand per più database SQL Server</block>
  <block id="f7dde35cb7209b4eae92eb8ec9dbe3ea" category="list-text">Dalla scheda *Resource*, selezionare view (Visualizza). Dal menu a discesa, selezionare *Gruppo di risorse*.</block>
  <block id="9179022dda578f3bced2dd96da8c87ff" category="paragraph"><block ref="9179022dda578f3bced2dd96da8c87ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdbf213e9f1bcad7fef14029eb9b537b" category="list-text">Selezionare il nome del gruppo di risorse.</block>
  <block id="1ac4dec59e8f8197fb29b8bfa0237d91" category="list-text">Fare clic su *Backup now* in alto a destra.</block>
  <block id="1cecf31da10780e2d39609c010d3df62" category="paragraph"><block ref="1cecf31da10780e2d39609c010d3df62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d29aeb4de3166648265a417a3ebdfa8d" category="list-text">Viene visualizzata una nuova finestra. Fare clic sulla casella di controllo *Verify after backup* (verifica dopo il backup), quindi fare clic su backup.</block>
  <block id="9e877656fc311f532df6e62273e160d5" category="paragraph"><block ref="9e877656fc311f532df6e62273e160d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1b01a18ba54b03ab361195cda9e11a04" category="list-text">Viene visualizzato un messaggio di conferma. Fare clic su *Sì*.</block>
  <block id="06ec3c59d97a4c7d9984adda2108135e" category="paragraph"><block ref="06ec3c59d97a4c7d9984adda2108135e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c39edf183648c1d5db4f2c93fb4eb28" category="section-title">Monitorare più processi di backup dei database</block>
  <block id="1010c73c274c132c818aa34d45372dd5" category="paragraph">Dalla barra di navigazione a sinistra, fare clic su *Monitor*, selezionare il processo di backup e fare clic su *Dettagli* per visualizzare l'avanzamento del processo.</block>
  <block id="50d14527999ad5610803d042f0537b0b" category="paragraph"><block ref="50d14527999ad5610803d042f0537b0b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf2af39d79fe9b75d3b016a40a1cb886" category="paragraph">Fare clic sulla scheda *Resource* per visualizzare il tempo necessario per il completamento del backup.</block>
  <block id="e1aa3da997feec6419955ef32aa87bdc" category="paragraph"><block ref="e1aa3da997feec6419955ef32aa87bdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b702b14abe98f98e647cd791bcb90f8d" category="section-title">Backup del log delle transazioni per il backup di più database</block>
  <block id="26d8c1709e6a02cee73b16f5c2acf6dc" category="paragraph">SnapCenter supporta i modelli di ripristino semplici, completi e con registrazione bulked. La modalità di ripristino semplice non supporta il backup del registro transazionale.</block>
  <block id="a60ccf2e4a30da040f5a49732187a6b7" category="paragraph">Per eseguire un backup del log delle transazioni, attenersi alla seguente procedura:</block>
  <block id="be7235e7e6dc252e8daebedf54c3b6c7" category="list-text">Dalla scheda *risorse*, modificare il menu di visualizzazione da *Database* a *Gruppo di risorse*.</block>
  <block id="e0fa4309d306e577eb4ee7fae977e8ec" category="paragraph"><block ref="e0fa4309d306e577eb4ee7fae977e8ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c48d8cc9d4f748c135f5b4812c1d7412" category="list-text">Selezionare il criterio di backup del gruppo di risorse creato.</block>
  <block id="f38bbe0d9131c48ea9ee602675754140" category="list-text">Selezionare *Modify Resource Group* (Modifica gruppo di risorse) in alto a destra.</block>
  <block id="2c49b9da12e1f8828a27c12785ae9fc3" category="paragraph"><block ref="2c49b9da12e1f8828a27c12785ae9fc3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d4b5ab9594400df9f8e77cbab0abea7" category="list-text">Per impostazione predefinita, la sezione *Nome* utilizza il nome e il tag del criterio di backup. Fare clic su *Avanti*.</block>
  <block id="9a35ea0c782dad0d67865885d193f274" category="paragraph">La scheda *risorse* evidenzia le basi in cui deve essere configurato il criterio di backup delle transazioni.</block>
  <block id="11b8d03d27b3abc5c6b6e021930b3e9e" category="paragraph"><block ref="11b8d03d27b3abc5c6b6e021930b3e9e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6daf111fad11fdef17162a8f8bf18b9c" category="list-text">Immettere il nome del criterio.</block>
  <block id="22f2c4c423feb263d1b0200d62e77858" category="paragraph"><block ref="22f2c4c423feb263d1b0200d62e77858" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f993771df9dbe7cf6b38a0f84b409d7" category="list-text">Selezionare le opzioni di backup di SQL Server.</block>
  <block id="ac47af84d5357e6141e59c1659b4ffb1" category="list-text">Selezionare log backup (backup registro).</block>
  <block id="1cf75fb83a264d296888dbfc66c1e24c" category="list-text">Impostare la frequenza di pianificazione in base all'RTO aziendale. Fare clic su *Avanti*.</block>
  <block id="3da946d8c357e8d3ba7d9dee6d9c48fc" category="paragraph"><block ref="3da946d8c357e8d3ba7d9dee6d9c48fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6a1a00356a0947050a129ae89c585c9" category="list-text">Configurare le impostazioni di conservazione del backup del registro. Fare clic su *Avanti*.</block>
  <block id="eca8085a550a32e2ea75af78dde57b58" category="paragraph"><block ref="eca8085a550a32e2ea75af78dde57b58" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46caf3d6b884d110f60cf7f4937e7519" category="list-text">(Facoltativo) configurare le opzioni di replica.</block>
  <block id="6e942622a4fc392b1c732fcb6128144f" category="paragraph"><block ref="6e942622a4fc392b1c732fcb6128144f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1a4bc0234ce8dfcbb64e7eeee67fad6" category="list-text">(Facoltativo) configurare gli script da eseguire prima di eseguire un processo di backup.</block>
  <block id="b1537af3c8af0a513d927136e6069e69" category="paragraph"><block ref="b1537af3c8af0a513d927136e6069e69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec35f0f916d59604b82ba19007187115" category="list-text">(Facoltativo) configurare la verificazione del backup.</block>
  <block id="a5b416c5101ea80de98741569ba40ad8" category="paragraph"><block ref="a5b416c5101ea80de98741569ba40ad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4a7ecfa93fa04065caa7a2ead6d3d113" category="list-text">Nella pagina *Riepilogo*, fare clic su *fine*.</block>
  <block id="85f4218eb49261c9a10c3ae757a7673e" category="paragraph"><block ref="85f4218eb49261c9a10c3ae757a7673e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21c62f698c67203ca218e38cedd9fd4a" category="section-title">Configurare e proteggere più database MSSQL Server</block>
  <block id="851434acbe50444b77cc093290088e54" category="list-text">Fare clic sul criterio di backup del registro delle transazioni appena creato.</block>
  <block id="aab3313d777fdf9a008349b1c52a3b38" category="paragraph"><block ref="aab3313d777fdf9a008349b1c52a3b38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8dc5a42c40277ce2884bea86757d8dda" category="list-text">Impostare la data *inizio* e *scadenza*.</block>
  <block id="2137cef28d44fe16621167c38bd398e5" category="list-text">Inserire la frequenza del criterio di backup del registro in base a SLA, RTP e RPO. Fare clic su OK.</block>
  <block id="699cfd55473b1a08a3afc68cdd6c0bc0" category="paragraph"><block ref="699cfd55473b1a08a3afc68cdd6c0bc0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eef345e42eb1ff7b7177a232bb1d1247" category="list-text">È possibile visualizzare entrambi i criteri. Fare clic su *Avanti*.</block>
  <block id="f0f5bc22b5d1f8a0d6c00b4127875d56" category="paragraph"><block ref="f0f5bc22b5d1f8a0d6c00b4127875d56" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d3d450b94383f42a06333f58c0ffb5a" category="list-text">Configurare il server di verifica.</block>
  <block id="df8d18ae668699fdea57fa8103444b04" category="paragraph"><block ref="df8d18ae668699fdea57fa8103444b04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9b705cea4d9eb8b1497ffce97bfe3609" category="list-text">Configurare la notifica via email.</block>
  <block id="46e4cfc3ee8ac0fcf4621b3b601fae9e" category="paragraph"><block ref="46e4cfc3ee8ac0fcf4621b3b601fae9e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="722243257c592026b8405ff352c17887" category="paragraph"><block ref="722243257c592026b8405ff352c17887" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ea4baaafde2e79cfcd31d97b84b1a12" category="section-title">Attivazione di un backup del log delle transazioni on-demand per diversi database SQL Server</block>
  <block id="a75cd7342eb195ccea0a0f5ef399cb13" category="paragraph">Per attivare un backup on-demand del log transazionale per più database di SQL Server, attenersi alla seguente procedura:</block>
  <block id="f790ac7cb18962dff9c720679845e234" category="list-text">Nella pagina policy appena creata, selezionare *Backup now* (Esegui backup ora) in alto a destra nella pagina.</block>
  <block id="44991ec351e06a97a765cfca75d312af" category="paragraph"><block ref="44991ec351e06a97a765cfca75d312af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1552095f0c2d2521f14458e1899ee71b" category="list-text">Dalla finestra a comparsa della scheda *Policy*, selezionare il menu a discesa, selezionare il criterio di backup e configurare il backup del log delle transazioni.</block>
  <block id="5baef8fc5a836fc8dce7a8277d0ebc84" category="paragraph"><block ref="5baef8fc5a836fc8dce7a8277d0ebc84" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0df35ef9b242c9f422a4cc2e1784903" category="list-text">Fare clic su *Backup*. Viene visualizzata una nuova finestra.</block>
  <block id="b16f685ee226b95caaad151608f96a19" category="list-text">Fare clic su *Sì* per confermare la policy di backup.</block>
  <block id="a8f620ad18e6f3f85da2b7be0f178e00" category="paragraph"><block ref="a8f620ad18e6f3f85da2b7be0f178e00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d0ccd5722bd3156105a495a57a9fcc19" category="paragraph">Passare alla scheda *Monitoring* e monitorare l'avanzamento del processo di backup.</block>
  <block id="1a289d2ae0641f0084f363bc4bf29ed2" category="paragraph"><block ref="1a289d2ae0641f0084f363bc4bf29ed2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a4a58eef11580db01b6b09289a7975b6" category="paragraph">Vedere i seguenti prerequisiti necessari per il ripristino di un database SQL Server in SnapCenter.</block>
  <block id="7ddc4eb994d251e5502d17ee020d88ad" category="list-text">L'istanza di destinazione deve essere in linea e in esecuzione prima del completamento di un processo di ripristino.</block>
  <block id="4c5a871f473eb2bc6ade24dc7c9abda4" category="list-text">Le operazioni SnapCenter pianificate per l'esecuzione sul database SQL Server devono essere disattivate, inclusi i processi pianificati su server di verifica remoti o di gestione remota.</block>
  <block id="542e99a23c6a8ebaa0cc7df2db932223" category="list-text">Se si ripristinano i backup personalizzati della directory di log su un host alternativo, il server SnapCenter e l'host del plug-in devono avere la stessa versione di SnapCenter installata.</block>
  <block id="81ec57bf05a69240771c922d647a651c" category="list-text">È possibile ripristinare il database di sistema su un host alternativo.</block>
  <block id="ec5b173df4b3313050ca64425e06f516" category="list-text">SnapCenter può ripristinare un database in un cluster Windows senza disattivare il gruppo di cluster di SQL Server.</block>
  <block id="042d132354b0d48ad24ee674bebdb6af" category="section-title">Ripristino delle tabelle eliminate in un database SQL Server a un punto temporale</block>
  <block id="4b4968094e7a3d8c79f9bc8caa8b22e4" category="paragraph">Per ripristinare un database SQL Server a un punto temporale, attenersi alla seguente procedura:</block>
  <block id="6df13174e00d0f623a406e9148d1548c" category="list-text">La seguente schermata mostra lo stato iniziale del database SQL Server prima delle tabelle eliminate.</block>
  <block id="dbc2a72710499aa1cf69652093b3b999" category="paragraph"><block ref="dbc2a72710499aa1cf69652093b3b999" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d61cd88cd62206db3a9f9cab1565d3ad" category="paragraph">La schermata mostra che 20 righe sono state eliminate dalla tabella.</block>
  <block id="515d7eb17c3e413f271bddce4ba5f6bd" category="paragraph"><block ref="515d7eb17c3e413f271bddce4ba5f6bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d3c565402042673af1d4898a8ff52a9" category="list-text">Accedere al server SnapCenter. Dalla scheda *risorse*, selezionare il database.</block>
  <block id="4863869b2ef5500a5ca305ffb9127ade" category="paragraph"><block ref="4863869b2ef5500a5ca305ffb9127ade" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a69269402d35f0cccddfd918911a97d9" category="list-text">Selezionare il backup più recente.</block>
  <block id="583e868d2c26244722b015fea16af076" category="list-text">A destra, selezionare *Restore* (Ripristina).</block>
  <block id="6b153885f2f75c1ff541921d0081d74b" category="paragraph"><block ref="6b153885f2f75c1ff541921d0081d74b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39435af0deb93996df3394c1b2036fd8" category="list-text">Viene visualizzata una nuova finestra. Selezionare l'opzione *Restore*.</block>
  <block id="d7020dd530a8bef5050168b840079b00" category="list-text">Ripristinare il database sullo stesso host in cui è stato creato il backup. Fare clic su *Avanti*.</block>
  <block id="5a718f24061d92ae97e1314ea8cb5fde" category="paragraph"><block ref="5a718f24061d92ae97e1314ea8cb5fde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="503e2d366ad9c17a4f549670670ad33e" category="list-text">Per il tipo di ripristino, selezionare *All log backups* (tutti i backup del registro). Fare clic su *Avanti*.</block>
  <block id="979629b8cf5823b370da8e731560f8cb" category="paragraph"><block ref="979629b8cf5823b370da8e731560f8cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68a3564e8eebf683090a9b209db57831" category="paragraph"><block ref="68a3564e8eebf683090a9b209db57831" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e63cae13f4b41b3fe8c7e3fec3319f06" category="paragraph">*Opzioni di pre-ripristino:*</block>
  <block id="de181095a646159b289fbcdbcf419e7b" category="list-text">Selezionare l'opzione *sovrascrivere il database con lo stesso nome durante il ripristino*. Fare clic su *Avanti*.</block>
  <block id="ad55b8f82ca21417dc4da683b1de0924" category="paragraph"><block ref="ad55b8f82ca21417dc4da683b1de0924" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed71c6a01179057b2d9bf0077204c6b" category="paragraph">*Opzioni di post-ripristino:*</block>
  <block id="9cfc344a514e0de0c6b807382b26c075" category="list-text">Selezionare l'opzione *operativo, ma non disponibile per il ripristino di ulteriori registri delle transazioni*. Fare clic su *Avanti*.</block>
  <block id="3ca7aa8d51b34a6dc37b4a42b98be1fe" category="paragraph"><block ref="3ca7aa8d51b34a6dc37b4a42b98be1fe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8420a5fc7b326a91c636b314aa454ec6" category="list-text">Fornire le impostazioni e-mail. Fare clic su *Avanti*.</block>
  <block id="735c30c428c3e84050f483061752691e" category="paragraph"><block ref="735c30c428c3e84050f483061752691e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8778317b34992e7e7c0354762cf0db9f" category="paragraph"><block ref="8778317b34992e7e7c0354762cf0db9f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4506debb4b8eeba79855725078a52afb" category="section-title">Monitoraggio dell'avanzamento del ripristino</block>
  <block id="9aff1c679025b15fa483f8f730686633" category="list-text">Dalla scheda *Monitoring* (monitoraggio), fare clic sui dettagli del processo di ripristino per visualizzare l'avanzamento del processo di ripristino.</block>
  <block id="1e062bc4b91bf77257da0f6d3b81e64d" category="paragraph"><block ref="1e062bc4b91bf77257da0f6d3b81e64d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2f265e204d2aa866e88f009e207aa68" category="list-text">Ripristinare i dettagli del lavoro.</block>
  <block id="1a50192540a2e763a60070967a8a04fd" category="paragraph"><block ref="1a50192540a2e763a60070967a8a04fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c5d988b8258420ba376fd703ae323bd" category="list-text">Torna all'host SQL Server &gt; database &gt; tabella sono presenti.</block>
  <block id="f3048bb52b66a41d7be00e28a6eaf957" category="paragraph"><block ref="f3048bb52b66a41d7be00e28a6eaf957" category="inline-image-macro-rx" type="image"></block></block>
  <block id="425103b894468ffe6015f984f2683d74" category="inline-link">TR-4714: Guida alle Best practice per Microsoft SQL Server con NetApp SnapCenter</block>
  <block id="9c42feba6d2410200720e2ceda752e13" category="list-text"><block ref="9c42feba6d2410200720e2ceda752e13" category="inline-link-rx"></block></block>
  <block id="ee50ef71e7fa5dbc3292cb856c5f8ee5" category="inline-link"><block ref="ee50ef71e7fa5dbc3292cb856c5f8ee5" category="inline-link-rx"></block></block>
  <block id="822d30d1b5bfcb219aa830739d5b89a0" category="paragraph"><block ref="822d30d1b5bfcb219aa830739d5b89a0" category="inline-link-rx"></block></block>
  <block id="818095849ac39056a1077a0f3a155684" category="inline-link">Requisiti per il ripristino di un database</block>
  <block id="0305a2a48c225d49081b5bccd776b23d" category="list-text"><block ref="0305a2a48c225d49081b5bccd776b23d" category="inline-link-rx"></block></block>
  <block id="9f413d2e154ecad28af03b6125df6837" category="inline-link"><block ref="9f413d2e154ecad28af03b6125df6837" category="inline-link-rx"></block></block>
  <block id="98c7a90e9f834e61987ed9dd4072a0f3" category="paragraph"><block ref="98c7a90e9f834e61987ed9dd4072a0f3" category="inline-link-rx"></block></block>
  <block id="9b256b378583dbf8a4aea7e4d96460ff" category="list-text">Comprendere i cicli di vita dei database clonati</block>
  <block id="a35c63f82a8b880dd7d77b8868394548" category="inline-link"><block ref="a35c63f82a8b880dd7d77b8868394548" category="inline-link-rx"></block></block>
  <block id="622d6fd30919e1009adf5b3b6a9b61c4" category="paragraph"><block ref="622d6fd30919e1009adf5b3b6a9b61c4" category="inline-link-rx"></block></block>
  <block id="a10998cc3e1dc7f2a013754d935c4f26" category="summary">Il tool NetApp SnapCenter utilizza RBAC (role based access control) per gestire l'accesso alle risorse utente e le autorizzazioni concesse, mentre l'installazione di SnapCenter crea ruoli prepopolati. Puoi anche creare ruoli personalizzati in base alle tue esigenze o alle tue applicazioni.</block>
  <block id="7e3b07f9add4cd78ade3c795a52dfad2" category="doc">Introduzione on-premise</block>
  <block id="32229cff9e0b41c513b3e3b9e19cec88" category="inline-link-macro">Precedente: Panoramica introduttiva.</block>
  <block id="6be036b00e3db4159514171a989cacd6" category="paragraph"><block ref="6be036b00e3db4159514171a989cacd6" category="inline-link-macro-rx"></block></block>
  <block id="d30e54646ba482722332f48ddc22bde5" category="section-title">1. Configurare l'utente amministratore del database in SnapCenter</block>
  <block id="72f706d19ed0d09889b4fbc7578cd1a3" category="paragraph">Il tool NetApp SnapCenter utilizza RBAC (role-based access control) per gestire l'accesso alle risorse utente e le autorizzazioni concesse, mentre l'installazione di SnapCenter crea ruoli prepopolati. Puoi anche creare ruoli personalizzati in base alle tue esigenze o alle tue applicazioni. È opportuno disporre di un ID utente admin dedicato per ciascuna piattaforma di database supportata da SnapCenter per il backup, il ripristino e/o il disaster recovery del database. È inoltre possibile utilizzare un unico ID per gestire tutti i database. Nei nostri test case e dimostrazioni, abbiamo creato un utente amministratore dedicato per Oracle e SQL Server, rispettivamente.</block>
  <block id="27733e8f07432bb94ac7621b28d3b2c8" category="paragraph">Alcune risorse SnapCenter possono essere fornite solo con il ruolo SnapCenterAdmin. Le risorse possono quindi essere assegnate ad altri ID utente per l'accesso.</block>
  <block id="64784aa3cec13e83af6e941f8489cf06" category="paragraph">In un ambiente SnapCenter on-premise preinstallato e configurato, le seguenti attività potrebbero essere già state completate. In caso contrario, i seguenti passaggi creano un utente amministratore del database:</block>
  <block id="c8867eac833e7bb55520105b00139f1a" category="list-text">Aggiungere l'utente amministratore a Windows Active Directory.</block>
  <block id="dd3e743eb52cbe7c2b6104573a9767e0" category="list-text">Accedere a SnapCenter utilizzando un ID concesso con il ruolo SnapCenterAdmin.</block>
  <block id="a6bd76cb24271ba173d16f01bf4108d0" category="list-text">Accedere alla scheda Access (accesso) in Settings and Users (Impostazioni e utenti) e fare clic su Add (Aggiungi) per aggiungere un nuovo utente. Il nuovo ID utente è collegato all'utente amministratore creato in Active Directory di Windows nel passaggio 1. . Assegnare all'utente il ruolo appropriato in base alle necessità. Assegnare le risorse all'utente amministratore in base alle esigenze.</block>
  <block id="6a67bb048bd14dd348cca7f81b62d699" category="paragraph"><block ref="6a67bb048bd14dd348cca7f81b62d699" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5d2c51e83f473f137861a132554d1916" category="section-title">2. Prerequisiti per l'installazione del plug-in SnapCenter</block>
  <block id="7bd973d4d28d6fcf5f50379b33a49758" category="paragraph">SnapCenter esegue il backup, il ripristino, la clonazione e altre funzioni utilizzando un agente plug-in in esecuzione sugli host DB. Si connette all'host del database e al database tramite credenziali configurate nella scheda Impostazioni e credenziali per l'installazione del plug-in e altre funzioni di gestione. Esistono requisiti specifici per i privilegi in base al tipo di host di destinazione, ad esempio Linux o Windows, nonché al tipo di database.</block>
  <block id="c342f214098114b90cb67297a2ef5dc3" category="paragraph">Le credenziali DEGLI host DB devono essere configurate prima dell'installazione del plug-in SnapCenter. In genere, si desidera utilizzare account utente amministratore sull'host DB come credenziali di connessione host per l'installazione del plug-in. È inoltre possibile concedere lo stesso ID utente per l'accesso al database utilizzando l'autenticazione basata sul sistema operativo. D'altra parte, è possibile utilizzare l'autenticazione del database con diversi ID utente del database per l'accesso alla gestione del database. Se si decide di utilizzare l'autenticazione basata sul sistema operativo, l'ID utente amministratore del sistema operativo deve avere accesso al DB. Per l'installazione di SQL Server basata su dominio di Windows, è possibile utilizzare un account amministratore di dominio per gestire tutti gli SQL Server all'interno del dominio.</block>
  <block id="19df1192effefad83e57653fd3a47415" category="paragraph">Host Windows per SQL Server:</block>
  <block id="e1cc3ce53d7753e33588201db3d3b147" category="list-text">Se si utilizzano credenziali Windows per l'autenticazione, è necessario impostare le credenziali prima di installare i plug-in.</block>
  <block id="a82f1290b72a26d654b93632a1ec50bb" category="list-text">Se si utilizza un'istanza di SQL Server per l'autenticazione, è necessario aggiungere le credenziali dopo l'installazione dei plug-in.</block>
  <block id="63f74bef6650942c6795f96366a39e6a" category="list-text">Se è stata attivata l'autenticazione SQL durante la configurazione delle credenziali, l'istanza o il database rilevato viene visualizzato con un'icona a forma di lucchetto rosso. Se viene visualizzata l'icona a forma di lucchetto, è necessario specificare le credenziali dell'istanza o del database per aggiungere correttamente l'istanza o il database a un gruppo di risorse.</block>
  <block id="b61dad3bbbf3270bf2dada5c2ac1f775" category="list-text">È necessario assegnare la credenziale a un utente RBAC senza accesso sysadmin quando vengono soddisfatte le seguenti condizioni:</block>
  <block id="34cefb5a19894e4f9b1b068544c0f591" category="list-text">La credenziale viene assegnata a un'istanza SQL.</block>
  <block id="6707464a5871a6aa26dcf785bea4052c" category="list-text">L'istanza o l'host SQL viene assegnato a un utente RBAC.</block>
  <block id="4bc8aac02ff00d874ad8b4ccd4d745ed" category="list-text">L'utente amministratore DB RBAC deve disporre sia del gruppo di risorse che dei privilegi di backup.</block>
  <block id="9198b455aa67840c7a69c7a54e94301a" category="paragraph">Host UNIX per Oracle:</block>
  <block id="71d53e54a48cfe7de69347bcd854ef30" category="list-text">È necessario attivare la connessione SSH basata su password per l'utente root o non root modificando sshd.conf e riavviando il servizio sshd. L'autenticazione SSH basata su password sull'istanza di AWS è disattivata per impostazione predefinita.</block>
  <block id="efa873f0464a14d54b066f475ad74480" category="list-text">Configurare i privilegi sudo per l'utente non root per l'installazione e l'avvio del processo di plug-in. Dopo aver installato il plug-in, i processi vengono eseguiti come utente root effettivo.</block>
  <block id="82a2174029175f8fbc3f52fea4e18c84" category="list-text">Creare le credenziali con la modalità di autenticazione Linux per l'utente di installazione.</block>
  <block id="86b3cc44ebd8e0a9185e48c4f22e81e9" category="list-text">È necessario installare Java 1.8.x (64 bit) sull'host Linux.</block>
  <block id="c1e8851d10ecc615c47a47f704569d29" category="list-text">L'installazione del plug-in del database Oracle installa anche il plug-in SnapCenter per Unix.</block>
  <block id="7efb27733d1fb21feae901a41580dced" category="section-title">3. Installazione del plug-in host SnapCenter</block>
  <block id="37a5c714defad8175b81b4d49eb0544c" category="admonition">Prima di tentare di installare i plug-in SnapCenter sulle istanze del server DB cloud, assicurarsi che tutte le fasi di configurazione siano state completate come indicato nella relativa sezione cloud per l'implementazione dell'istanza di calcolo.</block>
  <block id="283aa502c28fe1c9ff8dadd1700955fc" category="paragraph">La seguente procedura illustra come aggiungere un host di database a SnapCenter mentre è installato un plug-in SnapCenter sull'host. La procedura si applica all'aggiunta di host on-premise e host cloud. La seguente dimostrazione aggiunge un host Windows o Linux residente in AWS.</block>
  <block id="81ed46777c39c0d0618953601572fc27" category="section-title">Configurare le impostazioni globali di SnapCenter</block>
  <block id="2aa8a40dbbfb6b52621408c81aa5373c" category="paragraph">Accedere a Impostazioni &gt; Impostazioni globali. Selezionare "VM con iSCSI direct attached disks o NFS per tutti gli host" in Impostazioni hypervisor e fare clic su Aggiorna.</block>
  <block id="4c120331c9eea223eee675b6588d76ee" category="paragraph"><block ref="4c120331c9eea223eee675b6588d76ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f63a469619859e4cfab52fd63523aca" category="section-title">Aggiungere l'host Windows e l'installazione del plug-in sull'host</block>
  <block id="997da6deedab4436b559e3a8f7f05a2e" category="list-text">Accedere a SnapCenter con un ID utente con privilegi SnapCenterAdmin.</block>
  <block id="97e7f600216a2e9ae18423777e11ad9c" category="list-text">Fare clic sulla scheda host dal menu a sinistra, quindi fare clic su Add (Aggiungi) per aprire il flusso di lavoro Add host (Aggiungi host).</block>
  <block id="35314bae57d7ff62ab36156211c1cc71" category="list-text">Scegliere Windows come tipo di host; il nome host può essere un nome host o un indirizzo IP. Il nome host deve essere risolto con l'indirizzo IP host corretto dall'host SnapCenter. Scegliere le credenziali host create al punto 2. Scegliere Microsoft Windows e Microsoft SQL Server come pacchetti di plug-in da installare.</block>
  <block id="b9740ae9eb2ef0fe27e4c541d06a961f" category="paragraph"><block ref="b9740ae9eb2ef0fe27e4c541d06a961f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31efcd689861354799bb539ab2571ebe" category="list-text">Una volta installato il plug-in su un host Windows, il relativo stato generale viene visualizzato come "Configure log directory" (Configura directory log).</block>
  <block id="0e15e25c5ee21469698f72cf35caa7bf" category="paragraph"><block ref="0e15e25c5ee21469698f72cf35caa7bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2aeaa4503c6d72513c0dbe0f205ee3b" category="list-text">Fare clic su host Name (Nome host) per aprire la configurazione della directory di log di SQL Server.</block>
  <block id="6fc78660a180b747f815b878c89e3cb0" category="paragraph"><block ref="6fc78660a180b747f815b878c89e3cb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb2b40646a77b4f044e7fa04ea20306" category="list-text">Fare clic su "Configure log directory" (Configura directory log) per aprire "Configure Plug-in for SQL Server" (Configura plug-in per SQL Server).</block>
  <block id="5e3bf9ddacfcad12c5cf63614a869ad4" category="paragraph"><block ref="5e3bf9ddacfcad12c5cf63614a869ad4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7143b5d162d385dfb1af07f61c59f65" category="list-text">Fare clic su Browse (Sfoglia) per scoprire lo storage NetApp in modo da poter impostare una directory di log; SnapCenter utilizza questa directory di log per eseguire il rolloup dei file di log delle transazioni di SQL Server. Quindi fare clic su Save (Salva).</block>
  <block id="50eb49de485da684ac1556947ac46aba" category="paragraph"><block ref="50eb49de485da684ac1556947ac46aba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0d88588bdb07dd412a4ba1d08348b29" category="admonition">Affinché lo storage NetApp fornito a un host DB venga rilevato, lo storage (on-premise o CVO) deve essere aggiunto a SnapCenter, come illustrato nella fase 6 per CVO come esempio.</block>
  <block id="d744af12906d55ab51aa932b3ffcd121" category="list-text">Una volta configurata la directory di log, lo stato generale del plug-in host di Windows viene modificato in in in esecuzione.</block>
  <block id="3f7bfffdbb76fd620b0a31d300415528" category="paragraph"><block ref="3f7bfffdbb76fd620b0a31d300415528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f41517f2e270a138f4ae92988a4cbdd2" category="list-text">Per assegnare l'host all'ID utente per la gestione del database, accedere alla scheda Access (accesso) in Settings and Users (Impostazioni e utenti), fare clic sull'ID utente per la gestione del database (nel caso in cui sia necessario assegnare l'host all'host) e fare clic su Save (Salva) per completare l'assegnazione delle risorse host.</block>
  <block id="b21f826d2ea15e58b9c8aadccb566cfe" category="paragraph"><block ref="b21f826d2ea15e58b9c8aadccb566cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="021de72edbb0f174ffe954c5e5367b80" category="paragraph"><block ref="021de72edbb0f174ffe954c5e5367b80" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2fe19c733a6342990513e02264db163" category="section-title">Aggiungere l'host Unix e l'installazione del plug-in sull'host</block>
  <block id="6a0f36be9f208d20c3c1145c3a09b876" category="list-text">Fare clic sulla scheda host dal menu a sinistra, quindi fare clic su Add (Aggiungi) per aprire il flusso di lavoro Add host (Aggiungi host).</block>
  <block id="dd8c6d773e31c4254eb58b4b5e2ae1be" category="list-text">Scegliere Linux come tipo di host. Il nome host può essere il nome host o un indirizzo IP. Tuttavia, il nome host deve essere risolto per correggere l'indirizzo IP host dall'host SnapCenter. Scegliere le credenziali host create nel passaggio 2. Le credenziali host richiedono privilegi sudo. Selezionare Oracle Database come plug-in da installare, che installa sia i plug-in host Oracle che Linux.</block>
  <block id="7d4cdef2144fd1466fae298bd27476d1" category="paragraph"><block ref="7d4cdef2144fd1466fae298bd27476d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="711730391561a228d41f7fede13ca6e8" category="list-text">Fare clic su altre opzioni e selezionare "Ignora controlli di preinstallazione". Viene richiesto di confermare l'omissione del controllo di preinstallazione. Fare clic su Sì, quindi su Salva.</block>
  <block id="3511b18d059f3f300b5fbe827f7273ac" category="paragraph"><block ref="3511b18d059f3f300b5fbe827f7273ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e095a093138c6b1968d313d5f799255a" category="list-text">Fare clic su Submit (Invia) per avviare l'installazione del plug-in. Viene richiesto di confermare l'impronta digitale come mostrato di seguito.</block>
  <block id="146c4805beb9310e4554842f776cb88b" category="paragraph"><block ref="146c4805beb9310e4554842f776cb88b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53dcda6f2c03efbe73ae5eb311852a8d" category="list-text">SnapCenter esegue la convalida e la registrazione dell'host, quindi il plug-in viene installato sull'host Linux. Lo stato cambia da Installing Plugin (Installazione del plug-in) a running (in esecuzione)</block>
  <block id="2636403a6c50748422736d9d84a3e4be" category="paragraph"><block ref="2636403a6c50748422736d9d84a3e4be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="33ea9d9313933c68d640ebb655ec43dc" category="list-text">Assegnare l'host appena aggiunto all'ID utente corretto per la gestione del database (nel nostro caso, oradba).</block>
  <block id="2815d2f5e3b49d9332a320ec997271dd" category="paragraph"><block ref="2815d2f5e3b49d9332a320ec997271dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb6a9566891a97e0f8fbaefbd4878bdd" category="paragraph"><block ref="eb6a9566891a97e0f8fbaefbd4878bdd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b4c839521fd41e845e6e8c3158b809b" category="section-title">4. Rilevamento delle risorse del database</block>
  <block id="45e46a9524f23884445bf542bf464b93" category="paragraph">Una volta completata l'installazione del plug-in, è possibile rilevare immediatamente le risorse del database sull'host. Fare clic sulla scheda Resources (risorse) nel menu a sinistra. A seconda del tipo di piattaforma di database, sono disponibili diverse visualizzazioni, ad esempio il database, il gruppo di risorse e così via. Se le risorse dell'host non vengono rilevate e visualizzate, potrebbe essere necessario fare clic sulla scheda Refresh Resources (Aggiorna risorse).</block>
  <block id="79fca6395972f8079320d3229822e491" category="paragraph"><block ref="79fca6395972f8079320d3229822e491" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66789731e61fd3d4b6024e5fcb0945e1" category="paragraph">Quando il database viene rilevato inizialmente, lo stato generale viene visualizzato come "Not Protected" (non protetto). La schermata precedente mostra un database Oracle non ancora protetto da una policy di backup.</block>
  <block id="68148a1249ca9110d03c698ae152932a" category="paragraph">Quando viene impostata una configurazione o un criterio di backup ed è stato eseguito un backup, lo Stato generale del database mostra lo stato del backup come "Backup riuscito" e l'indicazione dell'ora dell'ultimo backup. La seguente schermata mostra lo stato del backup di un database utente SQL Server.</block>
  <block id="2cdfb74ac3aabfde7e1fae347ed5afc7" category="paragraph"><block ref="2cdfb74ac3aabfde7e1fae347ed5afc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c9616324bc00808729d46fba94ad75" category="paragraph">Se le credenziali di accesso al database non sono impostate correttamente, un pulsante di blocco rosso indica che il database non è accessibile. Ad esempio, se le credenziali Windows non dispongono dell'accesso sysadmin a un'istanza di database, è necessario riconfigurare le credenziali del database per sbloccare il blocco rosso.</block>
  <block id="dd4606e87689c86d82a694412c5654a5" category="paragraph"><block ref="dd4606e87689c86d82a694412c5654a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="884f07ad394b89553e7d6d1f90fae584" category="paragraph"><block ref="884f07ad394b89553e7d6d1f90fae584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0024854a814ddd68bcf3907357c46bc2" category="paragraph">Una volta configurate le credenziali appropriate a livello di Windows o di database, il blocco rosso scompare e le informazioni sul tipo di SQL Server vengono raccolte e riviste.</block>
  <block id="95c88e08b2fd416b4514ce2454af2038" category="paragraph"><block ref="95c88e08b2fd416b4514ce2454af2038" category="inline-image-macro-rx" type="image"></block></block>
  <block id="864f4d2595d06e5e8b46b08edb3899e6" category="section-title">5. Configurare il peering del cluster di storage e la replica dei volumi DB</block>
  <block id="785196ec55a9e713ad1a4f962baa31dd" category="paragraph">Per proteggere i dati del database on-premise utilizzando un cloud pubblico come destinazione di destinazione, i volumi di database del cluster ONTAP on-premise vengono replicati nel CVO del cloud utilizzando la tecnologia NetApp SnapMirror. I volumi di destinazione replicati possono quindi essere clonati per LO SVILUPPO/OPS o il disaster recovery. I seguenti passaggi di alto livello consentono di configurare il peering dei cluster e la replica dei volumi DB.</block>
  <block id="1f1927293f04e4cf0fc91a7e389612eb" category="list-text">Configurare le LIF di intercluster per il peering dei cluster sia sul cluster on-premise che sull'istanza del cluster CVO. Questo passaggio può essere eseguito con Gestione sistema ONTAP. Un'implementazione CVO predefinita prevede la configurazione automatica di LIF tra cluster.</block>
  <block id="9547803d96e78bbc38305e6300f7a800" category="paragraph">Cluster on-premise:</block>
  <block id="2ef6da9ba547bc5361495650ac3fc992" category="paragraph"><block ref="2ef6da9ba547bc5361495650ac3fc992" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3c5b3e342f57b792e2263e69e41677a" category="paragraph">Cluster CVO di destinazione:</block>
  <block id="d94586e4cd285619a4f1ef0e06636dd1" category="paragraph"><block ref="d94586e4cd285619a4f1ef0e06636dd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79d372933b80ed2ca8ca14d8458828af" category="inline-link-macro">Getting started - AWS Public Cloud</block>
  <block id="6a87ea28950f9209121872c9d2690049" category="list-text">Con le LIF intercluster configurate, è possibile configurare il peering dei cluster e la replica dei volumi utilizzando la funzione di trascinamento della selezione in NetApp Cloud Manager. Vedere <block ref="28783e162df4af496939d6f9f6f31d5f" category="inline-link-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="d1567c6c8f0752cbc7deb6d9f639ba12" category="paragraph">In alternativa, è possibile eseguire il peering del cluster e la replica del volume DB utilizzando Gestione di sistema di ONTAP come indicato di seguito:</block>
  <block id="494c0b53ff31502c0c1105881e2e389a" category="list-text">Accedere a Gestore di sistema di ONTAP. Accedere a Cluster &gt; Settings (Cluster &gt; Impostazioni) e fare clic su Peer Cluster (Cluster peer) per impostare il peering del cluster con l'istanza CVO nel cloud.</block>
  <block id="ba770272a0f634af47a5788634e80d54" category="paragraph"><block ref="ba770272a0f634af47a5788634e80d54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54de72c782c4b4ccc7f2914a858d5356" category="list-text">Accedere alla scheda Volumes (volumi). Selezionare il volume di database da replicare e fare clic su Proteggi.</block>
  <block id="32588f46a47679329b03194fd2e9084f" category="paragraph"><block ref="32588f46a47679329b03194fd2e9084f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0aace069b478e8b2b0753f855f2be94" category="list-text">Impostare il criterio di protezione su asincrono. Selezionare la SVM del cluster e dello storage di destinazione.</block>
  <block id="7dbec53b432ae53f7e454836ad0dad00" category="paragraph"><block ref="7dbec53b432ae53f7e454836ad0dad00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a2a64fe8af0790615a9344069794e2e" category="list-text">Verificare che il volume sia sincronizzato tra l'origine e la destinazione e che la relazione di replica sia corretta.</block>
  <block id="97edcd79a5e90d9caafde40fcb586185" category="paragraph"><block ref="97edcd79a5e90d9caafde40fcb586185" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36097c4ad6058de288de8992f89adbb8" category="section-title">6. Aggiunta di SVM per lo storage di database CVO a SnapCenter</block>
  <block id="ebcf85d67af3f672ade8bd7b224a8a2b" category="list-text">Fare clic sulla scheda sistema di storage dal menu, quindi fare clic su nuovo per aggiungere una SVM di storage CVO che ospita volumi di database di destinazione replicati in SnapCenter. Inserire l'IP di gestione del cluster nel campo Storage System (sistema di storage) e immettere il nome utente e la password appropriati.</block>
  <block id="41e9c94a0c8cb108959099b8f87adb82" category="paragraph"><block ref="41e9c94a0c8cb108959099b8f87adb82" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a27406b63f99780f65572b95f2f72348" category="list-text">Fare clic su More Options (altre opzioni) per aprire ulteriori opzioni di configurazione dello storage. Nel campo piattaforma, selezionare Cloud Volumes ONTAP, selezionare secondario, quindi fare clic su Salva.</block>
  <block id="8a60464ab91cb2499a03c722639c3aee" category="paragraph"><block ref="8a60464ab91cb2499a03c722639c3aee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b474a0a2de59b8e3013112beb48af7b7" category="list-text">Assegnare i sistemi storage agli ID utente di gestione del database SnapCenter, come illustrato nella <block ref="8a46cbc3838a53b9205abb25a577bbc8" category="inline-xref-macro-rx"></block>.</block>
  <block id="8691f91a1fe977fd76aa5e53b0f71034" category="paragraph"><block ref="8691f91a1fe977fd76aa5e53b0f71034" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39ec95149453e7bb6b73f1c03228e85c" category="section-title">7. Configurare i criteri di backup del database in SnapCenter</block>
  <block id="37d9f685e375f77a2231e13c88ccc606" category="paragraph">Le seguenti procedure illustrano come creare un database completo o un criterio di backup del file di log. Il criterio può quindi essere implementato per proteggere le risorse dei database. L'RPO (Recovery Point Objective) o RTO (Recovery Time Objective) determina la frequenza dei backup del database e/o del log.</block>
  <block id="739184f368f13e142dd034fcdc853594" category="section-title">Creare una policy di backup completa del database per Oracle</block>
  <block id="94b39254a7aba068b68fec64f6331b0b" category="list-text">Accedere a SnapCenter come ID utente per la gestione del database, fare clic su Impostazioni, quindi su criteri.</block>
  <block id="90affc4ffbb767a3d1272be5e1ad8f0c" category="paragraph"><block ref="90affc4ffbb767a3d1272be5e1ad8f0c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1d144b8c78fc8541b57aa9f0ca863a6" category="list-text">Fare clic su New (nuovo) per avviare un nuovo flusso di lavoro di creazione dei criteri di backup o scegliere un criterio esistente per la modifica.</block>
  <block id="29618ae8465c694d23d68e171fe9d905" category="paragraph"><block ref="29618ae8465c694d23d68e171fe9d905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c9dac29c26006ce512153a9bdabcc95" category="list-text">Selezionare il tipo di backup e la frequenza di pianificazione.</block>
  <block id="10e2791563a2891fd7e4e68c5673671b" category="paragraph"><block ref="10e2791563a2891fd7e4e68c5673671b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4df94ad44381c9fb7fe2f8d01dcd16d8" category="list-text">Impostare la conservazione del backup. Definisce il numero di copie di backup complete del database da conservare.</block>
  <block id="6dcc4aa023085480846059b6b1d5e5b3" category="paragraph"><block ref="6dcc4aa023085480846059b6b1d5e5b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd634020906b35a41e0ba633eddeb96a" category="list-text">Selezionare le opzioni di replica secondaria per inviare i backup delle snapshot primarie locali da replicare in una posizione secondaria nel cloud.</block>
  <block id="25ef9e4c73a2da8519e8d232b6a95fcb" category="paragraph"><block ref="25ef9e4c73a2da8519e8d232b6a95fcb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2e3af55a4355bc46e91425ac5701174" category="list-text">Specificare qualsiasi script opzionale da eseguire prima e dopo l'esecuzione di un backup.</block>
  <block id="326d50fae4f713cebe97d0f6bb23a2d9" category="paragraph"><block ref="326d50fae4f713cebe97d0f6bb23a2d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd009bc210e371d36d466b592179e883" category="list-text">Eseguire la verifica del backup, se necessario.</block>
  <block id="0b132e3438f5cf31e90f45e79710f0b9" category="paragraph"><block ref="0b132e3438f5cf31e90f45e79710f0b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dba73d3ec3f929ff18665087076291ac" category="list-text">Riepilogo.</block>
  <block id="4f92fa99421beeb9f74ee7613de52706" category="paragraph"><block ref="4f92fa99421beeb9f74ee7613de52706" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3594f2789840eda9633139ca530384a" category="section-title">Creare una policy di backup del log del database per Oracle</block>
  <block id="be763ec2afcb0358426bb0abcae4dd60" category="list-text">Accedere a SnapCenter con un ID utente per la gestione del database, fare clic su Impostazioni, quindi su criteri.</block>
  <block id="b0e663a3d363868d6c71ab9ec37940c6" category="list-text">Fare clic su New (nuovo) per avviare un nuovo flusso di lavoro di creazione dei criteri di backup o scegliere un criterio esistente per la modifica.</block>
  <block id="fa2687f5a5fbedb43745f649a2e11950" category="paragraph"><block ref="fa2687f5a5fbedb43745f649a2e11950" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0938f6574b189bdac27cdd92abc521c5" category="paragraph"><block ref="0938f6574b189bdac27cdd92abc521c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59480846ec23463481d361bf3026235e" category="list-text">Impostare il periodo di conservazione del registro.</block>
  <block id="c8df578fbf71151edda735bc81e8511c" category="paragraph"><block ref="c8df578fbf71151edda735bc81e8511c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04ba33c0584145006ca637b4556aa919" category="list-text">Abilitare la replica in una posizione secondaria nel cloud pubblico.</block>
  <block id="fdbe42a8484a3e984e4aacb6a31cccef" category="paragraph"><block ref="fdbe42a8484a3e984e4aacb6a31cccef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab9406cbd3a8f082700523fdac8a0c1d" category="list-text">Specificare eventuali script opzionali da eseguire prima e dopo il backup del registro.</block>
  <block id="5b04423521e56720f1f5d0291db584ef" category="paragraph"><block ref="5b04423521e56720f1f5d0291db584ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4b55e05a9ae89fe14377b98bc8a8166" category="list-text">Specificare eventuali script di verifica del backup.</block>
  <block id="c4dc219fd9466ab86c22ac8e859384ea" category="paragraph"><block ref="c4dc219fd9466ab86c22ac8e859384ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2564f2d008c62044da1b7f7397252edf" category="paragraph"><block ref="2564f2d008c62044da1b7f7397252edf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe147647227dfec6603bc76daf30463e" category="section-title">Creare una policy di backup completa del database per SQL</block>
  <block id="fa726a7e85857bee77ace96dcf7e5316" category="paragraph"><block ref="fa726a7e85857bee77ace96dcf7e5316" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ce2168daff0c9b1a74e59d999d6ead44" category="paragraph"><block ref="ce2168daff0c9b1a74e59d999d6ead44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30637cfd5a5cc820d6bc4116fccfff7e" category="list-text">Definire l'opzione di backup e la frequenza di pianificazione. Per SQL Server configurato con un gruppo di disponibilità, è possibile impostare una replica di backup preferita.</block>
  <block id="b520dcfd25c4b29395bb9b12ac643bb2" category="paragraph"><block ref="b520dcfd25c4b29395bb9b12ac643bb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f74ada8393aecd40e892de04b5b30f8" category="list-text">Impostare il periodo di conservazione del backup.</block>
  <block id="4ade95d8122243cda1455b04504d3367" category="paragraph"><block ref="4ade95d8122243cda1455b04504d3367" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1a67a80a7ad9403781b210983ea778d" category="list-text">Abilitare la replica delle copie di backup in una posizione secondaria nel cloud.</block>
  <block id="caf8324e53d9bb41b3ecb64f3e3b7dda" category="paragraph"><block ref="caf8324e53d9bb41b3ecb64f3e3b7dda" category="inline-image-macro-rx" type="image"></block></block>
  <block id="17b7b360fc2163537795a34cd8d14d6a" category="list-text">Specificare eventuali script opzionali da eseguire prima o dopo un processo di backup.</block>
  <block id="abbc7de57d2b0d5d1c462b7513199253" category="paragraph"><block ref="abbc7de57d2b0d5d1c462b7513199253" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb836d972496d965dd2170ed1480917b" category="list-text">Specificare le opzioni per eseguire la verifica del backup.</block>
  <block id="b4dd01df6b310e6b0814328a86bd6ed6" category="paragraph"><block ref="b4dd01df6b310e6b0814328a86bd6ed6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67cfb8548ccb78172db31d7af494fa02" category="paragraph"><block ref="67cfb8548ccb78172db31d7af494fa02" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b67ed2348002e614d5a35151577632" category="section-title">Creare un criterio di backup del log del database per SQL.</block>
  <block id="b405195aec7cf62440373fcdc490dec6" category="list-text">Accedere a SnapCenter con un ID utente per la gestione del database, fare clic su Impostazioni &gt; Criteri, quindi su nuovo per avviare un nuovo flusso di lavoro per la creazione di policy.</block>
  <block id="c236030076b67936a7c1c11d49408838" category="paragraph"><block ref="c236030076b67936a7c1c11d49408838" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acdaf46fc90606d68f3f2b52cca5e95b" category="list-text">Definire l'opzione di backup del registro e la frequenza di pianificazione. Per SQL Server configurato con un gruppo di disponibilità, è possibile impostare una replica di backup preferita.</block>
  <block id="19ab604707a9384fa4883cedd5a525f9" category="paragraph"><block ref="19ab604707a9384fa4883cedd5a525f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da00d968a5d810d846ddc815b8f405a4" category="list-text">Il criterio di backup dei dati di SQL Server definisce la conservazione del backup del registro; accettare i valori predefiniti qui.</block>
  <block id="783828e5ae6dcfd713966e7301831296" category="paragraph"><block ref="783828e5ae6dcfd713966e7301831296" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d04d89062d3ed67bbc9c4aee35bdba7f" category="list-text">Abilitare la replica del backup dei log su secondario nel cloud.</block>
  <block id="b1968bd01bc5c402dcd27c99ce6326cc" category="paragraph"><block ref="b1968bd01bc5c402dcd27c99ce6326cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30c50cf9d6726341a29a3caf97dc84e8" category="paragraph"><block ref="30c50cf9d6726341a29a3caf97dc84e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4d9b291b4ffaddb50c99313e530077f" category="paragraph"><block ref="c4d9b291b4ffaddb50c99313e530077f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f28f6c36698b3a4cd47cbeead15eddf2" category="section-title">8. Implementare policy di backup per proteggere il database</block>
  <block id="37b889cc1b57f66ae9018b6eacb891ba" category="paragraph">SnapCenter utilizza un gruppo di risorse per eseguire il backup di un database in un gruppo logico di risorse di database, ad esempio più database ospitati su un server, un database che condivide gli stessi volumi di storage, più database che supportano un'applicazione di business e così via. La protezione di un singolo database crea un proprio gruppo di risorse. Le seguenti procedure mostrano come implementare una policy di backup creata nella sezione 7 per proteggere i database Oracle e SQL Server.</block>
  <block id="0603dbbe978e4cd3ee1c45ba96a1aa6f" category="section-title">Creare un gruppo di risorse per il backup completo di Oracle</block>
  <block id="5f4e02f34bcd7993867c4b3297a171d0" category="list-text">Accedere a SnapCenter con un ID utente per la gestione del database e accedere alla scheda risorse. Nell'elenco a discesa Visualizza, scegliere Database o Gruppo di risorse per avviare il flusso di lavoro di creazione del gruppo di risorse.</block>
  <block id="6eac6f96ac8d968dfec8184d16a73d43" category="paragraph"><block ref="6eac6f96ac8d968dfec8184d16a73d43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="98dcf41bcde9cb6c4235a6a7dfe69346" category="list-text">Fornire un nome e tag per il gruppo di risorse. È possibile definire un formato di denominazione per la copia Snapshot e ignorare la destinazione del registro di archiviazione ridondante, se configurata.</block>
  <block id="a75ba82042ae54dd2e68cf6c7a26614c" category="paragraph"><block ref="a75ba82042ae54dd2e68cf6c7a26614c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0cd85a82e6f02b779006b158b9c5f828" category="list-text">Aggiungere risorse di database al gruppo di risorse.</block>
  <block id="3836a8be1f86b6658a7fa6b180e4a72d" category="paragraph"><block ref="3836a8be1f86b6658a7fa6b180e4a72d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cee52cb6702e7590fbef45eccc8fb2df" category="list-text">Selezionare una policy di backup completa creata nella sezione 7 dall'elenco a discesa.</block>
  <block id="af900bffdda986bc1db955ae78832742" category="paragraph"><block ref="af900bffdda986bc1db955ae78832742" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fe872cd84ea2e9051770379e63f9caf" category="list-text">Fare clic sul segno (+) per configurare la pianificazione di backup desiderata.</block>
  <block id="9da504fd8ab60cfcc873608530cf5d56" category="paragraph"><block ref="9da504fd8ab60cfcc873608530cf5d56" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdc27a4c5d48dbfc04f81ecac85acd64" category="list-text">Fare clic su Load Locators (carica locatori) per caricare il volume di origine e di destinazione.</block>
  <block id="7242164857e43688f8a7bec97559c36e" category="paragraph"><block ref="7242164857e43688f8a7bec97559c36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b612dc8868902cf8fbf2b1024ad94e65" category="paragraph"><block ref="b612dc8868902cf8fbf2b1024ad94e65" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95633243861715786b64e1554b629435" category="paragraph"><block ref="95633243861715786b64e1554b629435" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f7192b9766e6f09c261f3ca3d3bddc8" category="section-title">Creare un gruppo di risorse per il backup dei log di Oracle</block>
  <block id="1a0cd5de7c84ddbf632838dd9f510d37" category="paragraph"><block ref="1a0cd5de7c84ddbf632838dd9f510d37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0ad3d9537c50952c04b71be3f9d4579" category="paragraph"><block ref="f0ad3d9537c50952c04b71be3f9d4579" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c33c31714f671e112fbe52b660d3e7a4" category="paragraph"><block ref="c33c31714f671e112fbe52b660d3e7a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03955b73285eab0d68e90c627da9726d" category="list-text">Selezionare un criterio di backup del registro creato nella sezione 7 dall'elenco a discesa.</block>
  <block id="6286629570d2ca91cf6860e7da6e9073" category="paragraph"><block ref="6286629570d2ca91cf6860e7da6e9073" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88c73129e9a418955658ce5c48d9d8b5" category="list-text">Fare clic sul segno (+) per configurare la pianificazione di backup desiderata.</block>
  <block id="8cdd30063d988671ffa9240fe171b1ce" category="paragraph"><block ref="8cdd30063d988671ffa9240fe171b1ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eacfd6f10777b8dfb41199e4d4dfa915" category="list-text">Se la verifica del backup è configurata, viene visualizzata qui.</block>
  <block id="69911c1794125b768effca94c8153987" category="paragraph"><block ref="69911c1794125b768effca94c8153987" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a27fac4b1d49d5468930a56c3a6de56" category="list-text">Configurare un server SMTP per la notifica via email, se lo si desidera.</block>
  <block id="fd540644538dcedf1f6543455447728f" category="paragraph"><block ref="fd540644538dcedf1f6543455447728f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="554dbe35f6afa38e8232497f5d05d1c1" category="paragraph"><block ref="554dbe35f6afa38e8232497f5d05d1c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf688c7a95f421447e84a47fd03f3aa2" category="section-title">Creare un gruppo di risorse per il backup completo di SQL Server</block>
  <block id="d08ef097ee33c4a3506183adeb51c5e7" category="list-text">Accedere a SnapCenter con un ID utente per la gestione del database e accedere alla scheda risorse. Nell'elenco a discesa Visualizza, scegliere un database o un gruppo di risorse per avviare il flusso di lavoro di creazione del gruppo di risorse. Fornire un nome e tag per il gruppo di risorse. È possibile definire un formato di denominazione per la copia Snapshot.</block>
  <block id="87d2630813d214672697efc01974d64e" category="paragraph"><block ref="87d2630813d214672697efc01974d64e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1ace5324d60cb3faa1863efd675149" category="list-text">Selezionare le risorse di database di cui eseguire il backup.</block>
  <block id="15330fe5b8f32032bd3b30c091d7dc4b" category="paragraph"><block ref="15330fe5b8f32032bd3b30c091d7dc4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2fc1974f486effa4a60bf216e63a88d5" category="list-text">Selezionare una policy di backup SQL completa creata nella sezione 7.</block>
  <block id="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="paragraph"><block ref="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b70beeb570488ba753a620378cacd8" category="list-text">Aggiungi tempi esatti per i backup e la frequenza.</block>
  <block id="8fa0a3897bc03e9b1653d17308464031" category="paragraph"><block ref="8fa0a3897bc03e9b1653d17308464031" category="inline-image-macro-rx" type="image"></block></block>
  <block id="49252579bd8140847f4bbac20ef89b07" category="list-text">Scegliere il server di verifica per il backup su secondario se deve essere eseguita la verifica del backup. Fare clic su Load Locator (carica localizzatore) per popolare la posizione dello storage secondario.</block>
  <block id="355e5eb56524b7365674014ea5868ee6" category="paragraph"><block ref="355e5eb56524b7365674014ea5868ee6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19e819eadb96ee5769ff4c6309352a62" category="paragraph"><block ref="19e819eadb96ee5769ff4c6309352a62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0be278d93ec2e64895e31bf440c54b98" category="paragraph"><block ref="0be278d93ec2e64895e31bf440c54b98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4dd921984d3a8a89e7df5c97875b923" category="section-title">Creare un gruppo di risorse per il backup del log di SQL Server</block>
  <block id="4e94ca9b995e68691b4e67b82b9f5bce" category="list-text">Accedere a SnapCenter con un ID utente per la gestione del database e accedere alla scheda risorse. Nell'elenco a discesa Visualizza, scegliere un database o un gruppo di risorse per avviare il flusso di lavoro di creazione del gruppo di risorse. Fornire il nome e i tag per il gruppo di risorse. È possibile definire un formato di denominazione per la copia Snapshot.</block>
  <block id="4e71263f0aec815017fd21a22ddb87d6" category="paragraph"><block ref="4e71263f0aec815017fd21a22ddb87d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="013faf9f6cde83814469c6d583e10702" category="paragraph"><block ref="013faf9f6cde83814469c6d583e10702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23e15d7c127e66b1da1d72072a29e9eb" category="list-text">Selezionare un criterio di backup del registro SQL creato nella sezione 7.</block>
  <block id="52a8553e4c33eb8353d56286d3845b28" category="paragraph"><block ref="52a8553e4c33eb8353d56286d3845b28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e7cac98c16b45d7e4ebec8786b8fda1" category="list-text">Aggiungere la tempistica esatta per il backup e la frequenza.</block>
  <block id="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="paragraph"><block ref="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68398b6746dde91649e96505d97acc40" category="list-text">Scegliere il server di verifica per il backup su secondario se deve essere eseguita la verifica del backup. Fare clic su Load Locator per popolare la posizione dello storage secondario.</block>
  <block id="3bde998a2436b40589b20d91a713d3ee" category="paragraph"><block ref="3bde998a2436b40589b20d91a713d3ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80000e8cb7742af4686df786fdf38249" category="paragraph"><block ref="80000e8cb7742af4686df786fdf38249" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d32fb038efa6b409f8dedd0e02a10f26" category="paragraph"><block ref="d32fb038efa6b409f8dedd0e02a10f26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c72629a46c2e88cf7f6a012167bb16" category="section-title">9. Convalidare il backup</block>
  <block id="d1c55c296cbdaa8d88eda765a6158b62" category="paragraph">Una volta creati i gruppi di risorse di backup del database per proteggere le risorse del database, i processi di backup vengono eseguiti in base alla pianificazione predefinita. Controllare lo stato di esecuzione del lavoro nella scheda Monitor.</block>
  <block id="5f9af2a4e435e2b39c27f43b580d6d20" category="paragraph"><block ref="5f9af2a4e435e2b39c27f43b580d6d20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57882e224a8cbe8f694da9b1d8fa503e" category="paragraph">Accedere alla scheda Resources (risorse), fare clic sul nome del database per visualizzare i dettagli del backup del database e alternare tra Local Copies (copie locali) e Mirror Copies (copie mirror) per verificare che i backup Snapshot siano replicati in una posizione secondaria nel cloud pubblico.</block>
  <block id="f9b40afbdb387dd32b8523c95080a898" category="paragraph"><block ref="f9b40afbdb387dd32b8523c95080a898" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28268d417882b5cf7a3d3ee3a15834c8" category="paragraph">A questo punto, le copie di backup del database nel cloud sono pronte per essere clonate per eseguire processi di sviluppo/test o per il disaster recovery in caso di guasto primario.</block>
  <block id="78b29bbf3f07a44b62307ce90b34904e" category="inline-link-macro">Avanti: Introduzione al cloud pubblico AWS.</block>
  <block id="7d32c0298884bcc4c0211357748d0e6e" category="paragraph"><block ref="7d32c0298884bcc4c0211357748d0e6e" category="inline-link-macro-rx"></block></block>
  <block id="75b7d47e2aa19968e092ab7ddb108a3f" category="summary">Sia che tu stia prendendo di mira un cloud all-cloud o ibrido con database stretch, Azure NetApp Files offre opzioni eccellenti per implementare e gestire i carichi di lavoro del database, riducendo al contempo il TCO rendendo i requisiti dei dati perfetti a livello applicativo.</block>
  <block id="d8d2e6021f496c4e4a31a3d5d51c0a97" category="paragraph">In questo documento vengono illustrati i consigli per la pianificazione, la progettazione, l'ottimizzazione e la scalabilità delle implementazioni di Microsoft SQL Server con Azure NetApp Files, che possono variare notevolmente da un'implementazione all'altra. La soluzione giusta dipende sia dai dettagli tecnici dell'implementazione che dai requisiti di business alla base del progetto.</block>
  <block id="56925354251a536c23de1174d3001595" category="section-title">Punti da asporto</block>
  <block id="033e6e43f2148e187e072dc7e6585802" category="paragraph">I punti chiave di questo documento includono:</block>
  <block id="b2b363e230905b04f6e9c7263aa93f42" category="list-text">È ora possibile utilizzare Azure NetApp Files per ospitare il database e il testimone della condivisione file per il cluster SQL Server.</block>
  <block id="4d6ec76303888bc681d543d1f4593c55" category="list-text">È possibile aumentare i tempi di risposta delle applicazioni e fornire una disponibilità del 99.9999% per fornire l'accesso ai dati di SQL Server quando e dove necessario.</block>
  <block id="408e4b7fbec4ba85e097b9393d2b27a7" category="list-text">È possibile semplificare la complessità generale dell'implementazione di SQL Server e la gestione continua, come lo striping raid, con un ridimensionamento semplice e istantaneo.</block>
  <block id="41642b38214243168d907d92759dde36" category="list-text">Puoi affidarti a funzionalità operative intelligenti per implementare i database SQL Server in pochi minuti e accelerare i cicli di sviluppo.</block>
  <block id="61a32d891a5f7bca599a014bc56eec61" category="list-text">Se Azure Cloud è la destinazione, Azure NetApp Files è la soluzione di storage giusta per un'implementazione ottimizzata.</block>
  <block id="d83342bb55cac062a4841a3b7a62a7fd" category="summary">Questa sezione fornisce un riepilogo delle attività che devono essere completate per soddisfare i requisiti dei prerequisiti, come descritto nella sezione precedente. La sezione seguente fornisce un elenco di task di alto livello per le operazioni on-premise e di cloud pubblico. È possibile accedere ai processi e alle procedure dettagliate facendo clic sui relativi collegamenti.</block>
  <block id="21475c5fe4cf73cfbf7756ed71e43375" category="doc">Panoramica introduttiva</block>
  <block id="fa952e93a2f3bc19270cbedd1510f523" category="inline-link-macro">Precedente: Prerequisiti per il cloud pubblico.</block>
  <block id="f50eb88fd106752cf99e25d4a7259bb7" category="paragraph"><block ref="f50eb88fd106752cf99e25d4a7259bb7" category="inline-link-macro-rx"></block></block>
  <block id="b2e7ae8381268c9d97dc3576aa67da04" category="list-text">Configurare l'utente amministratore del database in SnapCenter</block>
  <block id="e1c4efcd7b5b155c8a6e57d348b6c071" category="list-text">Prerequisiti per l'installazione del plug-in SnapCenter</block>
  <block id="cf69df8da81eda7b468d606f3e9aff06" category="list-text">Installazione del plug-in host SnapCenter</block>
  <block id="2a6faa57bc6cc0f7a4c90cebd5e63344" category="list-text">Rilevamento delle risorse DB</block>
  <block id="2a36af746a3cc41f6964edac717b5206" category="list-text">Configurare il peering del cluster di storage e la replica del volume DB</block>
  <block id="a227a5da83d0a04e6e8e7e76a89eba09" category="list-text">Aggiunta di SVM per lo storage del database CVO a SnapCenter</block>
  <block id="3041fe5faf49efefd030e278790b4faf" category="list-text">Validare il backup</block>
  <block id="0bcf61b20ebca1ef90cb7982284867a6" category="list-text">Controllo prima del volo</block>
  <block id="c27b238e54d27696cafed4684c6f1335" category="list-text">Passaggi per implementare Cloud Manager e Cloud Volumes ONTAP in AWS</block>
  <block id="2bb50575568fc6429e2c1cef751d40f4" category="list-text">Implementare l'istanza di calcolo EC2 per il carico di lavoro del database</block>
  <block id="bc2dcb446bec0ecd131a2e612dbd1ecd" category="paragraph">Per ulteriori informazioni, fare clic sui seguenti collegamenti:</block>
  <block id="21aa279d0a145dcaab5feaa02df2c02a" category="inline-link-macro">Cloud pubblico - AWS</block>
  <block id="fd0476c0c92270df2d75402a67cfe0f4" category="paragraph"><block ref="8f0e2d08c6bad9ef491c2061921b9d90" category="inline-link-macro-rx"></block>, <block ref="11145243f1982fd305768240bff5daad" category="inline-link-macro-rx"></block></block>
  <block id="84f09994e75c5ede8e07c6ab4070faae" category="summary">Questa sezione fornisce dettagli sulla convalida delle performance e sui risultati del benchmark ottenuti da un carico di lavoro OLTP simulato di Swingbench.</block>
  <block id="d9a4da5bae7f5f09fa9c3850a052c626" category="doc">Convalida delle performance e risultati del benchmark</block>
  <block id="b944009da5cbc8c34fbaa084f3b1d385" category="inline-link-macro">Precedente: Gestione del database Oracle.</block>
  <block id="2a07c9ef23ed37175e1063bb7d752c54" category="paragraph"><block ref="2a07c9ef23ed37175e1063bb7d752c54" category="inline-link-macro-rx"></block></block>
  <block id="4e71b9ce7d16c817e38c3c0b45825062" category="paragraph">L'obiettivo di questa convalida delle performance è di non impostare alcun contrassegno. Piuttosto, seguendo le procedure di implementazione e le Best practice descritte nella presente documentazione, puoi aspettarti metriche di performance simili dalla tua implementazione di database Oracle in un cloud pubblico.</block>
  <block id="0215fc4537f81bbc2d6ff19ba75efeb5" category="paragraph">Abbiamo utilizzato un modulo Swingbench Sales Order Entry (SOE) per simulare un carico di lavoro di tipo OLTP e abbiamo applicato il carico di lavoro a un database Oracle implementato su un'istanza M5 EC2 con volumi di storage FSX sul protocollo NFS. Il profilo i/o SOE di Swingbench predefinito è vicino a una suddivisione in lettura/scrittura di 80/20, che è simile a un profilo di carico di lavoro Oracle OLTP reale.</block>
  <block id="611831b4b814ffa8e208ff6b01e797d9" category="paragraph">Il carico di lavoro viene incrementato aumentando il numero di utenti simultanei sul lato client che eseguono l'immissione degli ordini di vendita, la navigazione, le query di inventario e così via. I numeri testati erano 8, 16, 32, 64 e 128 utenti simultanei. L'algoritmo utilizzato da Swingbench è pesante sul lato server per spingere volumi di transazioni ragionevoli e verificare i limiti dei server Oracle. Abbiamo osservato che, con 128 utenti simultanei, l'utilizzo della CPU dell'istanza EC2 ha raggiunto circa il 80-90% della capacità.</block>
  <block id="a5cbb12f8f9f28c970230ab16d36e184" category="paragraph">Le sezioni seguenti forniscono informazioni dettagliate sull'installazione e sui risultati dei test.</block>
  <block id="e018eaf806fedc0fa46d2acde6f60425" category="section-title">Configurazione dell'ambiente di test</block>
  <block id="ff4adf700c0c4ba7e493af033a81ac29" category="paragraph">Abbiamo implementato un'istanza EC2 M5 con 8vCPU, 32G RAM e 10Gps di larghezza di banda di rete.</block>
  <block id="2940f21a2cd7581a414576699c946a28" category="paragraph"><block ref="2940f21a2cd7581a414576699c946a28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5e18ca4731d9d72ae0bd4438c7e84b5" category="section-title">Storage FSX</block>
  <block id="dc29ebaf5cc1f622aabb0ae70efeced6" category="paragraph">Abbiamo creato tre volumi di database e montato i volumi con NFS su un'istanza EC2 come segue:</block>
  <block id="829e4dfdaee315e0cfdba47e5047adf7" category="list-text">/u01 - binario Oracle</block>
  <block id="5853f5304485ce536b44cd0dfb18bdbc" category="list-text">/u02 - file di dati Oracle, file di controllo</block>
  <block id="ee6ac3c6792e507ea8c5717f79c8ab46" category="list-text">/u03 - file di log Oracle, file di controllo</block>
  <block id="363dd83f018d937efa507464961997c5" category="paragraph">Abbiamo conservato due copie di un file di controllo critico per la ridondanza.</block>
  <block id="009187ce6b03d07047e46c6ed738f305" category="paragraph"><block ref="009187ce6b03d07047e46c6ed738f305" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9c8184a7a7a9ecb63af93d93759b393" category="paragraph">Il file system FSX è configurato con una capacità di 80,000 IOPS e un throughput i/o di 2 GiBps.</block>
  <block id="3570146db42993029d30dbd022107030" category="section-title">Configurazione di Oracle</block>
  <block id="9daecb8faf1751109e100894205a6aef" category="paragraph">Oracle versione 19c è stato installato con la patch RU 19.8. DNFS è stato attivato sul server.</block>
  <block id="9041eebdfc5395440a43baff789c663b" category="paragraph">Il database è stato implementato come database containerizzato con tre PDB. Abbiamo utilizzato un'istanza PDB per il test delle performance. La figura seguente mostra il dimensionamento dello storage Oracle sui punti di montaggio NFS.</block>
  <block id="9ae30014c647d5fd5e38a292d1061810" category="paragraph"><block ref="9ae30014c647d5fd5e38a292d1061810" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8da929e8cdb57e8ea66260e3f7090d35" category="section-title">Configurazione di Swingbench</block>
  <block id="6af00d716d36ee74995307e004b66d3f" category="paragraph">Abbiamo implementato Swingbench 2.6 (la versione più recente) su un host Windows con 8vCPU e 32G RAM. Per il benchmark abbiamo utilizzato il modulo di test SOE plsql versione 2. Il profilo di carico predefinito fornisce un rapporto di lettura/scrittura di 80/20 per simulare il carico di lavoro reale delle transazioni OLTP.</block>
  <block id="5850fdbd1ed0c58b02c8d3797381e7c6" category="paragraph">Il fattore di scala dello schema utilizzato era 50, che forniva una dimensione iniziale del carico di dati di 160 G e 30 G di allocazione dello spazio temporaneo. Con questo fattore di scala, lo schema SOE ha fornito 1000 warehouse e 50 milioni di clienti per la simulazione dell'elaborazione degli ordini online.</block>
  <block id="9bc139569eaa30f1804b313d21ab69fa" category="paragraph">La schermata seguente mostra il profilo del carico di lavoro e le metriche di esecuzione transazionali tipiche dell'interfaccia utente di Swingbench Windows.</block>
  <block id="4da81979345d8adfb02c96de8993662a" category="paragraph"><block ref="4da81979345d8adfb02c96de8993662a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5531d1590836e811c3ace97db7e230eb" category="paragraph">Come mostra questo grafico, il livello di transazione è stato mantenuto allo stesso livello durante l'esecuzione del test.</block>
  <block id="6c805c8ead51e13766957cbda36fd2c0" category="section-title">Analisi dei risultati del test</block>
  <block id="54f9f904b574caddc93a83f3057be251" category="paragraph">Abbiamo acquisito i risultati di Swingbench per ciascuna esecuzione di test e ottenuto i corrispondenti report Oracle AWR per l'analisi delle performance.</block>
  <block id="9126019861ad7339333760b7b3bd5174" category="paragraph">Dal punto di vista dell'utente finale, abbiamo esaminato metriche chiave come il volume delle transazioni e i tempi di risposta dell'utente. Entrambe le metriche mostrano il numero di transazioni che gli utenti possono eseguire dal sistema di immissione degli ordini di vendita, dato il numero di utenti simultanei che accedono al sistema, nonché la velocità con cui gli utenti possono completare le transazioni e ricevere una risposta dopo aver inserito l'ordine.</block>
  <block id="809217313025f03af0a774770ed7688d" category="paragraph">Dal lato server Oracle, abbiamo analizzato il report AWR di Oracle per determinare gli eventi di attesa principali che potrebbero aver rallentato le transazioni degli utenti. I primi 10 eventi di attesa di Oracle hanno indicato che, durante l'esecuzione di test delle transazioni simulate di Swingbench, il server Oracle è principalmente legato all'i/o con un tempo di database compreso tra il 50% e il 60%<block ref="235591872ecf336383513d22098a1fa0" prefix=" " category="inline-code"></block>.<block ref="a249b22faad82bdea2a0930347b9e5ac" prefix=" " category="inline-code"></block> È anche un fattore che contribuisce perché i commit delle transazioni causano lo svuotamento dell'i/o di log da parte del processo di registrazione Oracle dalla cache del buffer al file di log sul disco, sebbene si tratti di un fattore minore sul livello di tempo-percentuale del database.</block>
  <block id="4da3501ef8d9ebc196009ef0bf4e4360" category="paragraph">Abbiamo registrato il volume della transazione utente, il tempo di risposta dell'utente e gli eventi top wait Oracle rispetto al numero di utenti simultanei durante l'esecuzione di una transazione. I risultati sono mostrati di seguito:</block>
  <block id="911fadede55cdf4e5db896695fd4f9c3" category="paragraph"><block ref="911fadede55cdf4e5db896695fd4f9c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b225219fb0a32b17f3f7f3964edfa599" category="paragraph">Questi risultati indicano che potremmo aumentare costantemente i volumi delle transazioni degli utenti con un numero maggiore di utenti simultanei, mantenendo una latenza i/o costantemente bassa e tempi di risposta degli utenti, che rappresentano le performance appropriate per un'applicazione Oracle.</block>
  <block id="ccc7b98ab0c81e5b7e4033e88910e92e" category="paragraph">La latenza di i/o e il tempo di risposta dell'utente hanno iniziato ad aumentare leggermente quando abbiamo raggiunto 128 utenti simultanei. Ciò è previsto perché l'istanza EC2 si sta avvicinando alla capacità completa del server, come mostrato nel diagramma seguente:</block>
  <block id="0cc8a57e10ae7e4e152d74423527f2f0" category="paragraph"><block ref="0cc8a57e10ae7e4e152d74423527f2f0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faf8392c1e8a1c488f303b45f48fd31d" category="paragraph">Allo stesso modo, il diagramma seguente mostra i corrispondenti IOPS FSX e il throughput durante l'esecuzione dei volumi delle transazioni utente in quel momento.</block>
  <block id="a18559304ff06a743412352fbfb82b00" category="paragraph"><block ref="37451e9b66358e4a66c6a1b882f378a1" category="inline-image-macro-rx" type="image"></block>
<block ref="b0d8c670dcd70932cfb6876c97b62036" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d8430502705720b257f565ec9140e72" category="inline-link-macro">Fattori da considerare per l'implementazione del database Oracle.</block>
  <block id="b25a4c32c9b6cc39890fa799e15301dc" category="paragraph">Non abbiamo raggiunto la capacità dello storage FSX con provisioning in IOPS o throughput quando l'istanza EC2 del server Oracle è diventata il fattore limitante. Pertanto, è necessario dimensionare correttamente il calcolo e lo storage in base al volume di transazioni a livello di applicazione dell'utente, come dimostrato nella sezione <block ref="fa519ff010063f0b425f11c556e4445d" category="inline-link-macro-rx"></block></block>
  <block id="03b125f503e8b797be1fe5a21a10d220" category="summary">In questa sezione viene descritto come proteggere il database Oracle con lo strumento azacsnap e il backup, il ripristino e il tiering di snapshot in Azure BLOB.</block>
  <block id="b47faaf85acf415e557bd0b669342659" category="doc">Proteggi il tuo database Oracle nel cloud Azure</block>
  <block id="cec4dbc9c066ab7b22ef743151be75eb" category="paragraph"><block ref="cec4dbc9c066ab7b22ef743151be75eb" category="inline-link-macro-rx"></block></block>
  <block id="b1d4b4bb33f177bb183f21d1c085e800" category="paragraph">Autore: Allen Cao, NetApp Solutions Engineering</block>
  <block id="06a2961d48a854a133ddfe05c7912732" category="section-title">Eseguire il backup del database Oracle con snapshot utilizzando lo strumento AzAcSnap</block>
  <block id="30462dbcf926561966ea824afd44e355" category="paragraph">Azure Application-coerenti Snapshot Tool (AzAcSnap) è uno strumento a riga di comando che consente la protezione dei dati per i database di terze parti gestendo tutte le orchestrazione necessarie per inserirli in uno stato coerente con l'applicazione prima di eseguire uno snapshot di storage, dopodiché riporta i database a uno stato operativo.</block>
  <block id="07612935f16f2665ef52f490f9b1f43b" category="paragraph">Nel caso di Oracle, il database viene messo in modalità di backup per acquisire un'istantanea e quindi uscire dalla modalità di backup.</block>
  <block id="070d0b63c9af5e43d43102c1869d4262" category="section-title">Dati di backup e volumi di log</block>
  <block id="7dd57abd8929da4f18cc94d1940161a1" category="paragraph">Il backup può essere impostato sull'host del server di database con un semplice script shell che esegue il comando snapshot. Quindi, è possibile pianificare l'esecuzione dello script da crontab.</block>
  <block id="087916fda35dba838b68193ed8bc3aeb" category="paragraph">In genere, la frequenza del backup dipende dall'RTO e dall'RPO desiderati. La frequente creazione di snapshot consuma più spazio di storage. Esiste un compromesso tra la frequenza del backup e il consumo di spazio.</block>
  <block id="e2ece357797b760af1c814632edcf99d" category="paragraph">In genere, i volumi di dati consumano più spazio di storage rispetto ai volumi di log. Pertanto, è possibile creare snapshot sui volumi di dati ogni poche ore e snapshot più frequenti sui volumi di log ogni 15 - 30 minuti.</block>
  <block id="2a2c2eb0d2bde8c24cc55a11862ca857" category="paragraph">Vedere i seguenti esempi di script di backup e pianificazione.</block>
  <block id="e048ccd48425229cea678849ba68a190" category="paragraph">Per le snapshot dei volumi di dati:</block>
  <block id="f0d6345b8e5345f55c21610283eaeedd" category="paragraph">Per le snapshot dei volumi di log:</block>
  <block id="c0340939954e1026bd670680d03fe329" category="paragraph">Programma crontab:</block>
  <block id="adf4ba1e0f3190afb18557f038ae1ecf" category="admonition">Durante la configurazione del backup<block ref="8ed8c6bfea85d72bc4a36772490109c7" prefix=" " category="inline-code"></block> file di configurazione, aggiungere tutti i volumi di dati, incluso il volume binario, a.<block ref="0fb9dff864caebba259b119756a2ce17" prefix=" " category="inline-code"></block> e tutti i volumi registrati in<block ref="5e5fb0a2540d102aeebc3dac60712494" prefix=" " category="inline-code"></block>. La conservazione massima degli snapshot è di 250 copie.</block>
  <block id="a93091ed018686dcf478589ba04fd6f6" category="section-title">Convalidare le istantanee</block>
  <block id="8a46f2968d5dc184634cff75cd1b8b8e" category="paragraph">Accedere al portale Azure &gt; Azure NetApp Files/Volumes per verificare se le snapshot sono state create correttamente.</block>
  <block id="3542e11f657b779fcef8cc387987e9f2" category="inline-image-macro">Questa schermata mostra due file nell'elenco di snapshot.</block>
  <block id="c2dd243538b072e19882bdcd6ac2c6c9" category="inline-image-macro">Questa schermata mostra otto file nell'elenco di snapshot.</block>
  <block id="af143d815dcd69aae3ff8d8bdde9fd58" category="paragraph"><block ref="bf87ea8d7de67f1fdc628b6bb4b400e5" category="inline-image-macro-rx" type="image"></block>
<block ref="1d682e6513772285b95199f0646e28da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7479b02641600cb6142d8594c1360d11" category="section-title">Ripristino e ripristino Oracle dal backup locale</block>
  <block id="76265d8fce7f282b6ff5a8581df8879c" category="paragraph">Uno dei vantaggi principali del backup snapshot è la coesistenza con i volumi del database di origine e il rollback dei volumi del database primario quasi istantaneo.</block>
  <block id="878609e3e12819fffdd7247406f655be" category="section-title">Ripristino e ripristino di Oracle sul server primario</block>
  <block id="8733b7b64c8d2c32caa423c7eb2955fc" category="paragraph">Nell'esempio riportato di seguito viene illustrato come ripristinare un database Oracle dalla dashboard di Azure e dall'interfaccia CLI sullo stesso host Oracle.</block>
  <block id="e0ffc65e6881a5936afffc4b840e9cd5" category="list-text">Creare una tabella di test nel database da ripristinare.</block>
  <block id="2817b9cf9fc0cd0d8bf9fb03acbfc93f" category="list-text">Rilasciare la tabella dopo i backup dello snapshot.</block>
  <block id="09d4fe137595af1cc975247ba704462d" category="list-text">Dalla dashboard di Azure NetApp Files, ripristinare il volume di registro all'ultimo snapshot disponibile. Scegliere *Volume di revert*.</block>
  <block id="33ba8417b2640d4172513bbf9cbc3e55" category="inline-image-macro">Questa schermata mostra il metodo di revversion dello snapshot per i volumi nel dashboard ANF.</block>
  <block id="546b967f1ce32832a90c77282f0cdf2b" category="paragraph"><block ref="546b967f1ce32832a90c77282f0cdf2b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b728fe18b10b9b611a1d3ab6acc0df9" category="list-text">Confermare il volume di revert e fare clic su *Ripristina* per completare la reversione del volume all'ultimo backup disponibile.</block>
  <block id="5c7deeb27ad1e0e4c1d6d52b2a2a1bfc" category="inline-image-macro">Il messaggio "are you sure you want to do this?" (sei sicuro di voler eseguire questa operazione?) pagina per la revisione dello snapshot.</block>
  <block id="ef80226ab5a9d2865852e606297da2cf" category="paragraph"><block ref="ef80226ab5a9d2865852e606297da2cf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18b9906dd2c95b12fdb987b7c2aa9917" category="list-text">Ripetere la stessa procedura per il volume di dati e assicurarsi che il backup contenga la tabella da ripristinare.</block>
  <block id="a38e609b2fd5c2dee1b4ccb1cbbac7d4" category="inline-image-macro">Questa schermata mostra il metodo di revversion dello snapshot per i volumi di dati nel dashboard ANF.</block>
  <block id="f0d819988fad0119995986a2bdfd9ad6" category="paragraph"><block ref="f0d819988fad0119995986a2bdfd9ad6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc824d4f774a64498f954eb2ebbc093b" category="list-text">Confermare nuovamente la reversione del volume e fare clic su "Ripristina".</block>
  <block id="5e2296a09eabbd34b62da3492091ff33" category="inline-image-macro">Il messaggio "are you sure you want to do this?" (sei sicuro di voler eseguire questa operazione?) pagina per la revisione delle snapshot del volume di dati.</block>
  <block id="af5f9a99ee2d86856d0e2477e417dc4c" category="paragraph"><block ref="af5f9a99ee2d86856d0e2477e417dc4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="170b40e31285910539e0d464f2bf33a6" category="list-text">Sincronizzare nuovamente i file di controllo se si dispone di più copie e sostituire il vecchio file di controllo con l'ultima copia disponibile.</block>
  <block id="bd99bc18393147b05e3f350eb6a61f47" category="list-text">Accedere alla macchina virtuale del server Oracle ed eseguire il ripristino del database con sqlplus.</block>
  <block id="8ad5254ade1fed8d3ccc482196b4c36c" category="paragraph">Questa schermata dimostra che la tabella interrotta è stata ripristinata utilizzando backup di snapshot locali.</block>
  <block id="34d73a671fa85d8d86ba1eff63b238d8" category="paragraph"><block ref="34d73a671fa85d8d86ba1eff63b238d8" category="inline-link-macro-rx"></block></block>
  <block id="d5b9082efbf726d2e38c5042668ae4f0" category="doc">TR-4250: SAP con Oracle su UNIX e NFS con NetApp Clustered Data ONTAP e SnapManager per SAP 3.4</block>
  <block id="bb8cd3f7aec777de29cee988f4ade068" category="paragraph">Nils Bauer, NetApp</block>
  <block id="ea455e11718ea0bfb200c540f4e0c038" category="paragraph">TR-4250 affronta le sfide legate alla progettazione di soluzioni storage per supportare i prodotti di business suite SAP utilizzando un database Oracle. L'obiettivo principale di questo documento è rappresentato dalle sfide comuni di progettazione, implementazione, funzionamento e gestione dell'infrastruttura storage affrontate dai leader aziendali e IT che utilizzano le soluzioni SAP di ultima generazione. Le raccomandazioni contenute in questo documento sono generiche e non sono specifiche di un'applicazione SAP o delle dimensioni e dell'ambito dell'implementazione SAP. TR-4250 presuppone che il lettore abbia una conoscenza di base della tecnologia e del funzionamento dei prodotti NetApp e SAP. TR-4250 è stato sviluppato in base all'interazione dello staff tecnico di NetApp, SAP, Oracle e dei nostri clienti.</block>
  <block id="fb558936249b78a9b426ac6a575ece20" category="paragraph"><block ref="fb558936249b78a9b426ac6a575ece20" category="inline-link-macro-rx"></block></block>
  <block id="d89002d36151bd13d2bba69f3533ee5f" category="summary">Questa soluzione fornisce ai clienti e al settore NetApp istruzioni e istruzioni per la configurazione, il funzionamento e la migrazione dei database in un ambiente di cloud ibrido utilizzando lo strumento basato sull'interfaccia grafica di NetApp SnapCenter e il servizio di storage CVO di NetApp nei cloud pubblici.</block>
  <block id="8269707c3930f3cbcd49193be33bc125" category="doc">TR-4908: Panoramica delle soluzioni di database per il cloud ibrido con SnapCenter</block>
  <block id="7c4d94e1b484fb577b0aeafbec788ea1" category="paragraph">Alan Cao, Felix Meligan, NetApp</block>
  <block id="268a30b4d0cad062acd42967ce0fab50" category="paragraph">Questa soluzione fornisce ai clienti e al campo NetApp istruzioni e istruzioni per la configurazione, il funzionamento e la migrazione dei database in un ambiente di cloud ibrido utilizzando lo strumento basato sull'interfaccia grafica di NetApp SnapCenter e il servizio di storage CVO di NetApp nei cloud pubblici per i seguenti casi di utilizzo:</block>
  <block id="e88a2467c8ad8bf481854b1a745a875b" category="list-text">Operazioni di sviluppo/test del database nel cloud ibrido</block>
  <block id="3c9552536897a076f75b078a5e2a3703" category="list-text">Disaster recovery del database nel cloud ibrido</block>
  <block id="a1ac690c228caf22f3228d3a4d8b5cab" category="paragraph">Oggi, molti database aziendali risiedono ancora in data center aziendali privati per motivi di performance, sicurezza e/o altro. Questa soluzione di database per il cloud ibrido consente alle aziende di gestire i propri database primari on-site utilizzando un cloud pubblico per le operazioni di sviluppo/test dei database e per il disaster recovery per ridurre i costi operativi e di licenza.</block>
  <block id="d900d125b3be40bcb79452d624c38561" category="paragraph">Molti database aziendali, come Oracle, SQL Server, SAP HANA e così via, costi operativi e di licenza elevati. Molti clienti pagano una quota di licenza una tantum e i costi di supporto annuali in base al numero di core di calcolo nel proprio ambiente di database, indipendentemente dal fatto che i core siano utilizzati per lo sviluppo, il test, la produzione o il disaster recovery. Molti di questi ambienti potrebbero non essere completamente utilizzati durante l'intero ciclo di vita dell'applicazione.</block>
  <block id="1f49cc83c5c3735827e3353f320f5f7f" category="paragraph">Le soluzioni offrono ai clienti l'opzione di ridurre potenzialmente il numero di core licenziabili spostando nel cloud gli ambienti di database dedicati allo sviluppo, al test o al disaster recovery. Utilizzando la scalabilità del cloud pubblico, la ridondanza, l'alta disponibilità e un modello di fatturazione basato sui consumi, il risparmio sui costi per le licenze e le operazioni può essere sostanziale, senza sacrificare l'usabilità o la disponibilità delle applicazioni.</block>
  <block id="1a197dd926608052c7d43edfd09556fa" category="paragraph">Oltre ai potenziali risparmi sui costi di licenza dei database, il modello di licenza CVO basato sulla capacità di NetApp consente ai clienti di risparmiare sui costi di storage per GB, offrendo al contempo un elevato livello di gestibilità dei database che non è disponibile dai servizi di storage della concorrenza. Il grafico seguente mostra un confronto dei costi di storage dei più diffusi servizi di storage disponibili nel cloud pubblico.</block>
  <block id="810fba7bc9a3829eb522ebbc24326a08" category="paragraph"><block ref="810fba7bc9a3829eb522ebbc24326a08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e222eb27a0002f2960d1cf1e14bbf7d" category="paragraph">Questa soluzione dimostra che, utilizzando lo strumento software basato su interfaccia grafica e la tecnologia SnapCenter SnapMirror, è possibile configurare, implementare e gestire in modo semplice le operazioni di database del cloud ibrido.</block>
  <block id="26cc8c416b5c9fd6bec3dc68e6f2f0c8" category="paragraph">I seguenti video mostrano SnapCenter in azione:</block>
  <block id="edc6673fe24c4867029921bbe72f25cb" category="inline-link">Backup di un database Oracle su un cloud ibrido utilizzando SnapCenter</block>
  <block id="b10d6cd72b187359c3769fbf5ff10e4c" category="list-text"><block ref="0d160cec2141981b284cd9986321651e" category="inline-link-rx"></block></block>
  <block id="68d9033a95c0ed286c9b7e0e7454cd86" category="inline-link">SnapCenter - Clona SVILUPPO/TEST su cloud AWS per un database Oracle</block>
  <block id="da8d0116fa67f0499837675277668911" category="list-text"><block ref="da8d0116fa67f0499837675277668911" category="inline-link-rx"></block></block>
  <block id="3b04263461ad5a7b57aa872e093ec9fa" category="paragraph">In particolare, sebbene le illustrazioni di questo documento mostrino CVO come istanza di storage di destinazione nel cloud pubblico, la soluzione è anche pienamente validata per la nuova release del motore di storage FSX ONTAP per AWS.</block>
  <block id="c5a6d2f45fc4352f35e95d92c804b6f2" category="paragraph">Per testare la soluzione e i casi di utilizzo, è possibile richiedere un NetApp Lab-on-Demand SL10680 al seguente link: https://labondemand.netapp.com/lod3/labtest/request?nodeid=68761&amp;destination=lod3/testlabs[TL_AWS_004 HCoD: AWS - NW,SnapCenter(OnPrem)^].</block>
  <block id="0830319fc7a6b051bbb0602c2778e67c" category="paragraph"><block ref="0830319fc7a6b051bbb0602c2778e67c" category="inline-link-macro-rx"></block></block>
  <block id="41f2543265fcbcf566ce925409c1bfbb" category="summary">In questa sezione vengono fornite informazioni dettagliate su come migrare il database Oracle da on-premise a Azure NetApp Files e viceversa.</block>
  <block id="3b99478aefcc6039ddcb29f19ce3f1ee" category="doc">Migrazione del database dal cloud on-premise al cloud Azure</block>
  <block id="964310198f864c746c945ff1c6fffe3f" category="inline-link-macro">Precedente: Protezione del database.</block>
  <block id="413dcfd081f137889743981159ac9abe" category="paragraph"><block ref="413dcfd081f137889743981159ac9abe" category="inline-link-macro-rx"></block></block>
  <block id="3c2b924258f32094eb64883db57a778a" category="paragraph">In seguito alla decisione di Oracle di eliminare gradualmente i database a singola istanza, molte organizzazioni hanno convertito i database Oracle a singola istanza in database container multi-tenant. In questo modo è possibile spostare facilmente un sottoinsieme di database container chiamato PDB nel cloud con l'opzione di massima disponibilità, riducendo al minimo i tempi di inattività durante la migrazione.</block>
  <block id="a221bb2d4b0b28bb7e9aa40527e36333" category="paragraph">Tuttavia, se si dispone ancora di una singola istanza di un database Oracle, è possibile prima convertirla in un database container multi-tenant in uso prima di tentare il trasferimento di PDB.</block>
  <block id="3312d9383c6e42558bb6c7ffa86498b5" category="paragraph">Le sezioni seguenti forniscono dettagli sulla migrazione dei database Oracle on-premise nel cloud Azure in entrambi gli scenari.</block>
  <block id="b65ba7cc82289837e3a44b6025b8a104" category="paragraph">Se si dispone ancora di un database Oracle a istanza singola, è necessario convertirlo in un database container multi-tenant, sia che si desideri migrare nel cloud o meno, perché Oracle smetterà di supportare i database a istanza singola a breve.</block>
  <block id="60a4157f0722b484d4ce9ec02662db31" category="paragraph">Le seguenti procedure collegano un database a singola istanza in un database container come database collegabile o PDB.</block>
  <block id="aefccbe3e9382cbdd83d84fee06a408d" category="list-text">Creare un database di container shell sullo stesso host del database a istanza singola in un database separato<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>.</block>
  <block id="182e093a477c76844c12680be3deb7a4" category="list-text">Arrestare il database a singola istanza e riavviarlo in modalità di sola lettura.</block>
  <block id="48270a516aeb2dd47c2b7f5d897c3182" category="list-text">Eseguire<block ref="707fc638546e97f4dca068fcf2fbe277" prefix=" " category="inline-code"></block> procedura per generare i metadati del database.</block>
  <block id="61c2d2d903cc3e2bc374cc66b3a1572d" category="list-text">Chiudere il database a istanza singola.</block>
  <block id="d0e90ac40083de7010746f1c7afa8680" category="list-text">Avviare il database container.</block>
  <block id="c9b14b140c5af8df85a71e71e823fcd9" category="list-text">Eseguire<block ref="6f6e7bfe46efb74f46338dcd4b8d7530" prefix=" " category="inline-code"></block> Funzione per determinare se il non-CDB è compatibile con il CDB.</block>
  <block id="b4579eff709cfd4a9e9d9b3c7823a470" category="paragraph">Se l'output è sì, il non-CDB è compatibile ed è possibile passare alla fase successiva.</block>
  <block id="b788542aadbeda07cae67fad51f01ecf" category="paragraph">Se l'output è NO, il non-CDB non è compatibile ed è possibile controllare<block ref="40bcd9431704d488bfba8de25bdd0469" prefix=" " category="inline-code"></block> visualizza per scoprire perché non è compatibile. Tutte le violazioni devono essere corrette prima di continuare. Ad esempio, qualsiasi errata corrispondenza di versioni o patch deve essere risolta eseguendo un aggiornamento o l'utility di opatch. Dopo aver corretto le violazioni, eseguire<block ref="6f6e7bfe46efb74f46338dcd4b8d7530" prefix=" " category="inline-code"></block> Anche in questo caso, per garantire che il non-CDB sia compatibile con il CDB.</block>
  <block id="3dc81f6d88ee2f38ca30676e4b371634" category="list-text">Collegare la singola istanza non CDB.</block>
  <block id="10a9ce9a6e151e6ff04bee976e0cb1de" category="admonition">Se lo spazio sull'host non è sufficiente, il<block ref="4777c7eb130280b37f5b4b3abde7c586" prefix=" " category="inline-code"></block> È possibile utilizzare questa opzione per creare la PDB. In tal caso, una singola istanza non CDB non può essere utilizzata dopo il plug-in come PDB perché i file di dati originali sono stati utilizzati per la PDB. Assicurarsi di creare un backup prima della conversione in modo che vi sia qualcosa da ripristinare se qualcosa va storto.</block>
  <block id="03d9f2c68151dce9edd03b346e5b110c" category="list-text">Iniziare con l'aggiornamento PDB dopo la conversione se la versione tra la singola istanza non CDB di origine e la CDB di destinazione sono diverse. Per la conversione della stessa versione, questo passaggio può essere ignorato.</block>
  <block id="81954d0087f2bc7590c39792b2d3ff79" category="paragraph">Esaminare il file di log dell'aggiornamento in<block ref="8940bd010306ed7bc730469a2815003c" prefix=" " category="inline-code"></block> directory.</block>
  <block id="65f9a981d9b9caaa37a227c9d787c280" category="list-text">Aprire il database collegabile, verificare la presenza di violazioni del plug-in pdb e ricompilare gli oggetti non validi.</block>
  <block id="f4d5586e12195159e664b1f0a78cccd3" category="list-text">Eseguire<block ref="30636d635a272a80dff68679e08f1c7a" prefix=" " category="inline-code"></block> per aggiornare il dizionario dati.</block>
  <block id="182d7c995640cc8ef16b728a670fbe58" category="paragraph">Arrestare e riavviare il database dei container. L'ncdb viene disconnesso dalla modalità limitata.</block>
  <block id="d6af386b8be94481db3de6778b3fc24a" category="section-title">Migrare i database Oracle on-premise in Azure con il trasferimento dei dati PDB</block>
  <block id="da5d44e97cbc406251573e1664b5e1f0" category="paragraph">Il trasferimento di Oracle PDB con l'opzione di massima disponibilità utilizza la tecnologia di hot-clone PDB, che consente la disponibilità di PDB di origine mentre la PDB viene copiata sulla destinazione. Al passaggio, le sessioni e le connessioni vengono reindirizzate automaticamente al PDB di destinazione. Pertanto, il tempo di inattività viene ridotto al minimo indipendentemente dalla dimensione della PDB che viene ricollocata. NetApp offre un toolkit basato su Ansible che automatizza la procedura di migrazione.</block>
  <block id="a8efacce1c06e5f64504448dec25740a" category="list-text">Creare una CDB nel cloud pubblico Azure su una macchina virtuale Azure con la stessa versione e lo stesso livello di patch.</block>
  <block id="0f09a4e81820f79a89d0b433bb0de6ca" category="list-text">Dal controller Ansible, clonare una copia del toolkit di automazione.</block>
  <block id="33abd0ac6a3fb7ef8c104725e8360e85" category="list-text">Leggere le istruzioni nel file README.</block>
  <block id="59082266ab8171963eb8785041055ee1" category="list-text">Configurare i file delle variabili host Ansible per i server Oracle di origine e di destinazione e per il file di configurazione dell'host del server DB per la risoluzione dei nomi.</block>
  <block id="166811e58fa2fd17b3ab3305ca4b1948" category="list-text">Installare i prerequisiti del controller Ansible sul controller Ansible.</block>
  <block id="e40dd1f176a77cef20eb421dee4fea9f" category="list-text">Eseguire qualsiasi attività di pre-migrazione sul server on-premise.</block>
  <block id="aba7f3209eb8c49aca729c7368fb42fe" category="admonition">L'utente admin è l'utente di gestione dell'host server Oracle on-premise con privilegi sudo. L'utente admin viene autenticato con una password.</block>
  <block id="a1da14dd2e192d36a7fe7bae327c2b23" category="list-text">Eseguire il trasferimento di Oracle PDB dall'host Azure Oracle on-premise all'host Oracle di destinazione.</block>
  <block id="39f1871870cabd138bd313c450662e67" category="admonition">Il controller Ansible può essere collocato on-premise o nel cloud Azure. Il controller deve essere collegato all'host server Oracle on-premise e all'host VM Oracle di Azure. La porta del database Oracle (ad esempio 1521) è aperta tra l'host del server Oracle on-premise e l'host Azure Oracle VM.</block>
  <block id="63a48a0f7ee4b39ef32c11b92acc2baa" category="section-title">Opzioni aggiuntive per la migrazione dei database Oracle</block>
  <block id="7619081ba13aebf0c83d5660f9bf01bb" category="inline-link-macro">Processo decisionale per la migrazione dei database Oracle</block>
  <block id="0257ad9cf0c221fcf0c611f835c027ca" category="paragraph">Consultare la documentazione Microsoft per ulteriori opzioni di migrazione: <block ref="421a85ebca6e289a6eff559e7e35faf8" category="inline-link-macro-rx"></block>.</block>
  <block id="57daddd847cdbab22b7363630de48a2f" category="inline-link-macro">Guida introduttiva e sezione sui requisiti</block>
  <block id="82ba94e85d91493ea6c88423c0b34605" category="paragraph">Questa sezione descrive i passaggi necessari per preparare e implementare il database Oracle19c con la CLI. Assicurarsi di aver esaminato il <block ref="598ea103507880273a5a1840cac102d8" category="inline-link-macro-rx"></block> e preparò il tuo ambiente di conseguenza.</block>
  <block id="0f2d7675188dbfc7b9df587588bff71b" category="section-title">Scarica Oracle19c repo</block>
  <block id="4e2b619426350db7e7d5b09c96b8010b" category="section-title">Modificare il file hosts</block>
  <block id="b183e47af1fa85c93e4a4368205c3249" category="paragraph">Prima dell'implementazione, completare le seguenti operazioni:</block>
  <block id="c4ab1530ffd8a3306d47c804ca88240c" category="list-text">Modificare la directory na_oracle19c_deploy del file hosts.</block>
  <block id="bc1dd0e50a3c20e78cc2d680eaf32378" category="list-text">In [ONTAP] (indirizzo IP), modificare l'indirizzo IP in base all'IP di gestione del cluster.</block>
  <block id="6475f51ce7ff0a21a5635ea50b1f1a86" category="list-text">Nel gruppo [oracle], aggiungere i nomi degli host oracle. Il nome host deve essere risolto nel relativo indirizzo IP tramite DNS o il file hosts, oppure deve essere specificato nell'host.</block>
  <block id="5c3f5e9dc815ca28c7cf1ff64cdc61a2" category="list-text">Una volta completata questa procedura, salvare le modifiche.</block>
  <block id="b27994a7bba852ac9a8f1a262413e68b" category="paragraph">Il seguente esempio illustra un file host:</block>
  <block id="1caa2eee0ed6a6c5c6edcbc0320e8671" category="paragraph">Questo esempio esegue il playbook e implementa oracle 19c su due server oracle DB contemporaneamente. È inoltre possibile eseguire il test con un solo server DB. In tal caso, è necessario configurare un solo file di variabili host.</block>
  <block id="d11927d6f93a4edaa78dc52c6e34fd5f" category="admonition">Il playbook viene eseguito allo stesso modo, indipendentemente dal numero di host e database Oracle implementati.</block>
  <block id="030c98564d5fbd7c8672a76e2a593b21" category="section-title">Modificare il file host_name.yml in host_vars</block>
  <block id="86c40bb4891f3e6b34a2eece7bb19532" category="paragraph">Ciascun host Oracle dispone di un file di variabili host identificato dal nome host che contiene variabili specifiche dell'host. È possibile specificare qualsiasi nome per l'host. Modificare e copiare<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> Dalla sezione host VARS Config (Configurazione VAR host) e incollarla nel file desiderato<block ref="caa6779553864dba00727ae27752b182" prefix=" " category="inline-code"></block> file.</block>
  <block id="44505c1007599884b05c0148599ad1b0" category="section-title">Modificare il file vars.yml</block>
  <block id="41cdd95196e2753968e0d69375c41825" category="paragraph">Il<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> File consolida tutte le variabili specifiche dell'ambiente (ONTAP, Linux o Oracle) per l'implementazione Oracle.</block>
  <block id="271f9ccf9c8189bb1888d25c7f0e025b" category="list-text">Modificare e copiare le variabili dalla sezione VAR e incollarle nel<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> file.</block>
  <block id="78d77851709e21512097cee585c59d0c" category="section-title">Eseguire il manuale</block>
  <block id="8f42d9f703ada5b4f1374ca96a4f1cec" category="paragraph">Dopo aver completato i prerequisiti di ambiente richiesti e aver copiato le variabili in<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> e.<block ref="97513b66e909abfd622924972387a816" prefix=" " category="inline-code"></block>, ora sei pronto per implementare i playbook.</block>
  <block id="6226590ec5d4a109e4b93317425994c1" category="admonition">&lt;username&gt; deve essere modificato in base all'ambiente in uso.</block>
  <block id="24b2767982b51deb19947fb3e94279c6" category="section-title">Implementare database aggiuntivi sullo stesso host Oracle</block>
  <block id="5cc75d1029461de7ddcd02bbc784af26" category="paragraph">La parte Oracle del playbook crea un singolo database container Oracle su un server Oracle per ogni esecuzione. Per creare un database container aggiuntivo sullo stesso server, attenersi alla seguente procedura:</block>
  <block id="b4a35a2d5c3a4f3efb7c77f6bcd2a905" category="list-text">Rivedere le variabili host_vars.</block>
  <block id="5641cb71d4e10abef15918c2dd828917" category="list-text">Tornare al passaggio 3 - modificare<block ref="caa6779553864dba00727ae27752b182" prefix=" " category="inline-code"></block> file sotto<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block>.</block>
  <block id="24f0029973c35b16fc49847b27215915" category="list-text">Modificare la porta EM Express con un numero diverso se è stato installato EM Express.</block>
  <block id="365c64de6adc281d7f484029d1356855" category="list-text">Copiare e incollare le variabili host riviste nel file delle variabili host Oracle in<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block>.</block>
  <block id="b64219fd8290ac8a154f733df0825dbb" category="list-text">Eseguire il manuale con<block ref="b656a5ae2d7a83cf0ead9c81fb96ec17" prefix=" " category="inline-code"></block> contrassegnare come illustrato nella <block ref="1c892654e23ff69bf71caefc702aa8b4" category="inline-xref-macro-rx"></block>.</block>
  <block id="cdf4d8a8fa9326debf96606ee7177f41" category="doc">Esempi di codifica e output di AsciiDoc</block>
  <block id="6c1cc46d8764b2147f50c80e336ab770" category="paragraph">In questo documento sono inclusi alcuni esempi di origine asciidoc e dell'output risultante.</block>
  <block id="c252a357a127635943f82514442e62b3" category="section-title">Livelli di intestazione</block>
  <block id="8000c50cdc8b68dd9ea0d326040cbd63" category="paragraph">[Sottolineatura blu]*origine AsciDoc:*</block>
  <block id="3c2f44ba0863f4f0fcb5023aa4ee6ca2" category="paragraph">[Sottolineatura blu]*HTML generato:*</block>
  <block id="efea650a2edf10e173ba726fa4e90c5f" category="section-title">Titolo 1 (titolo sezione)</block>
  <block id="2b70e22920b3d78a96efdd65b4b37c1f" category="section-title">Titolo livello 2 (titolo sezione)</block>
  <block id="3742ded2a390654e38f763a70bd4e35a" category="section-title">Titolo livello 3 (titolo sezione)</block>
  <block id="4d1ebef97112908dabe0c9c786eaa7ba" category="section-title">Titolo livello 4 (titolo sezione)</block>
  <block id="44e6fd3a1839882d90b6020944c4aeb1" category="section-title">Titolo livello 5 (titolo sezione)</block>
  <block id="4eb5c705ea54813c084d88a3d5a668f0" category="admonition">Dovrebbe essere presente un solo titolo del documento (livello 0) per documento e i titoli delle sezioni non possono essere ignorati (i sottotitoli delle sezioni devono essere il livello di intestazione successivo sotto la sezione). Per questo motivo, il campione non viene visualizzato nell'output per eliminare gli errori di costruzione durante l'elaborazione.</block>
  <block id="691d1860ec58dd973e803e209697d065" category="section-title">Elenchi</block>
  <block id="d3263947659da25e39643e07688fb919" category="paragraph">Elenco non ordinato:</block>
  <block id="6e991c331de28266251c487c42df1f10" category="list-text">questo è un elenco non ordinato</block>
  <block id="d1ad2884248be2067d5bc70a584eba6d" category="list-text">si tratta ancora di un elenco non ordinato</block>
  <block id="b84268ab94bb6da5f97f344b7f78bf9f" category="list-text">si tratta di un elemento secondario in un elenco non ordinato</block>
  <block id="434aab8bf1245d04dc3e96af08e1842e" category="paragraph">Elenco ordinato:</block>
  <block id="07628350d195b6ebaae83ec46df8e1c3" category="list-text">questo è un elenco ordinato</block>
  <block id="964f443f29145e9fa43a38671d07d447" category="list-text">questo è ancora un elenco ordinato</block>
  <block id="239cecc0851db8990cd18461b6243348" category="list-text">si tratta di un elemento secondario in un elenco ordinato</block>
  <block id="fff0d600f8a0b5e19e88bfb821dd1157" category="section-title">Immagini</block>
  <block id="340c4d7a25252d5807344db646713010" category="paragraph">È possibile collegarsi alle immagini all'interno del repository o in qualsiasi punto del Web. Per le immagini all'interno del repository, queste vengono posizionate nella cartella dei file multimediali, quindi è necessario assicurarsi che ":imagesdir: ./media/" sia impostato correttamente.</block>
  <block id="13d002c81cf56705c2becc11e5ed9a4f" category="image-alt">Immagine all'interno del repository</block>
  <block id="43d8eb4fa9bb019f23b6835a3d3c93d7" category="image-alt">Immagine esterna al repository</block>
  <block id="bd908db5ccb07777ced8023dffc802f4" category="section-title">Link</block>
  <block id="69faa60007e518154e5dfa6c7cb9606d" category="paragraph">Analogamente alle immagini, i link possono fare riferimento ai documenti all'interno del repository o in qualsiasi punto del web. Per i riferimenti interni, è importante assicurarsi che il percorso all'origine del collegamento sia specificato nell'istruzione "link::".</block>
  <block id="8cc0407dfab26edc02bac943afa1c50d" category="inline-link-macro">Registro delle modifiche delle soluzioni NetApp (interno)</block>
  <block id="e5eddd5cb0a7a1048bd37c62e18ae2dd" category="paragraph"><block ref="e5eddd5cb0a7a1048bd37c62e18ae2dd" category="inline-link-macro-rx"></block></block>
  <block id="4d9909e75daa4ee8685674e4136d2046" category="inline-link-macro">Registro delle modifiche delle soluzioni NetApp (esterno)</block>
  <block id="bc630a540bb452bb9f726ed7c7e14715" category="paragraph"><block ref="bc630a540bb452bb9f726ed7c7e14715" category="inline-link-macro-rx"></block></block>
  <block id="3bdabc119341b76ec34be01ada064a84" category="section-title">Contenuto comprimibile (a.k.a. Torsioni)</block>
  <block id="b78a3223503896721cca1303f776159b" category="example-title">Titolo</block>
  <block id="b66944886034ca73431f2e338216bd4b" category="paragraph">Qui viene visualizzato il testo da collassare.</block>
  <block id="70f60b4a0e07b27ad4d42c2ede9220f3" category="admonition">Fare clic su "Title" (titolo) per visualizzare il contenuto espanso</block>
  <block id="1cc54ce67047f47e6e0b998e4757610b" category="section-title">Creazione di una tavola</block>
  <block id="2e0fea6cc0d29edadf544e93bf56013c" category="cell">Colonna A</block>
  <block id="778c1ae51201605a08ca7745c8dd3856" category="cell">Colonna B</block>
  <block id="00862db58047a1191cc2f83e69ff9892" category="cell">Colonna C</block>
  <block id="19273115ac8897b4064a43ccf533c3ba" category="cell">Testo nella colonna A.</block>
  <block id="9ed785bee043f58e69669715e38bfe2d" category="cell">Testo nella colonna B</block>
  <block id="ec7498417999a2d1bc9ab843b061d478" category="cell">Testo nella colonna C.</block>
  <block id="19ffdf534588898ed43f67fde767f1fd" category="paragraph">Ecco un altro esempio in cui una riga copre l'intera tabella e altre righe hanno dati che si estendono su più colonne:</block>
  <block id="bf767d30d483b6701f943a456017bf9d" category="cell">Intestazione colonna 1</block>
  <block id="6e3e0843cfe6ff00d3b74bf168580453" category="cell">Intestazione colonna 2</block>
  <block id="a2fa10d34df17b106b689ca93f07c770" category="cell">Intestazione colonna 3</block>
  <block id="61bd6ed3bebad9294ee30668abbeff3c" category="cell">Intestazione colonna 4</block>
  <block id="1a168c8aca72f77bf84798bb31a4cb8c" category="cell">Si tratta di una riga davvero lunga che si estende su tutte e 4 le colonne della tabella. È l'unica cella di questa riga e non lascia celle vuote.</block>
  <block id="4f14cfb44ee45b336256dd439e135021" category="cell">Si tratta di una riga lunga che si estende su 3 colonne della tabella lasciando una cella vuota.</block>
  <block id="43eddd3ae82d79991b5cefa462bed9d7" category="cell">Questa riga si estende su 2 colonne e lascia 2 celle vuote.</block>
  <block id="77631ca4f0e08419b70726a447333ab6" category="cell">Questo</block>
  <block id="f1965a857bc285d26fe22023aa5ab50d" category="cell">riga</block>
  <block id="a2a551a6458a8de22446cc76d639a9e9" category="cell">è</block>
  <block id="fea087517c26fadd409bd4b9dc642555" category="cell">normale</block>
  <block id="00a4cb60b0815316a1416dae59b77543" category="inline-link-macro">Documentazione di AsciiDoc</block>
  <block id="c784ba850708b73450bc80d79e01313e" category="admonition">È possibile specificare diverse opzioni per modificare il layout di una tabella. Per ulteriori informazioni, cercare un esempio nel repository (versione HTML) che si desidera ottenere e accedere a VScode per visualizzare l'origine o visitare il sito <block ref="8ce64cdd9ff98df64c05c93fb30bd0b8" category="inline-link-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="e2f7e3242523777351b6658f86564416" category="section-title">Blocchi a schede</block>
  <block id="d6d281824a9f2f56cd13926cacd6f6c3" category="open-title">Prima scheda</block>
  <block id="a13c148381823333364efc7a66153681" category="paragraph">Il contenuto per la prima scheda va qui</block>
  <block id="99a1d6da572d7987b546c07b1053d7b0" category="open-title">Seconda scheda</block>
  <block id="d93aaa34fa764ccd0a071f1c256e0a6f" category="paragraph">Il contenuto per la seconda scheda va qui</block>
  <block id="3b04793c63a616fa65f54f1d98c263e1" category="admonition">Fare clic su "seconda scheda" per visualizzare il contenuto della sezione.</block>
  <block id="b2859c129ed9d2683658aaef48d31759" category="doc">&lt;Solution Name&gt;</block>
  <block id="4845fee41e2c9edce3bd46094fdb57a2" category="paragraph">Autore/i: &lt;name&gt;, &lt;title&gt;, &lt;company&gt;</block>
  <block id="50f68cc3bee11411ba8ee639a7ed59d7" category="list-text">&lt;use case 1&gt;</block>
  <block id="7a28dc06a92c8c13aba4217cc065d556" category="list-text">&lt;use case 2&gt; ...</block>
  <block id="bfbe592724efe7b70f86b50a78741381" category="list-text">&lt;use case n&gt;</block>
  <block id="46c04e63acdf5955295f68d8a963bfbd" category="paragraph">Questa soluzione è destinata al &lt;role&gt; interessato a &lt;goal&gt;.</block>
  <block id="1d00e7dce692e8dc3f6877f035e3a616" category="paragraph">OPPURE</block>
  <block id="732f94f3061dc1751b3c7e3ea8566239" category="paragraph">Questa soluzione è destinata a:</block>
  <block id="dab739113e8cfebbcfcfaea1515c0bcf" category="list-text">&lt;role&gt;, interessato a &lt;goal&gt;,</block>
  <block id="7367185552beb127edfea2f14982e67f" category="list-text">&lt;role&gt;, che è interessato a &lt;goal&gt;.</block>
  <block id="b98cf6de800fd94a50eaa1fff8bfd974" category="section-title">Ambiente di test/convalida della soluzione</block>
  <block id="aca7234abb238eb8646973440eb294d3" category="paragraph">Il test/convalida di questa soluzione è stato eseguito in un laboratorio che potrebbe corrispondere o meno all'ambiente di implementazione finale. Per ulteriori informazioni, fare riferimento alle seguenti sezioni.</block>
  <block id="bb46e30937334302b789ae4644fdc412" category="image-alt">Diagramma dell'architettura della soluzione</block>
  <block id="39f3ba4cf87d6a47181e787c275344e5" category="example-title">Componenti hardware/software</block>
  <block id="619d009ae026df3741648cc5d1d82614" category="cell">&lt;hardware name&gt;</block>
  <block id="295146e011d375f76fc8093d2a5f746a" category="cell">&lt;model / version&gt;</block>
  <block id="18206c5add24b8898426959c811b779b" category="cell">Ulteriori informazioni</block>
  <block id="b8b4ca3eb830ebaf39f536d59b342a79" category="cell">&lt;software name&gt;</block>
  <block id="192dcc5c64e1f37fd6c9e50a1b157443" category="cell">&lt;version&gt;</block>
  <block id="94f04537971d7a4a561c607ec55952a2" category="example-title">Note aggiuntive</block>
  <block id="5f8c710bd804698095dac1f01702f2dc" category="list-text">Nota 1</block>
  <block id="e71faea04999fd95e327c2ae1b14b591" category="list-text">Nota 2 ...</block>
  <block id="b5be88cc2b21098a0407835f4cf72ead" category="list-text">Nota n</block>
  <block id="39a42e9bc59c02bbbf3ed4eb16b1cca4" category="paragraph">L'implementazione di questa soluzione può essere completata:</block>
  <block id="7300ce5706dee36f69c820d38d478b65" category="list-text">Manualmente seguendo le istruzioni dettagliate complete di screenshot,</block>
  <block id="8412750c53dfad13bb8a2baccb69df63" category="list-text">Manualmente seguendo i video che mostrano i passaggi da eseguire, oppure</block>
  <block id="ec325ca23fb4f2a557b0efcf8667bf31" category="list-text">Seguendo automaticamente le istruzioni fornite nella sezione relativa all'automazione.</block>
  <block id="d22702677ec3ab6384e6dae329022796" category="open-title">Istruzioni dettagliate</block>
  <block id="335680aa8906e185cbdaebb23568afb0" category="example-title">Fase 1: &amp;Lt;nome del passo descrittivo&amp;gt;</block>
  <block id="8368bea2982e0341bdf3dd2e21ae59ba" category="list-text">Attività 1</block>
  <block id="233777e8b1ab8b0114d7518acdbd2377" category="list-text">Compito 2 ...</block>
  <block id="246b81c0be9905296fd43f043d65acf9" category="list-text">Mansione n</block>
  <block id="dc84800e606f171d76211870801056d9" category="example-title">Fase 2: &amp;Lt;nome del passo descrittivo&amp;gt;</block>
  <block id="2f43b42fd833d1e77420a8dae7419000" category="paragraph">...</block>
  <block id="1361b538eba6bc2813d883fde1eaa379" category="example-title">Fase n: &amp;Lt;nome del passo descrittivo&amp;gt;</block>
  <block id="a0c7049fba5354f8f1711e379e6f4201" category="open-title">Video - Panoramica</block>
  <block id="c6388aefff17f19b12b255766fe6b6fe" category="paragraph">&lt;Include the video(s) details here&gt;</block>
  <block id="b9e9e9354502c35dc60d3744fb1506e6" category="paragraph">&lt;include the automated steps/process/videos here&gt;</block>
  <block id="b57b7771f6b9c2ff769c133b18814390" category="section-title">Altre opzioni di implementazione</block>
  <block id="bbc8a731eb9387bfdc71e5f35721af4c" category="example-title">&amp;Lt;Descrizione dell'opzione 1&amp;gt;</block>
  <block id="e83c35e6afea2838c146155292120e3a" category="paragraph">&lt;enter the details of the option here&gt;</block>
  <block id="a8ec4bf9dc004e6dc4ec8c7c8cb307a3" category="example-title">&amp;Lt;Descrizione dell'opzione 2&amp;gt;</block>
  <block id="13e60333560bb11c5611ca7faa0dff3b" category="example-title">&amp;Lt;Descrizione dell'opzione n&amp;gt;</block>
  <block id="43437c4ac7246d8571bf69d647faab0e" category="inline-link-macro">Descrizione del documento</block>
  <block id="0da1d1196a3aec2a948937502374b5bb" category="list-text"><block ref="0da1d1196a3aec2a948937502374b5bb" category="inline-link-macro-rx"></block></block>
  <block id="71214e9c5af2e86babf8e62565a8dda2" category="inline-link-macro">Descrizione di un altro documento</block>
  <block id="2757c805d63f926c06b19e462b16de69" category="list-text"><block ref="2757c805d63f926c06b19e462b16de69" category="inline-link-macro-rx"></block></block>
  <block id="10b2aec15aae4d935355e27497e66c5f" category="summary">Serie di video e demo che illustrano le funzionalità di molte delle soluzioni NetApp</block>
  <block id="6354d74cd74c1d9f49224ac4e6209bab" category="doc">Soluzioni NetApp: Video e demo</block>
  <block id="60b5065968cf0f66d862a344124f6415" category="paragraph">Panoramica dei video e delle demo che evidenziano le funzionalità specifiche di molte delle soluzioni NetApp.</block>
  <block id="954a2b08ded0ca2c881930f5ebeee24a" category="example-title">Intelligenza artificiale (ai) e analisi dei dati moderna</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="inline-link-macro">Soluzioni ai di NetApp</block>
  <block id="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="list-text"><block ref="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="inline-link-macro-rx"></block></block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link-macro">MLOPS</block>
  <block id="90e97692c42b1eb0ec22c639049d78a1" category="list-text"><block ref="90e97692c42b1eb0ec22c639049d78a1" category="inline-link-macro-rx"></block></block>
  <block id="6ff1dafebf930a9c5fef12bf43046987" category="example-title">Applicazioni e database aziendali</block>
  <block id="031004dd1775e5fd9d35b534e33217ea" category="paragraph">[Sottolineare] * Video per database open source* n.</block>
  <block id="5b70a7f45ddd32cacfe28af238662d3d" category="video-title">Implementazione automatica PostgreSQL, configurazione della replica ha/DR, failover, risincronizzazione</block>
  <block id="672d7bebe35b300386767050d4222453" category="paragraph">[Sottolineare] * Video per la modernizzazione di Oracle con cloud ibrido in AWS e FSX* n.</block>
  <block id="deb1d0bb3f3f4ef0121635c0f832a3bf" category="video-title">Parte 1 - caso d'utilizzo e architettura della soluzione</block>
  <block id="369b9aec1beb25441dc7c7fb46bc0fc6" category="video-title">Parte 2a - migrazione del database da on-premise ad AWS utilizzando il trasferimento automatizzato di PDB con la massima disponibilità</block>
  <block id="2edb94ef9695015c5cd01fec59bcc782" category="video-title">Parte 2b - migrazione del database da on-premise ad AWS utilizzando la console BlueXP tramite SnapMirror</block>
  <block id="59fa2b2110d3350efd262bd841c10975" category="video-title">Parte 3 - Configurazione automatica della replica ha/DR del database, failover, risincronizzazione</block>
  <block id="938d46c61cee67ddb1711167aba9f463" category="video-title">Parte 4a - clone del database per sviluppo/test con interfaccia utente SnapCenter dalla copia di standby replicata</block>
  <block id="09b285fbf39efff75f085bbadedde45e" category="video-title">Parte 4b - Backup, ripristino e clonazione del database con l'interfaccia utente di SnapCenter</block>
  <block id="45885d9d91879afc9c37a8b3e046aac4" category="video-title">Parte 4c - Backup e ripristino del database con backup e ripristino di BlueXP SaaS Apps</block>
  <block id="c12ff13215c1f6de4c6dad4b8a475398" category="paragraph">[Sottolineato] * Video per database SQL Server* n.</block>
  <block id="2b1dd692c0da980c4ec2ad9fd523c47d" category="inline-link-macro">Cluster ad alta disponibilità SQL su Azure NetApp Files</block>
  <block id="98e44b407e40d6f57f90877a1960efae" category="list-text"><block ref="98e44b407e40d6f57f90877a1960efae" category="inline-link-macro-rx"></block></block>
  <block id="befb671d4726ae8f3ef8dab781033dcc" category="inline-link-macro">Oracle Multi-tenant Pluggable Database Clone con snapshot di storage</block>
  <block id="e2cd0f8dc5281c13263991c6973df405" category="list-text"><block ref="e2cd0f8dc5281c13263991c6973df405" category="inline-link-macro-rx"></block></block>
  <block id="9efcc0ad3c93b238cc0495e3c87b715f" category="inline-link-macro">Implementazione automatizzata di Oracle 19c RAC su FlexPod con Ansible</block>
  <block id="bf49d74794280c8a3a207a97d6447db7" category="list-text"><block ref="bf49d74794280c8a3a207a97d6447db7" category="inline-link-macro-rx"></block></block>
  <block id="ab440644113265a70e7e0bb7c44b2f63" category="paragraph">*Case study*</block>
  <block id="33be49f7ebc56eb7d336a201f7ac0df6" category="inline-link-macro">SAP su Azure NetApp Files</block>
  <block id="4efd965058c15f138d2c4d43454c3012" category="list-text"><block ref="4efd965058c15f138d2c4d43454c3012" category="inline-link-macro-rx"></block></block>
  <block id="d8cefe0428d28368238dbbeabef9c83f" category="example-title">Multicloud ibrido (HMC)</block>
  <block id="493f775d3c83d2c658056477b1d58f74" category="paragraph">[Sottolineato] * Video per AWS/VMC* n.</block>
  <block id="d7d56735bb43053ca43b2d9698b2623c" category="video-title">Installazione della configurazione e dell'implementazione di VMware HCX per VMC</block>
  <block id="e906083dc0b31806eab68df2c340504f" category="video-title">Dimostrazione della migrazione a freddo con VMware HCX per VMC e FSxN</block>
  <block id="62184265581f788d642b26b13c273b93" category="paragraph">[Sottolineato] * Video per Azure/AVS* n.</block>
  <block id="8eb2fa7c0d2a676485a155077b770fdd" category="video-title">Dimostrazione della migrazione a freddo con VMware HCX per AVS e ANF</block>
  <block id="664115ac899ebaf481e2b75540d5c56c" category="video-title">Dimostrazione di VMotion con VMware HCX per AVS e ANF</block>
  <block id="914c1d4cdf840b7b030978f1b07915d8" category="video-title">Dimostrazione della migrazione in blocco con VMware HCX per AVS e ANF</block>
  <block id="8b211d4c76db32ffc96c88ef826c76ac" category="example-title">MultiCloud ibrido con Red Hat OpenShift</block>
  <block id="7726892a5c5734a343a1539f3b3f6b28" category="video-title">ROSA DR con Astra Control Service</block>
  <block id="585d77f28be6ed7195a002752abf2272" category="video-title">Integrazione di FSxN con Astra Trident</block>
  <block id="bcb10d9a12c5b72d4b9a3e3af5c448bd" category="video-title">Failover e fail-back delle applicazioni su ROSA con FSxN</block>
  <block id="a1b302ac6b7c1aec08c902797c133e13" category="paragraph-title">Dr utilizzando Astra Control Center</block>
  <block id="7c75a912761dd20f4e8a9aceb430dc5f" category="paragraph"><block ref="7c75a912761dd20f4e8a9aceb430dc5f" category="inline-link-macro-rx"></block></block>
  <block id="25aa061b5bc79f1f85182fd8ca1f3165" category="inline-link-macro">Raccolta video VMware</block>
  <block id="847fff0b97afdc8ceabb5c717634d413" category="list-text"><block ref="847fff0b97afdc8ceabb5c717634d413" category="inline-link-macro-rx"></block></block>
  <block id="5bfc3700f5feddf9397449627edbbdb9" category="example-title">Container/Kubernetes</block>
  <block id="665b01682714e51e25b232a31a06b70e" category="inline-link-macro">Video NetApp con Google anthos</block>
  <block id="810afd9a3a1d12fd9dd41977c9ed1781" category="list-text"><block ref="810afd9a3a1d12fd9dd41977c9ed1781" category="inline-link-macro-rx"></block></block>
  <block id="668ed010c67826eb36328daf61db1909" category="inline-link-macro">Video NetApp con VMware Tanzu</block>
  <block id="f05d310ffaf62c6645cbc528c52f46e1" category="list-text"><block ref="f05d310ffaf62c6645cbc528c52f46e1" category="inline-link-macro-rx"></block></block>
  <block id="19ec96fa965825479da361c5626b34f0" category="inline-link-macro">Video NetApp per DevOps</block>
  <block id="f1afd91555fd6fb162a6343cf91fdc05" category="list-text"><block ref="f1afd91555fd6fb162a6343cf91fdc05" category="inline-link-macro-rx"></block></block>
  <block id="70fc473134508f4cbdb235049ab72bc6" category="inline-link-macro">Video di NetApp con Red Hat OpenShift</block>
  <block id="f86f2e66a68f28ad563c787ff0145ba4" category="list-text"><block ref="f86f2e66a68f28ad563c787ff0145ba4" category="inline-link-macro-rx"></block></block>
  <block id="44f55a60cc8f70d1e10efc62b75eeddc" category="doc">Soluzioni NetApp per VMware negli hyperscaler</block>
  <block id="51b0e38e5ec7edbe37b6672987ce5f2e" category="paragraph">Scopri di più sulle funzionalità offerte da NetApp ai tre (3) hyperscaler principali: Da NetApp come dispositivo di storage connesso come guest o come datastore NFS supplementare alla migrazione dei flussi di lavoro, all'estensione/diffusione nel cloud, al backup/ripristino e al disaster recovery.</block>
  <block id="f21c97f5b239021bb3f13d148516abb4" category="paragraph">Scegli il tuo cloud e lascia che NetApp faccia il resto!</block>
  <block id="c1304f98c6be845a236d7a27951ece4f" category="paragraph"><block ref="c1304f98c6be845a236d7a27951ece4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca4ac823f3f130f3c78d6ac26ba9f46b" category="admonition">Per visualizzare le funzionalità di un hyperscaler specifico, fare clic sulla scheda appropriata per tale hyperscaler.</block>
  <block id="addac5e706b2148d9c7b3bbe2d2fcdde" category="paragraph">Passare alla sezione relativa al contenuto desiderato selezionando una delle seguenti opzioni:</block>
  <block id="06262015df4851b380189212274a0e3e" category="inline-link-macro">VMware nella configurazione degli hyperscaler</block>
  <block id="7f08237a127b62af444f720f15216cee" category="list-text"><block ref="7f08237a127b62af444f720f15216cee" category="inline-link-macro-rx"></block></block>
  <block id="c774c23e9a97e08bfa096f1cbf18cc17" category="inline-link-macro">Opzioni di storage NetApp</block>
  <block id="d3fc27ff58dc3a0d839a16af858e7999" category="list-text"><block ref="d3fc27ff58dc3a0d839a16af858e7999" category="inline-link-macro-rx"></block></block>
  <block id="6db49f93b02d752e6b80616d15759056" category="inline-link-macro">Soluzioni cloud NetApp/VMware</block>
  <block id="a088d0b353502e225826d0feb3041d57" category="list-text"><block ref="a088d0b353502e225826d0feb3041d57" category="inline-link-macro-rx"></block></block>
  <block id="833413440fbbe13837d8b58256cfba65" category="paragraph">Come per i sistemi on-premise, la pianificazione di un ambiente di virtualizzazione basato sul cloud è fondamentale per un ambiente pronto per la produzione di successo per la creazione di macchine virtuali e la migrazione.</block>
  <block id="b4ea7c36c784b6da08e2b44d82018c65" category="open-title">AWS/VMC</block>
  <block id="162e9e1fd4657b8d9588a5ae8c8e6e66" category="paragraph">Questa sezione descrive come configurare e gestire VMware Cloud su AWS SDDC e utilizzarlo in combinazione con le opzioni disponibili per la connessione dello storage NetApp.</block>
  <block id="71b51633ceea83cdf1136196fce39901" category="admonition">Lo storage in-guest è l'unico metodo supportato per connettere Cloud Volumes ONTAP ad AWS VMC.</block>
  <block id="b9b37266c1f6c6a5244f3fef48f644e1" category="list-text">Implementazione e configurazione di VMware Cloud per AWS</block>
  <block id="b4f284d3b5bb40ee91901933b8f7ef5f" category="list-text">Connetti VMware Cloud a FSX ONTAP</block>
  <block id="57669ed11798d25a8216675c3f0f6ecf" category="inline-link-macro">Procedura di configurazione per VMC</block>
  <block id="fc835ae678d144f168b78fafb98286b2" category="paragraph">Visualizza i dettagli <block ref="0bca421d9cd22e10e81bd0c987fad54b" category="inline-link-macro-rx"></block>.</block>
  <block id="9e88bf7f3ee359d8f536975aa39ab6a5" category="open-title">Azure/AVS</block>
  <block id="491aa8f554f95207a4b7d47f89777e13" category="paragraph">Questa sezione descrive come configurare e gestire Azure VMware Solution e utilizzarla in combinazione con le opzioni disponibili per la connessione dello storage NetApp.</block>
  <block id="9761d5208d76a88ba5a08152c4431c2f" category="admonition">Lo storage in-guest è l'unico metodo supportato per connettere Cloud Volumes ONTAP alla soluzione VMware Azure.</block>
  <block id="3d24cd3e433bf1992e011c9f92c3fab6" category="list-text">Registrare il provider di risorse e creare un cloud privato</block>
  <block id="a1123889b6465e93a2209c2a0ca667ef" category="list-text">Connettersi a un gateway di rete virtuale ExpressRoute nuovo o esistente</block>
  <block id="ae1764c7cb70aed2d4548c424d7bf34a" category="list-text">Convalidare la connettività di rete e accedere al cloud privato</block>
  <block id="293193a848a4345d095f41ff490fd1a4" category="inline-link-macro">Procedura di configurazione per AVS</block>
  <block id="e2501a40b45cdc3295c28e82fc2ffa18" category="paragraph">Visualizza i dettagli <block ref="29745c898e96ab7473e2b2c19fa34fbf" category="inline-link-macro-rx"></block>.</block>
  <block id="7e7790ea083a371632d0764a881695f6" category="open-title">GCP/GCVE</block>
  <block id="6ad49d2b544134f2192d1612a572bdd6" category="paragraph">Questa sezione descrive come configurare e gestire GCVE e utilizzarlo in combinazione con le opzioni disponibili per la connessione dello storage NetApp.</block>
  <block id="a74a86037d1564ce62843a1252f6ad37" category="admonition">Lo storage in-guest è l'unico metodo supportato per connettere Cloud Volumes ONTAP e Cloud Volumes Services a GCVE.</block>
  <block id="11a31c6d83a723b3ea9c348c22e86238" category="list-text">Implementare e configurare GCVE</block>
  <block id="3e5cc29621d2619be0d7b1569da6909c" category="list-text">Attiva accesso privato a GCVE</block>
  <block id="e44b11e9adb07a14c72f48599f700cd4" category="inline-link-macro">Procedura di configurazione per GCVE</block>
  <block id="0969e77be69a346b123e1b2c625e25b0" category="paragraph">Visualizza i dettagli <block ref="7ffa56a4f5c5cf9fb86200a4dd2e1a5d" category="inline-link-macro-rx"></block>.</block>
  <block id="0ab328bbf8073ef01a9d54504bf7b317" category="paragraph">Lo storage NetApp può essere utilizzato in diversi modi, come guest connesso o come datastore NFS supplementare, all'interno di ciascuno dei 3 principali hyperscaler.</block>
  <block id="94772ee4b241fe0706c3aaef6e3a4505" category="inline-link-macro">Opzioni di storage NetApp supportate</block>
  <block id="67b586cdf9703ba67abe711415768cc0" category="paragraph">Visitare il sito <block ref="01a9bd21bfc714c8dec8aabc5b88eda7" category="inline-link-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="60ce80493de8468bdfd597af1c219a9f" category="paragraph">AWS supporta lo storage NetApp nelle seguenti configurazioni:</block>
  <block id="4a7272ea95323d5fef2e377b91b5f16d" category="list-text">FSX ONTAP come storage connesso guest</block>
  <block id="3017a9031d66c55b0258c102decfd1b9" category="list-text">Cloud Volumes ONTAP (CVO) come storage connesso guest</block>
  <block id="b6f0b1a9bd2c9c15cf02f97ead58d81f" category="list-text">FSX ONTAP come datastore NFS supplementare</block>
  <block id="52be4c6acc8cca3a598e3a651421de3d" category="inline-link-macro">Opzioni di storage di connessione guest per VMC</block>
  <block id="aa98d71f784cc09bb41639407a3263d5" category="inline-link-macro">Opzioni aggiuntive del datastore NFS per VMC</block>
  <block id="d1a83ba46ad33cdd3fc8bd7a4e73176d" category="paragraph">Visualizza i dettagli <block ref="faae832115390401ac20af18b263017a" category="inline-link-macro-rx"></block>. Visualizza i dettagli <block ref="5f92906354f0392b0588cf1731a5faf9" category="inline-link-macro-rx"></block>.</block>
  <block id="5f18b04dd7d7089a2177c4c930d8d57f" category="paragraph">Azure supporta lo storage NetApp nelle seguenti configurazioni:</block>
  <block id="1ffaf40c19facb6829b48b667d1dcaa3" category="list-text">Azure NetApp Files (ANF) come storage connesso guest</block>
  <block id="dd4fe8081ff6ae9c7e9975937aff6576" category="list-text">Azure NetApp Files (ANF) come datastore NFS supplementare</block>
  <block id="a8e9a5787febc7740af29cd0bebf2e95" category="inline-link-macro">Opzioni di storage di connessione guest per AVS</block>
  <block id="483a9a3bc528f4d194f9f8f3d2a8411a" category="inline-link-macro">Opzioni aggiuntive del datastore NFS per AVS</block>
  <block id="7772cfe9c74977a26d43cfda8576ff1a" category="paragraph">Visualizza i dettagli <block ref="b477b575563628f6202758f8f4d6ef57" category="inline-link-macro-rx"></block>. Visualizza i dettagli <block ref="e443f734d29f2f5bbba9449696a3f3f6" category="inline-link-macro-rx"></block>.</block>
  <block id="8f08ff97ca555f50f0d05fdf950a0568" category="paragraph">Google Cloud supporta lo storage NetApp nelle seguenti configurazioni:</block>
  <block id="9bb210767ccb9c085c816c82f3b6b1cb" category="list-text">Cloud Volumes Service (CVS) come storage connesso al guest</block>
  <block id="b2bf74ba9b2080c50a7214bcabdb670c" category="list-text">Cloud Volumes Service (CVS) come datastore NFS supplementare</block>
  <block id="2da991b20a7647acbdd67154515723cf" category="inline-link-macro">Opzioni di storage di connessione guest per GCVE</block>
  <block id="5d49b0ee57ad4b529c897b49789aa965" category="paragraph">Visualizza i dettagli <block ref="39710aaf95ad3f60e444c45fa2d1a561" category="inline-link-macro-rx"></block>.</block>
  <block id="8031035e3922dbc188f876cc6fb8434d" category="inline-link-macro">Supporto del datastore NetApp Cloud Volumes Service per il motore VMware di Google Cloud (blog NetApp)</block>
  <block id="71f1bcf72187cb460ce8534fd5439962" category="inline-link-macro">Come utilizzare NetApp CVS come datastore per Google Cloud VMware Engine (Google blog)</block>
  <block id="5ca70e1272bcfe0644f6a52e2d971039" category="paragraph">Scopri di più <block ref="0d04aae7b3b1a3149a54ebc44d21fc72" category="inline-link-macro-rx"></block> oppure <block ref="c1e740ec580b7430a1cc324eec4af172" category="inline-link-macro-rx"></block></block>
  <block id="0198315ccfb9d5c56e9c865f01bee365" category="paragraph">Con le soluzioni cloud NetApp e VMware, molti casi di utilizzo sono semplici da implementare nell'hyperscaler scelto. VMware definisce i casi di utilizzo del carico di lavoro del cloud primario come:</block>
  <block id="3fac70d2bc4023bd8c5bb8f7c93b16e8" category="list-text">Protect (include disaster recovery e backup/ripristino)</block>
  <block id="10b5b21ed1ee90eca305b558caf7d03b" category="list-text">Migrare</block>
  <block id="3bc026b815790a05493fa56fc4b8d8bd" category="list-text">Estendi</block>
  <block id="e0525641cbca59e199eed50739c0c3b8" category="inline-link-macro">Esplora le soluzioni NetApp per AWS/VMC</block>
  <block id="3a602723648efc3d9a864906b6ec2d9c" category="paragraph"><block ref="3a602723648efc3d9a864906b6ec2d9c" category="inline-link-macro-rx"></block></block>
  <block id="d18a9fea9b4ca38bf7f042e32420e14e" category="inline-link-macro">Esplora le soluzioni NetApp per Azure / AVS</block>
  <block id="bd6708bcf0c060976324512475c1a212" category="paragraph"><block ref="bd6708bcf0c060976324512475c1a212" category="inline-link-macro-rx"></block></block>
  <block id="cac969404c87e9e141b320e34ee1ba4b" category="inline-link-macro">Esplora le soluzioni NetApp per Google Cloud Platform (GCP) / GCVE</block>
  <block id="7f86100566a3de37a45dc2bd4ea422a0" category="paragraph"><block ref="7f86100566a3de37a45dc2bd4ea422a0" category="inline-link-macro-rx"></block></block>
  <block id="d7fe32206230432c446b09e24ab3f41a" category="doc">TR-4955: Disaster recovery con FSX per ONTAP e VMC (AWS VMware Cloud)</block>
  <block id="e99df6551992d3c39b8c5e87ee8a451f" category="paragraph">Il disaster recovery nel cloud è un metodo resiliente e conveniente per proteggere i carichi di lavoro da interruzioni del sito ed eventi di corruzione dei dati (ad esempio ransomware). Con la tecnologia NetApp SnapMirror, i carichi di lavoro VMware on-premise possono essere replicati su FSX per ONTAP in esecuzione in AWS.</block>
  <block id="c52f53db08961cb5fa061b55ca6812c7" category="paragraph">È possibile utilizzare Disaster Recovery Orchestrator (DRO, una soluzione basata su script con interfaccia utente) per ripristinare senza problemi i carichi di lavoro replicati da on-premise a FSX per ONTAP. DRO automatizza il ripristino dal livello SnapMirror, attraverso la registrazione delle macchine virtuali su VMC, fino alle mappature di rete direttamente su NSX-T. Questa funzione è inclusa in tutti gli ambienti VMC.</block>
  <block id="273c8112241e399eaf04dc840d119fb6" category="image-alt">Questa immagine mostra la struttura e le interconnessioni tra un data center on-premise, un'istanza di VMware Cloud su SDDC AWS e Amazon FSX per NetApp ONTAP. Ciò include la replica SnapMirror, il traffico DRaaS Ops, la connessione Internet o diretta e VMware Transit Connect.</block>
  <block id="246c1b44b3a8dc5d7fec2fdc031e49c5" category="section-title">Implementare e configurare VMware Cloud su AWS</block>
  <block id="4dab2f9796b0af6304d00e21e2b9dfb4" category="inline-link-macro">VMware Cloud su AWS</block>
  <block id="f828dbeef2a459e165a6fbd33ccf4781" category="paragraph"><block ref="88a970f127e79f2a50f427561bb2a4f6" category="inline-link-macro-rx"></block> Offre un'esperienza nativa del cloud per i carichi di lavoro basati su VMware nell'ecosistema AWS. Ogni VMware Software-Defined Data Center (SDDC) viene eseguito in un Amazon Virtual Private Cloud (VPC) e fornisce uno stack VMware completo (incluso vCenter Server), networking software-defined NSX-T, storage vSAN software-defined e uno o più host ESXi che forniscono risorse di calcolo e storage ai carichi di lavoro. Per configurare un ambiente VMC su AWS, seguire questa procedura <block ref="48c40480356563b3c93ca3177b91e728" category="inline-link-macro-rx"></block>. È possibile utilizzare anche un cluster di spie pilota per scopi di DR.</block>
  <block id="c3b336e3bd0ee5f4a24fd28ce72d7dea" category="admonition">Nella versione iniziale, DRO supporta un cluster pilota-light esistente. La creazione di SDDC on-demand sarà disponibile in una release imminente.</block>
  <block id="09a69d8335838329a7615e73fa6b1fe0" category="section-title">Provisioning e configurazione di FSX per ONTAP</block>
  <block id="37973daf609f18c7a64511d10e65453e" category="paragraph">Amazon FSX per NetApp ONTAP è un servizio completamente gestito che offre un file storage altamente affidabile, scalabile, dalle performance elevate e ricco di funzionalità, basato sul popolare file system ONTAP di NetApp. Seguire questa procedura <block ref="a5f36f80544ed8547e72f1f36fb2285b" category="inline-link-macro-rx"></block> Per eseguire il provisioning e la configurazione di FSX per ONTAP.</block>
  <block id="7f38204cc308b0521e747e38f1cb0062" category="section-title">Implementare e configurare SnapMirror in FSX per ONTAP</block>
  <block id="4a6b91648345db53156af03bcc00bde8" category="paragraph">Il passaggio successivo consiste nell'utilizzare NetApp BlueXP e individuare FSX per ONTAP su istanza AWS e replicare i volumi datastore desiderati da un ambiente on-premise a FSX per ONTAP con la frequenza appropriata e la conservazione delle copie Snapshot di NetApp:</block>
  <block id="6a4903522028d4e4bd24b3880afcf49f" category="image-alt">Questa immagine mostra la mappa delle relazioni di BlueXP Canvas che mostra le varie interazioni tra i servizi abilitati.</block>
  <block id="45568e41c66e2e325c210961987178e7" category="paragraph">Seguire la procedura descritta in questo collegamento per configurare BlueXP. È inoltre possibile utilizzare l'interfaccia utente di NetApp ONTAP per pianificare la replica seguendo questo collegamento.</block>
  <block id="07f3fd5642ddcadbf716c250ccf987f0" category="admonition">Una relazione SnapMirror è un prerequisito e deve essere creata in anticipo.</block>
  <block id="8513f47f7075dac35da070dbceb25a2e" category="section-title">Installazione DRO</block>
  <block id="9f8fa80dd85e2409bd0b4495b821f0f3" category="paragraph">Per iniziare a utilizzare DRO, utilizzare il sistema operativo Ubuntu su un'istanza EC2 o una macchina virtuale designata per assicurarsi di soddisfare i prerequisiti. Quindi installare il pacchetto.</block>
  <block id="7bf01cb2204f9dd0fdff029933600264" category="list-text">Assicurarsi che sia presente la connettività con i sistemi vCenter e storage di origine e di destinazione.</block>
  <block id="4c915967cda97460076cfdb71bc58421" category="list-text">Se si utilizzano i nomi DNS, la risoluzione DNS deve essere effettiva. In caso contrario, utilizzare gli indirizzi IP per vCenter e sistemi storage.</block>
  <block id="3cfe50231d6e1ba1b199fc7421fb72e6" category="list-text">Creare un utente con permessi root. È anche possibile utilizzare sudo con un'istanza EC2.</block>
  <block id="6e968857b32243865ebf039c1facf6cf" category="section-title">Requisiti del sistema operativo</block>
  <block id="b4fd1d48279ed0bed231fbd3b96a1e3a" category="list-text">Ubuntu 20.04 (LTS) con almeno 2 GB e 4 vCPU</block>
  <block id="184e93a2064767475a538c600a47eb17" category="list-text">I seguenti pacchetti devono essere installati sulla macchina virtuale dell'agente designata:</block>
  <block id="1dfe00693fad27f5da719e6aeea58ef6" category="list-text">Docker-Componi</block>
  <block id="31b4674ec2f7760117c224c883183141" category="list-text">JQ</block>
  <block id="240f5270a2e18be8a75b0712b343d07a" category="paragraph">Modificare le autorizzazioni su<block ref="b1360c159d030cf3e3075d3ec21faf46" prefix=" " category="inline-code"></block>:<block ref="e89a7e38128b2d546718b48d40d827f7" prefix=" " category="inline-code"></block>.</block>
  <block id="76af5eb969b6b58ab010f271730ae0ee" category="admonition">Il<block ref="60254338249f657a0a83f98258a56bfe" prefix=" " category="inline-code"></block> lo script esegue tutti i prerequisiti richiesti.</block>
  <block id="478159949d5b4b537a6ca19613ae98bf" category="section-title">Installare il pacchetto</block>
  <block id="54d75811a77a2a9b1526f372bc0a733e" category="list-text">Scaricare il pacchetto di installazione sulla macchina virtuale designata:</block>
  <block id="97c5338b12461548bb0ceefccd562486" category="admonition">L'agente può essere installato on-premise o all'interno di un VPC AWS.</block>
  <block id="2d2a358ce62dfc056eddea09ea87d1d1" category="list-text">Decomprimere il pacchetto, eseguire lo script di implementazione e immettere l'IP host (ad esempio, 10.10.10.10).</block>
  <block id="4e26021fda30753473246136bacc8094" category="list-text">Accedere alla directory ed eseguire lo script di distribuzione come segue:</block>
  <block id="049e44fe327f7679318c6cf222207da7" category="list-text">Accedere all'interfaccia utente utilizzando:</block>
  <block id="b7bd19f19df4ca5ef3102741951e7a1b" category="paragraph">con le seguenti credenziali predefinite:</block>
  <block id="d644796f5eb5712add7807df8829ee58" category="admonition">La password può essere modificata utilizzando l'opzione "Change Password" (Modifica password).</block>
  <block id="f1f49b31dc9a5d88e8029b9d361b9059" category="image-alt">Schermata di accesso a Disaster Recovery Orchestrator.</block>
  <block id="7b7ad84593d701138003778be3b6079f" category="section-title">Configurazione DRO</block>
  <block id="e9ff74e9030350261c678f0da3a354ee" category="paragraph">Dopo aver configurato correttamente FSX per ONTAP e VMC, è possibile iniziare a configurare DRO per automatizzare il ripristino dei carichi di lavoro on-premise su VMC utilizzando le copie SnapMirror di sola lettura su FSX per ONTAP.</block>
  <block id="0a99b6b57603a6a9f7dc56799a0fdd8e" category="paragraph">NetApp consiglia di implementare l'agente DRO in AWS e anche sullo stesso VPC in cui viene implementato FSX per ONTAP (può anche essere collegato in modo peer), In modo che l'agente DRO possa comunicare attraverso la rete con i componenti on-premise e con le risorse FSX per ONTAP e VMC.</block>
  <block id="c7c5a0daa14b8062f69791fd594efd37" category="paragraph">Il primo passo è scoprire e aggiungere le risorse on-premise e cloud (vCenter e storage) a DRO. Aprire DRO in un browser supportato e utilizzare il nome utente e la password predefiniti (admin/admin) e Add Sites (Aggiungi siti). I siti possono essere aggiunti anche utilizzando l'opzione Discover. Aggiungere le seguenti piattaforme:</block>
  <block id="16ee49909b80df9050959890b8f578cb" category="list-text">VCenter on-premise</block>
  <block id="e7aed9ec7e7600627310e041dbd517f7" category="list-text">Sistema storage ONTAP</block>
  <block id="e3691c446d2915370eb25cbc68a6521a" category="list-text">VMC vCenter</block>
  <block id="36df1b975561708b246ef1801ea416e5" category="list-text">FSX per ONTAP</block>
  <block id="c532da281c4c378954b0254be09c051b" category="image-alt">Descrizione dell'immagine segnaposto temporanea.</block>
  <block id="3506b8840bdbadcda795249c636510c4" category="image-alt">Pagina panoramica del sito DRO contenente i siti di origine e destinazione.</block>
  <block id="cf5e0df8cb3adb3df51d336ec0b2211a" category="paragraph">Una volta aggiunto, DRO esegue il rilevamento automatico e visualizza le macchine virtuali con le repliche SnapMirror corrispondenti dallo storage di origine a FSX per ONTAP. DRO rileva automaticamente le reti e i portgroup utilizzati dalle macchine virtuali e li popola.</block>
  <block id="abf7897bce5034c7714d0b7757ccac4c" category="image-alt">Schermata di rilevamento automatico contenente 219 VM e 10 datastore.</block>
  <block id="8ad855ec9cdd9c029c645af01c256999" category="paragraph">Il passaggio successivo consiste nel raggruppare le macchine virtuali richieste in gruppi funzionali che fungono da gruppi di risorse.</block>
  <block id="cdac0221d4dabd98123be4284952f872" category="section-title">Raggruppamenti di risorse</block>
  <block id="7546309b604714e5c864eef677efcd63" category="paragraph">Una volta aggiunte le piattaforme, è possibile raggruppare le macchine virtuali da ripristinare in gruppi di risorse. I gruppi di risorse DRO consentono di raggruppare un set di macchine virtuali dipendenti in gruppi logici che contengono i relativi ordini di avvio, ritardi di avvio e validazioni opzionali delle applicazioni che possono essere eseguite al momento del ripristino.</block>
  <block id="265d81bb1af077020a501dcc75af41e1" category="paragraph">Per iniziare a creare gruppi di risorse, attenersi alla seguente procedura:</block>
  <block id="a226ebee500532f5a9b1a5cbcb1db6d9" category="list-text">Accedere a *gruppi di risorse* e fare clic su *Crea nuovo gruppo di risorse*.</block>
  <block id="cfc3c82954c855841a78a216dec1b32b" category="list-text">In *nuovo gruppo di risorse*, selezionare il sito di origine dal menu a discesa e fare clic su *Crea*.</block>
  <block id="c47c9ace957accd98c45c515282fb851" category="list-text">Fornire *Dettagli gruppo di risorse* e fare clic su *continua*.</block>
  <block id="5e4c1f12f71cc535b41e76690fd718e3" category="list-text">Selezionare le macchine virtuali appropriate utilizzando l'opzione di ricerca.</block>
  <block id="de5c4b583db3aa4040c8d082ee2d1bcd" category="list-text">Selezionare l'ordine di avvio e il ritardo di avvio (sec) per le macchine virtuali selezionate. Impostare l'ordine della sequenza di accensione selezionando ciascuna macchina virtuale e impostando la relativa priorità. Tre è il valore predefinito per tutte le macchine virtuali.</block>
  <block id="c32b3a0f06aa80c00476ddcabd88fde1" category="paragraph">Le opzioni sono le seguenti:</block>
  <block id="a89a043e6faeacde759612c6bfa5cc1c" category="paragraph">1 – la prima macchina virtuale ad accenderlo 3 – Default 5 – l'ultima macchina virtuale ad accenderlo</block>
  <block id="84a63bc4997af6ded1933281f4b8babb" category="list-text">Fare clic su *Crea gruppo di risorse*.</block>
  <block id="0942dfbe3d3b0a1d41f357604f7e9fb2" category="image-alt">Schermata dell'elenco dei gruppi di risorse con due voci: Test e DemoRG1.</block>
  <block id="a8fc43ecd23ee9eb5e9efa5c60cb20b9" category="section-title">Piani di replica</block>
  <block id="901831e404573eb9a2cc09f43d42e661" category="paragraph">Hai bisogno di un piano per il ripristino delle applicazioni in caso di disastro. Selezionare le piattaforme vCenter di origine e di destinazione dall'elenco a discesa e scegliere i gruppi di risorse da includere in questo piano, oltre al raggruppamento delle modalità di ripristino e accensione delle applicazioni (ad esempio, controller di dominio, Tier-1, Tier-2 e così via). Tali piani sono talvolta chiamati anche blueprint. Per definire il piano di ripristino, accedere alla scheda *Replication Plan* (piano di replica) e fare clic su *New Replication Plan* (nuovo piano di replica).</block>
  <block id="f2e437ba3d91f90c4bd8d4b35ce32b78" category="paragraph">Per iniziare a creare un piano di replica, attenersi alla seguente procedura:</block>
  <block id="7e2b1b88ae2fef26c3f9f94bc389f0d1" category="list-text">Accedere a *Replication Plans* e fare clic su *Create New Replication Plan* (Crea nuovo piano di replica).</block>
  <block id="84ef8711a6a318c8bf4b8acfd4f1551c" category="image-alt">Schermata del piano di replica contenente un piano chiamato DemoRP.</block>
  <block id="b9493784814dfebf88fc26091f72b601" category="list-text">In *New Replication Plan* (nuovo piano di replica), specificare un nome per il piano e aggiungere i mapping di ripristino selezionando il sito di origine, il vCenter associato, il sito di destinazione e il vCenter associato.</block>
  <block id="88cedf638ed2d7e4779e1c47ee7c5ea1" category="image-alt">Screenshot dei dettagli del piano di replica, inclusa la mappatura di recovery.</block>
  <block id="d360387ddbca9636208f2b8a948f56b0" category="list-text">Una volta completata la mappatura di ripristino, selezionare la mappatura del cluster.</block>
  <block id="57e1d9c7da09c1484785ce5de748a5a4" category="list-text">Selezionare *Dettagli gruppo di risorse* e fare clic su *continua*.</block>
  <block id="28a5e1b451c50affbe5e71d787ef2818" category="list-text">Impostare l'ordine di esecuzione per il gruppo di risorse. Questa opzione consente di selezionare la sequenza di operazioni quando esistono più gruppi di risorse.</block>
  <block id="35e931afb6f8f9ea976030c41d20091d" category="list-text">Al termine, selezionare la mappatura di rete per il segmento appropriato. I segmenti devono essere già sottoposti a provisioning all'interno di VMC, quindi selezionare il segmento appropriato per mappare la macchina virtuale.</block>
  <block id="4279ce58393302704e1d9f4ef8e18ca2" category="list-text">In base alla selezione delle macchine virtuali, i mapping degli archivi dati vengono selezionati automaticamente.</block>
  <block id="920e197d79d1f4f66caaef11426066ba" category="admonition">SnapMirror è a livello di volume. Pertanto, tutte le macchine virtuali vengono replicate nella destinazione di replica. Assicurarsi di selezionare tutte le macchine virtuali che fanno parte dell'archivio dati. Se non sono selezionate, vengono elaborate solo le macchine virtuali che fanno parte del piano di replica.</block>
  <block id="76074b4a55fc86674d98cacd953dd720" category="list-text">In base ai dettagli della macchina virtuale, è possibile ridimensionare i parametri della CPU e della RAM della macchina virtuale; ciò può essere molto utile quando si ripristinano ambienti di grandi dimensioni in cluster di destinazione più piccoli o per eseguire test di DR senza dover eseguire il provisioning di un'infrastruttura fisica VMware uno a uno. Inoltre, è possibile modificare l'ordine di avvio e il ritardo di avvio (secondi) per tutte le macchine virtuali selezionate nei gruppi di risorse. Esiste un'opzione aggiuntiva per modificare l'ordine di avvio se sono necessarie modifiche da quelle selezionate durante la selezione dell'ordine di avvio del gruppo di risorse. Per impostazione predefinita, viene utilizzato l'ordine di avvio selezionato durante la selezione del gruppo di risorse; tuttavia, in questa fase è possibile eseguire qualsiasi modifica.</block>
  <block id="61b06cf38207274281ff2f90f66b49fa" category="list-text">Fare clic su *Crea piano di replica*.</block>
  <block id="8066d08fcf99bee6a3bb8bc060a5d031" category="paragraph">Una volta creato il piano di replica, è possibile utilizzare l'opzione di failover, l'opzione di test-failover o l'opzione di migrazione a seconda dei requisiti. Durante le opzioni di failover e test-failover, viene utilizzata la copia Snapshot SnapMirror più recente oppure è possibile selezionare una copia Snapshot specifica da una copia Snapshot point-in-time (in base alla policy di conservazione di SnapMirror). L'opzione point-in-time può essere molto utile se si sta affrontando un evento di corruzione come ransomware, in cui le repliche più recenti sono già compromesse o crittografate. DRO mostra tutti i punti disponibili nel tempo. Per attivare il failover o verificare il failover con la configurazione specificata nel piano di replica, fare clic su *failover* o *Test failover*.</block>
  <block id="9f6a9153365f1438c116145bc14ba9a9" category="image-alt">In questa schermata, vengono forniti i dettagli di Volume Snapshot e viene offerta la possibilità di scegliere tra l'utilizzo dell'ultima snapshot e la scelta di una specifica istantanea.</block>
  <block id="45c261be0b43693546955e87bd6ac10f" category="paragraph">Il piano di replica può essere monitorato nel menu delle attività:</block>
  <block id="0225a4a711bba4eb595e835ad67356fc" category="image-alt">Il menu delle attività mostra tutti i processi e le opzioni per il piano di replica e consente inoltre di visualizzare i registri.</block>
  <block id="8d2831d40faa91653285bd44edc3917d" category="paragraph">Dopo l'attivazione del failover, gli elementi ripristinati possono essere visualizzati in VMC vCenter (macchine virtuali, reti, datastore). Per impostazione predefinita, le macchine virtuali vengono ripristinate nella cartella workload.</block>
  <block id="d45215d9339daaa38e8c825812d30a02" category="paragraph">Il failback può essere attivato a livello di piano di replica. Per un failover di test, l'opzione di strappo può essere utilizzata per eseguire il rollback delle modifiche e rimuovere la relazione FlexClone. Il failback relativo al failover è un processo in due fasi. Selezionare il piano di replica e selezionare *Reverse data Sync*.</block>
  <block id="5f3ce61b7a4ffe23687402e421b81e18" category="image-alt">Schermata della panoramica del piano di replica con menu a discesa contenente l'opzione Reverse Data Sync.</block>
  <block id="acd827a33a3e445ce9d2c9d94ff63886" category="paragraph">Una volta completato, è possibile attivare il failback per tornare al sito di produzione originale.</block>
  <block id="0c86039a87483290f146f9170e80b40b" category="image-alt">Schermata della panoramica del piano di replica con menu a discesa contenente l'opzione di failover.</block>
  <block id="503c1e37074b31fdcd74fbffb13e3983" category="image-alt">Schermata della pagina di riepilogo di DRO con il sito di produzione originale in funzione.</block>
  <block id="0d95c1c8686951d59b82bdc816a93231" category="paragraph">Da NetApp BlueXP, possiamo notare che lo stato di salute della replica è stato interrotto per i volumi appropriati (quelli mappati a VMC come volumi di lettura/scrittura). Durante il failover di test, DRO non esegue il mapping del volume di destinazione o di replica. Invece, crea una copia FlexClone dell'istanza SnapMirror (o Snapshot) richiesta ed espone l'istanza FlexClone, che non consuma ulteriore capacità fisica per FSX per ONTAP. Questo processo garantisce che il volume non venga modificato e che i processi di replica possano continuare anche durante i test di DR o i flussi di lavoro di triage. Inoltre, questo processo garantisce che, in caso di errori o di ripristino di dati corrotti, il ripristino possa essere pulito senza il rischio di distruzione della replica.</block>
  <block id="648a04436d5621ca9c7c65c66c55cb79" category="section-title">Recovery ransomware</block>
  <block id="f1d63aa61bd9bd59550523eea84313e8" category="paragraph">Il ripristino dal ransomware può essere un compito scoraggiante. In particolare, può essere difficile per le organizzazioni IT individuare il punto di ritorno sicuro e, una volta stabilito, proteggere i carichi di lavoro recuperati da attacchi ricorrenti, ad esempio malware in sospensione o applicazioni vulnerabili.</block>
  <block id="c6ceeada99ad37301b94760e7f4bcab8" category="paragraph">DRO risolve questi problemi consentendo di ripristinare il sistema da qualsiasi punto in tempo disponibile. È inoltre possibile ripristinare i carichi di lavoro su reti funzionali ma isolate, in modo che le applicazioni possano funzionare e comunicare tra loro in una posizione in cui non sono esposte al traffico nord-sud. In questo modo, il tuo team di sicurezza è in una posizione sicura per condurre indagini legali e assicurarsi che non ci siano malware nascosti o inattivi.</block>
  <block id="468a6beafe68b7f0e997ea3b22eaf021" category="list-text">Utilizzo della replica SnapMirror efficiente e resiliente.</block>
  <block id="8dc2f1e4e39bbf8b271892846d90aee7" category="list-text">Ripristino in qualsiasi momento disponibile con la conservazione delle copie Snapshot.</block>
  <block id="6aaf12643047ec9787cc07db9f7e812a" category="list-text">Automazione completa di tutte le fasi necessarie per ripristinare da centinaia a migliaia di macchine virtuali dalle fasi di convalida di storage, calcolo, rete e applicazioni.</block>
  <block id="3067ce32bcf775ef4562f0900ee04ccf" category="list-text">Ripristino del workload con la tecnologia FlexClone di ONTAP che utilizza un metodo che non modifica il volume replicato.</block>
  <block id="6359f2b426c28e13cbb7b8382496081c" category="list-text">Evita il rischio di corruzione dei dati per volumi o copie Snapshot.</block>
  <block id="843b8877e30b7587ad87b95cd115df4a" category="list-text">Evita le interruzioni di replica durante i flussi di lavoro dei test di DR.</block>
  <block id="cd08b15dd8bc6a19026ca47b4bcd618d" category="list-text">Potenziale utilizzo dei dati di DR con risorse di cloud computing per flussi di lavoro che vanno oltre il DR, come DevTest, test di sicurezza, test di patch o upgrade e test di correzione.</block>
  <block id="7d73fdff5300d11e557be0d55023b8e8" category="list-text">Ottimizzazione della CPU e della RAM per ridurre i costi del cloud consentendo il ripristino in cluster di calcolo più piccoli.</block>
  <block id="8650b39d5e09def4c11e24f034a41e67" category="doc">TR-4955: Disaster recovery con Azure NetApp Files (ANF) e Azure VMware Solution (AVS)</block>
  <block id="e88bacbfc81933567e64c9db4797fe2a" category="paragraph">Autore: Niyaz Mohamed, NetApp Solutions Engineering</block>
  <block id="b9f6e76ebb09998e4efe8f7d8cdfc1a1" category="paragraph">Il disaster recovery che utilizza la replica a livello di blocco tra regioni all'interno del cloud è un metodo resiliente e conveniente per proteggere i carichi di lavoro da interruzioni del sito ed eventi di corruzione dei dati (ad esempio ransomware). Con la replica dei volumi Azure NetApp Files (ANF) cross-region, i carichi di lavoro VMware eseguiti su un sito SDDC Azure VMware Solution (AVS) utilizzando i volumi Azure NetApp Files come datastore NFS sul sito AVS primario possono essere replicati in un sito AVS secondario designato nella regione di recupero di destinazione.</block>
  <block id="6d3f247317af532e62e79af4e327e266" category="paragraph">Disaster Recovery Orchestrator (DRO) (una soluzione basata su script con un'interfaccia utente) può essere utilizzato per ripristinare senza problemi i carichi di lavoro replicati da un SDDC AVS a un altro. DRO automatizza il recovery interrompendo il peering delle repliche e montando il volume di destinazione come datastore, attraverso la registrazione delle macchine virtuali in AVS, sulle mappature di rete direttamente su NSX-T (incluso con tutti i cloud privati AVS).</block>
  <block id="20e61ee0f35516bf40c8c03f94d14f55" category="paragraph"><block ref="20e61ee0f35516bf40c8c03f94d14f55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54c0031f2ddfceeed5c28d8d32afd359" category="section-title">Prerequisiti e raccomandazioni generali</block>
  <block id="608e90a0df6dcf86f27467ce0c8ce54a" category="inline-link">Creare la replica di un volume per Azure NetApp Files</block>
  <block id="d855c43d14116e9cb3ec0930fee2f0dd" category="list-text">Verificare di aver attivato la replica tra regioni creando il peering delle repliche. Vedere<block ref="56da0221e637860c42ff0ac193595610" category="inline-link-rx"></block>.</block>
  <block id="83fefb057e39fc350c2c2f61a5961065" category="list-text">È necessario configurare ExpressRoute Global Reach tra i cloud privati Azure VMware Solution di origine e di destinazione.</block>
  <block id="6dce98a4bb089817cf9567558449180b" category="list-text">È necessario disporre di un service principal in grado di accedere alle risorse.</block>
  <block id="aebc7c3350448dc30015a87c3d89c2b2" category="list-text">È supportata la seguente topologia: Dal sito AVS primario al sito AVS secondario.</block>
  <block id="f29fabe637a472bf5222b12a0bc5df77" category="inline-link">replica</block>
  <block id="83fd61302a69aa66e69339e94e4ca2cf" category="list-text">Configurare<block ref="6d62eaf7384c288add248477bcaf361d" category="inline-link-rx"></block> pianifica ciascun volume in modo appropriato in base alle esigenze aziendali e al tasso di cambiamento dei dati.</block>
  <block id="7379a17a14e118aac108f1550bda8e15" category="admonition">Non sono supportate topologie a cascata e fan-in e fan-out.</block>
  <block id="5f06c97396f318992ec4285e547a7199" category="section-title">Implementare la soluzione VMware Azure</block>
  <block id="9789f0612fda153726aa8ad87265e4b9" category="inline-link">Soluzione VMware Azure</block>
  <block id="2d8e14d52496d7d3ab1bad5b1a8b0495" category="paragraph">Il<block ref="b39fc18162263c3a663125bcc24a1d36" category="inline-link-rx"></block> (AVS) è un servizio di cloud ibrido che fornisce SDDC VMware completamente funzionali all'interno di un cloud pubblico Microsoft Azure. AVS è una soluzione di prima parte completamente gestita e supportata da Microsoft e verificata da VMware che utilizza l'infrastruttura Azure. Pertanto, i clienti ottengono VMware ESXi per la virtualizzazione del calcolo, vSAN per lo storage iperconvergente e NSX per il networking e la sicurezza, il tutto sfruttando la presenza globale di Microsoft Azure, le strutture di data center leader di settore e la vicinanza al ricco ecosistema di servizi e soluzioni Azure native. Una combinazione di SDDC e Azure NetApp Files per la soluzione VMware Azure offre le migliori performance con una latenza di rete minima.</block>
  <block id="8f000bfe6ad06c9db52b34d413dc097e" category="paragraph">Per configurare un cloud privato AVS su Azure, seguire la procedura descritta in questa sezione<block ref="23c22ea299bb83ce2f82b3e1aef71be4" category="inline-link-rx"></block> Per la documentazione NetApp e in questo<block ref="21d8cba1c79bac0a64be5fa1f1f2361c" category="inline-link-rx"></block> Per la documentazione Microsoft. Un ambiente pilota con configurazione minima può essere utilizzato per scopi di DR. Questa configurazione contiene solo i componenti principali per supportare le applicazioni critiche e può scalare e generare più host per sostenere la maggior parte del carico in caso di failover.</block>
  <block id="c83dbf8bbfc81d6ea552177583a233a5" category="admonition">Nella versione iniziale, DRO supporta un cluster SDDC AVS esistente. La creazione di SDDC on-demand sarà disponibile in una release imminente.</block>
  <block id="96b758bcd58744b4e5415c3fbccd1a69" category="section-title">Provisioning e configurazione di Azure NetApp Files</block>
  <block id="2b636a8d03864ac97b7c30dc68f6f5a5" category="paragraph"><block ref="b56d3f248ea42ace920423401847f715" category="inline-link-rx"></block> è un servizio di file storage misurato di livello enterprise dalle performance elevate. Seguire la procedura descritta in questa sezione<block ref="1b959b45bbb3571141089802677ad765" category="inline-link-rx"></block> Eseguire il provisioning e la configurazione di Azure NetApp Files come datastore NFS per ottimizzare le implementazioni di cloud privato AVS.</block>
  <block id="2b1f9ff65c4506ccd4f1f6fb38649e87" category="section-title">Creazione di replica di volumi per i volumi datastore basati su file di Azure NetApp</block>
  <block id="5b95256d6ffa7467ef57d3c3f61ac38e" category="paragraph">Il primo passaggio consiste nell'impostare la replica cross-region per i volumi del datastore desiderati dal sito primario AVS al sito secondario AVS con le frequenze e le ritention appropriate.</block>
  <block id="0ebe5ac118b62c003b65a9b3c4f80ef6" category="paragraph"><block ref="0ebe5ac118b62c003b65a9b3c4f80ef6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca34c3e14ec19e036e86327c18ee97ff" category="inline-link">modificare il livello di servizio</block>
  <block id="1ac65c0a16d2eabb709d6d5b908f1745" category="paragraph">Seguire la procedura descritta in questa sezione<block ref="57cbb08765e0326150e1717bd79f16bf" category="inline-link-rx"></block> per impostare la replica tra regioni creando il peering delle repliche. Il livello di servizio per il pool di capacità di destinazione può corrispondere a quello del pool di capacità di origine. Tuttavia, per questo caso di utilizzo specifico, è possibile selezionare il livello di servizio standard, quindi<block ref="bacca1ab9fb985a705f3d2cbf4a7d58d" category="inline-link-rx"></block> In caso di disastro reale o di simulazioni di DR.</block>
  <block id="d9b36624eeaef41c5bf0404b4f9667f6" category="admonition">Una relazione di replica tra regioni è un prerequisito e deve essere creata in anticipo.</block>
  <block id="08735c190fa885a2bf1b7f36e1a2e8f3" category="paragraph">Per iniziare a utilizzare DRO, utilizzare il sistema operativo Ubuntu sulla macchina virtuale Azure designata e assicurarsi di soddisfare i prerequisiti. Quindi installare il pacchetto.</block>
  <block id="265472db458c37e522224c854e725fa5" category="paragraph">*Prerequisiti:*</block>
  <block id="2d2a5bfbd24c72950efbb0e05ff2c550" category="list-text">Service Principal in grado di accedere alle risorse.</block>
  <block id="291877ab9f9a26d5f7df0bcddeab5117" category="list-text">Assicurarsi che esista una connettività appropriata alle istanze SDDC e Azure NetApp Files di origine e destinazione.</block>
  <block id="5b0500a3592d99943c80ff54a25e978a" category="list-text">Se si utilizzano i nomi DNS, la risoluzione DNS deve essere effettiva. In caso contrario, utilizzare gli indirizzi IP per vCenter.</block>
  <block id="f06e54cea384d49e828ee5affd70c17f" category="paragraph">*Requisiti del sistema operativo:*</block>
  <block id="a3b6d9fb713cfc6d2e0a7693c132f7a7" category="list-text">Ubuntu Focal 20.04 (LTS)i seguenti pacchetti devono essere installati sulla macchina virtuale dell'agente designata:</block>
  <block id="0de0c471eabb6df904aed1160e17e5d0" category="list-text">Docker - comporre</block>
  <block id="c8a224d936a830223e7341615d656cb8" category="list-text">JqChange<block ref="b1360c159d030cf3e3075d3ec21faf46" prefix=" " category="inline-code"></block> a questa nuova autorizzazione:<block ref="e89a7e38128b2d546718b48d40d827f7" prefix=" " category="inline-code"></block>.</block>
  <block id="dac09e97665f1ce51b0eda57eb8d689f" category="admonition">Il<block ref="60254338249f657a0a83f98258a56bfe" prefix=" " category="inline-code"></block> lo script esegue tutti i prerequisiti richiesti.</block>
  <block id="8b389947da1beb9b783d0f6d93ff7379" category="paragraph">I passaggi sono i seguenti:</block>
  <block id="198238f0cb3b3c1ae0f172d5550ed1b1" category="admonition">L'agente deve essere installato nell'area del sito AVS secondario o nell'area del sito AVS primario in un AZ separato da SDDC.</block>
  <block id="0034cd44b3a2a2ebcd2491e08285c630" category="list-text">Decomprimere il pacchetto, eseguire lo script di implementazione e immettere l'IP host (ad esempio, <block ref="53c2d28edefdf501ab7c92e02a0c1687" prefix=" " category="inline-code"></block>).</block>
  <block id="e458c281a9aec07ea6c3bbd3fd4dee05" category="list-text">Accedere all'interfaccia utente utilizzando le seguenti credenziali:</block>
  <block id="257b3e8f9b30327f40243dfa0e6c25da" category="list-text">Nome utente:<block ref="21232f297a57a5a743894a0e4a801fc3" prefix=" " category="inline-code"></block></block>
  <block id="1b97f2409234d30285a10523ee6223cf" category="list-text">Password:<block ref="21232f297a57a5a743894a0e4a801fc3" prefix=" " category="inline-code"></block></block>
  <block id="0300b90d969cf3be8deea87c973b7034" category="paragraph"><block ref="0300b90d969cf3be8deea87c973b7034" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4a41f8b4753b15c1780f1b356cc4d36" category="paragraph">Dopo aver configurato correttamente Azure NetApp Files e AVS, è possibile iniziare a configurare DRO per automatizzare il ripristino dei workload dal sito AVS primario al sito AVS secondario. NetApp consiglia di implementare l'agente DRO nel sito AVS secondario e di configurare la connessione del gateway ExpressRoute in modo che l'agente DRO possa comunicare tramite la rete con i componenti AVS e Azure NetApp Files appropriati.</block>
  <block id="fd44f09b19421de944f8952f94dfe971" category="paragraph">Il primo passaggio consiste nell'aggiungere credenziali. DRO richiede l'autorizzazione per scoprire Azure NetApp Files e la soluzione VMware Azure. È possibile concedere le autorizzazioni richieste a un account Azure creando e configurando un'applicazione Azure Active Directory (ad) e ottenendo le credenziali Azure necessarie a DRO. È necessario associare l'entità del servizio all'abbonamento Azure e assegnargli un ruolo personalizzato con le autorizzazioni necessarie pertinenti. Quando si aggiungono ambienti di origine e di destinazione, viene richiesto di selezionare le credenziali associate all'entità del servizio. È necessario aggiungere queste credenziali a DRO prima di fare clic su Add New Site (Aggiungi nuovo sito).</block>
  <block id="0ea5490a5da4ab07ce30763f4395b20a" category="paragraph">Per eseguire questa operazione, attenersi alla seguente procedura:</block>
  <block id="e496bc8a09ef0bff2ed49dfc9746a61f" category="list-text">Aprire DRO in un browser supportato e utilizzare il nome utente e la password predefiniti <block ref="21232f297a57a5a743894a0e4a801fc3" prefix="(" category="inline-code"></block><block ref="21232f297a57a5a743894a0e4a801fc3" prefix="/" category="inline-code"></block>). La password può essere reimpostata dopo il primo accesso utilizzando l'opzione Change Password (Modifica password).</block>
  <block id="4ad2c508aa57459523225fea48cf2928" category="list-text">Nella parte superiore destra della console DRO, fare clic sull'icona *Impostazioni* e selezionare *credenziali*.</block>
  <block id="9a9321b8db1cac9beeecfa829e763dbe" category="list-text">Fare clic su Add New Credential (Aggiungi nuova credenziale) e seguire la procedura guidata.</block>
  <block id="f61fc6d956a5905e154da7bdc578662b" category="list-text">Per definire le credenziali, immettere le informazioni relative all'entità del servizio Azure Active Directory che concede le autorizzazioni richieste:</block>
  <block id="a5f3bff0d7667c1bb37c185dbaac3ff8" category="list-text">Nome della credenziale</block>
  <block id="7131a7a6bfe81200d21d5a33c64847b6" category="list-text">ID tenant</block>
  <block id="1b4739e491387ef5d8a546854308e5fe" category="list-text">Segreto del client</block>
  <block id="9bf79c7f10eadd0b612b8c354ad19bdc" category="list-text">ID abbonamento</block>
  <block id="3fb6b543576d4e6de4d8330552086cbf" category="paragraph">Queste informazioni dovrebbero essere state acquisite al momento della creazione dell'applicazione ad.</block>
  <block id="7c0994c6d36bea4a46a67ee7be492a0c" category="list-text">Confermare i dettagli relativi alle nuove credenziali e fare clic su Add Credential (Aggiungi credenziale).</block>
  <block id="860e0c902a247fd6fc5ba818a2e4c119" category="paragraph"><block ref="860e0c902a247fd6fc5ba818a2e4c119" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a569d23d0a18f8e5cdf96a9dbe0b318" category="paragraph">Dopo aver aggiunto le credenziali, è il momento di individuare e aggiungere i siti AVS primari e secondari (sia vCenter che l'account storage Azure NetApp Files) a DRO. Per aggiungere il sito di origine e di destinazione, attenersi alla seguente procedura:</block>
  <block id="01822078d676b28b71765f19b2abc174" category="list-text">Accedere alla scheda *Discover*.</block>
  <block id="27976ab4d078e6248b695907df6518a4" category="list-text">Fare clic su *Aggiungi nuovo sito*.</block>
  <block id="aed2a8b3a917727d4b43e29919cfccde" category="list-text">Aggiungere il seguente sito AVS primario (indicato come *origine* nella console).</block>
  <block id="889354880d57dd4dd4f8f3038526d974" category="list-text">VCenter SDDC</block>
  <block id="05f07fc27436b04820daaf552aae5b87" category="list-text">Account storage Azure NetApp Files</block>
  <block id="996c97afe4bc38c9853d27530a3df15e" category="list-text">Aggiungere il seguente sito AVS secondario (indicato come *destinazione* nella console).</block>
  <block id="a4005489f8d17cfe23209801e4384811" category="paragraph"><block ref="a4005489f8d17cfe23209801e4384811" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e505f2bafbc80afa614f045310efd28" category="list-text">Aggiungere i dettagli del sito facendo clic su *Source (origine),* immettendo un nome descrittivo del sito e selezionando il connettore. Quindi fare clic su *continua*.</block>
  <block id="a8984cd143f24c2d3e7b4079bac3b8d6" category="admonition">A scopo dimostrativo, l'aggiunta di un sito di origine viene trattata in questo documento.</block>
  <block id="03cb7c845b27b00d2fd5fcd6ca22399f" category="list-text">Aggiorna i dettagli di vCenter. A tale scopo, selezionare le credenziali, l'area Azure e il gruppo di risorse dal menu a discesa per l'AVS SDDC primario.</block>
  <block id="ae848f14f01425473dd19fd9cfcc5fa9" category="list-text">IL DRO elenca tutti gli SDDC disponibili all'interno della regione. Selezionare l'URL del cloud privato designato dal menu a discesa.</block>
  <block id="c02b7f0ffcc1d4da79302adf29a66e56" category="list-text">Inserire il<block ref="2a07e8a0872e7f8458933397e500f4e7" prefix=" " category="inline-code"></block> credenziali dell'utente. È possibile accedervi dal portale Azure. Seguire la procedura indicata in questo<block ref="9a765fe55ce09b5bcc5b9862623e77f3" category="inline-link-rx"></block>. Al termine, fare clic su *Continue* (continua).</block>
  <block id="4cc62b4cb463cf57b77ddc7d6cb1e329" category="paragraph"><block ref="4cc62b4cb463cf57b77ddc7d6cb1e329" category="inline-image-macro-rx" type="image"></block></block>
  <block id="becc83b5605c625633fe2d8e0b8b380e" category="list-text">Selezionare i dettagli dell'archiviazione di origine (ANF) selezionando il gruppo Azure Resource e l'account NetApp.</block>
  <block id="5296858fb0caa0a11f03202fcd7425e6" category="list-text">Fare clic su *Create Site* (Crea sito).</block>
  <block id="81f0a9cde4a335215c94ace73a76a98a" category="paragraph"><block ref="81f0a9cde4a335215c94ace73a76a98a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b43e8d7859f4e668e88bbec1012614f" category="paragraph">Una volta aggiunto, DRO esegue il rilevamento automatico e visualizza le macchine virtuali con repliche tra regioni corrispondenti dal sito di origine al sito di destinazione. DRO rileva automaticamente le reti e i segmenti utilizzati dalle macchine virtuali e li popola.</block>
  <block id="5b775ba0f30d059b52a43b406cc2e7c3" category="paragraph"><block ref="5b775ba0f30d059b52a43b406cc2e7c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2e9078f0eac4eabfab52411e25a94a45" category="paragraph">Il passaggio successivo consiste nel raggruppare le macchine virtuali richieste nei rispettivi gruppi funzionali come gruppi di risorse.</block>
  <block id="fd8b6f30869f4dd563c888ca814a33a9" category="paragraph">Una volta aggiunte le piattaforme, raggruppare le macchine virtuali che si desidera ripristinare in gruppi di risorse. I gruppi di risorse DRO consentono di raggruppare un set di macchine virtuali dipendenti in gruppi logici che contengono i relativi ordini di avvio, ritardi di avvio e validazioni opzionali delle applicazioni che possono essere eseguite al momento del ripristino.</block>
  <block id="d77884116359bfb00f05bd00d3e8d049" category="paragraph">Per iniziare a creare gruppi di risorse, fare clic sulla voce di menu *Crea nuovo gruppo di risorse*.</block>
  <block id="86cf73bd568d170320c05da514d80d57" category="list-text">Accedere a *Resource Grou*ps e fare clic su *Create New Resource Group* (Crea nuovo gruppo di risorse).</block>
  <block id="d05668f7a7c152b43c71f4e10ff83eb2" category="paragraph"><block ref="d05668f7a7c152b43c71f4e10ff83eb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="729041edea69eb39efcf6d3bb4958c20" category="list-text">In New Resource Group (nuovo gruppo di risorse), selezionare il sito di origine dal menu a discesa e fare clic su *Create* (Crea).</block>
  <block id="8b2c5e430ee578e1098fd0dd29ed3832" category="list-text">Fornire i dettagli del gruppo di risorse e fare clic su *continua*.</block>
  <block id="2036968de3c8690e533f2393b6eb23f2" category="list-text">Selezionare le macchine virtuali appropriate utilizzando l'opzione di ricerca.</block>
  <block id="9bdc69df94caa6e66eeb26bc6f11fe0b" category="list-text">Selezionare *Boot Order* (Ordine di avvio) e *Boot Delay* (sec) per tutte le macchine virtuali selezionate. Impostare l'ordine della sequenza di accensione selezionando ciascuna macchina virtuale e impostando la relativa priorità. Il valore predefinito per tutte le macchine virtuali è 3. Le opzioni sono le seguenti:</block>
  <block id="7bf779821eb857b7312d9fd21e28409c" category="list-text">La prima macchina virtuale ad accenderlo</block>
  <block id="7a1920d61156abc05a60135aefe8bc67" category="list-text">Predefinito</block>
  <block id="d3e1ce3079804318222f44cc5797acb6" category="list-text">L'ultima macchina virtuale ad accenderlo</block>
  <block id="aae5a12fc4a2fe256183b387a6d13520" category="paragraph"><block ref="aae5a12fc4a2fe256183b387a6d13520" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2ca70125ce517c525f91333e5647c922" category="paragraph"><block ref="2ca70125ce517c525f91333e5647c922" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01768278e2504e3e5697ae9ff4974842" category="paragraph">È necessario disporre di un piano per il ripristino delle applicazioni in caso di disastro. Selezionare le piattaforme vCenter di origine e di destinazione dall'elenco a discesa, scegliere i gruppi di risorse da includere in questo piano e includere anche il raggruppamento delle modalità di ripristino e accensione delle applicazioni (ad esempio, controller di dominio, Tier-1, Tier-2 e così via). I piani sono spesso chiamati anche blueprint. Per definire il piano di ripristino, accedere alla scheda Replication Plan (piano di replica) e fare clic su *New Replication Plan* (nuovo piano di replica).</block>
  <block id="578c9ba6f5077731855dfceecbaaa69e" category="list-text">Selezionare *Replication Plans* (piani di replica) e fare clic su *Create New Replication Plan* (Crea nuovo piano di replica</block>
  <block id="ab134bc6f5a247f30cd04a21a42a6e3e" category="paragraph"><block ref="ab134bc6f5a247f30cd04a21a42a6e3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc4a81ccf4d35c2d79e13b8d9e764ac3" category="list-text">In *New Replication Plan*, fornire un nome per il piano e aggiungere i mapping di ripristino selezionando Source Site (Sito di origine), Associated vCenter (vCenter associato), Destination Site (Sito di destinazione) e Associated vCenter (vCenter associato).</block>
  <block id="111af38498fbc99787f757630f9b6502" category="paragraph"><block ref="111af38498fbc99787f757630f9b6502" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb0d3f2303ecd179cbb41b4a89ce5c67" category="list-text">Una volta completata la mappatura di ripristino, selezionare *Cluster Mapping* (mappatura cluster).</block>
  <block id="e7c6ba3de84b5549973968926ac0d23b" category="paragraph"><block ref="e7c6ba3de84b5549973968926ac0d23b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2246eeda2d9dd58b6d0c476b7f59257" category="list-text">Al termine, impostare la mappatura di rete sul segmento appropriato. I segmenti devono essere già sottoposti a provisioning sul cluster AVS secondario e, per mappare le macchine virtuali su di essi, selezionare il segmento appropriato.</block>
  <block id="853f23cf3569d309e9916974d1a51876" category="list-text">I mapping degli archivi dati vengono selezionati automaticamente in base alla selezione delle macchine virtuali.</block>
  <block id="cbbdb677d49130a99047900675796b52" category="admonition">La replica cross-region (CRR) è a livello di volume. Pertanto, tutte le macchine virtuali che risiedono sul rispettivo volume vengono replicate nella destinazione CRR. Assicurarsi di selezionare tutte le macchine virtuali che fanno parte del datastore, in quanto vengono elaborate solo le macchine virtuali che fanno parte del piano di replica.</block>
  <block id="8799c7fd170fa15c94184f5e4db288d8" category="paragraph"><block ref="8799c7fd170fa15c94184f5e4db288d8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="884f1298b3bdd040ffb399dbc04901f0" category="list-text">In VM details (Dettagli VM), è possibile ridimensionare i parametri della CPU e della RAM delle macchine virtuali. Questo può essere molto utile quando si ripristinano ambienti di grandi dimensioni in cluster di destinazione più piccoli o quando si eseguono test di DR senza dover eseguire il provisioning di un'infrastruttura fisica VMware uno a uno. Inoltre, modificare l'ordine di avvio e il ritardo di avvio (sec) per tutte le macchine virtuali selezionate nei gruppi di risorse. Esiste un'opzione aggiuntiva per modificare l'ordine di avvio se sono necessarie modifiche da ciò che è stato selezionato durante la selezione dell'ordine di avvio del gruppo di risorse. Per impostazione predefinita, viene utilizzato l'ordine di avvio selezionato durante la selezione del gruppo di risorse, tuttavia in questa fase è possibile eseguire qualsiasi modifica.</block>
  <block id="f178cb66ab34b8fced158ec43b1b9b9d" category="paragraph"><block ref="f178cb66ab34b8fced158ec43b1b9b9d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be14c33c0e1307565b1b4265090e6004" category="list-text">Fare clic su *Create Replication Plan* (Crea piano di replica). Una volta creato il piano di replica, è possibile eseguire il failover, il failover di test o le opzioni di migrazione in base ai requisiti.</block>
  <block id="3d1083389392951c6f9506a1a837c338" category="paragraph"><block ref="3d1083389392951c6f9506a1a837c338" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eabe44ce43c0d27a3c7ed6090f8da8fe" category="paragraph">Durante le opzioni di failover e test di failover, viene utilizzato lo snapshot più recente oppure è possibile selezionare uno snapshot specifico da uno snapshot point-in-time. L'opzione point-in-time può essere molto vantaggiosa se si sta affrontando un evento di corruzione come ransomware, in cui le repliche più recenti sono già compromesse o crittografate. DRO mostra tutti i tempi di rilevazione disponibili.</block>
  <block id="b7ff5d05bb51bb1ba1f1948430b7f0ea" category="paragraph"><block ref="b7ff5d05bb51bb1ba1f1948430b7f0ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b20ccdef37c2fb3ba1dd6564f66dfd75" category="paragraph">Per attivare il failover o verificare il failover con la configurazione specificata nel piano di replica, fare clic su *failover* o *Test failover*. È possibile monitorare il piano di replica nel menu delle attività.</block>
  <block id="a2d45a6a3294c0f5907fc2a39cdf9427" category="paragraph"><block ref="a2d45a6a3294c0f5907fc2a39cdf9427" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c599217b8b3d1ed882a32d34779619f5" category="paragraph">Dopo l'attivazione del failover, gli elementi ripristinati possono essere visualizzati nel sito secondario AVS SDDC vCenter (VM, reti e datastore). Per impostazione predefinita, le macchine virtuali vengono ripristinate nella cartella workload.</block>
  <block id="22ab0c39f2f3febca61797b34cd8fabf" category="paragraph"><block ref="22ab0c39f2f3febca61797b34cd8fabf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b1403207c6b26d5ba9741226bc07955f" category="paragraph">Il failback può essere attivato a livello di piano di replica. In caso di failover di test, l'opzione di strappo può essere utilizzata per eseguire il rollback delle modifiche e rimuovere il volume appena creato. I fallback relativi al failover sono un processo in due fasi. Selezionare il piano di replica e selezionare *Reverse Data Sync*.</block>
  <block id="d653f5939cefc7bad010a2de7775f6b3" category="paragraph"><block ref="d653f5939cefc7bad010a2de7775f6b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="85ee6e66825baba0f8198b3dd30e87f0" category="paragraph">Al termine di questa fase, attivare il failback per tornare al sito AVS primario.</block>
  <block id="2cf097957a2bdcb5522a184f3700c7cc" category="paragraph"><block ref="2cf097957a2bdcb5522a184f3700c7cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="080e59f9730db0f9835804935f719573" category="paragraph"><block ref="080e59f9730db0f9835804935f719573" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5272991f0466fbd09b9b828354b71fbf" category="paragraph">Dal portale Azure, possiamo vedere che lo stato di salute della replica è stato interrotto per i volumi appropriati che sono stati mappati al sito secondario AVS SDDC come volumi di lettura/scrittura. Durante il failover di test, DRO non esegue il mapping del volume di destinazione o di replica. Al contrario, crea un nuovo volume dello snapshot di replica cross-region richiesto ed espone il volume come datastore, che consuma ulteriore capacità fisica dal pool di capacità e garantisce che il volume di origine non venga modificato. In particolare, i processi di replica possono continuare durante i test di DR o i flussi di lavoro di triage. Inoltre, questo processo garantisce che il ripristino possa essere ripulito senza il rischio che la replica venga distrutta in caso di errori o di ripristino di dati corrotti.</block>
  <block id="a5f63dad4856a347b9b7fc5a308fa216" category="paragraph">Il ripristino dal ransomware può essere un compito scoraggiante. In particolare, può essere difficile per le organizzazioni IT individuare il punto di ritorno sicuro e, una volta stabilito, come garantire che i carichi di lavoro recuperati siano protetti dagli attacchi che si verificano (ad esempio, da malware in sospensione o attraverso applicazioni vulnerabili).</block>
  <block id="0dd7fb82cd5ca2189a0483762c3ad4cd" category="paragraph">DRO risolve questi problemi consentendo alle organizzazioni di eseguire il ripristino da qualsiasi point-in-time disponibile. I carichi di lavoro vengono quindi ripristinati in reti funzionali ma isolate, in modo che le applicazioni possano funzionare e comunicare tra loro, ma non siano esposte al traffico nord-sud. Questo processo offre ai team di sicurezza un luogo sicuro per condurre indagini legali e identificare eventuali malware nascosti o inattivi.</block>
  <block id="97873cb64dd3b9de78b8dbf3541c1cb7" category="paragraph">La soluzione di disaster recovery Azure NetApp Files e Azure offre i seguenti vantaggi:</block>
  <block id="ea9b3d561aaa24c619c8bd8b411ed6df" category="list-text">Sfrutta una replica Azure NetApp Files cross-region efficiente e resiliente.</block>
  <block id="616f4cdbcb09376a462dda8ef67bbb64" category="list-text">Ripristino a qualsiasi point-in-time disponibile con la conservazione degli snapshot.</block>
  <block id="848e2ec26d0beb2339e91c67f385d9d3" category="list-text">Automatizzare completamente tutte le fasi necessarie per ripristinare da centinaia a migliaia di macchine virtuali dalle fasi di convalida di storage, calcolo, rete e applicazioni.</block>
  <block id="5248044020773fc0da962da4f0c97062" category="list-text">Il recupero del workload sfrutta il processo "Create new volumes from the most recent snapshot" (Crea nuovi volumi dalle snapshot più recenti), che non manipola il volume replicato.</block>
  <block id="c197954fd8a0b84ad03ef564ae13bcf5" category="list-text">Evitare qualsiasi rischio di corruzione dei dati sui volumi o sugli snapshot.</block>
  <block id="a709ce349016e4ae3d5d0c4d9dfbd871" category="list-text">Evita le interruzioni della replica durante i flussi di lavoro dei test di DR.</block>
  <block id="95a8950fc6379e50b04cfa6f61a36d11" category="list-text">Sfrutta i dati di DR e le risorse di calcolo del cloud per i flussi di lavoro che vanno oltre il DR, come sviluppo/test, test di sicurezza, test di patch e upgrade e test di correzione.</block>
  <block id="8f3b531b04dadc9320674c0e42b1a487" category="list-text">L'ottimizzazione della CPU e della RAM può contribuire a ridurre i costi del cloud consentendo il ripristino a cluster di calcolo più piccoli.</block>
  <block id="f64a0d6a033b67f67edba41e1bd8152c" category="inline-link"><block ref="f64a0d6a033b67f67edba41e1bd8152c" category="inline-link-rx"></block></block>
  <block id="5b7bf21e5e287cfaa11c6e67e2073b27" category="paragraph"><block ref="5b7bf21e5e287cfaa11c6e67e2073b27" category="inline-link-rx"></block></block>
  <block id="7b6802bdcfa19b11a01e1fa2b2f6010d" category="list-text">Replica cross-region di volumi Azure NetApp Files</block>
  <block id="0bfb405aa5c708395d0f8a337e30b65e" category="inline-link"><block ref="0bfb405aa5c708395d0f8a337e30b65e" category="inline-link-rx"></block></block>
  <block id="a931d15f7c97401d5f17df4edb5f3ad6" category="paragraph"><block ref="a931d15f7c97401d5f17df4edb5f3ad6" category="inline-link-rx"></block></block>
  <block id="3de91620717e92c6908e156194bcf68a" category="list-text"><block ref="3de91620717e92c6908e156194bcf68a" category="inline-link-rx"></block></block>
  <block id="4af3bddf434f9895d84aceb3a82b8c71" category="inline-link"><block ref="4af3bddf434f9895d84aceb3a82b8c71" category="inline-link-rx"></block></block>
  <block id="e01e170739dafe7d8690e443b02ffa37" category="paragraph"><block ref="e01e170739dafe7d8690e443b02ffa37" category="inline-link-rx"></block></block>
  <block id="bb01fec2870d3f698517f8471454637b" category="list-text">Implementare e configurare l'ambiente di virtualizzazione su Azure</block>
  <block id="95e48cdadbed4c3715638febbf224db0" category="inline-link"><block ref="95e48cdadbed4c3715638febbf224db0" category="inline-link-rx"></block></block>
  <block id="1f012963182d3d85fbf4cd4c6093d56c" category="paragraph"><block ref="1f012963182d3d85fbf4cd4c6093d56c" category="inline-link-rx"></block></block>
  <block id="e0d783f10c59be2d7b43e92ef42c1540" category="list-text">Implementare e configurare Azure VMware Solution</block>
  <block id="164a8b646e75ab3984103d6026f5a8f3" category="inline-link"><block ref="164a8b646e75ab3984103d6026f5a8f3" category="inline-link-rx"></block></block>
  <block id="42bdffc2ff584c6491929199aa95fdef" category="paragraph"><block ref="42bdffc2ff584c6491929199aa95fdef" category="inline-link-rx"></block></block>
  <block id="17c56e542773e2aafc2645d0e9f0d8ec" category="summary">Le soluzioni NetApp Hybrid Multivloud con VMware sono un insieme di funzionalità tecnologiche e strategiche che dimostrano le funzionalità dello storage NetApp nei principali hyperscaler del cloud pubblico.</block>
  <block id="fcee9cbc5f0c4f0ed62751d0d5f181ef" category="doc">Multicloud ibrido NetApp con soluzioni VMware</block>
  <block id="9114bfd7ba3e781df4e595c0a3199bfb" category="summary">Il primo passo per comprendere come proteggere i dati consiste nell'identificare i rischi e le potenziali superfici di attacco.</block>
  <block id="d446619c29484b970941bed7884dfd57" category="doc">Considerazioni sulla sicurezza e superfici di attacco</block>
  <block id="9835bd91d6121b399eb4318f5f6aecab" category="inline-link-macro">Precedente: In che modo Cloud Volumes Service in Google Cloud protegge i tuoi dati.</block>
  <block id="00bbf283b6d94328be9e19fd69a5e57d" category="paragraph"><block ref="00bbf283b6d94328be9e19fd69a5e57d" category="inline-link-macro-rx"></block></block>
  <block id="da24915274d8feb20f2be6f37c42bb43" category="paragraph">Il primo passo per comprendere come proteggere i dati consiste nell'identificare i rischi e le potenziali superfici di attacco. Questi includono (a titolo esemplificativo) i seguenti elementi:</block>
  <block id="1f48f12466296c53740ed0375b4d0111" category="list-text">Amministrazione e accessi</block>
  <block id="78b73d10586b526c3f0d3f97bd32dfba" category="list-text">Dati inattivi</block>
  <block id="42517361027a563c9ab61d813badc939" category="list-text">Dati in volo</block>
  <block id="58be36e591707c2a60f9bed405a8ef25" category="list-text">Rete e firewall</block>
  <block id="3a7d83d110f5fe7d4f435b9594806caf" category="list-text">Ransomware, malware e virus</block>
  <block id="417a78919920edf51d22038b236740f1" category="paragraph">La comprensione delle superfici di attacco può aiutarti a proteggere meglio i tuoi ambienti. Cloud Volumes Service in Google Cloud prende già in considerazione molti di questi argomenti e implementa le funzionalità di sicurezza per impostazione predefinita, senza alcuna interazione amministrativa.</block>
  <block id="70e43ccaf26985ea09dd44568ea9f36b" category="section-title">Garantire accessi sicuri</block>
  <block id="67fe2a3de92df4f2c45227cff1adea77" category="paragraph">Quando si proteggono i componenti critici dell'infrastruttura, è fondamentale assicurarsi che solo gli utenti approvati possano accedere e gestire gli ambienti. Se gli attori danneggiati violano le credenziali amministrative, dispongono delle chiavi del castello e possono fare qualsiasi cosa: Modificare le configurazioni, eliminare volumi e backup, creare backdoor o disattivare le pianificazioni Snapshot.</block>
  <block id="3a2f2973e275ef04d08d1dda935f1ee0" category="paragraph">Cloud Volumes Service per Google Cloud offre protezione dagli accessi amministrativi non autorizzati attraverso l'offuscamento dello storage come servizio (StaaS). Cloud Volumes Service è completamente gestito dal cloud provider senza alcuna disponibilità per l'accesso esterno. Tutte le operazioni di configurazione e configurazione sono completamente automatizzate, pertanto un amministratore umano non deve mai interagire con i sistemi, tranne in circostanze molto rare.</block>
  <block id="22b01eb5fb8c08ffb16c6ef9ef8b71b6" category="inline-link-macro">"Architettura Cloud Volumes Service".</block>
  <block id="b019d60ff2b9589700c94d2d71d13c8f" category="paragraph">Se è necessario effettuare l'accesso, Cloud Volumes Service in Google Cloud protegge gli accessi mantenendo un elenco molto breve di amministratori attendibili che hanno accesso ai sistemi. Questo gatepeeping aiuta a ridurre il numero di potenziali attori danneggiati con accesso. Inoltre, il networking Google Cloud nasconde i sistemi dietro livelli di sicurezza di rete ed espone solo ciò che è necessario al mondo esterno. Per informazioni sull'architettura di Google Cloud e Cloud Volumes Service, consulta la sezione <block ref="d008df97450ac642ad54d58196f67862" category="inline-link-macro-rx"></block></block>
  <block id="582157e9744c945cab3000f99e5c51f4" category="section-title">Amministrazione e aggiornamenti dei cluster</block>
  <block id="ac816ab3f2fb9ede37e87c223bf39690" category="paragraph">Due aree con potenziali rischi per la sicurezza includono l'amministrazione del cluster (cosa succede se un attore cattivo ha accesso all'amministratore) e gli aggiornamenti (cosa succede se un'immagine software viene compromessa).</block>
  <block id="e3f83199a3d154c9a938a90ed76188d4" category="section-title">Protezione dell'amministrazione dello storage</block>
  <block id="e9406b6097629a60364e6b24a83dd40b" category="inline-link-macro">"Operazione di assistenza".</block>
  <block id="a16c40cfa1517a64fe23c8a84e7fca32" category="paragraph">Lo storage fornito come servizio elimina il rischio aggiunto di esposizione agli amministratori rimuovendo tale accesso agli utenti finali al di fuori del data center cloud. Invece, l'unica configurazione eseguita è per il piano di accesso ai dati da parte dei clienti. Ogni tenant gestisce i propri volumi e nessun tenant può raggiungere altre istanze di Cloud Volumes Service. Il servizio è gestito dall'automazione, con un elenco molto piccolo di amministratori attendibili che hanno accesso ai sistemi attraverso i processi descritti nella sezione <block ref="b466e98e9a7ec570a0e595b4839650b9" category="inline-link-macro-rx"></block></block>
  <block id="bc94b58452719d0cfedd1ceb30c4fd53" category="paragraph">Il tipo di servizio CVS-Performance offre la replica tra regioni come opzione per fornire la protezione dei dati a una regione diversa in caso di guasto di una regione. In questi casi, è possibile eseguire il failover di Cloud Volumes Service nella regione non interessata per mantenere l'accesso ai dati.</block>
  <block id="b8bb5b62315a69e1364d070de73bbfa5" category="section-title">Aggiornamenti del servizio</block>
  <block id="a5e1144c0e37d7facbd53bdffaa58f52" category="paragraph">Gli aggiornamenti aiutano a proteggere i sistemi vulnerabili. Ogni aggiornamento offre miglioramenti alla sicurezza e correzioni di bug che riducono al minimo le superfici di attacco. Gli aggiornamenti software vengono scaricati da repository centralizzati e convalidati prima che gli aggiornamenti siano autorizzati a verificare che le immagini ufficiali siano utilizzate e che gli aggiornamenti non siano compromessi dagli attori danneggiati.</block>
  <block id="79f1689ccfaec67bc50dd620185adbac" category="paragraph">Con Cloud Volumes Service, gli aggiornamenti vengono gestiti dai team dei provider di cloud, il che elimina l'esposizione ai rischi per i team di amministratori fornendo esperti con una buona esperienza nella configurazione e negli aggiornamenti che hanno automatizzato e testato completamente il processo. Gli aggiornamenti sono senza interruzioni e Cloud Volumes Service mantiene gli ultimi aggiornamenti per ottenere i migliori risultati complessivi.</block>
  <block id="6a274e2791c8f2a1f59a7a6f87261122" category="paragraph">Per informazioni sul team di amministratori che esegue questi aggiornamenti del servizio, vedere la sezione <block ref="b466e98e9a7ec570a0e595b4839650b9" category="inline-link-macro-rx"></block></block>
  <block id="eeae9bcc33a487e1224ffb4815f79821" category="section-title">Protezione dei dati inattivi</block>
  <block id="11062b94d57add7cf5c44a9ec7e9274c" category="paragraph">La crittografia dei dati inattivi è importante per proteggere i dati sensibili in caso di furto, restituzione o riordinamento di un disco. I dati in Cloud Volumes Service sono protetti a riposo utilizzando la crittografia basata su software.</block>
  <block id="ad04a8dc3b058793f75e8c97c787ceea" category="list-text">Le chiavi generate da Google vengono utilizzate per CVS-SW.</block>
  <block id="b114edcfa107ab9d459e2e75aea2cfdb" category="inline-link">FIPS 140-2 Cert n. 4144</block>
  <block id="855bcb8730de4b24527a09801b103d97" category="list-text">Per CVS-Performance, le chiavi per volume vengono memorizzate in un gestore di chiavi integrato in Cloud Volumes Service, che utilizza NetApp ONTAP CryptoMod per generare chiavi di crittografia AES-256. CryptoMod è elencato nell'elenco dei moduli validati di CMVP FIPS 140-2. Vedere<block ref="c8bf3ef21e8efdca1f27a1e57e809607" category="inline-link-rx"></block>.</block>
  <block id="a934c8bfa11942a4baa792ed229b8bb8" category="paragraph">A partire da novembre 2021, l'anteprima della funzionalità Customer-Managed Encryption (CMEK) è stata resa disponibile per CVS-Performance. Questa funzionalità consente di crittografare le chiavi per volume con chiavi master per progetto, per regione, ospitate in Google Key Management Service (KMS). KMS consente di collegare i key manager esterni.</block>
  <block id="fd0625de17999274e1465433cabc43a7" category="inline-link">Consultare la documentazione di Cloud Volumes Service</block>
  <block id="fd313eaaaadfe56df9ec88896284165d" category="paragraph">Per ulteriori informazioni su come configurare KMS per CVS-Performance,<block ref="905a3b34ffbfe930acdbf23dd47d698f" category="inline-link-rx"></block>.</block>
  <block id="08a22fe6e00e4ceb40cd56453b4a5864" category="paragraph">Per ulteriori informazioni sull'architettura, vedere la sezione <block ref="d008df97450ac642ad54d58196f67862" category="inline-link-macro-rx"></block></block>
  <block id="fb787119808b111e9df5553be31361c8" category="section-title">Protezione dei dati in volo</block>
  <block id="8255b8a6d9844c87b5ecd1d2287b2f60" category="paragraph">Oltre a proteggere i dati a riposo, è necessario essere in grado di proteggere i dati anche quando sono in volo tra l'istanza di Cloud Volumes Service e un client o una destinazione di replica. Cloud Volumes Service fornisce la crittografia per i dati in-flight su protocolli NAS utilizzando metodi di crittografia come la crittografia SMB utilizzando Kerberos, la firma/sigillatura dei pacchetti e NFS Kerberos 5p per la crittografia end-to-end dei trasferimenti di dati.</block>
  <block id="c42b0018cf60c30c0490998e63dfdac1" category="paragraph">La replica dei volumi Cloud Volumes Service utilizza TLS 1.2, che sfrutta i metodi di crittografia AES-GCM.</block>
  <block id="c05431edaaaefc20b48a7cd96f110e5d" category="inline-link-macro">"Crittografia dei dati in transito"</block>
  <block id="17882f1649689ee4f6fcf4aeba6d150b" category="paragraph">La maggior parte dei protocolli insicuri in-flight, come telnet, NDMP e così via, sono disattivati per impostazione predefinita. Il DNS, tuttavia, non viene crittografato da Cloud Volumes Service (non supporta il DNS sec) e deve essere crittografato utilizzando la crittografia di rete esterna, se possibile. Vedere la sezione <block ref="051d363ef6081e123484b5da28bebf19" category="inline-link-macro-rx"></block> per ulteriori informazioni sulla protezione dei dati in volo.</block>
  <block id="4bb00cc1adfaf9a4b73ae2593bc7d4e8" category="inline-link-macro">"Protocolli NAS".</block>
  <block id="d47f2c6bf1e6a3776038244ab35f5415" category="paragraph">Per informazioni sulla crittografia del protocollo NAS, vedere la sezione <block ref="386abb448925212e530f9be720946265" category="inline-link-macro-rx"></block></block>
  <block id="46dc4f8fa1d2951250a02fa29fccc4cb" category="section-title">Utenti e gruppi per le autorizzazioni NAS</block>
  <block id="4a6786c54b7ea4a860834c0ffda11c7f" category="paragraph">Parte della protezione dei dati nel cloud implica un'autenticazione corretta di utenti e gruppi, in cui gli utenti che accedono ai dati vengono verificati come utenti reali nell'ambiente e i gruppi contengono utenti validi. Questi utenti e gruppi forniscono l'accesso iniziale alla condivisione e all'esportazione, nonché la convalida delle autorizzazioni per file e cartelle nel sistema di storage.</block>
  <block id="52c7382ae7438c8a3366ad6f38d5d2a4" category="paragraph">Cloud Volumes Service utilizza l'autenticazione standard di utenti e gruppi basata su Active Directory per le condivisioni SMB e le autorizzazioni di tipo Windows. Il servizio può anche sfruttare i provider di identità UNIX come LDAP per utenti e gruppi UNIX per le esportazioni NFS, la convalida dell'ID NFSv4, l'autenticazione Kerberos e gli ACL NFSv4.</block>
  <block id="59935480b9f5ac6361a1a360ad8a9ec2" category="admonition">Attualmente solo Active Directory LDAP è supportato con la funzionalità Cloud Volumes Service per LDAP.</block>
  <block id="7c47e0b7c3aa389a1b437364885d5562" category="section-title">Rilevamento, prevenzione e mitigazione di ransomware, malware e virus</block>
  <block id="b647cba0e4b0ad0f479019e47713c5a2" category="paragraph">Ransomware, malware e virus sono una minaccia persistente per gli amministratori e il rilevamento, la prevenzione e la mitigazione di tali minacce sono sempre in cima alla mente per le organizzazioni aziendali. Un singolo evento ransomware su un set di dati critico può potenzialmente costare milioni di dollari, quindi è utile fare ciò che è possibile per ridurre al minimo il rischio.</block>
  <block id="ba1e21a6e8310b88e0349770718e717c" category="inline-link">rilevamento automatico ransomware</block>
  <block id="b80fb0d337605da9f0fdaf2687c3de1e" category="paragraph">Sebbene Cloud Volumes Service attualmente non includa misure di rilevamento o prevenzione native, come la protezione antivirus o.<block ref="2ed126fbf9f5caf3d13a90f230e3475a" category="inline-link-rx"></block>, Esistono diversi modi per eseguire rapidamente il ripristino da un evento ransomware attivando pianificazioni Snapshot regolari. Le copie Snapshot sono immutabili e i puntatori di sola lettura ai blocchi modificati nel file system, sono quasi istantanei, hanno un impatto minimo sulle performance e occupano spazio solo quando i dati vengono modificati o cancellati. È possibile impostare le pianificazioni per le copie Snapshot in modo che corrispondano all'obiettivo RPO (Acceptable Recovery Point Objective)/RTO (Recovery Time Objective) desiderato e mantenere fino a 1,024 copie Snapshot per volume.</block>
  <block id="e9c1c7d4ca860adb553d87c2c1d9ef35" category="inline-link">La soluzione NetApp per ransomware</block>
  <block id="85ebd62090617323187e9e7827c343e7" category="paragraph">Il supporto di Snapshot è incluso senza costi aggiuntivi (al di là dei costi di storage dei dati per blocchi modificati/dati conservati dalle copie Snapshot) con Cloud Volumes Service e, in caso di attacco ransomware, può essere utilizzato per eseguire il rollback su una copia Snapshot prima che si verifichi l'attacco. Il completamento dei ripristini Snapshot richiede pochi secondi e consente di tornare alla normale gestione dei dati. Per ulteriori informazioni, vedere<block ref="e347ba4858ee244fead32d2fe59a64dd" category="inline-link-rx"></block>.</block>
  <block id="7994d1312e8f4fe2cdf2f7e13347d8bf" category="paragraph">Per evitare che il ransomware influisca sul tuo business, è necessario un approccio multilivello che includa uno o più dei seguenti elementi:</block>
  <block id="7aa2bd35ac13684bd5c9434296dd6b03" category="list-text">Protezione degli endpoint</block>
  <block id="9cdff1d919782c79338864086178c7b0" category="list-text">Protezione dalle minacce esterne attraverso firewall di rete</block>
  <block id="eb4079f2ecc7735fcfaa169c5562cbfd" category="list-text">Rilevamento di anomalie dei dati</block>
  <block id="aac3c67c846910bdfd381a7101344e96" category="list-text">Backup multipli (on-site e off-site) di set di dati critici</block>
  <block id="3845e8b5ec9d78bcebac29ec50d8077f" category="list-text">Test di ripristino regolari dei backup</block>
  <block id="a550fe6fd1b40af5260e9636cdea66fd" category="list-text">Copie Snapshot di NetApp immutabili in sola lettura</block>
  <block id="533a4f72ffc639d4cc87d034dfe92f2c" category="list-text">Autenticazione a più fattori per infrastrutture critiche</block>
  <block id="b1d3b419f981a509b3c5203c7546b96b" category="list-text">Controlli di sicurezza degli accessi al sistema</block>
  <block id="4e329c801824e6bdc0209c98146064c3" category="paragraph">Questo elenco è lungi dall'essere esaustivo, ma è un buon modello da seguire quando si affronta il potenziale degli attacchi ransomware. Cloud Volumes Service in Google Cloud offre diversi modi per proteggere da eventi ransomware e ridurre i loro effetti.</block>
  <block id="2fdb508dbc71674add1fe7fc21ccbf8e" category="section-title">Copie Snapshot immutabili</block>
  <block id="1682a7464d9210c8161ec78abc8010e2" category="paragraph">Cloud Volumes Service fornisce in modo nativo copie Snapshot immutabili in sola lettura, eseguite in base a una pianificazione personalizzabile per un rapido ripristino point-in-time in caso di eliminazione dei dati o se un intero volume è stato vittima di un attacco ransomware. I ripristini Snapshot delle copie Snapshot precedenti sono rapidi e riducono al minimo la perdita di dati in base al periodo di conservazione delle pianificazioni Snapshot e RTO/RPO. L'effetto delle performance con la tecnologia Snapshot è trascurabile.</block>
  <block id="c0bd33c36fff1f6dbb2bf9253a7f40dd" category="paragraph">Poiché le copie Snapshot in Cloud Volumes Service sono di sola lettura, non possono essere infettate dal ransomware a meno che il ransomware non sia proliferato nel dataset senza essere stato notato e siano state acquisite copie Snapshot dei dati infettati dal ransomware. Per questo motivo è necessario considerare anche il rilevamento ransomware in base alle anomalie dei dati. Cloud Volumes Service non fornisce attualmente il rilevamento nativo, ma è possibile utilizzare un software di monitoraggio esterno.</block>
  <block id="9b641219ac63451505f5a25a887038d4" category="section-title">Backup e ripristini</block>
  <block id="5e2f84170723d4cfed011f9ebc6c557e" category="paragraph">Cloud Volumes Service offre funzionalità di backup standard del client NAS (ad esempio backup su NFS o SMB).</block>
  <block id="0d69441d7fc21e56d3cf2eb944fbf6c1" category="inline-link">replica di un volume</block>
  <block id="9fd9d0ecc58c5d26f4934bc140ac2a41" category="list-text">CVS-Performance offre replica di volumi cross-region ad altri volumi CVS-Performance. Per ulteriori informazioni, vedere<block ref="ec408a29560fd662bec08bf50f9ff3d6" category="inline-link-rx"></block> Nella documentazione di Cloud Volumes Service.</block>
  <block id="161b127f579db2727ace94e4fb6f9e5b" category="inline-link">backup nel cloud</block>
  <block id="6a7870f99b17bbb49636a1e7be9d4be1" category="list-text">CVS-SW offre funzionalità di backup/ripristino dei volumi native del servizio. Per ulteriori informazioni, vedere<block ref="2377dc7e4548195ed704b70f3ce6250c" category="inline-link-rx"></block> Nella documentazione di Cloud Volumes Service.</block>
  <block id="56a32ac982c7663e59f24c58cfb673d6" category="paragraph">La replica dei volumi fornisce una copia esatta del volume di origine per un failover rapido in caso di disastro, inclusi gli eventi ransomware.</block>
  <block id="ae2679a66d07f8c7efd50d972a34a112" category="section-title">Replica tra regioni</block>
  <block id="1a094951f7e9c42a89c4ef4b0b328eee" category="paragraph">CVS-Performance consente di replicare in modo sicuro i volumi nelle aree di Google Cloud per la protezione dei dati e archiviare i casi di utilizzo utilizzando la crittografia TLS1.2 AES 256 GCM su una rete di servizi back-end controllata da NetApp utilizzando interfacce specifiche utilizzate per la replica in esecuzione sulla rete di Google. Un volume primario (di origine) contiene i dati di produzione attivi e replica su un volume secondario (di destinazione) per fornire una replica esatta del dataset primario.</block>
  <block id="f8e2c7b5b15f4332525ac9687a100a28" category="paragraph">La replica iniziale trasferisce tutti i blocchi, ma gli aggiornamenti trasmettono solo i blocchi modificati in un volume primario. Ad esempio, se un database da 1 TB che risiede su un volume primario viene replicato nel volume secondario, nella replica iniziale viene trasferito 1 TB di spazio. Se il database contiene poche centinaia di righe (ipoteticamente, alcuni MB) che cambiano tra l'inizializzazione e il successivo aggiornamento, solo i blocchi con le righe modificate vengono replicati nel secondario (alcuni MB). In questo modo è possibile garantire che i tempi di trasferimento rimangano bassi e che gli addebiti di replica siano ridotti.</block>
  <block id="fd25283b48ea77209e43fe9173df1354" category="paragraph">Tutte le autorizzazioni su file e cartelle vengono replicate nel volume secondario, ma le autorizzazioni di accesso alla condivisione (come criteri e regole di esportazione o condivisioni SMB e ACL di condivisione) devono essere gestite separatamente. In caso di failover di un sito, il sito di destinazione deve sfruttare gli stessi name service e le connessioni di dominio Active Directory per fornire una gestione coerente delle identità e delle autorizzazioni di utenti e gruppi. È possibile utilizzare un volume secondario come destinazione di failover in caso di disastro interrompendo la relazione di replica, che converte il volume secondario in lettura/scrittura.</block>
  <block id="940c6fa9c7eb366ae4e471e545edb27b" category="paragraph">Le repliche dei volumi sono di sola lettura, che fornisce una copia immutabile dei dati fuori sede per un rapido ripristino dei dati nei casi in cui un virus ha infettato i dati o ransomware ha crittografato il dataset primario. I dati di sola lettura non vengono crittografati, ma se il volume primario viene compromesso e si verifica la replica, anche i blocchi infetti vengono replicati. È possibile utilizzare copie Snapshot meno recenti e non interessate per il ripristino, ma gli SLA potrebbero non rientrare nell'intervallo dell'RTO/RPO promesso a seconda della velocità con cui viene rilevato un attacco.</block>
  <block id="fe62647cc35dde214e0df1ae1fe9d0ab" category="inline-link">Considerazioni sulla sicurezza</block>
  <block id="344c8cea0d31ef9e8c7c56863c714a04" category="paragraph">Inoltre, puoi prevenire azioni amministrative dannose, come eliminazioni di volumi, eliminazioni Snapshot o modifiche di pianificazione Snapshot, con la gestione della replica cross-region (CRR) in Google Cloud. Ciò avviene creando ruoli personalizzati che separano gli amministratori dei volumi, che possono eliminare i volumi di origine ma non interrompere i mirror e quindi non eliminare i volumi di destinazione, dagli amministratori CRR, che non possono eseguire alcuna operazione sui volumi. Vedere<block ref="bf2a9ccb864ad3a1fa1ddc1fec02a961" category="inline-link-rx"></block> Nella documentazione di Cloud Volumes Service per le autorizzazioni consentite da ciascun gruppo di amministratori.</block>
  <block id="48b5832efbf50440742eee7bfd02733b" category="section-title">Backup Cloud Volumes Service</block>
  <block id="8ee215caafa31f1ecdd53056d288eb19" category="paragraph">Sebbene Cloud Volumes Service offra un'elevata durata dei dati, gli eventi esterni possono causare la perdita di dati. In caso di eventi di sicurezza come virus o ransomware, i backup e i ripristini diventano critici per la ripresa dell'accesso ai dati in modo tempestivo. Un amministratore potrebbe eliminare accidentalmente un volume Cloud Volumes Service. In alternativa, gli utenti vogliono semplicemente conservare le versioni di backup dei propri dati per molti mesi e mantenere lo spazio di copia Snapshot aggiuntivo all'interno del volume diventa una sfida in termini di costi. Sebbene le copie Snapshot siano il modo migliore per conservare le versioni di backup delle ultime settimane per ripristinare i dati persi, sono contenute all'interno del volume e vengono perse se il volume scompare.</block>
  <block id="99144970696c7e366271871a0e83b6cd" category="paragraph">Per tutti questi motivi, NetApp Cloud Volumes Service offre servizi di backup tramite<block ref="253601e5d476a508040b734cbc7b3164" category="inline-link-rx"></block>.</block>
  <block id="a5cef37749b0ea6b89d13e2bfc190bcc" category="paragraph">Il backup di Cloud Volumes Service genera una copia del volume su Google Cloud Storage (GCS). Esegue il backup solo dei dati effettivi memorizzati nel volume, non dello spazio libero. Funziona come incrementale per sempre, il che significa che trasferisce il contenuto del volume una volta e da lì continua a eseguire il backup solo dei dati modificati. Rispetto ai classici concetti di backup con più backup completi, consente di risparmiare grandi quantità di storage di backup, riducendo i costi. Poiché il prezzo mensile dello spazio di backup è inferiore rispetto a un volume, è il posto ideale per mantenere le versioni di backup più a lungo.</block>
  <block id="d41618915810c18642064f885af2a835" category="paragraph">Gli utenti possono utilizzare un backup Cloud Volumes Service per ripristinare qualsiasi versione di backup sullo stesso volume o su un volume diverso all'interno della stessa regione. Se il volume di origine viene cancellato, i dati di backup vengono conservati e devono essere gestiti (ad esempio, eliminati) in modo indipendente.</block>
  <block id="3289695e643b478f0efa19edc74cf567" category="inline-link">Documentazione di backup di Cloud Volumes Service</block>
  <block id="be7923d42a302a1a86fdaa9f096fde63" category="inline-link">numero massimo di versioni di backup supportate</block>
  <block id="59aab28b54594c59dab8d19afd9478e4" category="inline-link">prezzi</block>
  <block id="57e8b261ab803839f73416e368f552bc" category="paragraph">Il backup Cloud Volumes Service è integrato in Cloud Volumes Service come opzione. Gli utenti possono decidere quali volumi proteggere attivando il backup Cloud Volumes Service per volume. Vedere<block ref="218d9dd384a48541f627c5084c286ade" category="inline-link-rx"></block> per informazioni sui backup, consultare<block ref="d724a11e2928bd8489b8ad8fe1eac94b" category="inline-link-rx"></block>, pianificazione e.<block ref="31e05107512c82ef17df4f5c4b3fe0bd" category="inline-link-rx"></block>.</block>
  <block id="9a647ae53ed9b2a783aef42530e1fe97" category="paragraph">Tutti i dati di backup di un progetto vengono memorizzati all'interno di un bucket GCS, gestito dal servizio e non visibile all'utente. Ogni progetto utilizza un bucket diverso. Attualmente, i bucket si trovano nella stessa regione dei volumi Cloud Volumes Service, ma sono in corso di discussione ulteriori opzioni. Consultare la documentazione per conoscere lo stato più recente.</block>
  <block id="4e1c6d2a637d959db4ce4a09b3e5c580" category="paragraph">Il trasporto dei dati da un bucket Cloud Volumes Service a GCS utilizza reti Google interne al servizio con HTTPS e TLS1.2. I dati vengono crittografati a riposo con chiavi gestite da Google.</block>
  <block id="5e467dce18f46b1803b06097fae60b82" category="inline-link">roles/netappclodvolumes.admin</block>
  <block id="de8a90c8653195ed30cc4920de8c7921" category="paragraph">Per gestire il backup Cloud Volumes Service (creazione, eliminazione e ripristino dei backup), un utente deve disporre di<block ref="595f329bf934dbc7996bb735e9664896" category="inline-link-rx"></block> ruolo.</block>
  <block id="d5588adba169169b3d9fbc3d40fa9e91" category="inline-link-macro">Pagina successiva: Panoramica dell'architettura.</block>
  <block id="70c94a86f99e1aa5d40b6ca87c17a399" category="paragraph"><block ref="70c94a86f99e1aa5d40b6ca87c17a399" category="inline-link-macro-rx"></block></block>
  <block id="f054dd8cc88786d8030b18d90271f377" category="summary">Cloud Volumes Service espone più porte TCP per le condivisioni NFS e SMB.</block>
  <block id="c5381dc540506dbb210e2d300554e4cd" category="doc">Firewall</block>
  <block id="3081ff6911f8297ddc53dab3c34d0811" category="inline-link-macro">Precedente: Crittografia dei dati a riposo.</block>
  <block id="4591bc0b4ed2ba115e753bad56145791" category="paragraph"><block ref="4591bc0b4ed2ba115e753bad56145791" category="inline-link-macro-rx"></block></block>
  <block id="1e45092c94634e40f68ce647e16109a4" category="paragraph">Cloud Volumes Service espone più porte TCP per le condivisioni NFS e SMB:</block>
  <block id="8ace993e6a8c37342617dbf22185890a" category="inline-link">Porte richieste per l'accesso NFS</block>
  <block id="c56328227fc3affbe6ed0ef4ba04f494" category="list-text"><block ref="c56328227fc3affbe6ed0ef4ba04f494" category="inline-link-rx"></block></block>
  <block id="259c7a7ef42d8165caa2c0238cb6f9fe" category="inline-link">Porte richieste per l'accesso SMB</block>
  <block id="c6563340810489dd712f25c2644eaed8" category="list-text"><block ref="c6563340810489dd712f25c2644eaed8" category="inline-link-rx"></block></block>
  <block id="48e54afcf03ca45bfe38f6b7ff58764a" category="inline-link">configurato</block>
  <block id="2957bc03d53f1be7c11d427906ed1479" category="inline-link">Rilevamento DC basato su DNS</block>
  <block id="150a343c955aa3114dca2e9c39571ad8" category="paragraph">Inoltre, le configurazioni SMB, NFS con LDAP, incluso Kerberos, e a doppio protocollo richiedono l'accesso a un dominio Active Directory di Windows. Le connessioni di Active Directory devono essere<block ref="10ec0b3d8ec2c3b73be0dd7483e61c9e" category="inline-link-rx"></block> in base all'area geografica. I controller di dominio Active Directory vengono identificati tramite<block ref="821541d595f9fee8c67d91aa5da861b4" category="inline-link-rx"></block> Utilizzando i server DNS specificati. Vengono utilizzati tutti i controller di dominio restituiti. L'elenco dei controller di dominio idonei può essere limitato specificando un sito Active Directory.</block>
  <block id="02d7b2e18b6bb033bf88be07d39aab4c" category="inline-link">A bordo del Cloud Volumes Service</block>
  <block id="7a9b1188e66f0581af9bc76ec3099a55" category="paragraph">Cloud Volumes Service raggiunge gli indirizzi IP dell'intervallo CIDR allocati con<block ref="3102e8199e828cb030b6f0ade5fc2cec" prefix=" " category="inline-code"></block> comando mentre<block ref="e8e0c669039859d9678de67879e03e1d" category="inline-link-rx"></block>. È possibile utilizzare questo CIDR come indirizzi di origine per configurare i firewall in entrata nei controller di dominio Active Directory.</block>
  <block id="934adb56d62c2e8a1334785cbb6d4987" category="inline-link">Esporre le porte ai CIDR Cloud Volumes Service come indicato qui</block>
  <block id="60bb23c83a123fdd2c99980eb34c8f80" category="paragraph">I controller di dominio Active Directory devono<block ref="7b35a292c67c7ee0f89d3dd389e188e4" category="inline-link-rx"></block>.</block>
  <block id="fa995eb117a30c2365b6a07bf00e36e4" category="inline-link-macro">Pagina successiva: Panoramica dei protocolli NAS.</block>
  <block id="6160acafbed3bd228bd0703f2991a4cb" category="paragraph"><block ref="6160acafbed3bd228bd0703f2991a4cb" category="inline-link-macro-rx"></block></block>
  <block id="599e7197321e9ab772426d7187714f67" category="summary">SMB è un protocollo di file sharing di rete sviluppato da Microsoft che fornisce autenticazione centralizzata di utenti/gruppi, autorizzazioni, blocco e condivisione di file a più client SMB su una rete Ethernet.</block>
  <block id="b4fdd997b1f33e0d4c6964444c2bf399" category="doc">PMI</block>
  <block id="b619a787e67dd6b7b38f5db3e4da5e80" category="inline-link-macro">Precedente: NFS.</block>
  <block id="d5c73fd283fc4c7fcf6fefda8649450f" category="paragraph"><block ref="d5c73fd283fc4c7fcf6fefda8649450f" category="inline-link-macro-rx"></block></block>
  <block id="e0a515b0910f55d3d1d5adda978e8e4f" category="paragraph"><block ref="395dbbdb78e4ae6be8daf8ab2b7828a7" category="inline-link-rx"></block> È un protocollo di condivisione file di rete sviluppato da Microsoft che fornisce autenticazione centralizzata di utenti/gruppi, autorizzazioni, blocco e condivisione file a più client SMB su una rete Ethernet. I file e le cartelle vengono presentati ai client tramite condivisioni, che possono essere configurate con una vasta gamma di proprietà di condivisione e offrono il controllo degli accessi tramite permessi a livello di condivisione. SMB può essere presentato a qualsiasi client che offra supporto per il protocollo, inclusi client Windows, Apple e Linux.</block>
  <block id="63f2e3eee09c9d71b23530e2205eb36a" category="paragraph">Cloud Volumes Service supporta le versioni SMB 2.1 e 3.x del protocollo.</block>
  <block id="cc4a835dfb2ac9e7ba402c068a4ef9a0" category="section-title">Controllo degli accessi/condivisioni SMB</block>
  <block id="f122c057113b41c182d10fddf2a82817" category="list-text">Quando un nome utente Windows richiede l'accesso al volume Cloud Volumes Service, Cloud Volumes Service cerca un nome utente UNIX utilizzando i metodi configurati dagli amministratori Cloud Volumes Service.</block>
  <block id="ac960a1b86a1625e4ff98dbb3feef120" category="list-text">Se viene configurato un provider di identità UNIX esterno (LDAP) e i nomi utente Windows/UNIX sono identici, i nomi utente di Windows verranno mappati 1:1 ai nomi utente UNIX senza alcuna configurazione aggiuntiva. Quando LDAP è attivato, Active Directory viene utilizzato per ospitare gli attributi UNIX per gli oggetti utente e gruppo.</block>
  <block id="3c60aff1fcf4407fc40492eebac8e37b" category="inline-link-macro">"Utilizzo di LDAP per la mappatura asimmetrica dei nomi"</block>
  <block id="e4adb9d6d8d5650dfb0663dde5495dff" category="list-text">Se i nomi Windows e UNIX non corrispondono in modo identico, è necessario configurare LDAP in modo da consentire a Cloud Volumes Service di utilizzare la configurazione di mappatura dei nomi LDAP (vedere la sezione <block ref="1cca6755f54a82023ec645e8be5d4c82" category="inline-link-macro-rx"></block>).</block>
  <block id="5205bf34161159f00d7f28cb5e6e2a89" category="list-text">Se LDAP non è in uso, gli utenti SMB di Windows si associano a un utente UNIX locale predefinito denominato<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> In Cloud Volumes Service. Ciò significa che i file scritti in Windows dagli utenti che eseguono il mapping a<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> Mostra la proprietà UNIX come<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> In ambienti NAS multiprotocollo.<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> qui è effettivamente il<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> Utente in ambienti Linux (UID 65534).</block>
  <block id="0ff58f508b02c651e0b4ee271b1792d9" category="paragraph">Nelle implementazioni solo con SMB, il<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> Il mapping continua a verificarsi, ma non è importante, perché la proprietà di utenti e gruppi di Windows viene visualizzata correttamente e l'accesso NFS al volume solo SMB non è consentito. Inoltre, i volumi solo SMB non supportano la conversione in NFS o volumi a doppio protocollo dopo la loro creazione.</block>
  <block id="9327392a148953617bfae88e7e46a666" category="paragraph">Windows sfrutta Kerberos per l'autenticazione del nome utente con i domain controller di Active Directory, che richiede uno scambio di nome utente e password con i controller di dominio ad, esterni all'istanza di Cloud Volumes Service. L'autenticazione Kerberos viene utilizzata quando<block ref="cd2eba6db07c5178e47368d41d7c8ecb" prefix=" " category="inline-code"></block> Il percorso UNC viene utilizzato dai client SMB ed è vero quanto segue:</block>
  <block id="61caea7c1c859702c330a0781763fd23" category="list-text">La voce DNS A/AAAA esiste per NOMESERVER</block>
  <block id="de4327d512f4e62f9b3ae80f8bb719cc" category="list-text">Esiste un SPN valido per l'accesso SMB/CIFS per NOMESERVER</block>
  <block id="f5c19a901f7d9431872c0e8893aaa498" category="inline-link-macro">"Come viene visualizzato Cloud Volumes Service in Active Directory."</block>
  <block id="93c756ce24f344cc333703bcd2e7a06e" category="paragraph">Quando viene creato un volume SMB Cloud Volumes Service, il nome dell'account del computer viene creato come definito nella sezione <block ref="087d516981f271a0b6f0df624ae1e840" category="inline-link-macro-rx"></block> Il nome account del computer diventa anche il percorso di accesso condiviso SMB perché Cloud Volumes Service sfrutta il DNS dinamico (DDNS) per creare le voci A/AAAA e PTR necessarie nel DNS e le voci SPN necessarie sull'account principal del computer.</block>
  <block id="aafa8c8c59e359a65d0c657f05772244" category="admonition">Per creare le voci PTR, la zona di ricerca inversa per l'indirizzo IP dell'istanza Cloud Volumes Service deve esistere sul server DNS.</block>
  <block id="ecd31d9efcb752f09a0690c2f62bf88f" category="paragraph">Ad esempio, questo volume Cloud Volumes Service utilizza il seguente percorso di condivisione UNC:<block ref="a1ee866c4518da1e9fbb52dd43e4e39d" prefix=" " category="inline-code"></block>.</block>
  <block id="c6ee58936680de9d2229f523a4c54ffb" category="paragraph">In Active Directory, queste sono le voci SPN generate dal servizio Cloud Volumes:</block>
  <block id="5c3c803198a53be899a500a43fcf1d24" category="paragraph"><block ref="5c3c803198a53be899a500a43fcf1d24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97422e33b69a5567af9908d5b2d397fc" category="paragraph">Questo è il risultato della ricerca DNS in avanti/indietro:</block>
  <block id="1d3d964bf7fdd6249507cb3738908e54" category="paragraph">Facoltativamente, è possibile applicare un maggiore controllo degli accessi attivando/richiedendo la crittografia SMB per le condivisioni SMB in Cloud Volumes Service. Se la crittografia SMB non è supportata da uno degli endpoint, l'accesso non è consentito.</block>
  <block id="e5e9be92303e18ef3f22dfa57dcbd0d3" category="section-title">Utilizzo degli alias dei nomi SMB</block>
  <block id="500c4de8d7a022d507313e514b85d485" category="paragraph">In alcuni casi, potrebbe essere un problema di sicurezza per gli utenti finali conoscere il nome dell'account del computer in uso per Cloud Volumes Service. In altri casi, è sufficiente fornire un percorso di accesso più semplice agli utenti finali. In questi casi, è possibile creare alias SMB.</block>
  <block id="6c7c194988807a9112adc7f6bc9b1dd5" category="paragraph">Se si desidera creare alias per il percorso di condivisione SMB, è possibile sfruttare ciò che è noto come record CNAME in DNS. Ad esempio, se si desidera utilizzare il nome<block ref="87154d57e8c4e5c93755c1e158cd3257" prefix=" " category="inline-code"></block> per accedere alle condivisioni anziché a.<block ref="a1ee866c4518da1e9fbb52dd43e4e39d" prefix=" " category="inline-code"></block>, Ma si desidera comunque utilizzare l'autenticazione Kerberos, un CNAME nel DNS che punta al record A/AAAA esistente e un ulteriore SPN aggiunto all'account del computer esistente fornisce l'accesso Kerberos.</block>
  <block id="620b0e4f14250d32e58b3411c5fd3044" category="paragraph"><block ref="620b0e4f14250d32e58b3411c5fd3044" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a030a66483dc3115cd014273bad041d" category="paragraph">Questo è il risultato della ricerca diretta DNS dopo l'aggiunta di un CNAME:</block>
  <block id="97ec437207d5ac6fb22613655e7e395e" category="paragraph">Questa è la query SPN risultante dopo l'aggiunta di nuovi numeri di servizio:</block>
  <block id="5730e2788651b014b918d2ee1bfdfe67" category="paragraph"><block ref="5730e2788651b014b918d2ee1bfdfe67" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df91b2b002b78b2f9f87c79b56293060" category="paragraph">In un'acquisizione di pacchetti, è possibile visualizzare la richiesta di configurazione della sessione utilizzando l'SPN legato al CNAME.</block>
  <block id="8b36b24049a6cda34019fd47ea0273fc" category="paragraph"><block ref="8b36b24049a6cda34019fd47ea0273fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65cc39e4fb8a95d5fcc2098d620ff3b6" category="section-title">Dialetti di autenticazione SMB</block>
  <block id="fe9fdc3d8157e10bf5b31e8d28fe7827" category="inline-link">dialetti</block>
  <block id="c50c24feef6ada40d8e2f7be85359c0f" category="paragraph">Cloud Volumes Service supporta quanto segue<block ref="88f3097f4ad7d144185bbacf0330fbeb" category="inline-link-rx"></block> Per l'autenticazione SMB:</block>
  <block id="dfd5b430bc4db2c2836d0227ad9ac0c4" category="list-text">LM</block>
  <block id="d11322c1a7a2383491c23f13113c59ea" category="list-text">NTLM</block>
  <block id="d0952ee882764dd5c3105f5b23a3e505" category="list-text">NTLMv2</block>
  <block id="87b3695bfd6f672e2c7c4da7ca2b46a8" category="list-text">Kerberos</block>
  <block id="11012bc0af4eda341c391c39cf6aa27c" category="paragraph">L'autenticazione Kerberos per l'accesso alle condivisioni SMB è il livello di autenticazione più sicuro possibile. Con la crittografia AES e SMB attivata, il livello di sicurezza aumenta ulteriormente.</block>
  <block id="e5c584f1ac6fa07c9594321f8fc845e2" category="paragraph">Cloud Volumes Service supporta anche la compatibilità con le versioni precedenti per l'autenticazione LM e NTLM. Quando Kerberos non è configurato correttamente (ad esempio quando si creano alias SMB), l'accesso alla condivisione viene ricallato ai metodi di autenticazione più deboli (ad esempio NTLMv2). Poiché questi meccanismi sono meno sicuri, sono disattivati in alcuni ambienti Active Directory. Se i metodi di autenticazione più deboli sono disattivati e Kerberos non è configurato correttamente, l'accesso alla condivisione non riesce perché non esiste un metodo di autenticazione valido.</block>
  <block id="d87250f3f8075c2dfbcfe941d0c7bde9" category="inline-link">Sicurezza di rete: Livello di autenticazione di LAN Manager</block>
  <block id="f4457a3dba045094cb39418e2233c8c1" category="paragraph">Per informazioni sulla configurazione e la visualizzazione dei livelli di autenticazione supportati in Active Directory, vedere<block ref="d671b936eec72b8caa6e3a555955a849" category="inline-link-rx"></block>.</block>
  <block id="6ccfb9a0791b337d38ef8ff2cdf26cf8" category="section-title">Modelli di permesso</block>
  <block id="b1728e361f14c53940f081871f87e6ee" category="section-title">Permessi NTFS/file</block>
  <block id="3e5348fb86c26b3cabf2912e6e597902" category="paragraph">Le autorizzazioni NTFS sono le autorizzazioni applicate a file e cartelle nei file system che aderiscono alla logica NTFS. È possibile applicare le autorizzazioni NTFS in<block ref="972e73b7a882d0802a4e3a16946a2f94" prefix=" " category="inline-code"></block> oppure<block ref="9b6545e4cea9b4ad4979d41bb9170e2b" prefix=" " category="inline-code"></block> e può essere impostato su<block ref="45f0fb72a0defdfdb01de4b5a5a6876b" prefix=" " category="inline-code"></block> oppure<block ref="3682d1665cf331373000c20680732d3a" prefix=" " category="inline-code"></block> per il controllo degli accessi.</block>
  <block id="80b0c49680a2b15ae6a40273fadefaa8" category="paragraph">Le autorizzazioni di base includono:</block>
  <block id="704a2a0ea2e007dae9f25d038a988076" category="list-text">Controllo completo</block>
  <block id="7f090bbab1cc7f9c08bf4e54d932d3c0" category="list-text">Modificare</block>
  <block id="3ed713666b4f5112539dd5ffb9376ff4" category="list-text">Lettura ed esecuzione</block>
  <block id="7a1a5f3e79fdc91edf2f5ead9d66abb4" category="list-text">Leggi</block>
  <block id="1129c0e4d43f2d121652a7302712cff6" category="list-text">Di scrittura</block>
  <block id="75484cb1059b92206b918bde1204007a" category="paragraph">Quando si impostano le autorizzazioni per un utente o un gruppo, denominato ACE, si trova in un ACL. Le autorizzazioni NTFS utilizzano le stesse basi di lettura/scrittura/esecuzione dei bit in modalità UNIX, ma possono anche estendersi a controlli di accesso più granulari ed estesi (noti anche come permessi speciali), come Take Ownership, Create Folders/Append Data, Write Attributes e altro ancora.</block>
  <block id="77636166006179e57dc5edc6df25b80c" category="paragraph">I bit in modalità UNIX standard non forniscono lo stesso livello di granularità delle autorizzazioni NTFS (ad esempio, la possibilità di impostare autorizzazioni per singoli oggetti utente e gruppo in un ACL o di impostare attributi estesi). Tuttavia, gli ACL NFSv4.1 offrono le stesse funzionalità degli ACL NTFS.</block>
  <block id="9434d016806e0f50ac7f14efbfa3a3df" category="paragraph">Le autorizzazioni NTFS sono più specifiche delle autorizzazioni di condivisione e possono essere utilizzate insieme alle autorizzazioni di condivisione. Con le strutture di autorizzazione NTFS, si applicano le impostazioni più restrittive. Di conseguenza, le negazioni esplicite a un utente o a un gruppo sovrascrivono anche il controllo completo quando si definiscono i diritti di accesso.</block>
  <block id="c0ad12f90a714e04744ab070d26a9c80" category="paragraph">Le autorizzazioni NTFS sono controllate dai client SMB di Windows.</block>
  <block id="ef950b5546945ec414f9da7909c4fe8a" category="section-title">Autorizzazioni di condivisione</block>
  <block id="3df5ef25e4045d2e51c43effb69aa5de" category="paragraph">Le autorizzazioni di condivisione sono più generali delle autorizzazioni NTFS (solo lettura/modifica/controllo completo) e controllano la voce iniziale in una condivisione SMB, in modo simile al funzionamento delle regole dei criteri di esportazione NFS.</block>
  <block id="41123e00ec2463c8d7c60a10f3d3ede4" category="paragraph">Sebbene le regole dei criteri di esportazione NFS controllino l'accesso attraverso informazioni basate su host come indirizzi IP o nomi host, le autorizzazioni di condivisione SMB possono controllare l'accesso utilizzando le ACE di utente e gruppo in un ACL condiviso. È possibile impostare gli ACL di condivisione dal client Windows o dall'interfaccia utente di gestione di Cloud Volumes Service.</block>
  <block id="7f455f054b3ad11fb335d2f9ec69e3ff" category="paragraph">Per impostazione predefinita, gli ACL di condivisione e gli ACL dei volumi iniziali includono Everyone con controllo completo. Gli ACL dei file devono essere modificati, ma le autorizzazioni di condivisione vengono ignorate dalle autorizzazioni dei file sugli oggetti nella condivisione.</block>
  <block id="8d37bee954f03966b12b65871768a438" category="paragraph">Ad esempio, se a un utente è consentito solo l'accesso in lettura all'ACL del file di volume Cloud Volumes Service, viene negato l'accesso per creare file e cartelle anche se l'ACL di condivisione è impostato su Everyone con controllo completo, come illustrato nella figura seguente.</block>
  <block id="47ff9e7720c14a2a27bfa4ce12bbd268" category="paragraph"><block ref="47ff9e7720c14a2a27bfa4ce12bbd268" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef46360b81c847c0d6f5015920fd5f3e" category="paragraph"><block ref="ef46360b81c847c0d6f5015920fd5f3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="316a22056a64a8465269d31ac436fc22" category="paragraph">Per ottenere i migliori risultati di sicurezza, procedere come segue:</block>
  <block id="09fced4bea14e9b030bd1179b95f3b89" category="list-text">Rimuovere tutti dagli ACL di file e condivisione e impostare l'accesso di condivisione per utenti o gruppi.</block>
  <block id="8941d253e49282460162b7dac68ad2ba" category="list-text">Utilizzare i gruppi per il controllo degli accessi invece di singoli utenti per semplificare la gestione e velocizzare la rimozione/aggiunta degli utenti per condividere gli ACL attraverso la gestione dei gruppi.</block>
  <block id="f63df4fd4f9e10c567332b34b05d35ae" category="list-text">Consentire un accesso di condivisione meno restrittivo e più generale alle ACE sulle autorizzazioni di condivisione e bloccare l'accesso a utenti e gruppi con permessi di file per un controllo degli accessi più granulare.</block>
  <block id="afe52910905ef63730591f8a01bcb75e" category="list-text">Evitare l'utilizzo generale di ACL di negazione esplicite, in quanto sovrascrivono gli ACL di consenso. Limitare l'utilizzo di ACL di negazione esplicite per utenti o gruppi che devono essere limitati all'accesso rapido a un file system.</block>
  <block id="9a2191ac8d9f65679cdf29455149f6cb" category="inline-link">Ereditarietà ACL</block>
  <block id="780d68252d03e9f7617f6bf5fe95c1ce" category="list-text">Assicurarsi di prestare attenzione a.<block ref="19af65d9616f33b3ccaee367e8d4dc82" category="inline-link-rx"></block> impostazioni durante la modifica delle autorizzazioni; l'impostazione del flag di ereditarietà al livello superiore di una directory o di un volume con un numero elevato di file indica che ogni file sotto a tale directory o volume ha ereditato le autorizzazioni aggiunte, che possono creare comportamenti indesiderati come accesso/negazione non intenzionale e lunga modifica delle autorizzazioni quando ogni file viene regolato.</block>
  <block id="0c2104afa1bd6c96b5ccc9c7a7ee8a6a" category="section-title">SMB condivide le funzionalità di sicurezza</block>
  <block id="05ec24f8004d55ad7596b79266cd4691" category="paragraph">La prima volta che si crea un volume con accesso SMB in Cloud Volumes Service, viene visualizzata una serie di opzioni per la protezione di tale volume.</block>
  <block id="53eaeead30ddbd2dcb1526241312aedf" category="paragraph">Alcune di queste scelte dipendono dal livello Cloud Volumes Service (prestazioni o software) e le scelte includono:</block>
  <block id="d65a6ba5ce40987a368f3f757b5721ae" category="list-text">*Rendi visibile la directory Snapshot (disponibile sia per CVS-Performance che per CVS-SW).* questa opzione controlla se i client SMB possono accedere o meno alla directory Snapshot in una condivisione SMB <block ref="f9f8c4c52f58b30f374525080a180c65" prefix="(" category="inline-code"></block> E/o versioni precedenti). L'impostazione predefinita non è selezionata, il che significa che il volume per impostazione predefinita nasconde e non consente l'accesso a<block ref="26bef40a7b3e14ad93e80f8f4be79090" prefix=" " category="inline-code"></block> Directory e non vengono visualizzate copie Snapshot nella scheda versioni precedenti del volume.</block>
  <block id="9ebf5e1b6bf20c2942f0add8e979dd7a" category="paragraph"><block ref="9ebf5e1b6bf20c2942f0add8e979dd7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="baf0124343f1806f3ff44f011e92c73f" category="paragraph">È possibile nascondere le copie Snapshot dagli utenti finali per motivi di sicurezza, di performance (nascondendo queste cartelle dalle scansioni AV) o di preferenza. Le istantanee di Cloud Volumes Service sono di sola lettura, quindi anche se sono visibili, gli utenti finali non possono eliminare o modificare i file nella directory Snapshot. Si applicano le autorizzazioni per i file o le cartelle al momento dell'esecuzione della copia Snapshot. Se le autorizzazioni di un file o di una cartella cambiano tra le copie Snapshot, le modifiche si applicano anche ai file o alle cartelle nella directory Snapshot. Utenti e gruppi possono accedere a questi file o cartelle in base alle autorizzazioni. Sebbene non sia possibile eliminare o modificare i file nella directory Snapshot, è possibile copiare file o cartelle dalla directory Snapshot.</block>
  <block id="2716bd858fb85bb9b111c5d51138cb40" category="list-text">*Attiva la crittografia SMB (disponibile sia per CVS-Performance che per CVS-SW).* la crittografia SMB è disattivata per impostazione predefinita nella condivisione SMB (non selezionata). Selezionando la casella viene attivata la crittografia SMB, il che significa che il traffico tra il client SMB e il server viene crittografato in-flight con i livelli di crittografia più elevati supportati negoziati. Cloud Volumes Service supporta la crittografia fino a AES-256 per le PMI. L'attivazione della crittografia SMB comporta una penalizzazione delle performance che potrebbe o meno essere evidente per i client SMB, approssimativamente nell'intervallo 10-20%. NetApp incoraggia vivamente i test per verificare se tale penalizzazione delle performance è accettabile.</block>
  <block id="ab7715a00a3e7691d84318bb2f1a3bc1" category="list-text">*Nascondi condivisione SMB (disponibile sia per CVS-Performance che CVS-SW).* l'impostazione di questa opzione nasconde il percorso di condivisione SMB dalla normale navigazione. Ciò significa che i client che non conoscono il percorso di condivisione non possono visualizzare le condivisioni quando accedono al percorso UNC predefinito (ad esempio<block ref="eaf10dd9986e1d76c577b974d994e349" prefix=" " category="inline-code"></block>). Quando la casella di controllo è selezionata, solo i client che conoscono esplicitamente il percorso di condivisione SMB o che hanno il percorso di condivisione definito da un oggetto Criteri di gruppo possono accedervi (sicurezza tramite offuscamento).</block>
  <block id="67699a5a5f5ec8d69977d9f44b521201" category="inline-link">Come funziona Access Based Enumeration (ABE)?</block>
  <block id="eb36f3383eadcd01f954bc9848b7de21" category="list-text">*Enable access-based enumeration (ABE) (solo CVS-SW).* questo è simile a nascondere la condivisione SMB, tranne che le condivisioni o i file sono nascosti solo agli utenti o ai gruppi che non dispongono delle autorizzazioni per accedere agli oggetti. Ad esempio, se utente Windows<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> Non è consentito almeno l'accesso in lettura tramite le autorizzazioni, quindi l'utente Windows<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> Impossibile visualizzare la condivisione SMB o i file. Questa opzione è disattivata per impostazione predefinita ed è possibile attivarla selezionando la casella di controllo. Per ulteriori informazioni su ABE, consultare l'articolo della Knowledge base di NetApp<block ref="6d2d0139fec74415d85dc1015aa48640" category="inline-link-rx"></block></block>
  <block id="5ff6480cf15803c821d9cc9bb3dcbe5c" category="inline-link">Condivisioni SMB sempre disponibili</block>
  <block id="17faa8cfb0bc70572c6d4f120cb6de10" category="list-text">*Attiva il supporto delle condivisioni CA (Continuously Available) (solo CVS-Performance).*<block ref="97476034cc2961d2c1c061d5bdcc519a" category="inline-link-rx"></block> Fornire un modo per ridurre al minimo le interruzioni delle applicazioni durante gli eventi di failover replicando gli stati di blocco tra i nodi nel sistema di back-end Cloud Volumes Service. Non si tratta di una funzionalità di sicurezza, ma offre una migliore resilienza generale. Attualmente, solo le applicazioni SQL Server e FSLogix sono supportate per questa funzionalità.</block>
  <block id="f816f594817af59eac10c8385f34d319" category="section-title">Condivisioni nascoste predefinite</block>
  <block id="7ce84bf53b21b783ae6c62b61f60f9e3" category="inline-link">condivisioni amministrative nascoste</block>
  <block id="31a7b0c828b1a1039c3fe9e855430acd" category="paragraph">Quando viene creato un server SMB in Cloud Volumes Service, ne esistono<block ref="e698db250309574e2563e69229bd950f" category="inline-link-rx"></block> (Utilizzando la convenzione di naming in dollari) creati in aggiunta alla condivisione SMB del volume di dati. Questi includono l'accesso allo spazio dei nomi e l'IPC (sharing named pipe for communication between programs, come le chiamate di procedura remota (RPC) utilizzate per l'accesso a Microsoft Management Console (MMC)).</block>
  <block id="64667cec654fa57a129c5c1fe752d7ae" category="inline-link">Per impostazione predefinita, Windows non consente l'accesso anonimo a queste condivisioni</block>
  <block id="7962a42fa319b5ea9ccf0429193d4f3c" category="paragraph">La condivisione IPC non contiene ACL di condivisione e non può essere modificata, ma viene utilizzata esclusivamente per le chiamate RPC e.<block ref="582b1e06ccfbbf9885ff446ec79f8b0f" category="inline-link-rx"></block>.</block>
  <block id="c2c8a4f76f99f203d14ee3c1adae3c40" category="paragraph">La condivisione consente l'accesso predefinito a BUILTIN/Administrators, ma l'automazione Cloud Volumes Service rimuove l'ACL della condivisione e non consente l'accesso a nessuno perché l'accesso alla condivisione consente la visibilità di tutti i volumi montati nei file system Cloud Volumes Service. Di conseguenza, tenta di accedere a.<block ref="33f61bb25149c01e06f9ef66d462e5a2" prefix=" " category="inline-code"></block> non riuscito.</block>
  <block id="444613ce56f4180cf88b531783a9e3bc" category="section-title">Account con diritti di amministratore/backup locali/BUILTIN</block>
  <block id="5659f387517ed75a127b9a6bda6f1329" category="paragraph">I server SMB di Cloud Volumes Service mantengono una funzionalità simile a quella dei normali server SMB di Windows, in quanto esistono gruppi locali (ad esempio BUILTIN/amministratori) che applicano i diritti di accesso a utenti e gruppi di dominio selezionati.</block>
  <block id="709eb202e09b717ba82624b788948428" category="inline-link">SeBackupPrivilege e SeRestorePrivilege</block>
  <block id="03455d8db7797aab1e6e9efe9bf4d2a5" category="paragraph">Quando si specifica un utente da aggiungere agli utenti di backup, l'utente viene aggiunto al gruppo BUILTIN/Backup Operators nell'istanza di Cloud Volumes Service che utilizza tale connessione, che ottiene quindi<block ref="3d66e5b4422b04db3b01ddbcafb3649a" category="inline-link-rx"></block>.</block>
  <block id="b5b39a908a856900d75e0b129fb9e349" category="inline-link">SQL Server su condivisioni SMB</block>
  <block id="52f5e8856edf4d634cf608cb64bec885" category="paragraph">Quando si aggiunge un utente a Security Privilege Users, all'utente viene assegnato il privilegio SeSecurityPrivilege, utile in alcuni casi di utilizzo dell'applicazione, ad esempio<block ref="b685ff2242ac25f5022af8207109cc39" category="inline-link-rx"></block>.</block>
  <block id="99c9211b9f5166d96d9e6613c4be9f77" category="paragraph"><block ref="99c9211b9f5166d96d9e6613c4be9f77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59976878f4cfcf8cd4a9bccf37270fec" category="paragraph">È possibile visualizzare le appartenenze ai gruppi locali di Cloud Volumes Service tramite MMC con i privilegi appropriati. La figura seguente mostra gli utenti aggiunti utilizzando la console di Cloud Volumes Service.</block>
  <block id="9b02abec53251430b553f5124b676b1f" category="paragraph"><block ref="9b02abec53251430b553f5124b676b1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09e7cb53843328fd35bff1d1075e8e04" category="paragraph">La seguente tabella mostra l'elenco dei gruppi BUILTIN predefiniti e gli utenti/gruppi aggiunti per impostazione predefinita.</block>
  <block id="52087222d7968b7bd85e5698912f6cee" category="cell">Locale/gruppo BUILTIN</block>
  <block id="c899fa178e9ccd9c46154a79773b9e8e" category="cell">Membri predefiniti</block>
  <block id="f6c0ddae69a704e001f6cba9fba3f951" category="cell">BUILTIN/amministratori*</block>
  <block id="6930162f33d7d3cc792907afc2d709d6" category="cell">AMMINISTRATORI DI DOMINIO/dominio</block>
  <block id="291b9d53abc37bd4eeab64a68607df4f" category="cell">BUILTIN/Backup Operator*</block>
  <block id="f87e4b3cc74234e59b0d07ad558b2c05" category="cell">BUILTIN/guest</block>
  <block id="bea5dc29e529ecf572942e7f6cbbf19b" category="cell">Dominio/dominio guest</block>
  <block id="bafee069f6320499a0f630485028a961" category="cell">UTENTI BUILTIN/Power</block>
  <block id="d3ffae89384cc2219d9dc26887d6422c" category="cell">UTENTI BUILTIN/dominio</block>
  <block id="a26444fe66f07a77f6e392ad714158ff" category="cell">UTENTI DI DOMINIO/dominio</block>
  <block id="ee6df957412594fad1ce714d75089e5f" category="paragraph">*Appartenenza al gruppo controllata nella configurazione della connessione ad Active Directory di Cloud Volumes Service.</block>
  <block id="c648fec724703de3d038fda21e884ef7" category="paragraph">È possibile visualizzare gli utenti e i gruppi locali (e i membri del gruppo) nella finestra MMC, ma non è possibile aggiungere o eliminare oggetti o modificare le appartenenze ai gruppi da questa console. Per impostazione predefinita, solo il gruppo Domain Admins e l'amministratore vengono aggiunti al gruppo BUILTIN/Administrators in Cloud Volumes Service. Al momento, non è possibile modificarlo.</block>
  <block id="39aedbfda9a943aea0e4c841bc68dc0a" category="paragraph"><block ref="39aedbfda9a943aea0e4c841bc68dc0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ae7d2b2ec0c231b6934886bf6690c9e" category="paragraph"><block ref="0ae7d2b2ec0c231b6934886bf6690c9e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="255c5bd3cdece4dd4a7891941d9c964e" category="section-title">Accesso MMC/Gestione computer</block>
  <block id="7f956759e187dbb2b65022241e8053cd" category="paragraph">L'accesso SMB in Cloud Volumes Service fornisce la connettività alla MMC Gestione computer, che consente di visualizzare le condivisioni, gestire gli ACL delle condivisioni, visualizzare/gestire le sessioni SMB e aprire i file.</block>
  <block id="e3d561744b3b4f6ab5953c2f96daaad7" category="paragraph">Per utilizzare MMC per visualizzare le condivisioni SMB e le sessioni in Cloud Volumes Service, l'utente attualmente connesso deve essere un amministratore di dominio. Agli altri utenti è consentito l'accesso per visualizzare o gestire il server SMB da MMC e ricevere una finestra di dialogo non si dispone delle autorizzazioni quando si tenta di visualizzare condivisioni o sessioni sull'istanza SMB di Cloud Volumes Service.</block>
  <block id="aaf8b324d80834b9d235cb6b6d84be89" category="paragraph">Per connettersi al server SMB, aprire Gestione computer, fare clic con il pulsante destro del mouse su Gestione computer, quindi selezionare Connetti a un altro computer. Viene visualizzata la finestra di dialogo Seleziona computer, in cui è possibile immettere il nome del server SMB (disponibile nelle informazioni sul volume Cloud Volumes Service).</block>
  <block id="c34ce8bbe19f26cf58867de938f87920" category="paragraph">Quando si visualizzano le condivisioni SMB con le autorizzazioni appropriate, vengono visualizzate tutte le condivisioni disponibili nell'istanza di Cloud Volumes Service che condividono la connessione Active Directory. Per controllare questo comportamento, impostare l'opzione Nascondi condivisioni SMB sull'istanza del volume Cloud Volumes Service.</block>
  <block id="5bcf8cb715ebf788ba3e70915f4256c2" category="paragraph">Tenere presente che è consentita una sola connessione Active Directory per regione.</block>
  <block id="b939aeb87de29dc576ad4adc5fa19bce" category="paragraph"><block ref="b939aeb87de29dc576ad4adc5fa19bce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c57a1134332b8bafcaa5f411a65b4a49" category="paragraph"><block ref="c57a1134332b8bafcaa5f411a65b4a49" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1325fb66f29e707e7e3402f0d45d59dc" category="paragraph">La seguente tabella mostra un elenco delle funzionalità supportate/non supportate per MMC.</block>
  <block id="241bac47978fca670a6b9c52e3432067" category="cell">Funzioni supportate</block>
  <block id="fe2de21fdfcaf4ed19a251aab83bf0ff" category="cell">Funzioni non supportate</block>
  <block id="ad338fe21209358afd2f29eee14817c6" category="list-text">Visualizza condivisioni</block>
  <block id="a5dc19ca94f052a57587a2f4f1433678" category="list-text">Visualizzare le sessioni SMB attive</block>
  <block id="ff50826288707e494282b4cf6bec983b" category="list-text">Visualizzare i file aperti</block>
  <block id="8c006cf58f2706f56d65e1431b1e128e" category="list-text">Visualizzare utenti e gruppi locali</block>
  <block id="bad02cc8e307a9ac8bf6899188811a54" category="list-text">Visualizzare le appartenenze ai gruppi locali</block>
  <block id="5ab1c0d0251d23bc086198a8fc219a69" category="list-text">Enumerare l'elenco di sessioni, file e connessioni ad albero nel sistema</block>
  <block id="bd7ff4b31e7eade785d74789a052242c" category="list-text">Chiudere i file aperti nel sistema</block>
  <block id="3a6cd2ea18cf077c57b65c28c40f9851" category="list-text">Chiudere le sessioni aperte</block>
  <block id="e5ded1413b3fd0a1690184029acf1845" category="list-text">Creare/gestire le condivisioni</block>
  <block id="b4d1348a7ae3aa39ac1fbd299a07ebb9" category="list-text">Creazione di nuovi utenti/gruppi locali</block>
  <block id="5c3d34e6fdaee1edee0722fcef147f8a" category="list-text">Gestione/visualizzazione di utenti/gruppi locali esistenti</block>
  <block id="1c79052ffd16d848acb6278dd54f0d33" category="list-text">Visualizza eventi o log delle performance</block>
  <block id="eedf037c0977372c4f0adaa359d5f6e0" category="list-text">Gestione dello storage</block>
  <block id="d5d1ca904ae55c0d5399eb923b8d6d21" category="list-text">Gestione di servizi e applicazioni</block>
  <block id="dddaf61539328810b230a60430960038" category="section-title">Informazioni sulla sicurezza dei server SMB</block>
  <block id="7c7ff5a0c882bba2c6d86dc13caa6e49" category="paragraph">Il server SMB di Cloud Volumes Service utilizza una serie di opzioni che definiscono le policy di sicurezza per le connessioni SMB, tra cui l'inclinazione del clock Kerberos, l'età del ticket, la crittografia e molto altro ancora.</block>
  <block id="bdf80cb84c583e3d6af81c4778921102" category="paragraph">La seguente tabella contiene un elenco di queste opzioni, le loro funzioni, le configurazioni predefinite e se possono essere modificate con Cloud Volumes Service. Alcune opzioni non si applicano a Cloud Volumes Service.</block>
  <block id="708cc30ece03d9ba30511bea4ea09792" category="cell">Opzione di sicurezza</block>
  <block id="b12c51b935d86f01d092fb23a1fa4f9f" category="cell">Che cosa fa</block>
  <block id="31ce3cdcd67850870b616f75b555bbc5" category="cell">Valore predefinito</block>
  <block id="216a8093d27a97d2912ed6822d19d410" category="cell">Può cambiare?</block>
  <block id="ad67361f283520dada90173b5fbfaad7" category="cell">Inclinazione massima del clock Kerberos (minuti)</block>
  <block id="ebd83f9f3f1a10793a7aaf199f57a32b" category="cell">Disallineamento massimo del tempo tra Cloud Volumes Service e i controller di dominio. Se l'intervallo di tempo supera i 5 minuti, l'autenticazione Kerberos non riesce. Viene impostato sul valore predefinito di Active Directory.</block>
  <block id="e4da3b7fbbce2345d7772b0674a318d5" category="cell">5</block>
  <block id="ccf9068a42f159a1b1cd3e07b84c5ecd" category="cell">Durata ticket Kerberos (ore)</block>
  <block id="34c1c29ec6cffe3b75b5f4db3cd4e12f" category="cell">Tempo massimo in cui un ticket Kerberos rimane valido prima di richiedere un rinnovo. Se non si verifica alcun rinnovo prima delle 10 ore, è necessario ottenere un nuovo biglietto. Cloud Volumes Service esegue automaticamente questi rinnovi. 10 ore è il valore predefinito di Active Directory.</block>
  <block id="b63288488b52af4af602d79dce8aa252" category="cell">Rinnovo massimo ticket Kerberos (giorni)</block>
  <block id="082ea39c709884c3439c0b1e937ee15a" category="cell">Numero massimo di giorni in cui un ticket Kerberos può essere rinnovato prima che sia necessaria una nuova richiesta di autorizzazione. Cloud Volumes Service rinnova automaticamente i ticket per le connessioni SMB. Sette giorni è il valore predefinito di Active Directory.</block>
  <block id="8f14e45fceea167a5a36dedd4bea2543" category="cell">7</block>
  <block id="2127af947646b417ab67c66e82922af5" category="cell">Timeout connessione KDC Kerberos (sec)</block>
  <block id="4a4dfa50ac48d9523d22b929a8df2e01" category="cell">Il numero di secondi prima del timeout di una connessione KDC.</block>
  <block id="09b779421f875a0831c9165f7730b710" category="cell">Richiedi firma per traffico SMB in entrata</block>
  <block id="8f4c5ae7b0c978c58bbe10790f9eb578" category="cell">Impostazione per richiedere la firma per il traffico SMB. Se impostata su true, i client che non supportano la firma non riescono a connettersi.</block>
  <block id="c77326ff7e3ae38e2b7ed07e3bff97e8" category="cell">Richiedi complessità password per account utente locali</block>
  <block id="fab3a355aeb5f939ba8dcdc4ae0ea4b8" category="cell">Utilizzato per le password degli utenti SMB locali. Cloud Volumes Service non supporta la creazione di utenti locali, pertanto questa opzione non si applica a Cloud Volumes Service.</block>
  <block id="f827cf462f62848df37c5e1e94a4da74" category="cell">Vero</block>
  <block id="a3ab2beb782b5f0d7b6d1eb3cacdff1f" category="cell">Utilizzare start_tls per le connessioni LDAP di Active Directory</block>
  <block id="0e46800ed1870ec055aaa1a1193ff94e" category="cell">Utilizzato per attivare le connessioni TLS iniziali per Active Directory LDAP. Cloud Volumes Service attualmente non supporta l'abilitazione di questa opzione.</block>
  <block id="b3734582301f762d04b757dd4bc38917" category="cell">AES-128 e AES-256 Encryption for Kerberos sono abilitati</block>
  <block id="4f36af6c9bdde3ebcee7b34176ffe895" category="cell">In questo modo si controlla se la crittografia AES viene utilizzata per le connessioni Active Directory e viene controllata con l'opzione Enable AES Encryption for Active Directory Authentication (attiva crittografia AES per l'autenticazione Active Directory) quando si crea o si modifica la connessione Active Directory.</block>
  <block id="60a39bccb81f56ddfcbb75f0ffcd1fb6" category="cell">Livello di compatibilità LM</block>
  <block id="a4ada97522d5a887e144bf5d59b41a79" category="cell">Livello dei dialetti di autenticazione supportati per le connessioni Active Directory. Vedere la sezione "<block ref="17dc1460fa48a825f7967ddb6804d663" category="inline-xref-macro-rx"></block>" per ulteriori informazioni.</block>
  <block id="cba8970659f15f342022079c22a97ee9" category="cell">ntlmv2-krb</block>
  <block id="5e22abe32604d6b7925fa4768934bb5d" category="cell">Richiedi crittografia SMB per traffico CIFS in entrata</block>
  <block id="ae7c4fcb353d520e8996acadf9c9c42f" category="cell">Richiede la crittografia SMB per tutte le condivisioni. Questa opzione non viene utilizzata da Cloud Volumes Service; impostare invece la crittografia per volume (vedere la sezione "<block ref="6931acdfb95dc44f28af40d26d20d65c" category="inline-xref-macro-rx"></block>").</block>
  <block id="e00514b301b6206c1024de564d0d71fe" category="cell">Sicurezza della sessione client</block>
  <block id="b9e69cb6a219e02ada3e29b808558c45" category="inline-link-macro">"Associazione del canale LDAP".</block>
  <block id="d16466e25f07f41d5c768e32becc9751" category="cell">Imposta la firma e/o il sealing per la comunicazione LDAP. Questa opzione non è attualmente impostata in Cloud Volumes Service, ma potrebbe essere necessaria nelle versioni future per risolvere . La risoluzione dei problemi di autenticazione LDAP dovuti alla patch di Windows è descritta nella sezione <block ref="4bb24ef2f48443c7e6d43902d0f8498e" category="inline-link-macro-rx"></block>.</block>
  <block id="b4c17f5cf25d927d8fb7dbab5e1d84c5" category="cell">Abilitazione SMB2 per connessioni DC</block>
  <block id="31a7643648d0d4454c1fd8a860f1a12d" category="cell">Utilizza SMB2 per le connessioni DC. Attivato per impostazione predefinita.</block>
  <block id="2cd88a3568a04efbfd46abb6cce9a411" category="cell">System-default</block>
  <block id="6158881a00903bd45b66955e6487a27c" category="cell">LDAP Referral Chasing</block>
  <block id="a408a02f7b8e36f4913d8dc2debb2b95" category="cell">Quando si utilizzano più server LDAP, la ricerca dei riferimenti consente al client di fare riferimento ad altri server LDAP nell'elenco quando non viene trovata una voce nel primo server. Attualmente non è supportato da Cloud Volumes Service.</block>
  <block id="4ddc9ad0bd193ba15a48f662666ccd96" category="cell">Utilizzare LDAPS per connessioni Active Directory sicure</block>
  <block id="4182d7f699521f08b56835082e7caf27" category="cell">Attiva l'utilizzo di LDAP su SSL. Attualmente non supportato da Cloud Volumes Service.</block>
  <block id="b31e0a21b1fa97ab2faf1479ea00c9db" category="cell">La crittografia è necessaria per la connessione DC</block>
  <block id="23cc5b51f575d3c458ac112689f7a2f1" category="cell">Richiede la crittografia per le connessioni DC riuscite. Disattivato per impostazione predefinita in Cloud Volumes Service.</block>
  <block id="595451bb2138edcd7bd73c4e11f8890d" category="inline-link-macro">Successivo: Protocollo doppio/multiprotocollo.</block>
  <block id="47b43136bb3740d6abdf3823c798bd7e" category="paragraph"><block ref="47b43136bb3740d6abdf3823c798bd7e" category="inline-link-macro-rx"></block></block>
  <block id="95151e0beeb1cf14e98ed9e0e0ebc86f" category="doc">Protocolli NAS</block>
  <block id="451abeb07875465ff669fc3bfc502564" category="summary">La sicurezza, in particolare nel cloud in cui l'infrastruttura non è sotto il controllo degli amministratori dello storage, è fondamentale per affidare i tuoi dati alle offerte di servizi fornite dai cloud provider. Questo documento offre una panoramica delle offerte di sicurezza offerte da NetApp Cloud Volumes Service in Google Cloud.</block>
  <block id="85f174d487aef272a0a9ea0f980e4827" category="doc">TR-4918: Panoramica sulla sicurezza - NetApp Cloud Volumes Service in Google Cloud</block>
  <block id="09f7873d6f07efaef82aef2b95f42e0a" category="paragraph">Oliver Krause, Justin Parisi, NetApp</block>
  <block id="1e06922fd676ae97f9dc69dbbfc93992" category="section-title">Scopo del documento</block>
  <block id="c2f1a37c5b3a149d2e79ad5a41c86139" category="inline-link">Cloud Volumes Service è disponibile in Google Cloud</block>
  <block id="c2197b5184a5af948e5dc6e6dcf6e5c3" category="paragraph">La sicurezza, in particolare nel cloud in cui l'infrastruttura non è sotto il controllo degli amministratori dello storage, è fondamentale per affidare i tuoi dati alle offerte di servizi fornite dai cloud provider. Questo documento offre una panoramica delle offerte di sicurezza offerte da NetApp<block ref="b29f7971c7793aea2bb4311fa5c38ee0" category="inline-link-rx"></block>.</block>
  <block id="f2b84afd0523a6df7547c404aa3647d8" category="section-title">Pubblico previsto</block>
  <block id="75ff467aeacdad8bd3ed9fe31431d022" category="paragraph">I destinatari del presente documento includono, a titolo esemplificativo e non esaustivo, i seguenti ruoli:</block>
  <block id="3487d2ed085064f5b68318d25038bcd6" category="list-text">Cloud provider</block>
  <block id="203ea32883f92321782cc1a312345903" category="list-text">Amministratori dello storage</block>
  <block id="7e89bd35a6b8558a95e9e4ec446df00d" category="list-text">Architetti dello storage</block>
  <block id="528efe83de18ec1cf2eb982cc641bb89" category="list-text">Risorse sul campo</block>
  <block id="a6205b388d7b872550efc1a57461e045" category="list-text">Decision maker aziendali</block>
  <block id="d9a404dc3c51a0dfc2360a6f7f97c00c" category="inline-link-macro">"Contattaci."</block>
  <block id="ec45e675f8dd5d470d6edacfc9ac6a2d" category="paragraph">In caso di domande sul contenuto di questo report tecnico, consulta la sezione <block ref="bbd2d7f57ba5e479a6b271845e2b7ec0" category="inline-link-macro-rx"></block></block>
  <block id="b54d58d7e43c404563f91e38d3efbcac" category="cell">Abbreviazione</block>
  <block id="0b890b1926b90387673882e6ccae7fdc" category="cell">Definizione</block>
  <block id="e898e7a5df4dec909ad011657b510e2d" category="cell">CVS-SW</block>
  <block id="3b558136fa0b6447d030d5fd2d28765b" category="cell">Cloud Volumes Service, CVS tipo di servizio</block>
  <block id="439d7969e09b4b31626fcf209b8fdcb7" category="cell">Performance CVS</block>
  <block id="3da305112390b1f2d5e6ad8818e00065" category="cell">Cloud Volume Service, tipo di servizio CVS-Performance</block>
  <block id="041159b903daf7d5923837346de98407" category="cell">PSA</block>
  <block id="eb2108209f61048e4b7ebba4b61f91ee" category="inline-link-macro">Avanti: In che modo Cloud Volumes Service in Google Cloud protegge i tuoi dati.</block>
  <block id="4c9538193c211d1d025b959f6407da23" category="paragraph"><block ref="4c9538193c211d1d025b959f6407da23" category="inline-link-macro-rx"></block></block>
  <block id="9b6e8c1f1a4d79991136cfd2b3fde77a" category="summary">Cloud Volumes Service consente di connettere l'istanza di Cloud Volumes Service a un server Active Directory esterno per la gestione delle identità per gli utenti SMB e UNIX. Per utilizzare SMB in Cloud Volumes Service è necessario creare una connessione Active Directory.</block>
  <block id="d099e6eafff98e1042c1029849e2db1b" category="doc">Considerazioni per la creazione di connessioni Active Directory</block>
  <block id="1ca3bc7ee6e687110fa43103bcff28e9" category="inline-link-macro">Precedente: Protocollo doppio/multiprotocollo.</block>
  <block id="90e9716dfe1097d996980af0b2d435b6" category="paragraph"><block ref="90e9716dfe1097d996980af0b2d435b6" category="inline-link-macro-rx"></block></block>
  <block id="b092138563f7b68473c3bf2a6a23a434" category="inline-link">Accesso privato a Google</block>
  <block id="dd1f65c08f03e8278da92a88b4c609b5" category="inline-link">Best practice per l'utilizzo di Active Directory in Google Cloud</block>
  <block id="758d9a1746e1f53cf6e7882ed864c1a4" category="paragraph">La configurazione fornisce diverse opzioni che richiedono una certa considerazione per la sicurezza. Il server Active Directory esterno può essere un'istanza on-premise o nativo del cloud. Se si utilizza un server Active Directory on-premise, non esporre il dominio alla rete esterna (ad esempio con un DMZ o un indirizzo IP esterno). Utilizzare, invece, tunnel privati o VPN sicuri, trust di foresta unirway o connessioni di rete dedicate alle reti on-premise con<block ref="76bc9bf9d2d87bee997fb1ade7da1eaa" category="inline-link-rx"></block>. Per ulteriori informazioni su, consultare la documentazione di Google Cloud<block ref="28831e2b31059cd3ce2ee26e8b5c8fcf" category="inline-link-rx"></block>.</block>
  <block id="22900d9fe4089ff2f29ada31dfd82836" category="admonition">CVS-SW richiede che i server Active Directory si trovino nella stessa regione. Se si tenta di stabilire una connessione CC in CVS-SW con un'altra regione, il tentativo non riesce. Quando si utilizza CVS-SW, assicurarsi di creare siti Active Directory che includono i controller di dominio Active Directory e specificare i siti in Cloud Volumes Service per evitare tentativi di connessione DC tra regioni.</block>
  <block id="9f69695f33b67147c3fd64e477aa784b" category="section-title">Credenziali di Active Directory</block>
  <block id="2ae640f39e0e652f621ec44b74e57892" category="paragraph">Quando SMB o LDAP per NFS è attivato, Cloud Volumes Service interagisce con i controller di Active Directory per creare un oggetto account macchina da utilizzare per l'autenticazione. Questo non è diverso dal modo in cui un client SMB di Windows si unisce a un dominio e richiede gli stessi diritti di accesso alle unità organizzative (OU) in Active Directory.</block>
  <block id="d5b16e2c41dd06274f88cd52182d8034" category="paragraph">In molti casi, i gruppi di protezione non consentono l'utilizzo di un account amministratore di Windows su server esterni come Cloud Volumes Service. In alcuni casi, l'utente amministratore di Windows viene disattivato completamente come procedura consigliata per la protezione.</block>
  <block id="e33d961644188dff361a3a61603aee23" category="section-title">Autorizzazioni necessarie per creare account di macchine SMB</block>
  <block id="7274d74c9decfd509d3c2a9c91098fca" category="inline-link">autorizzazioni delegate per creare e modificare oggetti account macchina</block>
  <block id="da90c2a52e7d047f641621a25fcd43c7" category="paragraph">Per aggiungere oggetti computer Cloud Volumes Service a un'Active Directory, un account che dispone di diritti amministrativi per il dominio o che dispone di<block ref="39a1d8c5f0c0a4ae053b3e24111592ed" category="inline-link-rx"></block> A un'unità organizzativa specificata. È possibile eseguire questa operazione con la delega guidata del controllo in Active Directory creando un'attività personalizzata che fornisce all'utente l'accesso alla creazione/eliminazione di oggetti computer con le seguenti autorizzazioni di accesso:</block>
  <block id="db3317ceb65be02e43db6f277e0ad94e" category="list-text">Lettura/scrittura</block>
  <block id="9da76760248a4997f94bdd63f1c04f01" category="list-text">Crea/Elimina tutti gli oggetti figlio</block>
  <block id="858ac25470b9539b8e2bb4d6958fde5b" category="list-text">Lettura/scrittura di tutte le proprietà</block>
  <block id="e798906fb7bcd7b0403d97d21044e339" category="list-text">Modificare/reimpostare la password</block>
  <block id="4eb6bcf48028313e542c0964c09b46b9" category="paragraph">Questa operazione consente di aggiungere automaticamente un ACL di sicurezza per l'utente definito all'unità organizzativa in Active Directory e di ridurre al minimo l'accesso all'ambiente Active Directory. Dopo la delega di un utente, il nome utente e la password possono essere forniti come credenziali Active Directory in questa finestra.</block>
  <block id="66d939bc6b363153976bbd24624850b8" category="admonition">Il nome utente e la password passati al dominio Active Directory sfruttano la crittografia Kerberos durante la query e la creazione dell'oggetto account del computer per una maggiore sicurezza.</block>
  <block id="8575c9ec9ca166098f9d546c3c12e9b1" category="section-title">Dettagli della connessione ad Active Directory</block>
  <block id="452740f6c26f32def386962441d5cb2c" category="inline-link">Dettagli connessione Active Directory</block>
  <block id="af31d4ab1f284e1f94d3522fd1fa36fe" category="paragraph">Il<block ref="9255123c1378b2d08be170075ba389b5" category="inline-link-rx"></block> Fornire agli amministratori campi per fornire informazioni specifiche sullo schema di Active Directory per il posizionamento degli account del computer, ad esempio:</block>
  <block id="353000b4dd170de2ebede38bb7420e40" category="list-text">*Tipo di connessione Active Directory.* consente di specificare se la connessione Active Directory in una regione viene utilizzata per volumi di tipo Cloud Volumes Service o CVS-Performance. Se questa impostazione non è corretta su una connessione esistente, potrebbe non funzionare correttamente quando viene utilizzata o modificata.</block>
  <block id="d5cc4c55027c65e3b8d52c15d308935d" category="list-text">*Domain.* il nome di dominio di Active Directory.</block>
  <block id="c3fab9d188d8e1e4a9e0ba27a52306c6" category="inline-link">considerazioni</block>
  <block id="925e235ec5866cd9c094261d9e20eec4" category="list-text">*Site.* limita i server Active Directory a un sito specifico per motivi di sicurezza e performance<block ref="cae534855afa8eaefaa37d26edea88d5" category="inline-link-rx"></block>. Ciò è necessario quando più server Active Directory si estendono in aree diverse, in quanto Cloud Volumes Service attualmente non supporta l'autorizzazione di richieste di autenticazione Active Directory per i server Active Directory in un'area diversa dall'istanza di Cloud Volumes Service. Ad esempio, il controller di dominio Active Directory si trova in un'area supportata solo da CVS-Performance, ma si desidera una condivisione SMB in un'istanza CVS-SW.</block>
  <block id="bc3a6531a92e21b83c95f7d7044fd498" category="list-text">*Server DNS.* server DNS da utilizzare nelle ricerche dei nomi.</block>
  <block id="44ea07387884d17ba7d18393d327374b" category="inline-link-macro">Come viene visualizzato Cloud Volumes Service in Active Directory</block>
  <block id="32b5af659fee51ef98e34710303d53ba" category="list-text">*Nome NetBIOS (opzionale).* se lo si desidera, il nome NetBIOS del server. Questa opzione viene utilizzata quando vengono creati nuovi account computer utilizzando la connessione Active Directory. Ad esempio, se il nome NetBIOS è impostato su CVS-EAST, i nomi degli account del computer saranno CVS-EAST-{1234}. Vedere la sezione <block ref="0bba591d00c255586e052c023629a690" category="inline-link-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="00a4c212426e322a34af5aeccdc494f7" category="list-text">*Unità organizzativa (OU).* unità organizzativa specifica per la creazione dell'account del computer. Ciò è utile se si sta delegando il controllo a un utente per gli account di computer a una specifica unità organizzativa.</block>
  <block id="06852342816b885474a42d89311e2113" category="list-text">*Crittografia AES.* è inoltre possibile selezionare o deselezionare la casella di controllo Enable AES Encryption for ad Authentication. L'attivazione della crittografia AES per l'autenticazione di Active Directory offre una maggiore sicurezza per le comunicazioni Cloud Volumes Service-Active Directory durante le ricerche di utenti e gruppi. Prima di attivare questa opzione, rivolgersi all'amministratore di dominio per verificare che i controller di dominio Active Directory supportino l'autenticazione AES.</block>
  <block id="7d51d6a8b37a2763f6c84b7b3a3a7e97" category="admonition">Per impostazione predefinita, la maggior parte dei server Windows non disattiva le crittografia più deboli (AD esempio DES o RC4-HMAC), ma se si sceglie di disattivare le crittografia più deboli, verificare che la connessione Active Directory di Cloud Volumes Service sia stata configurata per abilitare AES. In caso contrario, si verificano errori di autenticazione. L'attivazione della crittografia AES non disattiva le crittografie più deboli, ma aggiunge il supporto per le crittografie AES all'account della macchina SMB di Cloud Volumes Service.</block>
  <block id="3da975567fcd6ebd164f43cca13384f2" category="section-title">Dettagli area di autenticazione Kerberos</block>
  <block id="9a62ab6b4d79a99749d02cd8af945f25" category="paragraph">Questa opzione non si applica ai server SMB. Viene invece utilizzato durante la configurazione di NFS Kerberos per il sistema Cloud Volumes Service. Quando questi dettagli vengono popolati, viene configurato l'ambiente Kerberos NFS (simile a un file krb5.conf su Linux) e viene utilizzato quando NFS Kerberos viene specificato nella creazione del volume Cloud Volumes Service, in quanto la connessione Active Directory agisce come centro di distribuzione Kerberos NFS (KDC).</block>
  <block id="e53ab7e80d5d436b4a496f0c2bef7cb2" category="admonition">Attualmente i KDC non Windows non sono supportati per l'utilizzo con Cloud Volumes Service.</block>
  <block id="f447ac856e7e72435904956e3b15f433" category="section-title">Regione</block>
  <block id="38da42463bdc613d24159bd6e0405ba6" category="paragraph">Una regione consente di specificare la posizione in cui risiede la connessione Active Directory. Questa regione deve essere la stessa del volume Cloud Volumes Service.</block>
  <block id="4dfb982db9679a6eec578ccd86af978a" category="list-text">*Local NFS Users with LDAP.* in questa sezione è disponibile anche un'opzione per consentire agli utenti NFS locali con LDAP. Questa opzione deve essere lasciata deselezionata se si desidera estendere il supporto dell'appartenenza al gruppo di utenti UNIX oltre la limitazione di 16 gruppi di NFS (gruppi estesi). Tuttavia, l'utilizzo di gruppi estesi richiede un server LDAP configurato per le identità UNIX. Se non si dispone di un server LDAP, lasciare deselezionata questa opzione. Se si dispone di un server LDAP e si desidera utilizzare anche utenti UNIX locali (ad esempio root), selezionare questa opzione.</block>
  <block id="5059a39455b0e2649d69d289516cdf1b" category="section-title">Utenti di backup</block>
  <block id="0e051a51493712b34966f346e858a0c3" category="inline-link">abilitazione del controllo dell'accesso dell'utente</block>
  <block id="d3980aa1c5f0625161c9b0fb5a6cace0" category="paragraph">Questa opzione consente di specificare gli utenti Windows che dispongono delle autorizzazioni di backup per il volume Cloud Volumes Service. I privilegi di backup (SeBackupPrivilege) sono necessari per consentire ad alcune applicazioni di eseguire correttamente il backup e il ripristino dei dati nei volumi NAS. Questo utente dispone di un elevato livello di accesso ai dati nel volume, pertanto è necessario prendere in considerazione l'opzione<block ref="b5fba80299f6d29935863b6604a98277" category="inline-link-rx"></block>. Una volta attivato, gli eventi di controllo vengono visualizzati nel Visualizzatore eventi &gt; Log di Windows &gt; protezione.</block>
  <block id="70136e0b9257bc91e1eb5216b32580de" category="paragraph"><block ref="70136e0b9257bc91e1eb5216b32580de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6833e65d65b96c0d79b7fc114c9a2968" category="section-title">Utenti con privilegi di sicurezza</block>
  <block id="63a19a4d390181634079ba6ba20fe287" category="inline-link">Ad esempio SQL Server</block>
  <block id="c9a97779c6062109c66675cc5368a6b8" category="inline-link">controllo dell'accesso degli utenti</block>
  <block id="296bdd6f36456d0f48d21431f3bd7853" category="paragraph">Questa opzione consente di specificare gli utenti Windows che dispongono delle autorizzazioni per la modifica della protezione per il volume Cloud Volumes Service. Alcuni privilegi di sicurezza (SeSecurityPrivilege) sono necessari per alcune applicazioni <block ref="cef5278acd430b226f8e7bcad71f9075" category="inline-link-rx"></block>) per impostare correttamente le autorizzazioni durante l'installazione. Questo privilegio è necessario per gestire il registro di protezione. Sebbene questo privilegio non sia potente come SeBackupPrivilege, NetApp consiglia<block ref="2238ada9972b35c5f01addc7598ffd7a" category="inline-link-rx"></block> con questo livello di privilegio, se necessario.</block>
  <block id="f044d72e46ac4189129dc6e27333c449" category="inline-link">Privilegi speciali assegnati al nuovo accesso</block>
  <block id="1384ec27890f8bac59aae8edf1ff83e9" category="paragraph">Per ulteriori informazioni, vedere<block ref="791e82319c9cb432525cbf92f3a07623" category="inline-link-rx"></block>.</block>
  <block id="3fc6256a9aed6803167ff54873f78a00" category="paragraph">Cloud Volumes Service viene visualizzato in Active Directory come un normale oggetto account del computer. Le convenzioni di denominazione sono le seguenti.</block>
  <block id="864917f152404280b59cd43c564f6733" category="list-text">CIFS/SMB e NFS Kerberos creano oggetti account macchina separati.</block>
  <block id="79adcd3b0eb62b997e160c91e737deb2" category="list-text">NFS con LDAP attivato crea un account macchina in Active Directory per i binding LDAP Kerberos.</block>
  <block id="2ed35f8c3fa643ff6b7226a2163085c5" category="list-text">I volumi a doppio protocollo con LDAP condividono l'account CIFS/SMB per LDAP e SMB.</block>
  <block id="3028cc04aacef3f671388051ac5a05cf" category="list-text">Gli account CIFS/SMB utilizzano una convenzione di naming name-1234 (ID casuale a quattro cifre con trattino aggiunto al nome &lt;10 caratteri) per l'account del computer. È possibile definire IL NOME in base all'impostazione NetBIOS name (Nome NetBIOS) sulla connessione Active Directory (vedere la sezione "<block ref="7d2ad38c1c26cdc0446a7f473a720f92" category="inline-xref-macro-rx"></block>").</block>
  <block id="b3330aabe270fd3b52fec421dc299283" category="list-text">NFS Kerberos utilizza NFS-NAME-1234 come convenzione di naming (fino a 15 caratteri). Se vengono utilizzati più di 15 caratteri, il nome è NFS-TRONCED-NAME-1234.</block>
  <block id="50b0fcc303b033d01b24dbb96023de81" category="list-text">Le istanze CVS-Performance solo NFS con LDAP attivato creano un account SMB Machine per l'associazione al server LDAP con la stessa convenzione di denominazione delle istanze CIFS/SMB.</block>
  <block id="d4895b82fd7385bed173b438d89c807e" category="inline-link-macro">"Condivisioni nascoste predefinite"</block>
  <block id="6d7a9f810c1df414bda9e341201f414b" category="list-text">Quando viene creato un account SMB Machine, le condivisioni amministrative nascoste predefinite (vedere la sezione <block ref="15f1050f174b7bbba32ef5b54c17bc40" category="inline-link-macro-rx"></block>), ma tali condivisioni non hanno ACL assegnati e non sono accessibili.</block>
  <block id="e1547130d9a70017a557e263270469eb" category="list-text">Per impostazione predefinita, gli oggetti del centro di costo del computer vengono posizionati in CN=Computers, ma R è possibile specificare un'unità organizzativa diversa quando necessario. Vedere la sezione "<block ref="99b866e46eaefba106810f4a564a9de4" category="inline-xref-macro-rx"></block>" Per informazioni sui diritti di accesso necessari per aggiungere/rimuovere oggetti account macchina per Cloud Volumes Service.</block>
  <block id="5a1324cda45cd652ecb95755709fd8e1" category="paragraph">Quando Cloud Volumes Service aggiunge l'account del computer SMB ad Active Directory, vengono compilati i seguenti campi:</block>
  <block id="650ca2f93573bbd3b4e7f2e4fc5d536e" category="list-text">cn (con il nome del server SMB specificato)</block>
  <block id="493629591f73624fd57b9ff00cb6d94e" category="list-text">DNSHostName (con SMBserver.domain.com)</block>
  <block id="ed877e9b9c0c0bb19ecf1f342cdda00f" category="list-text">MSDS-SupportedEncryptionTypes (supporta DES_CBC_MD5, RC4_HMAC_MD5 se la crittografia AES non è attivata; se la crittografia AES è attivata, DES_CBC_MD5, RC4_HMAC_MD5, AES128_CTS_HMAC_SHA1_96, AES256_CTS_HMAC_SHA1_96 sono consentiti per lo scambio di account con il ticket SMB)</block>
  <block id="987e945fa65d0a9e76f890e3892961cc" category="list-text">Nome (con il nome del server SMB)</block>
  <block id="6c4b390273352496044f436350e3e996" category="list-text">SAMAccountName (con SMBserver)</block>
  <block id="603c37960edbea70b7dd05f369016869" category="list-text">ServicePrincipalName (con host/smbserver.domain.com e host/smbserver SPN per Kerberos)</block>
  <block id="e4d5beb18aee5989e4944d5f91b181e4" category="paragraph">Se si desidera disattivare i tipi di crittografia Kerberos più deboli (enctype) sull'account del computer, è possibile modificare il valore MSDS-SupportedEncryptionTypes sull'account del computer scegliendo uno dei valori nella tabella seguente per consentire solo AES.</block>
  <block id="d7b35b0eb85a800cd27ae4d86378e957" category="cell">Valore MSDS-SupportedEncryptionTypes</block>
  <block id="b20e97401d06f2734903c9c8ce3bd34e" category="cell">Entype attivato</block>
  <block id="3afb17e90ee63072dfd4ad5496e22ecf" category="cell">DES_CBC_MD5</block>
  <block id="427e6bbc6e437e1008a5c41adc923d0e" category="cell">RC4_HMAC</block>
  <block id="16105c1a0d76dfdb5c1df287b56762db" category="cell">SOLO AES128_CTS_HMAC_SHA1_96</block>
  <block id="bdacd7093a31449b44a8d708a5a055de" category="cell">SOLO AES256_CTS_HMAC_SHA1_96</block>
  <block id="ea8f561ef42d9f42f97782208f239797" category="cell">AES128_CTS_HMAC_SHA1_96 E AES256_CTS_HMAC_SHA1_96</block>
  <block id="34173cb38f07f89ddbebc2ac9128303f" category="cell">30</block>
  <block id="bbfe7622403fb2a786b158ba768ac4ca" category="cell">DES_CBC_MD5, RC4_HMAC, AES128_CTS_HMAC_SHA1_96 E AES256_CTS_HMAC_SHA1_96</block>
  <block id="adfa4c5560980c9b2841dda24bda5935" category="paragraph">Per attivare la crittografia AES per gli account dei computer SMB, fare clic su Enable AES Encryption for ad Authentication (attiva crittografia AES per l'autenticazione ad) quando si crea la connessione Active Directory.</block>
  <block id="9e167fdd1e36cc753653d71cef598f95" category="paragraph">Per attivare la crittografia AES per NFS Kerberos,<block ref="a1ea73992eb480d81ba9d6fd0002e272" category="inline-link-rx"></block>.</block>
  <block id="c36c6a3451be9921bddbe958fc50f971" category="inline-link-macro">Segue: Altre dipendenze del servizio infrastruttura NAS (KDC, LDAP, DNS).</block>
  <block id="0a243881b9403f37a34293a498b9dcb8" category="paragraph"><block ref="0a243881b9403f37a34293a498b9dcb8" category="inline-link-macro-rx"></block></block>
  <block id="be0bbf78cc02e3b8c5c134bc7dd71544" category="summary">Tutte le azioni di gestione di Cloud Volumes Service vengono eseguite tramite API. La gestione Cloud Volumes Service integrata nella console cloud GCP utilizza anche l'API Cloud Volumes Service.</block>
  <block id="dd03419f7f2124dca2e83694ae1b7211" category="doc">Architettura del piano di controllo</block>
  <block id="1d2a3e9b2f45b43494c66482366a665a" category="inline-link-macro">Precedente: Architettura Cloud Volumes Service.</block>
  <block id="f73a9343c8393a91c87eda2847dfab85" category="paragraph"><block ref="f73a9343c8393a91c87eda2847dfab85" category="inline-link-macro-rx"></block></block>
  <block id="791716f366839a73d41b8ac1ae95bad0" category="section-title">Gestione di identità e accessi</block>
  <block id="41dff7155cc7aeb11c06434f6a450bb3" category="inline-link">IAM</block>
  <block id="d0455114933a93b857dff40ad9829c80" category="paragraph">Gestione di identità e accessi <block ref="3e7f3b73b3f103986fbe162302b5e57e" category="inline-link-rx"></block>) È un servizio standard che consente di controllare l'autenticazione (accessi) e l'autorizzazione (autorizzazioni) per le istanze di progetto di Google Cloud. Google IAM offre un audit trail completo delle autorizzazioni di autorizzazione e rimozione. Attualmente Cloud Volumes Service non fornisce il controllo del piano di controllo.</block>
  <block id="697308a09680ed006fe009f5a90fd74c" category="section-title">Panoramica delle autorizzazioni</block>
  <block id="cb5b383a5c27210bdf8f2fd443c68ebb" category="inline-link">completa l'elenco delle autorizzazioni granulari qui</block>
  <block id="73867c3747b10f9f7b4b54a4597ff38b" category="paragraph">IAM offre permessi granulari integrati per Cloud Volumes Service. È possibile trovare un<block ref="fefbe49b0be12af5b957eff3a3dc2826" category="inline-link-rx"></block>.</block>
  <block id="f6c6a3fb346fa0197c1eeba05a4736c6" category="paragraph">IAM offre anche due ruoli predefiniti chiamati<block ref="4a5395c87dd91b3242056f83b7cedb9b" prefix=" " category="inline-code"></block> e.<block ref="d8cd72eb52281636a72e12ef877b62f8" prefix=" " category="inline-code"></block>. Questi ruoli possono essere assegnati a specifici utenti o account di servizio.</block>
  <block id="6d90e176a60105dd03d5580c615cc5fe" category="paragraph">Assegnare ruoli e autorizzazioni appropriati per consentire agli utenti IAM di gestire Cloud Volumes Service.</block>
  <block id="010558e705f1d93db66b5a129431b39d" category="paragraph">Di seguito sono riportati alcuni esempi di utilizzo delle autorizzazioni granulari:</block>
  <block id="cf95655b33a1e3a77d897074d8353e7e" category="list-text">Creare un ruolo personalizzato con solo autorizzazioni Get/List/create/Update in modo che gli utenti non possano eliminare i volumi.</block>
  <block id="fdc24340d58c0f0e7d38a4a3f6a7218c" category="list-text">Utilizzare un ruolo personalizzato solo con<block ref="984f6a68d5cd59b0b62580124dedfd98" prefix=" " category="inline-code"></block> Autorizzazioni per creare un account di servizio utilizzato per creare un'integrazione Snapshot coerente con l'applicazione.</block>
  <block id="b1ef9a9445de9905dc5e0ab77e08e183" category="list-text">Creare un ruolo personalizzato da delegare<block ref="49fb6de34b20a50950c47f0a75513736" prefix=" " category="inline-code"></block> a utenti specifici.</block>
  <block id="c33f7c2cbeaca5f1462c1b3e1c276145" category="section-title">Account di servizio</block>
  <block id="303e96f80576360d0c7b07ae7528fa4b" category="inline-link">Terraform</block>
  <block id="b6d8efd38d2a5551a2c43104314740bd" category="paragraph">Per effettuare chiamate API Cloud Volumes Service tramite script o.<block ref="d99d6c9612fe6a2189c372e0abf640d5" category="inline-link-rx"></block>, è necessario creare un account di servizio con<block ref="5e467dce18f46b1803b06097fae60b82" prefix=" " category="inline-code"></block> ruolo. È possibile utilizzare questo account di servizio per generare i token JWT necessari per autenticare le richieste API Cloud Volumes Service in due modi diversi:</block>
  <block id="87cacfdb2dd389d5d00fef712c2f874b" category="list-text">Generare una chiave JSON e utilizzare le API di Google per derivare un token JWT da essa. Questo è l'approccio più semplice, ma implica la gestione manuale dei segreti (la chiave JSON).</block>
  <block id="d77fb2baf15918343921ee724cfacb2f" category="inline-link">Rappresentazione dell'account di servizio</block>
  <block id="9d8270b5a4616fc246d5f96cccc9f61e" category="inline-link">Credenziali predefinite dell'applicazione</block>
  <block id="c1f48ac217f6b993bda4f82835777177" category="list-text">Utilizzare<block ref="09540132e155f93461287a2e21a4e25d" category="inline-link-rx"></block> con<block ref="4d4344aa5ad9d43d63ab2f068115cadb" prefix=" " category="inline-code"></block>. Il codice (script, Terraform e così via). funziona con<block ref="ffba44c35d88772fc8c63157b8dc0cf7" category="inline-link-rx"></block> e rappresenta l'account del servizio per ottenere le autorizzazioni. Questo approccio riflette le Best practice di sicurezza di Google.</block>
  <block id="01aa2fa55c64df5a4122b637c9ababc7" category="inline-link">Creazione dell'account di servizio e della chiave privata</block>
  <block id="00aa2e143f3d3b00e94456b23d239a8d" category="paragraph">Vedere<block ref="5d862676de2107050ea35e71368d2326" category="inline-link-rx"></block> Nella documentazione di Google Cloud per ulteriori informazioni.</block>
  <block id="a325b85a1545e8c507701fb5aa32e6b8" category="section-title">API Cloud Volumes Service</block>
  <block id="d06e940dcf329e87ca49cb2a665f5fd8" category="inline-link">Cloud Volumes API nella documentazione cloud di Google</block>
  <block id="4a0d70491e56eae6b1e0743d9c3a3777" category="paragraph">L'API Cloud Volumes Service utilizza un'API basata SU REST utilizzando HTTPS (TLSv1.2) come trasporto di rete sottostante. È possibile trovare la definizione API più recente<block ref="d30245d84ac801bb5beeb0b65de1621d" category="inline-link-rx"></block> E informazioni su come utilizzare l'API all'indirizzo<block ref="00c944b7c7739b905457d5d21be6a7ef" category="inline-link-rx"></block>.</block>
  <block id="de13c3e3b25af602f2652dd51a503a8a" category="paragraph">L'endpoint API viene gestito e protetto da NetApp utilizzando la funzionalità HTTPS standard (TLSv1.2).</block>
  <block id="8eac7c9151aa7742216ac387e27479a7" category="section-title">Token JWT</block>
  <block id="56ebd33e81a27d6c3c78f2f67f2d3c1a" category="inline-link">RFC-7519</block>
  <block id="f2c16a4802323f9b9c1ac55acf92645f" category="paragraph">L'autenticazione all'API viene eseguita con token bearer JWT <block ref="89a64c0d993ae56a4af8e7ccde6ee59e" category="inline-link-rx"></block>). I token JWT validi devono essere ottenuti utilizzando l'autenticazione IAM di Google Cloud. A tale scopo, è necessario recuperare un token da IAM fornendo una chiave JSON dell'account di servizio.</block>
  <block id="f45362733fe1dd1af3c58ae64471d466" category="section-title">Registrazione dell'audit</block>
  <block id="1ccbd48d467dc56358432c49ba82e95a" category="paragraph">Attualmente, non sono disponibili registri di audit del piano di controllo accessibili dall'utente.</block>
  <block id="f2787c6d19935adb1d88d6c832b68083" category="inline-link-macro">Avanti: Architettura del data plane.</block>
  <block id="9025e4ef245b32ed6f318a902095bafc" category="paragraph"><block ref="9025e4ef245b32ed6f318a902095bafc" category="inline-link-macro-rx"></block></block>
  <block id="3e7c5a939584e1a53201dd8eddfe85d1" category="summary">In modo simile ad altri servizi nativi di Google Cloud come CloudSQL, Google Cloud VMware Engine (GCVE) e FileStore, Cloud Volumes Service utilizza Google PSA per fornire il servizio.</block>
  <block id="16929468b925d0d420441bcbba519e7d" category="doc">Architettura Cloud Volumes Service</block>
  <block id="98cdf6a29cf39ecd5239e5071cb0dc88" category="inline-link">PSA di Google</block>
  <block id="d4d6aaf620a68430d28b38f847f2a6af" category="inline-link">Peering della rete VPC</block>
  <block id="f84137720cfd9533352746a01677a6b2" category="paragraph">In modo simile ad altri servizi nativi di Google Cloud come CloudSQL, Google Cloud VMware Engine (GCVE) e FileStore, Cloud Volumes Service utilizza<block ref="0f93a99b9e468a051182b66dabbf3bed" category="inline-link-rx"></block> per fornire il servizio. In PSA, i servizi sono costruiti all'interno di un progetto di service Producer, che utilizza<block ref="2d8d4488e7ed7b53a7aafab379ba8587" category="inline-link-rx"></block> per connettersi al cliente del servizio. Il produttore del servizio viene fornito e gestito da NetApp e il consumatore del servizio è un VPC in un progetto del cliente, che ospita i client che desiderano accedere alle condivisioni di file Cloud Volumes Service.</block>
  <block id="353164decd5aa0c4f58b4e56559e1b13" category="inline-link">sezione architettura</block>
  <block id="9448d83a67980a22f2db155347fa277c" category="paragraph">La figura seguente, a cui si fa riferimento da<block ref="6a8b5039754626811ee5b8fe5289e273" category="inline-link-rx"></block> Della documentazione di Cloud Volumes Service, mostra una vista di alto livello.</block>
  <block id="8055d5a25a1838f115c8636545abb21a" category="paragraph"><block ref="8055d5a25a1838f115c8636545abb21a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6f34964d3060f5dd66e2cc7c8711679" category="paragraph">La parte sopra la linea tratteggiata mostra il piano di controllo del servizio, che controlla il ciclo di vita del volume. La parte sotto la linea tratteggiata mostra il piano dati. La casella blu a sinistra rappresenta l'utente VPC (consumatore di servizi), la casella blu a destra rappresenta il produttore di servizi fornito da NetApp. Entrambi sono connessi tramite peering VPC.</block>
  <block id="0d127864a05110e3053c2690dea7d914" category="section-title">Modello di tenancy</block>
  <block id="dc947df9f7b14883cbc411bc0a7de469" category="paragraph">In Cloud Volumes Service, i singoli progetti sono considerati locatari unici. Ciò significa che la manipolazione di volumi, copie Snapshot e così via viene eseguita in base al progetto. In altre parole, tutti i volumi sono di proprietà del progetto in cui sono stati creati e solo quel progetto può gestire e accedere ai dati all'interno di essi per impostazione predefinita. Questa è considerata la vista del piano di controllo del servizio.</block>
  <block id="b9ea9f76a11191d80f8fe1abc9437eb6" category="section-title">VPC condivisi</block>
  <block id="cc11b3be8b129e07961938139b138eb5" category="paragraph">Nella vista del piano dati, Cloud Volumes Service può connettersi a un VPC condiviso. È possibile creare volumi nel progetto di hosting o in uno dei progetti di servizio connessi al VPC condiviso. Tutti i progetti (host o servizio) connessi a quel VPC condiviso sono in grado di raggiungere i volumi a livello di rete (TCP/IP). Poiché tutti i client con connettività di rete sul VPC condiviso possono potenzialmente accedere ai dati attraverso protocolli NAS, il controllo dell'accesso sul singolo volume (come gli elenchi di controllo dell'accesso utente/gruppo (ACL) e i nomi host/indirizzi IP per le esportazioni NFS) deve essere utilizzato per controllare chi può accedere ai dati.</block>
  <block id="0b97558649d416ff7a157c6ebb3415d9" category="paragraph">È possibile collegare Cloud Volumes Service a un massimo di cinque VPC per progetto del cliente. Sul piano di controllo, il progetto consente di gestire tutti i volumi creati, indipendentemente dal VPC a cui sono collegati. Sul piano dati, i VPC sono isolati l'uno dall'altro e ciascun volume può essere collegato solo a un VPC.</block>
  <block id="be52fe1bd184b72048acd2ba911bb069" category="paragraph">L'accesso ai singoli volumi è controllato da meccanismi di controllo degli accessi specifici del protocollo (NFS/SMB).</block>
  <block id="a3328901555fee8fe9134fc5bd6e641b" category="paragraph">In altre parole, a livello di rete, tutti i progetti connessi al VPC condiviso sono in grado di vedere il volume, mentre, dal lato di gestione, il piano di controllo consente solo al progetto proprietario di vedere il volume.</block>
  <block id="90f3668b3811dddcb8de24b77c6a6d64" category="section-title">Controlli del servizio VPC</block>
  <block id="d5fc4459a5e756d9c4ad2c88c260092b" category="paragraph">I controlli dei servizi VPC stabiliscono un perimetro di controllo degli accessi intorno ai servizi Google Cloud collegati a Internet e accessibili in tutto il mondo. Questi servizi forniscono il controllo degli accessi attraverso le identità degli utenti, ma non possono limitare le richieste di posizione di rete da cui provengono. I controlli dei servizi VPC colmano questa lacuna introducendo le funzionalità per limitare l'accesso a reti definite.</block>
  <block id="601553f09795c6051748c4f4f63ce893" category="paragraph">Il piano dati Cloud Volumes Service non è connesso a Internet esterno ma a VPC privati con confini di rete ben definiti (perimetri). All'interno di tale rete, ciascun volume utilizza il controllo degli accessi specifico del protocollo. Qualsiasi connettività di rete esterna viene creata esplicitamente dagli amministratori di progetto di Google Cloud. Il piano di controllo, tuttavia, non fornisce le stesse protezioni del piano dati e può essere utilizzato da chiunque disponga di credenziali valide (<block ref="f0e6a8c8639b1f1713f124143221142a" category="inline-link-rx"></block>).</block>
  <block id="7755a392158406ad802334080cd41f73" category="paragraph">In breve, il data plane Cloud Volumes Service offre la funzionalità di controllo dell'accesso alla rete, senza il requisito di supportare i controlli dei servizi VPC e non utilizza esplicitamente i controlli dei servizi VPC.</block>
  <block id="892d60d0a1c71243b5ddff2c66ed584c" category="section-title">Considerazioni su sniffing/trace dei pacchetti</block>
  <block id="93b0389d05d1b6926967749b8692f2f6" category="paragraph">Le acquisizioni di pacchetti possono essere utili per la risoluzione di problemi di rete o di altro tipo (come permessi NAS, connettività LDAP e così via), ma possono anche essere utilizzate in modo malizioso per ottenere informazioni su indirizzi IP di rete, indirizzi MAC, nomi di utenti e gruppi e sul livello di sicurezza utilizzato sugli endpoint. A causa del modo in cui vengono configurate le regole di rete, VPC e firewall di Google Cloud, l'accesso indesiderato ai pacchetti di rete dovrebbe essere difficile da ottenere senza le credenziali di accesso dell'utente o. <block ref="2a18c6d0cd80103144f47d02366a785f" category="inline-link-macro-rx"></block> nelle istanze cloud. Le acquisizioni di pacchetti sono possibili solo sugli endpoint (ad esempio macchine virtuali) e solo sugli endpoint interni al VPC, a meno che non venga utilizzato un VPC condiviso e/o un tunnel di rete esterno/inoltro IP per consentire esplicitamente il traffico esterno agli endpoint. Non esiste alcun modo per eseguire lo sniff del traffico al di fuori dei client.</block>
  <block id="198a269fc15076e5cc8ab572d6711771" category="inline-link-macro">Crittografia SMB</block>
  <block id="ed5f2bdecbd4bd349d09412d1ff6a6fb" category="inline-link-macro">DNS</block>
  <block id="738deb1a3cec2cc7d670e7de69d3a7c6" category="inline-link-macro">Query LDAP</block>
  <block id="a436da0007911ed6531e093688e82535" category="paragraph">Quando si utilizzano VPC condivisi, la crittografia in-flight con NFS Kerberos e/o <block ref="639817e82862065dd236f0597e0b07ea" category="inline-link-macro-rx"></block> può mascherare gran parte delle informazioni raccolte dalle tracce. Tuttavia, parte del traffico viene ancora inviato in formato non crittografato, ad esempio <block ref="c2e2f225386e22bd13a8b4b174f478da" category="inline-link-macro-rx"></block> e. <block ref="86c1c13023c15e9d9a6317a0b69e7ce3" category="inline-link-macro-rx"></block>. La figura seguente mostra un'acquisizione di pacchetti da una query LDAP non crittografata proveniente da Cloud Volumes Service e le potenziali informazioni di identificazione esposte. Le query LDAP in Cloud Volumes Service attualmente non supportano la crittografia o LDAP su SSL. CVS-Performance supporta la firma LDAP, se richiesto da Active Directory. CVS-SW non supporta la firma LDAP.</block>
  <block id="ce58b63a24bebe6bac29cfe248428477" category="paragraph"><block ref="ce58b63a24bebe6bac29cfe248428477" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c72e76f5c978aa82e296df17081b6836" category="admonition">UnixUserPassword viene interrogata da LDAP e non viene inviata in testo non crittografato, ma in un hash con salatura. Per impostazione predefinita, Windows LDAP non compila i campi unixUserPassword. Questo campo è necessario solo se è necessario sfruttare Windows LDAP per gli accessi interattivi tramite LDAP ai client. Cloud Volumes Service non supporta gli accessi LDAP interattivi alle istanze.</block>
  <block id="01b21a51d124432b5b7fe641eae6a004" category="paragraph">La figura seguente mostra un'acquisizione di pacchetti da una conversazione Kerberos NFS accanto a un'acquisizione di NFS su AUTH_SYS. Si noti come le informazioni disponibili in una traccia siano diverse tra le due e come l'abilitazione della crittografia in-flight offra una maggiore sicurezza generale per il traffico NAS.</block>
  <block id="0d66010f122b3df766abd8a0cb2ff598" category="paragraph"><block ref="0d66010f122b3df766abd8a0cb2ff598" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5ba81028f56cfd4f5e21c7102a8eff68" category="paragraph"><block ref="5ba81028f56cfd4f5e21c7102a8eff68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04aa3ce627dbf5b220c8aa6d4955fb34" category="section-title">Interfacce di rete delle macchine virtuali</block>
  <block id="8ec45d68b7d371d25a3b82a76db3142b" category="inline-link">modalità promiscua</block>
  <block id="e59b81e20588b0d3a3c495a545d75322" category="paragraph">Un trucco che gli autori degli attacchi potrebbero tentare di aggiungere una nuova scheda di interfaccia di rete (NIC) a una macchina virtuale in<block ref="39c80826df1f145e2784d4b04af9d477" category="inline-link-rx"></block> (Mirroring delle porte) o attivare la modalità promiscua su una scheda di rete esistente per eseguire lo sniff di tutto il traffico. In Google Cloud, l'aggiunta di una nuova NIC richiede l'arresto completo di una macchina virtuale, che crea avvisi, in modo che gli hacker non possano farlo inosservato.</block>
  <block id="b726bce4fa04e9b7a6d788f212f00c17" category="paragraph">Inoltre, le NIC non possono essere impostate sulla modalità promiscua e attiveranno avvisi in Google Cloud.</block>
  <block id="5be5e913f29871f00d216882fc58f26a" category="inline-link-macro">Avanti: Architettura del piano di controllo.</block>
  <block id="f9f0b661819d64fded86dba6dee4dd6b" category="paragraph"><block ref="f9f0b661819d64fded86dba6dee4dd6b" category="inline-link-macro-rx"></block></block>
  <block id="6ab0778deb23383f6063990e47d38567" category="summary">Tutti i volumi in Cloud Volumes Service sono crittografati a riposo utilizzando la crittografia AES-256, il che significa che tutti i dati utente scritti sui supporti sono crittografati e possono essere decifrati solo con una chiave per volume.</block>
  <block id="05a42723f4aebc1b8fea32f0da56f531" category="doc">Crittografia dei dati a riposo</block>
  <block id="914e9cc2016ed2891bc115163b671205" category="inline-link-macro">Precedente: Crittografia dei dati in transito.</block>
  <block id="3ab72ed338391088a345040cc4ede7e0" category="paragraph"><block ref="3ab72ed338391088a345040cc4ede7e0" category="inline-link-macro-rx"></block></block>
  <block id="4a41d68019f2643468ef37e122fc87a9" category="list-text">Per CVS-SW, vengono utilizzate chiavi generate da Google.</block>
  <block id="68056df8fa340722ff859d534da347e4" category="list-text">Per CVS-Performance, i tasti per volume sono memorizzati in un gestore di chiavi integrato in Cloud Volumes Service.</block>
  <block id="e23c4fadd8e7d70663bc3393bca7d576" category="inline-link">Google Key Management Service (KMS).</block>
  <block id="387ccb6d293c8d2f51b2730c375c3f3a" category="paragraph">A partire da novembre 2021, è stata resa disponibile l'anteprima delle chiavi di crittografia gestite dal cliente (CMEK). In questo modo è possibile crittografare le chiavi per volume con una chiave master per progetto, per regione, ospitata in<block ref="145d140dc09dde7f8aacc53f1269c2de" category="inline-link-rx"></block> KMS consente di collegare i key manager esterni.</block>
  <block id="1988a6b2308f38718c8100c2e344eb5c" category="inline-link">Impostazione delle chiavi di crittografia gestite dal cliente</block>
  <block id="811bec2d7b00d479640fbf3259346fe6" category="paragraph">Per informazioni sulla configurazione di KMS per CVS-Performance, vedere<block ref="a0d8b07d63b271255da3bba6f51651a4" category="inline-link-rx"></block>.</block>
  <block id="6a2064a5b36d77d1da28e1bb96fe613e" category="inline-link-macro">Avanti: Firewall.</block>
  <block id="d78ea12f26e93e819db4dd4772e8cb6e" category="paragraph"><block ref="d78ea12f26e93e819db4dd4772e8cb6e" category="inline-link-macro-rx"></block></block>
  <block id="5e64a4b25a4f107aefb7d4e2a56b9dfb" category="summary">Quando si utilizza Cloud Volumes Service per le condivisioni NAS, potrebbero essere necessarie dipendenze esterne per un corretto funzionamento. Queste dipendenze sono in gioco in circostanze specifiche.</block>
  <block id="f4b5e0cbc9d84ca994a4dc85d6f45205" category="doc">Altre dipendenze del servizio infrastruttura NAS (KDC, LDAP e DNS)</block>
  <block id="619169033066c83ff7d1cc580d748cd6" category="inline-link-macro">Precedente: Considerazioni per la creazione di connessioni Active Directory.</block>
  <block id="a67d66e488b843722a2bb6124e92d2c0" category="paragraph"><block ref="a67d66e488b843722a2bb6124e92d2c0" category="inline-link-macro-rx"></block></block>
  <block id="c4c97073fa9e6d604787db13592331a3" category="paragraph">Quando si utilizza Cloud Volumes Service per le condivisioni NAS, potrebbero essere necessarie dipendenze esterne per un corretto funzionamento. Queste dipendenze sono in gioco in circostanze specifiche. La seguente tabella mostra le varie opzioni di configurazione e le eventuali dipendenze richieste.</block>
  <block id="c9b3a27f085427ada9b946daa430f1f8" category="cell">Dipendenze richieste</block>
  <block id="954898296a4e7ec7e15ab65964b50da0" category="cell">Solo NFSv3</block>
  <block id="e69d896f8231ad7dd96dd4937ba18d07" category="cell">Solo NFSv3 Kerberos</block>
  <block id="6040c1d5c15727690384a7cd3e8d3fa4" category="cell">Active Directory di Windows: * KDC * DNS * LDAP</block>
  <block id="b88d0e1e32f67294d9d45e05a25495e7" category="cell">Solo NFSv4.1</block>
  <block id="1cc44815edb1648976dd6fa410f26802" category="cell">Configurazione mappatura ID client (/etc/idmap.conf)</block>
  <block id="c2e2e93edfc9ea6acddd551b71be27bf" category="cell">Solo NFSv4.1 Kerberos</block>
  <block id="411c501ecf4d59f4ef8d7e9c444b838a" category="list-text">Active Directory di Windows: LDAP DNS KDC</block>
  <block id="59b6dd4c5b36405b29c64750f1e82401" category="cell">Solo SMB</block>
  <block id="11a431c64d07fefe0bbb5880e03069c5" category="cell">Active Directory: * KDC * DNS</block>
  <block id="420da7f0cb45485c925482687369c1ad" category="cell">NAS multiprotocollo (NFS e SMB)</block>
  <block id="b756e6f6a894749273e32e03e551180c" category="list-text">Configurazione del mapping dell'ID client (solo NFSv4.1; /etc/idmap.conf)</block>
  <block id="8777a112bd8b1e9205dda0717a12965b" category="section-title">La rotazione/password del keytab Kerberos viene reimpostata per gli oggetti account macchina</block>
  <block id="b8333cf0e11040ea157a74560b3a6d77" category="paragraph">Con gli account delle macchine SMB, Cloud Volumes Service pianifica il ripristino periodico delle password per l'account delle macchine SMB. Queste password vengono reimpostate utilizzando la crittografia Kerberos e vengono eseguite ogni quarta domenica in un orario casuale compreso tra LE 23:00 e L'1:00. Queste reimpostazioni delle password modificano le versioni delle chiavi Kerberos, ruotano le linguette memorizzate nel sistema Cloud Volumes Service e contribuiscono a mantenere un livello di sicurezza maggiore per i server SMB in esecuzione in Cloud Volumes Service. Le password dell'account macchina sono casuali e non sono note agli amministratori.</block>
  <block id="6df7123d2b1a64b11c7df1c2b837f752" category="paragraph">Per gli account delle macchine Kerberos NFS, la reimpostazione delle password avviene solo quando viene creata o scambiata una nuova keytab con il KDC. Attualmente, non è possibile eseguire questa operazione in Cloud Volumes Service.</block>
  <block id="7631991924ea0015e269781ad88bd8d3" category="section-title">Porte di rete per l'utilizzo con LDAP e Kerberos</block>
  <block id="52d1b9583b81da6bee6ba24d74c4018b" category="inline-link">Documentazione Cloud Volumes Service sulle considerazioni relative alla sicurezza</block>
  <block id="1e21a0f8a8012a10d3db8d473ba52502" category="paragraph">Quando si utilizzano LDAP e Kerberos, è necessario determinare le porte di rete utilizzate da questi servizi. L'elenco completo delle porte utilizzate da Cloud Volumes Service è disponibile nella<block ref="0dc8f2243f86f97f7b6af9378a496f93" category="inline-link-rx"></block>.</block>
  <block id="2363dee608bcd9f6ce7f980bfdad5789" category="section-title">LDAP</block>
  <block id="d0a2de9b178b436803f7732ff69d0c14" category="paragraph">Cloud Volumes Service agisce come client LDAP e utilizza le query di ricerca LDAP standard per le ricerche di utenti e gruppi per le identità UNIX. LDAP è necessario se si intende utilizzare utenti e gruppi al di fuori degli utenti predefiniti standard forniti da Cloud Volumes Service. LDAP è necessario anche se si prevede di utilizzare NFS Kerberos con le identità dell'utente (ad esempio user1@domain.com). Attualmente, è supportato solo LDAP con Microsoft Active Directory.</block>
  <block id="2eaa173e56517db74fb0eb92806a0877" category="inline-link">RFC-2307-bis</block>
  <block id="50af1bf8bee07c6cb1c61e9c19599403" category="paragraph">Per utilizzare Active Directory come server LDAP UNIX, è necessario popolare gli attributi UNIX necessari per gli utenti e i gruppi che si intende utilizzare per le identità UNIX. Cloud Volumes Service utilizza un modello di schema LDAP predefinito che esegue query sugli attributi in base a.<block ref="54011f528a38d24d58a7f02f98da0d00" category="inline-link-rx"></block>. Di conseguenza, la seguente tabella mostra gli attributi minimi necessari di Active Directory da popolare per utenti e gruppi e per quale scopo viene utilizzato ciascun attributo.</block>
  <block id="a6e75b8341b03d08fb1d6817635b1d47" category="inline-link">Gestione dell'accesso a doppio protocollo.</block>
  <block id="c0f3d72f07b570cdf3f5d1376c72a389" category="paragraph">Per ulteriori informazioni sull'impostazione degli attributi LDAP in Active Directory, vedere<block ref="c2741a8ac44d0c827e11ee9004dcd081" category="inline-link-rx"></block></block>
  <block id="f2bbdf9f72c085adc4d0404e370f0f4c" category="cell">Attributo</block>
  <block id="e266bea072e01571abba7fc5075c2c86" category="cell">uid*</block>
  <block id="0689aaddc7bfae9cad3778f6d706bd7a" category="cell">Specifica il nome utente UNIX</block>
  <block id="525f84e25602ba8efb61d7b8ca793b7c" category="cell">UidNumber*</block>
  <block id="604edb3bb733537b2d6c63b0b84fa1ec" category="cell">Specifica l'ID numerico dell'utente UNIX</block>
  <block id="825c2f924ee564de1d57d2b63edd800d" category="cell">GidNumber*</block>
  <block id="eb91949970817d632278971bdf06baef" category="cell">Specifica l'ID numerico del gruppo primario dell'utente UNIX</block>
  <block id="18b5aa92067bde95c39c3039f02bf70e" category="cell">Objectclass*</block>
  <block id="ce41297dde1628c606d60ef2bbe154cd" category="cell">Specifica il tipo di oggetto utilizzato; Cloud Volumes Service richiede che l'opzione "user" sia inclusa nell'elenco delle classi di oggetti (per impostazione predefinita, è inclusa nella maggior parte delle implementazioni di Active Directory).</block>
  <block id="db108aa570113ecd6745a2e272d68544" category="cell">Informazioni generali sull'account (nome reale, numero di telefono e così via, anche noto come gecos)</block>
  <block id="17a12df2f12fa6f25328eb6c9fcffedf" category="cell">UnixUserPassword</block>
  <block id="4306442303f7519026403fc1912e8e2e" category="cell">Non è necessario impostare questo valore; non utilizzato nelle ricerche di identità UNIX per l'autenticazione NAS. Impostando questa opzione, il valore unixUserPassword configurato viene visualizzato in testo non crittografato.</block>
  <block id="d146b96a250f5bcf84b56d2a0f8a2f87" category="cell">UnixHomeDirectory</block>
  <block id="1208d15552f3ca8721989c162201e0de" category="cell">Definisce il percorso delle home directory UNIX quando un utente esegue l'autenticazione LDAP da un client Linux. Impostare questa opzione se si desidera utilizzare la funzionalità della home directory LDAP per UNIX.</block>
  <block id="0693ba16c955b74875d26f79148b66f0" category="cell">LoginShell</block>
  <block id="61940c4af8b62a3bb77f4ab0eb491c08" category="cell">Definisce il percorso della shell bash/profile per i client Linux quando un utente esegue l'autenticazione con LDAP.</block>
  <block id="9ed4554644da662e0634bf83a7e18666" category="paragraph">*Indica che l'attributo è necessario per la corretta funzionalità con Cloud Volumes Service. Gli attributi rimanenti sono solo per uso lato client.</block>
  <block id="ac975e575ff07bee5423d326c261e07e" category="cell">cn*</block>
  <block id="b982e168cd50ef73d1f3ce851cb4ddac" category="cell">Specifica il nome del gruppo UNIX. Quando si utilizza Active Directory per LDAP, questo viene impostato quando l'oggetto viene creato per la prima volta, ma può essere modificato in seguito. Questo nome non può essere uguale ad altri oggetti. Ad esempio, se l'utente UNIX denominato user1 appartiene a un gruppo denominato user1 sul client Linux, Windows non consente due oggetti con lo stesso attributo cn. Per risolvere questo problema, rinominare l'utente Windows con un nome univoco (ad esempio, user1-UNIX); LDAP in Cloud Volumes Service utilizza l'attributo uid per i nomi utente UNIX.</block>
  <block id="dc1d913bf6d70def379cf9f0d70abace" category="cell">Specifica l'ID numerico del gruppo UNIX.</block>
  <block id="1afbf0b9465b3d5c13329cd43dda4e9e" category="cell">Specifica il tipo di oggetto utilizzato; Cloud Volumes Service richiede che il gruppo sia incluso nell'elenco delle classi di oggetti (questo attributo è incluso per impostazione predefinita nella maggior parte delle implementazioni di Active Directory).</block>
  <block id="5e4db984d78b91a65e9096eebf726d40" category="cell">MemberUid</block>
  <block id="6cd5795a9ccf8fa0d1da852e88da95cd" category="cell">Specifica quali utenti UNIX sono membri del gruppo UNIX. Con Active Directory LDAP in Cloud Volumes Service, questo campo non è necessario. Lo schema LDAP di Cloud Volumes Service utilizza il campo membro per le appartenenze ai gruppi.</block>
  <block id="cadd4e3eefdff4ed3ad7de830179c314" category="cell">Membro*</block>
  <block id="defbfcaae1980c16f810c5ddaa1ecb87" category="cell">Richiesto per le appartenenze a gruppi/gruppi UNIX secondari. Questo campo viene compilato aggiungendo utenti Windows ai gruppi Windows. Tuttavia, se i gruppi Windows non hanno attributi UNIX popolati, non vengono inclusi negli elenchi di appartenenza del gruppo dell'utente UNIX. Tutti i gruppi che devono essere disponibili in NFS devono compilare gli attributi del gruppo UNIX richiesti elencati in questa tabella.</block>
  <block id="14476f6ea303cd9ac37328cb484a1fa1" category="section-title">Informazioni di binding LDAP</block>
  <block id="af0c1d97230a1daa0f7341dc35f53a29" category="paragraph">Per eseguire query agli utenti in LDAP, Cloud Volumes Service deve essere associato (login) al servizio LDAP. Questo accesso dispone di permessi di sola lettura e viene utilizzato per eseguire query sugli attributi LDAP UNIX per le ricerche di directory. Attualmente, i binding LDAP sono possibili solo utilizzando un account di macchina SMB.</block>
  <block id="4a9b831487cab83d7de4d5a515e0eadd" category="paragraph">È possibile attivare LDAP solo per<block ref="439d7969e09b4b31626fcf209b8fdcb7" prefix=" " category="inline-code"></block> E utilizzarlo per volumi NFSv3, NFSv4.1 o a doppio protocollo. È necessario stabilire una connessione Active Directory nella stessa regione del volume Cloud Volumes Service per una corretta implementazione del volume abilitato LDAP.</block>
  <block id="c41605f9de6fa81e35ab98dd9e8b1b02" category="paragraph">Quando LDAP è attivato, in scenari specifici si verifica quanto segue.</block>
  <block id="f9f5dcaa4945ab96d402d905be4ed78c" category="list-text">Se per il progetto Cloud Volumes Service viene utilizzato solo NFSv3 o NFSv4.1, viene creato un nuovo account computer nel controller di dominio Active Directory e il client LDAP in Cloud Volumes Service esegue l'associazione ad Active Directory utilizzando le credenziali dell'account del computer. Non vengono create condivisioni SMB per il volume NFS e le condivisioni amministrative nascoste predefinite (vedere la sezione <block ref="15f1050f174b7bbba32ef5b54c17bc40" category="inline-link-macro-rx"></block>) Hanno rimosso gli ACL di condivisione.</block>
  <block id="f3dad67ce399cefb4b495c573d3ddcb8" category="list-text">Se per il progetto Cloud Volumes Service vengono utilizzati volumi a doppio protocollo, viene utilizzato solo l'account singolo del computer creato per l'accesso SMB per associare il client LDAP in Cloud Volumes Service ad Active Directory. Non vengono creati account macchina aggiuntivi.</block>
  <block id="7168c010de7dd97d077c0e69f48cfbb5" category="list-text">Se i volumi SMB dedicati vengono creati separatamente (prima o dopo l'attivazione dei volumi NFS con LDAP), l'account del computer per i binding LDAP viene condiviso con l'account del computer SMB.</block>
  <block id="248e702975c1b53305536e1e9c698e19" category="list-text">Se è attivato anche NFS Kerberos, vengono creati due account macchina: Uno per le condivisioni SMB e/o le binding LDAP e uno per l'autenticazione Kerberos NFS.</block>
  <block id="a204dba492103f34b09fe60e7ab98921" category="paragraph">Anche se i binding LDAP sono crittografati, le query LDAP vengono trasmesse via cavo in testo non crittografato utilizzando la porta LDAP comune 389. Questa porta nota non può essere modificata in Cloud Volumes Service. Di conseguenza, un utente con accesso allo sniffing dei pacchetti nella rete può visualizzare i nomi degli utenti e dei gruppi, gli ID numerici e le appartenenze ai gruppi.</block>
  <block id="d10f3c8108e06d8e622b7a6fb88adb08" category="inline-link-macro">"Considerazioni su sniffing/traccia dei pacchetti".</block>
  <block id="b046f19aab64225d509f228ccd32fb2c" category="paragraph">Tuttavia, le macchine virtuali Google Cloud non possono sniff il traffico unicast di altre macchine virtuali. Solo le macchine virtuali che partecipano attivamente al traffico LDAP (ovvero, sono in grado di eseguire il binding) possono visualizzare il traffico proveniente dal server LDAP. Per ulteriori informazioni sullo sniffing dei pacchetti in Cloud Volumes Service, consulta la sezione <block ref="e06a781bd551a4c8ed55a5dfd008a50c" category="inline-link-macro-rx"></block></block>
  <block id="d815e456141423f092087c21cd312f23" category="section-title">Impostazioni predefinite della configurazione del client LDAP</block>
  <block id="1c1b57ee3fb14f95067e88e579a44eec" category="paragraph">Quando LDAP è attivato in un'istanza di Cloud Volumes Service, per impostazione predefinita viene creata una configurazione del client LDAP con dettagli di configurazione specifici. In alcuni casi, le opzioni non sono valide per Cloud Volumes Service (non supportate) o non sono configurabili.</block>
  <block id="cc2eacdb2cc579f99a0f4359e61ed258" category="cell">Opzione del client LDAP</block>
  <block id="ffe990396bf99448f8fe6e6fa1c3c3ea" category="cell">Elenco server LDAP</block>
  <block id="0b22102603051537f2c4bfccc964b74e" category="cell">Consente di impostare i nomi dei server LDAP o gli indirizzi IP da utilizzare per le query. Non utilizzato per Cloud Volumes Service. Viene invece utilizzato Active Directory Domain per definire i server LDAP.</block>
  <block id="9ba66a9f92056682b7d86a38b4bc18c0" category="cell">Non impostato</block>
  <block id="f490d3302e7cd81f3dafead6c8311b60" category="cell">Dominio Active Directory</block>
  <block id="63dfe9dc44b2881b25560d6d5bd5dff6" category="cell">Imposta il dominio Active Directory da utilizzare per le query LDAP. Cloud Volumes Service sfrutta i record SRV per LDAP nel DNS per trovare i server LDAP nel dominio.</block>
  <block id="6575821e7d2ff9eec297128f6e66933a" category="cell">Impostare sul dominio Active Directory specificato nella connessione Active Directory.</block>
  <block id="00227bc990a551282373139d6439feb4" category="cell">Server Active Directory preferiti</block>
  <block id="01d685ed68515214956910d3e26f1c71" category="cell">Imposta i server Active Directory preferiti da utilizzare per LDAP. Non supportato da Cloud Volumes Service. Utilizzare i siti Active Directory per controllare la selezione del server LDAP.</block>
  <block id="f41520c4ef898fb19bb93ee749be3fdd" category="cell">Non impostato.</block>
  <block id="b626ddcd91311f0f7c4622fdcb7ba05e" category="cell">Eseguire il binding utilizzando le credenziali del server SMB</block>
  <block id="cb97b8ae4a5bb23e8ffa9e1547fe5078" category="cell">Esegue il binding a LDAP utilizzando l'account SMB Machine. Attualmente, l'unico metodo di binding LDAP supportato in Cloud Volumes Service.</block>
  <block id="d95e3278cf3c7f4cd1d7e40c5a89e7a7" category="cell">Modello di schema</block>
  <block id="33387315b367e8397cc901a4bf37ad44" category="cell">Modello di schema utilizzato per le query LDAP.</block>
  <block id="16165a1c7229a30ce1a980b0e648d65f" category="cell">MS-AD-BIS</block>
  <block id="b825dd7cf8df99909db6f3117c567721" category="cell">Porta del server LDAP</block>
  <block id="731fba188f3670e36bac64d2ca64db37" category="cell">Il numero di porta utilizzato per le query LDAP. Attualmente Cloud Volumes Service utilizza solo la porta LDAP standard 389. LDAPS/porta 636 non è attualmente supportato.</block>
  <block id="c86a7ee3d8ef0b551ed58e354a836f2b" category="cell">389</block>
  <block id="9a76dbbba394b04594907973bb6c192e" category="cell">LDAPS è attivato</block>
  <block id="98c3437e89f8128c7359f6b999731fcc" category="cell">Controlla se LDAP su SSL (Secure Sockets Layer) viene utilizzato per query e binding. Attualmente non supportato da Cloud Volumes Service.</block>
  <block id="3452a15eecd4e9b3215025c747cfce4e" category="cell">Timeout query (sec)</block>
  <block id="4fbc7a2f8fb9f56de093d04afac67fa3" category="cell">Timeout per query. Se le query richiedono più tempo del valore specificato, le query non vengono eseguite correttamente.</block>
  <block id="4211f908e9b523117776324e2349a87c" category="cell">Livello minimo di autenticazione bind</block>
  <block id="cf6cfd37577ec3f1cc20caa7fb10bd45" category="cell">Il livello minimo di binding supportato. Poiché Cloud Volumes Service utilizza account di computer per i binding LDAP e Active Directory non supporta i binding anonimi per impostazione predefinita, questa opzione non viene utilizzata per motivi di sicurezza.</block>
  <block id="7079c72c21415131774625ba1d64f4b0" category="cell">Anonimo</block>
  <block id="58384d924f3205aaac5f4a09d3b33801" category="cell">DN di binding</block>
  <block id="4d73cec492ef07eaddad38a4a553639d" category="cell">Nome utente/distinto (DN) utilizzato per i binding quando viene utilizzato il binding semplice. Cloud Volumes Service utilizza account computer per i binding LDAP e attualmente non supporta l'autenticazione di binding semplice.</block>
  <block id="6c22befafec962f5002017b68e639f92" category="cell">DN di base</block>
  <block id="413689794b4599826344869870d6e0a7" category="cell">Il DN di base utilizzato per le ricerche LDAP.</block>
  <block id="796658213567ec39e68bd43e48ac6eff" category="cell">Il dominio Windows utilizzato per la connessione Active Directory, in formato DN (DC=dominio, DC=locale).</block>
  <block id="30e8b85f236e0c0e7b13a8a98bd46d6f" category="cell">Ambito di ricerca di base</block>
  <block id="26cbec2c997dd79e69cd5279817c5506" category="cell">Ambito di ricerca per le ricerche DN di base. I valori possono includere base, onelevel o sottostruttura. Cloud Volumes Service supporta solo le ricerche in sottostruttura.</block>
  <block id="187c471e7dfcb7890077311c532fffd0" category="cell">Sottostruttura</block>
  <block id="de20d00fd9f0840e6c05dce6aca169e4" category="cell">DN utente</block>
  <block id="4ddd431d35193d0d6dc9555aeecf86e1" category="cell">Definisce il DN in cui l'utente avvia le ricerche per le query LDAP. Attualmente non supportato per Cloud Volumes Service, pertanto tutte le ricerche degli utenti iniziano dal DN di base.</block>
  <block id="389048eda41eb7c0e810c83269814943" category="cell">Ambito della ricerca dell'utente</block>
  <block id="0c5e0f35296916ccacc860481c53c663" category="cell">L'ambito di ricerca per le ricerche DN dell'utente. I valori possono includere base, onelevel o sottostruttura. Cloud Volumes Service non supporta l'impostazione dell'ambito di ricerca dell'utente.</block>
  <block id="68a7f97c57468e034a3f8016831c3c54" category="cell">DN gruppo</block>
  <block id="5874ce023df38d8485da62d095f714f5" category="cell">Definisce il DN in cui iniziano le ricerche di gruppo per le query LDAP. Attualmente non supportato per Cloud Volumes Service, quindi tutte le ricerche di gruppo iniziano dal DN di base.</block>
  <block id="c76b264e7f1c2aadf6b61ca4a7b9dc52" category="cell">Ambito della ricerca di gruppo</block>
  <block id="2d21b088cabd39a7f25a62fc99148f20" category="cell">Ambito di ricerca per le ricerche DN di gruppo. I valori possono includere base, onelevel o sottostruttura. Cloud Volumes Service non supporta l'impostazione dell'ambito di ricerca di gruppo.</block>
  <block id="9819b4f0996b3e603488836501e3318e" category="cell">DN netgroup</block>
  <block id="b5e1f3448b6d3c978f83c2d3d12a2d1e" category="cell">Definisce il DN in cui inizia la ricerca delle query LDAP da parte del netgroup. Attualmente non supportato per Cloud Volumes Service, pertanto tutte le ricerche dei netgroup iniziano dal DN di base.</block>
  <block id="de25b155c30a2cba210598b604a5b8c8" category="cell">Ambito della ricerca nel netgroup</block>
  <block id="334dde86dbe71e59b3c942c6a2384d70" category="cell">Ambito di ricerca per le ricerche DN dei netgroup. I valori possono includere base, onelevel o sottostruttura. Cloud Volumes Service non supporta l'impostazione dell'ambito di ricerca del netgroup.</block>
  <block id="e2bdddbf27283c0eca38d39759107a44" category="cell">USA start_tls su LDAP</block>
  <block id="24788f1c660aa47d895fa832d61d2fcf" category="cell">Sfrutta Start TLS per connessioni LDAP basate su certificato sulla porta 389. Attualmente non supportato da Cloud Volumes Service.</block>
  <block id="cb64fc71803a6196ec2185116e525243" category="cell">Attiva la ricerca netgroup-by-host</block>
  <block id="d92aed09a16438d9bc4cf2735e54815f" category="cell">Attiva le ricerche di netgroup in base al nome host piuttosto che espandere i netgroup per elencare tutti i membri. Attualmente non supportato da Cloud Volumes Service.</block>
  <block id="ae1e3e9f0f050830d9ad4ff1441a4080" category="cell">DN netgroup-by-host</block>
  <block id="6dc9eeb7bc11f937a1c509e27237db6f" category="cell">Definisce il DN in cui iniziano le ricerche netgroup-by-host per le query LDAP. Netgroup-by-host attualmente non è supportato per Cloud Volumes Service.</block>
  <block id="0b5200ff3b38841dd95a404d7e6ff385" category="cell">Ambito di ricerca netgroup-by-host</block>
  <block id="4ce621e884478e7fc52e17ed91eed525" category="cell">Ambito di ricerca per le ricerche DN netgroup-by-host. I valori possono includere base, onelevel o sottostruttura. Netgroup-by-host attualmente non è supportato per Cloud Volumes Service.</block>
  <block id="19a0fc26f19842a9f7bc78040d0c381c" category="cell">Sicurezza della sessione client</block>
  <block id="b95b607ac94c4a8cb830243ecb537f59" category="cell">Definisce il livello di sicurezza della sessione utilizzato da LDAP (Sign, Seal o NONE). La firma LDAP è supportata da CVS-Performance, se richiesto da Active Directory. CVS-SW non supporta la firma LDAP. Per entrambi i tipi di servizio, il sealing non è attualmente supportato.</block>
  <block id="16ed23b379774b2be1797f8efa0fe9a5" category="cell">Ricerca di riferimenti LDAP</block>
  <block id="5f362229a019eb903f4b21e28b15a1f5" category="cell">Filtro di appartenenza al gruppo</block>
  <block id="55ad576cc6cd581d8a2f558d69828312" category="cell">Fornisce un filtro di ricerca LDAP personalizzato da utilizzare quando si cerca l'appartenenza a un gruppo da un server LDAP. Attualmente non supportato con Cloud Volumes Service.</block>
  <block id="b735835c02ee9b8eba41846beea27bc6" category="section-title">Utilizzo di LDAP per la mappatura asimmetrica dei nomi</block>
  <block id="10d248b3ae3729560e0f9f75ff23f70e" category="paragraph">Cloud Volumes Service, per impostazione predefinita, esegue il mapping bidirezionale degli utenti Windows e UNIX con nomi utente identici senza alcuna configurazione speciale. Finché Cloud Volumes Service trova un utente UNIX valido (con LDAP), viene eseguita la mappatura del nome 1:1. Ad esempio, se utente Windows<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> Viene utilizzato, quindi, se Cloud Volumes Service riesce a trovare un utente UNIX denominato<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> In LDAP, la mappatura dei nomi riesce per quell'utente, tutti i file/cartelle creati da<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> Mostrare la corretta proprietà dell'utente e tutti gli ACL che influiscono<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> Sono onorati indipendentemente dal protocollo NAS in uso. Questa funzione è nota come mappatura dei nomi simmetrica.</block>
  <block id="a4e6c429f8e2b5bc009025d9469cd6bd" category="paragraph">Il mapping asimmetrico dei nomi si verifica quando l'identità dell'utente Windows e UNIX non corrispondono. Ad esempio, se utente Windows<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> Ha un'identità UNIX di<block ref="39ce7e2a8573b41ce73b5ba41617f8f7" prefix=" " category="inline-code"></block>, Cloud Volumes Service ha bisogno di un modo per essere raccontata della variazione. Poiché Cloud Volumes Service attualmente non supporta la creazione di regole di mappatura dei nomi statiche, è necessario utilizzare LDAP per cercare l'identità degli utenti per le identità Windows e UNIX, al fine di garantire la corretta proprietà di file e cartelle e le autorizzazioni previste.</block>
  <block id="159e0e9db457fce00641b7a639cdfef9" category="paragraph">Per impostazione predefinita, Cloud Volumes Service include<block ref="2363dee608bcd9f6ce7f980bfdad5789" prefix=" " category="inline-code"></block> Nel ns-switch dell'istanza per il database della mappa dei nomi, in modo che per fornire la funzionalità di mappatura dei nomi utilizzando LDAP per i nomi asimmetrici, è sufficiente modificare alcuni attributi utente/gruppo per riflettere ciò che Cloud Volumes Service cerca.</block>
  <block id="5083578eb1523417a04b030704e11a97" category="paragraph">La tabella seguente mostra gli attributi da inserire in LDAP per la funzionalità di mappatura asimmetrica dei nomi. Nella maggior parte dei casi, Active Directory è già configurato per eseguire questa operazione.</block>
  <block id="2e4b53007a09bf23d9111917c46d1902" category="cell">Attributo Cloud Volumes Service</block>
  <block id="009097a0950f2d6565c2cb446aa081dd" category="cell">Valore utilizzato da Cloud Volumes Service per la mappatura dei nomi</block>
  <block id="df642bb30c436da15b0b74923cb45806" category="cell">ObjectClass da Windows a UNIX</block>
  <block id="75f68f87af42701b9e548f875f39cefe" category="cell">Specifica il tipo di oggetto utilizzato. (Ovvero, utente, gruppo, posixAccount e così via)</block>
  <block id="2b731e8ed189a8b7587c21b21d6620cf" category="cell">Deve includere l'utente (può contenere più altri valori, se lo si desidera).</block>
  <block id="288eebd1d2cddc03953f475edbcb2d5f" category="cell">Attributo da Windows a UNIX</block>
  <block id="1b356493e583b25fdd7b1e44d6a4df0d" category="cell">Che definisce il nome utente Windows al momento della creazione. Cloud Volumes Service lo utilizza per le ricerche da Windows a UNIX.</block>
  <block id="5ce0ca6d681fede8d46460fed64bf8ef" category="cell">Nessuna modifica necessaria; sAMAccountName corrisponde al nome di accesso di Windows.</block>
  <block id="e7d22294bdcb7133967c3548ece982e5" category="cell">UID</block>
  <block id="d93b9102027ae26f7bbfa53ff0cd3f28" category="cell">Definisce il nome utente UNIX.</block>
  <block id="abd2101078216980cdcf2dc6f87172b9" category="cell">Nome utente UNIX desiderato.</block>
  <block id="78e7065e65f76fc53c1953f598d424de" category="paragraph">Cloud Volumes Service attualmente non utilizza prefissi di dominio nelle ricerche LDAP, pertanto gli ambienti LDAP di più domini non funzionano correttamente con le ricerche della mappa dei nomi LDAP.</block>
  <block id="1a19ad8ba3f26bc83d40bf699210c5b3" category="paragraph">Nell'esempio riportato di seguito viene illustrato un utente con il nome Windows<block ref="188fda84cd10112124b8477615ee021d" prefix=" " category="inline-code"></block>, Il nome UNIX<block ref="a4e3d60786c42d81caec6aea737b5ce0" prefix=" " category="inline-code"></block>E il comportamento che segue quando si scrivono file da SMB e NFS.</block>
  <block id="cf613896f3bf97cfe22b19367188faac" category="paragraph">La figura seguente mostra l'aspetto degli attributi LDAP dal server Windows.</block>
  <block id="bb859b3ee7438471d7bd0441aec37b09" category="paragraph"><block ref="bb859b3ee7438471d7bd0441aec37b09" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74a3bb1b92afc37821849f4d2c6a2e08" category="paragraph">Da un client NFS, è possibile eseguire una query sul nome UNIX ma non sul nome di Windows:</block>
  <block id="9a9b54fd5d17009b1290538bd0bea332" category="paragraph">Quando un file viene scritto da NFS come<block ref="a4e3d60786c42d81caec6aea737b5ce0" prefix=" " category="inline-code"></block>, Il seguente è il risultato del client NFS:</block>
  <block id="2d78fc711a4a8afa3553c40cb81a7f5a" category="paragraph">Da un client Windows, è possibile vedere che il proprietario del file è impostato sull'utente Windows appropriato:</block>
  <block id="dd276babf175f2baaf7d31c63630e9ce" category="paragraph">Al contrario, i file creati dall'utente Windows<block ref="188fda84cd10112124b8477615ee021d" prefix=" " category="inline-code"></block> Da un client SMB mostrare il proprietario UNIX appropriato, come mostrato nel testo seguente.</block>
  <block id="840e343f2946d2e3ecafb4d3af6751c5" category="paragraph">PMI:</block>
  <block id="7369fcede1216c5a449bffa4016f597a" category="paragraph">NFS:</block>
  <block id="1a2ced64ce54d0878867c66c1264ef73" category="section-title">Binding del canale LDAP</block>
  <block id="7bc3122060898b084ade9ae81cb840d5" category="inline-link">Microsoft Security Advisory ADV190023</block>
  <block id="9c2bd50d1c3b17373f80735ce60e0d91" category="paragraph">A causa di una vulnerabilità dei controller di dominio Active Directory di Windows,<block ref="9230172696f08489abbbe06ad2878984" category="inline-link-rx"></block> Modifica il modo in cui i controller di dominio consentono i binding LDAP.</block>
  <block id="c389bcb5002ce56cb9cf28680eb6ff4c" category="paragraph">L'impatto per Cloud Volumes Service è lo stesso di qualsiasi client LDAP. Cloud Volumes Service attualmente non supporta il binding del canale. Poiché Cloud Volumes Service supporta la firma LDAP per impostazione predefinita attraverso la negoziazione, l'associazione del canale LDAP non dovrebbe rappresentare un problema. In caso di problemi di associazione a LDAP con l'associazione del canale attivata, seguire la procedura di risoluzione descritta in ADV190023 per consentire l'esecuzione dei binding LDAP da Cloud Volumes Service.</block>
  <block id="8cc300201cbc74e712f45393efb60e69" category="inline-link">DNS dinamico</block>
  <block id="80052c998ef6da49a98a2d9004c75c33" category="paragraph">Active Directory e Kerberos hanno entrambe dipendenze dal DNS per la risoluzione dei nomi host all'IP/IP. Il DNS richiede che la porta 53 sia aperta. Cloud Volumes Service non appora alcuna modifica ai record DNS, né supporta attualmente l'utilizzo di<block ref="2df544fb17221302fef729d1eb6bd715" category="inline-link-rx"></block> sulle interfacce di rete.</block>
  <block id="5f36386498075ef9c05d674112b69981" category="inline-link">DNS Windows sicuro</block>
  <block id="e3aa134886f9dad39f14489844fe7763" category="paragraph">È possibile configurare il DNS di Active Directory per limitare i server che possono aggiornare i record DNS. Per ulteriori informazioni, vedere<block ref="1abda701cc77717e0b1a0b391ec2fed8" category="inline-link-rx"></block>.</block>
  <block id="e8ba0470f4bd2498fbecdead3ab1b183" category="paragraph">Si noti che le risorse all'interno di un progetto Google utilizzano per impostazione predefinita il DNS di Google Cloud, che non è connesso al DNS di Active Directory. I client che utilizzano il DNS cloud non possono risolvere i percorsi UNC restituiti da Cloud Volumes Service. I client Windows associati al dominio Active Directory sono configurati per utilizzare il DNS di Active Directory e possono risolvere tali percorsi UNC.</block>
  <block id="71870bac7a9267067ab69566f75d36c3" category="inline-link">Perché il client non riesce a risolvere il nome NetBIOS SMB?</block>
  <block id="b0ffc266c9e05cd7ae80810305b932bf" category="paragraph">Per aggiungere un client ad Active Directory, è necessario configurare la relativa configurazione DNS in modo che utilizzi il DNS di Active Directory. Facoltativamente, è possibile configurare il DNS cloud per inoltrare le richieste al DNS di Active Directory. Vedere<block ref="d568657413aac86de4b237a9edcddc2d" category="inline-link-rx"></block>per ulteriori informazioni.</block>
  <block id="a0c7db04deaabb45ee60d5a501e67eb8" category="admonition">Cloud Volumes Service attualmente non supporta DNSSEC e le query DNS vengono eseguite in formato non crittografato.</block>
  <block id="c3a18bc4fd14cf11bc551540f29f6375" category="section-title">Controllo dell'accesso al file</block>
  <block id="cc6e776769986190d1536969ad7e5307" category="paragraph">Attualmente non supportato per Cloud Volumes Service.</block>
  <block id="5cffe1f133f0ed3a472da05d0b1d3f0d" category="section-title">Protezione antivirus</block>
  <block id="2b91875198ddd07e9b4cff7f1fe46663" category="paragraph">È necessario eseguire la scansione antivirus in Cloud Volumes Service sul client in una condivisione NAS. Attualmente non esiste alcuna integrazione antivirus nativa con Cloud Volumes Service.</block>
  <block id="f0e8b8e3bd62a1e919cd1935e44bf79c" category="inline-link-macro">Successivo: Operazione di assistenza.</block>
  <block id="fba0107176535938bcee4c0774160668" category="paragraph"><block ref="fba0107176535938bcee4c0774160668" category="inline-link-macro-rx"></block></block>
  <block id="9eb662185982de390339607d2ee459a4" category="summary">Cloud Volumes Service in Google Cloud offre una moltitudine di modi per proteggere in modo nativo i tuoi dati.</block>
  <block id="52aa20c1efa9dfeda78d72f4c056c23f" category="doc">In che modo Cloud Volumes Service in Google Cloud protegge i tuoi dati</block>
  <block id="78dad9c3bba77d55493b24502dbe6a1d" category="paragraph"><block ref="78dad9c3bba77d55493b24502dbe6a1d" category="inline-link-macro-rx"></block></block>
  <block id="9967209a1408f78f781d93dd0cdf88c4" category="section-title">Architettura sicura e modello di tenancy</block>
  <block id="9ba9e0f1cce71f64d3188bfdc502a43d" category="inline-link-macro">"Architettura Cloud Volumes Service"</block>
  <block id="33186704f78f73f32736a9ba7f8ddc85" category="inline-link">accesso ai servizi privati</block>
  <block id="00d6cadb7a586713782bbffe59d5bc21" category="paragraph">Cloud Volumes Service offre un'architettura sicura in Google Cloud segmentando la gestione del servizio (piano di controllo) e l'accesso ai dati (piano dati) tra diversi endpoint in modo che nessuno dei due possa influire sull'altro (vedere la sezione <block ref="d861c2ffd2960acc200167f08fd40005" category="inline-link-macro-rx"></block>). Utilizza Google<block ref="1ac65cff0d913f26dd36736caeefd5b7" category="inline-link-rx"></block> (PSA) per fornire il servizio. Questo framework distingue tra il produttore di servizi, fornito e gestito da NetApp, e il consumatore di servizi, che è un cloud privato virtuale (VPC) in un progetto del cliente, che ospita i client che desiderano accedere alle condivisioni di file Cloud Volumes Service.</block>
  <block id="5971da0242ce7b616ff2972978613cef" category="inline-link-macro">"Modello di tenancy"</block>
  <block id="01760cb04e3a4a93404ab2c878b036db" category="inline-link-macro">"VPC condivisi"</block>
  <block id="e70da8f06ec706ed45906f411481eda0" category="paragraph">In questa architettura, i tenant (vedere la sezione <block ref="0a088dd892133b6a77304655c2b8b829" category="inline-link-macro-rx"></block>) Sono definiti come progetti Google Cloud che sono completamente isolati l'uno dall'altro, a meno che l'utente non sia esplicitamente connesso. I tenant consentono l'isolamento completo dei volumi di dati, dei servizi di nomi esterni e di altre parti essenziali della soluzione da parte di altri tenant utilizzando la piattaforma per volumi Cloud Volumes Service. Poiché la piattaforma Cloud Volumes Service è connessa tramite peering VPC, tale isolamento si applica anche ad essa. È possibile abilitare la condivisione di volumi Cloud Volumes Service tra più progetti utilizzando un VPC condiviso (vedere la sezione <block ref="c2426c8c5bcdce9adb82a8906c5a3478" category="inline-link-macro-rx"></block>). È possibile applicare i controlli di accesso alle condivisioni SMB e alle esportazioni NFS per limitare chi o cosa può visualizzare o modificare i set di dati.</block>
  <block id="35a0e1620a03f33da8739635aaa3b607" category="section-title">Gestione efficace delle identità per il piano di controllo</block>
  <block id="4504de40d15959838801111af31d224e" category="inline-link">IAM (Identity Access Management)</block>
  <block id="d242c9a4fc4e118d87391841845ef44b" category="paragraph">Nel piano di controllo in cui avviene la configurazione Cloud Volumes Service, la gestione delle identità viene gestita tramite<block ref="490163f8d94b8a8397824811fb91c5ec" category="inline-link-rx"></block>. IAM è un servizio standard che consente di controllare l'autenticazione (accessi) e l'autorizzazione (autorizzazioni) per le istanze di progetto di Google Cloud. Tutta la configurazione viene eseguita con API Cloud Volumes Service su un trasporto HTTPS sicuro utilizzando la crittografia TLS 1.2 e l'autenticazione viene eseguita utilizzando token JWT per una maggiore sicurezza. L'interfaccia utente della console Google per Cloud Volumes Service converte l'input dell'utente in chiamate API Cloud Volumes Service.</block>
  <block id="688247a9da881160b1073a4b76442640" category="section-title">Protezione avanzata - limita le superfici di attacco</block>
  <block id="4901056002c8d64da3b67da6a5a2dbbb" category="paragraph">Una parte della sicurezza effettiva consiste nel limitare il numero di superfici di attacco disponibili in un servizio. Le superfici di attacco possono includere una varietà di elementi, tra cui dati a riposo, trasferimenti in volo, accessi e set di dati stessi.</block>
  <block id="733e720a346376b07eb9adac497c4063" category="inline-link-macro">"Funzionamento del servizio"</block>
  <block id="aa6187208cb06e0a43851ee1783a370c" category="paragraph">Un servizio gestito rimuove alcune delle superfici di attacco intrinsecamente nella sua progettazione. Gestione dell'infrastruttura, come descritto nella sezione <block ref="ddbc8ce5f4099ff7254959018f566688" category="inline-link-macro-rx"></block> è gestito da un team dedicato ed è automatizzato per ridurre il numero di volte in cui un umano tocca effettivamente le configurazioni, contribuendo a ridurre il numero di errori intenzionali e non intenzionali. La rete è disattivata in modo che solo i servizi necessari possano accedere l'uno all'altro. La crittografia viene inserita nello storage dei dati e solo il piano dati richiede attenzione per la sicurezza da parte degli amministratori di Cloud Volumes Service. Nascondendo la maggior parte della gestione dietro un'interfaccia API, la sicurezza viene ottenuta limitando le superfici di attacco.</block>
  <block id="d8d81a048343e815b76f916e1c58e636" category="section-title">Modello Zero Trust</block>
  <block id="d2c4e1022fc22d0780bd913d3f16498e" category="paragraph">Storicamente, la filosofia di sicurezza IT è stata quella di fidarsi, ma di verificare, e si è manifestata come affidandosi esclusivamente a meccanismi esterni (come firewall e sistemi di rilevamento delle intrusioni) per mitigare le minacce. Tuttavia, gli attacchi e le violazioni si sono evoluti per aggirare la verifica negli ambienti attraverso phishing, social engineering, minacce interne e altri metodi che forniscono la verifica per entrare nelle reti e causare caos.</block>
  <block id="853f80d22a64d4fff24c05d305e800a8" category="paragraph">Zero Trust è diventata una nuova metodologia per la sicurezza, con l'attuale mantra "fidarsi di nulla pur verificando tutto". Pertanto, per impostazione predefinita, non è consentito alcun accesso. Questo mantra viene applicato in diversi modi, tra cui firewall standard e sistemi di rilevamento delle intrusioni (IDS) e con i seguenti metodi:</block>
  <block id="d07f4106373448c16aedf0c01749e560" category="list-text">Metodi di autenticazione avanzata (ad esempio token Kerberos o JWT con crittografia AES)</block>
  <block id="4bbee6cac6b31b494ade66a9fc2f16e7" category="list-text">Singole fonti di identità sicure (come Windows Active Directory, Lightweight Directory Access Protocol (LDAP) e Google IAM)</block>
  <block id="da31693a70531052458cd4eff104672d" category="list-text">Segmentazione della rete e multi-tenancy sicura (solo i tenant possono accedere per impostazione predefinita)</block>
  <block id="a8ce5780cff146b27ae2c2b3fddc0447" category="list-text">Controlli granulari degli accessi con policy di accesso con privilegi minimi</block>
  <block id="493f70c348ea51d5c7cb8a28593df5a1" category="list-text">Piccoli elenchi esclusivi di amministratori affidabili e dedicati con audit digitale e percorsi cartacei</block>
  <block id="fd5070ec3e2f12398e4de9b77b900cbf" category="paragraph">Cloud Volumes Service eseguito in Google Cloud rispetta il modello Zero Trust implementando la posizione "Trust Nothing, Verify Everything".</block>
  <block id="d7f2615c71a1567cc13cf3a7f7de0aea" category="section-title">Crittografia</block>
  <block id="83c3a5400dd4f14665a803a22add4a9d" category="inline-link-macro">"Crittografia dei dati a riposo"</block>
  <block id="a37154afafe65368d5170741a4669261" category="inline-link-macro">"Crittografia SMB"</block>
  <block id="e688fd1eb8866f914263d3493c30ccbb" category="inline-link-macro">"Replica tra regioni"</block>
  <block id="48aa29a35d8e13e796333876f4ea9f62" category="inline-link-macro">"Rete Google Cloud"</block>
  <block id="31d64d3cd8b2a692701b32dd6a611c76" category="paragraph">Crittografare i dati inattivi (vedere la sezione <block ref="ce3046d8bb0cfdf8a89295f31068c29b" category="inline-link-macro-rx"></block>) Utilizzando le crittografia XTS-AES-256 con NetApp Volume Encryption (NVE) e in-flight con <block ref="9963d74c8d0d381d9818a5c550dd7163" category="inline-link-macro-rx"></block> O NFS Kerberos 5p. È facile sapere che i trasferimenti di replica tra regioni sono protetti dalla crittografia TLS 1.2 (vedere la sezione <block ref="8b1fa1a1fab3125dbb820bfe80ca0428" category="inline-link-macro-rx"></block>). Inoltre, Google Networking fornisce anche comunicazioni crittografate (vedere la sezione <block ref="051d363ef6081e123484b5da28bebf19" category="inline-link-macro-rx"></block>) per un ulteriore livello di protezione dagli attacchi. Per ulteriori informazioni sulla crittografia del trasporto, vedere la sezione <block ref="0e3bb83173de6418179f08aaa25b48dd" category="inline-link-macro-rx"></block>.</block>
  <block id="db57ea7882be0cb73c78bf1ba25a6823" category="section-title">Protezione dei dati e backup</block>
  <block id="cdb185875636a141b69ddabde6df7040" category="paragraph">La sicurezza non riguarda solo la prevenzione degli attacchi. Si tratta anche del modo in cui ripristiniamo gli attacchi in caso o quando si verificano. Questa strategia include backup e protezione dei dati. Cloud Volumes Service fornisce metodi per la replica in altre regioni in caso di interruzioni (vedere la sezione <block ref="8b1fa1a1fab3125dbb820bfe80ca0428" category="inline-link-macro-rx"></block>) o se un set di dati è interessato da un attacco ransomware. Inoltre, può eseguire backup asincroni dei dati in posizioni esterne all'istanza di Cloud Volumes Service utilizzando <block ref="92f2015a7a07a74ffc21a27b08fadbb0" category="inline-link-macro-rx"></block>. Con backup regolari, la mitigazione degli eventi di sicurezza può richiedere meno tempo e risparmiare denaro e angoscia per gli amministratori.</block>
  <block id="3b0aab94fdc89c539c78fcbbf0190080" category="section-title">Riduzione rapida del ransomware con copie Snapshot leader del settore</block>
  <block id="e7d51c7f9901730a4f176b908516d9f0" category="inline-link-macro">"Copie Snapshot immutabili"</block>
  <block id="613542b40dc5d23e9b7129726e6901e9" category="inline-link-macro">"Funzionamento del servizio"</block>
  <block id="06646d879e1be0df7191f42262dc1293" category="paragraph">Oltre alla protezione dei dati e ai backup, Cloud Volumes Service fornisce il supporto per copie Snapshot immutabili (vedere la sezione <block ref="46dfee0c3fc63af00a088b428ebe2c09" category="inline-link-macro-rx"></block>) di volumi che consentono il ripristino da attacchi ransomware (vedere la sezione <block ref="f545e9c9b1aa4e21f947ee53ac36de63" category="inline-link-macro-rx"></block>) entro pochi secondi dalla scoperta del problema e con interruzioni minime. I tempi e gli effetti di recovery dipendono dalla pianificazione di Snapshot, ma è possibile creare copie Snapshot che forniscono solo un'ora di delta negli attacchi ransomware. Le copie Snapshot hanno un effetto trascurabile sulle performance e sull'utilizzo della capacità e rappresentano un approccio a basso rischio e con premi elevati per la protezione dei set di dati.</block>
  <block id="f21f1562468eeb7bb67162f8fc79596c" category="inline-link-macro">Avanti: Considerazioni sulla sicurezza e superfici di attacco.</block>
  <block id="d6cb5b8910b7e61e1d2a16900dff7414" category="paragraph"><block ref="d6cb5b8910b7e61e1d2a16900dff7414" category="inline-link-macro-rx"></block></block>
  <block id="60298c0c8282022dec640948e48114c1" category="summary">Il team di Cloud Volumes Service gestisce i servizi di back-end in Google Cloud e utilizza diverse strategie per proteggere la piattaforma e prevenire accessi indesiderati.</block>
  <block id="d5558f87207ef258cc599e6b4f31fa1f" category="doc">Funzionamento del servizio</block>
  <block id="23fa70110ac44a6aa038c42f52919e60" category="inline-link-macro">Precedente: Altre dipendenze del servizio infrastruttura NAS (KDC, LDAP, DNS).</block>
  <block id="09db248feade063e1b222ff7a6fa8bae" category="paragraph"><block ref="09db248feade063e1b222ff7a6fa8bae" category="inline-link-macro-rx"></block></block>
  <block id="01f3694459a5570182960c35de3adea0" category="paragraph">Ogni cliente ottiene la propria subnet univoca che ha accesso negato da altri clienti per impostazione predefinita e ogni tenant in Cloud Volumes Service ottiene il proprio namespace e la propria VLAN per l'isolamento totale dei dati. Dopo l'autenticazione di un utente, il Service Delivery Engine (SDE) può leggere solo i dati di configurazione specifici del tenant.</block>
  <block id="3efd389b601ec82d2d3d7d1fe8c7a952" category="section-title">Sicurezza fisica</block>
  <block id="e6cbbd1872a42cfa36ceca16da55e6af" category="paragraph">Con un'adeguata preapprovazione, solo i tecnici on-site e gli ingegneri di assistenza sul campo (FSE) con badge NetApp hanno accesso alla gabbia e ai rack per il lavoro fisico. La gestione dello storage e della rete non è consentita. Solo queste risorse on-site sono in grado di eseguire attività di manutenzione dell'hardware.</block>
  <block id="f4cc7ff420af18ead26b06b01e65be30" category="paragraph">Per i tecnici in loco, viene presentato un ticket per la dichiarazione di lavoro (SOW) che include l'ID del rack e la posizione del dispositivo (RU) e tutti gli altri dettagli sono inclusi nel ticket. Per gli FSE NetApp, è necessario inoltrare un ticket di visita del sito con IL COLO e il biglietto include i dettagli, la data e l'ora del visitatore per scopi di verifica. Il SOW del FSE viene comunicato internamente a NetApp.</block>
  <block id="e6da80db21921cfa31a2ec8ae71c8a44" category="section-title">Team operativo</block>
  <block id="575c886f27b4fd6adbc422b9466a7d77" category="paragraph">Il team operativo di Cloud Volumes Service è composto da tecnici di produzione e da un tecnico di affidabilità del sito (SRE) per i servizi di volume cloud e da tecnici di assistenza sul campo e partner per l'hardware. Tutti i membri del team operativo sono accreditati per il lavoro in Google Cloud e vengono mantenuti record dettagliati di lavoro per ogni ticket generato. Inoltre, è in atto un rigoroso processo di approvazione e controllo delle modifiche per garantire che ogni decisione venga esaminata in modo appropriato.</block>
  <block id="62b92b1afcd6e99ad8ef6fc6e66fe1c6" category="paragraph">Il team SRE gestisce il piano di controllo e il modo in cui i dati vengono instradati dalle richieste dell'interfaccia utente all'hardware e al software di back-end in Cloud Volumes Service. Il team SRE gestisce anche le risorse di sistema, ad esempio i massimi di volume e inode. Gli SRE non possono interagire con i dati dei clienti o accedervi. Gli SRE forniscono inoltre il coordinamento con le RMA (Return Material Authorization), come le richieste di sostituzione di nuovi dischi o memoria per l'hardware back-end.</block>
  <block id="20ac318b6aafb241498518b27a204f2d" category="section-title">Responsabilità del cliente</block>
  <block id="5b18708f6a9b76d94aad073287e9c4aa" category="paragraph">I clienti di Cloud Volumes Service gestiscono la gestione dei ruoli utente e di Active Directory della propria organizzazione, nonché le operazioni di volume e dati. I clienti possono avere ruoli amministrativi e delegare le autorizzazioni ad altri utenti finali all'interno dello stesso progetto Google Cloud utilizzando i due ruoli predefiniti forniti da NetApp e Google Cloud (Administrator e Viewer).</block>
  <block id="70612d623f8ac2ccbad1aa9289e54eb2" category="paragraph">L'amministratore può eseguire il peer di qualsiasi VPC all'interno del progetto del cliente a Cloud Volumes Service che il cliente ritiene appropriato. È responsabilità del cliente gestire l'accesso al proprio Google Cloud Marketplace Subscription e i VPC che hanno accesso al data plane.</block>
  <block id="1e9614b8d81927a9e9bad94fe64884d6" category="section-title">Protezione SRE dannosa</block>
  <block id="1ced9b3b1b2408070d8594c7310def52" category="paragraph">Una preoccupazione che potrebbe sorgere è come Cloud Volumes Service protegge da scenari in cui si verifica un SRE dannoso o quando le credenziali SRE sono state compromesse?</block>
  <block id="0cf58dc2d9a00ecaeb191e61685b36e5" category="paragraph">L'accesso all'ambiente di produzione avviene solo con un numero limitato di individui SRE. I privilegi amministrativi sono ulteriormente limitati a pochi amministratori esperti. Tutte le azioni eseguite da chiunque nell'ambiente di produzione Cloud Volumes Service vengono registrate e qualsiasi anomalia alla linea di base o alle attività sospette viene rilevata dalla nostra piattaforma di Threat intelligence per la gestione delle informazioni sulla sicurezza e degli eventi (SIEM). Di conseguenza, le azioni dannose possono essere monitorate e mitigate prima che venga eseguito un danno eccessivo al backend Cloud Volumes Service.</block>
  <block id="9893b21aa64e031fdfd6920fef8147a3" category="section-title">Ciclo di vita del volume</block>
  <block id="1135939baa7babe550972f3d2430315f" category="paragraph">Cloud Volumes Service gestisce solo gli oggetti all'interno del servizio, non i dati all'interno dei volumi. Solo i client che accedono ai volumi possono gestire i dati, gli ACL, i proprietari dei file e così via. I dati in questi volumi vengono crittografati a riposo e l'accesso è limitato ai tenant dell'istanza di Cloud Volumes Service.</block>
  <block id="dd04bd242a373a0c9b066d0704ba4d66" category="paragraph">Il ciclo di vita del volume per Cloud Volumes Service è create-update-delete. I volumi conservano le copie Snapshot dei volumi fino all'eliminazione dei volumi e solo gli amministratori Cloud Volumes Service validati possono eliminare i volumi in Cloud Volumes Service. Quando un amministratore richiede l'eliminazione di un volume, per verificare l'eliminazione è necessario inserire un ulteriore passo per il nome del volume. Dopo l'eliminazione di un volume, il volume non viene più utilizzato e non può essere recuperato.</block>
  <block id="1744c1e09f5b1b7990b7f2b80a7a9500" category="paragraph">Nei casi in cui un contratto Cloud Volumes Service venga rescisso, NetApp contrassegna i volumi per l'eliminazione dopo un determinato periodo di tempo. Prima della scadenza di tale periodo di tempo, è possibile ripristinare i volumi su richiesta del cliente.</block>
  <block id="13e637fe96062929286b911c16b3c2df" category="section-title">Certificazioni</block>
  <block id="af06a002abcc2b02896192d8fd1052cd" category="inline-link">Compliance: Sicurezza dei dati e privacy dei dati</block>
  <block id="258a58248bd2280e3d97717c4150b3cf" category="paragraph">Cloud Volumes Services per Google Cloud è attualmente certificato in base agli standard ISO/IEC 27001:2013 e ISO/IEC 27018:2019. Il servizio ha inoltre ricevuto di recente il report di attestazione SOC2 di tipo I. Per informazioni sull'impegno di NetApp per la sicurezza e la privacy dei dati, vedere<block ref="751448d9ace7c1569cfa25749b75ea26" category="inline-link-rx"></block>.</block>
  <block id="4e94c8ad46c8aef1ca637841dfbe2159" category="section-title">GDPR</block>
  <block id="ee69241049506ca93a3a1cd627e44851" category="inline-link">contratti con i clienti</block>
  <block id="15655a5f67808f893102ffa3cbde3b01" category="inline-link">Addendum per l'elaborazione dei dati dei clienti</block>
  <block id="cd0ae90a69c7d21d42b18252b9e1707d" category="inline-link">Clausole contrattuali standard</block>
  <block id="de315e46a9bdf4936de71254f87d2fe0" category="paragraph">I nostri impegni in materia di privacy e conformità al GDPR sono disponibili in diversi nostri <block ref="c2118342007d8714fcb1b4f6106c575c" category="inline-link-rx"></block>, come il nostro<block ref="7f657124cd056ea8e74c57dcafd4df75" category="inline-link-rx"></block>, che include <block ref="85bd1a4ed188bfd53fcaef2fb6e1962a" category="inline-link-rx"></block> Fornito dalla Commissione europea. Inoltre, ci impegniamo a rispettare questi impegni nella nostra direttiva sulla privacy, supportata dai valori fondamentali stabiliti nel nostro Codice di condotta aziendale.</block>
  <block id="648d64814699b339816911e595b789cd" category="inline-link-macro">Pagina successiva: Ulteriori informazioni, cronologia delle versioni e informazioni di contatto.</block>
  <block id="259ea0e5275404f9f6b7793a369cf8d5" category="paragraph"><block ref="259ea0e5275404f9f6b7793a369cf8d5" category="inline-link-macro-rx"></block></block>
  <block id="fd7d290d66c64aa2fc13dd9bbca9c540" category="summary">Cloud Volumes Service offre la possibilità di condividere gli stessi set di dati con client SMB e NFS mantenendo le autorizzazioni di accesso appropriate a doppio protocollo. Ciò avviene coordinando il mapping delle identità tra i protocolli e utilizzando un server LDAP backend centralizzato per fornire le identità UNIX a Cloud Volumes Service. È possibile utilizzare Windows Active Directory per fornire agli utenti Windows e UNIX una maggiore facilità di utilizzo.</block>
  <block id="d27d01220b09abd6dc8be87dd2b7f8d4" category="doc">Protocollo doppio/multiprotocollo</block>
  <block id="8c14d6d170254470aea76e2185e26901" category="inline-link-macro">Precedente: SMB.</block>
  <block id="692e0ebc2797e7ae1a9618bdac0b5c02" category="paragraph"><block ref="692e0ebc2797e7ae1a9618bdac0b5c02" category="inline-link-macro-rx"></block></block>
  <block id="9a5ba82ef925964774fad34d380585ce" category="inline-link">protocollo doppio</block>
  <block id="afbf550dbb927e70d6e5e81aba4cf54e" category="paragraph">Cloud Volumes Service offre la possibilità di condividere gli stessi set di dati con client SMB e NFS mantenendo le autorizzazioni di accesso appropriate <block ref="090248040bf8d7cbf59e0f5bcb2aeb23" category="inline-link-rx"></block>). Ciò avviene coordinando il mapping delle identità tra i protocolli e utilizzando un server LDAP backend centralizzato per fornire le identità UNIX a Cloud Volumes Service. È possibile utilizzare Windows Active Directory per fornire agli utenti Windows e UNIX una maggiore facilità di utilizzo.</block>
  <block id="65bd83537129be15c8027ec94bec5bd3" category="section-title">Controllo degli accessi</block>
  <block id="b481dc764d87d694bd99e41051212b98" category="inline-link-macro">"Account con diritti di backup/amministratore BUILTIN locale."</block>
  <block id="4349221797619aa2539cd1d814d55cf3" category="inline-link">Gestione MMC/computer</block>
  <block id="ab67de3b2d37b16da324871c9cd7f96b" category="list-text">*Controlli di accesso alla condivisione.* determinare quali client e/o utenti e gruppi possono accedere a una condivisione NAS. Per NFS, le policy e le regole di esportazione controllano l'accesso dei client alle esportazioni. Le esportazioni NFS vengono gestite dall'istanza di Cloud Volumes Service. SMB utilizza le condivisioni CIFS/SMB e gli ACL di condivisione per fornire un controllo più granulare a livello di utente e gruppo. È possibile configurare gli ACL a livello di condivisione solo dai client SMB utilizzando<block ref="dbc4cec831b164bbb509e51caacd0209" category="inline-link-rx"></block> Con un account che dispone dei diritti di amministratore sull'istanza di Cloud Volumes Service (vedere la sezione <block ref="c9946e41ec7364b03516e2beacd1b339" category="inline-link-macro-rx"></block>).</block>
  <block id="1020ac8238c0e64a401514745b8a3c6a" category="list-text">*File access control.* Controlla le autorizzazioni a livello di file o cartella e sono sempre gestite dal client NAS. I client NFS possono utilizzare i bit di modalità tradizionali (rwx) o gli ACL NFSv4. I client SMB sfruttano le autorizzazioni NTFS.</block>
  <block id="dcfd17a407b936210845de342300e631" category="paragraph">Il controllo dell'accesso per i volumi che servono dati a NFS e SMB dipende dal protocollo in uso. Per informazioni sulle autorizzazioni con protocollo doppio, vedere la sezione "<block ref="7251f6a3aba1b22d43e125a8c39f6f0a" category="inline-xref-macro-rx"></block>."</block>
  <block id="20d918db09dacfd5fbfbaadfaede2f80" category="section-title">Mappatura dell'utente</block>
  <block id="c9677302c2548820abda217b496a541b" category="paragraph">Quando un client accede a un volume, Cloud Volumes Service tenta di mappare l'utente in entrata a un utente valido nella direzione opposta. Ciò è necessario per determinare l'accesso corretto tra i protocolli e per garantire che l'utente che richiede l'accesso sia effettivamente quello che afferma di essere.</block>
  <block id="7e9b11fc569fee58c3b42b689df2fbec" category="paragraph">Ad esempio, se un utente Windows ha denominato<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> Tenta di accedere a un volume con autorizzazioni UNIX tramite SMB, quindi Cloud Volumes Service esegue una ricerca per trovare un utente UNIX corrispondente denominato<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block>. Se ne esiste uno, i file scritti in una condivisione SMB come utente Windows<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> Viene visualizzato come utente UNIX<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> Dai client NFS.</block>
  <block id="b9e4f77748fb373f23ad2bc9eb2d3de0" category="paragraph">In alternativa, se si chiama un utente UNIX<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> Tenta di accedere a un volume Cloud Volumes Service con autorizzazioni Windows, quindi l'utente UNIX deve essere in grado di eseguire il mapping a un utente Windows valido. In caso contrario, l'accesso al volume viene negato.</block>
  <block id="98b9b81e4ad07f5198dd8381a0c5d43c" category="inline-link">Creazione di una connessione ad</block>
  <block id="d6210f83492bb730b32d0e719a1d5100" category="paragraph">Attualmente, solo Active Directory è supportato per la gestione esterna delle identità UNIX con LDAP. Per ulteriori informazioni sulla configurazione dell'accesso a questo servizio, vedere<block ref="cfe0f81fca904ab10d3dcbbfceb0f3de" category="inline-link-rx"></block>.</block>
  <block id="7fc7c5bf3cd7f453807f2e17dc846957" category="section-title">Modello di permesso</block>
  <block id="94b74cdf7c7dc9ef00fc04cf642127d9" category="paragraph">Quando si utilizzano configurazioni a doppio protocollo, Cloud Volumes Service utilizza gli stili di sicurezza per i volumi per determinare il tipo di ACL. Questi stili di sicurezza vengono impostati in base al protocollo NAS specificato o, nel caso del protocollo doppio, è possibile scegliere al momento della creazione del volume Cloud Volumes Service.</block>
  <block id="b3544688f5ad40244fc991f13471c525" category="list-text">Se si utilizza solo NFS, i volumi Cloud Volumes Service utilizzano le autorizzazioni UNIX.</block>
  <block id="95b899e9e3d21a94ae7e8ce04eac3bb3" category="list-text">Se si utilizza solo SMB, i volumi Cloud Volumes Service utilizzano le autorizzazioni NTFS.</block>
  <block id="51c16477dee3c257c4930e8614eda5ba" category="paragraph">Se si crea un volume a doppio protocollo, è possibile scegliere lo stile ACL alla creazione del volume. Questa decisione deve essere presa in base alla gestione delle autorizzazioni desiderata. Se gli utenti gestiscono le autorizzazioni dai client Windows/SMB, selezionare NTFS. Se gli utenti preferiscono utilizzare client NFS e chmod/chown, utilizzare gli stili di sicurezza UNIX.</block>
  <block id="fd859db4ea28a81227f07e2c125fc927" category="inline-link-macro">Segue: Considerazioni per la creazione di connessioni Active Directory.</block>
  <block id="bc695a7a8573373413beec401ab691e1" category="paragraph"><block ref="bc695a7a8573373413beec401ab691e1" category="inline-link-macro-rx"></block></block>
  <block id="8a7d64073f6ea3e3562e48ad7babe165" category="summary">I protocolli NAS includono NFS (v3 e v4.1) e SMB/CIFS (2.x e 3.x). Questi protocolli sono il modo in cui CVS consente l'accesso condiviso ai dati tra più client NAS. Inoltre, Cloud Volumes Service può fornire l'accesso simultaneo ai client NFS e SMB/CIFS (dual-Protocol) rispettando tutte le impostazioni di identità e autorizzazioni su file e cartelle nelle condivisioni NAS.</block>
  <block id="90654829f21fcf187b576a4c4bad0d65" category="doc">Panoramica dei protocolli NAS</block>
  <block id="571468eb1eb9e9369a3f638191a66df7" category="inline-link-macro">Precedente: Firewall.</block>
  <block id="01d123c65f0dd57ade00e4f9754df7de" category="paragraph"><block ref="01d123c65f0dd57ade00e4f9754df7de" category="inline-link-macro-rx"></block></block>
  <block id="2ea1602d2ad8b38f601e3e9a049c625d" category="paragraph">I protocolli NAS includono NFS (v3 e v4.1) e SMB/CIFS (2.x e 3.x). Questi protocolli sono il modo in cui CVS consente l'accesso condiviso ai dati tra più client NAS. Inoltre, Cloud Volumes Service può fornire l'accesso simultaneo ai client NFS e SMB/CIFS (dual-Protocol) rispettando tutte le impostazioni di identità e autorizzazioni su file e cartelle nelle condivisioni NAS. Per mantenere la massima sicurezza possibile per il trasferimento dei dati, Cloud Volumes Service supporta la crittografia del protocollo in uso con la crittografia SMB e NFS Kerberos 5p.</block>
  <block id="4fbbc372dd84225f54ba28f08d3ff4c7" category="admonition">Dual-Protocol è disponibile solo con CVS-Performance.</block>
  <block id="51f1eaeaea4deb044aabf0797f51c5c0" category="inline-link-macro">Segue: Nozioni di base sui protocolli NAS.</block>
  <block id="fcb7e93b14f588cd063c2c111732d865" category="paragraph"><block ref="fcb7e93b14f588cd063c2c111732d865" category="inline-link-macro-rx"></block></block>
  <block id="81e9930d895d3e301d9d41dffc998bf4" category="summary">Parte dell'affidabilità di una soluzione cloud è la comprensione dell'architettura e del modo in cui è protetta. In questa sezione vengono descritti diversi aspetti dell'architettura Cloud Volumes Service di Google per ridurre i potenziali problemi relativi alla protezione dei dati, nonché le aree in cui potrebbero essere necessarie ulteriori procedure di configurazione per ottenere un'implementazione più sicura.</block>
  <block id="cce1d49f67059a9bd1ae8d0bdb0c40c6" category="inline-link-macro">Precedente: Considerazioni sulla sicurezza e superfici di attacco.</block>
  <block id="64ff582fefc046b48708216a4686161c" category="paragraph"><block ref="64ff582fefc046b48708216a4686161c" category="inline-link-macro-rx"></block></block>
  <block id="e5a9d7217b1490853e4230120cdedb32" category="paragraph">L'architettura generale di Cloud Volumes Service può essere suddivisa in due componenti principali: Il piano di controllo e il piano dati.</block>
  <block id="650717c72d7a99e6505592f83821e4ed" category="section-title">Piano di controllo</block>
  <block id="b2b6e947ec64376b51417e89ab29e213" category="paragraph">Il piano di controllo di Cloud Volumes Service è l'infrastruttura di back-end gestita dagli amministratori Cloud Volumes Service e dal software di automazione nativo NetApp. Questo piano è completamente trasparente per gli utenti finali e include networking, hardware per lo storage, aggiornamenti software e così via per contribuire a fornire valore a una soluzione residente nel cloud come Cloud Volumes Service.</block>
  <block id="52a0e67f81bfbe486860a8219dfb3707" category="section-title">Piano dati</block>
  <block id="9d4d4fccf74cab21d8073077985a0cf6" category="paragraph">Il piano dati di Cloud Volumes Service include i volumi di dati effettivi e la configurazione generale di Cloud Volumes Service (ad esempio controllo degli accessi, autenticazione Kerberos e così via). Il data plane è interamente sotto il controllo degli utenti finali e dei consumatori della piattaforma Cloud Volumes Service.</block>
  <block id="099a80e29da5319c76116b6b2b41b2bf" category="paragraph">Esistono differenze distinte nel modo in cui ciascun piano viene protetto e gestito. Le seguenti sezioni illustrano queste differenze, a partire da una panoramica dell'architettura Cloud Volumes Service.</block>
  <block id="69259c19ec0d9503c7d352a664a85953" category="inline-link-macro">Avanti: Architettura Cloud Volumes Service.</block>
  <block id="06ef1ecb5da986ebfb9901831437a0d8" category="paragraph"><block ref="06ef1ecb5da986ebfb9901831437a0d8" category="inline-link-macro-rx"></block></block>
  <block id="13a2c7416db43025d8318ec9db325859" category="summary">I dati in transito possono essere crittografati a livello di protocollo NAS e la rete Google Cloud stessa viene crittografata, come descritto nelle sezioni seguenti.</block>
  <block id="f7ccd4455f141bba37dd989458bfd1f3" category="doc">Crittografia dei dati in transito</block>
  <block id="44782cad8de83a97138ea3bcbd36c028" category="inline-link-macro">Precedente: Architettura data plane.</block>
  <block id="9e17ee7c2f94201998bfd10292b5e098" category="paragraph"><block ref="9e17ee7c2f94201998bfd10292b5e098" category="inline-link-macro-rx"></block></block>
  <block id="8de1715de3864b137091fa8f6d71053f" category="section-title">Rete Google Cloud</block>
  <block id="a94ac9daf8e09a31f9e81f7de9ee7ab6" category="inline-link">Crittografia in transito</block>
  <block id="57d5b464e5bc1a25ae2337c72e492c88" category="paragraph">Google Cloud crittografa il traffico a livello di rete come descritto in<block ref="df3d10947a311abbd08a64a5cc9629d3" category="inline-link-rx"></block> Nella documentazione di Google. Come indicato nella sezione "architettura dei servizi cloud Volumes", Cloud Volumes Service viene fornito da un progetto di produttore PSA controllato da NetApp.</block>
  <block id="4322a5ae7fc781564c1349bf92846311" category="paragraph">Nel caso di CVS-SW, il tenant produttore esegue Google VM per fornire il servizio. Il traffico tra le macchine virtuali dell'utente e le macchine virtuali Cloud Volumes Service viene crittografato automaticamente da Google.</block>
  <block id="d3072f2789ba193441ddf485cc806a82" category="inline-link">Di crittografia IEEE 802.1AE (MACsec)</block>
  <block id="6141361c43c6e429fa93fd0f6f8b2dac" category="inline-link">incapsulamento</block>
  <block id="2a5cd9c0503b957ff28d59f12a8bb05a" category="paragraph">Sebbene il percorso dei dati per CVS-Performance non sia completamente crittografato sul layer di rete, NetApp e Google utilizzano una combinazione<block ref="83e770b09a2e800e59cae429b60dde07" category="inline-link-rx"></block>,<block ref="c5a2137e5d30663db35a2f990a0275f0" category="inline-link-rx"></block> (Crittografia dei dati) e reti con restrizioni fisiche per proteggere i dati in transito tra il tipo di servizio CVS-Performance di Cloud Volumes Service e Google Cloud.</block>
  <block id="7661437a0dea607fd6013193db5363be" category="paragraph">I protocolli NAS NFS e SMB forniscono una crittografia opzionale per il trasporto a livello di protocollo.</block>
  <block id="69c2cd6d510299a43f241a4afbeef373" category="paragraph"><block ref="ebb0763fea63f976f4d3ea586b6fe491" category="inline-link-rx"></block> Fornisce la crittografia end-to-end dei dati SMB e protegge i dati da eventi di intercettazione su reti non attendibili. È possibile attivare la crittografia sia per la connessione dati client/server (disponibile solo per i client compatibili con SMB3.x) che per l'autenticazione del server/controller di dominio.</block>
  <block id="a8c42b910beec902a232a69b59a37847" category="paragraph">Quando la crittografia SMB è attivata, i client che non supportano la crittografia non possono accedere alla condivisione.</block>
  <block id="72635a952bf12498ca4ca124b1a14d51" category="paragraph">Cloud Volumes Service supporta le crittografie di sicurezza RC4-HMAC, AES-128-CTS-HMAC-SHA1 e AES-256-CTS-HMAC-SHA1 per la crittografia SMB. SMB negozia con il tipo di crittografia più elevato supportato dal server.</block>
  <block id="980b28eb45b1ea66cdd07d05e78099a3" category="section-title">NFSv4.1 Kerberos</block>
  <block id="b97e4c9117cfcc0dd5d7a10e1a7a2631" category="inline-link">RFC7530</block>
  <block id="69a4f8e652e19cfdfb26e27d4447ae98" category="paragraph">Per NFSv4.1, CVS-Performance offre l'autenticazione Kerberos come descritto in<block ref="526af9c532c496dd16998f764e15dc87" category="inline-link-rx"></block>. È possibile attivare Kerberos in base al volume.</block>
  <block id="b2833929a77bd8c490997197ed3f00be" category="paragraph">Il tipo di crittografia attualmente più potente disponibile per Kerberos è AES-256-CTS-HMAC-SHA1. NetApp Cloud Volumes Service supporta AES-256-CTS-HMAC-SHA1, AES-128-CTS-HMAC-SHA1, DES3 e DES per NFS. Supporta anche ARCFOUR-HMAC (RC4) per il traffico CIFS/SMB, ma non per NFS.</block>
  <block id="59417c70dd426d4c6a1a81a09043bb7b" category="paragraph">Kerberos offre tre diversi livelli di sicurezza per i montaggi NFS, che offrono la possibilità di scegliere il livello di sicurezza Kerberos.</block>
  <block id="710c8a535ea62cee124026e31e71a5bd" category="inline-link">Opzioni di montaggio comuni</block>
  <block id="224b49d2f24ee42bbb73b2ca635c6d9a" category="paragraph">Come da RedHat<block ref="1849b335749f623c227052141b2e8b11" category="inline-link-rx"></block> documentazione:</block>
  <block id="babd6b3b4aea27ca41d56a231f2625af" category="paragraph">Di norma, più il livello di sicurezza Kerberos deve essere elevato, più le performance sono peggiori, in quanto client e server trascorrono del tempo a crittografare e decrittare le operazioni NFS per ogni pacchetto inviato. Molti client e server NFS supportano l'offload AES-NI sulle CPU per un'esperienza generale migliore, ma l'impatto delle performance di Kerberos 5p (crittografia completa end-to-end) è significativamente maggiore dell'impatto di Kerberos 5 (autenticazione dell'utente).</block>
  <block id="986c123032dbfdac18bc180d1a2c3562" category="paragraph">La seguente tabella mostra le differenze in termini di sicurezza e performance di ciascun livello.</block>
  <block id="f12149bd43eabe8557e021017cfb9b1f" category="cell">Livello di sicurezza</block>
  <block id="af75613ef5351b4f2563e49218c01d5b" category="cell">NFSv3: SIS</block>
  <block id="d65540b3d2f3c15e237b23f6d4d823e5" category="list-text">Meno sicuro; testo normale con ID utente/ID gruppo numerici</block>
  <block id="2310efb28386099d85b1dbcaf5f9c51f" category="list-text">In grado di visualizzare UID, GID, indirizzi IP client, percorsi di esportazione, nomi file, permessi nelle acquisizioni di pacchetti</block>
  <block id="07b50706d3894aa894686195ddeed426" category="list-text">Ideale per la maggior parte dei casi</block>
  <block id="54fcc149f825f18bfaaa374d6876e25a" category="cell">NFSv4.x: SIS</block>
  <block id="3777f761befcdc3f42a4d77cde2962fe" category="list-text">Più sicuro di NFSv3 (ID client, corrispondenza stringa nome/stringa di dominio) ma ancora testo normale</block>
  <block id="25199bb4f6f6a3eadd28c84579d0fcf7" category="list-text">Possibilità di visualizzare UID, GID, indirizzi IP client, stringhe di nomi, ID di dominio, percorsi di esportazione, nomi di file, permessi nelle acquisizioni di pacchetti</block>
  <block id="5145a8956e4807aeba5a7a4a1677c598" category="list-text">Ideale per carichi di lavoro sequenziali (come macchine virtuali, database, file di grandi dimensioni)</block>
  <block id="bc96a40b0174b0ec2f9133e1e704d7cb" category="list-text">Cattivo con elevato numero di file/metadati elevati (30-50% peggiore)</block>
  <block id="f25baf1a23f237c73f28b4834def4161" category="cell">NFS: Krb5</block>
  <block id="0661ead41dc806181d0a0bff696e49df" category="list-text">Crittografia Kerberos per le credenziali in ogni pacchetto NFS: Esegue il wrapping di UID/GID di utenti/gruppi nelle chiamate RPC nel wrapper GSS</block>
  <block id="b012a8b71e44e4c118c2a97f94c11c1f" category="list-text">L'utente che richiede l'accesso al montaggio deve disporre di un ticket Kerberos valido (tramite nome utente/password o scambio manuale della scheda della chiave); il ticket scade dopo un periodo di tempo specificato e l'utente deve eseguire nuovamente l'autenticazione per l'accesso</block>
  <block id="ab2293d06a9e3594a17eb02b827c471a" category="list-text">Nessuna crittografia per le operazioni NFS o i protocolli ausiliari come mount/portmapper/nlm (possono vedere percorsi di esportazione, indirizzi IP, handle di file, permessi, nomi di file, atime/mtime in pacchetti capture)</block>
  <block id="6d140d250a49ec533ff2211674c16138" category="list-text">Migliore nella maggior parte dei casi per Kerberos; peggiore di AUTH_SYS</block>
  <block id="bc578f6162e4255fe0d1d4445ec8d975" category="cell">NFS: Krb5i</block>
  <block id="7886fbf427a34b659783d690ee4ad3dd" category="list-text">L'utente che richiede l'accesso al montaggio deve disporre di un ticket Kerberos valido (tramite nome utente/password o scambio manuale della scheda delle chiavi); il ticket scade dopo un periodo di tempo specificato e l'utente deve eseguire nuovamente l'autenticazione per l'accesso</block>
  <block id="49d02d7e5db8eb8139c3777891f63e2e" category="list-text">Il checksum GSS Kerberos viene aggiunto a ogni pacchetto per garantire che nulla intercetti i pacchetti. Se i checksum corrispondono, è consentita la conversazione.</block>
  <block id="0ea3431437c971e8ac8f271b60694b38" category="list-text">Meglio di krb5p perché il payload NFS non è crittografato; solo l'overhead aggiunto rispetto a krb5 è il checksum di integrità. Le performance di krb5i non saranno molto peggiori di krb5, ma si verificherà un certo degrado.</block>
  <block id="facbd78bc28fa0b36f521d74ff5f0cec" category="cell">NFS: Krb5p</block>
  <block id="d11093694c8bd1d8897446e4cf645e48" category="list-text">L'utente che richiede l'accesso al montaggio deve disporre di un ticket Kerberos valido (tramite nome utente/password o scambio manuale di keytab); il ticket scade dopo il periodo di tempo specificato e l'utente deve eseguire nuovamente l'autenticazione per l'accesso</block>
  <block id="29af1c9e08784f1ef0e42433aef21eee" category="list-text">Tutti i payload dei pacchetti NFS sono crittografati con il wrapper GSS (non è possibile visualizzare handle di file, permessi, nomi di file, atime/mtime nelle acquisizioni di pacchetti).</block>
  <block id="70aa40903816c1fda65618ae32c56d8b" category="list-text">Include il controllo dell'integrità.</block>
  <block id="3e7dfd7567a414307d5fe93ea83ce4f6" category="list-text">Il tipo di operazione NFS è visibile (FSINFO, ACCESS, GETATTR e così via).</block>
  <block id="6b375be1f905197ba21c586647e973f4" category="list-text">I protocolli ausiliari (mount, portmap, nlm e così via) non sono crittografati (possono vedere percorsi di esportazione, indirizzi IP)</block>
  <block id="6de6f14759a24d6fcb16973384e01c00" category="list-text">Performance peggiori dei livelli di sicurezza; krb5p deve crittografare/decrittare di più.</block>
  <block id="6640e7cef3ca860543c49a5125ba4c5a" category="list-text">Performance migliori rispetto a krb5p con NFSv4.x per carichi di lavoro con elevato numero di file.</block>
  <block id="abac32415b4bfbaf4765dec9d36149cd" category="paragraph">In Cloud Volumes Service, un server Active Directory configurato viene utilizzato come server Kerberos e server LDAP (per cercare le identità degli utenti da uno schema compatibile con RFC2307). Non sono supportati altri server Kerberos o LDAP. NetApp consiglia vivamente di utilizzare LDAP per la gestione delle identità in Cloud Volumes Service. Per informazioni su come NFS Kerberos viene mostrato nelle acquisizioni di pacchetti, consulta la sezione <block ref="e06a781bd551a4c8ed55a5dfd008a50c" category="inline-link-macro-rx"></block></block>
  <block id="656b94b95418723e2acea6b86dc53e48" category="inline-link-macro">Avanti: Crittografia dei dati a riposo.</block>
  <block id="6ca1480f90da15333bae5670283ea19f" category="paragraph"><block ref="6ca1480f90da15333bae5670283ea19f" category="inline-link-macro-rx"></block></block>
  <block id="d1a7050a3a677e1c229160462a179103" category="doc">Informazioni aggiuntive, cronologia delle versioni e informazioni di contatto</block>
  <block id="b67313323e9670f2b3cc78a36af15174" category="inline-link-macro">Precedente: Operazione di servizio.</block>
  <block id="5390c35bfa9dd0545fb51b84c8af3252" category="paragraph"><block ref="5390c35bfa9dd0545fb51b84c8af3252" category="inline-link-macro-rx"></block></block>
  <block id="4780631a0451a6605045de3ace692cc6" category="list-text">Documentazione Google Cloud per Cloud Volumes Service</block>
  <block id="6e0173c8a46418c9ee6c916c7c275ef8" category="inline-link"><block ref="6e0173c8a46418c9ee6c916c7c275ef8" category="inline-link-rx"></block></block>
  <block id="8e65fc49f8ebbf3d9cc9651ce7940654" category="paragraph"><block ref="8e65fc49f8ebbf3d9cc9651ce7940654" category="inline-link-rx"></block></block>
  <block id="0e8aec42089c0c73812fa42d1888b3c8" category="list-text">Accesso al servizio privato di Google</block>
  <block id="75956b9ee748b806549eeec3c9a81192" category="inline-link"><block ref="75956b9ee748b806549eeec3c9a81192" category="inline-link-rx"></block></block>
  <block id="6c84917a571a2282fd9fb2a6f058a11e" category="paragraph"><block ref="6c84917a571a2282fd9fb2a6f058a11e" category="inline-link-rx"></block></block>
  <block id="f670e58416e680d41a98914939ff8b4d" category="list-text">Programma del modulo di convalida crittografica: NetApp CryptoMod</block>
  <block id="904728949094c548bcec2129979a28a6" category="inline-link"><block ref="904728949094c548bcec2129979a28a6" category="inline-link-rx"></block></block>
  <block id="50dc6dd0a76419597a78231ee45ad7f5" category="paragraph"><block ref="50dc6dd0a76419597a78231ee45ad7f5" category="inline-link-rx"></block></block>
  <block id="fb35bc32af8e0bce21ef22bad9052b39" category="inline-link"><block ref="0ea855bd074e3e4be70d90c120079c12" category="inline-link-rx"></block></block>
  <block id="56f0874ab11ee024b4419753f2a3f06f" category="paragraph"><block ref="801eea2aa1601f12cc3d53d718ad33a7" category="inline-link-rx"></block></block>
  <block id="61eb0e8494826dc8f30af9122fd97664" category="list-text">TR-4616: NFS Kerberos in ONTAP</block>
  <block id="ed78f5221deba5e60a950d28a62de702" category="inline-link"><block ref="ed78f5221deba5e60a950d28a62de702" category="inline-link-rx"></block></block>
  <block id="d677acd46c811ecd9bac37aa26d8668c" category="paragraph"><block ref="d677acd46c811ecd9bac37aa26d8668c" category="inline-link-rx"></block></block>
  <block id="1bebe65011b1928d45d041533c04d2b1" category="paragraph">Facci sapere come possiamo migliorare questo report tecnico.</block>
  <block id="8b1418ea0c579605e873907335ca62c7" category="paragraph">Contattaci all'indirizzo mailto:doccomments@netapp.com[doccomments@netapp.com^]. Includere IL REPORT TECNICO 4918 nell'oggetto.</block>
  <block id="402d245fd6f48d88ea661814c622456e" category="summary">I protocolli NAS consentono a più client su una rete di accedere agli stessi dati su un sistema storage, ad esempio Cloud Volumes Service su GCP. NFS e SMB sono i protocolli NAS definiti e operano su base client/server, dove Cloud Volumes Service agisce come server.</block>
  <block id="900608117b1be22303e2a172c6d9b280" category="doc">Nozioni di base sui protocolli NAS</block>
  <block id="d23b6e095547133ec383cdcb0f080e6e" category="inline-link-macro">Precedente: Panoramica dei protocolli NAS.</block>
  <block id="8de032a7ba389eddc7880273654515a6" category="paragraph"><block ref="8de032a7ba389eddc7880273654515a6" category="inline-link-macro-rx"></block></block>
  <block id="b03874a8574793b2c634d05da5dae732" category="paragraph">I protocolli NAS consentono a più client su una rete di accedere agli stessi dati su un sistema storage, ad esempio Cloud Volumes Service su GCP. NFS e SMB sono i protocolli NAS definiti e operano su base client/server, dove Cloud Volumes Service agisce come server. I client inviano al server richieste di accesso, lettura e scrittura e il server è responsabile del coordinamento dei meccanismi di blocco dei file, dell'archiviazione delle autorizzazioni e della gestione delle richieste di identità e autenticazione.</block>
  <block id="86a29faa66a25c7e3fd290cf1e53761c" category="paragraph">Ad esempio, se un client NAS desidera creare un nuovo file in una cartella, viene seguita la seguente procedura generale.</block>
  <block id="817aaff54aa6b5cd0e96c54c0b20ea1d" category="list-text">Il client richiede al server informazioni sulla directory (permessi, proprietario, gruppo, ID file, spazio disponibile, e così via); il server risponde con le informazioni se il client richiedente e l'utente hanno le autorizzazioni necessarie sulla cartella padre.</block>
  <block id="9ec40c2869366ebe8cf1a8c690bb6471" category="list-text">Se le autorizzazioni sulla directory consentono l'accesso, il client chiede al server se il nome del file creato esiste già nel file system. Se il nome del file è già in uso, la creazione non riesce. Se il nome del file non esiste, il server comunica al client che può procedere.</block>
  <block id="83a9d09522edde42d016b5f2649ad9b6" category="list-text">Il client invia una chiamata al server per creare il file con l'handle di directory e il nome del file e imposta l'accesso e i tempi di modifica. Il server invia un ID file univoco al file per assicurarsi che non vengano creati altri file con lo stesso ID.</block>
  <block id="4884742626257d3e2fee8f3fa6d74f9c" category="list-text">Il client invia una chiamata per controllare gli attributi del file prima dell'operazione DI SCRITTURA. Se le autorizzazioni lo consentono, il client scrive il nuovo file. Se il protocollo/applicazione utilizza il blocco, il client richiede al server un blocco per impedire ad altri client di accedere al file mentre sono bloccati per evitare il danneggiamento dei dati.</block>
  <block id="9f36fd781ab1b50b7d007cb7bbd31f1f" category="inline-link-macro">Avanti: NFS.</block>
  <block id="e120d5e9a70a32a053802947c9767294" category="paragraph"><block ref="e120d5e9a70a32a053802947c9767294" category="inline-link-macro-rx"></block></block>
  <block id="9dfacef1e7d01943a3363c481a0ab54f" category="summary">Cloud Volumes Service per Google Cloud sfrutta il framework di accesso ai servizi privati di Google Cloud. In questo framework, gli utenti possono connettersi a Cloud Volumes Service. Questo framework utilizza i costrutti di peering di Service Networking e VPC come altri servizi Google Cloud, garantendo un isolamento completo tra i tenant.</block>
  <block id="65d49b550fb0a0afd0ad601dc275ea12" category="doc">Architettura del data plane</block>
  <block id="bbabe197f6618c2911a8ad624a658a46" category="inline-link-macro">Precedente: Architettura del piano di controllo.</block>
  <block id="dfb92e74bf9227851402850c5c488e3c" category="paragraph"><block ref="dfb92e74bf9227851402850c5c488e3c" category="inline-link-macro-rx"></block></block>
  <block id="57e0a1cde7582cc59173756aff450054" category="paragraph">Cloud Volumes Service per Google Cloud sfrutta Google Cloud<block ref="466f20229cc0e1fa2efa2b4b45528417" category="inline-link-rx"></block> framework. In questo framework, gli utenti possono connettersi a Cloud Volumes Service. Questo framework utilizza i costrutti di peering di Service Networking e VPC come altri servizi Google Cloud, garantendo un isolamento completo tra i tenant.</block>
  <block id="fabc0e878e19ad7e95bb8e906ab9e8a1" category="inline-link">Architettura per Cloud Volumes Service</block>
  <block id="81001e33ae42635e6a292ced69cda439" category="paragraph">Per una panoramica dell'architettura di Cloud Volumes Service per Google Cloud, consulta<block ref="7e96ff285aa6f06b814f61dc37a8da61" category="inline-link-rx"></block>.</block>
  <block id="dcfa6d27a1891efb4ad8492d3a127b28" category="paragraph">Le VPC degli utenti (standalone o condiviso) vengono collegate ai VPC all'interno dei progetti di tenant gestiti da Cloud Volumes Service, che ospitano i volumi.</block>
  <block id="fcf4e9439b20c7a36f8ee4116fd5bc6d" category="paragraph"><block ref="fcf4e9439b20c7a36f8ee4116fd5bc6d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e3d4716c5a2ddac5bbd6a03d58d03af" category="paragraph">La figura precedente mostra un progetto (il progetto consumer CVS al centro) con tre reti VPC collegate a Cloud Volumes Service e più macchine virtuali del motore di calcolo (GCE1-7) che condividono volumi:</block>
  <block id="fbf1e8aceed7750d8ed8c4e7168cdb02" category="list-text">VPC1 consente a GCE1 di accedere ai volumi A e B.</block>
  <block id="dc5d4ca9052ec8ea299a69ef985a32b0" category="list-text">VPC2 consente a GCE2 e GCE4 di accedere al volume C.</block>
  <block id="3274f78cc9286288af4912642932b72e" category="list-text">La terza rete VPC è un VPC condiviso, condiviso con due progetti di servizio. Consente a GCE3, GCE4, GCE5 e GCE6 di accedere ai volumi D ed E. Le reti VPC condivise sono supportate solo per volumi del tipo di servizio CVS-Performance.</block>
  <block id="be3759e5f4a6574585df9e1159c20c30" category="admonition">GCE7 non può accedere ad alcun volume.</block>
  <block id="597134b02aeec788dec5f24fa0adba89" category="paragraph">I dati possono essere crittografati sia in transito (utilizzando la crittografia Kerberos e/o SMB) che a riposo in Cloud Volumes Service.</block>
  <block id="f8426b7150021bc2586e9c150051a408" category="inline-link-macro">Avanti: Crittografia dei dati in transito.</block>
  <block id="39148875a23c5a4ea00752d82ac14b14" category="paragraph"><block ref="39148875a23c5a4ea00752d82ac14b14" category="inline-link-macro-rx"></block></block>
  <block id="4a3327b1b286d1e67b6b26ccadab7e11" category="paragraph">Contattaci all'indirizzo mailto:doccomments@netapp.com[doccomments@netapp.com^]. Includere IL REPORT TECNICO 4918 nell'oggetto.</block>
  <block id="432be93985cd954e5f755048381e528d" category="summary">NFS è un protocollo di file system distribuito che è uno standard IETF aperto definito in Request for Comments (RFC) che consente a chiunque di implementare il protocollo.</block>
  <block id="ba3cb198ccc0137ff2861f85eff2b3ce" category="inline-link-macro">Precedente: Nozioni di base dei protocolli NAS_Overview.</block>
  <block id="2be8e5e3e57aed02dfb62a58afdadfad" category="paragraph"><block ref="2be8e5e3e57aed02dfb62a58afdadfad" category="inline-link-macro-rx"></block></block>
  <block id="b53dfc952aa9d99343d94971cf6c3fee" category="paragraph">I volumi in Cloud Volumes Service vengono condivisi ai client NFS esportando un percorso accessibile a un client o a un set di client. Le autorizzazioni per montare queste esportazioni sono definite da policy e regole di esportazione, configurabili dagli amministratori di Cloud Volumes Service.</block>
  <block id="0e3cb63bde3f98dbd812d470d8b100cf" category="paragraph">L'implementazione NetApp NFS è considerata uno standard di riferimento per il protocollo e viene utilizzata in innumerevoli ambienti NAS aziendali. Le sezioni seguenti illustrano NFS e le funzionalità di sicurezza specifiche disponibili in Cloud Volumes Service e le relative modalità di implementazione.</block>
  <block id="8b575afc20d2914501471190a68364ed" category="section-title">Utenti e gruppi UNIX locali predefiniti</block>
  <block id="c9f0864944a97085b2897c473c91dccc" category="paragraph">Cloud Volumes Service contiene diversi utenti e gruppi UNIX predefiniti per varie funzionalità di base. Questi utenti e gruppi non possono essere modificati o cancellati. Non è possibile aggiungere nuovi utenti e gruppi locali a Cloud Volumes Service. Gli utenti e i gruppi UNIX al di fuori degli utenti e dei gruppi predefiniti devono essere forniti da un name service LDAP esterno.</block>
  <block id="8002bcf6ec4e483483e32633f99bee00" category="paragraph">La seguente tabella mostra gli utenti e i gruppi predefiniti e i relativi ID numerici. NetApp consiglia di non creare nuovi utenti o gruppi in LDAP o sui client locali che riutilizzano questi ID numerici.</block>
  <block id="0346306b31bbb7a0ae5245da13ec03c4" category="cell">Utenti predefiniti: ID numerici</block>
  <block id="c782adef8851cb8855543f329d548bb2" category="cell">Gruppi predefiniti: ID numerici</block>
  <block id="a38b2868ff594195dcec8e7fe562b0be" category="list-text">root:0</block>
  <block id="44b4512252320c293616b69743e2a445" category="list-text">pcuser:65534</block>
  <block id="95312f9502cf30aaff5cbbd3a4585a68" category="list-text">nessuno:65535</block>
  <block id="39fff4671c3793536f3df78e41aed899" category="list-text">demone:1</block>
  <block id="ffe991bd5946c28affb0a08326a88c3f" category="admonition">Quando si utilizza NFSv4.1, l'utente root potrebbe essere visualizzato come nessuno quando si eseguono comandi di elenco di directory sui client NFS. Ciò è dovuto alla configurazione del mapping del dominio ID del client. Vedere la sezione chiamata <block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block> per informazioni dettagliate su questo problema e su come risolverlo.</block>
  <block id="97d69dfca64d2bd85ec6cc9736cd662b" category="section-title">L'utente root</block>
  <block id="767a04b899f673915ec8d6d78f549f3b" category="paragraph">In Linux, l'account root ha accesso a tutti i comandi, file e cartelle in un file system basato su Linux. A causa della potenza di questo account, le Best practice di sicurezza spesso richiedono che l'utente root sia disattivato o limitato in qualche modo. Nelle esportazioni NFS, il potere di un utente root sui file e sulle cartelle può essere controllato in Cloud Volumes Service attraverso policy e regole di esportazione e un concetto noto come root squash.</block>
  <block id="7cd60419657f1f0735c557afd44724f0" category="inline-link">comandi setuid/setgid (il bit adesivo)</block>
  <block id="b95ee7e499b2b5ee7f9c911c9c86f8a2" category="paragraph">Lo squashing root garantisce che l'utente root che accede a un montaggio NFS venga bloccato dall'utente numerico anonimo 65534 (vedere la sezione "<block ref="07a7b24bc0f7cda943dc05060d1188d8" category="inline-xref-macro-rx"></block>") ed è attualmente disponibile solo quando si utilizza CVS-Performance selezionando Off per l'accesso root durante la creazione della regola dei criteri di esportazione. Se l'utente root viene bloccato nell'utente anonimo, non ha più accesso per eseguire chown o.<block ref="451ac5d05b7e3e41db0c92126d9290ad" category="inline-link-rx"></block> Su file o cartelle nel montaggio NFS, e i file o le cartelle creati dall'utente root mostrano l'UID anon come proprietario/gruppo. Inoltre, gli ACL NFSv4 non possono essere modificati dall'utente root. Tuttavia, l'utente root ha ancora accesso a chmod e ha eliminato i file per i quali non dispone di permessi espliciti. Se si desidera limitare l'accesso ai permessi di file e cartelle di un utente root, si consiglia di utilizzare un volume con ACL NTFS, creando un utente Windows denominato<block ref="63a9f0ea7bb98050796b649e85481845" prefix=" " category="inline-code"></block>e applicando le autorizzazioni desiderate ai file o alle cartelle.</block>
  <block id="0b2cc4ee83c7e73e4426e294c95be2c7" category="section-title">L'utente anonimo</block>
  <block id="f489703ccadc6e9616bab479ace6cf03" category="paragraph">L'ID utente anonimo (anon) specifica un ID utente o un nome utente UNIX mappato alle richieste del client che arrivano senza credenziali NFS valide. Questo può includere l'utente root quando viene utilizzato lo squashing root. L'utente anon in Cloud Volumes Service è 65534.</block>
  <block id="48da046d67add0ab58d9cbc2c2da421c" category="paragraph">Questo UID è normalmente associato al nome utente<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> oppure<block ref="3ff01acd436943ffc00e90a99dd4f83e" prefix=" " category="inline-code"></block> Negli ambienti Linux. Cloud Volumes Service utilizza anche 65534 come utente UNIX locale` pcuser` (vedere la sezione "<block ref="21f1cd16f2baec63c7c604945762d1f2" category="inline-xref-macro-rx"></block>"), che è anche l'utente di fallback predefinito per le mappature dei nomi da Windows a UNIX quando non è possibile trovare un utente UNIX valido corrispondente in LDAP.</block>
  <block id="1a64786b80a72f5b468ee5a6c27c19bb" category="paragraph">A causa delle differenze nei nomi utente di Linux e Cloud Volumes Service per UID 65534, la stringa del nome per gli utenti mappati a 65534 potrebbe non corrispondere quando si utilizza NFSv4.1. Di conseguenza, potresti vedere<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> come utente di alcuni file e cartelle. Vedere la sezione "<block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block>" per informazioni su questo problema e su come risolverlo.</block>
  <block id="093b885796f6b6edbf133d153a574ee0" category="section-title">Controllo degli accessi/esportazioni</block>
  <block id="c40a72feaf9e622dcbd1a55edff6fdbf" category="paragraph">L'accesso iniziale all'esportazione/condivisione per i montaggi NFS è controllato attraverso regole di policy di esportazione basate su host contenute in una policy di esportazione. Viene definito un IP host, un nome host, una subnet, un netgroup o un dominio per consentire l'accesso per montare la condivisione NFS e il livello di accesso consentito all'host. Le opzioni di configurazione delle regole dei criteri di esportazione dipendono dal livello Cloud Volumes Service.</block>
  <block id="519377bf4a5b0a2078c3d66b249040aa" category="paragraph">Per CVS-SW, sono disponibili le seguenti opzioni per la configurazione dei criteri di esportazione:</block>
  <block id="fdbbd602d808015eb2f536ce2add5b6e" category="list-text">*Corrispondenza client.* elenco separato da virgole di indirizzi IP, elenco separato da virgole di nomi host, subnet, netgroup, nomi di dominio.</block>
  <block id="fb467c38c5af2ca41ea3f09fe535144d" category="list-text">*RO/RW access rules.* selezionare Read/write o Read only per controllare il livello di accesso all'esportazione.CVS-Performance offre le seguenti opzioni:</block>
  <block id="4984ee657e0bd2919476369a84dfe159" category="list-text">*RO/RW access rules.* selezionare Read/write o Read only per controllare il livello di accesso all'esportazione.</block>
  <block id="3a3236a433ddc1bb46fe40e058aad584" category="list-text">*Root access (on/off).* configura root squash (vedere la sezione "<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>" per ulteriori informazioni).</block>
  <block id="0c1b0b2a02124e4f1e2111f36d28432e" category="list-text">*Protocol type.* (tipo di protocollo): Limita l'accesso al montaggio NFS a una versione specifica del protocollo. Quando si specificano NFSv3 e NFSv4.1 per il volume, lasciare entrambe le caselle vuote o selezionare entrambe le caselle.</block>
  <block id="553de93bd85985676f0ef4762f4de2ab" category="list-text">*Livello di sicurezza Kerberos (quando si seleziona Enable Kerberos).* fornisce le opzioni krb5, krb5i e/o krb5p per l'accesso in sola lettura o in lettura/scrittura.</block>
  <block id="a98abf6af551f8564e89efb200e37032" category="section-title">Modifica proprietà (chown) e gruppo di cambiamento (chgrp)</block>
  <block id="545978eda72a981e986a37d84621575d" category="paragraph">NFS su Cloud Volumes Service consente solo all'utente root di eseguire chown/chgrp su file e cartelle. Altri utenti visualizzano un<block ref="7627e13d3e1910d7f604aa77914613da" prefix=" " category="inline-code"></block> errore: anche sui file di loro proprietà. Se si utilizza il root squash (come descritto nella sezione "<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>"), la root viene bloccata in un utente non root e non è consentito l'accesso a chown e chgrp. Attualmente non esistono soluzioni alternative in Cloud Volumes Service per consentire chown e chgrp agli utenti non root. Se sono necessarie modifiche alla proprietà, prendere in considerazione l'utilizzo di volumi a doppio protocollo e impostare lo stile di protezione su NTFS per controllare le autorizzazioni dal lato Windows.</block>
  <block id="b40637b973f7941123dacf09ceef0fba" category="section-title">Gestione delle autorizzazioni</block>
  <block id="b48f3521890100492cddc30349f6e7b2" category="paragraph">Cloud Volumes Service supporta entrambi i bit di modalità (come 644, 777 e così via per rwx) e gli ACL NFSv4.1 per controllare le autorizzazioni sui client NFS per i volumi che utilizzano lo stile di sicurezza UNIX. La gestione dei permessi standard viene utilizzata per questi (come chmod, chown o nfs4_setfacl) e funziona con qualsiasi client Linux che li supporti.</block>
  <block id="a4f4a04396f203764eb677e59aeea059" category="paragraph">Inoltre, quando si utilizzano volumi a doppio protocollo impostati su NTFS, i client NFS possono sfruttare la mappatura dei nomi Cloud Volumes Service per gli utenti Windows, che vengono poi utilizzati per risolvere le autorizzazioni NTFS. Questo richiede una connessione LDAP a Cloud Volumes Service per fornire traduzioni da ID numerico a nome utente, in quanto Cloud Volumes Service richiede un nome utente UNIX valido per eseguire correttamente il mapping a un nome utente Windows.</block>
  <block id="40c93306b7b5fa43d5bdeaaf6446b5c8" category="section-title">Fornitura di ACL granulari per NFSv3</block>
  <block id="38244b1450366af1bc12c6d85adcf6d2" category="paragraph">Le autorizzazioni di bit di modalità coprono solo proprietario, gruppo e tutti gli altri membri della semantica, il che significa che non esistono controlli granulari degli accessi utente per NFSv3 di base. Cloud Volumes Service non supporta gli ACL POSIX, né gli attributi estesi (come chattr), pertanto gli ACL granulari sono possibili solo nei seguenti scenari con NFSv3:</block>
  <block id="15ad8d0b9866344d62ea9ffa4ae25982" category="list-text">Volumi di sicurezza NTFS (server CIFS richiesto) con mappature valide da UNIX a utenti Windows.</block>
  <block id="c14f9a108935fe84b2ee2c80664062d4" category="list-text">Gli ACL NFSv4.1 vengono applicati utilizzando un client di amministrazione che monta NFSv4.1 per applicare gli ACL.</block>
  <block id="b90aebde70afe18a23fa55cafb7bd6e7" category="inline-link-macro">"LDAP"</block>
  <block id="fc96ac54908c774cd60159cf8c65272e" category="paragraph">Entrambi i metodi richiedono una connessione LDAP per la gestione delle identità UNIX e un utente UNIX valido e informazioni di gruppo compilate (vedere la sezione <block ref="941c88f858b9781fbfe78651e071df70" category="inline-link-macro-rx"></block>) E sono disponibili solo con istanze CVS-Performance. Per utilizzare i volumi di sicurezza NTFS con NFS, è necessario utilizzare il protocollo doppio (SMB e NFSv3) o il protocollo doppio (SMB e NFSv4.1), anche se non vengono effettuate connessioni SMB. Per utilizzare gli ACL NFSv4.1 con i montaggi NFSv3, selezionare<block ref="3e8ec25076adc34554202fd2df86b9b4" prefix=" " category="inline-code"></block> come tipo di protocollo.</block>
  <block id="b9fd9ad6fc3c3b72bb1d8b9db35c4ff8" category="inline-link">Nfs4_acl - elenchi di controllo degli accessi NFSv4</block>
  <block id="8454ec39d80a4c7dced33aed7bc5cc3c" category="paragraph">I bit in modalità UNIX standard non forniscono lo stesso livello di granularità delle autorizzazioni fornite dagli ACL NTFS o NFSv4.x. La tabella seguente confronta la granularità delle autorizzazioni tra i bit di modalità NFSv3 e gli ACL NFSv4.1. Per informazioni sugli ACL NFSv4.1, vedere<block ref="6f8990d4da30b2d9c1096f2d7fdec422" category="inline-link-rx"></block>.</block>
  <block id="04bf6ba29148b02f9bc0aece8b1ab976" category="cell">Bit di modalità NFSv3</block>
  <block id="ec969632045eaebe3e92b63bc00edf03" category="cell">ACL NFSv4.1</block>
  <block id="b7073329ceba059aa3ad7875190c661f" category="list-text">Impostare l'ID utente all'esecuzione</block>
  <block id="573fa671705c50ff1c121cd141dfeb90" category="list-text">Impostare l'ID del gruppo all'esecuzione</block>
  <block id="0ab8eb5c98bf5a8e01cc9dc03065fd63" category="list-text">Salva testo scambiato (non definito in POSIX)</block>
  <block id="78e3e57905e586d5d03519b5883d9b49" category="list-text">Permesso di lettura per il proprietario</block>
  <block id="07ea3a6ddfd17ab896abc34a5fb98c32" category="list-text">Permesso di scrittura per il proprietario</block>
  <block id="ef1c725ac00a8daafb96e6f926b38e84" category="list-text">Autorizzazione di esecuzione per il proprietario di un file o autorizzazione di ricerca per il proprietario nella directory</block>
  <block id="d51cc2a74a686e9f6b08108c215a677e" category="list-text">Permesso di lettura per il gruppo</block>
  <block id="6750a7dbc586cfe9c3c1e6fc348bc47f" category="list-text">Permesso di scrittura per il gruppo</block>
  <block id="66471165b6102256624c1aaa1bf05ef9" category="list-text">Autorizzazione di esecuzione per il gruppo su un file o autorizzazione di ricerca (ricerca) per il gruppo nella directory</block>
  <block id="860c8444d0dfe3bf1e1818fdbe8c3733" category="list-text">Permesso di lettura per altri</block>
  <block id="95663f359ae8aaa2910488b36c7168fb" category="list-text">Permesso di scrittura per altri</block>
  <block id="54384d9f12231abb228dd692b2c7a689" category="list-text">Autorizzazione di esecuzione per altri utenti su un file o autorizzazione di ricerca per altri utenti nella directory</block>
  <block id="4d6deb7613496d18f12d0d0d0fe84ecb" category="paragraph">Tipi di voci di controllo di accesso (ACE) (Allow/Nega/Audit) * flag di ereditarietà * eredità di directory * eredità di file * nessuna propagazione-eredita * eredita-solo</block>
  <block id="13640bb94453faf76256f49439337e2e" category="paragraph">Permessi * Read-data (file) / list-directory (directory) * write-data (file) / create-file (directory) * append-data (file) / create-subdirectory (directory) * execute (file) / change-directory (directory) * delete * delete-child * Read-attribute * write-attribute * Read-named-attribute * write-named * Read-ACL *-synchronize *-owner *-synchronize * -ACL *-synchronize *-lire</block>
  <block id="0bfe97b6a2010bf8a46c30c256d9bc67" category="paragraph">Infine, l'appartenenza al gruppo NFS (sia in NFSv3 che IN NFSV4.x) è limitata a un massimo predefinito di 16 per AUTH_SYS in base ai limiti dei pacchetti RPC. NFS Kerberos fornisce fino a 32 gruppi e gli ACL NFSv4 eliminano la limitazione attraverso ACL granulari di utenti e gruppi (fino a 1024 voci per ACE).</block>
  <block id="27aabeb671232f388e6288cf9395fda9" category="inline-link">Creazione e gestione di volumi NFS</block>
  <block id="b42b7de139bf4398a5d4b048ecf30c9f" category="paragraph">Inoltre, Cloud Volumes Service offre un supporto esteso per gruppi per estendere il numero massimo di gruppi supportati fino a 32. Questa operazione richiede una connessione LDAP a un server LDAP che contenga identità di gruppo e utenti UNIX valide. Per ulteriori informazioni sulla configurazione, vedere<block ref="744e76592290230cb7381c9b8a5414da" category="inline-link-rx"></block> Nella documentazione di Google.</block>
  <block id="75812520c9040a205064d0d2cb2263e9" category="section-title">ID utente e gruppo NFSv3</block>
  <block id="b1695eaaf5db3491be45228e42d7894f" category="paragraph">Gli ID utente e di gruppo NFSv3 vengono trasmessi in rete come ID numerici anziché come nomi. Cloud Volumes Service non risolve i nomi utente per questi ID numerici con NFSv3, con volumi di sicurezza UNIX che utilizzano solo i bit di modalità. Quando sono presenti ACL NFSv4.1, per risolvere correttamente l'ACL è necessario eseguire una ricerca di ID numerici e/o stringhe di nomi, anche quando si utilizza NFSv3. Con i volumi di sicurezza NTFS, Cloud Volumes Service deve risolvere un ID numerico a un utente UNIX valido e quindi eseguire il mapping a un utente Windows valido per negoziare i diritti di accesso.</block>
  <block id="c88acee1e86a1d4e088392362c04bb3b" category="section-title">Limitazioni di sicurezza degli ID utente e di gruppo NFSv3</block>
  <block id="51d0cb09f5edabf17b3490e1b53d7b22" category="paragraph">Con NFSv3, il client e il server non devono mai confermare che l'utente che tenta una lettura o una scrittura con un ID numerico sia un utente valido; è semplicemente implicitamente attendibile. In questo modo, il file system si apre a potenziali violazioni semplicemente eseguendo lo spoofing di qualsiasi ID numerico. Per evitare falle di sicurezza come questa, sono disponibili alcune opzioni per Cloud Volumes Service.</block>
  <block id="467b69ba310f54b371bbdbffe09e6497" category="list-text">L'implementazione di Kerberos per NFS obbliga gli utenti ad autenticarsi con un nome utente e una password o un file keytab per ottenere un ticket Kerberos per consentire l'accesso a un mount. Kerberos è disponibile con istanze CVS-Performance e solo con NFSv4.1.</block>
  <block id="9120b024c7fefc321f0ebc6fee670c59" category="list-text">La limitazione dell'elenco di host nelle regole dei criteri di esportazione limita i client NFSv3 che hanno accesso al volume Cloud Volumes Service.</block>
  <block id="1b652183dcffb7bab733d50929de6844" category="list-text">L'utilizzo di volumi a doppio protocollo e l'applicazione di ACL NTFS al volume obbliga i client NFSv3 a risolvere gli ID numerici dei nomi utente UNIX validi per autenticarsi correttamente per accedere ai montaggi. Ciò richiede l'abilitazione di LDAP e la configurazione delle identità di utenti e gruppi UNIX.</block>
  <block id="8d5c591e079f79f63fd9e9807dc0f747" category="list-text">Lo squashing dell'utente root limita i danni che un utente root può fare a un montaggio NFS, ma non rimuove completamente i rischi. Per ulteriori informazioni, vedere la sezione "<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>."</block>
  <block id="2013c75e17676506ba3c06142530277a" category="paragraph">In ultima analisi, la sicurezza NFS è limitata alla versione del protocollo in uso. NFSv3, pur essendo più performante in generale rispetto a NFSv4.1, non fornisce lo stesso livello di sicurezza.</block>
  <block id="1d9f0263509a5bc0f447962105bb1a92" category="paragraph">NFSv4.1 offre maggiore sicurezza e affidabilità rispetto a NFSv3, per i seguenti motivi:</block>
  <block id="11d0cb4a0817a571de35b1a57bcd7b86" category="list-text">Blocco integrato attraverso un meccanismo basato sul lease</block>
  <block id="2a7079f12b8b7175a78aa4192442cceb" category="list-text">Sessioni stateful</block>
  <block id="78d4290f55bf351449981f773525bc0b" category="list-text">Tutte le funzionalità NFS su una singola porta (2049)</block>
  <block id="53ec1aa3e51de041ca30580dcd5695db" category="list-text">Solo TCP</block>
  <block id="762c048886aaa3279e7ff7d4bbe56f5c" category="list-text">Mapping del dominio ID</block>
  <block id="7e6be8eb2ba9a556864cfd20857c1565" category="list-text">Integrazione Kerberos (NFSv3 può utilizzare Kerberos, ma solo per NFS, non per protocolli ausiliari come NLM)</block>
  <block id="1f2bcbb2c0049fcc033a40cb665f19fc" category="section-title">Dipendenze NFSv4.1</block>
  <block id="f83a89d33e724f74ff5a673c34fe9ac6" category="paragraph">A causa delle funzionalità di sicurezza aggiuntive di NFSv4.1, sono coinvolte alcune dipendenze esterne che non erano necessarie per utilizzare NFSv3 (in modo simile a come SMB richiede dipendenze come Active Directory).</block>
  <block id="0e8ff8f10d56a8534800018ecdbcbfb7" category="paragraph">Cloud Volumes Service offre il supporto per ACL NFSv4.x, che offrono vantaggi distinti rispetto alle normali autorizzazioni POSIX, come ad esempio:</block>
  <block id="e7c21967cc185dee47ba9548ba30b26e" category="list-text">Controllo granulare dell'accesso degli utenti a file e directory</block>
  <block id="a5e0d0cbd4020f568d08cdaed3dedd6b" category="list-text">Maggiore sicurezza NFS</block>
  <block id="fd272c227f4884473fc1b4409d1fa6f0" category="list-text">Maggiore interoperabilità con CIFS/SMB</block>
  <block id="1c0d9e3bfe82d85776be6deeefb1b8d1" category="list-text">Rimozione del limite NFS di 16 gruppi per utente con sicurezza AUTH_SYS</block>
  <block id="37c82add6470c2f73fad45f1e887f214" category="list-text">Gli ACL evitano la necessità di risoluzione degli ID di gruppo (GID), che rimuove efficacemente i GID limitNLSSv4.1 ACL sono controllati dai client NFS, non da Cloud Volumes Service. Per utilizzare gli ACL NFSv4.1, assicurarsi che la versione software del client li supporti e che siano installate le utility NFS appropriate.</block>
  <block id="f497540fbfe4bb6c8784249b7ca44322" category="section-title">Compatibilità tra ACL NFSv4.1 e client SMB</block>
  <block id="b18893becc5c5979b433330d581d0502" category="paragraph">Gli ACL NFSv4 sono diversi dagli ACL a livello di file di Windows (ACL NTFS) ma presentano funzionalità simili. Tuttavia, in ambienti NAS multiprotocollo, se sono presenti ACL NFSv4.1 e si utilizza l'accesso a doppio protocollo (NFS e SMB sugli stessi set di dati), i client che utilizzano SMB2.0 e versioni successive non saranno in grado di visualizzare o gestire gli ACL dalle schede di sicurezza di Windows.</block>
  <block id="e24382a2de980eb4d0fad087c2279291" category="section-title">Come funzionano gli ACL NFSv4.1</block>
  <block id="65da9b80e25e8e6b76e6f95a27e33773" category="paragraph">Per riferimento, vengono definiti i seguenti termini:</block>
  <block id="3f33ebc7aedc435f5da6f0cdb363e903" category="list-text">*Elenco di controllo di accesso (ACL).* elenco di voci delle autorizzazioni.</block>
  <block id="e8b619b2feea9964d68e458010421937" category="list-text">*Voce di controllo di accesso (ACE).* una voce di autorizzazione nell'elenco.</block>
  <block id="e22c8ddaa933012f7b9658b15556e1d9" category="paragraph">Quando un client imposta un ACL NFSv4.1 su un file durante un'operazione SETATTR, Cloud Volumes Service imposta tale ACL sull'oggetto, sostituendo qualsiasi ACL esistente. Se un file non contiene ACL, le autorizzazioni di modalità per il file vengono calcolate dal PROPRIETARIO@, DAL GRUPPO@ e DA EVERYONE@. Se nel file sono presenti SUID/SGID/bit ADESIVI, questi non vengono influenzati.</block>
  <block id="bbfc3dd393a8c0fb0275a317ea92cdb6" category="paragraph">Quando un client ottiene un ACL NFSv4.1 su un file durante un'operazione GETATTR, Cloud Volumes Service legge l'ACL NFSv4.1 associato all'oggetto, costruisce un elenco di ACE e restituisce l'elenco al client. Se il file ha un ACL NT o bit di modalità, un ACL viene costruito dai bit di modalità e restituito al client.</block>
  <block id="e91b7b9c71eaf21c16d5232d74f4c5c3" category="paragraph">L'accesso viene negato se nell'ACL è presente un ACE DI NEGAZIONE; l'accesso viene concesso se esiste un ACE DI AUTORIZZAZIONE. Tuttavia, l'accesso viene negato anche se nessuna delle ACE è presente nell'ACL.</block>
  <block id="85e34118580ac115f838cd805832291e" category="paragraph">Un descrittore di sicurezza è costituito da un ACL di sicurezza (SACL) e da un ACL discrezionale (DACL). Quando NFSv4.1 interagisce con CIFS/SMB, il DACL viene mappato uno a uno con NFSv4 e CIFS. Il DACL è costituito dalle ACE DI AUTORIZZAZIONE e NEGAZIONE.</block>
  <block id="f26fe9c5bd9a38964b075295ff6b600f" category="paragraph">Se di base<block ref="417e248f80c35ca0d471575a5fb951f5" prefix=" " category="inline-code"></block> Viene eseguito su un file o una cartella con gli ACL NFSv4.1 impostati, gli ACL degli utenti e dei gruppi esistenti vengono mantenuti, ma gli ACL PREDEFINITI DI PROPRIETARIO@, GRUPPO@, EVERYONE@ vengono modificati.</block>
  <block id="51cdc67f907418899df11513b246dd1c" category="inline-link">flag di ereditarietà</block>
  <block id="bfb9f4f4e0b3ee74bbf0624c3acb6f05" category="paragraph">Un client che utilizza ACL NFSv4.1 può impostare e visualizzare ACL per file e directory nel sistema. Quando viene creato un nuovo file o sottodirectory in una directory che dispone di un ACL, tale oggetto eredita tutte le ACE nell'ACL che sono state contrassegnate con il appropriato<block ref="efe32d9e162a0a9bfdfda1b55921a64c" category="inline-link-rx"></block>.</block>
  <block id="4ede33bb65432e74e322d690608c2334" category="paragraph">Se un file o una directory dispone di un ACL NFSv4.1, tale ACL viene utilizzato per controllare l'accesso indipendentemente dal protocollo utilizzato per accedere al file o alla directory.</block>
  <block id="0d733f1633c2aa51a107a6e21dfd5644" category="paragraph">File e directory ereditano ACE da ACL NFSv4 nelle directory principali (possibilmente con modifiche appropriate), purché gli ACE siano stati contrassegnati con i flag di ereditarietà corretti.</block>
  <block id="a61aaa9a4f599d5b80e71c232d23147a" category="paragraph">Quando viene creato un file o una directory come risultato di una richiesta NFSv4, l'ACL del file o della directory risultante dipende dal fatto che la richiesta di creazione del file includa un ACL o solo permessi di accesso ai file UNIX standard. L'ACL dipende anche dalla presenza o meno di un ACL nella directory principale.</block>
  <block id="5ac8b682abcf5cc600bff1df60b6eeb0" category="list-text">Se la richiesta include un ACL, viene utilizzato tale ACL.</block>
  <block id="68d4655ff3b6740e5735fd80c7910023" category="list-text">Se la richiesta include solo le autorizzazioni di accesso ai file UNIX standard e la directory principale non dispone di un ACL, la modalità file client viene utilizzata per impostare le autorizzazioni di accesso ai file UNIX standard.</block>
  <block id="2cf6ef9c801da66f5a80033edc51acf8" category="list-text">Se la richiesta include solo le autorizzazioni di accesso ai file UNIX standard e la directory principale dispone di un ACL non ereditabile, un ACL predefinito basato sui bit di modalità passati alla richiesta viene impostato sul nuovo oggetto.</block>
  <block id="c1eac2f9759f1dd2f7680287789d03f9" category="list-text">Se la richiesta include solo autorizzazioni di accesso ai file UNIX standard ma la directory principale dispone di un ACL, le ACE nell'ACL della directory principale vengono ereditate dal nuovo file o directory, purché le ACE siano state contrassegnate con gli indicatori di ereditarietà appropriati.</block>
  <block id="1aeffd8cf8d8faca5f1d6379d7ad7b42" category="section-title">Autorizzazioni ACE</block>
  <block id="be30a66f742a1c4b197f654c5456f525" category="inline-link">PROCEDURA: Utilizzare l'ACL NFSv4</block>
  <block id="1e0ba766d5b81a0076401367c75ba49d" category="paragraph">Le autorizzazioni ACL NFSv4.1 utilizzano una serie di valori di lettere maiuscole e minuscole (ad esempio<block ref="a0331a73af55fd5fda99201f776e847c" prefix=" " category="inline-code"></block>) per controllare l'accesso. Per ulteriori informazioni sui valori delle lettere, vedere<block ref="19e15d2b871d5802ed53b8bb943cfa1d" category="inline-link-rx"></block>.</block>
  <block id="e5db87d9c7835194478e833b1c2341a3" category="section-title">Comportamento dell'ACL di NFSv4.1 con ereditarietà di umask e ACL</block>
  <block id="2d01b8b9abf1cd5dd5dc3a87babfa478" category="inline-link">Gli ACL NFSv4 offrono l'ereditarietà degli ACL</block>
  <block id="90f70b82033cb9c398aab9c2ab8e4b97" category="inline-link">Flag di ereditarietà ACL</block>
  <block id="b40177dea06ae321d6ba903c296a8bf4" category="paragraph"><block ref="a4a4eca6555a8c7e71d54636b6d02bd2" category="inline-link-rx"></block>. L'ereditarietà degli ACL indica che i file o le cartelle creati sotto gli oggetti con gli ACL NFSv4.1 impostati possono ereditare gli ACL in base alla configurazione di<block ref="0dfdf6ea7cd5f3c14c3e752e09504ece" category="inline-link-rx"></block>.</block>
  <block id="e3847e2a1d0d27fe2e50f7b68080126e" category="inline-link">Umask</block>
  <block id="391e42635de569b9fd15585f0b03777a" category="inline-link">RFC 5661</block>
  <block id="a5147a6538ae36d50a705033dee8e1ea" category="paragraph"><block ref="63bfc707387dfd47bf50e485c5b4d27f" category="inline-link-rx"></block> viene utilizzato per controllare il livello di autorizzazione al quale i file e le cartelle vengono creati in una directory senza l'intervento dell'amministratore. Per impostazione predefinita, Cloud Volumes Service consente a umask di eseguire l'override degli ACL ereditati, il che è un comportamento previsto come indicato in<block ref="c202d210fe4151f93fd56939449ae558" category="inline-link-rx"></block>.</block>
  <block id="c283f512453dfbe4a4d54a5de963c63a" category="section-title">Formattazione ACL</block>
  <block id="af26ba96448cb4f36fa75d37c0c24884" category="paragraph">Gli ACL NFSv4.1 hanno una formattazione specifica. Il seguente esempio è un insieme ACE su un file:</block>
  <block id="90bdfef72a7e9f73c8492c28764bfecc" category="paragraph">L'esempio precedente segue le linee guida del formato ACL di:</block>
  <block id="7d665626903fe1069f3c052eb3b93597" category="inline-link"><block ref="7d665626903fe1069f3c052eb3b93597" category="inline-link-rx"></block></block>
  <block id="192707027419e02a79fe3b9af5a845c4" category="paragraph">Un tipo di<block ref="7fc56270e7a70fa81a5935b72eacbe29" prefix=" " category="inline-code"></block> significa "consenti". In questo caso, i flag Inherit non vengono impostati, in quanto l'entità non è un gruppo e non include l'ereditarietà. Inoltre, poiché l'ACE non è una voce DI AUDIT, non è necessario impostare gli indicatori di audit. Per ulteriori informazioni sugli ACL NFSv4.1, vedere<block ref="588b628ed19e81b60db990218fbd0aa2" category="inline-link-rx"></block>.</block>
  <block id="767a03c18193757348519856b05f7d1c" category="paragraph">Se l'ACL NFSv4.1 non è impostato correttamente (o una stringa di nomi non può essere risolta dal client e dal server), l'ACL potrebbe non funzionare come previsto oppure la modifica dell'ACL potrebbe non essere applicata e generare un errore.</block>
  <block id="e0ad83b43ccb7e44bcdb46bcdc1189d9" category="paragraph">Gli errori di esempio includono:</block>
  <block id="bf837e35002530c307569ba2ec195e9a" category="section-title">NEGARE esplicitamente</block>
  <block id="68a14c985893a66fdf24403b891ddc6c" category="paragraph">Le autorizzazioni NFSv4.1 possono includere attributi DI NEGAZIONE esplicita per PROPRIETARIO, GRUPPO e CHIUNQUE. Ciò è dovuto al fatto che gli ACL di NFSv4.1 sono di tipo default-deny, il che significa che se un ACL non viene esplicitamente concesso da un ACE, viene negato. Gli attributi DI NEGAZIONE esplicita sovrascrivono le ACE DI ACCESSO, esplicite o meno.</block>
  <block id="22759a58413e45c1ab8a0a53300ea43c" category="paragraph">GLI ACE DI NEGAZIONE vengono impostati con un tag di attributo di<block ref="f623e75af30e62bbd73d6df5b50bb7b5" prefix=" " category="inline-code"></block>.</block>
  <block id="3bce872a832106c5038ea04d532162ba" category="paragraph">Nell'esempio riportato di seguito, IL GRUPPO@ può disporre di tutte le autorizzazioni di lettura ed esecuzione, ma non di tutti gli accessi in scrittura.</block>
  <block id="8b4ed201924d12a3d0ec41f5538460b2" category="paragraph">GLI ACE DI NEGAZIONE devono essere evitati ogni volta che è possibile perché possono essere confusi e complicati; GLI ACL CHE NON sono esplicitamente definiti sono implicitamente negati. Quando si impostano LE ACE DI NEGAZIONE, agli utenti potrebbe essere negato l'accesso quando si prevede di ottenere l'accesso.</block>
  <block id="fb976fa579c74ac9e0b64ac922a938d7" category="paragraph">Il set precedente di ACE equivale a 755 in bit di modalità, il che significa:</block>
  <block id="de9d71e2841fbf06bf2e96e40b0655d0" category="list-text">Il proprietario ha tutti i diritti.</block>
  <block id="391533122a44e47fc6d7eed8f3d46152" category="list-text">I gruppi sono di sola lettura.</block>
  <block id="233c314243fd8ff0f129355150358c9b" category="list-text">Altri hanno la sola lettura.</block>
  <block id="004367158d382df49675a222d852e2c2" category="paragraph">Tuttavia, anche se le autorizzazioni vengono regolate sull'equivalente 775, l'accesso può essere negato a causa del NEGAZIONE esplicita impostata su EVERYONE.</block>
  <block id="c9533a3d4ca28b597d9e4f0b7c2d7d28" category="section-title">Dipendenze di mappatura del dominio ID NFSv4.1</block>
  <block id="b8c7283821c3d4795f01644c47598298" category="paragraph">NFSv4.1 sfrutta la logica di mappatura del dominio ID come livello di sicurezza per verificare che un utente che tenta di accedere a un montaggio NFSv4.1 sia effettivamente quello che afferma di essere. In questi casi, il nome utente e il nome del gruppo provenienti dal client NFSv4.1 aggiunge una stringa di nome e la invia all'istanza di Cloud Volumes Service. Se la combinazione di nome utente/gruppo e stringa ID non corrisponde, l'utente e/o il gruppo vengono esclusi dall'impostazione predefinita None User specificata in<block ref="f606fb2da2ae329157d791c6955a0337" prefix=" " category="inline-code"></block> sul client.</block>
  <block id="5aec5d2b81e4e7bc2bb96b8eee7f6a1f" category="paragraph">Questa stringa ID è un requisito per il corretto rispetto delle autorizzazioni, in particolare quando vengono utilizzati ACL NFSv4.1 e/o Kerberos. Di conseguenza, le dipendenze dei server dei nomi, come i server LDAP, sono necessarie per garantire la coerenza tra client e Cloud Volumes Service per una corretta risoluzione delle identità dei nomi di utenti e gruppi.</block>
  <block id="ea6c924c6846969cae29ab27aa4c3d9e" category="paragraph">Cloud Volumes Service utilizza un ID statico predefinito del nome di dominio<block ref="22a3233341e094b6c2067cb2972e530a" prefix=" " category="inline-code"></block>. Per impostazione predefinita, i client NFS utilizzano il nome di dominio DNS per le impostazioni del nome di dominio ID, ma è possibile modificare manualmente il nome di dominio ID in<block ref="f606fb2da2ae329157d791c6955a0337" prefix=" " category="inline-code"></block>.</block>
  <block id="a524142e9e2e4c80b2545aea06b82fb6" category="paragraph">Se LDAP è attivato in Cloud Volumes Service, Cloud Volumes Service automatizza il dominio ID NFS per modificare ciò che è configurato per il dominio di ricerca in DNS e i client non dovranno essere modificati a meno che non utilizzino nomi di ricerca di dominio DNS diversi.</block>
  <block id="13c371145cb8e423bcc06c41dafa7d27" category="paragraph">Quando Cloud Volumes Service è in grado di risolvere un nome utente o un nome di gruppo in file locali o LDAP, viene utilizzata la stringa di dominio e gli ID di dominio non corrispondenti vengono eliminati a nessuno. Se Cloud Volumes Service non riesce a trovare un nome utente o un nome di gruppo nei file locali o LDAP, viene utilizzato il valore ID numerico e il client NFS risolve il nome in modo corretto (simile al comportamento di NFSv3).</block>
  <block id="2920d1231c77a15a148be7e24a4224a8" category="paragraph">Senza modificare il dominio ID NFSv4.1 del client in modo che corrisponda a quello utilizzato dal volume Cloud Volumes Service, si verifica quanto segue:</block>
  <block id="cf7f7139ed9bd9c2ce206642dd7fa858" category="list-text">Gli utenti e i gruppi UNIX con voci locali in Cloud Volumes Service (come root, come definito in utenti e gruppi UNIX locali) vengono ridotti al valore None.</block>
  <block id="b4aa27a84e1a2079915902824805faed" category="list-text">Gli utenti e i gruppi UNIX con voci in LDAP (se Cloud Volumes Service è configurato per l'utilizzo di LDAP) non vengono visualizzati se i domini DNS sono diversi tra client NFS e Cloud Volumes Service.</block>
  <block id="ef7ad0d3015777d2990a6af6b71f374b" category="list-text">Gli utenti e i gruppi UNIX senza voci locali o LDAP utilizzano il valore numerico ID e si risolvono nel nome specificato sul client NFS. Se non esiste alcun nome sul client, viene visualizzato solo l'ID numerico.</block>
  <block id="62dcf28b3972264f1b30c2bd51a03def" category="paragraph">Di seguito sono riportati i risultati dello scenario precedente:</block>
  <block id="696c02f546b2ffcdac74d99c917daa24" category="paragraph">Quando i domini ID client e server corrispondono, viene visualizzato lo stesso elenco di file:</block>
  <block id="406ef9702da9a43b3a7b54a25411d799" category="paragraph">Per ulteriori informazioni su questo problema e su come risolverlo, vedere la sezione "<block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block>."</block>
  <block id="feb3aa3308fe030fd35a38b78a2300bd" category="section-title">Dipendenze Kerberos</block>
  <block id="40bbfae3ce12130d42058c7017ceb5ed" category="paragraph">Se si intende utilizzare Kerberos con NFS, è necessario disporre di quanto segue con Cloud Volumes Service:</block>
  <block id="97a82eff6d3d292af521c01da598a578" category="list-text">Dominio Active Directory per i servizi del centro di distribuzione Kerberos (KDC)</block>
  <block id="7539d3051db830d97dee8f6d5d504289" category="list-text">Dominio Active Directory con attributi utente e gruppo popolati con informazioni UNIX per la funzionalità LDAP (NFS Kerberos in Cloud Volumes Service richiede un'associazione utente da SPN a utente UNIX per la corretta funzionalità).</block>
  <block id="39780a85d8e7edcc28fd4bc1f6b379f9" category="list-text">LDAP attivato sull'istanza di Cloud Volumes Service</block>
  <block id="9b306ebe81f909f9a456adcadd197090" category="list-text">Dominio Active Directory per i servizi DNS</block>
  <block id="3f1e5b600401b83c49c16e0c80170842" category="section-title">NFSv4.1 e l'utente/gruppo nessuno</block>
  <block id="5c79e57a072b5ea9e69b08395268c3fe" category="paragraph">Uno dei problemi più comuni riscontrati con una configurazione NFSv4.1 è quando un file o una cartella viene visualizzata in un elenco utilizzando<block ref="44ba5ca65651b4f36f1927576dd35436" prefix=" " category="inline-code"></block> di proprietà di<block ref="aa22bf558e0fe9237af37223aa4eecbb" prefix=" " category="inline-code"></block> combinazione di<block ref="9a0f36d70a22b40baa26f3df113cd9eb" prefix=" " category="inline-code"></block>.</block>
  <block id="506c2c0c7f5b70af3df68c45c46f45a7" category="paragraph">Ad esempio:</block>
  <block id="2436a7de6f774d774219a86839e40d54" category="paragraph">E l'ID numerico è<block ref="ac627ab1ccbdb62ec96e702f07f6425b" prefix=" " category="inline-code"></block>.</block>
  <block id="89429eb5e6061e2e0b04707c39588b82" category="paragraph">In alcuni casi, il file potrebbe mostrare il proprietario corretto, ma<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> come gruppo.</block>
  <block id="8155be8c03c24d2ae2a39ba5b9659708" category="paragraph">Chi non è nessuno?</block>
  <block id="01e2f333d529d07a7774464ebe7c0d52" category="paragraph">Il<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> L'utente in NFSv4.1 è diverso da<block ref="3ff01acd436943ffc00e90a99dd4f83e" prefix=" " category="inline-code"></block> utente. È possibile visualizzare il modo in cui un client NFS vede ciascun utente eseguendo<block ref="b80bb7740288fda1f201890375a60c8f" prefix=" " category="inline-code"></block> comando:</block>
  <block id="bb1a16c53f7bf27e8010e55518128316" category="paragraph">Con NFSv4.1<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> user (utente) è l'utente predefinito definito da<block ref="83c686a28c61cd8fdbac9a1804f10e47" prefix=" " category="inline-code"></block> e può essere definito come qualsiasi utente che si desidera utilizzare.</block>
  <block id="25df38609547f38c12a30d2f7fa376e3" category="paragraph">Perché questo accade?</block>
  <block id="0c52fa2fe9ffee5f1757712d7b9151d3" category="paragraph">Poiché la sicurezza tramite il mapping della stringa del nome è un insieme di chiavi delle operazioni NFSv4.1, il comportamento predefinito quando una stringa del nome non corrisponde correttamente è quello di schiacciare l'utente a un utente che normalmente non avrà accesso a file e cartelle di proprietà di utenti e gruppi.</block>
  <block id="ee345fce71ab8dd58d64ab30df90665d" category="paragraph">Quando vedi<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> Per l'utente e/o il gruppo negli elenchi di file, ciò significa generalmente che qualcosa in NFSv4.1 è configurato in modo errato. La distinzione tra maiuscole e minuscole può entrare in gioco qui.</block>
  <block id="6f0eaeb67bf8645d4cb5b6d6634d62e9" category="paragraph">Ad esempio, se user1@CVSDEMO.LOCAL (uid 1234, gid 1234) sta accedendo a un'esportazione, Cloud Volumes Service deve essere in grado di trovare user1@CVSDEMO.LOCAL (uid 1234, gid 1234). Se l'utente in Cloud Volumes Service è USER1@CVSDEMO.LOCAL, non corrisponde (USER1 maiuscolo e user1 minuscolo). In molti casi, nel file dei messaggi sul client è possibile visualizzare quanto segue:</block>
  <block id="501dfba2ca7e696ebe3828fe0a72358d" category="paragraph">Il client e il server devono accettare che un utente sia effettivamente quello che dichiara di essere, quindi è necessario controllare quanto segue per assicurarsi che l'utente che il client vede abbia le stesse informazioni dell'utente che Cloud Volumes Service vede.</block>
  <block id="c45f88d46edf246ef524b5ae57bfd939" category="list-text">*NFSv4.x ID domain.* Client:<block ref="83c686a28c61cd8fdbac9a1804f10e47" prefix=" " category="inline-code"></block> File; utilizzi di Cloud Volumes Service<block ref="22a3233341e094b6c2067cb2972e530a" prefix=" " category="inline-code"></block> e non possono essere modificati manualmente. Se si utilizza LDAP con NFSv4.1, Cloud Volumes Service modifica il dominio ID in quello utilizzato dal dominio di ricerca DNS, che è lo stesso del dominio ad.</block>
  <block id="4ad682a8c77e394fdf80dd7dc8013933" category="list-text">*Nome utente e ID numerici.* determina dove il client cerca i nomi utente e sfrutta la configurazione dello switch del name service: Client:<block ref="ea2e5642148891c2d0cae7bf555be98a" prefix=" " category="inline-code"></block> E/o passwd locale e file di gruppo; Cloud Volumes Service non consente modifiche a questo, ma aggiunge automaticamente LDAP alla configurazione quando è attivato.</block>
  <block id="278ba27763f1a046a43e86bd394f831b" category="list-text">*Nome del gruppo e ID numerici.* determina la posizione in cui il client cerca i nomi dei gruppi e sfrutta la configurazione dello switch del name service: Client:<block ref="ea2e5642148891c2d0cae7bf555be98a" prefix=" " category="inline-code"></block> E/o passwd locale e file di gruppo; Cloud Volumes Service non consente modifiche a questo, ma aggiunge automaticamente LDAP alla configurazione quando è attivato.</block>
  <block id="6b9ce9cbf95dd872dc03e91534746dc9" category="paragraph">In quasi tutti i casi, se si vede<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> Negli elenchi di utenti e gruppi dei client, il problema è la traduzione dell'ID dominio del nome utente o del gruppo tra Cloud Volumes Service e il client NFS. Per evitare questo scenario, utilizzare LDAP per risolvere le informazioni relative a utenti e gruppi tra client e Cloud Volumes Service.</block>
  <block id="55c4b4ea1ecc6c7d5d39c90a0b42830f" category="section-title">Visualizzazione delle stringhe di ID nome per NFSv4.1 sui client</block>
  <block id="c194a1cc7281e9894e494f5ccc1267d9" category="paragraph">Se si utilizza NFSv4.1, durante le operazioni NFS viene eseguita una mappatura di stringa nome, come descritto in precedenza.</block>
  <block id="600a8e1223f644dfc8fc6d9eaf7c6585" category="inline-link">nfsidmap -l</block>
  <block id="315b0c6cb599d172afa3879fb5aff687" category="paragraph">Oltre all'utilizzo<block ref="452905a167cf4509fd08acb964fdb20c" prefix=" " category="inline-code"></block> Per trovare un problema con gli ID NFSv4, è possibile utilizzare<block ref="b0f2e0837ffda1ff0550aeef038779e7" category="inline-link-rx"></block> Sul client NFS per visualizzare i nomi utente correttamente mappati al dominio NFSv4.</block>
  <block id="c72321f4072e32fa1625318fcee53b38" category="paragraph">Ad esempio, questo è l'output del comando dopo che un utente può essere trovato dal client e Cloud Volumes Service accede a un montaggio NFSv4.x:</block>
  <block id="7fdd86c292924f1df8a7d9127ece25dc" category="paragraph">Quando un utente non mappato correttamente nel dominio ID NFSv4.1 (in questo caso,<block ref="7ddf2462d5aa52ee60f5901c04ede944" prefix=" " category="inline-code"></block>) tenta di accedere allo stesso mount e tocca un file, vengono assegnati<block ref="9a0f36d70a22b40baa26f3df113cd9eb" prefix=" " category="inline-code"></block>, come previsto.</block>
  <block id="bf667093961d1f59e9282ef8a28d89f7" category="paragraph">Il<block ref="600a8e1223f644dfc8fc6d9eaf7c6585" prefix=" " category="inline-code"></block> l'output mostra l'utente<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> nel display ma non<block ref="7ddf2462d5aa52ee60f5901c04ede944" prefix=" " category="inline-code"></block>; si tratta dell'utente anonimo nella nostra regola dei criteri di esportazione <block ref="f9df942af967185fc775031b3c286856" prefix="(" category="inline-code"></block>).</block>
  <block id="5ec4dbbd0b1975ade000088ec562aebe" category="inline-link-macro">Avanti: PMI.</block>
  <block id="a1989578ae6cff04ad5b049565c028a6" category="paragraph"><block ref="a1989578ae6cff04ad5b049565c028a6" category="inline-link-macro-rx"></block></block>
  <block id="9daaf09aeccc99c61fe453295253eae0" category="doc">Riepilogo e conclusione: Perché scegliere NetApp Hybrid Multifloud con VMware</block>
  <block id="0c17a5e22f572303947d9e14cd98db39" category="paragraph">NetApp Cloud Volumes e le soluzioni VMware per i principali hyperscaler offrono un grande potenziale alle organizzazioni che desiderano sfruttare il cloud ibrido. Il resto di questa sezione fornisce i casi di utilizzo che mostrano l'integrazione dei volumi cloud NetApp che consente di sfruttare le reali funzionalità del multicloud ibrido.</block>
  <block id="e7441dbfabeaebba75ddd1bf2bcf25e9" category="section-title">Caso d'utilizzo n. 1: Ottimizzazione dello storage</block>
  <block id="b9a8c3d27aa6638e02992c8b76fea769" category="paragraph">Quando si esegue un'esercitazione di dimensionamento utilizzando l'output di RVtools, è sempre evidente che la scalabilità della potenza (vCPU/VMEM) è parallela allo storage. Molte volte, le organizzazioni si trovano in una situazione in cui lo spazio di storage richiede unità di dimensioni del cluster ben superiori a quelle necessarie per la potenza.</block>
  <block id="cb575e0b8e023ca0a1789ea03bdb86fd" category="paragraph">Integrando NetApp Cloud Volumes, le organizzazioni possono realizzare una soluzione cloud basata su vSphere con un semplice approccio alla migrazione, senza re-platform, modifiche IP e modifiche architetturali. Inoltre, questa ottimizzazione consente di scalare l'impatto dello storage mantenendo il numero di host alla quantità minima richiesta in vSphere, senza modificare la gerarchia dello storage, la sicurezza o i file resi disponibili. In questo modo è possibile ottimizzare l'implementazione e ridurre il TCO complessivo del 35-45%. Questa integrazione consente inoltre di scalare lo storage dal warm storage alle performance a livello di produzione in pochi secondi.</block>
  <block id="9ae8084cfbf8c00bc50891fe51bb70b4" category="section-title">Caso d'utilizzo n. 2: Migrazione del cloud</block>
  <block id="40c30ee45ee11e766ec77dfd0d98cef0" category="paragraph">Le organizzazioni sono sotto pressione per migrare le applicazioni dai data center on-premise al cloud pubblico per diversi motivi: Una scadenza imminente del leasing, una direttiva finanziaria per passare dalla spesa in conto capitale (CAPEX) alla spesa in conto operativo (OPEX) o semplicemente un mandato top-down per spostare tutto nel cloud.</block>
  <block id="4744ec437cce262edc7110652b69ab21" category="paragraph">Quando la velocità è critica, è possibile solo un approccio di migrazione semplificato, perché il re-platform e il refactoring delle applicazioni per adattarsi alla specifica piattaforma IaaS del cloud è lento e costoso, spesso richiede mesi. Combinando i volumi NetApp Cloud con la replica SnapMirror efficiente in termini di larghezza di banda per lo storage connesso agli ospiti (inclusi RDM in combinazione con copie Snapshot coerenti con l'applicazione e HCX, migrazione specifica per il cloud (ad esempio Azure Migrate) o prodotti di terze parti per la replica delle macchine virtuali), questa transizione è ancora più semplice che affidarsi a lunghi meccanismi di filtri i/O.</block>
  <block id="d393e254c1adb8df50cfc41394c68645" category="section-title">Caso d'utilizzo n. 3: Espansione del data center</block>
  <block id="90c724dd3ba1ec0f533f7fb73a10323a" category="paragraph">Quando un data center raggiunge i limiti di capacità a causa di picchi stagionali della domanda o semplicemente di una crescita organica costante, il passaggio a VMware basato sul cloud insieme a NetApp Cloud Volumes è una soluzione semplice. L'utilizzo di NetApp Cloud Volumes consente la creazione, la replica e l'espansione dello storage in modo molto semplice, fornendo alta disponibilità nelle zone di disponibilità e funzionalità di scalabilità dinamica. L'utilizzo di NetApp Cloud Volumes consente di ridurre al minimo la capacità del cluster host, superando la necessità di stretch cluster.</block>
  <block id="0b95336d0f31a3bd4775f96c750bb9bc" category="section-title">Caso d'utilizzo n. 4: Disaster recovery nel cloud</block>
  <block id="c2aee451a27e7cf3993f462ee5b760e9" category="paragraph">In un approccio tradizionale, se si verifica un disastro, le macchine virtuali replicate nel cloud richiederebbero la conversione nella piattaforma hypervisor del cloud prima di poter essere ripristinate, non un'attività da gestire durante una crisi.</block>
  <block id="772dec0515d132f26bfa87cb31b5758d" category="paragraph">Utilizzando NetApp Cloud Volumes per lo storage connesso agli ospiti utilizzando la replica di SnapCenter e SnapMirror on-premise insieme alle soluzioni di virtualizzazione del cloud pubblico, è possibile definire un approccio migliore per il disaster recovery, consentendo il ripristino delle repliche delle macchine virtuali su un'infrastruttura SDDC VMware completamente coerente e con strumenti di recovery specifici per il cloud (Ad esempio Azure Site Recovery) o strumenti di terze parti equivalenti come Veeam. Questo approccio consente inoltre di eseguire rapidamente operazioni di disaster recovery e recovery dal ransomware. In questo modo è possibile scalare la produzione completa per il test o durante un disastro aggiungendo host on-demand.</block>
  <block id="24d0e6ab8003b406cf7e3f42363acbf5" category="section-title">Caso di utilizzo n. 5: Modernizzazione delle applicazioni</block>
  <block id="59e56fb67c730af04acf8a13665cadb3" category="paragraph">Una volta che le applicazioni si trovano nel cloud pubblico, le organizzazioni vorranno sfruttare le centinaia di potenti servizi cloud per modernizzarle ed estenderle. Con l'utilizzo di NetApp Cloud Volumes, la modernizzazione è un processo semplice perché i dati delle applicazioni non sono bloccati in vSAN e consentono la mobilità dei dati per un'ampia gamma di casi di utilizzo, tra cui Kubernetes.</block>
  <block id="eea420abccd820355b4bddd3524ae083" category="paragraph">Sia che tu stia prendendo in esame un cloud all-cloud o ibrido, NetApp Cloud Volumes offre opzioni eccellenti per implementare e gestire i carichi di lavoro delle applicazioni insieme ai file service e ai protocolli a blocchi, riducendo al contempo il TCO rendendo i requisiti dei dati perfetti a livello applicativo.</block>
  <block id="cd51ff9774803e84c79e8ab19bb7ffd2" category="paragraph">Qualunque sia il caso d'utilizzo, scegli il tuo cloud/hyperscaler preferito insieme a NetApp Cloud Volumes per una rapida realizzazione dei benefici del cloud, un'infrastruttura coerente e operazioni su cloud multipli e on-premise, portabilità bidirezionale dei carichi di lavoro e capacità e performance di livello Enterprise.</block>
  <block id="2993778cba8ea9a69af4ff9dc7e18fb8" category="paragraph">Si tratta degli stessi processi e procedure familiari utilizzati per collegare lo storage. Ricorda che è solo la posizione dei dati che è cambiata con nuovi nomi; i tool e i processi rimangono tutti gli stessi e NetApp Cloud Volumes aiuta a ottimizzare l'implementazione complessiva.</block>
  <block id="980ba21a8b1f775a9fae0552d8594171" category="doc">Panoramica del multicloud ibrido NetApp con VMware</block>
  <block id="415be703c228d9c6838b18850a1d9f31" category="paragraph">La maggior parte delle organizzazioni IT segue l'approccio ibrido cloud-first. Queste organizzazioni sono in fase di trasformazione e i clienti stanno valutando il loro attuale panorama IT e quindi migrando i workload nel cloud in base all'esercizio di valutazione e scoperta.</block>
  <block id="346972233965e89cf5b17c3907b35f86" category="paragraph">I fattori per i clienti che migrano al cloud possono includere flessibilità e burst, uscita dal data center, consolidamento del data center, scenari di fine ciclo di vita, fusioni, acquisizioni e così via. Il motivo di questa migrazione può variare in base a ciascuna organizzazione e alle rispettive priorità di business. Durante il passaggio al cloud ibrido, la scelta dello storage giusto nel cloud è molto importante per liberare la potenza dell'implementazione e dell'elasticità del cloud.</block>
  <block id="0c4a16ed987359b14dc407a858d1a78e" category="section-title">Opzioni di VMware Cloud nel cloud pubblico</block>
  <block id="f53db24f3a12ed8109f77a0f93c877af" category="paragraph">In questa sezione viene descritto il modo in cui ciascun provider cloud supporta uno stack VMware Software Defined Data Center (SDDC) e/o VMware Cloud Foundation (VCF) all'interno delle rispettive offerte di cloud pubblico.</block>
  <block id="d788a5499d320b05602a6a0805c81403" category="image-alt">avs</block>
  <block id="c7b818b90803789a74058cfb4396383d" category="paragraph">Azure VMware Solution è un servizio di cloud ibrido che consente il funzionamento completo degli SDDC VMware nel cloud pubblico Microsoft Azure. Azure VMware Solution è una soluzione di prima parte completamente gestita e supportata da Microsoft, verificata da VMware sfruttando l'infrastruttura Azure. Ciò significa che quando Azure VMware Solution viene implementata, i clienti ottengono VMware ESXi per la virtualizzazione del calcolo, vSAN per lo storage iperconvergente, E NSX per il networking e la sicurezza, il tutto sfruttando la presenza globale di Microsoft Azure, le strutture di data center leader di settore e la vicinanza al ricco ecosistema di servizi e soluzioni Azure native.</block>
  <block id="22b0614f106e2b7c956c60c8fc0d35c3" category="image-alt">vmc</block>
  <block id="8641a2440fc22db60ec877f3a8946fa2" category="paragraph">VMware Cloud su AWS porta il software SDDC di livello Enterprise di VMware su AWS Cloud con accesso ottimizzato ai servizi AWS nativi. Basato su VMware Cloud Foundation, VMware Cloud su AWS integra i prodotti di calcolo, storage e virtualizzazione di rete di VMware (VMware vSphere, VMware vSAN e VMware NSX) insieme alla gestione di VMware vCenter Server, ottimizzata per l'esecuzione su un'infrastruttura AWS bare-metal flessibile e dedicata.</block>
  <block id="8cb69aa5b1609d0a39f0fcd576c07df6" category="section-title">Motore VMware Google Cloud</block>
  <block id="5292de1147a4b3a1d5c63d057c4b0096" category="image-alt">gcve</block>
  <block id="1ffd600a1d8e07fe3b4bca16ae02167c" category="paragraph">Google Cloud VMware Engine è un'offerta Infrastructure-as-a-service (IaaS) basata sull'infrastruttura scalabile e dalle performance elevate di Google Cloud e sullo stack VMware Cloud Foundation: VMware vSphere, vCenter, vSAN e NSX-T. Questo servizio consente un percorso rapido verso il cloud, migrando o estendendo senza problemi i workload VMware esistenti dagli ambienti on-premise alla piattaforma Google Cloud senza i costi, gli sforzi o il rischio di riprogettare le applicazioni o di riorganizzare le operazioni. Si tratta di un servizio venduto e supportato da Google, che lavora a stretto contatto con VMware.</block>
  <block id="3310d189628fa6ef843aac57894a6db2" category="admonition">Il cloud privato SDDC e la co-locazione dei volumi cloud NetApp offrono le migliori performance con una latenza di rete minima.</block>
  <block id="c771fce16e2ba5df07df53cc5ab0748f" category="section-title">Lo sapevi?</block>
  <block id="8bba30129de0461b328be1e49f02b4d9" category="paragraph">Indipendentemente dal cloud utilizzato, quando viene implementato un VMware SDDC, il cluster iniziale include i seguenti prodotti:</block>
  <block id="7110e7a8682a9bc1c7105b83fe0cd9ea" category="list-text">VMware ESXi ospita la virtualizzazione di calcolo con un'appliance vCenter Server per la gestione</block>
  <block id="7d7a80e207de2136f4f19820758703fc" category="list-text">Storage iperconvergente VMware vSAN che incorpora le risorse di storage fisico di ciascun host ESXi</block>
  <block id="d2852e9d73c0ef81033c835719128b81" category="list-text">VMware NSX per reti virtuali e sicurezza con cluster NSX Manager per la gestione</block>
  <block id="afb91ca7e7763c77e44a41cb5ad0f78b" category="paragraph">Per i clienti che intendono ospitare carichi di lavoro a uso intensivo di storage e scalare su qualsiasi soluzione VMware ospitata nel cloud, l'infrastruttura iperconvergente predefinita impone che l'espansione debba essere sulle risorse di calcolo e storage.</block>
  <block id="fdb27bea654a8d874baecced2be84a1b" category="paragraph">Grazie all'integrazione con NetApp Cloud Volumes, come Azure NetApp Files, Amazon FSX per NetApp ONTAP, Cloud Volumes ONTAP (disponibile in tutti e tre gli hyperscaler principali) e Cloud Volumes Service per Google Cloud, i clienti ora hanno la possibilità di scalare in modo indipendente lo storage separatamente, E aggiungere nodi di calcolo al cluster SDDC solo se necessario.</block>
  <block id="2a01d572b1447155c310cabafac3fae9" category="section-title">Note:</block>
  <block id="a752c3529f0285d457f3b33b3c80d9a4" category="list-text">VMware non consiglia configurazioni di cluster sbilanciate, pertanto l'espansione dello storage implica l'aggiunta di più host, il che implica un TCO maggiore.</block>
  <block id="1d8249c60cae81d82fc5bfb80167babc" category="list-text">È possibile utilizzare un solo ambiente vSAN. Pertanto, tutto il traffico dello storage sarà direttamente in concorrenza con i carichi di lavoro di produzione.</block>
  <block id="c231690c8e9fabbd819ec1805becb157" category="list-text">Non è possibile fornire più livelli di performance per allineare requisiti, performance e costi delle applicazioni.</block>
  <block id="5d4c92ddd5fe9a6044b25c17d3368207" category="list-text">È molto semplice raggiungere i limiti di capacità dello storage di vSAN costruito sugli host del cluster. Utilizza NetApp Cloud Volumes per scalare lo storage in modo da ospitare set di dati attivi o dati Tier-cooler in storage persistente.</block>
  <block id="c1cf68955de5fa20274b29fa4a2a863f" category="paragraph">Azure NetApp Files, Amazon FSX per NetApp ONTAP, Cloud Volumes ONTAP (disponibile in tutti e tre i principali hyperscaler) e Cloud Volumes Service per Google Cloud possono essere utilizzati insieme alle macchine virtuali guest. Questa architettura di storage ibrido è costituita da un datastore vSAN che contiene i dati binari del sistema operativo guest e dell'applicazione. I dati dell'applicazione vengono collegati alla macchina virtuale tramite un iniziatore iSCSI basato su guest o i supporti NFS/SMB che comunicano direttamente con Amazon FSX per NetApp ONTAP, Cloud Volume ONTAP, Azure NetApp Files e Cloud Volumes Service per Google Cloud rispettivamente. Questa configurazione consente di superare facilmente le sfide con la capacità dello storage, come con vSAN, lo spazio libero disponibile dipende dallo spazio a vuoto e dalle policy di storage utilizzate.</block>
  <block id="1a5208bfffc624ccf99dfcbbf2078050" category="paragraph">Prendiamo in considerazione un cluster SDDC a tre nodi su VMware Cloud su AWS:</block>
  <block id="fab7fb31baaec1ccac4fe688e1a4c5d4" category="list-text">Capacità raw totale per un SDDC a tre nodi = 31,1 TB (circa 10 TB per ogni nodo).</block>
  <block id="ca189b47c3a1dfe1adbd1519688e4cc8" category="list-text">Lo spazio a vuoto da mantenere prima dell'aggiunta di host aggiuntivi = 25% = (0,25 x 31,1 TB) = 7,7 TB.</block>
  <block id="999b2c719df3f3e524bb10fb76521726" category="list-text">La capacità raw utilizzabile dopo la deduzione dello spazio a vuoto = 23,4 TB</block>
  <block id="2e1f3b31385d3304e1cda70b9cd8ed4c" category="list-text">Lo spazio libero effettivo disponibile dipende dalla policy di storage applicata.</block>
  <block id="2f5e6d9b0a4708c4d137ba14ac704a7b" category="list-text">RAID 0 = spazio libero effettivo = 23,4 TB (capacità raw utilizzabile/1)</block>
  <block id="df6b502d4d7283ef27d3821b69836c2d" category="list-text">RAID 1 = spazio libero effettivo = 11,7 TB (capacità raw utilizzabile/2)</block>
  <block id="921c660c11d4880048f3ef723f079e17" category="list-text">RAID 5 = spazio libero effettivo = 17,5 TB (capacità raw utilizzabile/1.33)</block>
  <block id="e3bdc3102c3de4f73860c229550bc6f4" category="paragraph">Pertanto, l'utilizzo di NetApp Cloud Volumes come storage connesso agli ospiti contribuirebbe ad espandere lo storage e ottimizzare il TCO, soddisfacendo al contempo i requisiti di performance e protezione dei dati.</block>
  <block id="36c48411397a73fcbe7ccac93862641b" category="admonition">Lo storage in-guest era l'unica opzione disponibile al momento della stesura del presente documento. Non appena sarà disponibile il supporto supplementare per datastore NFS, sarà disponibile ulteriore documentazione <block ref="2feee9d08b57f121d415095bba26ae78" category="inline-link-macro-rx"></block>.</block>
  <block id="571c0d425ce03c2532e7d9f34ca87cb1" category="section-title">Punti da ricordare</block>
  <block id="8e6eaed3852a3b311ab6ed1b8b6fc239" category="list-text">Nei modelli di storage ibrido, posizionare i carichi di lavoro di livello 1 o ad alta priorità sul datastore vSAN per soddisfare qualsiasi requisito di latenza specifico, poiché fanno parte dell'host stesso e si trovano nelle vicinanze. Utilizzare meccanismi in-guest per qualsiasi workload VM per cui le latenze transazionali sono accettabili.</block>
  <block id="43ff7a71a2ea2fc47a29d410cd1e4944" category="list-text">Utilizza la tecnologia NetApp SnapMirror® per replicare i dati del carico di lavoro dal sistema ONTAP on-premise a Cloud Volumes ONTAP o Amazon FSX per NetApp ONTAP per semplificare la migrazione utilizzando meccanismi a livello di blocco. Ciò non si applica a Azure NetApp Files e ai servizi Cloud Volumes. Per la migrazione dei dati a Azure NetApp Files o servizi cloud Volumes, utilizzare NetApp XCP, Cloud Sync, rysnc o robocopy a seconda del protocollo file utilizzato.</block>
  <block id="d3c0fd4b510310b9bd00463208eade94" category="list-text">I test mostrano una latenza aggiuntiva di 2-4 ms durante l'accesso allo storage dai rispettivi SDDC. Considerare questa latenza aggiuntiva nei requisiti dell'applicazione quando si esegue la mappatura dello storage.</block>
  <block id="b83cf0bc9b65a0fcd5f49d4c96dceea8" category="list-text">Per il montaggio dello storage connesso agli ospiti durante il failover di test e il failover effettivo, assicurarsi che gli iniziatori iSCSI siano riconfigurati, che il DNS sia aggiornato per le condivisioni SMB e che i punti di montaggio NFS siano aggiornati in fstab.</block>
  <block id="1b4048870ed334dbc2e7d6f09a814188" category="list-text">Assicurarsi che le impostazioni del Registro di sistema di i/o multipath Microsoft (MPIO), firewall e timeout del disco in-guest siano configurate correttamente all'interno della macchina virtuale.</block>
  <block id="bf3f0fd9ec5faf81793c3abc5e3b9127" category="admonition">Questo vale solo per lo storage connesso guest.</block>
  <block id="00b23e82efc2ec82b134496e575a934c" category="section-title">Vantaggi dello storage cloud NetApp</block>
  <block id="80def6ec4d999fc4d082800c8c33f6ec" category="paragraph">Lo storage cloud di NetApp offre i seguenti vantaggi:</block>
  <block id="2e594db552f7cd9c7f02d87507dbb471" category="list-text">Migliora la densità di calcolo-storage scalando lo storage indipendentemente dal calcolo.</block>
  <block id="479f9f236fc4cffa74f2e94b654bbeeb" category="list-text">Consente di ridurre il numero di host, riducendo così il TCO complessivo.</block>
  <block id="108dd736471686a2b8b87154d73cbc5b" category="list-text">Il guasto del nodo di calcolo non influisce sulle prestazioni dello storage.</block>
  <block id="a85e0a264279b851fbcec367c181932e" category="list-text">La risagomatura dei volumi e la funzionalità dinamica a livello di servizio di Azure NetApp Files consentono di ottimizzare i costi dimensionando i carichi di lavoro a stato stazionario e impedendo in tal modo l'over provisioning.</block>
  <block id="4e24ca7789e0b9320e302b8efa2caf9f" category="list-text">Le efficienze dello storage, il tiering del cloud e le funzionalità di modifica del tipo di istanza di Cloud Volumes ONTAP consentono di aggiungere e scalare lo storage in modo ottimale.</block>
  <block id="d7a87fa8fc914cf57f38eff05d53faa2" category="list-text">Impedisce l'overprovisioning delle risorse di storage vengono aggiunte solo quando necessario.</block>
  <block id="940eacbcb0faa8c3b1e0d995c154f693" category="list-text">Copie Snapshot e cloni efficienti consentono di creare rapidamente copie senza alcun impatto sulle performance.</block>
  <block id="a9e4a9fcd1f9bf0a9d0d0b2c0f198db5" category="list-text">Aiuta a risolvere gli attacchi ransomware utilizzando il ripristino rapido dalle copie Snapshot.</block>
  <block id="caf9b805c37cab661d4e3a26b7f71109" category="list-text">Offre un disaster recovery regionale basato su trasferimento incrementale dei blocchi efficiente e un livello di blocchi di backup integrato nelle varie regioni per offrire RPO e RTO migliori.</block>
  <block id="658fb5ef00749e8af5a974f612adea9b" category="section-title">Presupposti</block>
  <block id="a9e63f2a8549d717b777806268a0c0cb" category="list-text">La tecnologia SnapMirror o altri meccanismi di migrazione dei dati rilevanti sono abilitati. Esistono molte opzioni di connettività, da on-premise a qualsiasi cloud hyperscaler. Utilizzare il percorso appropriato e collaborare con i team di rete interessati.</block>
  <block id="478a13ed02b948c9cfd89a6197062012" category="admonition">Coinvolgi i Solution Architect di NetApp e i rispettivi cloud architect hyperscaler per la pianificazione e il dimensionamento dello storage e il numero richiesto di host. NetApp consiglia di identificare i requisiti di performance dello storage prima di utilizzare Cloud Volumes ONTAP Sizer per finalizzare il tipo di istanza dello storage o il livello di servizio appropriato con il throughput corretto.</block>
  <block id="c748546b5854ecb146d9caa41d781bdb" category="section-title">Architettura dettagliata</block>
  <block id="6e74d566879067f078b210f01e393989" category="paragraph">Da un punto di vista di alto livello, questa architettura (illustrata nella figura seguente) illustra come ottenere connettività multicloud ibrida e portabilità delle applicazioni tra più cloud provider utilizzando NetApp Cloud Volumes ONTAP, Cloud Volumes Service per Google Cloud e Azure NetApp Files come opzione aggiuntiva di storage in-guest.</block>
  <block id="1a8ac44404b1e5888d83801ac116ff66" category="inline-image-macro">Architettura di cloud ibrido aziendale</block>
  <block id="855b05f645c80247a3f11392cab187c2" category="paragraph"><block ref="855b05f645c80247a3f11392cab187c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b632c27ff82cfe142baffd346253a21b" category="doc">Casi di utilizzo per NetApp Hybrid Multibloud con VMware</block>
  <block id="5f1bd6ade489565bebba9a771b93fe70" category="paragraph">Panoramica dei casi di utilizzo importanti per l'organizzazione IT durante la pianificazione di implementazioni cloud ibrido o cloud-first.</block>
  <block id="0812fc943ecbd9a54d88fb25729d0aa5" category="section-title">Casi di utilizzo più comuni</block>
  <block id="f136615e6f2c1b330afb72bf4a45b4a4" category="paragraph">I casi di utilizzo includono:</block>
  <block id="3481fb80f122383c65ff8c6c8fd8c943" category="list-text">Disaster recovery,</block>
  <block id="4127bac8297e2af8866315910651ce47" category="list-text">Hosting dei carichi di lavoro durante la manutenzione del data center, * rapida esplosione in cui sono richieste risorse aggiuntive oltre a quanto previsto nel data center locale,</block>
  <block id="20b1c73b5938d2d878aa1d96fee7f1b2" category="list-text">Espansione del sito VMware,</block>
  <block id="5fe13b2b805496310dbaa281d7325877" category="list-text">Migrazione rapida al cloud,</block>
  <block id="b278a6d011d590bb350b9cb81c21a732" category="list-text">Dev/test, e.</block>
  <block id="04e248dee456b1f3910d53450d745125" category="list-text">Modernizzazione delle applicazioni sfruttando le tecnologie supplementari del cloud.</block>
  <block id="443f43c84a8efb54c46feb5a61b1a9cc" category="paragraph">In questa documentazione, i riferimenti al workload cloud verranno dettagliati utilizzando i casi di utilizzo di VMware. Questi casi di utilizzo sono:</block>
  <block id="bc262005b263505cc0464e05c4324687" category="section-title">Dentro il percorso DELL'IT</block>
  <block id="cfdb9aabb4aedf8cad2e330ba5a516a3" category="paragraph">La maggior parte delle organizzazioni è in viaggio verso la trasformazione e la modernizzazione. Nell'ambito di questo processo, le aziende stanno cercando di utilizzare gli investimenti VMware esistenti, sfruttando al contempo i vantaggi del cloud e esplorando i modi per rendere il processo di migrazione il più possibile perfetto. Questo approccio renderebbe molto semplice il loro impegno di modernizzazione perché i dati sono già nel cloud.</block>
  <block id="0257f1ddf73d49021a7feba150b7ea8b" category="paragraph">La risposta più semplice a questo scenario è rappresentata dalle offerte VMware in ogni hyperscaler. Come NetApp® Cloud Volumes, VMware offre un modo per spostare o estendere ambienti VMware on-premise su qualsiasi cloud, consentendo di mantenere risorse, competenze e strumenti on-premise esistenti durante l'esecuzione nativa dei carichi di lavoro nel cloud. Questo riduce i rischi perché non ci saranno interruzioni di servizio o necessità di modifiche IP e offre al team IT la possibilità di operare nel modo in cui si svolgono on-premise utilizzando le competenze e gli strumenti esistenti. Questo può portare a migrazioni del cloud accelerate e a una transizione molto più fluida verso un'architettura multicloud ibrida.</block>
  <block id="77d50dd2ce4e2531e14f13434a560e7d" category="section-title">Comprendere l'importanza delle opzioni di storage NFS supplementari</block>
  <block id="de8529127f85189767876e4d9a97427c" category="paragraph">Mentre VMware in qualsiasi cloud offre funzionalità ibride uniche a tutti i clienti, opzioni di storage NFS supplementari limitate hanno limitato la sua utilità per le organizzazioni con carichi di lavoro elevati in termini di storage. Poiché lo storage è direttamente legato agli host, l'unico modo per scalare lo storage è aggiungere più host, e questo può aumentare i costi del 35-40% o più per i carichi di lavoro a elevato utilizzo dello storage. Questi carichi di lavoro necessitano solo di storage aggiuntivo, non di potenza aggiuntiva. Ma ciò significa pagare per altri host.</block>
  <block id="0362604333fcf179ebf8b873f8f8c0ec" category="paragraph">Consideriamo questo scenario:</block>
  <block id="b401aa039e47ba98bfaca10532e40d08" category="paragraph">Un cliente richiede solo cinque host per CPU e memoria, ma ha molte esigenze di storage e ha bisogno di 12 host per soddisfare i requisiti di storage. Questo requisito finisce per mettere a punto la scala finanziaria dovendo acquistare la potenza aggiuntiva, quando è necessario solo incrementare lo storage.</block>
  <block id="7c25e9d8a9748905f5d456e20a93b413" category="paragraph">Quando stai pianificando l'adozione e la migrazione del cloud, è sempre importante valutare l'approccio migliore e seguire il percorso più semplice per ridurre gli investimenti totali. L'approccio più comune e più semplice per qualsiasi migrazione applicativa è il rehosting (noto anche come Lift and Shift) in cui non esiste una macchina virtuale (VM) o una conversione dei dati. L'utilizzo di NetApp Cloud Volumes con il software-defined data center (SDDC) VMware, integrando al contempo vSAN, offre un'opzione semplice di "lift-and-shift".</block>
  <block id="ba756c1a2b93ad97a639914aae828a16" category="doc">Funzionalità NetApp per AWS VMC</block>
  <block id="d22e98327d29984cdf19ebfeeb53bd99" category="paragraph">Scopri di più sulle funzionalità offerte da NetApp in AWS VMware Cloud (VMC), da NetApp come dispositivo di storage connesso come guest o come datastore NFS supplementare alla migrazione dei flussi di lavoro, all'estensione/diffusione nel cloud, al backup/ripristino e al disaster recovery.</block>
  <block id="8658ccb747e94ac624861f5761a34716" category="inline-link-macro">Configurazione di VMC in AWS</block>
  <block id="202373c4c91793dc8fb54647ff8a2241" category="list-text"><block ref="202373c4c91793dc8fb54647ff8a2241" category="inline-link-macro-rx"></block></block>
  <block id="e9f84da32eb512bd768458a738ed8aa6" category="inline-link-macro">Opzioni di storage NetApp per VMC</block>
  <block id="9597c351929448a6eea4162c4f4a80db" category="list-text"><block ref="9597c351929448a6eea4162c4f4a80db" category="inline-link-macro-rx"></block></block>
  <block id="461ab3a83d6c51e1cc25f42118f407bd" category="paragraph">Visualizza i dettagli <block ref="f56028ac73883785be6a54941a0e4e64" category="inline-link-macro-rx"></block>.</block>
  <block id="e3dea11e8144be98f637687e2a2cf316" category="paragraph">Lo storage NetApp può essere utilizzato in diversi modi, sia come congettura connessa che come datastore NFS supplementare, all'interno di AWS VMC.</block>
  <block id="7bf09ad035c9bf793d2fa043537aefb5" category="paragraph">Visualizza i dettagli <block ref="cfba6c34c6cd33cf1694f8b48900db44" category="inline-link-macro-rx"></block>. Visualizza i dettagli <block ref="a17693751f1eec7b9dedb49cf6a85cf2" category="inline-link-macro-rx"></block>.</block>
  <block id="cb9ab2dcef988aa0eaa2da1d789cfdb4" category="section-title">Casi di utilizzo della soluzione</block>
  <block id="3721bfebe60fa9888e0ea17bd294772d" category="paragraph">Con le soluzioni cloud NetApp e VMware, molti casi di utilizzo sono semplici da implementare nel tuo AWS VMC. I casi di utilizzo sono definiti per ciascuna delle aree cloud definite da VMware:</block>
  <block id="7c9a6204c3d04cd593127efe773bc82e" category="inline-link-macro">Esplora le soluzioni NetApp per AWS VMC</block>
  <block id="e9923439d335946afaff146da3d107ff" category="paragraph"><block ref="e9923439d335946afaff146da3d107ff" category="inline-link-macro-rx"></block></block>
  <block id="110493136fe9c9cec7895d42493cf949" category="doc">TR-4938: Montare Amazon FSX per ONTAP come datastore NFS con VMware Cloud su AWS</block>
  <block id="fac58d9bf77947f6384b904919414388" category="paragraph">Ogni organizzazione di successo sta passando per la trasformazione e la modernizzazione. Nell'ambito di questo processo, le aziende utilizzano solitamente i propri investimenti VMware esistenti per sfruttare i vantaggi del cloud e scoprire come migrare, eseguire il burst, estendere e fornire il disaster recovery per i processi nel modo più semplice possibile. I clienti che migrano al cloud devono valutare i casi di utilizzo per flessibilità e burst, uscita dal data center, consolidamento del data center, scenari di fine ciclo di vita, fusioni, acquisizioni e così via.</block>
  <block id="040632d7dc15d3ff95c3010b585c825d" category="inline-link">integrazione recente</block>
  <block id="d790d297409e3864a7ea5e89c42f2281" category="paragraph">Anche se VMware Cloud su AWS è l'opzione preferita dalla maggior parte dei clienti perché offre funzionalità ibride uniche a un cliente, opzioni di storage nativo limitate ne hanno limitato l'utilità per le organizzazioni con carichi di lavoro elevati in termini di storage. Poiché lo storage è direttamente legato agli host, l'unico modo per scalare lo storage è aggiungere più host, che possono aumentare i costi del 35-40% o più per i carichi di lavoro a elevato utilizzo dello storage. Questi carichi di lavoro richiedono storage aggiuntivo e performance separate, non potenza aggiuntiva, ma ciò significa pagare per altri host. È qui che si trova<block ref="ce6e0c0e7e2ab2c5f159e9999125a0f1" category="inline-link-rx"></block> Di FSX per ONTAP è utile per i carichi di lavoro con storage e performance intensive con VMware Cloud su AWS.</block>
  <block id="419a1659c567e39948d6e6e837c207d8" category="paragraph">Consideriamo il seguente scenario: Un cliente richiede otto host per la potenza (vCPU/VMEM), ma ha anche un requisito sostanziale per lo storage. In base alla loro valutazione, sono necessari 16 host per soddisfare i requisiti di storage. Questo aumenta il TCO complessivo perché devono acquistare tutta la potenza aggiuntiva quando è necessario solo uno storage maggiore. Questo è valido per qualsiasi caso di utilizzo, inclusi migrazione, disaster recovery, bursting, sviluppo/test, e così via.</block>
  <block id="477aa009d1d8f0ca50a38092473e92c8" category="paragraph">Questo documento illustra i passaggi necessari per il provisioning e l'aggiunta di FSX per ONTAP come datastore NFS per VMware Cloud su AWS.</block>
  <block id="51c7ff4d9c3185f2df469eed762010d5" category="inline-link-macro">Tech zone di VMware Cloud</block>
  <block id="baab3b6c6024ccda908423e27d1a7d5b" category="admonition">Questa soluzione è disponibile anche da VMware. Visitare il <block ref="e4f8fde8ba3579a04642cf870e6e362f" category="inline-link-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="dfc876546f6dc1183356f103bca8c9bf" category="section-title">Opzioni di connettività</block>
  <block id="a8a748d1990bd3dbc648c22396cec9c4" category="admonition">VMware Cloud su AWS supporta implementazioni multi-AZ e single-AZ di FSX per ONTAP.</block>
  <block id="96ebe87ba2bf6e2436936fad5261faee" category="paragraph">In questa sezione viene descritta l'architettura di connettività di alto livello e le fasi necessarie per implementare la soluzione per espandere lo storage in un cluster SDDC senza la necessità di aggiungere altri host.</block>
  <block id="f86935ff4bae98bba5454898ea941c13" category="paragraph"><block ref="f86935ff4bae98bba5454898ea941c13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5dfb62423539055e813d9c1ad0de5ec" category="paragraph">Le fasi di implementazione di alto livello sono le seguenti:</block>
  <block id="a7e048390e1de16427d130135387bbfa" category="list-text">Creare Amazon FSX per ONTAP in un nuovo VPC designato.</block>
  <block id="1f950f8c314491fa3429d8c2b47b567d" category="list-text">Creare un gruppo SDDC.</block>
  <block id="564e0792e18e12a265348716dc476e35" category="list-text">Creare VMware Transit Connect e un allegato TGW.</block>
  <block id="6618150a8dc116ed81a57b9c0241d023" category="list-text">Configurare il routing (AWS VPC e SDDC) e i gruppi di sicurezza.</block>
  <block id="657ef96833b0b326d08849a14b70424f" category="list-text">Collegare un volume NFS come datastore al cluster SDDC.</block>
  <block id="4950c77542ffaf6f7c4295f413cd34bf" category="inline-link-macro">Introduzione a VMware Cloud su AWS</block>
  <block id="38cb82c3cccc048a7afcc98467fce2aa" category="paragraph">Prima di eseguire il provisioning e collegare FSX per ONTAP come datastore NFS, è necessario configurare un ambiente VMware su cloud SDDC o aggiornare un SDDC esistente alla versione 1.20 o superiore. Per ulteriori informazioni, consultare <block ref="8f2441f58c4fdf4959e58cb9afc7d8c0" category="inline-link-macro-rx"></block>.</block>
  <block id="fcb9956e91549e3dd62d5abdb369413b" category="admonition">FSX per ONTAP non è attualmente supportato con i cluster estesi.</block>
  <block id="ee377d68ed297e79a44797bf1a95c224" category="paragraph">Questo documento illustra i passaggi necessari per configurare Amazon FSX per ONTAP con VMware cloud su AWS. Amazon FSX per ONTAP offre opzioni eccellenti per implementare e gestire i carichi di lavoro delle applicazioni insieme ai file service, riducendo al contempo il TCO, rendendo i requisiti dei dati perfetti a livello applicativo. Qualunque sia il caso d'utilizzo, scegli VMware Cloud su AWS insieme ad Amazon FSX per ONTAP per ottenere una rapida realizzazione dei vantaggi del cloud, un'infrastruttura coerente e operazioni da on-premise ad AWS, portabilità bidirezionale dei carichi di lavoro e capacità e performance di livello Enterprise. Si tratta degli stessi processi e procedure familiari utilizzati per collegare lo storage. Ricorda che è solo la posizione dei dati che sono stati modificati insieme ai nuovi nomi; i tool e i processi rimangono tutti gli stessi e Amazon FSX per ONTAP aiuta a ottimizzare l'implementazione generale.</block>
  <block id="0f7e01a8024cd158b945c34799508470" category="paragraph">Per ulteriori informazioni su questo processo, segui il video dettagliato.</block>
  <block id="eee9b49313d921d448286765fe05bd22" category="doc">Soluzioni multicloud ibride NetApp per AWS/VMC</block>
  <block id="0bcfdba2f090838df9da44d825fedc49" category="doc">TR 4942: Migrazione dei carichi di lavoro al datastore FSX ONTAP con VMware HCX</block>
  <block id="ddfd90f2a10c16cbd6548844b07532c2" category="paragraph">Autore: NetApp Solutions Engineering</block>
  <block id="086d898e7d4a481c2147d4eb71dff1f6" category="section-title">Panoramica: Migrazione di macchine virtuali con VMware HCX, datastore supplementari FSX ONTAP e VMware Cloud</block>
  <block id="82778188ea3c0ca7871389afec5bfd03" category="paragraph">Un caso di utilizzo comune per VMware Cloud (VMC) su Amazon Web Services (AWS), con il datastore NFS supplementare su Amazon FSX per NetApp ONTAP, è la migrazione dei workload VMware. VMware HCX è un'opzione preferita e offre diversi metodi di migrazione per spostare macchine virtuali (VM) on-premise e i relativi dati, in esecuzione su qualsiasi datastore supportato da VMware, negli archivi dati VMC, che includono datastore NFS supplementari su FSX per ONTAP.</block>
  <block id="2fbfc2601ddccd56b7728df6f0a658e1" category="paragraph">VMware HCX è principalmente una piattaforma di mobilità progettata per semplificare la migrazione dei workload, il ribilanciamento dei workload e la business continuity tra i cloud. È incluso in VMware Cloud su AWS e offre diversi modi per migrare i carichi di lavoro e può essere utilizzato per le operazioni di disaster recovery (DR).</block>
  <block id="aabc04eb6cd0b22670013ea8212b7a4f" category="paragraph">Questo documento fornisce istruzioni dettagliate per l'implementazione e la configurazione di VMware HCX, inclusi tutti i suoi componenti principali, on-premise e sul cloud data center, che abilita vari meccanismi di migrazione delle macchine virtuali.</block>
  <block id="d493b7ce0e1cf6434fdce9bd4fa1c847" category="inline-link">Introduzione alle implementazioni HCX</block>
  <block id="274e6762dc6bf155637729306a74154b" category="inline-link">Installare l'elenco di controllo B - HCX con VMware Cloud su AWS SDDC Destination Environment</block>
  <block id="1db2f90540d47d2fe14bfc6cad01537a" category="paragraph">Per ulteriori informazioni, vedere<block ref="871067259283ae637dd3ddcf90a49e5d" category="inline-link-rx"></block> e.<block ref="b5449e907f27219538721e57c42a92c0" category="inline-link-rx"></block>.</block>
  <block id="0ba40ecb813b20bd8c3277c4afcbd451" category="example-title">Passaggi di alto livello</block>
  <block id="18ad70c16d20c99de2753c4da7fb1291" category="paragraph">Questo elenco fornisce i passaggi di alto livello per installare e configurare VMware HCX:</block>
  <block id="b9b7e6b65417eaac8eeb13d3f809942d" category="list-text">Attivare HCX per il data center software-defined (SDDC) VMC tramite VMware Cloud Services Console.</block>
  <block id="76f775a9fe0b12df87ae0ad6b34efdd9" category="list-text">Scaricare e implementare IL programma di installazione di HCX Connector OVA nel server vCenter on-premise.</block>
  <block id="f970657dc986e56f66a60a02b1210c43" category="list-text">Attivare HCX con una chiave di licenza.</block>
  <block id="2d7e8f746bd165e0f342b659b51cff2c" category="list-text">Associare il connettore VMware HCX on-premise con VMC HCX Cloud Manager.</block>
  <block id="612a4c795715d17bfff4e0ba3a8f66d1" category="list-text">Configurare il profilo di rete, il profilo di calcolo e la mesh del servizio.</block>
  <block id="a9f9ba84cb2c76d9b8033c6f9ad14642" category="list-text">(Facoltativo) eseguire l'estensione di rete per estendere la rete ed evitare il re-IP.</block>
  <block id="dbed86346a8d7cb3692ba413f7e14f56" category="list-text">Verificare lo stato dell'appliance e assicurarsi che sia possibile eseguire la migrazione.</block>
  <block id="2f2c97fb0d914a7fc7bcb2c8fad16868" category="list-text">Migrare i carichi di lavoro delle macchine virtuali.</block>
  <block id="f5633594a47ccbe1e89229d43cbce0ec" category="inline-link">Preparazione per l'installazione HCX</block>
  <block id="ecdf05ad108113e6a7e36c14f4d8e596" category="paragraph">Prima di iniziare, assicurarsi che siano soddisfatti i seguenti prerequisiti. Per ulteriori informazioni, vedere<block ref="c59343d9a8c2798bf6815397e3f08bd3" category="inline-link-rx"></block>. Una volta soddisfatti i prerequisiti, inclusa la connettività, configurare e attivare HCX generando una chiave di licenza dalla console VMware HCX in VMC. Dopo l'attivazione DI HCX, il plug-in vCenter viene implementato ed è possibile accedervi utilizzando vCenter Console per la gestione.</block>
  <block id="f0983a6fa9c97fbc87ff3ad43495e008" category="paragraph">Prima di procedere con l'attivazione E l'implementazione DI HCX, è necessario completare i seguenti passaggi di installazione:</block>
  <block id="67863abb3ec8a28f54adf852298b392b" category="inline-link">Link NetApp</block>
  <block id="dba413fdbeffb35a4459e9d3f45be3bd" category="inline-link">Link VMware</block>
  <block id="b390c6b07bec05579868558e66fda8e2" category="list-text">Utilizzare un SDDC VMC esistente o creare un nuovo SDDC in seguito<block ref="11000cc7aedbe4805fa20a67d23d81ac" category="inline-link-rx"></block> o questo<block ref="5f912d133d878a69c5af374752da199e" category="inline-link-rx"></block>.</block>
  <block id="67cff13cad47354f1f51ce3ef47c6ddc" category="list-text">Il percorso di rete dall'ambiente vCenter on-premise all'SDDC VMC deve supportare la migrazione delle macchine virtuali utilizzando vMotion.</block>
  <block id="f3b5e5598d4c0c196bd2fd79b000637f" category="inline-link">porte e regole del firewall</block>
  <block id="c9f9609ee5731fe3777e57937464dc54" category="list-text">Assicurarsi di aver selezionato il necessario<block ref="69c9d7a74dad51c1c47ea8141c218514" category="inline-link-rx"></block> Sono consentiti per il traffico vMotion tra vCenter Server on-premise e vCenter SDDC.</block>
  <block id="aa8db0799849f7e0b11c7c3594394423" category="list-text">Il volume NFS FSX per ONTAP deve essere montato come datastore supplementare nell'SDDC VMC. Per collegare gli archivi dati NFS al cluster appropriato, seguire la procedura descritta in questa sezione<block ref="2d161daeb93489b09b5e8bcd39dbc4b1" category="inline-link-rx"></block> o questo<block ref="6eb21d78e613b27f69be6d996a6367b3" category="inline-link-rx"></block>.</block>
  <block id="915747189317f7496ecb2bcdc22e83b5" category="paragraph">A scopo di test, l'ambiente di laboratorio on-premise utilizzato per questa convalida è stato collegato tramite una VPN sito-sito ad AWS VPC, che ha consentito la connettività on-premise ad AWS e a VMware Cloud SDDC tramite External Transit Gateway. La migrazione HCX e il traffico di estensione della rete fluiscono su Internet tra SDDC di destinazione cloud on-premise e VMware. Questa architettura può essere modificata per utilizzare le interfacce virtuali private Direct Connect.</block>
  <block id="20c789c477f416c40ed37a0a96f352d5" category="paragraph">L'immagine seguente mostra l'architettura di alto livello.</block>
  <block id="9f4db1da9d84fe1111fd9ae7c377f786" category="paragraph"><block ref="9f4db1da9d84fe1111fd9ae7c377f786" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d84f7e9d42c2c0ee4f87ddeaa2e09bb2" category="paragraph">Seguire la serie di passaggi per completare l'implementazione di questa soluzione:</block>
  <block id="5189f076565998395f00538902b201d3" category="example-title">Fase 1: Attivare HCX tramite VMC SDDC utilizzando l'opzione Add-ons</block>
  <block id="f4ca86f94d0e12644ce102e7c48d6030" category="paragraph">Per eseguire l'installazione, attenersi alla seguente procedura:</block>
  <block id="84d84827fbe9c4b33c9c3b806b314d3f" category="inline-link">vmc.vmware.com</block>
  <block id="db44791d0479a0d2c9f5549eac8850ad" category="list-text">Accedere alla console VMC all'indirizzo<block ref="98f8f917cb7f10ee415fb6ce242d9349" category="inline-link-rx"></block> E accedere all'inventario.</block>
  <block id="049aac4163d4ee979d2ebd21434216a2" category="list-text">Per selezionare l'SDDC appropriato e accedere ai componenti aggiuntivi, fare clic su View Details (Visualizza dettagli) su SDDC e selezionare la scheda Add Ons (Aggiungi).</block>
  <block id="933c74bf858432dc81f521597cffbfbb" category="list-text">Fare clic su Activate for VMware HCX.</block>
  <block id="7335132a517aad5765c48773404c2687" category="admonition">Il completamento di questa fase richiede fino a 25 minuti.</block>
  <block id="be7b0f3d5e22843c4a2107342b36330b" category="paragraph"><block ref="be7b0f3d5e22843c4a2107342b36330b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcf3d539a908f48f7d82acf7470675f7" category="list-text">Una volta completata l'implementazione, convalidare l'implementazione confermando che HCX Manager e i relativi plug-in associati sono disponibili in vCenter Console.</block>
  <block id="8c0cff0c106bc3f5a4dd79c01c3de7a9" category="list-text">Creare i firewall di Management Gateway appropriati per aprire le porte necessarie per accedere A HCX Cloud Manager.HCX Cloud Manager è ora pronto per le operazioni HCX.</block>
  <block id="ae33ed8b7695cc113850f5a13bab6e56" category="example-title">Fase 2: Implementazione dell'OVA del programma di installazione nel server vCenter on-premise</block>
  <block id="6eac4c95d8f88bfb601f7b87770513ab" category="paragraph">Affinché il connettore on-premise comunichi con HCX Manager in VMC, assicurarsi che le porte firewall appropriate siano aperte nell'ambiente on-premise.</block>
  <block id="185b9319145cb225cdb1256b494e0595" category="list-text">Dalla console VMC, accedere alla dashboard HCX, accedere a Administration (Amministrazione) e selezionare la scheda Systems Update (aggiornamento sistemi). Fare clic su Request a Download link for the HCX Connector OVA image (Richiedi un link di download per l'immagine OVA</block>
  <block id="039b399de18508b9f1029358886fea99" category="list-text">Dopo aver scaricato HCX Connector, implementare OVA nel server vCenter on-premise. Fare clic con il pulsante destro del mouse su vSphere Cluster e selezionare l'opzione Deploy OVF Template.</block>
  <block id="bd18e96a29eec74967666d876a146937" category="paragraph"><block ref="bd18e96a29eec74967666d876a146937" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8df6b0257b180b48db7d56e06e4da54" category="list-text">Inserire le informazioni richieste nella procedura guidata Deploy OVF Template (implementazione modello OVF), fare clic su Next (Avanti), quindi su Finish (fine) per implementare VMware HCX Connector OVA.</block>
  <block id="dca749083ce6c763573225ed6a46a64e" category="inline-link">Guida utente di VMware HCX</block>
  <block id="8925cbdefd949dca662858e368d4ccfb" category="list-text">Accendere manualmente l'appliance virtuale.per istruzioni dettagliate, visitare il sito Web<block ref="856d054195f2a40a0c4a2869d5895904" category="inline-link-rx"></block>.</block>
  <block id="6897bb7015f874baf69560eef515010c" category="example-title">Fase 3: Attivare HCX Connector con la chiave di licenza</block>
  <block id="fab9859fcf95f41f7bb654e91e6876b4" category="paragraph">Dopo aver implementato VMware HCX Connector OVA on-premise e avviato l'appliance, completare la seguente procedura per attivare HCX Connector. Generare la chiave di licenza dalla console VMware HCX in VMC e immettere la licenza durante la configurazione del connettore VMware HCX.</block>
  <block id="fddda62632eb91015346909c9da3cf70" category="list-text">Da VMware Cloud Console, accedere a Inventory (inventario), selezionare SDDC e fare clic su View Details (Visualizza dettagli). Dalla scheda Add Ons (Aggiungi servizio), nel riquadro VMware HCX, fare clic su Open HCX (Apri HCX).</block>
  <block id="51e51578490c90a69c673d41361b0070" category="list-text">Dalla scheda Activation Keys (chiavi di attivazione), fare clic su Create Activation Key (Crea chiave di Selezionare il tipo di sistema come connettore HCX e fare clic su Confirm (Conferma) per generare la chiave. Copiare la chiave di attivazione.</block>
  <block id="e30847f53a6e375f1da81f871c44e963" category="paragraph"><block ref="e30847f53a6e375f1da81f871c44e963" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c410deb9d7b04917aff523f97f944894" category="admonition">È necessaria una chiave separata per ciascun connettore HCX implementato on-premise.</block>
  <block id="1111fa8f5187058abdce3daca03b7e32" category="inline-link"><block ref="1111fa8f5187058abdce3daca03b7e32" category="inline-link-rx"></block></block>
  <block id="d9432955aa7705a1f97c9e94c730fdc9" category="list-text">Accedere a VMware HCX Connector on-premise all'indirizzo<block ref="ece20a9f7dc6720cdeb30c7e7733cd22" category="inline-link-rx"></block> utilizzando le credenziali di amministratore.</block>
  <block id="b2719f92794cef282f9cd7684baca4c4" category="admonition">Utilizzare la password definita durante l'implementazione di OVA.</block>
  <block id="f5f8371708aa6ae3ddb84d1f4d9b5d17" category="list-text">Nella sezione Licensing (licenze), inserire la chiave di attivazione copiata dal passaggio 2 e fare clic su Activate (attiva).</block>
  <block id="404a7c7a7d73b870628663e76e974d09" category="admonition">Il connettore HCX on-premise deve disporre di accesso a Internet per completare correttamente l'attivazione.</block>
  <block id="564ed09bba79e1d4262e37fc94987fbe" category="list-text">Nella sezione Datacenter Location, specificare la posizione desiderata per l'installazione di VMware HCX Manager on-premise. Fare clic su continua.</block>
  <block id="61ce05ace76ff1424841e5e551873a97" category="list-text">In System Name (Nome sistema), aggiornare il nome e fare clic su Continue (continua).</block>
  <block id="4bc852451f43c4b3df306f35e67e4178" category="list-text">Selezionare Sì, quindi continuare.</block>
  <block id="7eefbebbdefe472b13ce5d0bce410737" category="list-text">In Connect Your vCenter (Connetti il vCenter), fornire l'indirizzo IP o il nome di dominio completo (FQDN) e le credenziali per vCenter Server, quindi fare clic su Continue (continua).</block>
  <block id="47a7ea3464363cf9baa528c91d3aa4dc" category="admonition">Utilizzare l'FQDN per evitare problemi di comunicazione in un secondo momento.</block>
  <block id="eb7e70dd1954a71454c2e6a0cb9ed5f8" category="list-text">In Configure SSO/PSC (Configura SSO/PSC), fornire l'indirizzo FQDN o IP del controller dei servizi della piattaforma e fare clic su Continue (continua).</block>
  <block id="1f2f2ed2ec24b1f1ab37799a6f27fa40" category="admonition">Inserire l'indirizzo IP o l'FQDN del server vCenter.</block>
  <block id="24b993e60859697b0875bc838cfe12aa" category="list-text">Verificare che le informazioni siano inserite correttamente e fare clic su Restart (Riavvia).</block>
  <block id="b0fca3e3f2889bbec562577014fafd9a" category="list-text">Al termine dell'operazione, vCenter Server viene visualizzato in verde. VCenter Server e SSO devono avere i parametri di configurazione corretti, che devono essere gli stessi della pagina precedente.</block>
  <block id="8463d9f0fc95490bc0c65d3ba9063dea" category="admonition">Questo processo richiede circa 10–20 minuti e l'aggiunta del plug-in al server vCenter.</block>
  <block id="a56ac8f65b53b91dba588aafc428f8b2" category="paragraph"><block ref="a56ac8f65b53b91dba588aafc428f8b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65d6e263d26134bb05aeec17adc73a06" category="example-title">Fase 4: Associazione on-premise di VMware HCX Connector con VMC HCX Cloud Manager</block>
  <block id="f68b6001164eba9a9e765e551c59a3c1" category="list-text">Per creare una coppia di siti tra vCenter Server on-premise e VMC SDDC, accedere al vCenter Server on-premise e al plug-in del client Web HCX vSphere.</block>
  <block id="10f9af0781b3c0a9d621bac0b8719365" category="paragraph"><block ref="10f9af0781b3c0a9d621bac0b8719365" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1af79e59a8d820cc101f77efa75cb01d" category="list-text">In infrastruttura, fare clic su Aggiungi associazione sito. Per autenticare il sito remoto, immettere l'URL o l'indirizzo IP di VMC HCX Cloud Manager e le credenziali per il ruolo CloudAdmin.</block>
  <block id="1b49b2932a225dd49cc6f5298ad6cc8f" category="paragraph"><block ref="1b49b2932a225dd49cc6f5298ad6cc8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a7c72a1b7e925abd687d2c7a4ac5a2f" category="admonition">Le informazioni HCX possono essere recuperate dalla pagina Impostazioni SDDC.</block>
  <block id="1272226ee970b8e49c49d25af6f4b6b8" category="paragraph"><block ref="1272226ee970b8e49c49d25af6f4b6b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="838d70471e28171464ffd4fed8d9df3a" category="paragraph"><block ref="838d70471e28171464ffd4fed8d9df3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dbcfb2058c277401b0872487463fe313" category="list-text">Per avviare l'associazione del sito, fare clic su Connect (Connetti).</block>
  <block id="2147cde45e80d7c6a5db679f7180eab4" category="admonition">VMware HCX Connector deve essere in grado di comunicare con HCX Cloud Manager IP sulla porta 443.</block>
  <block id="ddea1cbf444f5d4e69d68b23eb0b4b59" category="list-text">Una volta creata l'associazione, l'associazione del sito appena configurata è disponibile nella dashboard HCX.</block>
  <block id="38bca9c1088c36da27f6910232836b09" category="example-title">Fase 5: Configurare il profilo di rete, il profilo di calcolo e la mesh del servizio</block>
  <block id="618a4f677a45dc2b53f7c464b5598c28" category="paragraph">L'appliance VMware HCX Interconnect (HCX-IX) offre funzionalità di tunnel sicuro su Internet e connessioni private al sito di destinazione che consentono la replica e funzionalità basate su vMotion. L'interconnessione fornisce crittografia, ingegneria del traffico e una SD-WAN. Per creare l'appliance di interconnessione HCI-IX, attenersi alla seguente procedura:</block>
  <block id="f32fcca3303979d42a8f0be055fc36dd" category="list-text">In Infrastructure (infrastruttura), selezionare Interconnect (interconnessione) &gt; Multi-Site Service Mesh (Mesh servizio multi-sito) &gt; Compute Profiles (profili di calcolo) &gt; Create Compute Profile</block>
  <block id="46c0e6a1b2dbd6331bcea8e4726de843" category="admonition">I profili di calcolo contengono i parametri di calcolo, storage e implementazione di rete necessari per implementare un'appliance virtuale di interconnessione. Inoltre, specifica quale parte del data center VMware sarà accessibile al servizio HCX.</block>
  <block id="46a447d35c4917802c9d612dd8ede3b5" category="inline-link">Creazione di un profilo di calcolo</block>
  <block id="9fc475734bed02e370e17ea150a74fd3" category="paragraph">Per istruzioni dettagliate, vedere<block ref="3e2a71be9bcd47a34446e38d1b8f4987" category="inline-link-rx"></block>.</block>
  <block id="648388c6923f0b4fc45138b46fb56158" category="paragraph"><block ref="648388c6923f0b4fc45138b46fb56158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad3c8534d57516f63a1f263c7e4a4c7a" category="list-text">Una volta creato il profilo di calcolo, creare il profilo di rete selezionando Mesh servizio multi-sito &gt; profili di rete &gt; Crea profilo di rete.</block>
  <block id="52d18a4f9043fce9a1e9d57e92fc77a4" category="list-text">Il profilo di rete definisce un intervallo di indirizzi IP e reti che VERRANNO utilizzati DA HCX per le proprie appliance virtuali.</block>
  <block id="2565e95c468130be3fbdbb45da6cadeb" category="admonition">Questo richiede due o più indirizzi IP. Questi indirizzi IP verranno assegnati dalla rete di gestione alle appliance virtuali.</block>
  <block id="f62f78e1c7b4b764032cbdad0c61a6d0" category="paragraph"><block ref="f62f78e1c7b4b764032cbdad0c61a6d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9fad750cff1511b959d686e3a0829f0" category="inline-link">Creazione di un profilo di rete</block>
  <block id="51cbf458571723275b781ce4b3fec323" category="paragraph">Per istruzioni dettagliate, vedere<block ref="fb1b37f7979e3209d40171b59e47f33b" category="inline-link-rx"></block>.</block>
  <block id="784e6023ad40986353535651f974e468" category="admonition">Se si effettua la connessione a una SD-WAN tramite Internet, è necessario riservare gli IP pubblici nella sezione rete e sicurezza.</block>
  <block id="c1b5864550e5f67407a0efd2cbe55b67" category="list-text">Per creare una mesh del servizio, selezionare la scheda Service Mesh (Mesh del servizio) all'interno dell'opzione Interconnect (interconnessione) e selezionare on-premise and VMC SDDC sites (siti SDDC on-premise e VMC).</block>
  <block id="295ecbce57290e03752d2e06d4575fff" category="paragraph">La mesh del servizio stabilisce una coppia di profili di rete e di calcolo locale e remoto.</block>
  <block id="1e21db3cc04207cfb46fd912cdfef571" category="paragraph"><block ref="1e21db3cc04207cfb46fd912cdfef571" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dba94996b6f6f31ef7ea483dc8f0046c" category="admonition">Parte di questo processo prevede l'implementazione di appliance HCX che verranno configurate automaticamente sui siti di origine e di destinazione, creando un fabric di trasporto sicuro.</block>
  <block id="b7e93bb3e8f576437ca086d1702a7994" category="list-text">Selezionare i profili di calcolo di origine e remoti e fare clic su Continue (continua).</block>
  <block id="ef7ca07b9da6362e4aa341061333a66c" category="paragraph"><block ref="ef7ca07b9da6362e4aa341061333a66c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e42fcfe670e1a9e7a259fb3c9d3dad87" category="list-text">Selezionare il servizio da attivare e fare clic su Continue (continua).</block>
  <block id="ff89555f65d5e42967fac9abcecb74c8" category="paragraph"><block ref="ff89555f65d5e42967fac9abcecb74c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8438ec331921e82a31eaa97deb5f8c0" category="admonition">Per la migrazione vMotion assistita da replica, l'integrazione SRM e la migrazione assistita dal sistema operativo è richiesta una licenza HCX Enterprise.</block>
  <block id="9a44378d7dd14730acf075e18d7d8c29" category="list-text">Creare un nome per la mesh del servizio e fare clic su Finish (fine) per avviare il processo di creazione. Il completamento dell'implementazione richiede circa 30 minuti. Dopo aver configurato la mesh del servizio, sono state create l'infrastruttura virtuale e il networking necessari per migrare le VM dei carichi di lavoro.</block>
  <block id="725a12cf06f45e850e7588b816663c20" category="paragraph"><block ref="725a12cf06f45e850e7588b816663c20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d0de3992884fcc0e48531f19cce447e7" category="example-title">Fase 6: Migrazione dei carichi di lavoro</block>
  <block id="af65fc6bdee93e32363bfe5c2cf8ee3a" category="paragraph">HCX offre servizi di migrazione bidirezionale tra due o più ambienti distinti, come gli SDDC on-premise e VMC. È possibile migrare i carichi di lavoro delle applicazioni da e verso i siti attivati DA HCX utilizzando una vasta gamma di tecnologie di migrazione, come LA migrazione in blocco HCX, HCX vMotion, HCX Cold Migration, HCX Replication Assisted vMotion (disponibile con HCX Enterprise Edition) e HCX OS Assisted Migration (disponibile con HCX Enterprise Edition).</block>
  <block id="94638809b72d557d4335dfce65f69e35" category="inline-link">Tipi di migrazione VMware HCX</block>
  <block id="0afeac0ffbe358cc58864e34fc54c9b2" category="paragraph">Per ulteriori informazioni sulle tecnologie di migrazione HCX disponibili, consulta<block ref="17989ba7d4a97ba4d6ebb072be2dc216" category="inline-link-rx"></block></block>
  <block id="97957dd6d4c5d792035241d68a97795e" category="paragraph">L'appliance HCX-IX utilizza il servizio Mobility Agent per eseguire migrazioni vMotion, Cold e Replication Assisted vMotion (RAV).</block>
  <block id="2234ed56b9cbb2a083fd5fe49a89bce1" category="admonition">L'appliance HCX-IX aggiunge il servizio Mobility Agent come oggetto host in vCenter Server. Il processore, la memoria, lo storage e le risorse di rete visualizzati su questo oggetto non rappresentano il consumo effettivo dell'hypervisor fisico che ospita l'appliance IX.</block>
  <block id="c3735752087d3a11c85329680057de55" category="paragraph"><block ref="c3735752087d3a11c85329680057de55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c14d0d24d8dccac2ac3ca3ddacf8ba8" category="example-title">VMware HCX vMotion</block>
  <block id="8f2dbd716f60bbee8012a3f0e361fc65" category="paragraph">In questa sezione viene descritto il meccanismo vMotion DI HCX. Questa tecnologia di migrazione utilizza il protocollo VMware vMotion per migrare una macchina virtuale a VMC SDDC. L'opzione di migrazione vMotion viene utilizzata per la migrazione dello stato della macchina virtuale di una singola macchina virtuale alla volta. Durante questo metodo di migrazione non si verifica alcuna interruzione del servizio.</block>
  <block id="0c1394a246edcdcb98e3c5fe3cedabbb" category="admonition">Network Extension deve essere installato (per il gruppo di porte a cui è collegata la macchina virtuale) per migrare la macchina virtuale senza dover modificare l'indirizzo IP.</block>
  <block id="896f227a656a8b0f4a64aa3e12b2506e" category="list-text">Dal client vSphere on-premise, accedere a Inventory (inventario), fare clic con il pulsante destro del mouse sulla macchina virtuale da migrare e selezionare HCX Actions (azioni HCX) &gt; Migrate to HCX Target Site (Migra al sito di destinazione HCX).</block>
  <block id="d683c9596c42727fea13c654874f39be" category="paragraph"><block ref="d683c9596c42727fea13c654874f39be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4479366aca979ecb9be874cab7bc543" category="list-text">Nella procedura guidata Migrate Virtual Machine, selezionare Remote Site Connection (SDDC VMC di destinazione).</block>
  <block id="09ca4fea7b9ff384e38622ce7cc20a9c" category="paragraph"><block ref="09ca4fea7b9ff384e38622ce7cc20a9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67358e55b470861e1e14c63c30156dd4" category="list-text">Aggiungere un nome di gruppo e, in Transfer and Placement (trasferimento e posizionamento), aggiornare i campi obbligatori (Cluster, Storage e Destination Network), quindi fare clic su Validate (convalida).</block>
  <block id="1ce9ff194ee5bdbf4df7b739baf9b3d2" category="paragraph"><block ref="1ce9ff194ee5bdbf4df7b739baf9b3d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a961199f9300128fcaa431e9245ac13" category="list-text">Al termine dei controlli di convalida, fare clic su Go (Vai) per avviare la migrazione.</block>
  <block id="f3d5cf5ffd51c9062748a6a292f749f7" category="inline-link">Informazioni su VMware HCX vMotion e Cold Migration</block>
  <block id="136739244c82e4bdcdb6a1b1c3712d3b" category="admonition">Il trasferimento vMotion acquisisce la memoria attiva della macchina virtuale, il suo stato di esecuzione, il suo indirizzo IP e il suo indirizzo MAC. Per ulteriori informazioni sui requisiti e sulle limitazioni di HCX vMotion, vedere<block ref="011541f11351d17074bdfa0823ec743b" category="inline-link-rx"></block>.</block>
  <block id="f2ca81fdc3e7326c354dc180a98c7ef2" category="list-text">È possibile monitorare l'avanzamento e il completamento di vMotion dalla dashboard HCX &gt; Migration (HCX &gt; migrazione).</block>
  <block id="b41362505f00e258d5e04636a0edaf7c" category="paragraph"><block ref="b41362505f00e258d5e04636a0edaf7c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e4900648931ee918be9251a268e792c" category="example-title">VMotion VMware Replication Assisted</block>
  <block id="3bb995dd361711179fda278eb498a385" category="paragraph">Come si può notare dalla documentazione VMware, VMware HCX Replication Assisted vMotion (RAV) combina i vantaggi della migrazione in blocco e di vMotion. La migrazione in blocco utilizza la replica vSphere per migrare più macchine virtuali in parallelo: La macchina virtuale viene riavviata durante lo switchover. HCX vMotion esegue la migrazione senza downtime, ma viene eseguita in maniera seriale una macchina virtuale alla volta in un gruppo di replica. RAV replica la macchina virtuale in parallelo e la mantiene sincronizzata fino alla finestra di switchover. Durante il processo di switchover, effettua la migrazione di una macchina virtuale alla volta senza downtime per la macchina virtuale.</block>
  <block id="93e2f4753a86232a37f8bd57209f626d" category="paragraph">La seguente schermata mostra il profilo di migrazione come Replication Assisted vMotion.</block>
  <block id="7c12abc7edfaeb45279b8ee126759269" category="paragraph"><block ref="7c12abc7edfaeb45279b8ee126759269" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a740a2796b321475f6bd003fafa67e5b" category="paragraph">La durata della replica potrebbe essere maggiore rispetto al vMotion di un numero ridotto di macchine virtuali. Con RAV, sincronizzare solo i delta e includere i contenuti della memoria. Di seguito viene riportata una schermata dello stato della migrazione, che mostra come l'ora di inizio della migrazione sia la stessa e l'ora di fine sia diversa per ciascuna macchina virtuale.</block>
  <block id="27e8bd561ebb9d9ee4d23860c10a3883" category="paragraph"><block ref="27e8bd561ebb9d9ee4d23860c10a3883" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e61c2a41cf1924a0a1e3d5217e16a084" category="paragraph">Per ulteriori informazioni sulle opzioni di migrazione HCX e su come migrare i carichi di lavoro da on-premise a VMware Cloud su AWS utilizzando HCX, consulta la<block ref="15dbc17e63bae3f57dd4aa8612bacb9d" category="inline-link-rx"></block>.</block>
  <block id="f261622b527cc27756d5ba83c22662f8" category="admonition">VMware HCX vMotion richiede un throughput di 100 Mbps o superiore.</block>
  <block id="60bd242580d7de82c0a2e6eee14d2f50" category="admonition">Il datastore VMC FSX di destinazione per ONTAP deve disporre di spazio sufficiente per consentire la migrazione.</block>
  <block id="17e30673228b69814c7132c287c12ecb" category="paragraph">Sia che tu stia prendendo di mira il cloud all-cloud o ibrido e i dati che risiedono su storage di qualsiasi tipo/vendor in on-premise, Amazon FSX per NetApp ONTAP insieme A HCX offrono opzioni eccellenti per implementare e migrare i carichi di lavoro riducendo al contempo il TCO rendendo i requisiti dei dati perfetti per il livello applicativo. Qualunque sia il caso d'utilizzo, scegli VMC insieme a FSX per il datastore ONTAP per una rapida realizzazione dei benefici del cloud, un'infrastruttura coerente e operazioni su cloud multipli e on-premise, portabilità bidirezionale dei carichi di lavoro e capacità e performance di livello Enterprise. Si tratta degli stessi processi e procedure familiari utilizzati per connettere lo storage e migrare le macchine virtuali utilizzando la replica VMware vSphere, VMware vMotion o persino la copia NFC.</block>
  <block id="273435500e4b837aea488094a233f579" category="list-text">Ora puoi utilizzare Amazon FSX ONTAP come datastore con VMC SDDC.</block>
  <block id="cbbc4fc2bc12f5fd25f84b44f93fd5f3" category="list-text">È possibile migrare facilmente i dati da qualsiasi data center on-premise a VMC in esecuzione con FSX per datastore ONTAP</block>
  <block id="9004e09f6485129980daf3188affad35" category="list-text">È possibile espandere e ridurre facilmente il datastore FSX ONTAP per soddisfare i requisiti di capacità e performance durante l'attività di migrazione.</block>
  <block id="34e948a9d10cb991d2da187e3e54caef" category="list-text">Documentazione di VMware Cloud</block>
  <block id="56f2ce0be9d32c6c0e3c983d011be4d7" category="inline-link"><block ref="56f2ce0be9d32c6c0e3c983d011be4d7" category="inline-link-rx"></block></block>
  <block id="1427dee608f6801474787ea58df57a2c" category="paragraph"><block ref="1427dee608f6801474787ea58df57a2c" category="inline-link-rx"></block></block>
  <block id="cc788b7e72b2a734dd0985bd1e0e9fe3" category="list-text">Documentazione di Amazon FSX per NetApp ONTAP</block>
  <block id="9c7174d13497f84bdd0b3e21af13794d" category="inline-link"><block ref="9c7174d13497f84bdd0b3e21af13794d" category="inline-link-rx"></block></block>
  <block id="05c89cf5b898c5c58986dac08f22a2a1" category="paragraph"><block ref="05c89cf5b898c5c58986dac08f22a2a1" category="inline-link-rx"></block></block>
  <block id="61af664797ae795435faba35dd141335" category="inline-link"><block ref="61af664797ae795435faba35dd141335" category="inline-link-rx"></block></block>
  <block id="ab19b6733f7a9500ff9d392433071ef2" category="list-text"><block ref="ab19b6733f7a9500ff9d392433071ef2" category="inline-link-rx"></block></block>
  <block id="e4d49e783d07283d117d34b32c4415cd" category="doc">Opzione supplementare NFS Datastore in AWS</block>
  <block id="b2e86378d41d58201dddc613a82c81e2" category="paragraph">Una volta che VMware Cloud è pronto e connesso ad AWS VPC, è necessario implementare Amazon FSX per NetApp ONTAP in un nuovo VPC designato piuttosto che nel VPC predefinito originale connesso o esistente.</block>
  <block id="b96e49fe229de5c473c616c913f822c8" category="inline-link">Configurazione di un gruppo SDDC in VMware Cloud</block>
  <block id="ff5a4226923e95cf43bd31559660d1c8" category="paragraph">Per iniziare, implementa un VPC aggiuntivo nella stessa regione e zona di disponibilità in cui risiede SDDC, quindi implementa Amazon FSX per NetApp ONTAP nel nuovo VPC.<block ref="5be76f2b0a93cb7fee056cbead96da1a" category="inline-link-rx"></block> Console abilita le opzioni di configurazione di rete necessarie per connettersi al nuovo VPC designato in cui verrà implementato FSX per ONTAP.</block>
  <block id="61a4d8e132eda51933073e665a4eac93" category="admonition">Implementare FSX per ONTAP nella stessa area disponibile di VMware Cloud su SDDC AWS.</block>
  <block id="714163a53d8c9c62964e7d6931c1c9ec" category="admonition">Non è possibile implementare FSX per ONTAP nel VPC connesso. È invece necessario implementarlo in un nuovo VPC designato e quindi collegarlo a un VMware Managed Transit Gateway (vTGW) tramite gruppi SDDC.</block>
  <block id="d7641cecb55db2651063f3be07278b31" category="example-title">Fase 1: Creazione di Amazon FSX per ONTAP in un nuovo VPC designato</block>
  <block id="55304a7521acfdd7143fb9cdb66a6344" category="paragraph">Per creare e montare il file system Amazon FSX per NetApp ONTAP, attenersi alla seguente procedura:</block>
  <block id="1a8a81e4c4d14a95fc47e07b614950b5" category="list-text">Aprire la console Amazon FSX all'indirizzo<block ref="3cac88c5e8406527329e138d581346fe" prefix=" " category="inline-code"></block> E scegliere *Crea file system* per avviare la procedura guidata *creazione file system*.</block>
  <block id="ffd72149dd51740fcd4d150cabc5561f" category="list-text">Nella pagina Seleziona tipo di file system, selezionare *Amazon FSX per NetApp ONTAP*, quindi fare clic su *Avanti*. Viene visualizzata la pagina *Create file System* (Crea file system).</block>
  <block id="e71747de43d70e18285f2764e5a036a6" category="paragraph"><block ref="e71747de43d70e18285f2764e5a036a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4817656b0e2a8e3ebdf2bd3377b2456" category="list-text">Per il metodo di creazione, scegliere *Standard Create*.</block>
  <block id="35eb19b4c782b6a9c50e35b42f8c1f8c" category="paragraph"><block ref="35eb19b4c782b6a9c50e35b42f8c1f8c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f47a2dd0d360703b1b45075c63cff1b" category="paragraph"><block ref="5f47a2dd0d360703b1b45075c63cff1b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e0c93d8fb3b7cedc4f8d92d8d692e85" category="admonition">Le dimensioni del datastore variano leggermente da cliente a cliente. Sebbene il numero consigliato di macchine virtuali per datastore NFS sia soggettivo, molti fattori determinano il numero ottimale di macchine virtuali che è possibile posizionare su ciascun datastore. Sebbene la maggior parte degli amministratori consideri solo la capacità, la quantità di i/o simultanei inviata ai VMDK è uno dei fattori più importanti per le performance complessive. Utilizza le statistiche delle performance on-premise per dimensionare di conseguenza i volumi del datastore.</block>
  <block id="11dd82404551d7373785e4fcbc9b1005" category="list-text">Nella sezione *Networking* per Virtual Private Cloud (VPC), scegliere le subnet VPC e preferite appropriate insieme alla tabella di routing. In questo caso, dal menu a discesa viene selezionato Demo- FSxforONTAP-VPC.</block>
  <block id="2f0865bd1a50874390d074524829bfc4" category="admonition">Assicurarsi che si tratti di un nuovo VPC designato e non del VPC collegato.</block>
  <block id="55431364d6f307d0c1adb83c07425d6c" category="admonition">Per impostazione predefinita, FSX per ONTAP utilizza 198.19.0.0/16 come intervallo di indirizzi IP dell'endpoint predefinito per il file system. Assicurarsi che l'intervallo di indirizzi IP degli endpoint non sia in conflitto con il VMC sull'SDDC AWS, le subnet VPC associate e l'infrastruttura on-premise. In caso di dubbi, utilizzare un intervallo non sovrapposto senza conflitti.</block>
  <block id="a9bc1797cfb722fb8dbfec3b16f44cb9" category="paragraph"><block ref="a9bc1797cfb722fb8dbfec3b16f44cb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a560e434862aec182aa626e0de6ca3a" category="list-text">Nella sezione *sicurezza e crittografia* della chiave di crittografia, scegliere la chiave di crittografia AWS Key Management Service (AWS KMS) che protegge i dati del file system inattivi. Per la *Password amministrativa del file system*, immettere una password sicura per l'utente fsxadmin.</block>
  <block id="9626f8b41e6908a3873b72869026a9da" category="paragraph"><block ref="9626f8b41e6908a3873b72869026a9da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75f7834ca5cbd9bf6c7a2b2e5073b427" category="list-text">Nella sezione *Default Storage Virtual Machine Configuration*, specificare il nome della SVM.</block>
  <block id="7c32cf52ace07fb1672e72defde4ac61" category="admonition">A partire da GA, sono supportati quattro datastore NFS.</block>
  <block id="5c732cc058a6b6d4676b55223bf85f5f" category="paragraph"><block ref="5c732cc058a6b6d4676b55223bf85f5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="505582b625e19e5637e0557ad61b581e" category="list-text">Nella sezione *Default Volume Configuration* (Configurazione volume predefinita), specificare il nome e le dimensioni del volume richiesti per l'archivio dati e fare clic su *Next* (Avanti). Si tratta di un volume NFSv3. Per *efficienza dello storage*, scegliere *abilitato* per attivare le funzionalità di efficienza dello storage ONTAP (compressione, deduplica e compattazione). Dopo la creazione, utilizzare la shell per modificare i parametri del volume utilizzando *_volume modify_* come segue:</block>
  <block id="9fdea1f4f5c62c2485312ab231c865ee" category="cell">Garanzia di volume (stile Space Guarantee)</block>
  <block id="bd03fce695997bf49af026bcb349a578" category="cell">None (thin provisioning) - impostazione predefinita</block>
  <block id="9399f3b9e96901f84ac3bd68deec8850" category="cell">fractional_reserve (riserva frazionale)</block>
  <block id="6b3edd41659df403c04fb39ee40b0b0a" category="cell">0% - impostazione predefinita</block>
  <block id="dfa2ec9e60d8028b01d021f862fb77da" category="cell">snap_reserve (spazio-snapshot-percentuale)</block>
  <block id="80c2511d74ccaf27c63f1b6c3aafb2dc" category="cell">Dimensionamento automatico (modalità dimensionamento automatico)</block>
  <block id="535a7e7f6a8dd82fa6603e44982e0525" category="cell">Enabled (attivato): Impostazione predefinita</block>
  <block id="5987147997d274c5292cab0b0006bef1" category="cell">Policy di tiering dei volumi</block>
  <block id="df370ff95c6787552e774c17a2878b11" category="cell">Snapshot Only (solo snapshot): Impostazione predefinita</block>
  <block id="f072855ce664b2c9dd19371c8f451e72" category="paragraph">Utilizzare il seguente comando SSH per creare e modificare i volumi:</block>
  <block id="82bf57f964fd07a578454495c4ae3a34" category="paragraph">*Comando per creare un nuovo volume datastore dalla shell:*</block>
  <block id="3fe80d288dea7b9265abdfe33f302a9a" category="paragraph">*Nota:* i volumi creati tramite shell richiederanno alcuni minuti per essere visualizzati nella console AWS.</block>
  <block id="34b5a79399461f15942cc2bbb68ddb58" category="paragraph">*Comando per modificare i parametri del volume non impostati per impostazione predefinita:*</block>
  <block id="7c031a8d1af863155f52c6a16c34e0c1" category="paragraph"><block ref="7c031a8d1af863155f52c6a16c34e0c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3216fa1649258260fcc7fb0c291ff2fb" category="paragraph"><block ref="3216fa1649258260fcc7fb0c291ff2fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f2384de60fd85d0b57b92b82a7b1835" category="admonition">Durante lo scenario di migrazione iniziale, il criterio di snapshot predefinito può causare problemi di capacità del datastore piena. Per superarla, modificare la policy di Snapshot in base alle esigenze.</block>
  <block id="b2d2529841aebb478d3748c5528b4696" category="list-text">Esaminare la configurazione del file system mostrata nella pagina *Create file System*.</block>
  <block id="a7f848b3fa508f3850a768505d8de438" category="list-text">Fare clic su *Create file System* (Crea file system).</block>
  <block id="8c63e014bdbc571ce93e6b93d628d4e2" category="paragraph"><block ref="8c63e014bdbc571ce93e6b93d628d4e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef936ea5a977520b22368e3dbad83818" category="paragraph"><block ref="ef936ea5a977520b22368e3dbad83818" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a19c957e90534613b36e90008ac1736c" category="admonition">Ripetere i passaggi precedenti per creare più macchine virtuali o file system storage e volumi datastore in base ai requisiti di capacità e performance.</block>
  <block id="f36688b56a320d6a48574b6092329e26" category="paragraph">Per ulteriori informazioni sulle prestazioni di Amazon FSX per ONTAP, consulta<block ref="45a884cbefaf34ae6fd7defa1c6be8c3" category="inline-link-rx"></block>.</block>
  <block id="6d3e0252631c98651b062c2fc85ad936" category="example-title">Fase 2: Creazione del gruppo SDDC</block>
  <block id="82fd9df68bd32ff1e24a66dc98b1e237" category="paragraph">Una volta creati i file system e le SVM, utilizzare VMware Console per creare un gruppo SDDC e configurare VMware Transit Connect. A tale scopo, completare i seguenti passaggi e ricordare che è necessario spostarsi tra VMware Cloud Console e AWS Console.</block>
  <block id="cfdf8bfdb817c09bbd04bc1f8aec640d" category="list-text">Accedere alla console VMC all'indirizzo<block ref="80524a1862c565bfe10233035e45c5b3" prefix=" " category="inline-code"></block>.</block>
  <block id="7959effd33c50a6257362d30f57326de" category="list-text">Nella pagina *inventario*, fare clic su *gruppi SDDC*.</block>
  <block id="b8f684e055bd625606633c09969e9540" category="list-text">Nella scheda *gruppi SDDC*, fare clic su *AZIONI* e selezionare *Crea gruppo SDDC*. Per scopi dimostrativi, viene chiamato il gruppo SDDC<block ref="a34cf36b08316aadda6e1c15679a89f8" prefix=" " category="inline-code"></block>.</block>
  <block id="ab3ee4623c465cb9edfbfeccc6ca86ba" category="list-text">Nella griglia Membership (appartenenza), selezionare gli SDDC da includere come membri del gruppo.</block>
  <block id="7e52f6f87b99cfdf5ba2a85e9fe2e795" category="paragraph"><block ref="7e52f6f87b99cfdf5ba2a85e9fe2e795" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef4fa61cc3be19123a586bd1f8e29e6e" category="list-text">Verificare che l'opzione "la configurazione di VMware Transit Connect per il proprio gruppo comporta costi per allegato e trasferimento dati" sia selezionata, quindi selezionare *Crea gruppo*. Il completamento del processo può richiedere alcuni minuti.</block>
  <block id="a3f9cb9f805a5c5abc39008c09a7f2b1" category="paragraph"><block ref="a3f9cb9f805a5c5abc39008c09a7f2b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b17d6992e86eba9b41dc8a123e6e8fb" category="example-title">Fase 3: Configurare VMware Transit CONNECT</block>
  <block id="dde50926302f7ec2015681d9c6a96817" category="inline-link">Istruzioni per il collegamento di un VPC esterno al gruppo</block>
  <block id="8ebb2eb5630a76b1fe25c564158f80f6" category="list-text">Collegare il VPC designato appena creato al gruppo SDDC. Selezionare la scheda *External VPC* (VPC esterno) e seguire le istruzioni<block ref="b29559f9008e4efd51a29ebaa2e02912" category="inline-link-rx"></block>. Il completamento di questo processo può richiedere 10-15 minuti.</block>
  <block id="ac3defa2f0f4566a77fa8a1608c03c29" category="paragraph"><block ref="ac3defa2f0f4566a77fa8a1608c03c29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="633bd88abb0a911cad29e551387946b8" category="list-text">Fare clic su *Aggiungi account*.</block>
  <block id="cec0191b59ccf1e88591a2c33ced8c4b" category="list-text">Fornire l'account AWS utilizzato per il provisioning del file system FSX per ONTAP.</block>
  <block id="7dee7e783d13b6d5d415926ce0bfc306" category="list-text">Fare clic su *Aggiungi*.</block>
  <block id="6a61e881b78352ae03c966d62ea1556d" category="list-text">Nella console AWS, accedere allo stesso account AWS e accedere alla pagina del servizio *Resource Access Manager*. È disponibile un pulsante per accettare la condivisione delle risorse.</block>
  <block id="8fd6a12de6d9f24e91a89e003fe58ccd" category="paragraph"><block ref="8fd6a12de6d9f24e91a89e003fe58ccd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b5910ab3c7395246baf35589ead376f" category="admonition">Come parte del processo VPC esterno, tramite la console AWS viene richiesto di accedere a una nuova risorsa condivisa tramite Resource Access Manager. La risorsa condivisa è l'AWS Transit Gateway gestito da VMware Transit Connect.</block>
  <block id="48fb6ee0dcc903c5fcfb9d1b15f2e3ad" category="list-text">Fare clic su *Accetta condivisione risorse*.</block>
  <block id="333af8dd6d2cdd37922abf85ebd7179a" category="paragraph"><block ref="333af8dd6d2cdd37922abf85ebd7179a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e8fd48c7d02ab11c26a3e1882fd465a" category="list-text">Nella console VMC, ora si vede che il VPC esterno si trova in uno stato associato. Questa operazione può richiedere alcuni minuti.</block>
  <block id="49ba8c3245c3d07a0ed6167e466b43e1" category="example-title">Fase 4: Creazione dell'allegato del gateway di transito</block>
  <block id="9db03aae4c3c9b489ffa8fc51242bb7e" category="list-text">Nella console AWS, accedere alla pagina del servizio VPC e accedere al VPC utilizzato per il provisioning del file system FSX. In questo punto, è possibile creare un allegato del gateway di transito facendo clic su *Transit Gateway Attachment* (collegamento gateway di transito) nel riquadro di navigazione a destra.</block>
  <block id="6d37c5b21f24bcca6d12fc5042185d45" category="list-text">Nella sezione *allegato VPC*, assicurarsi che sia selezionata l'opzione supporto DNS e selezionare il VPC in cui è stato implementato FSX per ONTAP.</block>
  <block id="1dcf4f0eabbad36654447dfb34f237b4" category="paragraph"><block ref="1dcf4f0eabbad36654447dfb34f237b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc8975fcad9c69f295fb15e5a13f2e40" category="list-text">Fare clic su *Create* *Transit gateway Attachment*.</block>
  <block id="89483e202d4e3f304f821390c4a7a7cc" category="paragraph"><block ref="89483e202d4e3f304f821390c4a7a7cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2e46cdc573277625faad22330cf154f" category="list-text">Tornare alla console di VMware Cloud e tornare alla scheda Gruppo SDDC &gt; VPC esterno. Selezionare l'ID account AWS utilizzato per FSX, fare clic sul VPC e fare clic su *Accept* (Accetta).</block>
  <block id="36fdbe9831a4d114b9917bcd89fac4c2" category="paragraph"><block ref="36fdbe9831a4d114b9917bcd89fac4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3d94f2f6e446adaf149684973d365ee" category="paragraph"><block ref="c3d94f2f6e446adaf149684973d365ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a81e35637833161072f4311f3cb32ac5" category="admonition">La visualizzazione di questa opzione potrebbe richiedere alcuni minuti.</block>
  <block id="08783cc975c3897f2fbd3671f2f82620" category="list-text">Quindi, nella scheda *External VPC* della colonna *routes*, fare clic sull'opzione *Add routes* (Aggiungi percorsi) e aggiungere i percorsi richiesti:</block>
  <block id="028ce3dd99b949a311e20d5403f17103" category="list-text">Un percorso per l'intervallo IP mobile per Amazon FSX per gli IP mobili NetApp ONTAP.</block>
  <block id="efffbab523616433e2c1ea67cbcaab53" category="list-text">Un percorso per lo spazio di indirizzi VPC esterno appena creato.</block>
  <block id="40fd62af6ee711539f271fc7513146a5" category="paragraph"><block ref="40fd62af6ee711539f271fc7513146a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e007562e54d1b070168e2b77a1766fdc" category="paragraph"><block ref="e007562e54d1b070168e2b77a1766fdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="937e96f27b1c5759ad7123b60f3775db" category="example-title">Fase 5: Configurare il routing (AWS VPC e SDDC) e i gruppi di sicurezza</block>
  <block id="b484a2377e56c4c768b99fa1ba1b950a" category="list-text">Nella console AWS, creare il percorso di ritorno a SDDC individuando il VPC nella pagina di servizio VPC e selezionare la tabella di percorso *main* per il VPC.</block>
  <block id="a563a48fad77850ec5058bda722b322a" category="list-text">Individuare la tabella dei percorsi nel pannello inferiore e fare clic su *Edit routes* (Modifica percorsi).</block>
  <block id="85f3b67e1c98b7869b12f779e5f02b51" category="paragraph"><block ref="85f3b67e1c98b7869b12f779e5f02b51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb26d090b870823ae62ed28050e3aa89" category="list-text">Nel pannello *Edit routes* (Modifica percorsi), fare clic su *Add route* (Aggiungi percorso) e immettere il CIDR per l'infrastruttura SDDC selezionando *Transit Gateway* (Gateway di transito) e l'ID TGW associato. Fare clic su *Save Changes* (Salva modifiche).</block>
  <block id="99388849296a3bbf649a9a953c7ce7d5" category="paragraph"><block ref="99388849296a3bbf649a9a953c7ce7d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5659fbd7d9a7a1963d1f57717f874bcb" category="list-text">Il passo successivo consiste nel verificare che il gruppo di sicurezza nel VPC associato sia aggiornato con le regole in entrata corrette per il CIDR del gruppo SDDC.</block>
  <block id="358c085fce4b273ef954f6147feeb2c8" category="list-text">Aggiornare la regola inbound con il blocco CIDR dell'infrastruttura SDDC.</block>
  <block id="74b3770eecc791f1748634fe7f30e559" category="paragraph"><block ref="74b3770eecc791f1748634fe7f30e559" category="inline-image-macro-rx" type="image"></block></block>
  <block id="268ce11e03f9defefab0c436b3818aab" category="admonition">Verificare che la tabella di routing VPC (dove risiede FSX per ONTAP) sia aggiornata per evitare problemi di connettività.</block>
  <block id="a3debdddc4080cea8851b37aee79d278" category="admonition">Aggiornare il gruppo di protezione per accettare il traffico NFS.</block>
  <block id="381318b231b70d3c81a3bb05e8912be3" category="paragraph">Questa è la fase finale della preparazione della connettività all'SDDC appropriato. Con il file system configurato, i percorsi aggiunti e i gruppi di sicurezza aggiornati, è il momento di montare gli archivi dati.</block>
  <block id="492fa7be92a68b15ae3479a6542a7774" category="example-title">Fase 6: Collegare il volume NFS come datastore al cluster SDDC</block>
  <block id="e91ba866f25c52426b4d551f9fa981ef" category="paragraph">Dopo aver eseguito il provisioning del file system e aver attivato la connettività, accedere a VMware Cloud Console per montare il datastore NFS.</block>
  <block id="3c4c5dd0c54ac8e289c4fb955dfe019e" category="list-text">Nella console VMC, aprire la scheda *Storage* del controller SDDC.</block>
  <block id="b953143972b1f780c4334b7673a4c696" category="paragraph"><block ref="b953143972b1f780c4334b7673a4c696" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b525bd0f1409ea87d946684edb92331" category="list-text">Fare clic su *ATTACH DATASTORE* e inserire i valori richiesti.</block>
  <block id="ad7075e284143c915d4b8c07e499daa4" category="admonition">L'indirizzo del server NFS è l'indirizzo IP NFS che si trova in FSX &gt; scheda Storage virtual machine &gt; Endpoints all'interno della console AWS.</block>
  <block id="98c1a8bf80cc3d0fcacfd52aeb1ac321" category="paragraph"><block ref="98c1a8bf80cc3d0fcacfd52aeb1ac321" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d13c0b52cc34c4f5571b5ea17a13e01" category="list-text">Fare clic su *ATTACH DATASTORE* per collegare il datastore al cluster.</block>
  <block id="3d8b70e4499f2e2dd0c18b8b7f29eff9" category="paragraph"><block ref="3d8b70e4499f2e2dd0c18b8b7f29eff9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea3387672e6f02f40253d603226e4fd8" category="list-text">Validare il datastore NFS accedendo a vCenter come mostrato di seguito:</block>
  <block id="30880d4531deb5f77cf22e65ed7f3bc8" category="paragraph"><block ref="30880d4531deb5f77cf22e65ed7f3bc8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ae295ef15cb155f8a1af7d255e34298d" category="doc">Opzioni di storage NetApp Guest Connected per AWS</block>
  <block id="f52c436d16c8976963f940ce7dfbd3b0" category="paragraph">AWS supporta lo storage NetApp connesso agli ospiti con il servizio FSX nativo (FSX ONTAP) o con Cloud Volumes ONTAP (CVO).</block>
  <block id="480bc55cb0b0c11472f598d17424afa2" category="section-title">ONTAP FSX</block>
  <block id="6df37dbe4c736ce113cfd677b79431d8" category="paragraph">Amazon FSX per NetApp ONTAP è un servizio completamente gestito che offre un file storage altamente affidabile, scalabile, dalle performance elevate e ricco di funzionalità, basato sul popolare file system ONTAP di NetApp. FSX per ONTAP combina le funzionalità, le performance, le funzionalità e le operazioni API dei file system NetApp con l'agilità, la scalabilità e la semplicità di un servizio AWS completamente gestito.</block>
  <block id="f1afd8f76dc3ed417abd5daffa1d5a5f" category="paragraph">FSX per ONTAP offre uno storage di file condiviso ricco di funzionalità, rapido e flessibile, ampiamente accessibile dalle istanze di calcolo Linux, Windows e macOS eseguite in AWS o on-premise. FSX per ONTAP offre storage a stato solido (SSD) dalle performance elevate con latenze sotto al millisecondo. Con FSX per ONTAP, puoi ottenere livelli di performance SSD per il tuo carico di lavoro pagando allo stesso tempo lo storage SSD per una piccola frazione dei tuoi dati.</block>
  <block id="dd29cd696f931f8230a783a5d65ab8c4" category="paragraph">La gestione dei dati con FSX per ONTAP è più semplice perché puoi creare snapshot, clonare e replicare i file con un semplice clic. Inoltre, FSX per ONTAP esegue automaticamente il Tier dei dati per uno storage elastico e a basso costo, riducendo la necessità di eseguire il provisioning o la gestione della capacità.</block>
  <block id="697c147172074c2927997e2d7c472fc0" category="paragraph">FSX per ONTAP offre inoltre storage altamente disponibile e durevole con backup completamente gestiti e supporto per il disaster recovery multiregione. Per semplificare la protezione e la protezione dei dati, FSX per ONTAP supporta le applicazioni antivirus e di sicurezza dei dati più diffuse.</block>
  <block id="6e3fe132749fe21d23cf75f00317a6fe" category="example-title">Configurare Amazon FSX per NetApp ONTAP con VMware Cloud su AWS</block>
  <block id="5f19d821dc2e2e3a8e9418909df59733" category="paragraph">Le condivisioni e le LUN dei file ONTAP di Amazon FSX per NetApp possono essere montate da macchine virtuali create nell'ambiente SDDC di VMware presso AWS. I volumi possono anche essere montati sul client Linux e mappati sul client Windows utilizzando il protocollo NFS o SMB, mentre I LUN possono essere utilizzati sui client Linux o Windows come dispositivi a blocchi se montati su iSCSI. Amazon FSX per il file system NetApp ONTAP può essere configurato rapidamente con i seguenti passaggi.</block>
  <block id="190b27040d3191ccf35bdb35221f0682" category="admonition">Amazon FSX per NetApp ONTAP e VMware Cloud su AWS devono trovarsi nella stessa zona di disponibilità per ottenere performance migliori ed evitare i costi di trasferimento dei dati tra le zone di disponibilità.</block>
  <block id="f8caa19e45e4a42ea7bc10cad5d49ae8" category="example-title">Creare e montare Amazon FSX per ONTAP Volumes</block>
  <block id="e765d7d83fde51af5391c87cc45dccf2" category="paragraph">Per creare e montare il file system Amazon FSX per NetApp ONTAP, attenersi alla seguente procedura:</block>
  <block id="43935f267f64b4ca1a3f1803272df64b" category="inline-link-macro">Console Amazon FSX</block>
  <block id="4d33567207f0232b86c9bec4b4f38d45" category="list-text">Aprire <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block> E scegliere Create file system (Crea file system) per avviare la creazione guidata del file system.</block>
  <block id="df08dda7dc18ddb7de0e9ad5001a9f04" category="list-text">Nella pagina Seleziona tipo di file system, scegliere Amazon FSX per NetApp ONTAP, quindi Avanti. Viene visualizzata la pagina Create file System (Crea file system).</block>
  <block id="c40ea60211b89b2179fe7a947527ff66" category="paragraph"><block ref="c40ea60211b89b2179fe7a947527ff66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f29804f0e866cb47ba2fa233a71a54fd" category="list-text">Nella sezione rete, per Virtual Private Cloud (VPC), scegliere le subnet VPC e preferite appropriate insieme alla tabella di routing. In questo caso, vmcfsx2.vpc viene selezionato dal menu a discesa.</block>
  <block id="628892e49fa967795d4d8d3269c5bb31" category="paragraph"><block ref="628892e49fa967795d4d8d3269c5bb31" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf9c04e1d81f05e344db236ac47ea588" category="list-text">Per il metodo di creazione, scegliere Standard Create (Crea standard). È anche possibile scegliere creazione rapida, ma questo documento utilizza l'opzione di creazione standard.</block>
  <block id="e3c13c0fe612a941f86617c0ad730fca" category="paragraph"><block ref="e3c13c0fe612a941f86617c0ad730fca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e47c53bc440aebf2328e497b46953118" category="paragraph"><block ref="e47c53bc440aebf2328e497b46953118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed02b1594feb57e5c5c1ca0678086dd" category="list-text">Nella sezione Security &amp; Encryption (sicurezza e crittografia), per la chiave di crittografia, scegliere la chiave di crittografia AWS Key Management Service (AWS KMS) che protegge i dati del file system inattivi. Per la password amministrativa del file system, immettere una password sicura per l'utente fsxadmin.</block>
  <block id="450514d9ec3a47df8e580605e80579b7" category="paragraph"><block ref="450514d9ec3a47df8e580605e80579b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b969656105cc9174e398fa5754382d5b" category="list-text">Nella macchina virtuale e specificare la password da utilizzare con vsadmin per l'amministrazione di ONTAP utilizzando API REST o CLI. Se non viene specificata alcuna password, è possibile utilizzare un utente fsxadmin per amministrare la SVM. Nella sezione Active Directory, assicurarsi di aggiungere Active Directory a SVM per il provisioning delle condivisioni SMB. Nella sezione Default Storage Virtual Machine Configuration (Configurazione macchina virtuale dello storage predefinita), specificare un nome per lo storage in questa convalida. Il provisioning delle condivisioni SMB viene eseguito utilizzando un dominio Active Directory autogestato.</block>
  <block id="0b0a8d3b6da586b1c3d7ace81f086743" category="paragraph"><block ref="0b0a8d3b6da586b1c3d7ace81f086743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89a8b582feabb26f60740f7b0a57aaef" category="list-text">Nella sezione Default Volume Configuration (Configurazione volume predefinita), specificare il nome e le dimensioni del volume. Si tratta di un volume NFS. Per l'efficienza dello storage, scegliere Enabled (attivato) per attivare le funzioni di efficienza dello storage ONTAP (compressione, deduplica e compattazione) o Disabled (Disattivato) per disattivarle.</block>
  <block id="2cfdc5814e94a8d05a802a6b639158b7" category="paragraph"><block ref="2cfdc5814e94a8d05a802a6b639158b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59ed30f46b9afae4f90b77ac3ed74f8e" category="list-text">Esaminare la configurazione del file system mostrata nella pagina Create file System (Crea file system).</block>
  <block id="08ef5aaea85c8112d5d0e368443ee4fe" category="list-text">Fare clic su Crea file system.</block>
  <block id="d385818e8551a5f93e9591daf3cf7c22" category="paragraph"><block ref="aae4a315cf943820b378b71447a7994a" category="inline-image-macro-rx" type="image"></block>
<block ref="e34db9249abae41534adba1bed16b8d1" category="inline-image-macro-rx" type="image"></block>
<block ref="f1c6728d54b85d98dd49bf5dc91e4f97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f5cc47067a5c4b536ab91f1a843de82" category="inline-link-macro">Introduzione a Amazon FSX per NetApp ONTAP</block>
  <block id="e37ec80b6a23f377fd957d8c83c7a7b5" category="paragraph">Per ulteriori informazioni, vedere <block ref="01eec31289b39ab7b89a00515912c371" category="inline-link-macro-rx"></block>.</block>
  <block id="af62c8c40f4b51eaee5cfbcfdb7bffaa" category="paragraph">Dopo aver creato il file system come sopra, creare il volume con le dimensioni e il protocollo richiesti.</block>
  <block id="5eb9e90ab2c5435bcefd918c8c8a7304" category="list-text">Aprire <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block>.</block>
  <block id="4cdc643691b84580850903954cdca1d1" category="list-text">Nel riquadro di spostamento di sinistra, scegliere file system, quindi scegliere il file system ONTAP per cui si desidera creare un volume.</block>
  <block id="05c0eed2abbd9c20871b6af0eb7b1e38" category="list-text">Selezionare la scheda Volumes (volumi).</block>
  <block id="511e546bcb3da3ea3db700200e857ebf" category="list-text">Selezionare la scheda Create Volume (Crea volume).</block>
  <block id="328a4173ff8b40f0204a78c6a579b01e" category="list-text">Viene visualizzata la finestra di dialogo Create Volume (Crea volume).</block>
  <block id="b1734fefd5bf5fc9e481a277d683ca10" category="paragraph">A scopo dimostrativo, in questa sezione viene creato un volume NFS che può essere facilmente montato sulle macchine virtuali in esecuzione sul cloud VMware su AWS. nfsdemovol01 viene creato come illustrato di seguito:</block>
  <block id="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="paragraph"><block ref="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72e172d843c1baf9acb881337f0bb2cc" category="example-title">Montare il volume FSX ONTAP sul client Linux</block>
  <block id="682dccf32ec3d6c1e1ca2548a43c4245" category="paragraph">Per montare il volume FSX ONTAP creato nel passaggio precedente. Dalle macchine virtuali Linux all'interno di VMC su AWS SDDC, completare i seguenti passaggi:</block>
  <block id="e059ff9407d5207f003eae103b4c7a3a" category="list-text">Connettersi all'istanza Linux designata.</block>
  <block id="a8dc83c93fa2350d1419b44103864f2c" category="list-text">Aprire un terminale sull'istanza utilizzando Secure Shell (SSH) e accedere con le credenziali appropriate.</block>
  <block id="454d9d1fe6ad680e393543d5e7b11669" category="list-text">Creare una directory per il punto di montaggio del volume con il seguente comando:</block>
  <block id="9e770ba792bd4db694940294a77cccee" category="list-text">Montare il volume NFS Amazon FSX per NetApp ONTAP nella directory creata nel passaggio precedente.</block>
  <block id="6631f82f4a955cf7fe5644adadf79e47" category="paragraph"><block ref="6631f82f4a955cf7fe5644adadf79e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2774f9046ee4873805e1f044fa12fe85" category="list-text">Una volta eseguito, eseguire il comando df per convalidare il mount.</block>
  <block id="d06051412d6da4495ca1a69429ea4fdf" category="paragraph"><block ref="d06051412d6da4495ca1a69429ea4fdf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0927b028b8b35cb7421cd2d29ebac0ab" category="example-title">Collegare i volumi FSX ONTAP ai client Microsoft Windows</block>
  <block id="49a305dd021166bf8a508fb51b3fce24" category="paragraph">Per gestire e mappare le condivisioni di file su un file system Amazon FSX, è necessario utilizzare la GUI delle cartelle condivise.</block>
  <block id="0f51d6ad9d95d24bf6d5b0e18d947382" category="list-text">Aprire il menu Start ed eseguire fsmgmt.msc utilizzando Esegui come amministratore. In questo modo si apre la GUI delle cartelle condivise.</block>
  <block id="0186f9c0fa21b0c8ab82fadf036afe8f" category="list-text">Fare clic su azione &gt; tutte le attività e scegliere Connetti a un altro computer.</block>
  <block id="f5cf362d19da392bad46d1cb4bbea453" category="list-text">Per un altro computer, immettere il nome DNS della macchina virtuale di storage (SVM). Ad esempio, in questo esempio viene utilizzato FSXSMBTESTING01.FSXTESTING.LOCAL.</block>
  <block id="882da317003fa80717e3939e41c5aa32" category="admonition">TP individuare il nome DNS della SVM sulla console Amazon FSX, scegliere Storage Virtual Machines, SVM, quindi scorrere verso il basso fino agli endpoint per trovare il nome DNS SMB. Fare clic su OK. Il file system Amazon FSX viene visualizzato nell'elenco delle cartelle condivise.</block>
  <block id="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="paragraph"><block ref="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd517d0d40877562e2dae460910a5260" category="list-text">Nello strumento cartelle condivise, scegliere condivisioni nel riquadro sinistro per visualizzare le condivisioni attive per il file system Amazon FSX.</block>
  <block id="e4fb530e581118e4aa66166f33242547" category="paragraph"><block ref="e4fb530e581118e4aa66166f33242547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b994a2e22edf9cb0de792e6a494da514" category="list-text">A questo punto, scegliere una nuova condivisione e completare la procedura guidata Crea una cartella condivisa.</block>
  <block id="9630a309cdca9ed17b688fe15c03a200" category="paragraph"><block ref="f821d910b54d4df166bfb6c9a0fbeac1" category="inline-image-macro-rx" type="image"></block>
<block ref="1456921fb33e6c835f2ea077607c478a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed3796b20dc1d1a4f1756d0cb0f45489" category="inline-link-macro">Creazione di condivisioni SMB</block>
  <block id="dc77f3b6074a456c2be3f16b862db081" category="paragraph">Per ulteriori informazioni sulla creazione e la gestione delle condivisioni SMB su un file system Amazon FSX, consulta <block ref="a85495f11ff3e696252abf798d30d57d" category="inline-link-macro-rx"></block>.</block>
  <block id="470140537c670eb8edb32bf6e8b2bad5" category="list-text">Dopo aver attivato la connettività, è possibile collegare e utilizzare la condivisione SMB per i dati delle applicazioni. A tale scopo, copiare il percorso di condivisione e utilizzare l'opzione Map Network Drive (Mappa unità di rete) per montare il volume sulla macchina virtuale in esecuzione su VMware Cloud su AWS SDDC.</block>
  <block id="0542af5401c04588abf9b665f31829b6" category="paragraph"><block ref="0542af5401c04588abf9b665f31829b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6c5856c2845517bb6408529fb90b57e" category="example-title">Connessione di un LUN FSX per NetApp ONTAP a un host utilizzando iSCSI</block>
  <block id="716fd43b3bc7735b075d056d4ac18dc4" category="paragraph">Il traffico iSCSI per FSX attraversa VMware Transit Connect/AWS Transit Gateway attraverso i percorsi forniti nella sezione precedente. Per configurare un LUN in Amazon FSX per NetApp ONTAP, seguire la documentazione disponibile <block ref="70da71f7286decf7407c5db884b5344a" category="inline-link-macro-rx"></block>.</block>
  <block id="32139f76f200f13f9078d49f80c95815" category="paragraph">Sui client Linux, assicurarsi che il daemon iSCSI sia in esecuzione. Una volta eseguito il provisioning dei LUN, consultare le istruzioni dettagliate sulla configurazione iSCSI con Ubuntu (come esempio) <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>.</block>
  <block id="102b54837bec429c2bc9f3f9fee8a857" category="paragraph">In questo documento, viene illustrata la connessione del LUN iSCSI a un host Windows:</block>
  <block id="29980d065df6792c6cf2015646e8744d" category="example-title">Provisioning di un LUN in FSX per NetApp ONTAP:</block>
  <block id="6da38655de350d44c878e17adb0fd12c" category="list-text">Accedere alla CLI di NetApp ONTAP utilizzando la porta di gestione di FSX per il file system ONTAP.</block>
  <block id="6f8dec9d607d68b3712504d90548dc7f" category="list-text">Creare le LUN con le dimensioni richieste, come indicato dall'output di dimensionamento.</block>
  <block id="c31d63ac510efc7c433e07d70ef0a11a" category="paragraph">In questo esempio, è stato creato un LUN di dimensioni 5g (5368709120).</block>
  <block id="e3de6fee1eaf0d0777dc125d42255a4b" category="list-text">Creare gli igroups necessari per controllare quali host hanno accesso a LUN specifiche.</block>
  <block id="8c92602adf53776d90c46162f150dd3c" category="paragraph">Sono state visualizzate due voci.</block>
  <block id="e71def0bc16c2989d418764ced77c368" category="list-text">Associare i LUN a igroups utilizzando il seguente comando:</block>
  <block id="fd29357379ec9a1916e7512ba9cba2d5" category="list-text">Connettere il LUN appena fornito a una macchina virtuale Windows:</block>
  <block id="15bea41b01d7287439a04eb0c57a5ef5" category="paragraph">Per collegare il nuovo LUN a un host Windows che risiede sul cloud VMware su AWS SDDC, attenersi alla seguente procedura:</block>
  <block id="eabaddae6242a6352bd11a6bdf29b55a" category="list-text">RDP sulla macchina virtuale Windows ospitata su VMware Cloud su AWS SDDC.</block>
  <block id="debd85c1c5da22a2c5e207ae0ad4b91a" category="list-text">Accedere a Server Manager &gt; Dashboard &gt; Tools &gt; iSCSI Initiator per aprire la finestra di dialogo iSCSI Initiator Properties (Proprietà iSCSI Initiator).</block>
  <block id="beacd9a0aebca77f6cc20d5cab0fb37c" category="list-text">Dalla scheda Discovery (rilevamento), fare clic su Discover Portal (Scopri portale) o Add Portal (Aggiungi portale), quindi inserire l'indirizzo IP della porta di destinazione iSCSI.</block>
  <block id="213e827694caf7236290f845284dcc05" category="list-text">Dalla scheda Target, selezionare la destinazione rilevata, quindi fare clic su Log on (Accedi) o Connect (Connetti).</block>
  <block id="43237019bec64292757878b08a9d1a63" category="list-text">Selezionare attiva multipath, quindi selezionare "Ripristina automaticamente la connessione all'avvio del computer" o "Aggiungi questa connessione all'elenco delle destinazioni preferite". Fare clic su Avanzate.</block>
  <block id="ed010f49a5a1ad0895131daffcd73a3c" category="admonition">L'host Windows deve disporre di una connessione iSCSI a ciascun nodo del cluster. Il DSM nativo seleziona i percorsi migliori da utilizzare.</block>
  <block id="6aa775ce454f9bfcd13c7e20b90531e7" category="paragraph"><block ref="6aa775ce454f9bfcd13c7e20b90531e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dc2a4ed37392086accdd3db98b75509" category="paragraph">I LUN sulla macchina virtuale di storage (SVM) vengono visualizzati come dischi sull'host Windows. I nuovi dischi aggiunti non vengono rilevati automaticamente dall'host. Attivare una nuova scansione manuale per rilevare i dischi completando la seguente procedura:</block>
  <block id="d16c566049378cf49448803dfc6ab25d" category="list-text">Aprire l'utility Gestione computer di Windows: Start &gt; Strumenti di amministrazione &gt; Gestione computer.</block>
  <block id="b1babb2780a260f54d7e9f21602773df" category="list-text">Espandere il nodo Storage nella struttura di navigazione.</block>
  <block id="678149d88ae91abbb05c5df448a4e8af" category="list-text">Fare clic su Gestione disco.</block>
  <block id="35e2e6c4175353900be410088efcc1b9" category="list-text">Fare clic su Action (azione) &gt; Rescan Disks (Nuova scansione</block>
  <block id="3ba2e4c8502f30b8e6d44fc88ebe784a" category="paragraph"><block ref="3ba2e4c8502f30b8e6d44fc88ebe784a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="405bdc4379d9776fbda741356a79c543" category="paragraph">Quando l'host Windows accede per la prima volta a un nuovo LUN, non dispone di partizione o file system. Inizializzare il LUN e, facoltativamente, formattare il LUN con un file system attenendosi alla seguente procedura:</block>
  <block id="8db13bd6122ee1a2b04931073cb808d7" category="list-text">Avviare Gestione disco di Windows.</block>
  <block id="18e601e3f0e159e918f7adb9fd89fb99" category="list-text">Fare clic con il pulsante destro del mouse sul LUN, quindi selezionare il tipo di disco o partizione richiesto.</block>
  <block id="605158a22ab35f7223fe6f37b0f761b7" category="list-text">Seguire le istruzioni della procedura guidata. In questo esempio, viene montato il disco F:.</block>
  <block id="848c01bbaad78639e22ba05626884091" category="paragraph"><block ref="848c01bbaad78639e22ba05626884091" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7afda8c8e445dfa1015ae8245fa8026e" category="section-title">Cloud Volumes ONTAP (CVO)</block>
  <block id="8560d03d6d9a5398acd72a06a8fddd12" category="paragraph">Cloud Volumes ONTAP, o CVO, è la soluzione per la gestione dei dati nel cloud leader del settore basata sul software di storage ONTAP, disponibile in modalità nativa su Amazon Web Services (AWS), Microsoft Azure e Google Cloud Platform (GCP).</block>
  <block id="12f2a9cf238d1339eddfc43be9f107e1" category="paragraph">Si tratta di una versione software-defined di ONTAP che utilizza lo storage nativo del cloud, consentendoti di avere lo stesso software di storage nel cloud e on-premise, riducendo la necessità di riorganizzare il tuo staff IT con metodi completamente nuovi per gestire i tuoi dati.</block>
  <block id="62c9becbf4c5643c0df4cbe868b09f0c" category="paragraph">CVO offre ai clienti la possibilità di spostare senza problemi i dati dall'edge al data center, al cloud e viceversa, unendo il tuo cloud ibrido, il tutto gestito con una console di gestione a singolo pannello, NetApp Cloud Manager.</block>
  <block id="aafae379e910c7a153b831ce5122f5e8" category="paragraph">Per progettazione, CVO offre performance estreme e funzionalità avanzate di gestione dei dati per soddisfare anche le applicazioni più esigenti nel cloud</block>
  <block id="4859596b2360db2dac4c6a687efe10d2" category="example-title">Implementare la nuova istanza di Cloud Volumes ONTAP in AWS (eseguire l'operazione autonomamente)</block>
  <block id="ddf355809a57f794eb4f9cff41a1ad86" category="paragraph">Le condivisioni e i LUN Cloud Volumes ONTAP possono essere montati dalle macchine virtuali create nell'ambiente SDDC di VMware Cloud su AWS. I volumi possono essere montati anche su client Windows nativi di AWS VM e I LUN possono essere utilizzati su client Linux o Windows come dispositivi a blocchi quando montati su iSCSI perché Cloud Volumes ONTAP supporta i protocolli iSCSI, SMB e NFS. I volumi Cloud Volumes ONTAP possono essere configurati in pochi semplici passaggi.</block>
  <block id="3b020916a45973167bc70cb4517bd8c8" category="inline-link-macro">Configurazione della replica dei dati tra sistemi</block>
  <block id="091112e3dbffea1fef77b4b6bbcec4d3" category="paragraph">Per replicare i volumi da un ambiente on-premise al cloud per scopi di disaster recovery o migrazione, stabilire la connettività di rete ad AWS, utilizzando una VPN sito-sito o DirectConnect. La replica dei dati da on-premise a Cloud Volumes ONTAP non rientra nell'ambito di questo documento. Per replicare i dati tra sistemi on-premise e Cloud Volumes ONTAP, vedere <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>.</block>
  <block id="9eb931a836eecf8e743b47b449c70bc5" category="inline-link-macro">Cloud Volumes ONTAP Sizer</block>
  <block id="c4fab68ae07564acd6ecd9b911dfff79" category="admonition">Utilizzare <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> Per dimensionare con precisione le istanze di Cloud Volumes ONTAP. Inoltre, è possibile monitorare le performance on-premise da utilizzare come input nel Cloud Volumes ONTAP Sizer.</block>
  <block id="44ca838e7d04a1071dc78602ef005cb3" category="list-text">Accedere a NetApp Cloud Central; viene visualizzata la schermata Fabric View. Individuare la scheda Cloud Volumes ONTAP (Gestione cloud) e selezionare Go to Cloud Manager (Vai a Gestione cloud). Una volta effettuato l'accesso, viene visualizzata la schermata Canvas.</block>
  <block id="6b0e3e8cb8d190a2310f526f49f7908f" category="paragraph"><block ref="6b0e3e8cb8d190a2310f526f49f7908f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="613b8a42b8ee051cdae0288a52604a55" category="list-text">Nella home page di Cloud Manager, fare clic su Add a Working Environment (Aggiungi ambiente di lavoro), quindi selezionare AWS come cloud e il tipo di configurazione del sistema.</block>
  <block id="1ce9ef4a253b6301539d9cab4fca67b6" category="paragraph"><block ref="1ce9ef4a253b6301539d9cab4fca67b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1552a04c8237c4a2d938cca2db53683" category="list-text">Fornire i dettagli dell'ambiente da creare, inclusi il nome dell'ambiente e le credenziali di amministratore. Fare clic su continua.</block>
  <block id="525c0dbff313821edbeaa46a9b5d88dd" category="paragraph"><block ref="525c0dbff313821edbeaa46a9b5d88dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fdbae44a4deac52e923aa6480a3f1f2" category="list-text">Seleziona i servizi aggiuntivi per l'implementazione di Cloud Volumes ONTAP, tra cui Cloud Data Sense, Cloud Backup e Cloud Insights. Fare clic su continua.</block>
  <block id="7191330ca38db1397356e7619c4baf63" category="paragraph"><block ref="7191330ca38db1397356e7619c4baf63" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5908a77615c1d6294f872ff6f0e9ec5c" category="list-text">Nella pagina ha Deployment Models (modelli di implementazione ha), scegliere la configurazione di più zone di disponibilità.</block>
  <block id="e2dff93e99a18f3bbf601965a86556d3" category="paragraph"><block ref="e2dff93e99a18f3bbf601965a86556d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5eee77262911549d8a2fd262ee2a983d" category="list-text">Nella pagina Region &amp; VPC (Regione e VPC), immettere le informazioni di rete, quindi fare clic su Continue (continua).</block>
  <block id="94a6592c275cad51dc739b4ab70338db" category="paragraph"><block ref="94a6592c275cad51dc739b4ab70338db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6f20610782706f69940c617f7154ffe" category="list-text">Nella pagina Connectivity and SSH Authentication (connettività e autenticazione SSH), scegliere i metodi di connessione per la coppia ha e il mediatore.</block>
  <block id="d121b588f00dfd906d6291024c708f8d" category="paragraph"><block ref="d121b588f00dfd906d6291024c708f8d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a012735965bc67df3b6e4c64b7b894f" category="list-text">Specificare gli indirizzi IP mobili, quindi fare clic su Continue (continua).</block>
  <block id="bc0e2f9513cce33557343a1867d4bdfb" category="paragraph"><block ref="bc0e2f9513cce33557343a1867d4bdfb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b2221e159f51173ae2b52e02587cc42" category="list-text">Selezionare le tabelle di routing appropriate per includere i percorsi verso gli indirizzi IP mobili, quindi fare clic su continua.</block>
  <block id="5486a792746fe5fbf546c327f6be2773" category="paragraph"><block ref="5486a792746fe5fbf546c327f6be2773" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e18f42f3f9ea4d4f2e8df33f334d9939" category="list-text">Nella pagina Data Encryption (crittografia dati), scegliere AWS-Managed Encryption (crittografia gestita da AWS).</block>
  <block id="143c5081e907e69e16f1df952eafae3e" category="paragraph"><block ref="143c5081e907e69e16f1df952eafae3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a25e3ac90ce2b5cc921531efdc5963e" category="list-text">Selezionare l'opzione di licenza: Pay-as-you-Go o BYOL per utilizzare una licenza esistente. In questo esempio, viene utilizzata l'opzione Pay-as-You-Go.</block>
  <block id="e3750564d3942e5c1d3cec322e411d5e" category="paragraph"><block ref="e3750564d3942e5c1d3cec322e411d5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df531dd5efab87543ed07d56595eca08" category="list-text">Scegliere tra diversi pacchetti preconfigurati disponibili in base al tipo di carico di lavoro da implementare sulle macchine virtuali in esecuzione sul cloud VMware su AWS SDDC.</block>
  <block id="30e80bd4d8d23ac64059627389a8b348" category="paragraph"><block ref="30e80bd4d8d23ac64059627389a8b348" category="inline-image-macro-rx" type="image"></block></block>
  <block id="623ce055c6e7272198e998744efd8deb" category="list-text">Nella pagina Review &amp; Approve (esamina e approva), rivedere e confermare le selezioni.per creare l'istanza di Cloud Volumes ONTAP, fare clic su Go (Vai).</block>
  <block id="ce4ab7c38fc244e8d1e30dd47a1c578d" category="paragraph"><block ref="ce4ab7c38fc244e8d1e30dd47a1c578d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b8217eede1f57c19d7d36c1501891b" category="list-text">Una volta eseguito il provisioning, Cloud Volumes ONTAP viene elencato negli ambienti di lavoro nella pagina Canvas.</block>
  <block id="bc498db1b5b048e74d02bcfa90076dfe" category="paragraph"><block ref="bc498db1b5b048e74d02bcfa90076dfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="962c53cd54b0b3876e054c2fea4c4ff8" category="example-title">Configurazioni aggiuntive per volumi SMB</block>
  <block id="9af22b589cfa398b9a704f786d96a90d" category="list-text">Una volta pronto l'ambiente di lavoro, assicurarsi che il server CIFS sia configurato con i parametri di configurazione DNS e Active Directory appropriati. Questo passaggio è necessario prima di poter creare il volume SMB.</block>
  <block id="8427c8fe11e3a00ca10a2cf45a96dd90" category="paragraph"><block ref="8427c8fe11e3a00ca10a2cf45a96dd90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31574a22471145d2a1ea069062aa95ec" category="list-text">Selezionare l'istanza CVO per creare il volume e fare clic sull'opzione Create Volume (Crea volume). Scegli le dimensioni appropriate e il cloud manager sceglie l'aggregato contenente o utilizza un meccanismo di allocazione avanzato da collocare su un aggregato specifico. Per questa demo, SMB viene selezionato come protocollo.</block>
  <block id="d657856abbf9bb39436a3f6f849251ea" category="paragraph"><block ref="d657856abbf9bb39436a3f6f849251ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="976543d01a4b5d38482c487005aadc68" category="list-text">Una volta eseguito il provisioning, il volume è disponibile nel riquadro Volumes (volumi). Poiché viene fornita una condivisione CIFS, è necessario concedere agli utenti o ai gruppi l'autorizzazione per i file e le cartelle e verificare che tali utenti possano accedere alla condivisione e creare un file.</block>
  <block id="eac2d4365044c30420d99e4450f5b3da" category="paragraph"><block ref="eac2d4365044c30420d99e4450f5b3da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ea4081e5d5395a0dd61744757f9abb9" category="list-text">Una volta creato il volume, utilizzare il comando mount per connettersi alla condivisione dalla macchina virtuale in esecuzione su VMware Cloud negli host AWS SDDC.</block>
  <block id="7786302dcdbb8e27839c1d68acb8c3ba" category="list-text">Copiare il seguente percorso e utilizzare l'opzione Map Network Drive per montare il volume sulla macchina virtuale in esecuzione su VMware Cloud in AWS SDDC.</block>
  <block id="fff9636198d4c8106d5edeb1a72f789c" category="paragraph"><block ref="97606ae260ebd0d0acdf4aac70a2a0b5" category="inline-image-macro-rx" type="image"></block>
<block ref="b4382417b1dd50929cfd78b7e90bc2aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27c47ada1e7cb796a499ede048474b99" category="example-title">Collegare il LUN a un host</block>
  <block id="70ac69b194f074f8b2ce79ee769a0c96" category="paragraph">Per collegare il LUN Cloud Volumes ONTAP a un host, attenersi alla seguente procedura:</block>
  <block id="4a8c2e183609aa00cfce8401be26e193" category="list-text">Nella pagina Canvas di Cloud Manager, fare doppio clic sull'ambiente di lavoro Cloud Volumes ONTAP per creare e gestire i volumi.</block>
  <block id="298c5ecf2fc7c7ab04d3ff27df17c420" category="list-text">Fare clic su Add Volume (Aggiungi volume) &gt; New Volume (nuovo volume), selezionare iSCSI, quindi fare clic su Create Initiator Group (Crea gruppo di Fare clic su continua.</block>
  <block id="a3f6544e066d08b352bdd873e84efd9f" category="paragraph"><block ref="d08d8d37d464a0090209067a27ccf9bf" category="inline-image-macro-rx" type="image"></block>
<block ref="dd9a8ac9d2dee64126f68f4ab9b10f3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6297ccc26d99397b36875f005bb1b800" category="list-text">Una volta eseguito il provisioning del volume, selezionare il volume, quindi fare clic su Target IQN (IQN di destinazione). Per copiare il nome qualificato iSCSI (IQN), fare clic su Copy (Copia). Impostare una connessione iSCSI dall'host al LUN.</block>
  <block id="c5a9ec38aba893e2a0d701ba2f45a50e" category="paragraph">Per ottenere lo stesso risultato per l'host residente su VMware Cloud su AWS SDDC, attenersi alla seguente procedura:</block>
  <block id="2cbe60394fdca23a31c3a05a49aba035" category="list-text">RDP sulla macchina virtuale ospitata sul cloud VMware su AWS.</block>
  <block id="c4b994ff6c03cf45471392a32ff9809b" category="list-text">Aprire la finestra di dialogo iSCSI Initiator Properties (Proprietà iSCSI Initiator): Server Manager &gt; Dashboard &gt; Tools &gt; iSCSI Initiator.</block>
  <block id="04d63507299c2b866ddad09b32b37fb3" category="list-text">Selezionare Enable multipath (attiva multipath), quindi selezionare Automatically Restore this Connection when the computer starts or Add this Connection to the List of Favorite targets (Ripristina automaticamente questa connessione all'avvio del computer). Fare clic su Avanzate.</block>
  <block id="15c42f0d55e1a75b7606d8cd1d0f0840" category="paragraph">+<block ref="f87da6f2c46cbdbedc31faf67374f8f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11f54f9bd2797dc115ca9e98fb0116d" category="paragraph">I LUN della SVM vengono visualizzati come dischi sull'host Windows. I nuovi dischi aggiunti non vengono rilevati automaticamente dall'host. Attivare una nuova scansione manuale per rilevare i dischi completando la seguente procedura:</block>
  <block id="733dc90ee8ecde5a3fe64fd837d0eec1" category="paragraph"><block ref="733dc90ee8ecde5a3fe64fd837d0eec1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8a056111a10f9e055d309c54e7ca2bb" category="paragraph">Quando l'host Windows accede per la prima volta a un nuovo LUN, non dispone di partizione o file system. Inizializzare il LUN e, facoltativamente, formattare il LUN con un file system completando la seguente procedura:</block>
  <block id="5b173d8aceed1850c1882fee5f7479d4" category="paragraph"><block ref="5b173d8aceed1850c1882fee5f7479d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1085f8441673a34397360c417066d18f" category="paragraph">Sui client Linux, assicurarsi che il daemon iSCSI sia in esecuzione. Dopo aver eseguito il provisioning dei LUN, consultare le istruzioni dettagliate sulla configurazione iSCSI per la distribuzione Linux. Ad esempio, è possibile trovare la configurazione iSCSI di Ubuntu <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>. Per verificare, eseguire lsblk cmd dalla shell.</block>
  <block id="7b88883556cc41d9ed2a47bd0cfe1bb4" category="example-title">Montare il volume NFS Cloud Volumes ONTAP sul client Linux</block>
  <block id="af16b968e0e3b3975cdcefb5cdd9858a" category="paragraph">Per montare il file system Cloud Volumes ONTAP (DIY) dalle macchine virtuali all'interno di VMC su AWS SDDC, attenersi alla seguente procedura:</block>
  <block id="b3bcde31f03d76e154f81e6b5221b007" category="list-text">Aprire un terminale sull'istanza utilizzando la shell sicura (SSH) e accedere con le credenziali appropriate.</block>
  <block id="42d35ecc4606c7783372ab3953fb10d6" category="list-text">Creare una directory per il punto di montaggio del volume con il seguente comando.</block>
  <block id="2b9f5ac2397a7a0e82ca568de7f62512" category="paragraph"><block ref="c1b4b180fa34b46779c12a4e278fa487" category="inline-image-macro-rx" type="image"></block>
<block ref="cf487bf9f5a361811181e443893feb53" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97be15a34c6b82b6177132129dd0b293" category="doc">Disponibilità regionale: Datastore NFS supplementare per VMC</block>
  <block id="46c2094fdbb2fbdc301a330fb7419074" category="paragraph">La disponibilità di datastore NFS supplementari su AWS / VMC è definita da Amazon. Innanzitutto, è necessario determinare se VMC e FSxN sono disponibili in una regione specifica. Quindi, è necessario determinare se il datastore NFS supplementare FSxN è supportato in quella regione.</block>
  <block id="fa3811ba5828de9b5ce35701ec38d154" category="list-text">Verificare la disponibilità di VMC <block ref="bd516ef46cad23535fac2e4d7f54defe" category="inline-link-macro-rx"></block>.</block>
  <block id="0ecaf171a89c41ea509c3f45896220b8" category="list-text">La guida ai prezzi di Amazon offre informazioni su dove è disponibile FSxN (FSX ONTAP). Queste informazioni sono disponibili <block ref="2d4b4b449ef448fbb3000f58e542f4ee" category="inline-link-macro-rx"></block>.</block>
  <block id="c10e413ea65850b7369ee5ae6f60b460" category="list-text">La disponibilità del datastore NFS supplementare FSxN per VMC sarà presto disponibile.</block>
  <block id="a1838a4ac0f386c517d82fae26f2372e" category="paragraph">Mentre le informazioni sono ancora in fase di rilascio, il seguente grafico identifica il supporto corrente per VMC, FSxN e FSxN come datastore NFS supplementare.</block>
  <block id="9ceed07936bb73f756027dc20e7869e5" category="open-title">Americhe</block>
  <block id="a58c228b4723aee54800749a595ee3d1" category="cell">*Regione AWS*</block>
  <block id="0ea8853bd99df0275ce197d81b4acdf3" category="cell">*Disponibilità VMC*</block>
  <block id="da5de74c1914c54c36141e9bbc0bfb2c" category="cell">*Disponibilità FSX ONTAP*</block>
  <block id="db1904255fd919e193388d9dfc4066ae" category="cell">*Disponibilità datastore NFS*</block>
  <block id="34f9a39dcbb737fbdd35cfb9214308b5" category="cell">US East (Virginia del Nord)</block>
  <block id="227b0fc1350a24236051cdda52db89ae" category="cell">USA Est (Ohio)</block>
  <block id="578ab1f7b2f00d70184a6fd055855a32" category="cell">US West (California settentrionale)</block>
  <block id="2826ad747baf050dc2cfb69d5171f78f" category="cell">STATI UNITI occidentali (Oregon)</block>
  <block id="1978cc170637ba3fa169853b7c5b2791" category="cell">GovCloud (ovest degli Stati Uniti)</block>
  <block id="86378e5a26945a10df6434e3cebc709b" category="cell">Canada (centrale)</block>
  <block id="1289483fccf49359b30e09d42f550943" category="cell">Sud America (San Paolo)</block>
  <block id="dbb56fbaa43a12cf5dc69fde5096e785" category="paragraph">Ultimo aggiornamento: 2 giugno 2022.</block>
  <block id="0f1c6d45b761226679e0927cc47d24d3" category="open-title">EMEA</block>
  <block id="8c0594d8d8e156a108f31e22903e4349" category="cell">Europa (Irlanda)</block>
  <block id="05f6cd9d18df6f52665dab10eda2ebe1" category="cell">Europa (Londra)</block>
  <block id="5efd079b952b87c886a8a02de8dd5d83" category="cell">Europa (Francoforte)</block>
  <block id="5be61c2e880e77ca057a65a4ff532d45" category="cell">Europa (Parigi)</block>
  <block id="ecb3d21f3ca319a515169d4aafe9ed99" category="cell">Europa (Milano)</block>
  <block id="529f3fee69162e06098d8924e8084ca6" category="cell">Europa (Stoccolma)</block>
  <block id="2ebc1f6a39f03ec89f2b4bfdaf802f4c" category="open-title">Asia Pacifico</block>
  <block id="4c2aaaa08c4d6f6e7e5af0e5fecf29df" category="cell">Asia Pacifico (Sydney)</block>
  <block id="60b549aa334760e9f2bd47c8296afb7b" category="cell">Asia Pacifico (Tokyo)</block>
  <block id="dfbd3a51c0e9a689817234013c0d51ee" category="cell">Asia Pacifico (Osaka)</block>
  <block id="c8d7db357b2344e3ebeab70a1e63c6c9" category="cell">Asia Pacifico (Singapore)</block>
  <block id="5294ca76dd36c8368fcafd7e951115ef" category="cell">Asia Pacifico (Seul)</block>
  <block id="78c8c0f60d4851b109cbd33284f812ca" category="cell">Asia Pacifico (Mumbai)</block>
  <block id="82f98bf67698e189fc9d846325345bbd" category="cell">Asia Pacifico (Giacarta)</block>
  <block id="1b15cf1d695d130132edd42a701b41a1" category="cell">Asia Pacifico (Hong Kong)</block>
  <block id="4573434025dab87886cfb0b766c70cb1" category="paragraph">Ultimo aggiornamento: 28 settembre 2022.</block>
  <block id="29f8b77f5f7c79b566706e0d55c9de8b" category="doc">Soluzioni NetApp per Amazon VMware Managed Cloud (VMC)</block>
  <block id="4c27cd4763075e77fef142db7e967384" category="paragraph">Scopri di più sulle soluzioni offerte da NetApp ad AWS.</block>
  <block id="d8732ebfbd98db5a8cd9db59aa5b0637" category="paragraph">VMware definisce i carichi di lavoro del cloud in una delle tre categorie seguenti:</block>
  <block id="2cb256015e8585083bd2350f010676fb" category="list-text">Protezione (inclusi disaster recovery e backup/ripristino)</block>
  <block id="2c0a3f21d3cbc96381e4c2fe29329ec1" category="paragraph">Consultare le soluzioni disponibili nelle seguenti sezioni.</block>
  <block id="97740c0c87b83b324e18993ba93f0617" category="open-title">Proteggere</block>
  <block id="5b13229945c45439c072dc9c270e8177" category="inline-link-macro">Disaster Recovery con VMC su AWS (connesso come guest)</block>
  <block id="866b55fdae1463f1934c300853ecefe2" category="list-text"><block ref="866b55fdae1463f1934c300853ecefe2" category="inline-link-macro-rx"></block></block>
  <block id="13549bdeea4691de1cb8770ad340fe98" category="inline-link-macro">Backup Veeam &amp;amp; Ripristino in VMC con FSX per ONTAP</block>
  <block id="c7e33bfa2affc748125a7a3ac5add080" category="list-text"><block ref="a4040abe827501c59f63af5f8c85d98b" category="inline-link-macro-rx"></block></block>
  <block id="d923ff878d26dac68fc7ac0c94a428f0" category="inline-link-macro">Disaster recovery (DRO) con FSX per ONTAP e VMC</block>
  <block id="bcc01e72c7e79a58e573ae6519d6b0b4" category="list-text"><block ref="bcc01e72c7e79a58e573ae6519d6b0b4" category="inline-link-macro-rx"></block></block>
  <block id="7c5ba33b986ba469d277c4ca9f906e55" category="inline-link-macro">Migrazione dei carichi di lavoro nel datastore FSxN con VMware HCX</block>
  <block id="c037991d132128e15cdbfefe3ac8e997" category="list-text"><block ref="c037991d132128e15cdbfefe3ac8e997" category="inline-link-macro-rx"></block></block>
  <block id="e74fe990166c1a4bb77dde7f12823b5d" category="paragraph">PRESTO DISPONIBILE!</block>
  <block id="07b0eade4402d209b5dbe587a8ad3f6f" category="doc">Implementare e configurare l'ambiente di virtualizzazione su AWS</block>
  <block id="e647d88b9bd859d2c3e943c24b4fef00" category="paragraph">Come per i servizi on-premise, la pianificazione di VMware Cloud su AWS è fondamentale per un ambiente pronto per la produzione di successo per la creazione di macchine virtuali e la migrazione.</block>
  <block id="bb19e956b854f8e209f51237a29feb31" category="admonition">Lo storage in-guest è attualmente l'unico metodo supportato per connettere Cloud Volumes ONTAP (CVO) ad AWS VMC.</block>
  <block id="389544cc8199f2ddd936397695d0dbe9" category="example-title">Implementare e configurare VMware Cloud per AWS</block>
  <block id="02b412692a538ee9dc2534f0f9c73dc1" category="paragraph"><block ref="560d5b2cd40977bd7b77b31d7088f657" category="inline-link-macro-rx"></block> Offre un'esperienza nativa nel cloud per i carichi di lavoro basati su VMware nell'ecosistema AWS. Ogni VMware Software-Defined Data Center (SDDC) viene eseguito in un Amazon Virtual Private Cloud (VPC) e fornisce uno stack VMware completo (incluso vCenter Server), networking software-defined NSX-T, storage vSAN software-defined e uno o più host ESXi che forniscono risorse di calcolo e storage ai carichi di lavoro.</block>
  <block id="dc77b78f59a0c38a9a2e8927dc05e916" category="paragraph">Questa sezione descrive come configurare e gestire VMware Cloud su AWS e utilizzarlo in combinazione con Amazon FSX per NetApp ONTAP e/o Cloud Volumes ONTAP su AWS con storage in-guest.</block>
  <block id="3712f34e1b7039d6d9bfb255ecc54445" category="paragraph">Il processo di configurazione può essere suddiviso in tre parti:</block>
  <block id="6619dc0097706121ef2efa1294da110b" category="example-title">Registrati per un account AWS</block>
  <block id="f54d8dbbc1cb20fd37a59a4563644ef8" category="inline-link-macro">Account Amazon Web Services</block>
  <block id="4ca1486cd3276884e41ad4b36080c10b" category="paragraph">Registratevi per un <block ref="ab3390028f6599a1b73b747febbf672d" category="inline-link-macro-rx"></block>.</block>
  <block id="252c0d3625c410f643362d13f1e35681" category="paragraph">Per iniziare, è necessario un account AWS, supponendo che non ne sia già stato creato uno. Nuovi o esistenti, per eseguire molte operazioni di questa procedura sono necessari privilegi amministrativi nell'account. Vedi questo <block ref="d01b332d778720bc2fe2a9a15e6ba01d" category="inline-link-macro-rx"></block> Per ulteriori informazioni sulle credenziali AWS.</block>
  <block id="3f01bd52a695afbced7f2a43525ec966" category="example-title">Registrati per un account My VMware</block>
  <block id="020e995219c3fad42714462fc9368253" category="inline-link-macro">Il mio VMware</block>
  <block id="4f87cd22b54abb602d4264ede77c75fd" category="paragraph">Registratevi per un <block ref="6fb1d438d7363efa930c55af527a6c23" category="inline-link-macro-rx"></block> account.</block>
  <block id="e1ed167660991d514f55d806a323f3b5" category="paragraph">Per accedere al portfolio cloud di VMware (incluso VMware Cloud su AWS), è necessario un account cliente VMware o un account My VMware. Se non lo si è già fatto, creare un account VMware <block ref="aefb6f511cceca70505b3e5bf76155fe" category="inline-link-macro-rx"></block>.</block>
  <block id="60fa505f14fb504e941cbc61b74d644a" category="example-title">Provisioning di SDDC in VMware Cloud</block>
  <block id="6d931b72d8efc3fd87b7fdd5127cbba7" category="paragraph">Una volta configurato l'account VMware e eseguito il dimensionamento corretto, l'implementazione di un Software-Defined Data Center è il passaggio successivo più ovvio per l'utilizzo del servizio VMware Cloud su AWS. Per creare un SDDC, scegliere una regione AWS per ospitarla, assegnare un nome all'SDDC e specificare quanti host ESXi si desidera che l'SDDC contenga. Se non si dispone già di un account AWS, è comunque possibile creare un SDDC di configurazione iniziale contenente un singolo host ESXi.</block>
  <block id="7e70ad389301fa9d8936c18cefd85b53" category="list-text">Accedere a VMware Cloud Console utilizzando le credenziali VMware esistenti o create di recente.</block>
  <block id="28570a642842f2bfa7db5cc3679fd904" category="paragraph"><block ref="28570a642842f2bfa7db5cc3679fd904" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53722f60844c899c63607413f74e8dd8" category="list-text">Configurare la regione AWS, l'implementazione, il tipo di host e il nome SDDC:</block>
  <block id="5ec07ba481e6291d3af5e3ca61f27f57" category="paragraph"><block ref="5ec07ba481e6291d3af5e3ca61f27f57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5c464b97b208b8c43e9fdd315c80793" category="list-text">Connettersi all'account AWS desiderato ed eseguire lo stack di formazione cloud AWS.</block>
  <block id="b6822d593b3a1b683cb4e513b210c080" category="paragraph"><block ref="941b74b5e4d054f44fb05f89bfb30732" category="inline-image-macro-rx" type="image"></block>
<block ref="5ca301c5ba248bc9f9566d74470fcc6b" category="inline-image-macro-rx" type="image"></block>
<block ref="54108005ae53e37fa06b081374d6ea43" category="inline-image-macro-rx" type="image"></block>
<block ref="9f7f4a317cf9d46aa6a2aa8f441279ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59e9afc055ce73e7e6154ea7609eec59" category="admonition">In questa convalida viene utilizzata la configurazione a host singolo.</block>
  <block id="3f68cef60baccc27cfef6b618e56f809" category="list-text">Selezionare il VPC AWS desiderato per la connessione dell'ambiente VMC.</block>
  <block id="49e131b27a342d4970e86a31a127d41c" category="paragraph"><block ref="49e131b27a342d4970e86a31a127d41c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="102a37b9412553c4ae6b25a174592fbb" category="list-text">Configurare la subnet di gestione VMC; questa subnet contiene servizi gestiti da VMC come vCenter, NSX e così via. Non scegliere uno spazio di indirizzi sovrapposto con altre reti che necessitano di connettività all'ambiente SDDC. Infine, seguire le raccomandazioni per la dimensione CIDR indicate di seguito.</block>
  <block id="0e8db488f9554136a65dd18025db8cf0" category="paragraph"><block ref="0e8db488f9554136a65dd18025db8cf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a541610269aad8edaf8defd851246b08" category="list-text">Esaminare e riconoscere la configurazione SDDC, quindi fare clic su Deploy the SDDC (implementa SDDC).</block>
  <block id="a8246981b8dc3e6123523500b3b1371d" category="paragraph"><block ref="a8246981b8dc3e6123523500b3b1371d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1bb7bef7f28887197cfca7059ef2d6d3" category="paragraph">Il completamento del processo di implementazione richiede in genere circa due ore.</block>
  <block id="e9dcc1b6680c77f105c83d040009d685" category="paragraph"><block ref="e9dcc1b6680c77f105c83d040009d685" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79b6ae1d041f5cd8b33d3f351b301275" category="list-text">Al termine dell'operazione, SDDC è pronto per l'uso.</block>
  <block id="9013490d3a116eed1c849197a6c8aac0" category="paragraph"><block ref="9013490d3a116eed1c849197a6c8aac0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e149dd16e33c6137fe08782e96c9b226" category="inline-link-macro">Implementare un SDDC dalla console VMC</block>
  <block id="086760513a416fbc6578703211523314" category="paragraph">Per una guida dettagliata sull'implementazione di SDDC, vedere <block ref="7279ebe13e8b8c4ee89b8961f2bf1157" category="inline-link-macro-rx"></block>.</block>
  <block id="8a69f1bae52e494c6960f92a27390dcf" category="paragraph">Per connettere VMware Cloud a FSX ONTAP, attenersi alla seguente procedura:</block>
  <block id="7ca6fbd8bbb6725fab7413e4179738f6" category="list-text">Una volta completata l'implementazione di VMware Cloud e connessa ad AWS VPC, è necessario implementare Amazon FSX per NetApp ONTAP in un nuovo VPC anziché nel VPC collegato originale (vedere la schermata riportata di seguito). FSX (IP mobili NFS e SMB) non è accessibile se viene implementato nel VPC connesso. Tenere presente che gli endpoint ISCSI come Cloud Volumes ONTAP funzionano correttamente dal VPC connesso.</block>
  <block id="da6646a18f048724eb432bf61285ca7f" category="paragraph"><block ref="da6646a18f048724eb432bf61285ca7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a85dd65f7163e587c050ea8931a368ae" category="list-text">Implementare un VPC aggiuntivo nella stessa regione, quindi implementare Amazon FSX per NetApp ONTAP nel nuovo VPC.</block>
  <block id="c78834afa7d24e921aa4d756d0a6409f" category="paragraph">La configurazione di un gruppo SDDC nella console VMware Cloud abilita le opzioni di configurazione di rete necessarie per connettersi al nuovo VPC in cui viene implementato FSX. Nella fase 3, verificare che l'opzione "Configurazione di VMware Transit Connect per il gruppo comporterà costi per allegato e trasferimento dati" sia selezionata, quindi scegliere Crea gruppo. Il completamento del processo può richiedere alcuni minuti.</block>
  <block id="f91a2b452c63b5ccfcb4c39c2957c74e" category="paragraph"><block ref="ca83e0582a449c1b4399270025e1cc4a" category="inline-image-macro-rx" type="image"></block>
<block ref="9232dff72050e533bd1e173e5a0dd48c" category="inline-image-macro-rx" type="image"></block>
<block ref="5a108f597862e683ab9463f7c3ba6df6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fae60fbb10da5c3df46ec8ae03cd29b5" category="inline-link-macro">Istruzioni per il collegamento di un VPC esterno</block>
  <block id="784ad3266f853af20763bb78f5eec87a" category="list-text">Collegare il VPC appena creato al gruppo SDDC appena creato. Selezionare la scheda External VPC (VPC esterno) e seguire le istruzioni <block ref="19928d01a63fe78e1303b296c2046666" category="inline-link-macro-rx"></block> al gruppo. Il completamento di questo processo può richiedere da 10 a 15 minuti.</block>
  <block id="14466a85376e8776f891db4cb3c38c6c" category="paragraph"><block ref="dd1eb585a08c833cec9544c048af36b6" category="inline-image-macro-rx" type="image"></block>
<block ref="38542de5661e382aba9345fe6e5a991b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8acea1c4fcca87631ca127e2bc757f13" category="inline-link-macro">AWS Transit Gateway</block>
  <block id="77508ef16874a250b66be2f90fc59918" category="list-text">Nell'ambito del processo VPC esterno, viene richiesto tramite la console AWS di accedere a una nuova risorsa condivisa tramite Resource Access Manager. La risorsa condivisa è <block ref="ccce2323414354d76e9cea0c1df9221b" category="inline-link-macro-rx"></block> Gestito da VMware Transit Connect.</block>
  <block id="ac81300f843e6b91377e64a8edb819c2" category="paragraph"><block ref="63de05888c0a11205c33fd560dba3bc5" category="inline-image-macro-rx" type="image"></block>
<block ref="0455c56bd9863ddfae4079b5aabd42e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bcf415daee6d6f894a54f025534ba071" category="list-text">Creare l'allegato del gateway di transito.</block>
  <block id="e222d36183b455bb51f289144826c239" category="paragraph"><block ref="e222d36183b455bb51f289144826c239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b6693c4eff7f7923c59277702b441a9" category="list-text">Sulla console VMC, accettare l'allegato VPC. Il completamento di questo processo può richiedere circa 10 minuti.</block>
  <block id="64d5d06ed03c085c4f5ce23ff6eeddac" category="paragraph"><block ref="64d5d06ed03c085c4f5ce23ff6eeddac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9b85dc0e557eb865bfa9ae84e251623" category="list-text">Nella scheda External VPC (VPC esterno), fare clic sull'icona di modifica nella colonna routes (percorsi) e aggiungere i seguenti percorsi richiesti:</block>
  <block id="ae6434a5ebe0bad2f978fef8e0ed9efe" category="inline-link-macro">IP mobili</block>
  <block id="06651ace1eab88d681ca9a8852bf26e2" category="list-text">Un percorso per l'intervallo IP mobile per Amazon FSX per NetApp ONTAP <block ref="14a98976d888daccbd07561411cfd6fa" category="inline-link-macro-rx"></block>.</block>
  <block id="5e16e681111a1a5b2dc805d69827532f" category="list-text">Route per l'intervallo IP mobile per Cloud Volumes ONTAP (se applicabile).</block>
  <block id="daa8a39ba75e8ac01fd26d579ce35fd9" category="paragraph"><block ref="daa8a39ba75e8ac01fd26d579ce35fd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="853349bb92eccb477b47eef3b8a5d9e2" category="inline-link-macro">regole del firewall</block>
  <block id="499ca5dd26dbcc4c89a04ac771b316a6" category="inline-link-macro">passaggi dettagliati</block>
  <block id="14c6314f2ae331d7f9a01ac04a75cd2b" category="list-text">Infine, consentire il traffico bidirezionale <block ref="0756551700fd3215666355892b2f3692" category="inline-link-macro-rx"></block> Per l'accesso a FSX/CVO. Seguire queste istruzioni <block ref="583f77470215de8611ddf3fba5fc6512" category="inline-link-macro-rx"></block> Per le regole firewall del gateway di calcolo per la connettività dei carichi di lavoro SDDC.</block>
  <block id="098b98cba4d6766e7de663adf0fdabb0" category="paragraph"><block ref="098b98cba4d6766e7de663adf0fdabb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f4480b9caed7d956fd6071b4cce03b9" category="list-text">Una volta configurati i gruppi di firewall per il gateway di gestione e di calcolo, è possibile accedere a vCenter come segue:</block>
  <block id="f1c1b29fad3f2bdb9d8d054686b86542" category="paragraph"><block ref="f1c1b29fad3f2bdb9d8d054686b86542" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8b86f112029b19bf6451ba4624a4090" category="paragraph">Il passaggio successivo consiste nel verificare che Amazon FSX ONTAP o Cloud Volumes ONTAP sia configurato in base ai requisiti e che i volumi siano configurati per trasferire i componenti di storage da vSAN per ottimizzare l'implementazione.</block>
  <block id="3bd61e230841633b4a28f6d2f882d50e" category="summary">Un ambiente e un piano di disaster recovery (DR) comprovati sono fondamentali per le organizzazioni per garantire che le applicazioni business-critical possano essere ripristinate rapidamente in caso di grave interruzione del servizio. Questa soluzione si concentra sulla dimostrazione dei casi di utilizzo del DR con particolare attenzione alle tecnologie VMware e NetApp, sia on-premise che con VMware Cloud su AWS.</block>
  <block id="1ae55e7a3caf44baf5721cdf304e676d" category="doc">TR-4931: Disaster recovery con VMware Cloud su Amazon Web Services e Guest Connect</block>
  <block id="67c8804409fa1f91b1b477b7c99d1d71" category="paragraph">Autori: Chris Reno, Josh Powell e Suresh Thoppay - NetApp Solutions Engineering</block>
  <block id="5f3d0127b9424be374b1c1474deb2684" category="paragraph">NetApp vanta una lunga storia di integrazione con VMware, come dimostrano le decine di migliaia di clienti che hanno scelto NetApp come partner di storage per il loro ambiente virtualizzato. Questa integrazione continua con le opzioni di connessione guest nel cloud e le recenti integrazioni con i datastore NFS. Questa soluzione si concentra sul caso di utilizzo comunemente indicato come storage connesso al guest.</block>
  <block id="1134d985d8893464bee3d37e02a36402" category="paragraph">Nello storage connesso agli ospiti, il VMDK guest viene implementato su un datastore con provisioning VMware e i dati delle applicazioni vengono memorizzati su iSCSI o NFS e mappati direttamente sulla macchina virtuale. Le applicazioni Oracle e MS SQL vengono utilizzate per dimostrare uno scenario di DR, come illustrato nella figura seguente.</block>
  <block id="50dd1256f4cf87b2fa70e300ade578e4" category="paragraph"><block ref="50dd1256f4cf87b2fa70e300ade578e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37242160d8bbd9ad700322c3c2499272" category="section-title">Presupposti, prerequisiti e panoramica dei componenti</block>
  <block id="3ea8c755cca91dd6bbeec88e906263e9" category="paragraph">Prima di implementare questa soluzione, esaminare la panoramica dei componenti, i prerequisiti necessari per implementare la soluzione e i presupposti della documentazione della soluzione.</block>
  <block id="7bcf43f481a8076036689561dce0e62d" category="inline-link-macro">Requisiti, requisiti e pianificazione della soluzione DR</block>
  <block id="88ac8db9784908706c34feb6caee9044" category="paragraph"><block ref="88ac8db9784908706c34feb6caee9044" category="inline-link-macro-rx"></block></block>
  <block id="684b2b80ca970225e77585d96775fc95" category="section-title">Eseguire il DR con SnapCenter</block>
  <block id="dcbabf28828ef9b03cf9856a74eedf64" category="paragraph">In questa soluzione, SnapCenter fornisce snapshot coerenti con l'applicazione per i dati delle applicazioni SQL Server e Oracle. Questa configurazione, insieme alla tecnologia SnapMirror, offre una replica dei dati ad alta velocità tra il nostro cluster AFF on-premise e FSX ONTAP. Inoltre, Veeam Backup &amp; Replication offre funzionalità di backup e ripristino per le nostre macchine virtuali.</block>
  <block id="a7b22ebf343cad0f97e90df47a7d7f0c" category="paragraph">In questa sezione viene descritta la configurazione di SnapCenter, SnapMirror e Veeam per il backup e il ripristino.</block>
  <block id="66b3c7123c5d46e3d176f20cb0ede484" category="paragraph">Le seguenti sezioni illustrano la configurazione e i passaggi necessari per completare un failover nel sito secondario:</block>
  <block id="860d1fc24372044f6c88f15cea6b9155" category="section-title">Configurare le relazioni di SnapMirror e le pianificazioni di conservazione</block>
  <block id="0e966aefc6e57da3e61d08eb83f8f9b7" category="paragraph">SnapCenter può aggiornare le relazioni di SnapMirror all'interno del sistema di storage primario (primario &gt; mirror) e ai sistemi di storage secondario (primario &gt; vault) per l'archiviazione e la conservazione a lungo termine. A tale scopo, è necessario stabilire e inizializzare una relazione di replica dei dati tra un volume di destinazione e un volume di origine utilizzando SnapMirror.</block>
  <block id="1888797bfba812a31bad2548f183ffe6" category="paragraph">I sistemi ONTAP di origine e di destinazione devono trovarsi in reti con peering tramite VPC Amazon, gateway di transito, connessione diretta AWS o VPN AWS.</block>
  <block id="aa318628cbf2869d724b704d547dc8f4" category="paragraph">Per impostare le relazioni di SnapMirror tra un sistema ONTAP on-premise e FSX ONTAP sono necessari i seguenti passaggi:</block>
  <block id="fbfcc1aa520560c558b69fb448e3e601" category="inline-link">FSX per ONTAP - Guida utente di ONTAP</block>
  <block id="7ffc7a254a972aeb4df657be8d41c5a2" category="admonition">Fare riferimento a.<block ref="67cdb2cad717abb12c965d934ae13809" category="inline-link-rx"></block> Per ulteriori informazioni sulla creazione di relazioni SnapMirror con FSX.</block>
  <block id="cc9e567b33c3e82ac1b18f4780ca5f42" category="example-title">Registrare le interfacce logiche Intercluster di origine e destinazione</block>
  <block id="44c719fef7654c0f1aecbd77f14b9ab7" category="paragraph">Per il sistema ONTAP di origine residente on-premise, è possibile recuperare le informazioni LIF tra cluster da Gestore di sistema o dall'interfaccia CLI.</block>
  <block id="d3983f090ac28583ca4499e720c4cc25" category="list-text">In Gestore di sistema di ONTAP, accedere alla pagina Panoramica di rete e recuperare gli indirizzi IP di tipo: Intercluster configurati per comunicare con il VPC di AWS su cui è installato FSX.</block>
  <block id="de45ac288e78c12d34318717ae7cacd8" category="paragraph"><block ref="de45ac288e78c12d34318717ae7cacd8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94cf5d813faccf347c0faaab27941922" category="list-text">Per recuperare gli indirizzi IP dell'Intercluster per FSX, accedere alla CLI ed eseguire il seguente comando:</block>
  <block id="244c638485f1bcb26a0e966bd289e4a9" category="paragraph"><block ref="244c638485f1bcb26a0e966bd289e4a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ce2dabb10080d128fabb2edc80a417a" category="example-title">Stabilire il peering del cluster tra ONTAP e FSX</block>
  <block id="84c8209b0c6f3e5e18c66f9f45cf5358" category="paragraph">Per stabilire il peering del cluster tra i cluster ONTAP, è necessario confermare una passphrase univoca inserita nel cluster ONTAP di avvio nell'altro cluster peer.</block>
  <block id="085f57325580b1a203343baf39c910d1" category="list-text">Impostare il peering sul cluster FSX di destinazione utilizzando<block ref="9b5825a8b104756a9fc62c8432005be0" prefix=" " category="inline-code"></block> comando. Quando richiesto, immettere una passphrase univoca da utilizzare in seguito nel cluster di origine per completare il processo di creazione.</block>
  <block id="475947ec353590c018e5b0d813538a84" category="list-text">Nel cluster di origine, è possibile stabilire la relazione peer del cluster utilizzando Gestore di sistema di ONTAP o l'interfaccia CLI. Da Gestore di sistema di ONTAP, accedere a protezione &gt; Panoramica e selezionare cluster peer.</block>
  <block id="692ee36299ec8b049d7462a75dd1463a" category="paragraph"><block ref="692ee36299ec8b049d7462a75dd1463a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aa5f33eeccc2dab1c1b6aba564ec238" category="list-text">Nella finestra di dialogo Peer Cluster, inserire le informazioni richieste:</block>
  <block id="28b3f47a49c9a2fb506879e23a7b1723" category="list-text">Inserire la passphrase utilizzata per stabilire la relazione del cluster peer nel cluster FSX di destinazione.</block>
  <block id="157bacc8ed48f5dc430560300ef9f5a5" category="list-text">Selezionare<block ref="93cba07454f06a4a960172bbd6e2a435" prefix=" " category="inline-code"></block> per stabilire una relazione crittografata.</block>
  <block id="70c324b6369e6cb6f4a8df99ac8b4b7e" category="list-text">Inserire gli indirizzi IP LIF dell'intercluster del cluster FSX di destinazione.</block>
  <block id="c9af913b694e4e4dcce39b7e3a2eabd2" category="list-text">Fare clic su Initiate Cluster peering (Avvia peering cluster) per completare il processo.</block>
  <block id="409a2deb1ca3f5fe6ad3f90977529965" category="paragraph"><block ref="409a2deb1ca3f5fe6ad3f90977529965" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b39da3667dd0f4cab32a9027eeadf60" category="list-text">Verificare lo stato della relazione peer del cluster dal cluster FSX con il seguente comando:</block>
  <block id="25ca322582650fd7d3732bea77176905" category="paragraph"><block ref="25ca322582650fd7d3732bea77176905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdf4cefe90737a4248cd083c1a1d2e36" category="example-title">Stabilire una relazione di peering SVM</block>
  <block id="4f194687804b9dff8219b58d47dc2a69" category="paragraph">Il passaggio successivo consiste nell'impostare una relazione SVM tra le macchine virtuali dello storage di destinazione e di origine che contengono i volumi che si trovano nelle relazioni di SnapMirror.</block>
  <block id="9bd0b716a7c6f7821d01f58d3576978d" category="list-text">Dal cluster FSX di origine, utilizzare il seguente comando dalla CLI per creare la relazione peer SVM:</block>
  <block id="1a82405201cf3be5b0f3f96ffb551406" category="list-text">Dal cluster ONTAP di origine, accettare la relazione di peering con Gestore di sistema ONTAP o CLI.</block>
  <block id="dd0f7f7da0626cbd138836fd072f65de" category="list-text">Da Gestore di sistema ONTAP, andare a protezione &gt; Panoramica e selezionare le VM di storage peer in peer di macchine virtuali di storage.</block>
  <block id="486b508476b1f8dff9a5314ac26e36e9" category="paragraph"><block ref="486b508476b1f8dff9a5314ac26e36e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8b0c3d15e3f1c8ecebfa725f753f98e7" category="list-text">Nella finestra di dialogo Peer Storage VM, compilare i campi obbligatori:</block>
  <block id="b980118a5ade1402e409e2354f286c60" category="list-text">La VM di storage di origine</block>
  <block id="2cb119a467d09216231bdf2ff83bfb5f" category="list-text">Il cluster di destinazione</block>
  <block id="1d1fa3ffdce0bd1d4a0faf3d15fb94f6" category="list-text">La VM di storage di destinazione</block>
  <block id="22a926c9631a59bce535d179c6f1f5ae" category="paragraph"><block ref="22a926c9631a59bce535d179c6f1f5ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52fee5b72c266bcf84963c260c8cf2ed" category="list-text">Fare clic su Peer Storage VM per completare il processo di peering SVM.</block>
  <block id="332a29af91768111608bcb6bf43107e7" category="example-title">Creare un criterio di conservazione delle snapshot</block>
  <block id="b2659ce2591907c1c9269d82e68d8109" category="paragraph">SnapCenter gestisce le pianificazioni di conservazione per i backup che esistono come copie Snapshot sul sistema di storage primario. Questo viene stabilito quando si crea un criterio in SnapCenter. SnapCenter non gestisce le policy di conservazione per i backup conservati nei sistemi di storage secondari. Questi criteri vengono gestiti separatamente attraverso un criterio SnapMirror creato nel cluster FSX secondario e associato ai volumi di destinazione che si trovano in una relazione SnapMirror con il volume di origine.</block>
  <block id="1d64d8f27569c9f8182a6c536add0069" category="paragraph">Quando si crea un criterio SnapCenter, è possibile specificare un'etichetta di criterio secondaria che viene aggiunta all'etichetta SnapMirror di ogni snapshot generato quando viene eseguito un backup SnapCenter.</block>
  <block id="b3ca63efc1d304947f75061071da604c" category="admonition">Sullo storage secondario, queste etichette vengono associate alle regole dei criteri associate al volume di destinazione allo scopo di applicare la conservazione degli snapshot.</block>
  <block id="422f63101989fe9b50c840c82bb5fe9f" category="paragraph">L'esempio seguente mostra un'etichetta SnapMirror presente su tutte le snapshot generate come parte di una policy utilizzata per i backup giornalieri del database SQL Server e dei volumi di log.</block>
  <block id="5f70d8aa597c91ed28f7be347e2fac0a" category="paragraph"><block ref="5f70d8aa597c91ed28f7be347e2fac0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5c9b73d439aa92ef011ebf02237c888" category="inline-link">Documentazione SnapCenter</block>
  <block id="2d0828fbc32c49aad5149bd71dd05ddf" category="paragraph">Per ulteriori informazioni sulla creazione di criteri SnapCenter per un database SQL Server, vedere<block ref="7f14e0044cbde8b494ce0e026c2561cf" category="inline-link-rx"></block>.</block>
  <block id="f508c027fda31d58c4677043e1a3eaa8" category="paragraph">È necessario innanzitutto creare un criterio SnapMirror con regole che determinano il numero di copie snapshot da conservare.</block>
  <block id="bb66348f31a358d5d6f969b7ab6ee82c" category="list-text">Creare il criterio SnapMirror sul cluster FSX.</block>
  <block id="e8d5c5ace79f3b8be2db75ba7135e0a8" category="list-text">Aggiungere regole al criterio con le etichette SnapMirror che corrispondono alle etichette dei criteri secondari specificate nei criteri SnapCenter.</block>
  <block id="5a3507b9cf4dd4a569d2ffe314e6b7eb" category="paragraph">Il seguente script fornisce un esempio di regola che è possibile aggiungere a un criterio:</block>
  <block id="762402f82600698541f18b3a2f4ac8f4" category="admonition">Creare regole aggiuntive per ciascuna etichetta SnapMirror e il numero di snapshot da conservare (periodo di conservazione).</block>
  <block id="2f061612da9689d76bf56673168e2297" category="example-title">Creare volumi di destinazione</block>
  <block id="3c09a07bfb806c844317f3b57d93a884" category="paragraph">Per creare un volume di destinazione su FSX che riceverà le copie Snapshot dai volumi di origine, eseguire il seguente comando su FSX ONTAP:</block>
  <block id="9a9f4d5cf2f4ccad396091e224e45c7e" category="example-title">Creare le relazioni di SnapMirror tra i volumi di origine e di destinazione</block>
  <block id="dfceac14afc666c56290006c22ba8a0a" category="paragraph">Per creare una relazione SnapMirror tra un volume di origine e un volume di destinazione, eseguire il seguente comando su FSX ONTAP:</block>
  <block id="e3a7ebd416df655cee455d58e86e8477" category="example-title">Inizializzare le relazioni di SnapMirror</block>
  <block id="a457a30bf4ecea53998aa344bee4329a" category="paragraph">Inizializzare la relazione SnapMirror. Questo processo avvia un nuovo snapshot generato dal volume di origine e lo copia nel volume di destinazione.</block>
  <block id="2cd2d537da5641f8e4fc5712872944c4" category="paragraph">Per creare un volume, eseguire il seguente comando su FSX ONTAP:</block>
  <block id="b33c39866fb3627a46e2d343e5fcdb1a" category="section-title">Implementare e configurare Windows SnapCenter Server on-premise.</block>
  <block id="d312952f462ee1dc88347d6060c708da" category="example-title">Implementazione del server Windows SnapCenter on-premise</block>
  <block id="a9a05fe4fa63215c3d368883b85e9312" category="paragraph">Questa soluzione utilizza NetApp SnapCenter per eseguire backup coerenti con l'applicazione dei database SQL Server e Oracle. Insieme a Veeam Backup &amp; Replication per il backup dei VMDK delle macchine virtuali, questo offre una soluzione completa di disaster recovery per data center on-premise e basati sul cloud.</block>
  <block id="989d04f01dc04fe21c2b542b83a45a6b" category="inline-link">Centro di documentazione NetApp</block>
  <block id="5d15da138c85d083e6e6409b418b8411" category="paragraph">Il software SnapCenter è disponibile sul sito di supporto NetApp e può essere installato su sistemi Microsoft Windows che risiedono in un dominio o in un gruppo di lavoro. Una guida dettagliata alla pianificazione e le istruzioni di installazione sono disponibili all'indirizzo<block ref="c18608d8aa7f8cbafcf1d09b2fb01df0" category="inline-link-rx"></block>.</block>
  <block id="e6220e7462e6d815945c93dcd734235f" category="paragraph">Il software SnapCenter è disponibile all'indirizzo<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>.</block>
  <block id="d2476cc18d417aa498cc7c32f99e980b" category="paragraph">Una volta installata, è possibile accedere alla console SnapCenter da un browser Web utilizzando _ https://Virtual_Cluster_IP_or_FQDN:8146_.</block>
  <block id="782f10deb2809cc33e0082dbe9371f9b" category="paragraph">Dopo aver effettuato l'accesso alla console, è necessario configurare SnapCenter per il backup dei database SQL Server e Oracle.</block>
  <block id="63b96bb46045042b50fd68d9b5a0f0ba" category="example-title">Aggiungere controller storage a SnapCenter</block>
  <block id="8956d4de491225a4e6515ba0ad92fb30" category="paragraph">Per aggiungere controller di storage a SnapCenter, attenersi alla seguente procedura:</block>
  <block id="2ba7db7e99ccd03f69c81ce1f25330e6" category="list-text">Dal menu a sinistra, selezionare sistemi storage, quindi fare clic su nuovo per avviare il processo di aggiunta dei controller storage a SnapCenter.</block>
  <block id="f1d609f44050cd3b443f66e474c3b93c" category="paragraph"><block ref="f1d609f44050cd3b443f66e474c3b93c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48806d1941dc50dadf8bcd5d590511ab" category="list-text">Nella finestra di dialogo Aggiungi sistema di storage, aggiungere l'indirizzo IP di gestione del cluster ONTAP locale on-premise e il nome utente e la password. Quindi fare clic su Submit (Invia) per avviare il rilevamento del sistema storage.</block>
  <block id="7b7a93dac3e0141a111190c64a54a220" category="paragraph"><block ref="7b7a93dac3e0141a111190c64a54a220" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc7b9fe54780f87aa8bdf884b95187c5" category="list-text">Ripetere questa procedura per aggiungere il sistema FSX ONTAP a SnapCenter. In questo caso, selezionare More Options (altre opzioni) nella parte inferiore della finestra Add Storage System (Aggiungi sistema di storage) e fare clic sulla casella di controllo Secondary (secondario) per designare il sistema FSX come sistema di storage secondario aggiornato con le copie SnapMirror o le snapshot di backup primarie.</block>
  <block id="4a8fedebba8d5bd8e357863942b66b79" category="paragraph"><block ref="4a8fedebba8d5bd8e357863942b66b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62104d735113c9c7e8a23cd031ca2004" category="paragraph">Per ulteriori informazioni sull'aggiunta di sistemi storage a SnapCenter, consultare la documentazione all'indirizzo<block ref="05f72e618af68eda439c6d688692dcd6" category="inline-link-rx"></block>.</block>
  <block id="c81dcfed07648c407976127bb0bdbed2" category="example-title">Aggiungere host a SnapCenter</block>
  <block id="e796a589329333070ad568f533b21931" category="paragraph">Il passaggio successivo consiste nell'aggiungere server applicazioni host a SnapCenter. Il processo è simile sia per SQL Server che per Oracle.</block>
  <block id="6718a4b38f7a3df604d1fd6079decaae" category="list-text">Dal menu a sinistra, selezionare host, quindi fare clic su Aggiungi per avviare il processo di aggiunta dei controller di storage a SnapCenter.</block>
  <block id="4106a2178f1f526d51c57cb723e0f3ef" category="list-text">Nella finestra Add hosts (Aggiungi host), aggiungere il tipo di host, il nome host e le credenziali del sistema host. Selezionare il tipo di plug-in. Per SQL Server, selezionare il plug-in Microsoft Windows e Microsoft SQL Server.</block>
  <block id="3eae7017924ae8e187a046e62f5c334e" category="paragraph"><block ref="3eae7017924ae8e187a046e62f5c334e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdb2b840f37deff5210ef9f13e554fd5" category="list-text">Per Oracle, compilare i campi obbligatori nella finestra di dialogo Add host (Aggiungi host) e selezionare la casella di controllo per il plug-in Oracle Database. Fare clic su Submit (Invia) per avviare il processo di rilevamento e aggiungere l'host a SnapCenter.</block>
  <block id="6430fb639e6454a8e47d23925ec8f583" category="paragraph"><block ref="6430fb639e6454a8e47d23925ec8f583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7da39703d1c501afafc02c06d1c31788" category="example-title">Creare policy SnapCenter</block>
  <block id="fa5cc6d015db1929ddc02765f2003a33" category="paragraph">I criteri stabiliscono le regole specifiche da seguire per un processo di backup. Includono, a titolo esemplificativo ma non esaustivo, la pianificazione del backup, il tipo di replica e il modo in cui SnapCenter gestisce il backup e il troncamento dei log delle transazioni.</block>
  <block id="817a33901829b57a630a499c24b4daf2" category="paragraph">È possibile accedere ai criteri nella sezione Impostazioni del client Web di SnapCenter.</block>
  <block id="6ddda0770a816978059cd0702e0223d0" category="paragraph"><block ref="6ddda0770a816978059cd0702e0223d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9d91360f1fd4ad1abf6c445ec8ff103" category="paragraph">Per informazioni complete sulla creazione di criteri per i backup di SQL Server, vedere<block ref="7f14e0044cbde8b494ce0e026c2561cf" category="inline-link-rx"></block>.</block>
  <block id="f079afadb233d404e335685a7b58c70e" category="paragraph">Per informazioni complete sulla creazione di policy per i backup Oracle, vedere<block ref="be1c60aeb8bf91be9c4096428152eedc" category="inline-link-rx"></block>.</block>
  <block id="5847f474084786fc8a16763856c1b0da" category="list-text">Durante la creazione guidata dei criteri, prendere nota della sezione Replication (Replica). In questa sezione vengono descritti i tipi di copie SnapMirror secondarie che si desidera eseguire durante il processo di backup.</block>
  <block id="fc3c693a9b60faa4913d47e755b4cf34" category="list-text">L'impostazione "Update SnapMirror after creating a local Snapshot copy" (Aggiorna SnapMirror dopo la creazione di una copia Snapshot locale) fa riferimento all'aggiornamento di una relazione SnapMirror quando tale relazione esiste tra due macchine virtuali di storage che risiedono sullo stesso cluster.</block>
  <block id="77bf66c8cee4cd2482095210be78e13a" category="list-text">L'impostazione "Aggiorna SnapVault dopo la creazione di una copia snapshot locale" viene utilizzata per aggiornare una relazione SnapMirror esistente tra due cluster separati e tra un sistema ONTAP on-premise e Cloud Volumes ONTAP o FSxN.</block>
  <block id="824aec6074385910e619ac91969c68a3" category="paragraph">L'immagine seguente mostra le opzioni precedenti e l'aspetto della procedura guidata dei criteri di backup.</block>
  <block id="89bace67b9ee8f5a253e88d282ceb63d" category="paragraph"><block ref="89bace67b9ee8f5a253e88d282ceb63d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6bd8190e5c79ad5d86289d596dd8c16" category="example-title">Creare gruppi di risorse SnapCenter</block>
  <block id="2f15c296209e980cccf829b7e5c1bbca" category="paragraph">I gruppi di risorse consentono di selezionare le risorse di database che si desidera includere nei backup e i criteri seguiti per tali risorse.</block>
  <block id="e96fdebed13bd03c9e88f6cff2b7ed67" category="list-text">Accedere alla sezione risorse nel menu a sinistra.</block>
  <block id="8b5265ba89102ff3a5fd8b504ba85140" category="list-text">Nella parte superiore della finestra, selezionare il tipo di risorsa da utilizzare (in questo caso Microsoft SQL Server), quindi fare clic su New Resource Group (nuovo gruppo di risorse).</block>
  <block id="695c07b026f6602eff292288473cdc42" category="paragraph"><block ref="695c07b026f6602eff292288473cdc42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bad635c8aa26c147bd68eb7b700cabbe" category="paragraph">La documentazione di SnapCenter illustra i dettagli passo-passo per la creazione di gruppi di risorse per database SQL Server e Oracle.</block>
  <block id="6f9886092f343d1ecc5b676f4ca381c7" category="paragraph">Per eseguire il backup delle risorse SQL, seguire questa procedura<block ref="d0500a8d119256a2ca6775a9357c88fa" category="inline-link-rx"></block>.</block>
  <block id="ffbeca6b667809b446c63465c7ff671f" category="paragraph">Per eseguire il backup delle risorse Oracle, seguire questa procedura<block ref="c6b13e1956473c7b22893d8b12c1b8be" category="inline-link-rx"></block>.</block>
  <block id="498fdd311192093265ba745435fc1476" category="section-title">Implementare e configurare Veeam Backup Server</block>
  <block id="48e37aaf43e2a1010e9e267340ce923e" category="inline-link">Documentazione tecnica del centro di assistenza Veeam</block>
  <block id="9e67d6bed8c55a98c2cfe02531c07393" category="paragraph">Il software Veeam Backup &amp; Replication viene utilizzato nella soluzione per eseguire il backup delle macchine virtuali delle applicazioni e archiviare una copia dei backup in un bucket Amazon S3 utilizzando un repository di backup scale-out Veeeam (SOBR). Veeam viene implementato su un server Windows in questa soluzione. Per informazioni specifiche sull'implementazione di Veeam, vedere<block ref="43bd82bcfa6fc650951eb1c3021cf923" category="inline-link-rx"></block>.</block>
  <block id="a2af8a9311b9c3a74f6418a81bb700d2" category="example-title">Configurare il repository di backup scale-out Veeam</block>
  <block id="b61099b9ef1858547775741cc632226a" category="paragraph">Dopo aver implementato e ottenuto la licenza del software, è possibile creare un repository di backup scale-out (SOBR) come storage di destinazione per i processi di backup. È inoltre necessario includere un bucket S3 come backup dei dati delle macchine virtuali fuori sede per il disaster recovery.</block>
  <block id="b2fe763ad14c7947f74a8693fa06bf2b" category="paragraph">Prima di iniziare, consultare i seguenti prerequisiti.</block>
  <block id="e787194bd6ef5154135951b4ab7f0317" category="list-text">Creare una condivisione di file SMB sul sistema ONTAP on-premise come storage di destinazione per i backup.</block>
  <block id="1c2ed63d64d034cdd6fe30f769495f52" category="list-text">Crea un bucket Amazon S3 da includere nel SOBR. Si tratta di un repository per i backup fuori sede.</block>
  <block id="e349d3884df12b302e0d564f4cf3dec4" category="example-title">Aggiungere storage ONTAP a Veeam</block>
  <block id="3f71ccdf6fe8797ee5930ef4b5a0eaf1" category="paragraph">Innanzitutto, aggiungere il cluster di storage ONTAP e il relativo file system SMB/NFS come infrastruttura storage in Veeam.</block>
  <block id="dc14600d8d3627181cbe1757142b1c03" category="list-text">Aprire la console Veeam ed effettuare l'accesso. Accedere a Storage Infrastructure (infrastruttura storage) e selezionare Add Storage (Aggiungi storage).</block>
  <block id="a55b866e82b1226d8874e7d53e6e50a9" category="paragraph"><block ref="a55b866e82b1226d8874e7d53e6e50a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5bb1dc14738b469545970cd32668931f" category="list-text">Nella procedura guidata Aggiungi storage, selezionare NetApp come vendor dello storage, quindi selezionare Data ONTAP.</block>
  <block id="391d2bf94e1387196a435da4f4f0af41" category="list-text">Inserire l'indirizzo IP di gestione e selezionare la casella NAS Filer (Filer NAS). Fare clic su Avanti.</block>
  <block id="a8485af4e188b4009412f68ce18de31a" category="paragraph"><block ref="a8485af4e188b4009412f68ce18de31a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fab62b3f01af99a63f513f81f07f4c93" category="list-text">Aggiungere le credenziali per accedere al cluster ONTAP.</block>
  <block id="5e9ee6438a10072376c31e6014cef8c3" category="paragraph"><block ref="5e9ee6438a10072376c31e6014cef8c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f55d6a23cbf126acc9c5ca42a97be0fc" category="list-text">Nella pagina NAS Filer (Filer NAS), scegliere i protocolli desiderati per la scansione e selezionare Next (Avanti).</block>
  <block id="596ee09f3551be34368ba19aa36584cd" category="paragraph"><block ref="596ee09f3551be34368ba19aa36584cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="674fb2409a1f0a9e628bebcb470960cf" category="list-text">Completare le pagine Apply (Applica) e Summary (Riepilogo) della procedura guidata e fare clic su Finish (fine) per avviare il processo di rilevamento dello storage. Al termine della scansione, il cluster ONTAP viene aggiunto insieme ai filer NAS come risorse disponibili.</block>
  <block id="dc2bb995c316bc90c4d3a169bbb877d5" category="paragraph"><block ref="dc2bb995c316bc90c4d3a169bbb877d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f9b12801eaee10c32275f4ee61916aa" category="list-text">Creare un repository di backup utilizzando le condivisioni NAS appena rilevate. Da Backup Infrastructure (infrastruttura di backup), selezionare Backup Repository (repository di backup) e fare clic sulla voce di menu Add Repository (Aggiungi repository).</block>
  <block id="621999df528dc938edd5a395cf0df8f3" category="paragraph"><block ref="621999df528dc938edd5a395cf0df8f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="afc15a9e4c0cbbfa567d40414a9725a1" category="inline-link">Documentazione Veeam</block>
  <block id="218b99cee35d61ca3e9cb2d068673d9a" category="list-text">Seguire tutti i passaggi della procedura guidata nuovo repository di backup per creare il repository. Per informazioni dettagliate sulla creazione di repository di backup Veeam, vedere<block ref="3932357efba07e37ed76091ad3c0260c" category="inline-link-rx"></block>.</block>
  <block id="b56272bcb8aa2b6cb2998d01ed46d1f8" category="paragraph"><block ref="b56272bcb8aa2b6cb2998d01ed46d1f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6fdf6cc44242ceed0927b180d30e5e75" category="example-title">Aggiungi il bucket Amazon S3 come repository di backup</block>
  <block id="8c5c80325137d0f76fbe191272748ba6" category="paragraph">Il passaggio successivo consiste nell'aggiungere lo storage Amazon S3 come repository di backup.</block>
  <block id="6a1ed885510bb28a64f66f0870fbaa39" category="list-text">Accedere a infrastruttura di backup &gt; Repository di backup. Fare clic su Add Repository (Aggiungi repository).</block>
  <block id="bf510a56b5d84298de7541e645b836b7" category="paragraph"><block ref="bf510a56b5d84298de7541e645b836b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="021391ea3955cab71330e7a32f03333f" category="list-text">Nella procedura guidata Aggiungi repository di backup, selezionare Archivio oggetti, quindi Amazon S3. Viene avviata la procedura guidata nuovo archivio oggetti.</block>
  <block id="c1f1ad1062498b5eeb9d31293b71343c" category="paragraph"><block ref="c1f1ad1062498b5eeb9d31293b71343c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d3a3eb593a619e4becab9e45b8f46652" category="list-text">Fornire un nome per il repository di storage a oggetti e fare clic su Next (Avanti).</block>
  <block id="97f3c4606f2c2ebb0ffadd0616b76446" category="list-text">Nella sezione successiva, fornire le credenziali. Sono necessari una chiave di accesso AWS e una chiave segreta.</block>
  <block id="e561e4c61aaefae45d0344b4ce87f23b" category="paragraph"><block ref="e561e4c61aaefae45d0344b4ce87f23b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="157669cd4d5a68c9ab9f3537a9e0ea33" category="list-text">Una volta caricata la configurazione Amazon, scegliere il data center, il bucket e la cartella e fare clic su Apply (Applica). Infine, fare clic su fine per chiudere la procedura guidata.</block>
  <block id="2e9f45d4556ef13d4724b6f93eea5fd3" category="example-title">Creare un repository di backup scale-out</block>
  <block id="7d8f14e05d872984577255cdeb1f14ec" category="paragraph">Ora che abbiamo aggiunto i nostri repository di storage a Veeam, possiamo creare il SOBR per tierare automaticamente le copie di backup nel nostro storage a oggetti Amazon S3 fuori sede per il disaster recovery.</block>
  <block id="328e03460d532c3507b2a6ba6ce53438" category="list-text">Da Backup Infrastructure (infrastruttura di backup), selezionare Scale-out Repository (repository scale-out), quindi fare clic sulla voce di menu Add Scale-out Repository (Aggiungi repository scale-out).</block>
  <block id="3ffac3b915968cb75860eac6dcb2255b" category="paragraph"><block ref="3ffac3b915968cb75860eac6dcb2255b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="582671a9090106ace80b09bb160558c6" category="list-text">Nel nuovo repository di backup scale-out, immettere un nome per il SOBR e fare clic su Avanti.</block>
  <block id="8f7df3cc6ed6758328582e4972dcb532" category="list-text">Per il livello di performance, scegliere il repository di backup che contiene la condivisione SMB che risiede nel cluster ONTAP locale.</block>
  <block id="2c4b66b86991d603fc9db639a47179f8" category="paragraph"><block ref="2c4b66b86991d603fc9db639a47179f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7362749638566881b7b5f8fe545c64e8" category="list-text">Per la policy di posizionamento, scegli la localizzazione dei dati o le performance in base ai tuoi requisiti. Selezionare Avanti.</block>
  <block id="2d1b39bdffbca5df6978176960bb0148" category="list-text">Per il livello di capacità estendiamo il SOBR con lo storage a oggetti Amazon S3. Ai fini del disaster recovery, selezionare Copy Backup to Object Storage (Copia backup su storage a oggetti) non appena vengono creati per garantire la consegna tempestiva dei backup secondari.</block>
  <block id="3a54badf400b7e061484dbadf3a19b19" category="paragraph"><block ref="3a54badf400b7e061484dbadf3a19b19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="248e4221544eda567f1dd23b587cec68" category="list-text">Infine, selezionare Apply (Applica) e Finish (fine) per finalizzare la creazione del SOBR.</block>
  <block id="97f8173a9f8ac774dbbb04ad209a46ee" category="example-title">Creare i processi di repository di backup scale-out</block>
  <block id="d7b3c8996a5cc044c6c1221d000a9d9b" category="inline-link">Documentazione tecnica del Centro assistenza Veeam</block>
  <block id="2b6483678eaaf63094c195aa8a37e401" category="paragraph">L'ultima fase della configurazione di Veeam consiste nella creazione di processi di backup utilizzando il SOBR appena creato come destinazione di backup. La creazione di processi di backup è una parte normale del repertorio di qualsiasi amministratore dello storage e non viene descritta la procedura dettagliata. Per informazioni più complete sulla creazione di processi di backup in Veeam, vedere<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>.</block>
  <block id="ee51a40e9d2538b4e33b441d66869c24" category="section-title">Configurazione e tool di backup del cloud</block>
  <block id="f201deaeba7cc565253f52d974008543" category="paragraph">Per eseguire un failover delle macchine virtuali applicative e dei volumi di database sui servizi di volume cloud VMware in esecuzione in AWS, è necessario installare e configurare un'istanza in esecuzione del server SnapCenter e del server di backup e replica Veeeam. Una volta completato il failover, è necessario configurare questi strumenti per riprendere le normali operazioni di backup fino a quando non viene pianificato ed eseguito un failback al data center on-premise.</block>
  <block id="a514f4da2fec40b52d89613d7b3854fa" category="example-title">Implementare il server Windows SnapCenter secondario</block>
  <block id="dba3e8475ef38dcd147447c5730c2f7c" category="paragraph">Il server SnapCenter viene implementato nell'SDDC cloud VMware o installato su un'istanza EC2 che risiede in un VPC con connettività di rete all'ambiente cloud VMware.</block>
  <block id="257b2c5a413bf4e187ebd89c8a363827" category="inline-link">Centro di documentazione NetApp</block>
  <block id="1a297f32b70010f208d00a4f58855fec" category="paragraph">Il software SnapCenter è disponibile sul sito di supporto NetApp e può essere installato su sistemi Microsoft Windows che risiedono in un dominio o in un gruppo di lavoro. Una guida dettagliata alla pianificazione e le istruzioni di installazione sono disponibili all'indirizzo<block ref="92e6fa322f689d7da93690560d0b41bd" category="inline-link-rx"></block>.</block>
  <block id="4adffd967d9bbc0f71287e67a568e0ae" category="paragraph">Il software SnapCenter è disponibile all'indirizzo<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>.</block>
  <block id="224efa116a105cfd586d82f09e7cd1fe" category="example-title">Configurare il server secondario Windows SnapCenter</block>
  <block id="9ec64430f94c7b2f3824857182b8ff9d" category="paragraph">Per eseguire un ripristino dei dati applicativi mirrorati in FSX ONTAP, è necessario prima eseguire un ripristino completo del database SnapCenter on-premise. Una volta completato questo processo, la comunicazione con le macchine virtuali viene ristabilita e i backup delle applicazioni possono ora riprendere utilizzando FSX ONTAP come storage primario.</block>
  <block id="b502974234450ceabf2344f2a3e45f7a" category="paragraph">A tale scopo, è necessario completare i seguenti elementi sul server SnapCenter:</block>
  <block id="13d56fa22f861d817f01e34bd0dff18d" category="list-text">Configurare il nome del computer in modo che sia identico al server SnapCenter on-premise originale.</block>
  <block id="87da734902f9a20ba518a732df6228fc" category="list-text">Configurare il networking per comunicare con VMware Cloud e l'istanza di FSX ONTAP.</block>
  <block id="7f2fdcaa4d368c36731db2bdf5eb79a9" category="list-text">Completare la procedura per ripristinare il database SnapCenter.</block>
  <block id="b9f6e6c037c51c372d51f5f4254d76cc" category="list-text">Verificare che SnapCenter sia in modalità di disaster recovery per assicurarsi che FSX sia ora lo storage primario per i backup.</block>
  <block id="b8864a7697abc4d58d337a7803f7ca8e" category="list-text">Verificare che la comunicazione con le macchine virtuali ripristinate sia stata ristabilita.</block>
  <block id="6b9d280aee667ad2407fdb311dc034cb" category="inline-link-macro">Processo di ripristino del database SnapCenter</block>
  <block id="4757e8da6d3b5465a3ae91d8390db6d9" category="paragraph">Per ulteriori informazioni sul completamento di questi passaggi, vedere la sezione a. <block ref="fe5a34b461345b6f910f9d5fd86fde40" category="inline-link-macro-rx"></block>.</block>
  <block id="cf5c2d1e726e35ab57a75901cde43919" category="example-title">Implementare il server di replica Veeam Backup &amp;amp; secondario</block>
  <block id="b827704a3bb22b3992173e0581a1c28b" category="paragraph">È possibile installare il server Veeam Backup &amp; Replication su un server Windows in VMware Cloud su AWS o su un'istanza EC2. Per informazioni dettagliate sull'implementazione, vedere<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>.</block>
  <block id="2b0e654aa884c8c50887b2eff59bc68f" category="example-title">Configurare il server di replica di Veeam Backup &amp;amp; secondario</block>
  <block id="e271ecc9b2a2050b58d0914d62a2325b" category="paragraph">Per eseguire un ripristino delle macchine virtuali di cui è stato eseguito il backup sullo storage Amazon S3, è necessario installare Veeam Server su un server Windows e configurarlo per comunicare con VMware Cloud, FSX ONTAP e il bucket S3 che contiene il repository di backup originale. Deve inoltre disporre di un nuovo repository di backup configurato su FSX ONTAP per eseguire nuovi backup delle macchine virtuali dopo il ripristino.</block>
  <block id="d569da58bc917eb906ada72f76bf1030" category="paragraph">Per eseguire questo processo, è necessario completare i seguenti elementi:</block>
  <block id="6443544e723bdb5a8e0b2e300ce4e821" category="list-text">Configurare il networking per comunicare con VMware Cloud, FSX ONTAP e il bucket S3 contenente il repository di backup originale.</block>
  <block id="d19ea991ccb7ded9582c07fa062fb3b4" category="list-text">Configura una condivisione SMB su FSX ONTAP per diventare un nuovo repository di backup.</block>
  <block id="adf79b820407599132e907adb994746d" category="list-text">Montare il bucket S3 originale utilizzato come parte del repository di backup scale-out on-premise.</block>
  <block id="a706ef66660617fcf4a5aeb2e6f6d76b" category="list-text">Dopo il ripristino della macchina virtuale, stabilire nuovi processi di backup per proteggere le macchine virtuali SQL e Oracle.</block>
  <block id="28850f35c95cf12d5e28a35c2fdd8e5d" category="inline-link-macro">Ripristinare le macchine virtuali dell'applicazione con il ripristino completo di Veeam</block>
  <block id="fa907e97b7f9d454ad88521e57137cfe" category="paragraph">Per ulteriori informazioni sul ripristino delle macchine virtuali utilizzando Veeam, vedere la sezione <block ref="00a6103995562d7a2009f890514665b7" category="inline-link-macro-rx"></block>.</block>
  <block id="997d17d93cccb6709985c79ccc870db0" category="section-title">Backup del database SnapCenter per il disaster recovery</block>
  <block id="9cb03f5cfb57a7f655c8a28ca64ae0d1" category="paragraph">SnapCenter consente il backup e il ripristino del database MySQL sottostante e dei dati di configurazione allo scopo di ripristinare il server SnapCenter in caso di disastro. Per la nostra soluzione, abbiamo recuperato il database e la configurazione di SnapCenter su un'istanza di AWS EC2 che risiede nel nostro VPC. Per ulteriori informazioni su questo passaggio, vedere<block ref="85e9a4a54f289ebdfa6c4169fb097d15" category="inline-link-rx"></block>.</block>
  <block id="46137d274838eaef40c110eac160dabc" category="example-title">Prerequisiti per il backup di SnapCenter</block>
  <block id="2fe071c4476effcd542a95a182832104" category="paragraph">Per il backup di SnapCenter sono necessari i seguenti prerequisiti:</block>
  <block id="be2b68df1cb3db2a8f1393a8c89a5c30" category="list-text">Un volume e una condivisione SMB creati sul sistema ONTAP on-premise per individuare i file di database e di configurazione di cui è stato eseguito il backup.</block>
  <block id="1a9ee88991730f920252a1445a467c77" category="list-text">Una relazione SnapMirror tra il sistema ONTAP on-premise e FSX o CVO nell'account AWS. Questa relazione viene utilizzata per trasportare lo snapshot contenente il database SnapCenter di cui è stato eseguito il backup e i file di configurazione.</block>
  <block id="3c0e70fa217603c0388de21f978923f3" category="list-text">Windows Server installato nell'account cloud, su un'istanza EC2 o su una macchina virtuale nel VMware Cloud SDDC.</block>
  <block id="328228524f87469e005c8944ad925402" category="list-text">SnapCenter installato sull'istanza di Windows EC2 o sulla macchina virtuale in VMware Cloud.</block>
  <block id="0038f6b75b40b9c37893544119ad7ca4" category="example-title">Riepilogo del processo di backup e ripristino di SnapCenter</block>
  <block id="f4644dc8d01e527218cd1fc0daa6af40" category="list-text">Creare un volume sul sistema ONTAP on-premise per ospitare i file di configurazione e di database di backup.</block>
  <block id="c4232930a0fc8d0f9a5e1a16db36a816" category="list-text">Impostare una relazione SnapMirror tra on-premise e FSX/CVO.</block>
  <block id="3e1461fe483fb58c7a6642074cb71d8d" category="list-text">Montare la condivisione SMB.</block>
  <block id="dd5b017c2cafc1394e2d7ab7081652e3" category="list-text">Recuperare il token di autorizzazione Swagger per eseguire le attività API.</block>
  <block id="51263d7f64b29b2b3bd6730068e64a27" category="list-text">Avviare il processo di ripristino del db.</block>
  <block id="23011a36184705e18919c3e5560fd514" category="list-text">Utilizzare l'utility xcopy per copiare la directory locale del file db e config nella condivisione SMB.</block>
  <block id="b84dd176bda6a6d30c5cb8901a8bf5b1" category="list-text">Su FSX, creare un clone del volume ONTAP (copiato tramite SnapMirror da on-premise).</block>
  <block id="1a3f92b9c5623f19d294ef2907d98cc8" category="list-text">Montare la condivisione SMB da FSX a EC2/VMware Cloud.</block>
  <block id="87d37b3dfd2b98df04243247ebff4325" category="list-text">Copiare la directory di ripristino dalla condivisione SMB in una directory locale.</block>
  <block id="fd516b8b37d528453c538c9022d6d9db" category="list-text">Eseguire il processo di ripristino di SQL Server da Swagger.</block>
  <block id="63c6890e4065bde44f84394d274e05db" category="example-title">Eseguire il backup del database e della configurazione di SnapCenter</block>
  <block id="493aa18049179f21c66cc95e36c19670" category="paragraph">SnapCenter fornisce un'interfaccia client Web per l'esecuzione dei comandi API REST. Per informazioni sull'accesso alle API REST tramite Swagger, consultare la documentazione di SnapCenter all'indirizzo<block ref="2a9068db8cebf7672f374b2eb0a0c5ec" category="inline-link-rx"></block>.</block>
  <block id="911dd02ad9a62d89e83d996753811c7b" category="example-title">Accedere a Swagger e ottenere il token di autorizzazione</block>
  <block id="820336a66e164f408946dd8235833c07" category="paragraph">Una volta aperta la pagina Swagger, è necessario recuperare un token di autorizzazione per avviare il processo di ripristino del database.</block>
  <block id="99899958b071bcb677dc5a5b24f1b2a3" category="list-text">Accedere alla pagina Web dell'API di swagger SnapCenter all'indirizzo _/https://&lt;SnapCenter Server IP&gt;:8146/swagger/_.</block>
  <block id="20f069ff72fb03614b867af722c7c40b" category="paragraph"><block ref="20f069ff72fb03614b867af722c7c40b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5ad3b9c1075f899242a74f969cbb12fa" category="list-text">Espandere la sezione Auth e fare clic su Provalo.</block>
  <block id="5ffa75198edfa553c162f3b9945a23a0" category="paragraph"><block ref="5ffa75198edfa553c162f3b9945a23a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="41402cfc6490d3bf582b8a14ff8bfcbe" category="list-text">Nell'area UserOperationContext, inserire le credenziali e il ruolo SnapCenter e fare clic su Esegui.</block>
  <block id="2e1aa1ca38ffa5e45db5da3276238eac" category="paragraph"><block ref="2e1aa1ca38ffa5e45db5da3276238eac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18e649ac855810eb5b8a774b3fab5f5c" category="list-text">Nel corpo di risposta riportato di seguito, è possibile visualizzare il token. Copiare il testo del token per l'autenticazione durante l'esecuzione del processo di backup.</block>
  <block id="32d5d8e51cafb2b4d387df356fe41955" category="paragraph"><block ref="32d5d8e51cafb2b4d387df356fe41955" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a1a34831e3e917e934e09eb9402b4d6" category="example-title">Eseguire un backup del database SnapCenter</block>
  <block id="3d8b8b9e239f00e8fbddb0437a5c5659" category="paragraph">Quindi, accedere all'area Disaster Recovery della pagina Swagger per avviare il processo di backup di SnapCenter.</block>
  <block id="5fd8196e8aa6d444acf7a65f639a6085" category="list-text">Espandere l'area Disaster Recovery facendo clic su di essa.</block>
  <block id="7ec34046162f53040f7ca7c8a78c4b17" category="paragraph"><block ref="7ec34046162f53040f7ca7c8a78c4b17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14245d6803dae3fc2cab0fe1fd18565e" category="list-text">Espandere<block ref="ff68c70c197c21bcd2eda286f1ff14b6" prefix=" " category="inline-code"></block> E fare clic su Provalo.</block>
  <block id="b5f8e4e588ebd761591d02cb02f2a5dd" category="paragraph"><block ref="b5f8e4e588ebd761591d02cb02f2a5dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aad454707845382aef2a040acc30177a" category="list-text">Nella sezione SmDRBackupRequest, aggiungere il percorso di destinazione locale corretto e selezionare Execute (Esegui) per avviare il backup del database e della configurazione di SnapCenter.</block>
  <block id="949b4a3f3887b0d48d721acc506fb82e" category="admonition">Il processo di backup non consente il backup diretto su una condivisione file NFS o CIFS.</block>
  <block id="ef97a1ec7f6c4c7d84f053938ce48398" category="paragraph"><block ref="ef97a1ec7f6c4c7d84f053938ce48398" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f638b2ae24161dbfa69705afbf177bd" category="example-title">Monitorare il processo di backup da SnapCenter</block>
  <block id="03322e4ba2c5a628edfa27eb5a52741b" category="paragraph">Accedere a SnapCenter per esaminare i file di registro quando si avvia il processo di ripristino del database. Nella sezione Monitor, è possibile visualizzare i dettagli del backup di disaster recovery del server SnapCenter.</block>
  <block id="82c39eed34769992987a93ed6b12a97f" category="paragraph"><block ref="82c39eed34769992987a93ed6b12a97f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac753614a3d47f00caddc06fd2dc281f" category="example-title">Utilizzare l'utility XCOPY per copiare il file di backup del database nella condivisione SMB</block>
  <block id="d2a0be1c4b7f47c09b612fb78a28adee" category="paragraph">Quindi, spostare il backup dal disco locale sul server SnapCenter alla condivisione CIFS utilizzata per copiare i dati nella posizione secondaria situata sull'istanza FSX in AWS. Utilizzare xcopy con opzioni specifiche che conservano i permessi dei file.</block>
  <block id="fa13c8e8caa807a78a4301f1cfa0ec2f" category="paragraph">Aprire un prompt dei comandi come Amministratore. Dal prompt dei comandi, immettere i seguenti comandi:</block>
  <block id="7388404ef116c3ff812bfd290b094d9e" category="section-title">Failover</block>
  <block id="03c450647cafbb7294b1d6fef9f2476f" category="example-title">Il disastro si verifica nel sito primario</block>
  <block id="d48ec23d0c00af2c45aa4b1c24b412d8" category="paragraph">In caso di disastro che si verifica nel data center primario on-premise, il nostro scenario include il failover su un sito secondario che risiede nell'infrastruttura Amazon Web Services utilizzando VMware Cloud su AWS. Supponiamo che le macchine virtuali e il nostro cluster ONTAP on-premise non siano più accessibili. Inoltre, le macchine virtuali SnapCenter e Veeam non sono più accessibili e devono essere ricostruite nel nostro sito secondario.</block>
  <block id="ff36edd2e7e49fd0a40827688d2f4d8c" category="paragraph">In questa sezione viene descritto il failover della nostra infrastruttura nel cloud e vengono trattati i seguenti argomenti:</block>
  <block id="9555d80191893a5b671187e1a859f379" category="list-text">Ripristino del database SnapCenter. Una volta stabilito un nuovo server SnapCenter, ripristinare il database MySQL e i file di configurazione e attivare la modalità di disaster recovery per consentire allo storage FSX secondario di diventare il dispositivo di storage primario.</block>
  <block id="2f2ee1d320a4d17fae8f4228f0a0c17a" category="list-text">Ripristinare le macchine virtuali dell'applicazione utilizzando Veeam Backup &amp; Replication. Collegare lo storage S3 che contiene i backup delle macchine virtuali, importare i backup e ripristinarli su VMware Cloud su AWS.</block>
  <block id="8509dc3cb04f91e9c6eb62971df36219" category="list-text">Ripristinare i dati dell'applicazione SQL Server utilizzando SnapCenter.</block>
  <block id="81e920a3cfad3020139d281a7be1093a" category="list-text">Ripristinare i dati dell'applicazione Oracle utilizzando SnapCenter.</block>
  <block id="7c3080588178d0f5908a96d9e20be883" category="example-title">Processo di ripristino del database SnapCenter</block>
  <block id="86c580a0ed766eb38c0ef43f08d425e5" category="paragraph">SnapCenter supporta scenari di disaster recovery consentendo il backup e il ripristino del database MySQL e dei file di configurazione. Ciò consente a un amministratore di mantenere backup regolari del database SnapCenter nel data center on-premise e di ripristinare successivamente tale database in un database SnapCenter secondario.</block>
  <block id="ee1f8cb839e16951e7004e4047603101" category="paragraph">Per accedere ai file di backup di SnapCenter sul server SnapCenter remoto, attenersi alla seguente procedura:</block>
  <block id="0b5c65b05530328f42d8b65f68657302" category="list-text">Interrompere la relazione di SnapMirror dal cluster FSX, che rende il volume in lettura/scrittura.</block>
  <block id="dbfff075901e62d26ef1f316380d01f7" category="list-text">Creare un server CIFS (se necessario) e una condivisione CIFS che punta al percorso di giunzione del volume clonato.</block>
  <block id="26b0d9d510f38125c4de3a7b68569b29" category="list-text">Utilizzare xcopy per copiare i file di backup in una directory locale sul sistema SnapCenter secondario.</block>
  <block id="fa0138f778767381d2b0af9bdabad76e" category="list-text">Installare SnapCenter v4.6.</block>
  <block id="736c8557bca1ad901b82efb5e946a527" category="list-text">Assicurarsi che il server SnapCenter abbia lo stesso nome FQDN del server originale. Questo è necessario per il ripristino del db.</block>
  <block id="6f77488ce3ed6db6422cddaa1e4cbf8f" category="paragraph">Per avviare il processo di ripristino, attenersi alla seguente procedura:</block>
  <block id="7220866a3d1d3ba6c1aef39d02d64b1f" category="list-text">Accedere alla pagina Web API Swagger per il server SnapCenter secondario e seguire le istruzioni precedenti per ottenere un token di autorizzazione.</block>
  <block id="a5214e49691510795c98aad40874caa1" category="list-text">Accedere alla sezione Disaster Recovery della pagina Swagger e selezionare<block ref="533e3565b4ab97ee497d4500afcfa0ca" prefix=" " category="inline-code"></block>E fare clic su Provalo.</block>
  <block id="3c235173c5db1037212eff5e3a152a26" category="paragraph"><block ref="3c235173c5db1037212eff5e3a152a26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d76d7bbb789675126fd1e9a0bf929635" category="list-text">Incollare il token di autorizzazione e, nella sezione SmDRResterRequest, incollare il nome del backup e la directory locale sul server SnapCenter secondario.</block>
  <block id="34938ae261d31ae76af2e4369a2c8b0a" category="paragraph"><block ref="34938ae261d31ae76af2e4369a2c8b0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4579e653c0e46ed15c466f496b60b0f3" category="list-text">Selezionare il pulsante Execute (Esegui) per avviare il processo di ripristino.</block>
  <block id="fcbb767c97ce18f6b82f09bf8ea9c993" category="list-text">Da SnapCenter, accedere alla sezione Monitor per visualizzare l'avanzamento del processo di ripristino.</block>
  <block id="8fa0520efd67da15041467d3126133a7" category="paragraph"><block ref="8fa0520efd67da15041467d3126133a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d67615193bee26cd99be6b7ea889f065" category="paragraph"><block ref="d67615193bee26cd99be6b7ea889f065" category="inline-image-macro-rx" type="image"></block></block>
  <block id="49b4fb23e31b4cd2d12434ce03b24134" category="list-text">Per abilitare i ripristini di SQL Server dallo storage secondario, è necessario attivare la modalità di disaster recovery nel database SnapCenter. Questa operazione viene eseguita come operazione separata e avviata sulla pagina Web API di Swagger.</block>
  <block id="35afa1a915c7752e139ef7b0362596a6" category="list-text">Accedere alla sezione Disaster Recovery e fare clic su<block ref="6f4ce9a3fde10d5d540991396641c75c" prefix=" " category="inline-code"></block>.</block>
  <block id="7633ff4043449878afbd5ca925faa5b1" category="list-text">Incollare il token di autorizzazione dell'utente.</block>
  <block id="5fb3d7404a8cc43eb5e120b4e22fe16d" category="list-text">Nella sezione SmSetDisasterRecoverySettingsRequest, modificare<block ref="b7332a241d968e08b968a292c8d519aa" prefix=" " category="inline-code"></block> a.<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>.</block>
  <block id="e7470af265e05d2efa8863c259541c2b" category="list-text">Fare clic su Execute (Esegui) per attivare la modalità di disaster recovery per SQL Server.</block>
  <block id="8579e283f02173e29df7090294128589" category="paragraph"><block ref="8579e283f02173e29df7090294128589" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc4a08ff9e7fd1ec468bc55c7ba9df45" category="admonition">Vedere i commenti relativi alle procedure aggiuntive.</block>
  <block id="9ba3ddc84b2f59fd2a102309365db81a" category="section-title">Ripristinare le macchine virtuali applicative con il ripristino completo di Veeam</block>
  <block id="36dc3b29e336105b87846d5917f36466" category="example-title">Creare un repository di backup e importare i backup da S3</block>
  <block id="bfa510d8cc1cb8902740f538c9871cd5" category="paragraph">Dal server Veeam secondario, importare i backup dallo storage S3 e ripristinare le macchine virtuali SQL Server e Oracle nel cluster VMware Cloud.</block>
  <block id="e2f3927605d5be5f9e2924c7578d06ab" category="paragraph">Per importare i backup dall'oggetto S3 che faceva parte del repository di backup scale-out on-premise, attenersi alla seguente procedura:</block>
  <block id="04e06ef7f33197a158ddc19d53c0d1a5" category="list-text">Accedere a Backup Repository e fare clic su Add Repository (Aggiungi repository) nel menu in alto per avviare la procedura guidata Add Backup Repository (Aggiungi repository di backup). Nella prima pagina della procedura guidata, selezionare Object Storage come tipo di repository di backup.</block>
  <block id="6206d8a7c31f00a44ec41ebae87e8b6b" category="paragraph"><block ref="6206d8a7c31f00a44ec41ebae87e8b6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4fcfafe3d4baedadc9910b99baf527a" category="list-text">Selezionare Amazon S3 come tipo di storage a oggetti.</block>
  <block id="293aed632d96ade5bfef832bcdc2cd1e" category="paragraph"><block ref="293aed632d96ade5bfef832bcdc2cd1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="698ebee929c01fad4c318876313789ab" category="list-text">Dall'elenco di Amazon Cloud Storage Services, selezionare Amazon S3.</block>
  <block id="12cfad41ab613d7744d12d07d4a556d4" category="paragraph"><block ref="12cfad41ab613d7744d12d07d4a556d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2639f2cf7409eb24ed59c46794f26c33" category="list-text">Selezionare le credenziali preinserite dall'elenco a discesa o aggiungere una nuova credenziale per accedere alla risorsa di storage cloud. Fare clic su Next (Avanti) per continuare.</block>
  <block id="ca271cf67d4c973e828e31689285727f" category="paragraph"><block ref="ca271cf67d4c973e828e31689285727f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d158a2a4f2b2c9b52c009bfbd87668a" category="list-text">Nella pagina bucket, inserire il data center, il bucket, la cartella e le opzioni desiderate. Fare clic su Applica.</block>
  <block id="cf2158b0a3f58d891bcbc6031fde92d4" category="paragraph"><block ref="cf2158b0a3f58d891bcbc6031fde92d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5adae514074dc7c746819968e035e2a0" category="list-text">Infine, selezionare fine per completare il processo e aggiungere il repository.</block>
  <block id="076951b7756435f95654310ef960f866" category="example-title">Importare backup dallo storage a oggetti S3</block>
  <block id="397f99a04387aed7bca366a20084083f" category="paragraph">Per importare i backup dal repository S3 aggiunto nella sezione precedente, attenersi alla seguente procedura.</block>
  <block id="6add4097706ff1ee04793b80b99c3980" category="list-text">Dal repository di backup S3, selezionare Importa backup per avviare la procedura guidata di importazione dei backup.</block>
  <block id="d2e0dedfd0a67b45116f5c02f41dfad6" category="paragraph"><block ref="d2e0dedfd0a67b45116f5c02f41dfad6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f08dd57757030d81cfcdd38f9c443e05" category="list-text">Dopo aver creato i record del database per l'importazione, selezionare Avanti, quindi fine nella schermata di riepilogo per avviare il processo di importazione.</block>
  <block id="dee3665bb9cd000955be1a118818554f" category="paragraph"><block ref="dee3665bb9cd000955be1a118818554f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4afd5477c1ce1473a255dee8ce524184" category="list-text">Una volta completata l'importazione, è possibile ripristinare le macchine virtuali nel cluster VMware Cloud.</block>
  <block id="8f2cd7b75623b2421c1eaadd379ca431" category="paragraph"><block ref="8f2cd7b75623b2421c1eaadd379ca431" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73fee194f5e4e8ac33d750244fe7ebd5" category="example-title">Ripristinare le macchine virtuali applicative con il ripristino completo di Veeam su VMware Cloud</block>
  <block id="ec223385ec31537dfd3adc4f3f97735d" category="paragraph">Per ripristinare le macchine virtuali SQL e Oracle su VMware Cloud su cluster/dominio del carico di lavoro AWS, completare la seguente procedura.</block>
  <block id="9085bbecf522e8f0cf0f7d5480dd7cd9" category="list-text">Dalla home page di Veeam, selezionare lo storage a oggetti contenente i backup importati, selezionare le macchine virtuali da ripristinare, quindi fare clic con il pulsante destro del mouse e selezionare Restore entire VM (Ripristina intera macchina virtuale).</block>
  <block id="5320e29249c22b00240fc3df301d60a6" category="paragraph"><block ref="5320e29249c22b00240fc3df301d60a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d53e507da99665f0cd76090f0c8b932" category="list-text">Nella prima pagina della procedura guidata di ripristino completo della macchina virtuale, modificare le macchine virtuali per il backup, se necessario, e selezionare Avanti.</block>
  <block id="118ea730c6c794b12c6da0062216053b" category="paragraph"><block ref="118ea730c6c794b12c6da0062216053b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93e4b62efeb3d091b37047e066e45da4" category="list-text">Nella pagina Restore Mode (modalità ripristino), selezionare Restore to a New Location (Ripristina in una nuova posizione) o with different Settings (con impostazioni diverse).</block>
  <block id="53ddd9505ead460715da91ab5ae479ae" category="paragraph"><block ref="53ddd9505ead460715da91ab5ae479ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faca70e3cfbddf72933acf5dcbedf4ff" category="list-text">Nella pagina host, selezionare l'host o il cluster ESXi di destinazione su cui ripristinare la macchina virtuale.</block>
  <block id="5c468616bb48a8d3a72e2b3f20932126" category="paragraph"><block ref="5c468616bb48a8d3a72e2b3f20932126" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ee5d8dddaf8720bc49f23dc8e19f11b" category="list-text">Nella pagina datastore, selezionare la posizione del datastore di destinazione per i file di configurazione e il disco rigido.</block>
  <block id="ae5ebb3a87f25b2bf09c963a4029e53a" category="paragraph"><block ref="ae5ebb3a87f25b2bf09c963a4029e53a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48d9c25678124f335015d969c2c7645f" category="list-text">Nella pagina Network (rete), mappare le reti originali sulla macchina virtuale alle reti nella nuova posizione di destinazione.</block>
  <block id="b33233fb74ffe76bde21729b21fde02d" category="paragraph"><block ref="b33233fb74ffe76bde21729b21fde02d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3d7fc3c9f85e5663d3361a9e999487c" category="paragraph"><block ref="b3d7fc3c9f85e5663d3361a9e999487c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="511bf18240f9f57b5658a22974a640f0" category="list-text">Selezionare se eseguire la scansione della macchina virtuale ripristinata alla ricerca di malware, esaminare la pagina di riepilogo e fare clic su Finish (fine) per avviare il ripristino.</block>
  <block id="b7dd764025f54c4b3bccf4f05424bf77" category="section-title">Ripristinare i dati dell'applicazione SQL Server</block>
  <block id="95f316bb0a092035f960a46cc12705d3" category="paragraph">Il seguente processo fornisce istruzioni su come ripristinare un SQL Server in VMware Cloud Services in AWS in caso di disastro che rende il sito on-premise inutilizzabile.</block>
  <block id="eb7b93b4aadbfaf4b78c0c4bfe125171" category="paragraph">Si presuppone che i seguenti prerequisiti siano completi per continuare con le fasi di ripristino:</block>
  <block id="aca50891060f7ebe7be1192b4a8b78ad" category="list-text">La macchina virtuale Windows Server è stata ripristinata nel VMware Cloud SDDC utilizzando il ripristino completo di Veeam.</block>
  <block id="9731e8839876f65368eab4ef1eecdc20" category="inline-link-macro">Riepilogo del processo di backup e ripristino di SnapCenter.</block>
  <block id="6afeb7a829e309830236eb7d13dafb4b" category="list-text">È stato stabilito un server SnapCenter secondario e il ripristino e la configurazione del database SnapCenter sono stati completati seguendo la procedura illustrata nella sezione <block ref="c05666153a222d3eb881a4a76532fde4" category="inline-link-macro-rx"></block></block>
  <block id="565a76f57020cb4db728d0a24384a0d9" category="example-title">VM: Configurazione post-ripristino per SQL Server VM</block>
  <block id="eface2367b3de31eee3102f62de9295d" category="paragraph">Una volta completato il ripristino della macchina virtuale, è necessario configurare la rete e altri elementi in preparazione per il rispristino della macchina virtuale host in SnapCenter.</block>
  <block id="0a64ec0b8b14816ed47650a0096fd3b3" category="list-text">Assegnare nuovi indirizzi IP per Management e iSCSI o NFS.</block>
  <block id="8ceacb8e6c12d270f190550e317ed5be" category="list-text">Unire l'host al dominio Windows.</block>
  <block id="612dbb7fb61a87afcf471d797448e487" category="list-text">Aggiungere i nomi host al DNS o al file hosts sul server SnapCenter.</block>
  <block id="21b91bc158a5a6579966133ece84f927" category="admonition">Se il plug-in SnapCenter è stato distribuito utilizzando credenziali di dominio diverse da quelle del dominio corrente, è necessario modificare l'account di accesso per il plug-in per il servizio Windows sulla macchina virtuale di SQL Server. Dopo aver modificato l'account di accesso, riavviare i servizi SMCore, Plug-in per Windows e Plug-in per SnapCenter Server.</block>
  <block id="0634c3a099feec2a74ff9c0751719ed6" category="admonition">Per riscoprire automaticamente le macchine virtuali ripristinate in SnapCenter, l'FQDN deve essere identico alla macchina virtuale originariamente aggiunta a SnapCenter on-premise.</block>
  <block id="0d4bede73841f93a92c80d25b0194d1e" category="example-title">Configurare lo storage FSX per il ripristino di SQL Server</block>
  <block id="1a87030fb5d5a31f7bcfdfa68ade9691" category="paragraph">Per eseguire il processo di ripristino del disaster recovery per una macchina virtuale SQL Server, è necessario interrompere la relazione SnapMirror esistente dal cluster FSX e concedere l'accesso al volume. A tale scopo, attenersi alla seguente procedura.</block>
  <block id="4c9e09e4807ffb0a4456b29e6f9a4281" category="list-text">Per interrompere la relazione SnapMirror esistente per il database SQL Server e i volumi di log, eseguire il seguente comando dalla CLI FSX:</block>
  <block id="3d20282913974593577c784c3192e510" category="list-text">Concedere l'accesso al LUN creando un gruppo di iniziatori contenente l'IQN iSCSI della macchina virtuale Windows di SQL Server:</block>
  <block id="d287a88d877191e5695e6e46cde801a3" category="list-text">Infine, mappare le LUN al gruppo iniziatore appena creato:</block>
  <block id="e47557c42d0af2df20a15a19f84795ee" category="list-text">Per trovare il nome del percorso, eseguire<block ref="b8fdaa53ba08988f3b422c1226f85a2a" prefix=" " category="inline-code"></block> comando.</block>
  <block id="c38f08ac05515c2b594fc836b22181e0" category="example-title">Configurare la macchina virtuale Windows per l'accesso iSCSI e rilevare i file system</block>
  <block id="39eb9c3b6c8eb2106dcb06edfdbb6f65" category="list-text">Da SQL Server VM, configurare l'adattatore di rete iSCSI per comunicare sul gruppo di porte VMware stabilito con la connettività alle interfacce di destinazione iSCSI sull'istanza FSX.</block>
  <block id="cf8c6b6b8c54ec784d05b5f092751a4d" category="list-text">Aprire l'utility iSCSI Initiator Properties (Proprietà iSCSI Initiator) e cancellare le vecchie impostazioni di connettività nelle schede Discovery (rilevamento), Favorite Targets (destinazioni preferite) e Targets (destinazioni).</block>
  <block id="1a2e1a79fa495e5f511838af9609be4f" category="list-text">Individuare gli indirizzi IP per l'accesso all'interfaccia logica iSCSI sull'istanza/cluster FSX. Questa opzione si trova nella console AWS in Amazon FSX &gt; ONTAP &gt; Storage Virtual Machines (Impostazioni &gt; macchine virtuali di storage).</block>
  <block id="d9401c99c6ddc6dbcd6070c357088cf5" category="paragraph"><block ref="d9401c99c6ddc6dbcd6070c357088cf5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba5037ceee608981a7684c3277ceca73" category="list-text">Dalla scheda Discovery (rilevamento), fare clic su Discover Portal (Scopri portale) e inserire gli indirizzi IP per le destinazioni iSCSI FSX.</block>
  <block id="49ba75dd04ab3da15488d6e271466575" category="paragraph"><block ref="49ba75dd04ab3da15488d6e271466575" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd6bd08689af39f12a04ce95acbaa7df" category="paragraph"><block ref="cd6bd08689af39f12a04ce95acbaa7df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="193f314b02dfe15e71a9ec5d16f5ce73" category="list-text">Nella scheda Target, fare clic su Connect (Connetti), selezionare Enable Multi-Path (attiva percorso multiplo) se appropriato per la configurazione, quindi fare clic su OK per connettersi alla destinazione.</block>
  <block id="8625607d58104640aa3cc3a687356560" category="paragraph"><block ref="8625607d58104640aa3cc3a687356560" category="inline-image-macro-rx" type="image"></block></block>
  <block id="907488914aeab882127886e6028b0ea0" category="list-text">Aprire l'utility Gestione computer e portare i dischi in linea. Verificare che conservino le stesse lettere di unità in precedenza.</block>
  <block id="885afbf2d17d52ec64abfd147535488e" category="paragraph"><block ref="885afbf2d17d52ec64abfd147535488e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bc8ec032118740c31355c3345d62bf4" category="example-title">Collegare i database di SQL Server</block>
  <block id="7f423619ca14c77f6b9db6f7bda8de76" category="list-text">Da SQL Server VM, aprire Microsoft SQL Server Management Studio e selezionare Allega per avviare il processo di connessione al database.</block>
  <block id="fd43b9851dc24c4889086cdc9afd2a3a" category="paragraph"><block ref="fd43b9851dc24c4889086cdc9afd2a3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8bff2998bccc1ca5a6d707233af02c9" category="list-text">Fare clic su Add (Aggiungi) e accedere alla cartella contenente il file di database primario di SQL Server, selezionarlo e fare clic su OK.</block>
  <block id="f700bbcedcee0092e600d8527c84b19f" category="paragraph"><block ref="f700bbcedcee0092e600d8527c84b19f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a827dff2feb3c6226fcac7b4b80a3cc8" category="list-text">Se i log delle transazioni si trovano su un'unità separata, scegliere la cartella che contiene il log delle transazioni.</block>
  <block id="f42947d249de7e97db085085f542e3c4" category="list-text">Al termine, fare clic su OK per allegare il database.</block>
  <block id="74242a349c592d71e13c317715f21c6f" category="paragraph"><block ref="74242a349c592d71e13c317715f21c6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f8fd7fd0d8b19f4ee350fa3bfaca1ca" category="example-title">Confermare la comunicazione SnapCenter con il plug-in di SQL Server</block>
  <block id="b6c6326ece2d2042cc822762ac90932a" category="paragraph">Una volta ripristinato lo stato precedente, il database SnapCenter rileva automaticamente gli host di SQL Server. Affinché questo funzioni correttamente, tenere presente i seguenti prerequisiti:</block>
  <block id="db44d05563a2083dddeaf5a8c08c36b8" category="list-text">SnapCenter deve essere impostato sulla modalità di disaster recovery. Questa operazione può essere eseguita tramite l'API Swagger o in Impostazioni globali in Disaster Recovery.</block>
  <block id="f77564f6296c2b86366fa8c55cde3b3d" category="list-text">L'FQDN di SQL Server deve essere identico all'istanza in esecuzione nel data center on-premise.</block>
  <block id="7effb9a6b0bfb89f35e1496a0b8ee21c" category="list-text">La relazione SnapMirror originale deve essere interrotta.</block>
  <block id="25c898cf2666acc247fd6eda6262658f" category="list-text">Le LUN contenenti il database devono essere montate sull'istanza di SQL Server e sul database allegato.</block>
  <block id="9c7568e40b946736fc8b8e0b79f35603" category="paragraph">Per verificare che SnapCenter sia in modalità di disaster recovery, accedere a Impostazioni dal client Web di SnapCenter. Accedere alla scheda Global Settings (Impostazioni globali) e fare clic su Disaster Recovery (Ripristino di emergenza). Assicurarsi che la casella di controllo Enable Disaster Recovery (attiva Disaster Recovery) sia attivata.</block>
  <block id="fa26a16fa4868aed3c0c634a2d7a27a5" category="paragraph"><block ref="fa26a16fa4868aed3c0c634a2d7a27a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c8ae03dc8bb68d2ad3e63a9126f795e6" category="section-title">Ripristinare i dati delle applicazioni Oracle</block>
  <block id="38631d978812c49b6f395a78becd9750" category="paragraph">Il seguente processo fornisce istruzioni su come ripristinare i dati delle applicazioni Oracle in VMware Cloud Services in AWS in caso di disastro che rende il sito on-premise inutilizzabile.</block>
  <block id="18ed07dc9f8533a3a2cf047292765486" category="paragraph">Completare i seguenti prerequisiti per continuare con la procedura di ripristino:</block>
  <block id="d55274d1968c306eb025dc5e6eca42b4" category="list-text">La macchina virtuale del server Oracle Linux è stata ripristinata su VMware Cloud SDDC utilizzando Veeam Full Restore.</block>
  <block id="7ddf1a9656f14a9883540ea830093e20" category="list-text">È stato creato un server SnapCenter secondario e il database SnapCenter e i file di configurazione sono stati ripristinati seguendo la procedura descritta in questa sezione <block ref="c05666153a222d3eb881a4a76532fde4" category="inline-link-macro-rx"></block></block>
  <block id="b723df724fefe9f2021e7bb7bd8a57d0" category="example-title">Configurazione di FSX per il ripristino di Oracle - interruzione della relazione SnapMirror</block>
  <block id="ab26994a6aef07f6a796a6109f921a28" category="paragraph">Per rendere accessibili ai server Oracle i volumi di storage secondari ospitati sull'istanza FSxN, è necessario prima interrompere la relazione SnapMirror esistente.</block>
  <block id="d80c0676712ecc3e8d717347b9a0113a" category="list-text">Dopo aver effettuato l'accesso alla CLI FSX, eseguire il seguente comando per visualizzare i volumi filtrati dal nome corretto.</block>
  <block id="c534b90634ff37c01e77b058859f2a29" category="paragraph"><block ref="c534b90634ff37c01e77b058859f2a29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="771b4d8e9d4a9f112068c45d013c2940" category="list-text">Eseguire il seguente comando per interrompere le relazioni SnapMirror esistenti.</block>
  <block id="60c89c7c11b1e5d09c8f7d6fcf1b4255" category="paragraph"><block ref="60c89c7c11b1e5d09c8f7d6fcf1b4255" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a4480a103abe04e17eca64a771420a8" category="list-text">Aggiornare il percorso di giunzione nel client Web Amazon FSX:</block>
  <block id="a3848e78db2c915e6ec7913bc0779a86" category="paragraph"><block ref="a3848e78db2c915e6ec7913bc0779a86" category="inline-image-macro-rx" type="image"></block></block>
  <block id="467332d89a649add4b0efb09dd2386c5" category="list-text">Aggiungere il nome del percorso di giunzione e fare clic su Update (Aggiorna). Specificare questo percorso di giunzione quando si monta il volume NFS dal server Oracle.</block>
  <block id="7a522c1cba5b4c9df88cb71a944d5efd" category="paragraph"><block ref="7a522c1cba5b4c9df88cb71a944d5efd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="974ee05a635ebfcae6d6f6aa6f5da0b9" category="example-title">Montare volumi NFS su Oracle Server</block>
  <block id="f3677efe1cf868a895b6634743ae53cd" category="paragraph">In Cloud Manager, è possibile ottenere il comando mount con l'indirizzo IP NFS LIF corretto per il montaggio dei volumi NFS che contengono i file di database e i log Oracle.</block>
  <block id="5ecb7cb864e3f6e77b9ae7264115942e" category="list-text">In Cloud Manager, accedi all'elenco dei volumi per il cluster FSX.</block>
  <block id="dc33973d3bef150b7e3be67c8acbde9a" category="paragraph"><block ref="dc33973d3bef150b7e3be67c8acbde9a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf957a98bd60352ec8312937f87b49dc" category="list-text">Dal menu delle azioni, selezionare Mount Command per visualizzare e copiare il comando mount da utilizzare sul server Oracle Linux.</block>
  <block id="42ae5bd08cec138b52386d868d92bcfe" category="paragraph"><block ref="42ae5bd08cec138b52386d868d92bcfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8026151c7c8dc5002a8652cdd0ac0610" category="paragraph"><block ref="8026151c7c8dc5002a8652cdd0ac0610" category="inline-image-macro-rx" type="image"></block></block>
  <block id="91d32453a4c3b285d62be2bc5eb3d24c" category="list-text">Montare il file system NFS su Oracle Linux Server. Le directory per il montaggio della condivisione NFS esistono già sull'host Oracle Linux.</block>
  <block id="3f7f1270061c2e231f722bfd466cec0d" category="list-text">Dal server Oracle Linux, utilizzare il comando mount per montare i volumi NFS.</block>
  <block id="5cafad6c0970ad9fd32dd43eb98a7d6f" category="paragraph">Ripetere questo passaggio per ogni volume associato ai database Oracle.</block>
  <block id="264225a103d86a5e552aebab3ee7dd3f" category="admonition">Per rendere persistente il montaggio NFS al riavvio, modificare<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> per includere i comandi di montaggio.</block>
  <block id="2095b7305d1da91dff871c600b482eb9" category="list-text">Riavviare il server Oracle. I database Oracle dovrebbero avviarsi normalmente e essere disponibili per l'utilizzo.</block>
  <block id="314695da56c7e601cdf6cfc3227858d9" category="paragraph">Una volta completato con successo il processo di failover descritto in questa soluzione, SnapCenter e Veeam riprendono le funzioni di backup in esecuzione in AWS, mentre FSX per ONTAP viene ora designato come storage primario senza relazioni SnapMirror esistenti con il data center on-premise originale. Una volta ripristinato il normale funzionamento on-premise, è possibile utilizzare un processo identico a quello descritto in questa documentazione per eseguire il mirroring dei dati nel sistema di storage ONTAP on-premise.</block>
  <block id="44ee07074aaf6f8c932889c7158c9906" category="paragraph">Come indicato anche in questa documentazione, è possibile configurare SnapCenter per eseguire il mirroring dei volumi di dati dell'applicazione da FSX per ONTAP a un sistema storage ONTAP residente on-premise. Allo stesso modo, puoi configurare Veeam per replicare le copie di backup su Amazon S3 utilizzando un repository di backup scale-out in modo che tali backup siano accessibili a un server di backup Veeam che risiede nel data center on-premise.</block>
  <block id="fd41e9ec1db4527e12ae403974c6c63c" category="paragraph">Il failback non rientra nell'ambito di questa documentazione, ma il failback non differisce molto dal processo dettagliato qui descritto.</block>
  <block id="6f10db05e58b527be630ad143ec566a5" category="paragraph">Il caso d'utilizzo presentato in questa documentazione si concentra su tecnologie di disaster recovery comprovate che evidenziano l'integrazione tra NetApp e VMware. I sistemi di storage NetApp ONTAP offrono tecnologie di mirroring dei dati comprovate che consentono alle organizzazioni di progettare soluzioni di disaster recovery che abbracciano tecnologie on-premise e ONTAP che risiedono presso i principali cloud provider.</block>
  <block id="86082b0bfc7279f0a1feebe1de23f618" category="paragraph">FSX per ONTAP su AWS è una soluzione di questo tipo che consente un'integrazione perfetta con SnapCenter e SyncMirror per la replica dei dati delle applicazioni nel cloud. Veeam Backup &amp; Replication è un'altra tecnologia ben nota che si integra perfettamente con i sistemi storage NetApp ONTAP e può fornire il failover allo storage nativo vSphere.</block>
  <block id="81127e42ddbedbb1cad03bf70d694aa9" category="paragraph">Questa soluzione ha presentato una soluzione di disaster recovery che utilizza lo storage Connect guest da un sistema ONTAP che ospita i dati delle applicazioni SQL Server e Oracle. SnapCenter con SnapMirror offre una soluzione semplice da gestire per proteggere i volumi delle applicazioni sui sistemi ONTAP e replicarli su FSX o CVO che risiedono nel cloud. SnapCenter è una soluzione abilitata al DR per eseguire il failover di tutti i dati delle applicazioni su VMware Cloud su AWS.</block>
  <block id="66e5d5ad5173b295e6b59ee5152216d0" category="list-text">Collegamenti alla documentazione della soluzione</block>
  <block id="4f6300de9742001d9f7a797da5d53a27" category="paragraph"><block ref="4f6300de9742001d9f7a797da5d53a27" category="inline-link-rx"></block></block>
  <block id="6590e8ec3c5ce0748f55250c70ec048c" category="paragraph"><block ref="6590e8ec3c5ce0748f55250c70ec048c" category="inline-link-rx"></block></block>
  <block id="06aafe83993d5d8e055426c9dd2eae76" category="doc">Backup e ripristino Veeam in VMware Cloud, con AWS FSX per ONTAP</block>
  <block id="899cca084f1a1bf69adac32c1398adb6" category="paragraph">Autore: Josh Powell - NetApp Solutions Engineering</block>
  <block id="227cecf5e7044ae569299b6dacc2a687" category="paragraph">Veeam Backup &amp; Replication è una soluzione efficace e affidabile per la protezione dei dati in VMware Cloud. Questa soluzione dimostra la corretta configurazione e configurazione per l'utilizzo di backup e replica Veeam per il backup e il ripristino delle macchine virtuali dell'applicazione che risiedono su datastore NFS FSX per ONTAP in VMware Cloud.</block>
  <block id="c4b912446bf11dcde10ac980b8819578" category="paragraph">VMware Cloud (in AWS) supporta l'utilizzo di datastore NFS come storage supplementare, mentre FSX per NetApp ONTAP è una soluzione sicura per i clienti che hanno bisogno di memorizzare grandi quantità di dati per le loro applicazioni cloud, in grado di scalare indipendentemente dal numero di host ESXi nel cluster SDDC. Questo servizio di storage AWS integrato offre uno storage altamente efficiente con tutte le funzionalità tradizionali di NetApp ONTAP.</block>
  <block id="75043beff1323591f4f4edb731c5ce37" category="list-text">Backup e ripristino di macchine virtuali Windows e Linux ospitate in VMC utilizzando FSX per NetApp ONTAP come repository di backup.</block>
  <block id="575860316b82ab24561ab5cd41209029" category="list-text">Backup e ripristino dei dati delle applicazioni Microsoft SQL Server utilizzando FSX per NetApp ONTAP come repository di backup.</block>
  <block id="014dac3ed531510f50fc4dcf086101bd" category="list-text">Backup e ripristino dei dati delle applicazioni Oracle utilizzando FSX per NetApp ONTAP come repository di backup.</block>
  <block id="1a160f6d5e4c0f03da493f0b6d7548ff" category="section-title">Archivi dati NFS che utilizzano Amazon FSX per ONTAP</block>
  <block id="36b4e7f3463e2ead8679ebc34829ef59" category="paragraph">Tutte le macchine virtuali di questa soluzione risiedono su datastore NFS supplementari FSX per ONTAP. L'utilizzo di FSX per ONTAP come datastore NFS supplementare offre diversi vantaggi. Ad esempio, consente di:</block>
  <block id="c40ee4ce6dfe0563d18cf384ace88765" category="list-text">Crea un file system scalabile e altamente disponibile nel cloud senza la necessità di complesse operazioni di configurazione e gestione.</block>
  <block id="e745aa1d0e918c96cea168491895d6fb" category="list-text">Integrazione con l'ambiente VMware esistente, che consente di utilizzare strumenti e processi familiari per gestire le risorse cloud.</block>
  <block id="43cd0f845dc959949e9ac1e3a35e45bf" category="list-text">Sfrutta le funzionalità avanzate di gestione dei dati fornite da ONTAP, come snapshot e replica, per proteggere i tuoi dati e garantirne la disponibilità.</block>
  <block id="5497ec7c1fdee07126ed64bf9fed5d87" category="example-title">Panoramica sull'implementazione della soluzione</block>
  <block id="9b6e4c8a49f0160a14314bd62bfe0a69" category="paragraph">Questo elenco fornisce i passaggi di alto livello necessari per configurare il backup e la replica di Veeeam, eseguire processi di backup e ripristino utilizzando FSX per ONTAP come repository di backup ed eseguire ripristini di macchine virtuali e database SQL Server e Oracle:</block>
  <block id="e871c13ae67a9af23b556e907002fa12" category="list-text">Creare il file system FSX per ONTAP da utilizzare come repository di backup iSCSI per il backup e la replica Veeam.</block>
  <block id="989dd576e8b1eb03cbf28639a2931613" category="list-text">Implementare Veeam Proxy per distribuire i carichi di lavoro di backup e montare repository di backup iSCSI ospitati su FSX per ONTAP.</block>
  <block id="b60278b7e91394afcc745ae75fa44aa4" category="list-text">Configurare Veeam Backup Jobs per il backup di macchine virtuali SQL Server, Oracle, Linux e Windows.</block>
  <block id="1b245e740482771d5d3992478a82d724" category="list-text">Ripristinare le macchine virtuali SQL Server e i singoli database.</block>
  <block id="13cd489b0849b840f8ab36d74b8293ec" category="list-text">Ripristinare le macchine virtuali Oracle e i singoli database.</block>
  <block id="a7170e8fda73e91fa62b13d3622ef444" category="paragraph">Lo scopo di questa soluzione è dimostrare la protezione dei dati delle macchine virtuali in esecuzione in VMware Cloud e situate su archivi dati NFS ospitati da FSX per NetApp ONTAP. Questa soluzione presuppone che i seguenti componenti siano configurati e pronti per l'uso:</block>
  <block id="307f5c37781c29657edae5fb925162a2" category="list-text">File system FSX per ONTAP con uno o più datastore NFS connessi a VMware Cloud.</block>
  <block id="f868183ec79787eaaf74ea89a47669dc" category="list-text">Macchina virtuale Microsoft Windows Server con software Veeam Backup &amp; Replication installato.</block>
  <block id="5736f2ed579d3ef6cf3f20fb689ab01e" category="list-text">Il server vCenter è stato rilevato dal server Veeam Backup &amp; Replication utilizzando il proprio indirizzo IP o il nome di dominio completo.</block>
  <block id="331f1124497c0ac124ff038480809c69" category="list-text">Microsoft Windows Server VM da installare con i componenti di Veeam Backup Proxy durante l'implementazione della soluzione.</block>
  <block id="3a3f8abc64509c161ec11b01ef580eb2" category="list-text">Macchine virtuali Microsoft SQL Server con VMDK e dati delle applicazioni che risiedono su FSX per datastore NFS di ONTAP. Per questa soluzione avevamo due database SQL su due VMDK separati.</block>
  <block id="8dfe3f043b3df38e0413e36fbd24db7f" category="list-text">Nota: Come Best practice, i file di log delle transazioni e dei database vengono collocati su dischi separati, in quanto ciò migliorerà le performance e l'affidabilità. Ciò è dovuto in parte al fatto che i log delle transazioni vengono scritti in sequenza, mentre i file di database vengono scritti in modo casuale.</block>
  <block id="8be960cd9539642d1747f77549b61640" category="list-text">VM di database Oracle con VMDK e dati delle applicazioni che risiedono su FSX per datastore NFS di ONTAP.</block>
  <block id="1a181903b99cf17676f681159276eb0f" category="list-text">VM di file server Linux e Windows con VMDK residenti su FSX per datastore NFS ONTAP.</block>
  <block id="363652c12cab9d20a25160a8429e6749" category="inline-link">Guida utente di Veeam Backup and Replication per VMware vSphere</block>
  <block id="ef67d6716f36cc4d904840c87baf49e8" category="list-text">Veeam richiede porte TCP specifiche per la comunicazione tra server e componenti nell'ambiente di backup. Sui componenti dell'infrastruttura di backup Veeam, le regole firewall richieste vengono create automaticamente. Per un elenco completo dei requisiti delle porte di rete, consultare la sezione Porte del<block ref="a201e119e9bf364010037d27795ac7b3" category="inline-link-rx"></block>.</block>
  <block id="35d6eccff0f72c28cfe3309ffa950add" category="paragraph">Lo scopo di questa soluzione è dimostrare la protezione dei dati delle macchine virtuali in esecuzione in VMware Cloud e situate su archivi dati NFS ospitati da FSX per NetApp ONTAP. Questa soluzione presuppone che i seguenti componenti siano già configurati e pronti per l'uso:</block>
  <block id="2296042ba6aa3359318593608ca0345d" category="list-text">Macchine virtuali Microsoft Windows situate su un archivio dati NFS FSX per ONTAP</block>
  <block id="c6d1f5be073c9cd0daaf474564f8467c" category="list-text">Macchine virtuali Linux (CentOS) situate su un archivio dati NFS FSX per ONTAP</block>
  <block id="b3320f54be7deb0784e4a01661688928" category="list-text">Macchine virtuali Microsoft SQL Server situate su un archivio dati NFS FSX per ONTAP</block>
  <block id="4adae5f55535a5ee71371da1efc9ca6d" category="list-text">Due database ospitati su VMDK separati</block>
  <block id="8722af64f7207084921888f7b8dc2619" category="list-text">Oracle VM si trova su un archivio dati FSX per NFS ONTAP</block>
  <block id="ab74fd995780c1e0c54a3d450fdc334f" category="paragraph">In questa soluzione forniamo istruzioni dettagliate per l'implementazione e la convalida di una soluzione che utilizza il software di backup e replica Veeam per eseguire il backup e il ripristino di macchine virtuali di file server SQL Server, Oracle e Windows e Linux in un VMware Cloud SDDC su AWS. Le macchine virtuali di questa soluzione risiedono su un datastore NFS supplementare ospitato da FSX per ONTAP. Inoltre, viene utilizzato un file system FSX separato per ONTAP per ospitare volumi iSCSI che verranno utilizzati per i repository di backup Veeam.</block>
  <block id="1d11ec5b678e358544414cea998244f1" category="paragraph">Passeremo a FSX per la creazione di file system ONTAP, il montaggio di volumi iSCSI da utilizzare come repository di backup, la creazione e l'esecuzione di processi di backup e il ripristino di macchine virtuali e database.</block>
  <block id="f5fadf616d77899c034abd76a2af86c2" category="inline-link">Guida utente di FSX per ONTAP</block>
  <block id="5a7878288054d2ea7843552720ab553e" category="paragraph">Per informazioni dettagliate su FSX per NetApp ONTAP, fare riferimento a.<block ref="3c0b139db5fd16e7a1648aeb8ddd690b" category="inline-link-rx"></block>.</block>
  <block id="392249183bc4f33aaba419554722c65a" category="paragraph">Per informazioni dettagliate su Veeam Backup e Replication, fare riferimento a.<block ref="83de5255f1620c94ccf67b2665aee6d6" category="inline-link-rx"></block> sito.</block>
  <block id="f8de66c023a023128fae72baff4768e8" category="inline-link">VMware Cloud su AWS e VMware Cloud su supporto Dell EMC. Considerazioni e limitazioni</block>
  <block id="01956504f12da2e314d3cbcbcae47df8" category="paragraph">Per considerazioni e limitazioni sull'utilizzo di Veeam Backup and Replication con VMware Cloud su AWS, fare riferimento a.<block ref="4e47976d7d0e280800947db2b44c65e3" category="inline-link-rx"></block>.</block>
  <block id="6ed4923c81194d5cd4fe3073f7f77b05" category="section-title">Implementare il server proxy Veeam</block>
  <block id="c7da1d365711815b85fa18bc74f530d0" category="paragraph">Un server proxy Veeam è un componente del software Veeam Backup &amp; Replication che funge da intermediario tra l'origine e la destinazione di backup o replica. Il server proxy consente di ottimizzare e accelerare il trasferimento dei dati durante i processi di backup elaborando i dati in locale e può utilizzare diverse modalità di trasporto per accedere ai dati utilizzando le API VMware vStorage per la protezione dei dati o attraverso l'accesso diretto allo storage.</block>
  <block id="8f061a3a51bbd5c953777928783cb5a8" category="paragraph">Quando si sceglie un server proxy Veeam, è importante considerare il numero di attività simultanee e la modalità di trasporto o il tipo di accesso allo storage desiderato.</block>
  <block id="9a2d7db98a8dc31fcc50b3e57a8fe217" category="inline-link">Veeeam VMware vSphere Best Practice Guide</block>
  <block id="e204b26976814adc33c2b02aff3edb3d" category="paragraph">Per il dimensionamento del numero di server proxy e i relativi requisiti di sistema, fare riferimento a.<block ref="c614dc8f78d8f8492061379ec6b8259d" category="inline-link-rx"></block>.</block>
  <block id="1da132279065b63629529e4a20b86a40" category="paragraph">Veeam Data Mover è un componente di Veeam Proxy Server e utilizza una Transport Mode come metodo per ottenere i dati delle macchine virtuali dall'origine e trasferirli alla destinazione. La modalità di trasporto viene specificata durante la configurazione del processo di backup. È possibile aumentare l'efficienza dei backup dagli archivi dati NFS utilizzando l'accesso diretto allo storage.</block>
  <block id="6056e2661738180a6bfcef495f66a14c" category="paragraph">Per ulteriori informazioni sulle modalità di trasporto, fare riferimento a.<block ref="6493e4830783387b4fb12861d9b0db3d" category="inline-link-rx"></block>.</block>
  <block id="4f3a320d9cc1654fb192fa3ef09e777d" category="paragraph">Nella fase successiva verrà descritta l'implementazione di Veeam Proxy Server su una macchina virtuale Windows nel software SDDC VMware Cloud.</block>
  <block id="c38e42cbd3153669c49509cb5921ef27" category="example-title">Implementare Veeam Proxy per distribuire i carichi di lavoro di backup</block>
  <block id="6c805e2bd591e34c8b2c7b40ce3ae66c" category="paragraph">In questa fase, il proxy Veeam viene distribuito su una macchina virtuale Windows esistente. Ciò consente di distribuire i processi di backup tra il server di backup Veeam primario e il proxy Veeam.</block>
  <block id="9d4fc0a95b3ccfd4aa30cfdd72dabd57" category="list-text">Sul server Veeam Backup and Replication, aprire la console di amministrazione e selezionare *Backup Infrastructure* nel menu in basso a sinistra.</block>
  <block id="40244b4ec6aa1e9698b8539fe85f2496" category="list-text">Fare clic con il pulsante destro del mouse su *Backup Proxy* e fare clic su *Add VMware backup proxy...* per aprire la procedura guidata.</block>
  <block id="7436617703d50f796dbea213fcf40927" category="image-alt">Aprire la procedura guidata Aggiungi proxy di backup Veeam</block>
  <block id="5bbbf82976c13ef8e6e1a11e418b2c5b" category="list-text">Nella procedura guidata *Add VMware Proxy* fare clic sul pulsante *Add New...* (Aggiungi nuovo...) per aggiungere un nuovo server proxy.</block>
  <block id="78666bc2e843e9cef4d24aefc5a57856" category="image-alt">Selezionare per aggiungere un nuovo server</block>
  <block id="b3dd2563d84571dcc5398bd076e4521e" category="list-text">Selezionare per aggiungere Microsoft Windows e seguire le istruzioni per aggiungere il server:</block>
  <block id="7024d72957ee528cd2aa6a4d4c3d7adb" category="list-text">Inserire il nome DNS o l'indirizzo IP</block>
  <block id="a8efba444dcd5af95bbb5c5b3817a600" category="list-text">Selezionare un account da utilizzare per le credenziali nel nuovo sistema o aggiungere nuove credenziali</block>
  <block id="a191caed54c4b1c1063d3b9968aef212" category="list-text">Esaminare i componenti da installare, quindi fare clic su *Apply* (Applica) per iniziare la distribuzione</block>
  <block id="bd5b42eeb98d5eb2694cb6f0f4d108b1" category="image-alt">Compila i prompt per aggiungere un nuovo server</block>
  <block id="50067741ebd921230d3dbab184bf075e" category="list-text">Nella procedura guidata *New VMware Proxy*, scegliere una modalità di trasporto. Nel nostro caso abbiamo scelto *selezione automatica*.</block>
  <block id="9185b2ae21b13d792b77c630bcacd8b5" category="image-alt">Selezionare la modalità di trasporto</block>
  <block id="d9aa13b7d3b607b0cfa63839ed5459bc" category="list-text">Selezionare gli archivi dati connessi ai quali si desidera che VMware Proxy abbia accesso diretto.</block>
  <block id="07aea82b8f0e111675ae303b4a9efb09" category="image-alt">Selezionare un server per VMware Proxy</block>
  <block id="4eafd51f0a87b847a7d38cd8f86c0b0a" category="image-alt">Selezionare gli archivi dati a cui accedere</block>
  <block id="e983b249a5363ad45edfeec5ed46dfff" category="list-text">Configurare e applicare le regole di traffico di rete desiderate, ad esempio la crittografia o la limitazione. Al termine, fare clic sul pulsante *Apply* (Applica) per completare l'implementazione.</block>
  <block id="3ab7229eb48fbece0f1af78a35a3bb94" category="image-alt">Configurare le regole del traffico di rete</block>
  <block id="185ecac0c5555658a5a82a00b0d2ddb4" category="section-title">Configurare storage e repository di backup</block>
  <block id="d739ffc348078951ba9d7b0cb18da383" category="paragraph">Il server primario Veeam Backup e il server Veeam Proxy hanno accesso a un repository di backup sotto forma di storage a connessione diretta. In questa sezione viene descritta la creazione di un file system FSX per ONTAP, il montaggio di LUN iSCSI sui server Veeam e la creazione di repository di backup.</block>
  <block id="ab86a3c6c49221029e087069c67afde4" category="example-title">Creare FSX per il file system ONTAP</block>
  <block id="b1482c3c8ddb524e489f598fb1682bec" category="paragraph">Creare un file system FSX per ONTAP che verrà utilizzato per ospitare i volumi iSCSI per i repository di backup Veeam.</block>
  <block id="63dadfa2e7bb649f2cf37a4f5bb57234" category="list-text">Nella console AWS, andare a FSX e quindi a *Create file system*</block>
  <block id="e92c790de743d72c9d5e30676ffc92a6" category="image-alt">Creare FSX per il file system ONTAP</block>
  <block id="2d70ffe1aef831779c654e87ef9a61cb" category="list-text">Selezionare *Amazon FSX per NetApp ONTAP*, quindi *Avanti* per continuare.</block>
  <block id="da42c7b111f6ebbd0e83be11785bb4a8" category="image-alt">Selezionare Amazon FSX per NetApp ONTAP</block>
  <block id="7d660d9d9190db31e2bd116860682a0e" category="list-text">Inserire il nome del file system, il tipo di implementazione, la capacità dello storage SSD e il VPC in cui si trova il cluster FSX per ONTAP. Deve essere un VPC configurato per comunicare con la rete di macchine virtuali in VMware Cloud. Fare clic su *Avanti*.</block>
  <block id="04bdd1dac84aa4ac8a5de06bed454bec" category="image-alt">Compilare le informazioni sul file system</block>
  <block id="d2cc66e895c715b9d24a0f9e0e3b88f0" category="list-text">Esaminare le fasi di implementazione e fare clic su *Create file System* (Crea file system) per avviare il processo di creazione del file system.</block>
  <block id="c119c68e0942c93c70a5ca74df29411e" category="example-title">Configurare e montare LUN iSCSI</block>
  <block id="04bce2f95605efb88d967dab73395d7a" category="paragraph">Creare e configurare i LUN iSCSI su FSX per ONTAP e montarli sui server proxy e di backup Veeam. Questi LUN verranno utilizzati in seguito per creare repository di backup Veeam.</block>
  <block id="5005cc580f96bbd1531e77d5532a5d64" category="admonition">La creazione di un LUN iSCSI su FSX per ONTAP è un processo multi-step. La prima fase della creazione dei volumi può essere eseguita nella console Amazon FSX o con la CLI NetApp ONTAP.</block>
  <block id="dcf268d2cfc916821c6b6f5555261152" category="admonition">Per ulteriori informazioni sull'utilizzo di FSX per ONTAP, consultare<block ref="3c0b139db5fd16e7a1648aeb8ddd690b" category="inline-link-rx"></block>.</block>
  <block id="66ddf6562e817e09542dfdb3581a772c" category="list-text">Dalla CLI di NetApp ONTAP creare i volumi iniziali utilizzando il seguente comando:</block>
  <block id="2135d9bb62fb8c3d2e8360df647e4580" category="list-text">Creare LUN utilizzando i volumi creati nel passaggio precedente:</block>
  <block id="143a3308766e722bc51c4a272aef9459" category="list-text">Concedere l'accesso alle LUN creando un gruppo di iniziatori contenente l'IQN iSCSI dei server proxy e di backup Veeam:</block>
  <block id="4a829a8db516d06fa3598fcf317a2bdf" category="admonition">Per completare il passaggio precedente, è necessario recuperare prima IQN dalle proprietà di iSCSI Initiator sui server Windows.</block>
  <block id="46aba17afdc1c5c75177648e448e9e73" category="list-text">Per montare i LUN iSCSI, accedere a Veeam Backup &amp; Replication Server e aprire iSCSI Initiator Properties. Accedere alla scheda *Discover* e inserire l'indirizzo IP di destinazione iSCSI.</block>
  <block id="a1410f742ec3c6b9771b8b56e4f74397" category="image-alt">Rilevamento degli iniziatori iSCSI</block>
  <block id="7896ed45c3a165871425e5e7a7754068" category="list-text">Nella scheda *targets*, evidenziare il LUN inattivo e fare clic su *Connect*. Selezionare la casella *Enable multi-path* (attiva percorso multiplo) e fare clic su *OK* per connettersi al LUN.</block>
  <block id="cfe06ced4041dba025b5783050223aa6" category="image-alt">Collegare iSCSI Initiator al LUN</block>
  <block id="1e1ae1e60a8dfc7ed96a6ca196efb3f7" category="list-text">Nell'utility Disk Management inizializza il nuovo LUN e crea un volume con il nome e la lettera del disco desiderati. Selezionare la casella *Enable multi-path* (attiva percorso multiplo) e fare clic su *OK* per connettersi al LUN.</block>
  <block id="91fb417f634afe2d6560149b5394c9c9" category="image-alt">Gestione dei dischi di Windows</block>
  <block id="ec7c7f1a4620a0e2176556c71854ae66" category="list-text">Ripetere questa procedura per montare i volumi iSCSI sul server Veeam Proxy.</block>
  <block id="7d038f3b910671baddd68728149b7c4b" category="example-title">Creare repository di backup Veeam</block>
  <block id="2f1071c15bba30d1cb3ebab14b3bfe35" category="paragraph">Nella console di backup e replica di Veeam, creare repository di backup per i server Veeam Backup e Veeam Proxy. Questi repository verranno utilizzati come destinazioni di backup per i backup delle macchine virtuali.</block>
  <block id="f2aa8c30f4a71e2af740c1d46fbebaa7" category="list-text">Nella console di backup e replica di Veeam, fare clic su *Backup Infrastructure* in basso a sinistra, quindi selezionare *Add Repository*</block>
  <block id="889057427ca75e67d9ad9b5449ed0210" category="image-alt">Creare un nuovo repository di backup</block>
  <block id="7f5523627751b57497ad0cf5c9b3f765" category="list-text">Nella procedura guidata nuovo repository di backup, immettere un nome per il repository, quindi selezionare il server dall'elenco a discesa e fare clic sul pulsante *popola* per scegliere il volume NTFS da utilizzare.</block>
  <block id="9968b60de9291c8910745941617de5c4" category="image-alt">Selezionare Backup Repository Server (Server repository di backup)</block>
  <block id="2525a35c51623cb0a8ed1199138d6828" category="list-text">Nella pagina successiva, scegliere un server Mount che verrà utilizzato per montare i backup quando si eseguono ripristini avanzati. Per impostazione predefinita, si tratta dello stesso server a cui è collegato lo storage del repository.</block>
  <block id="b57ba393732dc8f80d3571ae4ec575f5" category="list-text">Esaminare le selezioni e fare clic su *Apply* (Applica) per avviare la creazione del repository di backup.</block>
  <block id="939d6e1647073b59730a25661269ba57" category="image-alt">Scegliere montare il server</block>
  <block id="f2f54d55f13232525ba25b2714e262c6" category="list-text">Ripetere questa procedura per tutti i server proxy aggiuntivi.</block>
  <block id="891594a875e25ad7383fe31f29b45c3c" category="section-title">Configurare i processi di backup Veeam</block>
  <block id="9920c3a0639f4da25555907aea043dc5" category="paragraph">I processi di backup devono essere creati utilizzando i repository di backup nella sezione precedente. La creazione di processi di backup è una parte normale del repertorio di qualsiasi amministratore dello storage e non vengono descritte tutte le fasi qui descritte. Per informazioni più complete sulla creazione di processi di backup in Veeam, vedere<block ref="83de5255f1620c94ccf67b2665aee6d6" category="inline-link-rx"></block>.</block>
  <block id="6bfc66c2628109275c896a988b4526ba" category="paragraph">In questa soluzione sono stati creati processi di backup separati per:</block>
  <block id="e3903b9e363074bac4445648a8709a9d" category="list-text">Microsoft Windows SQL Server</block>
  <block id="55eae047caeecf8cc118db0747f7d743" category="list-text">Server di database Oracle</block>
  <block id="097f33de9b678c4fc9f275c0df2b1a05" category="list-text">File server Windows</block>
  <block id="ae1149b4824a31c171106b9190f70a09" category="list-text">File server Linux</block>
  <block id="6725114ce430d926feb402a2063ab9bc" category="example-title">Considerazioni generali per la configurazione dei processi di backup Veeam</block>
  <block id="bf4caa458a928f51528c2f10b31b3e10" category="list-text">Abilitare l'elaborazione basata sulle applicazioni per creare backup coerenti ed eseguire l'elaborazione del log delle transazioni.</block>
  <block id="3c7c53d645ec38808c26ca2d19b9a4d4" category="list-text">Dopo aver abilitato l'elaborazione in base all'applicazione, aggiungere le credenziali corrette con privilegi di amministratore all'applicazione, poiché potrebbero essere diverse dalle credenziali del sistema operativo guest.</block>
  <block id="1c4fdcc86146f7632fdc110e81c00e02" category="image-alt">Impostazioni di elaborazione dell'applicazione</block>
  <block id="f773d224b5cf1a1dbd085266d448b926" category="list-text">Per gestire il criterio di conservazione per il backup, selezionare *Mantieni alcuni backup completi più a lungo per scopi di archiviazione* e fare clic sul pulsante *Configura...* per configurare il criterio.</block>
  <block id="8598cf5b5d0f91f3236081af11f8057b" category="image-alt">Policy di conservazione a lungo termine</block>
  <block id="15d9da9e054f4fa32f65f8287f31988f" category="section-title">Ripristinare le macchine virtuali applicative con il ripristino completo di Veeam</block>
  <block id="f71bd591b9504e7e051735f31e3e8297" category="paragraph">Eseguire un ripristino completo con Veeam è il primo passo per eseguire un ripristino dell'applicazione. Abbiamo validato che i ripristini completi delle nostre macchine virtuali erano accesi e tutti i servizi funzionavano normalmente.</block>
  <block id="b63970925e7df13313ea4e9bfb20d25b" category="paragraph">Il ripristino dei server è una parte normale del repertorio di qualsiasi amministratore dello storage e non vengono descritte tutte le fasi qui descritte. Per informazioni più complete sull'esecuzione di ripristini completi in Veeam, consultare la<block ref="83de5255f1620c94ccf67b2665aee6d6" category="inline-link-rx"></block>.</block>
  <block id="d5b892977fb8e256e082bc08621c1e91" category="section-title">Ripristinare i database di SQL Server</block>
  <block id="4dbf9d1e20e42b8ceb9eb7b9bfacaf26" category="paragraph">Veeam Backup &amp; Replication offre diverse opzioni per il ripristino dei database di SQL Server. Per questa convalida abbiamo utilizzato Veeam Explorer per SQL Server con Instant Recovery per eseguire ripristini dei database SQL Server. SQL Server Instant Recovery è una funzionalità che consente di ripristinare rapidamente i database di SQL Server senza dover attendere il ripristino completo del database. Questo rapido processo di recovery riduce al minimo i downtime e garantisce la continuità del business. Ecco come funziona:</block>
  <block id="f7f8bb0d8f1bc9a76e9d24b9755056e3" category="list-text">Veeeam Explorer *monta il backup* contenente il database SQL Server da ripristinare.</block>
  <block id="32184bfa3ec6d72ef5157d490eef9b42" category="list-text">Il software *pubblica il database* direttamente dai file montati, rendendolo accessibile come database temporaneo sull'istanza di SQL Server di destinazione.</block>
  <block id="147b6b44a29d176cd64d9f1f8a347346" category="list-text">Mentre il database temporaneo è in uso, Veeam Explorer *reindirizza le query utente* a questo database, garantendo che gli utenti possano continuare ad accedere e lavorare con i dati.</block>
  <block id="fc87b31ab41cb9094fdafe90e5c33ee8" category="list-text">In background, Veeam *esegue un ripristino completo del database*, trasferendo i dati dal database temporaneo alla posizione originale del database.</block>
  <block id="326bd27551ad96c083a3af1d636fba2f" category="list-text">Una volta completato il ripristino completo del database, Veeam Explorer *riporta le query dell'utente al database originale* e rimuove il database temporaneo.</block>
  <block id="53d7653e886de31f64f1934f6106967b" category="example-title">Ripristinare il database SQL Server con Veeam Explorer Instant Recovery</block>
  <block id="62efbbf0b1972f3db725ff341efb5b9e" category="list-text">Nella console di backup e replica di Veeam, accedere all'elenco dei backup di SQL Server, fare clic con il pulsante destro del mouse su un server e selezionare *Restore application ITEMS* (Ripristina elementi dell'applicazione), quindi *Microsoft SQL Server Databases...* (Database Microsoft SQL Server...).</block>
  <block id="cb2c84aa5dd5450ed2bb5c2e9e182122" category="list-text">Nella finestra Ripristino guidato database di Microsoft SQL Server, selezionare un punto di ripristino dall'elenco e fare clic su *Avanti*.</block>
  <block id="83f3bf3328f655dc26285ddf3e56f6a0" category="image-alt">Selezionare un punto di ripristino dall'elenco</block>
  <block id="7d09cc51774cd8dd944f427698b0e331" category="list-text">Inserire un valore di *Restore Reason* (motivo ripristino), se desiderato, quindi, nella pagina Summary (Riepilogo), fare clic sul pulsante *Browse* (Sfoglia) per avviare Veeam Explorer per Microsoft SQL Server.</block>
  <block id="93ef50124e2b75448543f1fceee8720d" category="image-alt">Fare clic su Browse (Sfoglia) per avviare Veeam Explorer</block>
  <block id="23f91d399193160e78b4a9a09a5e29cf" category="list-text">In Veeam Explorer espandere l'elenco delle istanze di database, fare clic con il pulsante destro del mouse e selezionare *Instant Recovery*, quindi il punto di ripristino specifico su cui eseguire il ripristino.</block>
  <block id="91848752ef347f0a72d0ffcaf6514993" category="image-alt">Selezionare il punto di ripristino del ripristino istantaneo</block>
  <block id="3dc0ac32b83cfdecc3c501fdf7c091f3" category="list-text">Nella procedura guidata di ripristino istantaneo, specificare il tipo di switchover. Questo può avvenire automaticamente con tempi di inattività minimi, manualmente o in un momento specifico. Quindi fare clic sul pulsante *Recover* (Ripristina) per avviare il processo di ripristino.</block>
  <block id="4e2a44728723140f9ba14c7275424bd9" category="image-alt">Selezionare il tipo di switchover</block>
  <block id="23cf892bc742964f8ed1e855683c6670" category="list-text">Il processo di ripristino può essere monitorato da Veeam Explorer.</block>
  <block id="e974549c6230612aab13ea02dd581e36" category="image-alt">monitorare il processo di ripristino di sql server</block>
  <block id="098837e218303bd96735334e58cfc2cc" category="inline-link">Guida utente di Veeeam Explorers</block>
  <block id="ab470be1706ecee3652bec4686980395" category="paragraph">Per informazioni più dettagliate sull'esecuzione delle operazioni di ripristino di SQL Server con Veeam Explorer, consultare la sezione Microsoft SQL Server nella<block ref="b3e7ff59f86494dde184c05b201d855e" category="inline-link-rx"></block>.</block>
  <block id="1b6a2be6f12549e32286e4f2dc12e2c7" category="section-title">Ripristinare i database Oracle con Veeam Explorer</block>
  <block id="0313e321d89b71cf80cc311103cca603" category="paragraph">Veeeam Explorer per database Oracle offre la possibilità di eseguire un ripristino standard del database Oracle o un ripristino ininterrotto utilizzando Instant Recovery. Supporta inoltre la pubblicazione di database per un accesso rapido, il ripristino dei database Data Guard e i ripristini dai backup RMAN.</block>
  <block id="b534180c333f658f337d96b0a9665fef" category="paragraph">Per informazioni più dettagliate sull'esecuzione delle operazioni di ripristino del database Oracle con Veeam Explorer, fare riferimento alla sezione Oracle nella<block ref="d86e2dea88de74702b776a7b6a2794dc" category="inline-link-rx"></block>.</block>
  <block id="bb3c66c1da92cedc05fe3488c730b18c" category="example-title">Ripristinare il database Oracle con Veeam Explorer</block>
  <block id="3b195aff157bd167f1dd37a9fcd0b60d" category="paragraph">In questa sezione viene descritto un ripristino del database Oracle su un server diverso utilizzando Veeam Explorer.</block>
  <block id="be228e79b0bceacb5ae08d8a6461bbc8" category="list-text">Nella console di backup e replica di Veeam, accedere all'elenco dei backup Oracle, fare clic con il pulsante destro del mouse su un server e selezionare *Restore application ITEMS* (Ripristina elementi dell'applicazione), quindi *Oracle Databases...* (Database Oracle...*).</block>
  <block id="71a36e1ed26cc0d0e6741bc701e2b712" category="image-alt">Ripristinare i database Oracle</block>
  <block id="cece11bd872faf4c7efa691216eaeea2" category="list-text">In Oracle Database Restore Wizard (Ripristino guidato database Oracle), selezionare un punto di ripristino dall'elenco e fare clic su *Next* (Avanti).</block>
  <block id="896155df2e0009da3f3945055f1978bf" category="list-text">Inserire un *Restore Reason* (motivo ripristino), se desiderato, quindi, nella pagina Summary (Riepilogo), fare clic sul pulsante *Browse* (Sfoglia) per avviare Veeam Explorer per Oracle.</block>
  <block id="e2665092e2db451c18c439aa87b1ab45" category="list-text">In Veeam Explorer espandere l'elenco delle istanze di database, fare clic sul database da ripristinare, quindi selezionare *Ripristina database* dal menu a discesa in alto. Selezionare *Ripristina su un altro server...*.</block>
  <block id="6059785cc38cd2515737ba8afc9e5c4a" category="image-alt">Selezionare Ripristina su un altro server</block>
  <block id="5f920b9ccb9fe5c395400fdf2d9fbb88" category="list-text">Nella procedura guidata di ripristino, specificare il punto di ripristino da cui eseguire il ripristino e fare clic su *Avanti*.</block>
  <block id="e1d921ef21984b10f12b79b9ee5dcc16" category="image-alt">Selezionare il punto di ripristino</block>
  <block id="408c26bdfc2d93171c71473e59ea7851" category="list-text">Specificare il server di destinazione in cui verrà ripristinato il database e le credenziali dell'account, quindi fare clic su *Avanti*.</block>
  <block id="90414640ba0911f4dc486ddcb8b1d8e0" category="image-alt">Specificare le credenziali del server di destinazione</block>
  <block id="ed368a5b1fde6fe23e70c02279ab0ada" category="list-text">Infine, specificare il percorso di destinazione dei file di database e fare clic sul pulsante *Restore* per avviare il processo di ripristino.</block>
  <block id="6d9d046bf4302de591ebf5af70c02969" category="image-alt">Specificare la posizione di destinazione</block>
  <block id="0b461fa79920c88a3497485474af2292" category="list-text">Una volta completato il ripristino del database, controllare che il database Oracle venga avviato correttamente sul server.</block>
  <block id="8810f2f9802fa165dfd359b5b76b6b7b" category="example-title">Pubblicare il database Oracle su un server alternativo</block>
  <block id="5e066f91cc8d7f9491f75664f7e20dd6" category="paragraph">In questa sezione viene pubblicato un database su un server alternativo per un accesso rapido senza avviare un ripristino completo.</block>
  <block id="2e9ce0916306fede470954bd646f1cdc" category="list-text">In Veeam Explorer espandere l'elenco delle istanze di database, fare clic sul database da ripristinare, quindi selezionare *pubblica database* dal menu a discesa in alto, quindi scegliere *pubblica su un altro server...*.</block>
  <block id="3139a1fa03fe835f5f536efc10409e11" category="list-text">Nella Pubblicazione guidata, specificare il punto di ripristino da cui pubblicare il database e fare clic su *Avanti*.</block>
  <block id="b8a6d62ddfa6710c97f1e494dc9e45ac" category="list-text">Infine, specificare la posizione del file system linux di destinazione e fare clic su *Publish* per avviare il processo di ripristino.</block>
  <block id="1b421299cbc14ee7afd66f3aa0c1f358" category="list-text">Una volta completata la pubblicazione, accedere al server di destinazione ed eseguire i seguenti comandi per assicurarsi che il database sia in esecuzione:</block>
  <block id="cfd3a34ff975bc1959bfb5793e2b6ff8" category="paragraph">VMware Cloud è una potente piattaforma per l'esecuzione di applicazioni business-critical e l'archiviazione di dati sensibili. Una soluzione sicura per la protezione dei dati è essenziale per le aziende che si affidano a VMware Cloud per garantire la continuità del business e contribuire alla protezione dalle minacce informatiche e dalla perdita di dati. Scegliendo una soluzione di protezione dei dati affidabile e solida, le aziende possono essere sicure che i loro dati critici siano sicuri e sicuri, indipendentemente da cosa.</block>
  <block id="a72d18c7f6b828d17adc2b0ed2dedd79" category="paragraph">Il caso di utilizzo presentato in questa documentazione si concentra su tecnologie di data Protection comprovate che evidenziano l'integrazione tra NetApp, VMware e Veeeam. FSX per ONTAP è supportato come datastore NFS supplementari per VMware Cloud in AWS e viene utilizzato per tutti i dati delle macchine virtuali e delle applicazioni. Veeam Backup &amp; Replication è una soluzione completa per la protezione dei dati progettata per aiutare le aziende a migliorare, automatizzare e ottimizzare i processi di backup e recovery. Veeam viene utilizzato insieme ai volumi target di backup iSCSI, ospitati su FSX per ONTAP, per fornire una soluzione di protezione dei dati sicura e facile da gestire per i dati applicativi residenti in VMware Cloud.</block>
  <block id="825bcb57c4a920b6ec1b4c96c593210a" category="paragraph">Per ulteriori informazioni sulle tecnologie presentate in questa soluzione, fare riferimento alle seguenti informazioni aggiuntive.</block>
  <block id="391429dd9e1e9b2ff88f428c7b849eb7" category="list-text"><block ref="391429dd9e1e9b2ff88f428c7b849eb7" category="inline-link-rx"></block></block>
  <block id="b7d636e1b78edc933a4c14acff575931" category="list-text"><block ref="d130370c3ed147d52bd7d669d0f774b8" category="inline-link-rx"></block></block>
  <block id="1e0561f6acd458eaa1243b2cd1f781e1" category="inline-link">Supporto di VMware Cloud su AWS. Considerazioni e limitazioni</block>
  <block id="2d57bbd81ef9a580a0f2d6b36c8d86c2" category="list-text"><block ref="2d57bbd81ef9a580a0f2d6b36c8d86c2" category="inline-link-rx"></block></block>
  <block id="cd39f47230bb959e72acb3eb9e5be469" category="paragraph">Questa soluzione include tecnologie innovative di NetApp, VMware, Amazon Web Services (AWS) e Veeeam.</block>
  <block id="ded9cd19cde727f824d72e3ad8ef7662" category="example-title">VMware Cloud Foundation</block>
  <block id="66c9de10f8f96cbfebae805c8a5d0c23" category="paragraph">La piattaforma VMware Cloud Foundation integra diverse offerte di prodotti che consentono agli amministratori di eseguire il provisioning di infrastrutture logiche in un ambiente eterogeneo. Queste infrastrutture (note come domini) forniscono operazioni coerenti tra cloud pubblici e privati. Il software Cloud Foundation è corredato da una distinta materiali che identifica i componenti pre-validati e qualificati per ridurre i rischi per i clienti e semplificare l'implementazione.</block>
  <block id="6fa493c0540d656a06e5bc7de182aa5d" category="paragraph">I componenti della distinta materiali di Cloud Foundation includono quanto segue:</block>
  <block id="ea712de8051099e742f7b2832804bbe4" category="list-text">Cloud Builder</block>
  <block id="719175eb8771501a012c6d964c29be69" category="list-text">Gestore SDDC</block>
  <block id="beb9456af324db48fa76084e755d8d0b" category="list-text">Appliance server VMware vCenter</block>
  <block id="f7eea647714641318ee86fedbbed4691" category="list-text">VMware ESXi</block>
  <block id="4ef3d5ade4e00a1767e0cb9da8f6a895" category="list-text">NSX VMware</block>
  <block id="8b1198108d735d15d15ede582012a434" category="list-text">VRealize Automation</block>
  <block id="ea7e7011cc6c20fceefe3f63a6f66b73" category="list-text">VRealize Suite Lifecycle Manager</block>
  <block id="7b0dffec85c977f50577ae9e44323ccc" category="list-text">VRealize Log Insight</block>
  <block id="9170490ac213e0fff83de34c7e91bcae" category="inline-link">Documentazione di VMware Cloud Foundation</block>
  <block id="d48b3b75cdd9d69e243c551b712f75e8" category="paragraph">Per ulteriori informazioni su VMware Cloud Foundation, vedere<block ref="c470e518572535c6a48639b6f7d6e5a7" category="inline-link-rx"></block>.</block>
  <block id="776e392281968fc227c904b7efb2c82d" category="paragraph">VMware vSphere è una piattaforma di virtualizzazione che trasforma le risorse fisiche in pool di calcolo, rete e storage che possono essere utilizzati per soddisfare i requisiti applicativi e di carico di lavoro dei clienti. I componenti principali di VMware vSphere includono:</block>
  <block id="ef424b79c70de97da1b97dc4f12fadee" category="list-text">*ESXi.* questo hypervisor VMware consente l'astrazione di processori di calcolo, memoria, rete e altre risorse e le rende disponibili per macchine virtuali e carichi di lavoro container.</block>
  <block id="b061e8a5ed8a3a3c319736ff70d51a55" category="list-text">*VCenter.* VMware vCenter crea un'esperienza di gestione centralizzata per interagire con risorse di calcolo, networking e storage come parte dell'infrastruttura virtuale.</block>
  <block id="d42d5a3f8818d925febb1ccce5b5ea10" category="paragraph">I clienti realizzano il pieno potenziale del proprio ambiente vSphere utilizzando NetApp ONTAP con una profonda integrazione dei prodotti, un supporto affidabile e potenti funzionalità ed efficienze dello storage per creare un solido multi-cloud ibrido.</block>
  <block id="841d75538dc45858ed53ac16358cc7ad" category="paragraph">Per ulteriori informazioni su VMware vSphere, seguire<block ref="e516b39e5a9a3597e0dc419e086e5395" category="inline-link-rx"></block>.</block>
  <block id="95d57daea7acbc2a7bbae6ded68ee952" category="paragraph">Per ulteriori informazioni sulle soluzioni NetApp con VMware, seguire<block ref="3137e9e57f0cd434b880b626db7b2f62" category="inline-link-rx"></block>.</block>
  <block id="3c7164d9420b263a215271d6db617f2b" category="paragraph">Comunemente chiamato hypervisor di rete, VMware NSX utilizza un modello software-defined per connettere i carichi di lavoro virtualizzati. VMware NSX è onnipresente on-premise e in VMware Cloud su AWS, dove potenzia la virtualizzazione e la sicurezza di rete per le applicazioni e i carichi di lavoro dei clienti.</block>
  <block id="0b044c7db1e40b4d475fb5b8e225f65e" category="paragraph">Per ulteriori informazioni su VMware NSX, seguire<block ref="24474a71eda89537e8233714a7d94cc5" category="inline-link-rx"></block>.</block>
  <block id="1299e00bdf464c0bee14fc2f6aab0f37" category="paragraph">Il software NetApp ONTAP è da quasi vent'anni una soluzione di storage leader per gli ambienti VMware vSphere e continua ad aggiungere funzionalità innovative per semplificare la gestione e ridurre i costi. L'utilizzo di ONTAP insieme a vSphere è un'ottima combinazione che consente di ridurre le spese relative all'hardware host e al software VMware. Puoi anche proteggere i tuoi dati a costi inferiori con performance elevate e costanti sfruttando al contempo l'efficienza dello storage nativo.</block>
  <block id="00f8f930135e2662dd01e1e4fc65ec48" category="paragraph">Per ulteriori informazioni su NetApp ONTAP, seguire<block ref="2fb3b932a008429024fefba27ce7f6c0" category="inline-link-rx"></block>.</block>
  <block id="cc1cc96c6bd7a597d867c658bca3b7d2" category="example-title">Strumenti NetApp ONTAP per VMware</block>
  <block id="f19b4defe5bd521861bd47f062cab40e" category="paragraph">I tool ONTAP per VMware combinano diversi plug-in in una singola appliance virtuale che offre una gestione del ciclo di vita end-to-end per le macchine virtuali in ambienti VMware che utilizzano sistemi storage NetApp. I tool ONTAP per VMware includono:</block>
  <block id="dd167aeb5a59f14930ce90d7b32a1310" category="list-text">*Virtual Storage Console (VSC).* esegue attività amministrative complete per macchine virtuali e datastore utilizzando lo storage NetApp.</block>
  <block id="caba40f1f4e68f7405c7405bbdf4067a" category="list-text">*Il provider VASA per ONTAP.* abilita la gestione basata su policy di storage (SPBM) con volumi virtuali VMware (vVol) e storage NetApp.</block>
  <block id="52d97a7fde4d2984a3335c87380d5ab4" category="list-text">*Storage Replication Adapter (SRA)*. Ripristina datastore e macchine virtuali di vCenter in caso di guasto se abbinati a VMware Site Recovery Manager (SRM).</block>
  <block id="829e52698f21d046badfc12c5846a723" category="paragraph">I tool ONTAP per VMware consentono agli utenti di gestire non solo lo storage esterno, ma anche di integrarsi con vVol e con VMware Site Recovery Manager. In questo modo, è molto più semplice implementare e utilizzare lo storage NetApp dall'interno dell'ambiente vCenter.</block>
  <block id="88d6ca70545898ecc8709b701555225b" category="paragraph">Per ulteriori informazioni sui tool NetApp ONTAP per VMware, fai clic qui<block ref="c1c4ef8e79ad3b0cab24049eb01885be" category="inline-link-rx"></block>.</block>
  <block id="805c9517e95d3e9efc4b46738ab825fc" category="example-title">NetApp SnapCenter</block>
  <block id="de29da4940709c9f9b03e3d597dcb7cd" category="paragraph">Il software NetApp SnapCenter è una piattaforma aziendale di facile utilizzo per coordinare e gestire in modo sicuro la protezione dei dati tra applicazioni, database e file system. SnapCenter semplifica il backup, il ripristino e la gestione del ciclo di vita dei cloni trasferendo queste attività ai proprietari delle applicazioni senza sacrificare la capacità di supervisionare e regolare l'attività sui sistemi storage. Sfruttando la gestione dei dati basata sullo storage, SnapCenter aumenta le performance e la disponibilità e riduce i tempi di test e sviluppo.</block>
  <block id="a1f54fde77874bbd5be133ca3970d7e8" category="paragraph">Il plug-in SnapCenter per VMware vSphere supporta operazioni di backup e ripristino coerenti con le macchine virtuali (VM), datastore e dischi delle macchine virtuali (VMDK). Supporta inoltre i plug-in specifici dell'applicazione SnapCenter per proteggere le operazioni di backup e ripristino coerenti con l'applicazione per i database e i file system virtualizzati.</block>
  <block id="f655858b5e82a216de5b6aea071de457" category="paragraph">Per ulteriori informazioni su NetApp SnapCenter, seguire<block ref="aa600981aea381f09908ce10e8269417" category="inline-link-rx"></block>.</block>
  <block id="98c2040e71eaa6795dfe7287a8c6ad93" category="section-title">Protezione dei dati di terze parti</block>
  <block id="ed8b9b5c064b716d4c1d3f30a595410f" category="example-title">&amp;Amp; Replication di Veeam Backup</block>
  <block id="a03670ab805efda6af1029d0cc6ed56e" category="paragraph">Veeam Backup &amp; Replication è una soluzione di backup, recovery e gestione dei dati per carichi di lavoro cloud, virtuali e fisici. Veeam Backup &amp; Replication offre integrazioni specializzate con la tecnologia Snapshot di NetApp che proteggono ulteriormente gli ambienti vSphere.</block>
  <block id="a174e33a347bdf86d254ef6b64ebb844" category="paragraph">Per ulteriori informazioni su Veeam Backup &amp; Replication, seguire<block ref="ff5498b1e93a9fbc10c4f9b6c05db801" category="inline-link-rx"></block>.</block>
  <block id="e1d618f208de1e0652f995ea9ef70c8a" category="example-title">Gestione delle identità e degli accessi AWS</block>
  <block id="72e3b385ab9dce0490acd4320d69b190" category="paragraph">Gli ambienti AWS contengono una vasta gamma di prodotti, tra cui calcolo, storage, database, rete, analytics, e molto altro ancora per risolvere le sfide aziendali. Le aziende devono essere in grado di definire chi è autorizzato ad accedere a questi prodotti, servizi e risorse. È altrettanto importante determinare in quali condizioni gli utenti possono manipolare, modificare o aggiungere configurazioni.</block>
  <block id="e0371101cd60437f116ae662823d656b" category="paragraph">AWS Identity and Access Management (AIM) fornisce un piano di controllo sicuro per la gestione dell'accesso ai servizi e ai prodotti AWS. Utenti, chiavi di accesso e autorizzazioni configurati correttamente consentono l'implementazione di VMware Cloud su AWS e Amazon FSX.</block>
  <block id="f97bd254f4560b300dffc1c8320c079a" category="paragraph">Per ulteriori informazioni su AIM, seguire<block ref="51dd129a9a709f0af102f91347214719" category="inline-link-rx"></block>.</block>
  <block id="f93a7ad035f2ab23b92d7f904c204a67" category="paragraph">VMware Cloud su AWS porta il software SDDC di livello Enterprise di VMware su AWS Cloud con accesso ottimizzato ai servizi AWS nativi. Basato su VMware Cloud Foundation, VMware Cloud su AWS integra i prodotti di calcolo, storage e virtualizzazione di rete di VMware (VMware vSphere, VMware vSAN e VMware NSX) insieme alla gestione di VMware vCenter Server ottimizzata per l'esecuzione su un'infrastruttura AWS bare-metal flessibile e dedicata.</block>
  <block id="21b9508ecf23f768b8172f58ec935a32" category="paragraph">Per ulteriori informazioni su VMware Cloud su AWS, seguire<block ref="2fb3b932a008429024fefba27ce7f6c0" category="inline-link-rx"></block>.</block>
  <block id="5588d719a2e52cc2437eac404a5afac6" category="paragraph">Amazon FSX per NetApp ONTAP è un sistema ONTAP completo e completamente gestito, disponibile come servizio AWS nativo. Basato su NetApp ONTAP, offre funzionalità familiari offrendo la semplicità di un servizio cloud completamente gestito.</block>
  <block id="4f706209d760c6b9c796b171e747ba84" category="paragraph">Amazon FSX per ONTAP offre il supporto multiprotocollo per una varietà di tipi di calcolo, tra cui VMware nel cloud pubblico o on-premise. Disponibile oggi per i casi di utilizzo connessi agli ospiti e per gli archivi dati NFS in anteprima tecnologica, Amazon FSX per ONTAP consente alle aziende di sfruttare le funzionalità familiari dei propri ambienti on-premise e nel cloud.</block>
  <block id="97461b19a572ee6589bfdc8bb87cf344" category="paragraph">Per ulteriori informazioni su Amazon FSX per NetApp ONTAP, fai clic qui<block ref="8010f27a5d53263c1742228bc262a2e3" category="inline-link-rx"></block>.</block>
  <block id="bd6d688efed13ace07c5656a3de04479" category="section-title">Panoramica - Disaster Recovery dello storage AWS connesso agli ospiti</block>
  <block id="67b5a180b1adfc09bd2752e51613fea5" category="paragraph">Questa sezione fornisce istruzioni per aiutare gli utenti a verificare, configurare e validare i propri ambienti on-premise e cloud per l'utilizzo con NetApp e VMware. In particolare, questa soluzione si concentra sul caso di utilizzo VMware connesso a guest con ONTAP AFF on-premise e VMware Cloud e AWS FSX ONTAP per il cloud. Questa soluzione viene dimostrata con due applicazioni: Oracle e MS SQL in uno scenario di disaster recovery.</block>
  <block id="0b55c8177ba39a322f35975c0c3bd3ba" category="example-title">Competenze e conoscenze</block>
  <block id="b1adf7ef88c9564fb1f6c97bf42dca5c" category="paragraph">Per accedere a Cloud Volumes Service per AWS sono necessarie le seguenti competenze e informazioni:</block>
  <block id="7b83d82f99126fdb6efaa234f31683f5" category="list-text">Accesso e conoscenza dell'ambiente VMware e ONTAP on-premise.</block>
  <block id="39a8abb00c1f9d982e3a29b4baec67f2" category="list-text">Accesso e conoscenza di VMware Cloud e AWS.</block>
  <block id="eaad72d3a50e4be3e11d36792eb96d62" category="list-text">Accesso e conoscenza di AWS e Amazon FSX ONTAP.</block>
  <block id="25e65b652ca97821fa49aa9571b2b54a" category="list-text">Conoscenza delle risorse SDDC e AWS.</block>
  <block id="18334368a9f4fce73ca297bdd4be123a" category="list-text">Conoscenza della connettività di rete tra le risorse on-premise e cloud.</block>
  <block id="f917b7afd251e67bbdf50fa466a9918e" category="list-text">Conoscenza pratica degli scenari di disaster recovery.</block>
  <block id="77d0638c77df28bd77c058b3da580702" category="list-text">Conoscenza operativa delle applicazioni implementate su VMware.</block>
  <block id="9ef15415f400d1d1a7b2c4d3e8879124" category="example-title">Amministrativo</block>
  <block id="99be46c7a7d783d36552f0f11df8cd5e" category="paragraph">Sia che interagiscano con le risorse on-premise o nel cloud, gli utenti e gli amministratori devono avere la capacità e i diritti necessari per eseguire il provisioning delle risorse dove servono, quando necessario, in base ai diritti. L'interazione dei tuoi ruoli e permessi per i tuoi sistemi on-premise, tra cui ONTAP e VMware, e le tue risorse cloud, tra cui VMware Cloud e AWS, è fondamentale per un'implementazione di cloud ibrido di successo.</block>
  <block id="e5d4baff0167d033367d67396f5608f6" category="paragraph">Per creare una soluzione di DR con VMware e ONTAP on-premise e VMware Cloud su AWS e FSX ONTAP, è necessario eseguire le seguenti attività amministrative.</block>
  <block id="e6833d473d476a99c7ec8095a5bfe8df" category="list-text">Ruoli e account che consentono il provisioning dei seguenti elementi:</block>
  <block id="297c8005623a7f22aad3d141e82fabb5" category="list-text">Risorse di storage ONTAP</block>
  <block id="864d5ea26def3831e53731dc58671672" category="list-text">Macchine virtuali VMware, datastore e così via</block>
  <block id="61b883742c54e0000affbbf61cecb00a" category="list-text">AWS VPC e gruppi di sicurezza</block>
  <block id="cae667335742a0f5e8a41bb0caa73e4c" category="list-text">Provisioning dell'ambiente VMware on-premise e di ONTAP</block>
  <block id="7098bf260c6533f1ebf70f5b9bb041b0" category="list-text">Ambiente cloud VMware</block>
  <block id="eca5f84e846df7323fccde83f4ff44d5" category="list-text">Un file system Amazon per FSX per ONTAP</block>
  <block id="29b34be64d30233d5ed6d4f314db7483" category="list-text">Connettività tra il tuo ambiente on-premise e AWS</block>
  <block id="c89c49a63ff46b95a3a1930093133477" category="list-text">Connettività per AWS VPC</block>
  <block id="9301a9f205ba883a750d8c90b33c2bbc" category="paragraph">L'ambiente virtuale VMware include licenze per host ESXi, VMware vCenter Server, reti NSX e altri componenti, come illustrato nella figura seguente. Tutte le licenze sono diverse ed è importante comprendere come i componenti sottostanti consumano la capacità disponibile concessa in licenza.</block>
  <block id="c99ec32d06b1f19699d82b1b34a80ca0" category="paragraph"><block ref="c99ec32d06b1f19699d82b1b34a80ca0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="42094e9e4a0f05012b8d6753300a1657" category="example-title">Host ESXi</block>
  <block id="1d50ac197ef032b2bc2e46d8e2e64598" category="paragraph">Gli host di calcolo in un ambiente VMware vengono implementati con ESXi. Se concesso in licenza con vSphere a diversi livelli di capacità, le macchine virtuali possono sfruttare le CPU fisiche di ciascun host e le funzionalità pertinenti.</block>
  <block id="43e02e05b2879c1406a010bf6a28f8f7" category="example-title">VMware vCenter</block>
  <block id="05f79f8867c02153173be8abc21ae61a" category="paragraph">La gestione degli host e dello storage ESXi è una delle numerose funzionalità messe a disposizione dell'amministratore VMware con vCenter Server. A partire da VMware vCenter 7.0, sono disponibili tre edizioni di VMware vCenter, a seconda della licenza:</block>
  <block id="f958b6a3f3407168711a82d395fb4ac7" category="list-text">VCenter Server Essentials</block>
  <block id="a0301fdeb61b558341af142a9f2dd3aa" category="list-text">VCenter Server Foundation</block>
  <block id="62a846eee92143dee42cae576208c443" category="list-text">VCenter Server Standard</block>
  <block id="e44df2b6e256fb033bf0234d942a29f3" category="paragraph">VMware NSX offre agli amministratori la flessibilità necessaria per abilitare funzionalità avanzate. Le funzioni sono abilitate a seconda della versione di NSX-T Edition concessa in licenza:</block>
  <block id="9e8b160226c9fe22a910c782ce5076e2" category="list-text">Professionale</block>
  <block id="9b6545e4cea9b4ad4979d41bb9170e2b" category="list-text">Avanzato</block>
  <block id="1330271d87fae19afa4e7be5cd94b9f8" category="list-text">Sede remota/filiale</block>
  <block id="88793829da8796f676eaebd57e42009d" category="paragraph">Licensing with NetApp ONTAP si riferisce al modo in cui gli amministratori possono accedere a varie funzionalità e funzionalità dello storage NetApp. Una licenza è un record di una o più autorizzazioni software. L'installazione delle chiavi di licenza, note anche come codici di licenza, consente di utilizzare determinate funzioni o servizi sul sistema storage. Ad esempio, ONTAP supporta tutti i principali protocolli client standard di settore (NFS, SMB, FC, FCoE, iSCSI, E NVMe/FC) attraverso le licenze.</block>
  <block id="90a29bf269cfe6c256d42b29776d14dd" category="paragraph">Le licenze delle funzionalità di Data ONTAP vengono rilasciate come pacchetti, ciascuno dei quali contiene più funzionalità o una singola funzionalità. Un pacchetto richiede una chiave di licenza e l'installazione della chiave consente di accedere a tutte le funzionalità del pacchetto.</block>
  <block id="e4b843c32b9db50414c1dfbad0c4d1c0" category="paragraph">I tipi di licenza sono i seguenti:</block>
  <block id="0f00a6a817b378adf16de8d25fbf24fa" category="list-text">*Licenza Node-Locked.* l'installazione di una licenza Node-Locked dà diritto a un nodo alla funzionalità concessa in licenza. Affinché il cluster utilizzi la funzionalità concessa in licenza, è necessario che almeno un nodo sia concesso in licenza per tale funzionalità.</block>
  <block id="52db1a3edfedfc7015c35209e22f04c2" category="list-text">*Licenza master/sito.* Una licenza master o di sito non è legata a un numero seriale di sistema specifico. Quando si installa una licenza di sito, tutti i nodi del cluster hanno diritto alla funzionalità concessa in licenza.</block>
  <block id="b2aa6f86c442a3ce1bedb4a83498fcc6" category="list-text">*Licenza demo/temporanea.* Una licenza demo o temporanea scade dopo un certo periodo di tempo. Questa licenza consente di provare alcune funzionalità software senza acquistare alcun diritto.</block>
  <block id="c6009ee65fbe56a5eed91a0a06f3a1b5" category="list-text">*Licenza di capacità (solo ONTAP Select e FabricPool).* un'istanza di ONTAP Select viene concessa in licenza in base alla quantità di dati che l'utente desidera gestire. A partire da ONTAP 9.4, FabricPool richiede una licenza di capacità da utilizzare con un Tier di storage di terze parti (ad esempio, AWS).</block>
  <block id="13b92bafad23a87622890420ed0b860b" category="paragraph">SnapCenter richiede diverse licenze per abilitare le operazioni di protezione dei dati. Il tipo di licenze SnapCenter installate dipende dall'ambiente di storage e dalle funzionalità che si desidera utilizzare. La licenza standard SnapCenter protegge applicazioni, database, file system e macchine virtuali. Prima di aggiungere un sistema storage a SnapCenter, è necessario installare una o più licenze SnapCenter.</block>
  <block id="c2aa46e5e57aae7e4f4c969c417f1238" category="paragraph">Per consentire la protezione di applicazioni, database, file system e macchine virtuali, è necessario disporre di una licenza basata su controller standard installata sul sistema di storage FAS o AFF o di una licenza basata sulla capacità standard installata sulle piattaforme ONTAP Select e Cloud Volumes ONTAP.</block>
  <block id="14c2700881a435ad41069af9e8ee6f85" category="paragraph">Per questa soluzione, consultare i seguenti prerequisiti per il backup di SnapCenter:</block>
  <block id="96b3493b2e1844322d28e845c314e10b" category="list-text">Un volume e una condivisione SMB creati sul sistema ONTAP on-premise per individuare i file di database e di configurazione di cui è stato eseguito il backup.</block>
  <block id="f39931d0fa94c8e0cb577222f77fb09d" category="list-text">Una relazione SnapMirror tra il sistema ONTAP on-premise e FSX o CVO nell'account AWS. Utilizzato per trasportare lo snapshot contenente il database SnapCenter di cui è stato eseguito il backup e i file di configurazione.</block>
  <block id="d2727816fa1087ddac7dff69e35c5536" category="example-title">MS SQL</block>
  <block id="f9e005542c2e103eede9db2dfe82bdc7" category="paragraph">Come parte della convalida di questa soluzione, utilizziamo MS SQL per dimostrare il disaster recovery.</block>
  <block id="ed94f710e6ae715e2f17c5670d6bf092" category="paragraph">Per ulteriori informazioni sulle Best practice relative a MS SQL e NetApp ONTAP, seguire questa procedura<block ref="1ed6e40008e985821d1338a60f7ccab3" category="inline-link-rx"></block>.</block>
  <block id="30162ed78b6c10f731411f2fc440c24f" category="example-title">Oracle</block>
  <block id="877ee5bcf7f0335c93ce9f231f44f195" category="paragraph">Come parte della convalida di questa soluzione, utilizziamo ORACLE per dimostrare il disaster recovery. Per ulteriori informazioni sulle Best practice relative A ORACLE e NetApp ONTAP, seguire questa procedura<block ref="3b13b5361a3a7b7e48b79b29a907e9fc" category="inline-link-rx"></block>.</block>
  <block id="05241239c2e205951eabc51d0b39de96" category="example-title">Veeam</block>
  <block id="cf575d98d37c3423857f91c318d883e7" category="paragraph">Come parte della convalida di questa soluzione, utilizziamo Veeam per dimostrare il disaster recovery. Per ulteriori informazioni sulle Best practice relative a Veeam e NetApp ONTAP, seguire<block ref="69659c9961c1e42b0f8742562f24fdfa" category="inline-link-rx"></block>.</block>
  <block id="59288c543af9b26fa84b24054d3be8dc" category="paragraph">È necessario essere in grado di eseguire le seguenti attività:</block>
  <block id="f35a1ddfb2f9b2cac114bd32ce5bbbab" category="list-text">Implementare e configurare i servizi di dominio.</block>
  <block id="71877c1e84cfa72072c46494d86a8ee7" category="list-text">Implementazione di FSX ONTAP in base ai requisiti dell'applicazione in un determinato VPC.</block>
  <block id="9135a2c6ac5c27bd10c50337c5a89f26" category="list-text">Configurare VMware Cloud sul gateway di calcolo AWS per consentire il traffico da FSX ONTAP.</block>
  <block id="8a401f5d4b33a44bd1812ff7ead2248d" category="list-text">Configurare un gruppo di sicurezza AWS per consentire la comunicazione tra VMware Cloud sulle subnet AWS alle subnet AWS VPC in cui viene implementato il servizio FSX ONTAP.</block>
  <block id="2e31cdf7daad1ca06d6642765fa13252" category="example-title">VMware Cloud</block>
  <block id="f7f38aee276941a8501ab3a4788fb838" category="list-text">Configurare VMware Cloud su AWS SDDC.</block>
  <block id="08aa379cc2bcb108397d323bd5732f6c" category="example-title">Verifica dell'account Cloud Manager</block>
  <block id="17d24c2f3d504e509ec34ba87bfea6a5" category="paragraph">Devi essere in grado di implementare le risorse con NetApp Cloud Manager. Per verificare che sia possibile, completare le seguenti attività:</block>
  <block id="2ee5d6132c6433861745857e6af68778" category="inline-link">Iscriviti a Cloud Central</block>
  <block id="604e59aa26a0b211909e4b9590685eb1" category="list-text"><block ref="35c2f2ba3f068c3df62b94b779d38cce" category="inline-link-rx"></block> se non lo hai già fatto.</block>
  <block id="e7ef0ccc08f963a97d6ab9c3aabc5081" category="inline-link">Accedere a Cloud Manager</block>
  <block id="5ec677c5c014e60203e82de8cbed20e4" category="list-text"><block ref="77549d8461eff5ea7726f72f7e171b7c" category="inline-link-rx"></block>.</block>
  <block id="78e80a35b7d01f404398eea432dd9654" category="inline-link">Configurare aree di lavoro e utenti</block>
  <block id="6693afd5aef7c87168fb40b34d61e795" category="list-text"><block ref="491866e862424f2a10f9441373484bc0" category="inline-link-rx"></block>.</block>
  <block id="e7a9cd1dc4bf0c230d0684e18369d70d" category="inline-link">Creare un connettore</block>
  <block id="821d88deb5e031a9587e5a8e00abe556" category="list-text"><block ref="b3797d3b448c35004d47db91b5cf65cf" category="inline-link-rx"></block>.</block>
  <block id="4c0f2b07e3034da6a2b901197cec7210" category="paragraph">Una volta ottenuto un account AWS, è necessario essere in grado di eseguire la seguente attività:</block>
  <block id="7d8207e3bfa061fd6c5b1389d79e23e4" category="list-text">Creare un utente amministrativo IAM in grado di fornire Amazon FSX per il file system NetApp ONTAP.</block>
  <block id="7984cdcb84b94f3ec5af3c2aa0bc9f9c" category="example-title">Prerequisiti di configurazione</block>
  <block id="799b279302dc2106f49a0c61994a42a1" category="paragraph">Date le diverse topologie dei clienti, questa sezione si concentra sulle porte necessarie per consentire la comunicazione dalle risorse on-premise alle risorse cloud.</block>
  <block id="dee55c33a91e43d371aa8eab0ee8968e" category="example-title">Considerazioni su porte e firewall richiesti</block>
  <block id="34e0f9db6d0a94f20e464420fb481570" category="paragraph">Le seguenti tabelle descrivono le porte che devono essere attivate in tutta l'infrastruttura.</block>
  <block id="28c5fdd36289c2258f08118f41c54729" category="paragraph">Per un elenco più completo delle porte richieste per il software Veeam Backup &amp; Replication, seguire questa procedura<block ref="2a9b4a1873abbc6819ad7073e9ebc1a5" category="inline-link-rx"></block>.</block>
  <block id="2a975bb27423e33e6c65cb2e2b14db28" category="paragraph">Per un elenco più completo dei requisiti delle porte per SnapCenter, segui questa procedura<block ref="4939c26301b3a22bfb3c0a6725311b88" category="inline-link-rx"></block>.</block>
  <block id="8a042a39d5b3b0e7e0554c5af7abd76b" category="paragraph">La seguente tabella elenca i requisiti della porta Veeam per Microsoft Windows Server.</block>
  <block id="5da618e8e4b89c66fe86e32cdafde142" category="cell">Da</block>
  <block id="e12167aa0a7698e6ebc92b4ce3909b53" category="cell">A.</block>
  <block id="60aaf44d4b562252c04db7f98497e9aa" category="cell">Porta</block>
  <block id="f4c6f851b00d5518bf888815de279aba" category="cell">Note</block>
  <block id="52045ab804b1b913874ef04c2c3a2f69" category="cell">Server di backup</block>
  <block id="de6900dd0f213be9d369252ce490a1df" category="cell">Server Microsoft Windows</block>
  <block id="b136ef5f6a01d816991fe3cf7a6ac763" category="cell">TCP</block>
  <block id="67f7fb873eaf29526a11a9b7ac33bfac" category="cell">445</block>
  <block id="3f8c4ba1591441de01c30814d6be96cb" category="cell">Porta richiesta per l'implementazione dei componenti di backup e replica di Veeam.</block>
  <block id="a34fcb59deecb10582ae58c505df58ba" category="cell">Proxy di backup</block>
  <block id="fa3060edb66e6ff4507886f9912e1ab9" category="cell">6160</block>
  <block id="a615435ab6eb1aac4a4b4c4ebe2a89e9" category="cell">Porta predefinita utilizzata dal servizio di installazione Veeam.</block>
  <block id="480ddf908a09bb49e2eb46b2293d83e0" category="cell">Repository di backup</block>
  <block id="84c456c47f1859be98a88fa53ffca994" category="cell">da 2500 a 3500</block>
  <block id="1622c3ddec12802a4bc6cbb96c7b1b49" category="cell">Intervallo predefinito di porte utilizzate come canali di trasmissione dei dati e per la raccolta dei file di log.</block>
  <block id="a31f402016255891ea5a6010567d0c28" category="cell">Montare il server</block>
  <block id="6aaba9a124857622930ca4e50f5afed2" category="cell">6162</block>
  <block id="f36e2d75f4071e4e994fdbc77c14ddb0" category="cell">Porta predefinita utilizzata da Veeam Data Mover.</block>
  <block id="510f315f3436af1e5ec4cb22dd263070" category="admonition">Per ogni connessione TCP utilizzata da un lavoro, viene assegnata una porta di questo intervallo.</block>
  <block id="655a5fe10451fb66645cbcdec5034698" category="paragraph">La seguente tabella elenca i requisiti della porta Veeam per Linux Server.</block>
  <block id="b5d9f1a9fbf0fb75f6765f140eb5774f" category="cell">Server Linux</block>
  <block id="28c991d1c426febedd1596fd29a3f864" category="cell">Porta utilizzata come canale di controllo dalla console all'host Linux di destinazione.</block>
  <block id="a4fda10bbaa8015596c2c1c1dd6f1a36" category="paragraph">La seguente tabella elenca i requisiti delle porte di Veeam Backup Server.</block>
  <block id="4197adf45342f775880cf0b40b2bebe4" category="cell">HTTPS, TCP</block>
  <block id="ff48f6174c8c54c3faa04ebcf25b720d" category="cell">Porta predefinita utilizzata per le connessioni a vCenter Server. Porta utilizzata come canale di controllo dalla console all'host Linux di destinazione.</block>
  <block id="dad95acf5318650271f0853ca3c36a1a" category="cell">Microsoft SQL Server che ospita il database di configurazione di Veeeam Backup &amp; Replication</block>
  <block id="8fb5f8be2aa9d6c64a04e3ab9f63feee" category="cell">1443</block>
  <block id="dc0848552680aa2839c317b54853b6c8" category="cell">Porta utilizzata per la comunicazione con Microsoft SQL Server su cui è distribuito il database di configurazione di Veeeam Backup &amp; Replication (se si utilizza un'istanza predefinita di Microsoft SQL Server).</block>
  <block id="1cdaa0286d1e5b2da16bb4a4d56030e5" category="cell">Server DNS con risoluzione dei nomi di tutti i server di backup</block>
  <block id="8643c8e2107ba86c47371e037059c4b7" category="cell">3389</block>
  <block id="2914ea759530f85f84d8d97088f4c0fb" category="cell">Porta utilizzata per la comunicazione con il server DNS</block>
  <block id="462cb0982d9c6d8b64cd1a92197cad0e" category="admonition">Se si utilizza vCloud Director, assicurarsi di aprire la porta 443 sui server vCenter sottostanti.</block>
  <block id="5fd55c0224ae845943b259eaa37fa9de" category="paragraph">La seguente tabella elenca i requisiti della porta del proxy di backup Veeam.</block>
  <block id="e564618b1a0f9a0e5b043f63d43fc065" category="cell">6210</block>
  <block id="06c6eec6c18e0d75ea5c6853a2397d90" category="cell">Porta predefinita utilizzata da Veeam Backup VSS Integration Service per l'acquisizione di uno snapshot VSS durante il backup della condivisione file SMB.</block>
  <block id="dd46e35ec3bd7632e2b6924b4ace5592" category="cell">Porta del servizio Web VMware predefinita che può essere personalizzata nelle impostazioni di vCenter.</block>
  <block id="67f0bc6c760260e8ecb1e44fc5337bd6" category="paragraph">La seguente tabella elenca i requisiti delle porte SnapCenter.</block>
  <block id="bd9f125b279a19f0d5b7f09c7d793d35" category="cell">Tipo di porta</block>
  <block id="d7ca8612b857419959ee2c089e5be08c" category="cell">Porta di gestione SnapCenter</block>
  <block id="0e8433f9a404f1f3ba601c14b026d321" category="cell">HTTPS</block>
  <block id="202ed3792e2cfa7318b12ead83763c37" category="cell">8146</block>
  <block id="a1a3a7ab0e2e0b654e17bb8a2e57e9e5" category="cell">Questa porta viene utilizzata per la comunicazione tra il client SnapCenter (l'utente SnapCenter) e il server SnapCenter. Utilizzato anche per la comunicazione dagli host plug-in al server SnapCenter.</block>
  <block id="18622e175ff22b2375f9cbc2314b3285" category="cell">Porta di comunicazione SMCore SnapCenter</block>
  <block id="bb68b5529560433e58ff13eb45622724" category="cell">Questa porta viene utilizzata per la comunicazione tra il server SnapCenter e gli host in cui sono installati i plug-in SnapCenter.</block>
  <block id="f79093a340ccf8139d6e585381acc44c" category="cell">Host plug-in Windows, installazione</block>
  <block id="a1639b6147c7f85402852464ce33b9ae" category="cell">135, 445</block>
  <block id="4b790f3dbcd2d867091d8fbf3b63026f" category="cell">Queste porte vengono utilizzate per la comunicazione tra il server SnapCenter e l'host in cui viene installato il plug-in. Le porte possono essere chiuse dopo l'installazione. Inoltre, i servizi di strumentazione di Windows ricercano le porte da 49152 a 65535, che devono essere aperte.</block>
  <block id="da8fa0760683502b8b15e2d8f992b780" category="cell">Host plug-in Linux, installazione</block>
  <block id="765553e6c7ac8592c389acb9878a050a" category="cell">SSH</block>
  <block id="e541d805fe886aded7cfb18984fba335" category="cell">Queste porte vengono utilizzate per la comunicazione tra il server SnapCenter e l'host in cui viene installato il plug-in. Le porte vengono utilizzate da SnapCenter per copiare i binari dei pacchetti plug-in su host plug-in Linux.</block>
  <block id="8ffa3ad47599004a1c67f905da7456c0" category="cell">Pacchetto plug-in SnapCenter per Windows/Linux</block>
  <block id="0c0cfd9478c6551fbfe74a7acb6fc037" category="cell">8145</block>
  <block id="9b52abdc2eaa620c3f1c7588679b8764" category="cell">Questa porta viene utilizzata per la comunicazione tra SMCore e gli host in cui sono installati i plug-in SnapCenter.</block>
  <block id="7c1239972879fe0b69b4bb6d5c9a743e" category="cell">Porta di VMware vSphere vCenter Server</block>
  <block id="4047860556fa008e56adfadd36f5b7af" category="cell">Questa porta viene utilizzata per la comunicazione tra il plug-in SnapCenter per VMware vSphere e il server vCenter.</block>
  <block id="87db2cdf992c6481194f67a3c24f2d31" category="cell">Plug-in SnapCenter per porta VMware vSphere</block>
  <block id="397d2ce87a0d127486b8fa20c5f3cdb9" category="cell">Questa porta viene utilizzata per le comunicazioni dal client Web vCenter vSphere e dal server SnapCenter.</block>
  <block id="d4fab32948320ef14f4b14bb30559cd4" category="paragraph">Questa soluzione richiede una comunicazione di successo dal cluster ONTAP on-premise ad AWS FSX per gli indirizzi di rete del cluster di interconnessione ONTAP di NetApp per eseguire le operazioni SyncMirror di NetApp. Inoltre, un server di backup Veeam deve avere accesso a un bucket AWS S3. Invece di utilizzare il trasporto Internet, è possibile utilizzare un collegamento VPN o Direct Connect esistente come collegamento privato a un bucket S3.</block>
  <block id="c850af3ffbdd92ab67281dbdfeaf4e52" category="paragraph">ONTAP supporta tutti i principali protocolli di storage utilizzati per la virtualizzazione, tra cui iSCSI, Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) o NVMe/FC (non-volatile Memory Express over Fibre Channel) per ambienti SAN. ONTAP supporta inoltre NFS (v3 e v4.1) e SMB o S3 per le connessioni guest. È possibile scegliere i protocolli più adatti al proprio ambiente e combinare i protocolli in base alle esigenze in un singolo sistema. Ad esempio, è possibile aumentare l'utilizzo generale degli archivi dati NFS con alcune LUN iSCSI o condivisioni guest.</block>
  <block id="dc8286bc14e4eca04d5c8c3d3745e742" category="paragraph">Questa soluzione sfrutta i datastore NFS per datastore on-premise per VMDK guest e sia iSCSI che NFS per i dati delle applicazioni guest.</block>
  <block id="89cf31d317f3100637041ccf296c3421" category="example-title">Reti client</block>
  <block id="d6c8c82593995a45499a762d317c04ec" category="paragraph">Le porte di rete VMkernel e il networking software-defined forniscono connettività agli host ESXi consentendo loro di comunicare con elementi esterni all'ambiente VMware. La connettività dipende dal tipo di interfacce VMkernel utilizzate.</block>
  <block id="774cca28a02c25118dc9668598f65663" category="paragraph">Per questa soluzione, sono state configurate le seguenti interfacce VMkernel:</block>
  <block id="fe4dbcab9b910577e5035e97ac068dae" category="list-text">Gestione</block>
  <block id="31ce31cccd4aecd29ff8b40dd37b8305" category="example-title">Provisioning delle reti di storage</block>
  <block id="a09cf1d6ddb872a8c1ee517538a9373d" category="paragraph">Una LIF (interfaccia logica) rappresenta un punto di accesso di rete a un nodo del cluster. Ciò consente la comunicazione con le macchine virtuali dello storage che ospitano i dati a cui accedono i client. È possibile configurare le LIF sulle porte su cui il cluster invia e riceve le comunicazioni sulla rete.</block>
  <block id="b976c5d6eaa4fa1f606cff663f77835f" category="paragraph">Per questa soluzione, i LIF sono configurati per i seguenti protocolli di storage:</block>
  <block id="cfba851bf46ae36ca092575bba6c7289" category="example-title">Opzioni di connettività cloud</block>
  <block id="466c519a74055fba20814454ab577c83" category="paragraph">I clienti hanno molte opzioni per connettere il proprio ambiente on-premise alle risorse cloud, inclusa l'implementazione di topologie VPN o Direct Connect.</block>
  <block id="ce24b5f233dc29fc3614b2c7d961948b" category="example-title">VPN (Virtual Private Network)</block>
  <block id="55e6887f1e4e535089db85cbcae36acd" category="paragraph">Le VPN (Virtual Private Network) vengono spesso utilizzate per creare un tunnel IPSec sicuro con reti MPLS private o basate su Internet. Una VPN è facile da configurare, ma non offre affidabilità (se basata su Internet) e velocità. Il punto finale può essere terminato su AWS VPC o su VMware Cloud SDDC. Per questa soluzione di disaster recovery, abbiamo creato la connettività ad AWS FSX per NetApp ONTAP dalla rete on-premise. Pertanto, può essere terminato sul VPC AWS (gateway privato virtuale o gateway di transito) dove è connesso FSX per NetApp ONTAP.</block>
  <block id="365e9311cae767fae52a5cdba7003f9a" category="paragraph">La configurazione VPN può essere basata su routing o policy. Con una configurazione basata su route, gli endpoint si scambiano automaticamente i percorsi e la configurazione apprende il percorso verso le subnet appena create. Con un'impostazione basata su policy, è necessario definire le subnet locali e remote e, quando vengono aggiunte nuove subnet e consentite la comunicazione nel tunnel IPSec, è necessario aggiornare le route.</block>
  <block id="fb932a9cb1f7aff6a88af2645c80731e" category="admonition">Se il tunnel VPN IPSec non viene creato sul gateway predefinito, i percorsi di rete remoti devono essere definiti nelle tabelle di routing tramite il punto finale del tunnel VPN locale.</block>
  <block id="2dc9d6f2c2810edb190acfe717c84a68" category="paragraph">La figura seguente mostra le opzioni di connessione VPN tipiche.</block>
  <block id="d90d767da5b6da33c2785b3d3120c23f" category="paragraph"><block ref="d90d767da5b6da33c2785b3d3120c23f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac1fc9354c56b77f7143d2b6a7d185ad" category="example-title">Connessione diretta</block>
  <block id="4aa5340761d0794e8da7cfa5ead94eb3" category="paragraph">Direct Connect fornisce un collegamento dedicato alla rete AWS. Le connessioni dedicate creano collegamenti ad AWS utilizzando una porta Ethernet da 1 Gbps, 10 Gbps o 100 Gbps. I partner AWS Direct Connect forniscono connessioni in hosting utilizzando collegamenti di rete prestabiliti tra loro e AWS e sono disponibili da 50 Mbps fino a 10 Gbps. Per impostazione predefinita, il traffico non è crittografato. Tuttavia, sono disponibili opzioni per proteggere il traffico con MACsec o IPSec. MACsec fornisce la crittografia Layer-2, mentre IPSec fornisce la crittografia Layer-3. MACsec offre una maggiore sicurezza nascondendo quali dispositivi stanno comunicando.</block>
  <block id="f41e1aa529328c6c391ee2bbb3e7b35f" category="paragraph">I clienti devono disporre dell'apparecchiatura router in una sede AWS Direct Connect. Per configurare questa opzione, è possibile utilizzare AWS Partner Network (APN). Viene stabilita una connessione fisica tra il router e il router AWS. Per consentire l'accesso a FSX per NetApp ONTAP su VPC, è necessario disporre di un'interfaccia virtuale privata o di un'interfaccia virtuale di transito da connessione diretta a un VPC. Con un'interfaccia virtuale privata, la scalabilità della connessione Direct Connect a VPC è limitata.</block>
  <block id="aac639f893699a86dc44236deb8c2ff8" category="paragraph">La figura seguente mostra le opzioni dell'interfaccia Direct Connect.</block>
  <block id="65d0f01c0d2abb5df490f85de1a3c7f5" category="paragraph"><block ref="65d0f01c0d2abb5df490f85de1a3c7f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a547cd01b7307bbc41da8aed4983dc1" category="example-title">Gateway di transito</block>
  <block id="5789b6855d128c642555ffa55396a65c" category="inline-link">Documentazione di AWS Direct Connect</block>
  <block id="3ae6c7e3aea4c72d9bf07244d7b959e6" category="paragraph">Il gateway di transito è un modello a livello di regione che consente una maggiore scalabilità di una connessione Direct Connect-to-VPC all'interno di una regione. Se è richiesta una connessione tra regioni, i gateway di transito devono essere peering. Per ulteriori informazioni, consultare<block ref="9f2a100b6fab526146ca277977e4ef3a" category="inline-link-rx"></block>.</block>
  <block id="ac8979d211e20b50e94073d31f2e8d44" category="example-title">Considerazioni sulla rete cloud</block>
  <block id="02c5109954e68b54548d5ef777afaf76" category="paragraph">Nel cloud, l'infrastruttura di rete sottostante è gestita dal provider di servizi cloud, mentre i clienti devono gestire le reti VPC, le subnet, le tabelle di routing e così via in AWS. Devono inoltre gestire i segmenti di rete NSX all'edge del calcolo. SDDC raggruppa i percorsi per VPC esterno e Transit Connect.</block>
  <block id="ee94a9a0de351e37a54ce1fec2961c62" category="paragraph">Quando FSX per NetApp ONTAP con disponibilità multi-AZ viene implementato su un VPC connesso a VMware Cloud, il traffico iSCSI riceve gli aggiornamenti necessari della tabella di routing per abilitare la comunicazione. Per impostazione predefinita, non è disponibile alcun percorso da VMware Cloud alla subnet NFS/SMB di FSX ONTAP sul VPC connesso per l'implementazione multi-AZ. Per definire questo percorso, abbiamo utilizzato il gruppo VMware Cloud SDDC, un gateway di transito gestito da VMware, per consentire la comunicazione tra gli SDDC VMware Cloud nella stessa regione, nonché con i VPC esterni e altri gateway di transito.</block>
  <block id="7ee08649d3bd024352f28df7dabbb32f" category="admonition">L'utilizzo di un gateway di transito comporta costi di trasferimento dei dati. Per i dettagli sui costi specifici di una regione, vedere<block ref="b6f8eb4f405293cd9bb0c07a2ec1b299" category="inline-link-rx"></block>.</block>
  <block id="68010b6bb26779cadbf96e9d04dad537" category="paragraph">VMware Cloud SDDC può essere implementato in una singola zona di disponibilità, come avere un singolo data center. È inoltre disponibile un'opzione di stretch cluster, simile a una soluzione NetApp MetroCluster in grado di fornire una maggiore disponibilità e ridurre i downtime in caso di guasto della zona di disponibilità.</block>
  <block id="0d5aa9b9832dc4c044a656ccdd139dcf" category="paragraph">Per ridurre al minimo i costi di trasferimento dei dati, mantenere le istanze o i servizi di VMware Cloud SDDC e AWS nella stessa zona di disponibilità. È meglio corrispondere con un ID di zona di disponibilità piuttosto che con un nome, perché AWS fornisce l'elenco di ordini AZ specifico per l'account per distribuire il carico tra le zone di disponibilità. Ad esempio, un account (US-East-1a) potrebbe indicare l'ID AZ 1, mentre un altro account (US-East-1c) potrebbe indicare l'ID AZ 1. L'ID della zona di disponibilità può essere recuperato in diversi modi. Nell'esempio seguente, è stato recuperato l'ID AZ dalla subnet VPC.</block>
  <block id="64c06e81643d1c8b6eba37a5343885ec" category="paragraph"><block ref="64c06e81643d1c8b6eba37a5343885ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70cd8bfb8fd7a4082087201414ab2fe4" category="inline-link">Documentazione VMware</block>
  <block id="8920393d6c2c8771eef99f947100b883" category="paragraph">In VMware Cloud SDDC, il networking viene gestito con NSX e l'edge gateway (router Tier-0) che gestisce la porta di uplink del traffico nord-sud viene connesso ad AWS VPC. Il gateway di calcolo e i gateway di gestione (router Tier-1) gestiscono il traffico est-ovest. Se le porte di uplink dell'edge vengono utilizzate in modo massiccio, è possibile creare gruppi di traffico da associare a specifici IP host o sottoreti. La creazione di un gruppo di traffico crea nodi edge aggiuntivi per separare il traffico. Controllare<block ref="616556354bfd279ba90d5c2485799af5" category="inline-link-rx"></block> Sul numero minimo di host vSphere necessari per utilizzare una configurazione multi-edge.</block>
  <block id="e064913c9382e82051f900b9564779d5" category="paragraph">Quando si esegue il provisioning di VMware Cloud SDDC, le porte VMkernel sono già configurate e pronte per l'uso. VMware gestisce queste porte e non è necessario effettuare alcun aggiornamento.</block>
  <block id="edbc8b71394d65a981746a0ed9072b51" category="paragraph">La figura seguente mostra informazioni di esempio sul VMkernel host.</block>
  <block id="24d3a9af73ac14dc11a2d9a4745a77b0" category="paragraph"><block ref="24d3a9af73ac14dc11a2d9a4745a77b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1315738b589a4d2de3fd82a05b2d4e19" category="example-title">Reti di storage con provisioning (iSCSI, NFS)</block>
  <block id="1a6b4ca0fa5ca04588d2e2eac3bf0444" category="paragraph">Per le reti di storage guest delle macchine virtuali, in genere creiamo gruppi di porte. Con NSX, creiamo segmenti che vengono utilizzati su vCenter come gruppi di porte. Poiché le reti di storage si trovano in una subnet instradabile, è possibile accedere alle LUN o montare le esportazioni NFS utilizzando la NIC predefinita anche senza creare segmenti di rete separati. Per separare il traffico di storage, è possibile creare segmenti aggiuntivi, definire regole e controllare le dimensioni MTU su tali segmenti. Per garantire la fault tolerance, è meglio avere almeno due segmenti dedicati alla rete storage. Come accennato in precedenza, se la larghezza di banda di uplink diventa un problema, è possibile creare gruppi di traffico e assegnare prefissi e gateway IP per eseguire il routing basato sull'origine.</block>
  <block id="87e62e5f6f235efbfc557b0177d0e112" category="paragraph">Si consiglia di far corrispondere i segmenti nell'SDDC DR con l'ambiente di origine per evitare di individuare i segmenti di rete di mappatura durante il failover.</block>
  <block id="9175bb34d0aede26315b313b9432bcbb" category="example-title">Gruppi di sicurezza</block>
  <block id="7c9ffa8d590736372f008da84037edaa" category="paragraph">Molte opzioni di sicurezza offrono comunicazioni sicure su AWS VPC e sulla rete VMware Cloud SDDC. All'interno della rete SDDC di VMware Cloud, è possibile utilizzare il flusso di traccia NSX per identificare il percorso, incluse le regole utilizzate. Quindi, è possibile utilizzare un analizzatore di rete sulla rete VPC per identificare il percorso, incluse le tabelle di routing, i gruppi di sicurezza e gli elenchi di controllo dell'accesso alla rete, che viene utilizzato durante il flusso.</block>
  <block id="db4ff15d9c0c503103508af3dd860139" category="paragraph">I sistemi NetApp AFF A-Series offrono un'infrastruttura storage dalle performance elevate con opzioni di gestione dei dati flessibili abilitate al cloud per soddisfare una vasta gamma di scenari aziendali. In questa soluzione, abbiamo utilizzato ONTAP AFF A300 come sistema di storage primario on-premise.</block>
  <block id="6e5148fc476ca76eb8c330524bc1064d" category="paragraph">NetApp ONTAP e i tool ONTAP per VMware e SnapCenter sono stati utilizzati nella soluzione per fornire funzionalità complete di gestione e backup delle applicazioni strettamente integrate con VMware vSphere.</block>
  <block id="e64f2bbe0643eeea77fa30ad5e4bdbe4" category="paragraph">Abbiamo utilizzato lo storage ONTAP per gli archivi dati VMware che ospitavano le macchine virtuali e i relativi file VMDK. VMware supporta più protocolli di storage per datastore connessi e, in questa soluzione, abbiamo utilizzato volumi NFS per datastore sugli host ESXi. Tuttavia, i sistemi storage ONTAP supportano tutti i protocolli supportati da VMware.</block>
  <block id="ba1139b1becb929a6ba79e930297c5b7" category="paragraph">La seguente figura illustra le opzioni di storage VMware.</block>
  <block id="6869f0a16b26f7047d40a5a9c5a0ccd4" category="paragraph"><block ref="6869f0a16b26f7047d40a5a9c5a0ccd4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aed995b63d54f1d314ad87fc5d16b69d" category="paragraph">I volumi ONTAP sono stati utilizzati per lo storage connesso a iSCSI e NFS guest per le nostre macchine virtuali applicative. Per i dati applicativi abbiamo utilizzato i seguenti protocolli di storage:</block>
  <block id="c787b4233027288b06ace5dad3c0e461" category="list-text">Volumi NFS per i file di database Oracle connessi al guest.</block>
  <block id="6a13696c6a6b506058d391582e402c83" category="list-text">LUN iSCSI per database Microsoft SQL Server e log delle transazioni connessi con guest.</block>
  <block id="6504ffb2b49026508f8d68a73a0893a1" category="cell">Tipo di database</block>
  <block id="9b8bdf7379e889d83ab24e782c87d2ac" category="cell">Protocollo storage</block>
  <block id="0fc2cb6a177a3a14f31bd4810e09fa97" category="cell">Descrizione del volume</block>
  <block id="e40ceeaead715c564e85bdc9b183e491" category="cell">SQL Server 2019</block>
  <block id="458648f675593beefe031e7b7ba9fcdd" category="cell">File di database</block>
  <block id="81fae4ea40cc442afa43dab4cc001004" category="cell">File di log</block>
  <block id="ed47cdd7d93d911c4e94fc2801456784" category="cell">Oracle Linux 8.5</block>
  <block id="e13e1c4f4700229b02ee474e7dda4ea2" category="cell">Oracle 19c</block>
  <block id="4659ac5526bf8dff13f1ec371e79b766" category="cell">Binario Oracle</block>
  <block id="f0a16b1024d40f006a15728ebd0e0f12" category="cell">Dati Oracle</block>
  <block id="1d9c31e9be3c01076e13f0f4fa1c15ae" category="cell">File di ripristino Oracle</block>
  <block id="26f11a15ba5f458b3d86d9ecc01b56f3" category="paragraph">Abbiamo anche utilizzato lo storage ONTAP per il repository di backup Veeam primario e per una destinazione di backup per i backup del database SnapCenter.</block>
  <block id="e8d719041d7958d85248e29684218330" category="list-text">Condivisione SMB per il repository di backup Veeam.</block>
  <block id="6005cf3be81f9c1a1908df0afb543b7d" category="list-text">SMB share come destinazione per i backup del database SnapCenter.</block>
  <block id="6872c2b6282a1ff41523f7b84a51d4da" category="example-title">Cloud storage</block>
  <block id="72cd2806db1eac2f04ef89c81542dd54" category="paragraph">Questa soluzione include VMware Cloud su AWS per l'hosting di macchine virtuali ripristinate come parte del processo di failover. Al momento della stesura del presente documento, VMware supporta lo storage vSAN per gli archivi dati che ospitano le macchine virtuali e i VMDK.</block>
  <block id="501c11094fdd604514f321bced51fe82" category="paragraph">FSX per ONTAP viene utilizzato come storage secondario per i dati delle applicazioni sottoposti a mirroring utilizzando SnapCenter e SyncMirror. Come parte del processo di failover, il cluster FSX per ONTAP viene convertito in storage primario e le applicazioni di database possono riprendere la normale funzione in esecuzione sul cluster di storage FSX.</block>
  <block id="2872e9fbf25a6695761c355a5170f21f" category="example-title">Configurazione di Amazon FSX per NetApp ONTAP</block>
  <block id="81d8366c2ec35340f9822e490b614b41" category="paragraph">Per implementare AWS FSX per NetApp ONTAP utilizzando Cloud Manager, seguire le istruzioni all'indirizzo<block ref="f938a02d8e5f1cc6cb4c026bb367a9b5" category="inline-link-rx"></block>.</block>
  <block id="e48c9f83aba7e50a34062296356c11da" category="paragraph">Dopo aver implementato FSX ONTAP, trascinare le istanze di ONTAP on-premise in FSX ONTAP per avviare la configurazione della replica dei volumi.</block>
  <block id="bfeecfa1e5aafaba3386ba09221608e3" category="paragraph">La figura seguente illustra l'ambiente FSX ONTAP.</block>
  <block id="f0eabf6ad2404299416504a68c18c70b" category="paragraph"><block ref="f0eabf6ad2404299416504a68c18c70b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46fabc81c23066d3f0ef74556fc23d0d" category="example-title">Interfacce di rete create</block>
  <block id="cf36149275607710e0655ce5a52d4745" category="paragraph">FSX per NetApp ONTAP dispone di interfacce di rete preconfigurate e pronte all'uso per reti iSCSI, NFS, SMB e tra cluster.</block>
  <block id="a23141775a4b1f964c8a4c1335d366c7" category="example-title">Storage del datastore delle macchine virtuali</block>
  <block id="60d2a0c028f1fc1db964ff9d52cfe139" category="paragraph">VMware Cloud SDDC viene fornito con due datastore VSAN denominati<block ref="c6a4bd2172044149e40e139792052ab8" prefix=" " category="inline-code"></block> e.<block ref="8ca7ba8bcaef71f95d69539e78c555c3" prefix=" " category="inline-code"></block>. Abbiamo utilizzato<block ref="c6a4bd2172044149e40e139792052ab8" prefix=" " category="inline-code"></block> Per ospitare macchine virtuali di gestione con accesso limitato alle credenziali cloud admin. Per i carichi di lavoro, abbiamo utilizzato<block ref="8ca7ba8bcaef71f95d69539e78c555c3" prefix=" " category="inline-code"></block>.</block>
  <block id="f0fa38f675f888f14af946299f91a36a" category="paragraph">VMware vSphere offre un'infrastruttura virtualizzata nel data center e in tutti i principali provider di cloud. Questo ecosistema è ideale per scenari di disaster recovery per i quali il calcolo virtualizzato rimane coerente indipendentemente dalla posizione. Questa soluzione utilizza le risorse di calcolo virtualizzate VMware sia nella sede del data center che in VMware Cloud su AWS.</block>
  <block id="c0b7ac0f313be4f2bef55fc6cf3a1947" category="paragraph">Questa soluzione utilizza server HPE ProLiant DL360 Gen 10 con VMware vSphere v7.0U3. Abbiamo implementato sei istanze di calcolo per fornire risorse adeguate per i server SQL e Oracle.</block>
  <block id="ff1600196b624f9503bddaca0ce10f5d" category="paragraph">Abbiamo implementato 10 macchine virtuali Windows Server 2019 con SQL Server 2019 con dimensioni di database variabili e 10 macchine virtuali Oracle Linux 8.5 con Oracle 19c, ancora una volta, con dimensioni di database variabili.</block>
  <block id="20f748e1f003c63ad3c63122e1629424" category="paragraph">Abbiamo implementato un SDDC in VMware Cloud su AWS con due host per fornire risorse adeguate per eseguire le macchine virtuali ripristinate dal nostro sito primario.</block>
  <block id="a84e981cfea0f9fca307649d4e7bd364" category="paragraph"><block ref="a84e981cfea0f9fca307649d4e7bd364" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f93f90f32b570b5fbcc3458fb93a6ab2" category="section-title">Tool di backup cloud</block>
  <block id="601c3055944b06a3d06d7da4128af752" category="paragraph">Per eseguire un failover delle nostre macchine virtuali applicative e dei volumi di database sui servizi di volume cloud VMware in esecuzione in AWS, era necessario installare e configurare un'istanza in esecuzione del server SnapCenter e del server di backup e replica Veeeam. Una volta completato il failover, questi strumenti devono essere configurati in modo da riprendere le normali operazioni di backup fino a quando non viene pianificato ed eseguito un failback al data center on-premise.</block>
  <block id="4f31ced8146865d2c2823db3f623bf36" category="example-title">Implementazione di strumenti di backup</block>
  <block id="4dad49c9583060929c06d355e24a683a" category="paragraph">È possibile installare il server SnapCenter e il server di backup e replica Veeam nel software SDDC di VMware Cloud oppure installarli su istanze EC2 che risiedono in un VPC con connettività di rete all'ambiente VMware Cloud.</block>
  <block id="f709ed2f05802131924f53cb483d0216" category="example-title">Server SnapCenter</block>
  <block id="2bd8e8f9848a7635d56bcd86b9ad4c8f" category="paragraph">Il software SnapCenter è disponibile sul sito di supporto NetApp e può essere installato su sistemi Microsoft Windows che risiedono in un dominio o in un gruppo di lavoro. Una guida dettagliata alla pianificazione e le istruzioni di installazione sono disponibili all'indirizzo <block ref="a00f6e57d5c269a935cd1b0491cebb83" category="inline-link-macro-rx"></block>.</block>
  <block id="d099bc9c6d34500d99c2caac0e6df36c" category="paragraph">Il software SnapCenter è disponibile all'indirizzo<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>.</block>
  <block id="42c8c901c8d4c00c90f9f66d69df3cdb" category="example-title">Veeam Backup &amp;amp; Replication server</block>
  <block id="5a8e524620f781b94c018014370aad68" category="paragraph">È possibile installare il server Veeam Backup &amp; Replication su un server Windows in VMware Cloud su AWS o su un'istanza EC2. Per informazioni dettagliate sull'implementazione, vedere<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>.</block>
  <block id="af7bd34681425c09ae0ef24381972fb5" category="example-title">Strumenti di backup e configurazione</block>
  <block id="82634d63ab3a3344fb59974c50487bac" category="paragraph">Una volta installati, SnapCenter e Veeeam Backup &amp; Replication devono essere configurati per eseguire le attività necessarie per ripristinare i dati su VMware Cloud su AWS.</block>
  <block id="4b152f4bba0a5ca6345daa47736e4622" category="list-text">Configurazione di SnapCenter</block>
  <block id="411fce4d2b732a8bfda73c4f04da246c" category="paragraph">Per ripristinare i dati delle applicazioni che sono stati mirrorati in FSX ONTAP, è necessario prima eseguire un ripristino completo del database SnapCenter on-premise. Una volta completato questo processo, la comunicazione con le macchine virtuali viene ristabilita e i backup delle applicazioni possono ora riprendere utilizzando FSX ONTAP come storage primario.</block>
  <block id="d307f68836099290d00bdc9341ec2be7" category="inline-link-macro">Implementare il server Windows SnapCenter secondario</block>
  <block id="52463fc86a53e3e78c2a77069889838f" category="paragraph">Per un elenco dei passaggi da completare sul server SnapCenter che risiede in AWS, vedere la sezione <block ref="1d252dd870179a0ef2258cd4837b106d" category="inline-link-macro-rx"></block>.</block>
  <block id="17f0b02d31e76cb9b2878b4a08f19eb5" category="example-title">Veeam Backup &amp;amp; Configurazione della replica</block>
  <block id="50d8cb6b9ada9f3e6328cb534ed5773f" category="paragraph">Per ripristinare le macchine virtuali di cui è stato eseguito il backup sullo storage Amazon S3, Veeam Server deve essere installato su un server Windows e configurato per comunicare con VMware Cloud, FSX ONTAP e il bucket S3 che contiene il repository di backup originale. Deve inoltre disporre di un nuovo repository di backup configurato su FSX ONTAP per eseguire nuovi backup delle macchine virtuali una volta ripristinate.</block>
  <block id="845690e8aecca4f756b60cbd6c80c7f9" category="inline-link-macro">Implementare Secondary Veeam Backup &amp;amp; Replication Server</block>
  <block id="5de00fbb5f941e4a6da089a424224039" category="paragraph">Per un elenco completo dei passaggi necessari per completare il failover delle macchine virtuali dell'applicazione, vedere la sezione <block ref="26a23d90f8b49a2bef24fd9bd32f1a97" category="inline-link-macro-rx"></block>.</block>
  <block id="6120544c737d67dd31f47d101fe21a84" category="doc">Configurazione dell'ambiente di virtualizzazione nel cloud provider</block>
  <block id="f4f7adb7cbe18f2cdd82be75a52b0417" category="paragraph">I dettagli su come configurare l'ambiente di virtualizzazione in ciascuno degli hyperscaler supportati sono illustrati qui.</block>
  <block id="43f154001e329eb4cb13b7745ba16dac" category="doc">Configurazioni supportate per NetApp Hybrid Multibloud con VMware</block>
  <block id="5e1c36a2c24e0aaf7844ec890c15e430" category="paragraph">Comprendere le combinazioni per il supporto dello storage NetApp nei principali hyperscaler.</block>
  <block id="685435b4b2388bd8f370b8fbb6ef6cc7" category="cell">*Guest connesso*</block>
  <block id="58098d451cf2728b0542acd542f9000b" category="cell">*Database NFS supplementare*</block>
  <block id="8299249ba5f910704b6288ee7e271747" category="cell">*AWS*</block>
  <block id="eb35b03ceb49f5f06a4570454e08c34c" category="cell">ONTAP CVO FSX<block ref="999b20d9470091fda2e66b2dde5b0af7" category="inline-link-macro-rx"></block></block>
  <block id="ff56eef7a458cc9250ee84cb0b8b3752" category="cell">ONTAP FSX<block ref="b9210f6aa16b7e370d59e02bd5b54f88" category="inline-link-macro-rx"></block></block>
  <block id="1bdeba09294eb5abc383607bb93ff443" category="cell">*Azure*</block>
  <block id="06a1c60be3b7274c063385eaa240863f" category="cell">ANF. CVO<block ref="f44f46a20eba78aa72ad4f68a0486a31" category="inline-link-macro-rx"></block></block>
  <block id="ef7615d9ff40c00e9893de8051347a72" category="cell">AN<block ref="11e701f660af04a4005e56e6ac4b1c05" category="inline-link-macro-rx"></block></block>
  <block id="25bdffbd4ab087e994a0e54fe22ff6bd" category="cell">*GCP*</block>
  <block id="96e48152153beabed038aa4e41f2abf8" category="cell">CVO CVS<block ref="a54d2eac225d57696bf863778373ea0b" category="inline-link-macro-rx"></block></block>
  <block id="b577d5e5fe684be74c0fcbceb61e27d4" category="cell">CVS<block ref="2bc02f38a6be3889a69283e362618186" category="inline-link-macro-rx"></block></block>
  <block id="b583dc49832a978014ef0d14fe7ef1ce" category="paragraph">Scopri di più sulle soluzioni offerte da NetApp per l'ambiente VMware in ciascuno degli hyperscaler, dalla migrazione dei flussi di lavoro, dall'estensione/diffusione al cloud, al backup/ripristino e al disaster recovery.</block>
  <block id="ef3abc0e33a9bba2f6844fc8bc6416c6" category="section-title">Soluzioni NetApp per ambienti VMware</block>
  <block id="7c56979dc4b16fa4dd69a289608a432d" category="paragraph">Sia che operiate in un modello di cloud ibrido o in un modello "cloud first", NetApp offre un'ampia gamma di soluzioni per affrontare i casi di utilizzo più comuni per la gestione dei carichi di lavoro in un modello di cloud o cloud ibrido.</block>
  <block id="206616b83a19162051802c3823da0f7c" category="paragraph">NetApp offre anche soluzioni per lo storage con provisioning come storage in-guest (connesso al guest) o come datastore NFS supplementare in ciascuno degli hyperscaler. Tutte le soluzioni sono classificate in base alla classificazione VMware dei carichi di lavoro cloud. Tali classificazioni includono:</block>
  <block id="14b428df74ec47d859b4b41c2a528f79" category="paragraph">Per ulteriori informazioni sulle soluzioni disponibili per ciascun hyperscaler, visitare il sito:</block>
  <block id="d7d90ddf3d849c680942374007293390" category="inline-link-macro">Soluzioni per AWS/VMC</block>
  <block id="3efe4c396a8490c63650f3271e66c5ab" category="list-text"><block ref="3efe4c396a8490c63650f3271e66c5ab" category="inline-link-macro-rx"></block></block>
  <block id="902d95c8e7b033260ed791d46b121684" category="inline-link-macro">Soluzioni per Azure / AVS</block>
  <block id="a22d65ac7c37a480dfd6ea3cc467903d" category="list-text"><block ref="a22d65ac7c37a480dfd6ea3cc467903d" category="inline-link-macro-rx"></block></block>
  <block id="739e02805dc104b2c68811e1ea86f2e5" category="inline-link-macro">Soluzioni per GCP/GCVE</block>
  <block id="72792598cb09eae6cc992790a3677b2d" category="list-text"><block ref="72792598cb09eae6cc992790a3677b2d" category="inline-link-macro-rx"></block></block>
  <block id="668f202e4850de68f941501493126dea" category="doc">TR-4940: Migrazione dei carichi di lavoro al datastore Azure NetApp Files con VMware HCX - Guida rapida</block>
  <block id="e5baae71bfede792aee5ab0c09fbcd23" category="section-title">Panoramica: Migrazione di macchine virtuali con VMware HCX, datastore Azure NetApp Files e soluzione VMware Azure</block>
  <block id="45c532c5535fe16cf9a5868bbd9a3fcd" category="paragraph">Uno dei casi di utilizzo più comuni per la soluzione VMware Azure e il datastore Azure NetApp Files è la migrazione dei carichi di lavoro VMware. VMware HCX è un'opzione preferita e offre vari meccanismi di migrazione per spostare macchine virtuali (VM) on-premise e i relativi dati negli archivi dati Azure NetApp Files.</block>
  <block id="a2ee24315378af7416f8fef29e0f0efa" category="paragraph">VMware HCX è principalmente una piattaforma di migrazione progettata per semplificare la migrazione delle applicazioni, il ribilanciamento dei carichi di lavoro e persino la business continuity tra i cloud. È incluso come parte di Azure VMware Solution Private Cloud e offre diversi modi per migrare i workload e può essere utilizzato per le operazioni di disaster recovery (DR).</block>
  <block id="227830ba037f63bb97cffeeb98e3a13e" category="paragraph">Questo documento fornisce istruzioni dettagliate per il provisioning del datastore Azure NetApp Files, seguito dal download, dall'implementazione e dalla configurazione di VMware HCX, inclusi tutti i componenti principali in sede e il lato soluzione VMware Azure, tra cui interconnessione, estensione di rete e ottimizzazione WAN per l'abilitazione di vari meccanismi di migrazione delle macchine virtuali.</block>
  <block id="a7441e9f968c9ea792320876fd73622a" category="admonition">VMware HCX funziona con qualsiasi tipo di datastore poiché la migrazione è a livello di VM. Pertanto, questo documento è valido per i clienti NetApp esistenti e non, che intendono implementare la soluzione Azure NetApp Files con Azure VMware per un'implementazione cloud VMware conveniente.</block>
  <block id="9a40c0b2781fd2a3a99aa2a6c0c4616e" category="paragraph">Questo elenco fornisce i passaggi di alto livello necessari per installare e configurare HCX Cloud Manager sul lato cloud di Azure e installare HCX Connector on-premise:</block>
  <block id="d7bfcf4345887ee24f2c3083038c6327" category="list-text">Installare HCX attraverso il portale Azure.</block>
  <block id="ea0d203a776b5c56ae3ed2c61269d2a9" category="list-text">Scaricare e implementare IL programma di installazione DI HCX Connector Open Virtualization Appliance (OVA) nel server VMware vCenter on-premise.</block>
  <block id="2be88e0d3f6d4e20f4bf2bcca7895d7b" category="list-text">Attivare HCX con la chiave di licenza.</block>
  <block id="6a0721ebaaff6c0b1564863ac23c2509" category="list-text">Associare il connettore VMware HCX on-premise con Azure VMware Solution HCX Cloud Manager.</block>
  <block id="81feabec43f9f1bcb7230fd62f89fb76" category="list-text">(Facoltativo) eseguire l'estensione di rete per evitare il re-IP durante le migrazioni.</block>
  <block id="f2f281974ab353b606093268f9d5335e" category="paragraph">Prima di iniziare, assicurarsi che siano soddisfatti i seguenti prerequisiti. Per ulteriori informazioni, consulta questa sezione<block ref="88354f8e41d1a2e6cea84b3d932b3286" category="inline-link-rx"></block>. Una volta soddisfatti i prerequisiti, inclusa la connettività, configurare e attivare HCX generando la chiave di licenza dal portale Azure VMware Solution. Una volta scaricato il programma di installazione di OVA, procedere con la procedura di installazione come descritto di seguito.</block>
  <block id="f52b030029e78590ca66fbf452dfcb14" category="admonition">HCX Advanced è l'opzione predefinita e VMware HCX Enterprise Edition è disponibile anche attraverso un ticket di supporto e supportato senza costi aggiuntivi.</block>
  <block id="d2a5cfbad293008f62b5d4e58457a6d1" category="inline-link">Collegamento Microsoft</block>
  <block id="1ed491d88e9198d83430469156bf2665" category="list-text">Utilizza un data center software-defined (SDDC) esistente per la soluzione Azure VMware o crea un cloud privato utilizzando questo<block ref="db330bdc7708ed0196dccd83d189a8ae" category="inline-link-rx"></block> o questo<block ref="5633c6477a16a80a8050560dab9783c9" category="inline-link-rx"></block>.</block>
  <block id="e265f4db94070f55784ef698e7f4f29b" category="inline-link">Configurare una connessione VPN sito-sito o di accesso globale Express Route</block>
  <block id="bb764f1df90a85d77eec079e03bd9764" category="list-text">La migrazione delle macchine virtuali e dei dati associati dal data center abilitato VMware vSphere on-premise richiede la connettività di rete dal data center all'ambiente SDDC. Prima di migrare i carichi di lavoro,<block ref="31180ecf5c9f25ba891b891b395a9305" category="inline-link-rx"></block> tra l'ambiente on-premise e il rispettivo cloud privato.</block>
  <block id="d08fd3825f77e870dd8e93463aea245d" category="list-text">Il percorso di rete dall'ambiente VMware vCenter Server on-premise al cloud privato Azure VMware Solution deve supportare la migrazione delle macchine virtuali utilizzando vMotion.</block>
  <block id="e1be03b35dc8e9fb114970b06dcd6c18" category="list-text">Assicurarsi di aver selezionato il necessario<block ref="69c9d7a74dad51c1c47ea8141c218514" category="inline-link-rx"></block> Sono consentiti per il traffico vMotion tra vCenter Server on-premise e vCenter SDDC. Nel cloud privato, il routing sulla rete vMotion è configurato per impostazione predefinita.</block>
  <block id="444617dcfe0d17ad386105e865d21113" category="list-text">Il volume NFS di Azure NetApp Files deve essere montato come datastore nella soluzione VMware di Azure. Seguire i passaggi descritti in questa sezione<block ref="1b959b45bbb3571141089802677ad765" category="inline-link-rx"></block> Per collegare datastore Azure NetApp Files agli host delle soluzioni VMware Azure.</block>
  <block id="ce32836b59e052d959dee4d2358e5a21" category="paragraph">A scopo di test, l'ambiente di laboratorio on-premise utilizzato per questa convalida è stato collegato tramite una VPN sito-sito, che consente la connettività on-premise con Azure VMware Solution.</block>
  <block id="39fc1d64ec4b3a4ff5306e55bdaf2c0f" category="paragraph"><block ref="39fc1d64ec4b3a4ff5306e55bdaf2c0f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c8f77e6ab4a9e453faf4063978f94d5" category="example-title">Fase 1: Installare HCX attraverso Azure Portal utilizzando l'opzione Add-ons</block>
  <block id="7d4c34e9f83446ef58ad083cd2c29580" category="list-text">Accedi al portale Azure e accedi al cloud privato Azure VMware Solution.</block>
  <block id="16671eada5939f5c2129db7e8f9522a0" category="list-text">Selezionare il cloud privato appropriato e accedere ai componenti aggiuntivi. Per eseguire questa operazione, accedere a *Gestisci &gt; componenti aggiuntivi*.</block>
  <block id="de23e32bd14f5f77d4178bb7d56c2eb0" category="list-text">Nella sezione HCX workload Mobility, fare clic su *Get Started* (inizia subito).</block>
  <block id="239ba3d7293041d0d4dcb4c5b538ea74" category="inline-image-macro">Screenshot della sezione HCX workload Mobility.</block>
  <block id="91a36107da2b4f5cbc4963027f871289" category="paragraph"><block ref="91a36107da2b4f5cbc4963027f871289" category="inline-image-macro-rx" type="image"></block></block>
  <block id="de66be71be828600d682c9f0bdb03a18" category="list-text">Selezionare l'opzione *Accetto i termini e le condizioni* e fare clic su *attiva e implementa*.</block>
  <block id="e26184583d86572b90efcca3db66731e" category="admonition">L'implementazione predefinita è HCX Advanced. Aprire una richiesta di supporto per attivare l'edizione Enterprise.</block>
  <block id="adafe418547291754cadbfc0d2c5c1dc" category="admonition">L'implementazione richiede da 25 a 30 minuti circa.</block>
  <block id="e39769185df95d6577314b0c683cf848" category="inline-image-macro">Schermata del completamento della sezione HCX workload Mobility.</block>
  <block id="6df468c8490be1137779d8811f53bddb" category="paragraph"><block ref="6df468c8490be1137779d8811f53bddb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e957ef97a04368fda5e2652e51c19d1d" category="paragraph">Affinché il connettore on-premise si connetta a HCX Manager in Azure VMware Solution, assicurarsi che le porte firewall appropriate siano aperte nell'ambiente on-premise.</block>
  <block id="0c216cee9411e03f1127e6ffc2bf025d" category="paragraph">Per scaricare e installare HCX Connector nel server vCenter on-premise, attenersi alla seguente procedura:</block>
  <block id="c28009ba42c1703c33046d99285a0a10" category="list-text">Dal portale Azure, accedere alla soluzione VMware Azure, selezionare il cloud privato, quindi selezionare *Gestisci &gt; componenti aggiuntivi &gt; migrazione* utilizzando HCX e copiare IL portale HCX Cloud Manager per scaricare il file OVA.</block>
  <block id="3a858d6f55c84c77db797aafa874a8a5" category="admonition">Utilizzare le credenziali utente predefinite di CloudAdmin per accedere al portale HCX.</block>
  <block id="7efdfa090ad75b0c0f02e115ab8e56bd" category="inline-image-macro">Schermata del portale Azure per scaricare il file HCX OVA.</block>
  <block id="ab9fbdf98484d630980bec96dac55284" category="paragraph"><block ref="ab9fbdf98484d630980bec96dac55284" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69d5565b77c91d5d6d289858e4d7ea91" category="list-text">Dopo aver effettuato l'accesso al portale HCX con mailto:cloudadmin@vsphere.local[cloudadmin@vsphere.local^] utilizzando il jumphost, accedere a *Administration &gt; System Updates* e fare clic su *Request Download link*.</block>
  <block id="f6b26e036b373b18f11dc0da33ef5268" category="admonition">Scaricare o copiare il collegamento a OVA e incollarlo in un browser per avviare il processo di download del file OVA di VMware HCX Connector da implementare sul server vCenter on-premise.</block>
  <block id="894d2481892f65fcae6dfc0ac7b9ec0d" category="inline-image-macro">Errore: Schermata del collegamento per il download di OVA.</block>
  <block id="2a8ced383f2ab7fb9d4a69fc8d344b0e" category="paragraph"><block ref="2a8ced383f2ab7fb9d4a69fc8d344b0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12e1c817f24a0aa94d2ae26ea6535479" category="list-text">Una volta scaricato l'OVA, implementarlo nell'ambiente VMware vSphere on-premise utilizzando l'opzione *Deploy OVF Template*.</block>
  <block id="fc1a0933af5c68cc43dbb90b50c1b0d3" category="inline-image-macro">Errore: Schermata per selezionare il modello OVA corretto.</block>
  <block id="d36fa73d8072d1ab34f185f12d5fede5" category="paragraph"><block ref="d36fa73d8072d1ab34f185f12d5fede5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ba87ef75729cfcffc74d93e0a0852a1" category="list-text">Inserire tutte le informazioni richieste per l'implementazione di OVA, fare clic su *Avanti*, quindi fare clic su *fine* per implementare l'OVA di VMware HCX Connector.</block>
  <block id="ed1aadd2fcd5906dd58f9a89179a638e" category="admonition">Accendere l'appliance virtuale manualmente.</block>
  <block id="e10fbd147d2ee50fbbb460ad2f18fa14" category="paragraph">Per istruzioni dettagliate, consultare<block ref="856d054195f2a40a0c4a2869d5895904" category="inline-link-rx"></block>.</block>
  <block id="4aa14207b82768ed77473306cc7a65c2" category="paragraph">Dopo aver implementato VMware HCX Connector OVA on-premise e avviato l'appliance, completare la seguente procedura per attivare HCX Connector. Generare la chiave di licenza dal portale Azure VMware Solution e attivarla in VMware HCX Manager.</block>
  <block id="3535419e37127ca2de6abd9538414466" category="list-text">Dal portale Azure, accedere alla soluzione VMware Azure, selezionare il cloud privato e selezionare *Gestisci &gt; componenti aggiuntivi &gt; migrazione con HCX*.</block>
  <block id="436402d536d27aaa2091a54751a60036" category="list-text">In *Connect with on-premise using HCX keys* (connessione con chiavi HCX on-premise), fare clic su *Add* (Aggiungi) e copiare la chiave di attivazione.</block>
  <block id="0b053e667d8c9baa8cbb4a5402fe69e1" category="inline-image-macro">Schermata per l'aggiunta di chiavi HCX.</block>
  <block id="5d9de146e997662a8510bd175e5c593a" category="paragraph"><block ref="5d9de146e997662a8510bd175e5c593a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03fc385dd3b54c80a78341c5aa2189a3" category="admonition">Per ciascun connettore HCX on-premise implementato è necessaria una chiave separata.</block>
  <block id="e8edfbded2eb5193c58170d5f9073d7d" category="inline-link"><block ref="e8edfbded2eb5193c58170d5f9073d7d" category="inline-link-rx"></block></block>
  <block id="b6d4af6a25f46f3687120681e525d833" category="list-text">Accedere a VMware HCX Manager on-premise all'indirizzo<block ref="f9ac10929d1e2f12c4fea5c57d73b3eb" category="inline-link-rx"></block> utilizzando le credenziali di amministratore.</block>
  <block id="a864855f2120d5c8d4793a4866b6a7bb" category="list-text">Nella licenza, inserire la chiave copiata dal passaggio 3 e fare clic su *Activate* (attiva).</block>
  <block id="e5c8d88f2fa7af9f1a719e04c4b17740" category="admonition">Il connettore HCX on-premise deve disporre di accesso a Internet.</block>
  <block id="ee746d79ab481579a8c0202a94e8d378" category="list-text">In *posizione del data center*, fornire la posizione più vicina per l'installazione di VMware HCX Manager on-premise. Fare clic su *continua*.</block>
  <block id="c72431b355c96ffdfb7baece307881f0" category="list-text">In *Nome sistema*, aggiornare il nome e fare clic su *continua*.</block>
  <block id="030627b8e0e3f6ba69c6a9e524d8e9c0" category="list-text">Fare clic su *Sì, continua*.</block>
  <block id="05399e57e0b2a25ce8cef32f3628b2e3" category="list-text">In *Connect your vCenter*, fornire il nome di dominio completo (FQDN) o l'indirizzo IP di vCenter Server e le credenziali appropriate, quindi fare clic su *Continue* (continua).</block>
  <block id="96b1cf77a862dc0408a3e2e9678b2165" category="admonition">Utilizzare l'FQDN per evitare problemi di connettività in un secondo momento.</block>
  <block id="390f6c76fee2d7fb6d09bcedc3622467" category="list-text">In *Configure SSO/PSC* (Configura SSO/PSC*), fornire l'indirizzo FQDN o IP del Platform Services Controller e fare clic su *Continue* (continua).</block>
  <block id="b070c615098fb975bc2bc3a9f6c67b3e" category="admonition">Immettere l'indirizzo IP o il nome FQDN di VMware vCenter Server.</block>
  <block id="f4bb2b9a4de7e44c942457943977fd34" category="list-text">Verificare che le informazioni immesse siano corrette e fare clic su *Restart* (Riavvia).</block>
  <block id="a565e4f9db7c03385f61c3bdb0f4b806" category="list-text">Dopo il riavvio dei servizi, vCenter Server viene visualizzato in verde nella pagina visualizzata. VCenter Server e SSO devono disporre dei parametri di configurazione appropriati, che devono essere gli stessi della pagina precedente.</block>
  <block id="457446477fbd3326ba80d1248eaca490" category="admonition">Questo processo richiede circa 10 - 20 minuti e l'aggiunta del plug-in al server vCenter.</block>
  <block id="1181827ced4ce13f7bd91097d9b10dac" category="inline-image-macro">Schermata che mostra il processo completato.</block>
  <block id="534d4f43f7a513cf2f2152686da775ae" category="paragraph"><block ref="534d4f43f7a513cf2f2152686da775ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0b94fcafcd5f76f4f84be761263d657" category="example-title">Fase 4: Associazione on-premise di VMware HCX Connector con Azure VMware Solution HCX Cloud Manager</block>
  <block id="ae37843769e741d076e2422772db5395" category="paragraph">Dopo aver installato HCX Connector sia in sede che in Azure VMware Solution, configurare VMware HCX Connector on-premise per Azure VMware Solution Private Cloud aggiungendo l'accoppiamento. Per configurare l'associazione del sito, attenersi alla seguente procedura:</block>
  <block id="28b0363954066139335c413f28022037" category="list-text">Per creare una coppia di siti tra l'ambiente vCenter on-premise e Azure VMware Solution SDDC, accedere a vCenter Server on-premise e al nuovo plug-in HCX vSphere Web Client.</block>
  <block id="f4f57342a1f5bfd667f7d19048c4aa85" category="inline-image-macro">Schermata del plug-in DI HCX vSphere Web Client.</block>
  <block id="1ecb33e8c47a03470ff03bb6c09a1d87" category="paragraph"><block ref="1ecb33e8c47a03470ff03bb6c09a1d87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="302ca8cbe91eb456c9defb6fe514b81e" category="list-text">In Infrastructure (infrastruttura), fare clic su *Add a Site Pairing* (Aggiungi associazione sito).</block>
  <block id="cd6182a85ca09ca99bda2787165407d9" category="admonition">Immettere l'URL o l'indirizzo IP di Azure VMware Solution HCX Cloud Manager e le credenziali per il ruolo CloudAdmin per l'accesso al cloud privato.</block>
  <block id="407d1d705e5bdedf2e1c5e9257c0c1ef" category="inline-image-macro">URL o indirizzo IP della schermata e credenziali per il ruolo CloudAdmin.</block>
  <block id="6e861dfeca468a35e2aa6f6a42b2ad5f" category="paragraph"><block ref="6e861dfeca468a35e2aa6f6a42b2ad5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9bccd838ddedeb361e65189136ac5c0f" category="list-text">Fare clic su *Connect* (Connetti).</block>
  <block id="7630a70e4d4511de5ac0f8ce18edd594" category="admonition">Il connettore VMware HCX deve essere in grado di instradare all'indirizzo IP DI HCX Cloud Manager tramite la porta 443.</block>
  <block id="8cdce778f46399f121d65006767f466a" category="inline-image-macro">Schermata del processo completato sul dashboard HCX.</block>
  <block id="a71387f99ef8fc06b56323de8e6a67e6" category="paragraph"><block ref="a71387f99ef8fc06b56323de8e6a67e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a030f25f2e21cc0db80d6a88646adb63" category="paragraph">L'appliance di servizio VMware HCX Interconnect offre funzionalità di replica e migrazione basata su vMotion su Internet e connessioni private al sito di destinazione. L'interconnessione offre crittografia, progettazione del traffico e mobilità delle macchine virtuali. Per creare un'appliance di servizio Interconnect, attenersi alla seguente procedura:</block>
  <block id="efb9332572aac00947298fc1ed65c0da" category="list-text">In Infrastructure (infrastruttura), selezionare *Interconnect &gt; Multi-Site Service Mesh &gt; Compute Profiles &gt; Create Compute Profile* (interconnessione &gt; Mesh servizio multi-sito &gt; profili di calcolo &gt; Crea profilo di calcolo</block>
  <block id="96e78a381f203820b7fb0d823994f764" category="admonition">I profili di calcolo definiscono i parametri di implementazione, incluse le appliance implementate e la parte del data center VMware accessibile al servizio HCX.</block>
  <block id="df03fa88f502c44f3476981d50c25ae4" category="inline-image-macro">Schermata della pagina di interconnessione del client vSphere.</block>
  <block id="0f7d2c9383c1f40641b39e9f65126dcf" category="paragraph"><block ref="0f7d2c9383c1f40641b39e9f65126dcf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba9d884b8a48f110e052a2644f36c6bb" category="list-text">Una volta creato il profilo di calcolo, creare i profili di rete selezionando *Multi-Site Service Mesh &gt; Network Profiles &gt; Create Network Profile* (Mesh servizio multi-sito &gt; profili di rete &gt; Crea profilo di rete).</block>
  <block id="7e461f559c367396eca97f75c2262003" category="paragraph">Il profilo di rete definisce un intervallo di indirizzi IP e reti utilizzati DA HCX per le proprie appliance virtuali.</block>
  <block id="12618dff60108a0e440afb082e782c71" category="admonition">Questa operazione richiede due o più indirizzi IP. Questi indirizzi IP vengono assegnati dalla rete di gestione alle appliance di interconnessione.</block>
  <block id="9f137734809298c4fa85b07a7ddb6c5f" category="inline-image-macro">Schermata dell'aggiunta di indirizzi IP alla pagina di interconnessione del client vSphere.</block>
  <block id="c1fdcb13f1a622ccbe4f21a52d31bcb1" category="paragraph"><block ref="c1fdcb13f1a622ccbe4f21a52d31bcb1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f78591a00b39059d077f422f8695286" category="list-text">A questo punto, i profili di calcolo e di rete sono stati creati correttamente.</block>
  <block id="5e8122825414e5afe12c228e3afb9f77" category="list-text">Creare la mesh del servizio selezionando la scheda *Mesh del servizio* all'interno dell'opzione *Interconnect* e selezionando i siti SDDC on-premise e Azure.</block>
  <block id="efe6cc3fe15f7c67781cd956f1aa3b8e" category="list-text">Service Mesh specifica una coppia di profili di rete e di calcolo locale e remoto.</block>
  <block id="292b454f1874f04a4b6f9258b5f933e4" category="admonition">Nell'ambito di questo processo, le appliance HCX vengono implementate e configurate automaticamente sui siti di origine e di destinazione per creare un fabric di trasporto sicuro.</block>
  <block id="0433a192b31baf05b1deba1471c492ff" category="inline-image-macro">Schermata della scheda Service Mesh nella pagina di interconnessione del client vSphere.</block>
  <block id="55551523a891564fc7b09d6dec2fe75f" category="paragraph"><block ref="55551523a891564fc7b09d6dec2fe75f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9df03f8fa3fc5e40e9100c8ebbd3a2ad" category="list-text">Questa è la fase finale della configurazione. Il completamento dell'implementazione richiede circa 30 minuti. Una volta configurata la mesh del servizio, l'ambiente è pronto con i tunnel IPSec creati correttamente per migrare le macchine virtuali del carico di lavoro.</block>
  <block id="532b4e992bd2794e777d1c1320e94f98" category="inline-image-macro">Schermata del processo completato nella pagina di interconnessione del client vSphere.</block>
  <block id="9158466ef9c7277d9287f86080b2c362" category="paragraph"><block ref="9158466ef9c7277d9287f86080b2c362" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0e8a1058909962c26cdead8b3fab020" category="example-title">Fase 6: Migrazione dei carichi di lavoro</block>
  <block id="80ea378666ca268305d30933ca376035" category="paragraph">I carichi di lavoro possono essere migrati bidirezionalmente tra gli SDDC on-premise e Azure utilizzando varie tecnologie di migrazione VMware HCX. Le VM possono essere spostate da e verso le entità attivate da VMware HCX utilizzando diverse tecnologie di migrazione, come LA migrazione in blocco HCX, HCX vMotion, HCX Cold Migration, HCX Replication Assisted vMotion (disponibile con HCX Enterprise Edition) e HCX OS Assisted Migration (disponibile con HCX Enterprise Edition).</block>
  <block id="aa52e427086548446f11ad8e43c6e998" category="paragraph">Per ulteriori informazioni sui vari meccanismi di migrazione HCX, vedere<block ref="17989ba7d4a97ba4d6ebb072be2dc216" category="inline-link-rx"></block>.</block>
  <block id="998d1ed8e82c8145e094c99bf11f8408" category="paragraph">*Migrazione in massa*</block>
  <block id="15a3af99dcf6c8651b8f168e13625c61" category="paragraph">In questa sezione viene descritto in dettaglio il meccanismo di migrazione in blocco. Durante una migrazione in blocco, LA funzionalità di migrazione in blocco di HCX utilizza vSphere Replication per migrare i file disco ricreando la macchina virtuale sull'istanza di destinazione di vSphere HCX.</block>
  <block id="181b4946601ef2026e3d3ca16145a722" category="paragraph">Per avviare migrazioni di macchine virtuali in blocco, attenersi alla seguente procedura:</block>
  <block id="76b01c506c1450a5b0ff6dccaeb0e9b7" category="list-text">Accedere alla scheda *Migrate* in *servizi &gt; migrazione*.</block>
  <block id="bdfca72da9e5f7e7bfcd81aa9844aa45" category="inline-image-macro">Schermata della sezione migrazione del client vSphere.</block>
  <block id="005bf2b00a4806639f3ea37ea4509f6b" category="paragraph"><block ref="005bf2b00a4806639f3ea37ea4509f6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc18384d5bbc3aa89ffea93d51abc451" category="list-text">Nella sezione *connessione sito remoto*, selezionare la connessione del sito remoto e selezionare l'origine e la destinazione. In questo esempio, la destinazione è Azure VMware Solution SDDC HCX endpoint.</block>
  <block id="251b1066293b131079328f5d09e33aca" category="list-text">Fare clic su *Select VM for Migration* (Seleziona VM per la migrazione Questo fornisce un elenco di tutte le macchine virtuali on-premise. Selezionare le macchine virtuali in base all'espressione match:value e fare clic su *Add* (Aggiungi).</block>
  <block id="70dc92c7c0c3752e5757560b72fa8f04" category="list-text">Nella sezione *Transfer and Placement* (trasferimento e posizionamento), aggiornare i campi obbligatori (*Cluster*, *Storage*, *Destination* e *Network*), incluso il profilo di migrazione, quindi fare clic su *Validate* (convalida).</block>
  <block id="009e0b54f8062ebadb85388889541f12" category="inline-image-macro">Schermata della sezione trasferimento e posizionamento del client vSphere.</block>
  <block id="e5cde894c26fccdfef420936d570829b" category="paragraph"><block ref="e5cde894c26fccdfef420936d570829b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7599f8a3668b692ca7501152d4682c07" category="list-text">Al termine dei controlli di convalida, fare clic su *Go* per avviare la migrazione.</block>
  <block id="79af22f136dbfe3d3bf950a72f2c5f5b" category="inline-image-macro">Schermata di avvio della migrazione.</block>
  <block id="c40f6796f391e80926e1a459f389859b" category="paragraph"><block ref="c40f6796f391e80926e1a459f389859b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c1969ef22141ce348651d2b0f4eb5dd8" category="admonition">Durante questa migrazione, viene creato un disco segnaposto nel datastore Azure NetApp Files specificato all'interno del vCenter di destinazione per consentire la replica dei dati del disco VM di origine nei dischi segnaposto. L'HBR viene attivato per una sincronizzazione completa con la destinazione e, una volta completata la linea di base, viene eseguita una sincronizzazione incrementale in base al ciclo RPO (Recovery Point Objective). Una volta completata la sincronizzazione completa/incrementale, lo switchover viene attivato automaticamente, a meno che non venga impostata una pianificazione specifica.</block>
  <block id="c0b39ee3609ffbaf676e9119dd912e9b" category="list-text">Una volta completata la migrazione, validare la stessa accedendo al vCenter SDDC di destinazione.</block>
  <block id="5d882ffc756bfb07c0785abe30634c3c" category="paragraph"><block ref="5d882ffc756bfb07c0785abe30634c3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d785f8302edf28ffd50ba9bd9a1e3e5" category="paragraph">Per ulteriori e dettagliate informazioni sulle varie opzioni di migrazione e su come migrare i carichi di lavoro da una soluzione VMware on-premise a Azure utilizzando HCX, vedere<block ref="15dbc17e63bae3f57dd4aa8612bacb9d" category="inline-link-rx"></block>.</block>
  <block id="128dd96b5323b02401db618a27f67394" category="paragraph">Ecco una schermata dell'opzione HCX vMotion.</block>
  <block id="d77e1c6edbcf98bc28017153ba737ae7" category="paragraph"><block ref="d77e1c6edbcf98bc28017153ba737ae7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="efb5f7e867e5fc98adcdcb1d219cdd4a" category="admonition">Assicurarsi che sia disponibile una larghezza di banda sufficiente per gestire la migrazione.</block>
  <block id="6147587d84b933dcb429334a5e2594f9" category="admonition">Il datastore ANF di destinazione deve disporre di spazio sufficiente per gestire la migrazione.</block>
  <block id="d7372a0d2d0e1ec31f9e1d607d52e246" category="paragraph">Sia che tu stia prendendo come riferimento il cloud all-cloud o ibrido e i dati che risiedono su storage di qualsiasi tipo/vendor in on-premise, Azure NetApp Files e HCX offrono eccellenti opzioni per implementare e migrare i carichi di lavoro delle applicazioni, riducendo al contempo il TCO rendendo i requisiti dei dati perfetti a livello applicativo. Qualunque sia il caso d'utilizzo, scegli la soluzione VMware Azure insieme a Azure NetApp Files per una rapida realizzazione dei vantaggi del cloud, un'infrastruttura coerente e operazioni su cloud multipli e on-premise, portabilità bidirezionale dei carichi di lavoro e capacità e performance di livello Enterprise. Si tratta degli stessi processi e procedure familiari utilizzati per connettere lo storage e migrare le macchine virtuali utilizzando VMware vSphere Replication, VMware vMotion o persino la copia del file di rete (NFC).</block>
  <block id="7a7f4f94771d5c3f94a76599dcacb0cf" category="list-text">Ora puoi utilizzare Azure NetApp Files come datastore su Azure VMware Solution SDDC.</block>
  <block id="44b43fa706a816b30490196d187959c4" category="list-text">È possibile migrare facilmente i dati da un datastore on-premise a un datastore Azure NetApp Files.</block>
  <block id="bc6808bfb84f0a05f9640103114929fa" category="list-text">È possibile espandere e ridurre facilmente il datastore Azure NetApp Files per soddisfare i requisiti di capacità e performance durante l'attività di migrazione.</block>
  <block id="a13de136306e099dce523fd8db3f037c" category="list-text">Documentazione della soluzione VMware Azure</block>
  <block id="2f2e78e0c7d7ff0caf67f34519d3f5e5" category="inline-link"><block ref="2f2e78e0c7d7ff0caf67f34519d3f5e5" category="inline-link-rx"></block></block>
  <block id="5e65b51c08430d6fa3dc13275b00da9d" category="paragraph"><block ref="5e65b51c08430d6fa3dc13275b00da9d" category="inline-link-rx"></block></block>
  <block id="6c32a3d0f1a665987b98dde5a0f96d7d" category="list-text">Documentazione Azure NetApp Files</block>
  <block id="ac236475735595f1237223b0184c5cca" category="inline-link"><block ref="ac236475735595f1237223b0184c5cca" category="inline-link-rx"></block></block>
  <block id="742cb4a55dadc1d5ca8efd2956575138" category="paragraph"><block ref="742cb4a55dadc1d5ca8efd2956575138" category="inline-link-rx"></block></block>
  <block id="827f15aa97cbfccd71eb2ba3ac7d4eac" category="doc">Opzione supplementare NFS Datastore in Azure</block>
  <block id="8d60f49fa5ec93fd2bea5e083359bdc1" category="paragraph">Il supporto per datastore NFS è stato introdotto con ESXi versione 3 nelle implementazioni on-premise, che hanno notevolmente ampliato le funzionalità di storage di vSphere.</block>
  <block id="1aaea72f240547a6a057b9a88a27144b" category="paragraph">L'esecuzione di vSphere su NFS è un'opzione ampiamente adottata per le implementazioni di virtualizzazione on-premise perché offre performance e stabilità elevate. Se si dispone di uno storage NAS (Network-Attached Storage) significativo in un data center on-premise, si consiglia di implementare una soluzione Azure VMware SDDC in Azure con archivi dati Azure NetApp per superare le sfide di capacità e performance.</block>
  <block id="19fb9916968211db983d13bffe0cc6af" category="inline-link">99.99%</block>
  <block id="ad25c186e2eeaa2ec5fa0b9d3fa4b8c7" category="paragraph">Azure NetApp Files si basa sul software per la gestione dei dati NetApp ONTAP, leader del settore e altamente disponibile. I servizi Microsoft Azure sono raggruppati in tre categorie: Di base, mainstream e specialistiche. Azure NetApp Files è nella categoria specializzata ed è supportato da hardware già implementato in molte regioni. Grazie all'alta disponibilità (ha) integrata, Azure NetApp Files protegge i dati dalla maggior parte delle interruzioni e offre uno SLA leader del settore<block ref="404362048587970f5f15a4d9376a71ea" category="inline-link-rx"></block> uptime.</block>
  <block id="1b69b6091c2756a0aac2b81e4a880f93" category="paragraph">Prima dell'introduzione della funzionalità datastore di Azure NetApp Files, le operazioni scale-out per i clienti che intendono ospitare carichi di lavoro ad alta intensità di performance e storage richiedevano l'espansione di calcolo e storage.</block>
  <block id="09d432ffd44a3af2e2524362730628cf" category="paragraph">Tenere presenti i seguenti problemi:</block>
  <block id="79786892120b18078ded972068ce7cab" category="list-text">In un cluster SDDC non sono consigliate configurazioni di cluster sbilanciate. Pertanto, espandere lo storage significa aggiungere più host, il che implica un TCO maggiore.</block>
  <block id="4d7a269595fa13e9d4bb48449c996a41" category="list-text">È possibile utilizzare un solo ambiente vSAN. Pertanto, tutto il traffico dello storage compete direttamente con i carichi di lavoro di produzione.</block>
  <block id="99407e1fc016dc5a4f17896a330e66b0" category="list-text">Non esiste alcuna opzione per fornire più livelli di performance per allineare requisiti, performance e costi delle applicazioni.</block>
  <block id="f5188d9f655a6ac9c3d0dccb20d81997" category="list-text">È facile raggiungere i limiti della capacità di storage per vSAN costruito sugli host cluster.integrando le offerte platform-as-a-service (PaaS) native di Azure come Azure NetApp Files come datastore, I clienti hanno la possibilità di scalare in modo indipendente lo storage separatamente e aggiungere nodi di calcolo al cluster SDDC solo se necessario. Questa funzionalità consente di superare le sfide menzionate in precedenza.</block>
  <block id="d6e093aa5c1e7500fe79b8732c410c91" category="paragraph">Azure NetApp Files consente inoltre di implementare più datastore, che consentono di simulare un modello di implementazione on-premise posizionando le macchine virtuali nel datastore appropriato e assegnando il livello di servizio richiesto per soddisfare i requisiti di performance dei workload. Grazie all'esclusiva funzionalità del supporto multiprotocollo, lo storage guest è un'opzione aggiuntiva per i carichi di lavoro dei database come SQL e Oracle, oltre a utilizzare la funzionalità aggiuntiva del datastore NFS per ospitare i rimanenti VMDK. Inoltre, la funzionalità di snapshot nativa consente di eseguire backup rapidi e ripristini granulari.</block>
  <block id="cf1c082028930ec1827badc0e64627c6" category="admonition">Contatta Azure e NetApp Solution Architect per pianificare e dimensionare lo storage e determinare il numero richiesto di host. NetApp consiglia di identificare i requisiti di performance dello storage prima di finalizzare il layout del datastore per le implementazioni di test, POC e produzione.</block>
  <block id="402936a0724fed1eeed39a4791eae422" category="paragraph">Da un punto di vista di alto livello, questa architettura descrive come ottenere connettività del cloud ibrido e portabilità delle applicazioni in ambienti on-premise e Azure. Descrive inoltre l'utilizzo di Azure NetApp Files come datastore NFS supplementare e come opzione di storage in-guest per le macchine virtuali guest ospitate sulla soluzione VMware Azure.</block>
  <block id="1622404dda50f5803c9577efc058ec11" category="paragraph"><block ref="1622404dda50f5803c9577efc058ec11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3488e5e13ca2586de3bcc01700bd61b" category="paragraph">L'aspetto più importante nella migrazione o nel disaster recovery è determinare le dimensioni corrette per l'ambiente di destinazione. È molto importante capire quanti nodi sono necessari per ospitare un esercizio di lift-and-shift da on-premise a Azure VMware Solution.</block>
  <block id="b39d58eedf7db669f2a65fd75198d49e" category="paragraph">Per il dimensionamento, utilizza i dati storici dell'ambiente on-premise utilizzando RVTools (preferito) o altri strumenti come Live Optics o Azure Migrate. RVTools è uno strumento ideale per acquisire vCPU, VMEM, disco virtuale e tutte le informazioni richieste, incluse le macchine virtuali accese o spente, per caratterizzare l'ambiente di destinazione.</block>
  <block id="9b45f8f524f59dcb44852dc933d31d60" category="paragraph">Per eseguire RVtools, attenersi alla seguente procedura:</block>
  <block id="b9b14f9a77af6302e167ec8031bac435" category="list-text">Scaricare e installare RVTools.</block>
  <block id="a379941a0582174b350ce316b1e64b36" category="list-text">Eseguire RVTools, immettere le informazioni richieste per connettersi al server vCenter on-premise e premere Login.</block>
  <block id="7d0ff8053a5012b379d5e45f7d80bd81" category="list-text">Esportare l'inventario in un foglio di calcolo Excel.</block>
  <block id="ad7235861abcfd585f9793a320142cb9" category="list-text">Modifica il foglio di calcolo e rimuovi le macchine virtuali che non sono candidate ideali dalla scheda vInfo. Questo approccio fornisce un output chiaro sui requisiti di storage che possono essere utilizzati per dimensionare correttamente il cluster Azure VMware SDDC con il numero richiesto di host.</block>
  <block id="66a03e4bdc70563bcc83f39fd18f2993" category="admonition">Le macchine virtuali guest utilizzate con lo storage in-guest devono essere calcolate separatamente; tuttavia, Azure NetApp Files può facilmente coprire la capacità di storage aggiuntiva, mantenendo così basso il TCO complessivo.</block>
  <block id="ee7f083efd1984641bff3ff302c447a9" category="section-title">Implementazione e configurazione di Azure VMware Solution</block>
  <block id="95220678e12ace3a65339c08bb6019e5" category="paragraph">Come on-premise, la pianificazione di una soluzione Azure VMware è fondamentale per un ambiente pronto per la produzione di successo per la creazione di macchine virtuali e la migrazione.</block>
  <block id="1b3379256eb1cb0d26126368cc62ab52" category="paragraph">In questa sezione viene descritto come configurare e gestire AVS per l'utilizzo in combinazione con Azure NetApp Files come datastore con lo storage in-guest.</block>
  <block id="449e01682ffd6d9e79c75acf22fa249b" category="list-text">Registrare il provider di risorse e creare un cloud privato.</block>
  <block id="17d7be5e1d44a11ff74be89af34822c9" category="list-text">Connettersi a un gateway di rete virtuale ExpressRoute nuovo o esistente.</block>
  <block id="28325f137394bcd829a01024c035cb5e" category="list-text">Convalidare la connettività di rete e accedere al cloud privato. Fare riferimento a questo <block ref="c494c3efc2923b26ad63800ea1f5c612" category="inline-link-macro-rx"></block> Per una panoramica dettagliata del processo di provisioning SDDC della soluzione VMware di Azure.</block>
  <block id="b2666a13d31389019b43a9085ffd2fe8" category="section-title">Configurazione di Azure NetApp Files con la soluzione VMware Azure</block>
  <block id="dbfbac0b1aee2557c747f90a52c200ed" category="paragraph">La nuova integrazione tra Azure NetApp Files consente di creare datastore NFS tramite le API/CLI del provider di risorse della soluzione VMware Azure con volumi Azure NetApp Files e di montare i datastore sui cluster scelti in un cloud privato. Oltre a ospitare le VM e le VMDK delle applicazioni, è possibile montare i volumi di file di Azure NetApp anche dalle macchine virtuali create nell'ambiente SDDC di Azure VMware Solution. I volumi possono essere montati sul client Linux e mappati su un client Windows, perché Azure NetApp Files supporta i protocolli SMB (Server message Block) e NFS (Network file System).</block>
  <block id="3fcf61e60f3486b366489a2db86e92c0" category="admonition">Per ottenere performance ottimali, implementa Azure NetApp Files nella stessa zona di disponibilità del cloud privato. La co-locazione con Express Route fastpath offre le migliori performance, con una latenza di rete minima.</block>
  <block id="7042805ebe69bccc6ab09f9518f94556" category="paragraph">Per collegare un volume Azure NetApp file come archivio dati VMware di un cloud privato Azure VMware Solution, assicurarsi che siano soddisfatti i seguenti prerequisiti.</block>
  <block id="49588f95c73f4a9df95958ba5e856d0c" category="list-text">Utilizzare l'accesso az e verificare che l'abbonamento sia registrato alla funzionalità CloudSanExperience nello spazio dei nomi Microsoft.AVS.</block>
  <block id="c0e46e4183896be214bad3fd077b5834" category="list-text">Se non è registrato, registrarlo.</block>
  <block id="8fb14eb63139db9a1c626865766368e4" category="admonition">Il completamento della registrazione può richiedere circa 15 minuti.</block>
  <block id="91bc7290f2d4745c25033c52b73c0662" category="list-text">Per verificare lo stato della registrazione, eseguire il seguente comando.</block>
  <block id="bd00d81bc80103cfbf6f24470f9de4fa" category="list-text">Se la registrazione rimane bloccata in uno stato intermedio per più di 15 minuti, annullare la registrazione e registrare nuovamente il flag.</block>
  <block id="30d4986a1e28c78ed243b8fe94ebe5be" category="list-text">Verificare che l'abbonamento sia registrato alla funzionalità AnfDatastoreExperience nello spazio dei nomi Microsoft.AVS.</block>
  <block id="10b9b69a3124f921ee9a3a8271028b78" category="list-text">Verificare che l'estensione vmware sia installata.</block>
  <block id="329e9fb0e53008fcf269d03c5476847d" category="list-text">Se l'estensione è già installata, verificare che la versione sia 3.0.0. Se è installata una versione precedente, aggiornare l'estensione.</block>
  <block id="f5e4a463688cab0acae8d53e64bd5e36" category="list-text">Se l'estensione non è già installata, installarla.</block>
  <block id="8c8b1c25fd4bcb4102a3a834f721ec3e" category="example-title">Creare e montare volumi Azure NetApp Files</block>
  <block id="11d2eb5b9d070e139a779747ce885490" category="list-text">Accedere al portale Azure e a Azure NetApp Files. Verificare l'accesso al servizio Azure NetApp Files e registrare il provider di risorse Azure NetApp Files utilizzando<block ref="37ac6d6acd87f35d4712fb725270d9df" prefix=" " category="inline-code"></block><block ref="d6c188468a5654ff07f3d8da04d06877" prefix=" " category="inline-code"></block> comando. Dopo la registrazione, creare un account NetApp. Fare riferimento a questo<block ref="2c2f4008511e047aaaf92ad514e98ec9" category="inline-link-rx"></block> per i passaggi dettagliati.</block>
  <block id="09e7af76fc12c4b14e8fbca51314b508" category="paragraph"><block ref="09e7af76fc12c4b14e8fbca51314b508" category="inline-image-macro-rx" type="image"></block></block>
  <block id="187927c7525fb36ec9428b4d84fe0aff" category="list-text">Dopo aver creato un account NetApp, impostare i pool di capacità con il livello e le dimensioni di servizio richiesti. Per informazioni dettagliate, fare riferimento a questa sezione<block ref="0a52e91c67ac030fc237a7b13d0404c6" category="inline-link-rx"></block>.</block>
  <block id="c7d6fd5f235d0c8a960facf04a79e4a7" category="paragraph"><block ref="c7d6fd5f235d0c8a960facf04a79e4a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c573a9eace62b9790820458dd59448b0" category="list-text">NFSv3 è supportato per gli archivi dati su Azure NetApp Files.</block>
  <block id="c91dcf7c665570f3603fa32cb3a8c644" category="list-text">Utilizza il Tier Premium o standard per i carichi di lavoro legati alla capacità e il Tier Ultra per i carichi di lavoro legati alle performance, se necessario, integrando lo storage vSAN predefinito.</block>
  <block id="0d55d5c3a7459f59fd437a2311322791" category="list-text">Configurare una subnet delegata per Azure NetApp Files e specificare questa subnet durante la creazione dei volumi. Per informazioni dettagliate sulla creazione di una subnet delegata, fare riferimento a questa sezione<block ref="e84891bed408b1977d062f4ccc1816aa" category="inline-link-rx"></block>.</block>
  <block id="36fc58c2c3fa32ac586d5628570e9499" category="list-text">Aggiungere un volume NFS per il datastore utilizzando il blade Volumes sotto il blade Capacity Pools.</block>
  <block id="2832d137c1714a9759f87412fb05253e" category="paragraph"><block ref="2832d137c1714a9759f87412fb05253e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe5eed95829ff2b525461ee72a9f3f23" category="inline-link-macro">Considerazioni sulle performance per Azure NetApp Files</block>
  <block id="60ce6ba5fcd445684c9982883f234b8c" category="paragraph">Per ulteriori informazioni sulle prestazioni dei volumi Azure NetApp Files in base alle dimensioni o alla quota, vedere <block ref="62d66f64400ed6e4ba5e012bbe140a31" category="inline-link-macro-rx"></block>.</block>
  <block id="372d7a6604390fe9757888aff0a92970" category="example-title">Aggiungi datastore Azure NetApp Files al cloud privato</block>
  <block id="a01ca5d7b443422e0bc655c4d457707f" category="inline-link-macro">Collegamento da Microsoft</block>
  <block id="37028a2422f1f35ed56a07f1003896d1" category="admonition">Il volume Azure NetApp Files può essere collegato al cloud privato utilizzando il portale Azure. Seguire questa procedura <block ref="c627cf01abf17d7b29d4322a9f16e21d" category="inline-link-macro-rx"></block> Per un approccio graduale all'utilizzo del portale Azure per il montaggio di un datastore Azure NetApp Files.</block>
  <block id="0f9e7cabe2f81455810e96baca91c6a7" category="paragraph">Per aggiungere un datastore Azure NetApp Files a un cloud privato, attenersi alla seguente procedura:</block>
  <block id="b1248573ef968f7d6fc7eaa453fa4d45" category="list-text">Una volta registrate le funzionalità richieste, collegare un datastore NFS al cluster di cloud privato Azure VMware Solution eseguendo il comando appropriato.</block>
  <block id="567531ac8390e0378f43db080cbeec2b" category="list-text">Creare un datastore utilizzando un volume ANF esistente nel cluster di cloud privato Azure VMware Solution.</block>
  <block id="ed491060b6ac47e89ad70eecda183065" category="paragraph">{ { 4497 } "diskPoolVolume": Null, "id": "/subscriptions/0efa2dfb-917c-4497-b56a-b3f4eadb8111/resvalores, Microsoft.NetApp/netAppAccounts/anfdatastoreacct/capacityPools/anfrecods/volumes/ANFRecoDS001" "DSAF3f2llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll } { "DiskPoolVolume": Null, "id": "/subscriptions/0efa2dfb-917c-4497-b56a-b3f4eadb8111/resourceGroups/anfavanswal2/providers/Microsoft.AVS/privateDafay2/{/}/favanswalb2": "Appfavanswalb/Microsoft.NetApp/netAppAccounts/anfdatastoreacct/capacityPools/anfrecodsu/volumes/anfrecodsU002"", "adswalb/}/4497", "avanswalb/favanswalb/fa002", "adswalb/favanswalb/favanswalb": "Adswalb//adswalb//adswalb/f2", "adswalb/adswalb/adswalb: "Adswalb/adswalb/adswalb/adswalb//adswalb/adswalb/adswalb//adswalb", "adswalb", "adswalb</block>
  <block id="d1903b7932291ae49bf265e5af7a75f4" category="list-text">Una volta installata la connettività necessaria, i volumi vengono montati come datastore.</block>
  <block id="b9eb0553d93e0e4bbee4142fec9403f9" category="paragraph"><block ref="b9eb0553d93e0e4bbee4142fec9403f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="078f601da77f62e8c7e097d5744f9b1b" category="section-title">Dimensionamento e ottimizzazione delle performance</block>
  <block id="2954ff66e26b577154cf218d077ff1a9" category="paragraph">Azure NetApp Files supporta tre livelli di servizio: Standard (16 Mbps per terabyte), Premium (64 MB per terabyte) e Ultra (128 MB per terabyte). Il provisioning delle giuste dimensioni del volume è importante per ottenere performance ottimali del carico di lavoro del database. Con Azure NetApp Files, le performance dei volumi e il limite di throughput vengono determinati in base ai seguenti fattori:</block>
  <block id="a5d62ae512b963e1f05e839467577f19" category="paragraph"><block ref="a5d62ae512b963e1f05e839467577f19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7dfe1e95238cceec93165ab8ff605d28" category="paragraph">Fare riferimento a questo <block ref="06f6144b70bdd3c5a376672271533656" category="inline-link-macro-rx"></block> per benchmark dettagliati delle performance che possono essere utilizzati durante un esercizio di dimensionamento.</block>
  <block id="b1404b6b3614fe54358fb1bdb8bd294a" category="list-text">Utilizza il Tier Premium o Standard per i volumi del datastore per ottenere capacità e performance ottimali. Se sono richieste prestazioni, è possibile utilizzare il Tier Ultra.</block>
  <block id="1048ee221e43763386324d16721681fc" category="list-text">Per i requisiti di montaggio guest, utilizzare il Tier Premium o Ultra e, per i requisiti di condivisione file per le macchine virtuali guest, utilizzare volumi Tier Standard o Premium.</block>
  <block id="1261ba8eeb83d9d138ff9e9a37214a7e" category="section-title">Considerazioni sulle performance</block>
  <block id="f4479400cc63a0bc54ea3a609d8d89aa" category="paragraph">È importante comprendere che con NFS versione 3 esiste una sola pipe attiva per la connessione tra l'host ESXi e una singola destinazione di storage. Ciò significa che, anche se potrebbero essere disponibili connessioni alternative per il failover, la larghezza di banda per un singolo datastore e lo storage sottostante sono limitati a ciò che una singola connessione può fornire.</block>
  <block id="f4c57c87dfa0d5843279b51c6e10d0a6" category="paragraph">Per sfruttare una maggiore larghezza di banda disponibile con i volumi Azure NetApp Files, un host ESXi deve disporre di più connessioni alle destinazioni di storage. Per risolvere questo problema, è possibile configurare più datastore, con ciascun datastore utilizzando connessioni separate tra l'host ESXi e lo storage.</block>
  <block id="bde357669435115ce8fac67e3a3a5786" category="paragraph">Per una maggiore larghezza di banda, come Best practice, creare più datastore utilizzando più volumi ANF, creare VMDK e stripare i volumi logici tra VMDK.</block>
  <block id="c01a936a44f773bc3d0a636cb655c28c" category="list-text">La soluzione VMware di Azure consente otto datastore NFS per impostazione predefinita. Questo può essere aumentato attraverso una richiesta di supporto.</block>
  <block id="cd58e3b202d882202a16834028640630" category="list-text">Sfrutta ER fastpath insieme a Ultra SKU per una maggiore larghezza di banda e una latenza inferiore. Ulteriori informazioni</block>
  <block id="6ef5173b6cc36d0f4efabbafeeee7443" category="list-text">Con le funzioni di rete "di base" di Azure NetApp Files, la connettività della soluzione VMware Azure è legata alla larghezza di banda del circuito ExpressRoute e del gateway ExpressRoute.</block>
  <block id="e421004f0e3e2303f272ef4b0fa6c089" category="list-text">Per i volumi Azure NetApp Files con funzioni di rete "standard", è supportato ExpressRoute FastPath. Se attivato, FastPath invia il traffico di rete direttamente ai volumi Azure NetApp Files, bypassando il gateway fornendo una maggiore larghezza di banda e una latenza inferiore.</block>
  <block id="0d3f5dc8a647758ee9ad71d0af34e75e" category="section-title">Aumento delle dimensioni del datastore</block>
  <block id="9ae97248366686f76c6f9f6ac9b8d073" category="paragraph">La riformizzazione dei volumi e le modifiche dinamiche dei livelli di servizio sono completamente trasparenti per SDDC. In Azure NetApp Files, queste funzionalità offrono performance continue, capacità e ottimizzazioni dei costi. Aumentare le dimensioni degli archivi dati NFS ridimensionando il volume da Azure Portal o utilizzando la CLI. Al termine dell'operazione, accedere a vCenter, accedere alla scheda datastore, fare clic con il pulsante destro del mouse sull'archivio dati appropriato e selezionare Refresh Capacity Information (Aggiorna informazioni capacità). Questo approccio può essere utilizzato per aumentare la capacità del datastore e per aumentare le performance del datastore in modo dinamico senza downtime. Questo processo è anche completamente trasparente per le applicazioni.</block>
  <block id="fad725216d945a6443f15949ae73b316" category="cell">Punti da ricordare</block>
  <block id="264b475cf0374b319edf3b094fe25874" category="list-text">La riformizzazione dei volumi e la funzionalità dinamica del livello di servizio consentono di ottimizzare i costi dimensionando i carichi di lavoro a stato stazionario ed evitando così l'overprovisioning.</block>
  <block id="80a4a92a47a4b87bb9d0fcf9ded1dda8" category="list-text">VAAI non abilitato.</block>
  <block id="35084d885dea7b061e6894c1cf3036d9" category="section-title">Carichi di lavoro</block>
  <block id="f7458ac9343d5418ff038f156d9b29fc" category="paragraph">Uno dei casi di utilizzo più comuni è la migrazione. Utilizzare VMware HCX o vMotion per spostare macchine virtuali on-premise. In alternativa, è possibile utilizzare Rivermeadow per migrare le macchine virtuali in datastore Azure NetApp Files.</block>
  <block id="21a1e68164f738b8be1dae11d5a694b3" category="example-title">Protezione dei dati</block>
  <block id="36e402ac6b1a4b9a31bd376a7f89c68e" category="paragraph">Il backup delle macchine virtuali e il loro rapido ripristino sono tra i punti di forza degli archivi dati ANF. Utilizza le copie Snapshot per creare copie rapide della tua macchina virtuale o del datastore senza influire sulle performance, quindi inviale allo storage Azure per una protezione dei dati a lungo termine o a una regione secondaria utilizzando la replica cross-region per il disaster recovery. Questo approccio riduce al minimo lo spazio di storage e la larghezza di banda della rete memorizzando solo le informazioni modificate.</block>
  <block id="2bd24edc1157f2ea366bbf67e980b57e" category="paragraph">Utilizzare le copie Snapshot di Azure NetApp Files per la protezione generale e gli strumenti applicativi per proteggere i dati transazionali come SQL Server o Oracle che risiedono sulle macchine virtuali guest. Queste copie Snapshot sono diverse dalle snapshot VMware (coerenza) e sono adatte per una protezione a lungo termine.</block>
  <block id="c69157396b1ac0cb910d839c99a0a9e3" category="admonition">Con gli archivi dati ANF, l'opzione Restore to New Volume (Ripristina su nuovo volume) può essere utilizzata per clonare un intero volume dell'archivio dati e il volume ripristinato può essere montato come un altro archivio dati negli host all'interno di AVS SDDC. Dopo aver montato un datastore, le VM all'interno dell'IT possono essere registrate, riconfigurate e personalizzate come se fossero macchine virtuali clonate singolarmente.</block>
  <block id="92b97805e00b695b9f8aeddf2cc8828d" category="example-title">Backup cloud per macchine virtuali</block>
  <block id="3b0ec96ab43930bb5b0f274d7a4733bd" category="paragraph">Cloud Backup per macchine virtuali fornisce un'interfaccia grafica del client web vSphere su vCenter per proteggere le macchine virtuali e i datastore Azure NetApp Files di Azure VMware Solution tramite policy di backup. Queste policy possono definire pianificazione, conservazione e altre funzionalità. La funzionalità Cloud Backup per Virtual Machine può essere implementata utilizzando il comando Esegui.</block>
  <block id="ad15ef62ee17e83e2a2c4de5cfc0a7e0" category="paragraph">I criteri di installazione e protezione possono essere installati completando la procedura seguente:</block>
  <block id="68efc774d1525ecfc4ad132a4f363c10" category="list-text">Installare Cloud Backup per macchina virtuale nel cloud privato Azure VMware Solution utilizzando il comando Esegui.</block>
  <block id="3a1d9263efa0039dd46c2e2d0dfc2dec" category="list-text">Aggiungere le credenziali di abbonamento al cloud (valore client e segreto), quindi aggiungere un account di abbonamento al cloud (account NetApp e gruppo di risorse associato) contenente le risorse che si desidera proteggere.</block>
  <block id="60d5826756f013d28eadac75aec57698" category="list-text">Creare una o più policy di backup per gestire la conservazione, la frequenza e altre impostazioni per i backup dei gruppi di risorse.</block>
  <block id="6ad3833cba216d2fe6639be4726ad69e" category="list-text">Creare un container per aggiungere una o più risorse che devono essere protette con criteri di backup.</block>
  <block id="f0c88a652a15d9fedafa82483a1959b4" category="list-text">In caso di guasto, ripristinare l'intera macchina virtuale o i singoli VMDK specifici nella stessa posizione.</block>
  <block id="52c902402ab9b60471632cf95f1940b6" category="admonition">Con la tecnologia Snapshot di Azure NetApp Files, i backup e i ripristini sono molto veloci.</block>
  <block id="08042ba10c942968c10ed6576a20c1e6" category="paragraph"><block ref="08042ba10c942968c10ed6576a20c1e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e3a1d923fd4fc5d2bc1c7e9ac58f59ef" category="example-title">Disaster recovery con Azure NetApp Files, JetStream DR e Azure VMware Solution</block>
  <block id="93460124cbffe590c9cee7667d85d1da" category="paragraph">Il disaster recovery nel cloud è un metodo resiliente e conveniente per proteggere i carichi di lavoro da interruzioni del sito ed eventi di corruzione dei dati (ad esempio ransomware). Utilizzando il framework VMware VAIO, è possibile replicare i workload VMware on-premise sullo storage Azure Blob e ripristinarli, consentendo una perdita di dati minima o quasi nulla e un RTO quasi nullo. Il DR Jetstream può essere utilizzato per ripristinare perfettamente i carichi di lavoro replicati da on-premise ad AVS e in particolare a Azure NetApp Files. Consente un disaster recovery conveniente utilizzando risorse minime presso il sito di DR e uno storage cloud conveniente. Jetstream DR automatizza il ripristino degli archivi dati ANF tramite Azure Blob Storage. Jetstream DR ripristina macchine virtuali indipendenti o gruppi di macchine virtuali correlate nell'infrastruttura del sito di ripristino in base alla mappatura di rete e fornisce un ripristino point-in-time per la protezione ransomware.</block>
  <block id="8b8adea1567023f8a36745e1e256b41e" category="inline-link-macro">Soluzione DR con ANF, JetStream e AVS</block>
  <block id="adeb8aee914844a07a855dd7b8fe7ffc" category="paragraph"><block ref="d016a1e57ae2464bcf00474caa126151" category="inline-link-macro-rx"></block>.</block>
  <block id="7e0686a26bc7a91429819c2aeb7b414a" category="doc">Soluzioni NetApp per Azure VMware Solution (AVS)</block>
  <block id="a46eb72d67c0cbcbbdfcde010fbc0b03" category="paragraph">Scopri di più sulle soluzioni offerte da NetApp ad Azure.</block>
  <block id="af68f7a1e7ca322318bf949baba2129e" category="inline-link-macro">Disaster Recovery con ANF e JetStream (datastore NFS supplementare)</block>
  <block id="73c807da78ef06fdb99e2307b5d8cb57" category="list-text"><block ref="73c807da78ef06fdb99e2307b5d8cb57" category="inline-link-macro-rx"></block></block>
  <block id="f93c390413608eaad8cc43b29f8073d0" category="inline-link-macro">Disaster Recovery con ANF e CVO (storage connesso guest)</block>
  <block id="233b8f979ad627e56656fbdd647fdc2b" category="list-text"><block ref="233b8f979ad627e56656fbdd647fdc2b" category="inline-link-macro-rx"></block></block>
  <block id="e41aedb86788cb5e4409a06bc4b16279" category="inline-link-macro">Disaster Recovery (DRO) con ANF e AVS</block>
  <block id="c26f803d28a5cb346d4655a22f90bb26" category="list-text"><block ref="c26f803d28a5cb346d4655a22f90bb26" category="inline-link-macro-rx"></block></block>
  <block id="04a1b40e30ee3bddef53c85ca68c8b36" category="inline-link-macro">Migrazione dei carichi di lavoro nel datastore Azure NetApp Files con VMware HCX</block>
  <block id="edf47ba9dc6467e3104102f10bafe323" category="list-text"><block ref="edf47ba9dc6467e3104102f10bafe323" category="inline-link-macro-rx"></block></block>
  <block id="7a328b7e18172ee10e60d198b9fc26f7" category="doc">Soluzioni multicloud ibride NetApp per Azure/AVS</block>
  <block id="00ce356ad004b72efc4b99389b52af63" category="paragraph">Come per la soluzione VMware di Azure on-premise, la pianificazione è fondamentale per un ambiente pronto per la produzione di successo per la creazione di macchine virtuali e la migrazione.</block>
  <block id="6a3b9d31df0a58cc23207c2af925ef0f" category="paragraph">Per utilizzare Azure VMware Solution, registrare innanzitutto il provider di risorse nell'abbonamento identificato:</block>
  <block id="58c59ab4d5d488609913efa7b1daaa31" category="list-text">Accedi al portale Azure.</block>
  <block id="5d704d400396fefbe3427ee665a0ec16" category="list-text">Nel menu del portale Azure, selezionare tutti i servizi.</block>
  <block id="eff35df9bedc80337261af1399e526a2" category="list-text">Nella finestra di dialogo tutti i servizi, inserire l'abbonamento e selezionare Abbonamenti.</block>
  <block id="41825376d695df481d13f37e3e1587db" category="list-text">Per visualizzare, selezionare l'abbonamento dall'elenco.</block>
  <block id="4d3e5a69b8f8c0bec64cf18db73fff95" category="list-text">Selezionare Resource Providers (Provider di risorse) e immettere Microsoft.AVS nella ricerca.</block>
  <block id="2bf384915bc11a9360bdf9792dc43bf3" category="list-text">Se il provider di risorse non è registrato, selezionare Registra.</block>
  <block id="0b4b8a7bf2e1e647f3be6dde423b9b79" category="paragraph"><block ref="0b4b8a7bf2e1e647f3be6dde423b9b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bdb08f4992bb541aec19da4c688d0239" category="paragraph"><block ref="bdb08f4992bb541aec19da4c688d0239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="382da60e8008eed186472cc1a3c3ca37" category="list-text">Una volta registrato il provider di risorse, creare un cloud privato Azure VMware Solution utilizzando il portale Azure.</block>
  <block id="397065cbdc87787d17122a18f5c5088d" category="list-text">Selezionare Crea una nuova risorsa.</block>
  <block id="39d2b5824a6dce05a74b5a60d5769656" category="list-text">Nella casella di testo Cerca nel marketplace, immettere Azure VMware Solution e selezionarla dai risultati.</block>
  <block id="d090262ac8690f612cbc8bd5fc83b11c" category="list-text">Nella pagina Azure VMware Solution, selezionare Create (Crea).</block>
  <block id="4a62c7a4f3f3f4a3927621c33c12bb63" category="list-text">Nella scheda Basics (informazioni di base), immettere i valori nei campi e selezionare Review (esamina) + Create (Crea).</block>
  <block id="7c1ec568c35f8a03d9cfd64b465a4e4f" category="list-text">Per un rapido avvio, raccogliere le informazioni necessarie durante la fase di pianificazione.</block>
  <block id="d61ffacba4094067e86b90bcf3739fcf" category="list-text">Selezionare un gruppo di risorse esistente o creare un nuovo gruppo di risorse per il cloud privato. Un gruppo di risorse è un container logico in cui le risorse Azure vengono distribuite e gestite.</block>
  <block id="81d6141ddb9ac3b3888dce83fbf00cf6" category="list-text">Assicurarsi che l'indirizzo CIDR sia univoco e non si sovrapponga ad altre reti virtuali Azure o on-premise. Il CIDR rappresenta la rete di gestione del cloud privato e viene utilizzato per i servizi di gestione del cluster, come vCenter Server e NSX-T Manager. NetApp consiglia di utilizzare uno spazio di indirizzi /22. In questo esempio, viene utilizzato 10.21.0.0/22.</block>
  <block id="266811324b3ca32d24624ba571c07de8" category="paragraph"><block ref="266811324b3ca32d24624ba571c07de8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd710e77504d5568fd5079361107a7eb" category="paragraph">Il processo di provisioning richiede circa 4-5 ore. Una volta completato il processo, verificare che l'implementazione abbia avuto esito positivo accedendo al cloud privato dal portale Azure. Al termine dell'implementazione viene visualizzato lo stato riuscito.</block>
  <block id="411f20742da0d4f8cdc568d7aee8fab3" category="paragraph">Un cloud privato Azure VMware Solution richiede una rete virtuale Azure. Poiché Azure VMware Solution non supporta vCenter on-premise, sono necessari ulteriori passaggi per l'integrazione con un ambiente on-premise esistente. È inoltre necessaria la configurazione di un circuito ExpressRoute e di un gateway di rete virtuale. In attesa del completamento del provisioning del cluster, creare una nuova rete virtuale o utilizzarne una esistente per connettersi alla soluzione VMware Azure.</block>
  <block id="aa86eba8b2b706f81a805eb35b834541" category="paragraph"><block ref="aa86eba8b2b706f81a805eb35b834541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ae6569fd64694b91a054cbdfdfef84d2" category="paragraph">Per creare una nuova rete virtuale Azure (VNET), selezionare la scheda Azure VNET Connect. In alternativa, è possibile crearne una manualmente dal portale Azure utilizzando la procedura guidata Create Virtual Network (Crea rete virtuale):</block>
  <block id="34b04201ae997eaabb6802b04d5c1708" category="list-text">Accedere al cloud privato Azure VMware Solution e alla connettività sotto l'opzione Manage (Gestisci).</block>
  <block id="da40ae630b63a930be4e1230efc306e1" category="list-text">Selezionare Azure VNET Connect.</block>
  <block id="40292c219898a1253befc6301234575a" category="list-text">Per creare un nuovo VNET, selezionare l'opzione Create New (Crea nuovo).</block>
  <block id="f98e10d9ba9ac83ac2adeacde774d051" category="paragraph">Questa funzione consente di connettere un VNET al cloud privato Azure VMware Solution. VNET consente la comunicazione tra i carichi di lavoro in questa rete virtuale creando automaticamente i componenti necessari (ad esempio, jump box, servizi condivisi come Azure NetApp Files e Cloud Volume ONTAP) al cloud privato creato in Azure VMware Solution su ExpressRoute.</block>
  <block id="0314a97a9eb0aae73531717ef45ad195" category="paragraph">*Nota:* lo spazio degli indirizzi VNET non deve sovrapporsi al CIDR del cloud privato.</block>
  <block id="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="paragraph"><block ref="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="inline-image-macro-rx" type="image"></block></block>
  <block id="206843027dd7ebe90f425f9ee4765a01" category="list-text">Fornire o aggiornare le informazioni per il nuovo VNET e selezionare OK.</block>
  <block id="26c6d54522f3fd79684f463116e9634b" category="paragraph"><block ref="26c6d54522f3fd79684f463116e9634b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="027524e66bad6099279342bf8d8f6dd4" category="paragraph">La rete VNET con l'intervallo di indirizzi e la subnet del gateway forniti viene creata nel gruppo di risorse e di abbonamento designato.</block>
  <block id="5ecf2fb7501138eaa14be97a59d2a773" category="inline-link-macro">Configura il networking per il tuo cloud privato VMware in Azure</block>
  <block id="5da6ff60860f48de7bb7f4467c28f26f" category="admonition">Se si crea un VNET manualmente, creare un gateway di rete virtuale con lo SKU appropriato e ExpressRoute come tipo di gateway. Una volta completata l'implementazione, collegare la connessione ExpressRoute al gateway di rete virtuale contenente il cloud privato Azure VMware Solution utilizzando la chiave di autorizzazione. Per ulteriori informazioni, vedere <block ref="4807c1aea8c93bde3104bd4ecfa22a07" category="inline-link-macro-rx"></block>.</block>
  <block id="5c2d9a62bb25b00981f59e22e27bfd17" category="example-title">Convalidare la connessione di rete e l'accesso al cloud privato Azure VMware Solution</block>
  <block id="40228f700f5965975e4aff8c6c2ff4b3" category="paragraph">Azure VMware Solution non consente di gestire un cloud privato con VMware vCenter on-premise. Per connettersi all'istanza di Azure VMware Solution vCenter è invece necessario un host jump. Creare un host jump nel gruppo di risorse designato e accedere a Azure VMware Solution vCenter. Questo host jump dovrebbe essere una macchina virtuale Windows sulla stessa rete virtuale creata per la connettività e dovrebbe fornire l'accesso a vCenter e NSX Manager.</block>
  <block id="d88c36b93ae5dcb2646d56c57f27bf0e" category="paragraph"><block ref="d88c36b93ae5dcb2646d56c57f27bf0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44f5524c6ac4144dbabf7a4d365b837b" category="paragraph">Una volta eseguito il provisioning della macchina virtuale, utilizzare l'opzione Connect (Connetti) per accedere a RDP.</block>
  <block id="443f53614721177f7c44df93d426a919" category="paragraph"><block ref="443f53614721177f7c44df93d426a919" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36cb4e54805ffde727ffbc809183608e" category="paragraph">Accedere a vCenter da questa nuova macchina virtuale host jump utilizzando l'utente amministratore cloud . Per accedere alle credenziali, accedere al portale Azure e selezionare Identity (identità) (sotto l'opzione Manage (Gestisci) nel cloud privato). Da qui è possibile copiare gli URL e le credenziali utente per il cloud privato vCenter e NSX-T Manager.</block>
  <block id="9620acd59a8e7ad0f318754391c40c4e" category="paragraph"><block ref="9620acd59a8e7ad0f318754391c40c4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73d88630b730fa00c46338a0aef4c2d3" category="paragraph">Nella macchina virtuale Windows, aprire un browser e accedere all'URL del client Web vCenter <block ref="2db127a24dc88638a76677b404bda5a4" category="inline-link-rx"></block> e utilizzare il nome utente admin come *cloudadmin@vsphere.local* e incollare la password copiata. Allo stesso modo, è possibile accedere al gestore NSX-T anche utilizzando l'URL del client Web <block ref="bb142e18a679100de3817fcefaa25b07" category="inline-link-rx"></block> e utilizzare il nome utente admin e incollare la password copiata per creare nuovi segmenti o modificare i gateway tier esistenti.</block>
  <block id="4a6e0ba5b4d42fb0f658bdfdbbea32fc" category="admonition">Gli URL del client Web sono diversi per ogni SDDC fornito.</block>
  <block id="49848931415b32db238a2dd1daddf3a7" category="paragraph"><block ref="49848931415b32db238a2dd1daddf3a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="87f65f698ac6bac1ada03193e1cdabb8" category="paragraph"><block ref="87f65f698ac6bac1ada03193e1cdabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec3eeb836273dbc92b27ce718a90b212" category="inline-link-macro">Ambienti on-premise peer per Azure VMware Solution</block>
  <block id="097529edf2feb9ed1237427eaa3b2599" category="paragraph">Azure VMware Solution SDDC è ora implementato e configurato. Sfrutta ExpressRoute Global Reach per connettere l'ambiente on-premise al cloud privato Azure VMware Solution. Per ulteriori informazioni, vedere <block ref="29749340a5d7bf5df1867a3f2d2723a1" category="inline-link-macro-rx"></block>.</block>
  <block id="dee7570423fb41bfa5f00fd539ed91da" category="doc">Disponibilità regionale: Datastore NFS supplementare per ANF</block>
  <block id="9e779086e93810f8495caf5b07f578cd" category="paragraph">La disponibilità di datastore NFS supplementari su Azure / AVS è definita da Microsoft. Innanzitutto, è necessario determinare se AVS e ANF sono disponibili in una regione specifica. Quindi, è necessario determinare se il datastore NFS supplementare ANF è supportato in quella regione.</block>
  <block id="8ff7e1fad21e60bbdef17593aae83ff6" category="list-text">Verificare la disponibilità di AVS e ANF <block ref="757f75bead0b939967621d226ba54faa" category="inline-link-macro-rx"></block>.</block>
  <block id="2f53a51554f6e0b66622228f3db68361" category="list-text">Verificare la disponibilità del datastore NFS supplementare ANF <block ref="02ba6bc5fe71be0f7426aedd427de443" category="inline-link-macro-rx"></block>.</block>
  <block id="33a1a24f2edf4ad9358baef7fb3c9cdf" category="doc">Disaster Recovery con ANF e JetStream</block>
  <block id="14f4fb472fe43e084476c5d8329b15f8" category="paragraph">Il disaster recovery nel cloud è un metodo resiliente e conveniente per proteggere i carichi di lavoro da interruzioni del sito ed eventi di corruzione dei dati (ad esempio ransomware). Utilizzando il framework VMware VAIO, è possibile replicare i workload VMware on-premise sullo storage Azure Blob e ripristinarli, consentendo una perdita di dati minima o quasi nulla e un RTO quasi nullo.</block>
  <block id="b614fc13a076bceeca03cda9c4b1fdce" category="paragraph">Il DR Jetstream può essere utilizzato per ripristinare perfettamente i carichi di lavoro replicati da on-premise ad AVS e in particolare a Azure NetApp Files. Consente un disaster recovery conveniente utilizzando risorse minime presso il sito di DR e uno storage cloud conveniente. Jetstream DR automatizza il ripristino degli archivi dati ANF tramite Azure Blob Storage. Jetstream DR ripristina macchine virtuali indipendenti o gruppi di macchine virtuali correlate nell'infrastruttura del sito di ripristino in base alla mappatura di rete e fornisce un ripristino point-in-time per la protezione ransomware.</block>
  <block id="29d141d1797b070195b4a3a5af842d35" category="paragraph">Il presente documento fornisce informazioni sui principi operativi di DR di JetStream e sui relativi componenti principali.</block>
  <block id="0b3b3c3ee7cf95d87f597441efd5f743" category="example-title">Panoramica sull'implementazione della soluzione</block>
  <block id="1dff5e9fa7f5c212df3e98d343d6a771" category="list-text">Installare il software DR JetStream nel data center on-premise.</block>
  <block id="7b87ce74b3d0f7e81fef7a7994f9c8ed" category="list-text">Scarica il pacchetto software DR JetStream da Azure Marketplace (ZIP) e implementa il DR MSA (OVA) JetStream nel cluster designato.</block>
  <block id="56c27e9a114a51f4863d0fef4cab3eba" category="list-text">Configurare il cluster con il pacchetto di filtri i/o (installare JetStream VIB).</block>
  <block id="43de8924da88a34109307d6aac84811a" category="list-text">Provisioning di Azure Blob (Azure Storage account) nella stessa regione del cluster DR AVS.</block>
  <block id="2cee29b70a6ea4765a6365e4d71775c7" category="list-text">Implementare appliance DRVA e assegnare volumi di log di replica (VMDK da datastore esistente o storage iSCSI condiviso).</block>
  <block id="9c6ca12d0f999d69d715e02482665e5d" category="list-text">Creare domini protetti (gruppi di macchine virtuali correlate) e assegnare DRVA e Azure Blob Storage/ANF.</block>
  <block id="04fd46fc4d0422c8562609b47b636797" category="list-text">Protezione all'avviamento.</block>
  <block id="8391f9ad7383911e1b8e67d8dfd23ffb" category="list-text">Installare il software DR JetStream nel cloud privato Azure VMware Solution.</block>
  <block id="81aaea44e289ce199fea205f7d0b8cd9" category="list-text">Utilizzare il comando Esegui per installare e configurare il DR JetStream.</block>
  <block id="ef261b549f401ed8d66b72f8310d7376" category="list-text">Aggiungere lo stesso container Azure Blob e individuare i domini utilizzando l'opzione Scan Domains (domini di scansione).</block>
  <block id="3c22f96e96fb514aec06cc03a6d35958" category="list-text">Implementare le appliance DRVA richieste.</block>
  <block id="a8930e0df42395d789466e0695d11ce7" category="list-text">Creare volumi di log di replica utilizzando datastore vSAN o ANF disponibili.</block>
  <block id="087316b53a71d576c6dfeda2385ef108" category="list-text">Importare domini protetti e configurare ROCvA (Recovery VA) per utilizzare il datastore ANF per il posizionamento delle macchine virtuali.</block>
  <block id="f47df812f6139d9d12dc179df9e7da57" category="list-text">Selezionare l'opzione di failover appropriata e avviare la reidratazione continua per domini RTO o macchine virtuali quasi a zero.</block>
  <block id="eb50fc931b0aff72e9034088a04a260b" category="list-text">Durante un evento di emergenza, attivare il failover degli archivi dati Azure NetApp Files nel sito di DR AVS designato.</block>
  <block id="21e74b3c28d006317f38a2bc8eb1da3b" category="inline-link">Azure Marketplace</block>
  <block id="f314a6aa5faf9dfffba2cdac4d4dd420" category="list-text">Richiamare il failback sul sito protetto dopo il ripristino del sito protetto.prima di iniziare, assicurarsi che i prerequisiti siano soddisfatti, come indicato in questa sezione<block ref="600591f3feccd7454d660dd4d2972306" category="inline-link-rx"></block> Inoltre, eseguire il Bandwidth Testing Tool (BWT) fornito dal software JetStream per valutare le performance potenziali dello storage Azure Blob e la relativa larghezza di banda di replica se utilizzato con il software DR JetStream. Una volta implementati i prerequisiti, inclusa la connettività, impostare e sottoscrivere JetStream DR per AVS da<block ref="e842a0f9c9000f3898fd5cb9408b8b3e" category="inline-link-rx"></block>. Una volta scaricato il pacchetto software, procedere con la procedura di installazione descritta in precedenza.</block>
  <block id="01543f177a0cc07917f4dc3510b8649e" category="paragraph">Quando si pianifica e si avvia la protezione per un gran numero di macchine virtuali (ad esempio, 100+), utilizzare il Capacity Planning Tool (CPT) di JetStream DR Automation Toolkit. Fornire un elenco di macchine virtuali da proteggere insieme alle preferenze RTO e del gruppo di ripristino, quindi eseguire CPT.</block>
  <block id="ddfb9ed8decef8b3db76f88d682c7f1e" category="paragraph">CPT esegue le seguenti funzioni:</block>
  <block id="ab5991781a05bc72668a8bf941d7a4a5" category="list-text">Combinazione di macchine virtuali in domini di protezione in base al proprio RTO.</block>
  <block id="b3229123cf8dd56b28f1a8e13f79ddde" category="list-text">Definizione del numero ottimale di DRVA e delle relative risorse.</block>
  <block id="2c3b2c6c87689b15c4cd3ea75cb40ef8" category="list-text">Stima della larghezza di banda di replica richiesta.</block>
  <block id="88d06f884976bb7a1ce66e51624c0196" category="list-text">Identificazione delle caratteristiche del volume del registro di replica (capacità, larghezza di banda e così via).</block>
  <block id="60a85cb526817dd0f1172dcdacc94700" category="list-text">Stima della capacità di storage a oggetti richiesta e molto altro ancora.</block>
  <block id="ea56b8a01683ebc544ddabe2f0fcf571" category="admonition">Il numero e il contenuto dei domini prescritti dipendono da diverse caratteristiche delle macchine virtuali, come IOPS medi, capacità totale, priorità (che definisce l'ordine di failover), RTO e altre.</block>
  <block id="fc321ed0fcff278e628765c7a327d1c0" category="section-title">Installare JetStream DR in Datacenter on-premise</block>
  <block id="87674fd676f223da1c84cd30ba47e2d2" category="paragraph">Il software Jetstream DR è costituito da tre componenti principali: Appliance virtuale Jetstream DR Management Server (MSA), appliance virtuale DR (DRVA) e componenti host (pacchetti di filtro i/o). MSA viene utilizzato per installare e configurare i componenti host sul cluster di calcolo e quindi per amministrare il software DR JetStream. Il seguente elenco fornisce una descrizione dettagliata del processo di installazione:</block>
  <block id="4d6f369fd362693ff1e7c02749ce60d9" category="example-title">Come installare JetStream DR per on-premise</block>
  <block id="44a5c8a42b561b0a83b98c7dffe66dc4" category="list-text">Verificare i prerequisiti.</block>
  <block id="6035c664a9aaf8fa1c40e58c8beaab92" category="list-text">Eseguire Capacity Planning Tool per ottenere consigli su risorse e configurazione (facoltativo ma consigliato per le prove proof-of-concept).</block>
  <block id="ccc2ab66d8941e0dddf26ed50f55ba4c" category="list-text">Implementare l'MSA DR JetStream su un host vSphere nel cluster designato.</block>
  <block id="efdd725636035b733a89826db0da74f4" category="list-text">Avviare MSA utilizzando il nome DNS in un browser.</block>
  <block id="39602c8241f165da483e3678f5d62871" category="list-text">Registrare il server vCenter con MSA.per eseguire l'installazione, attenersi alla seguente procedura dettagliata:</block>
  <block id="f6a1019b86d486190fed5e4a0c122f59" category="list-text">Una volta implementato JetStream DR MSA e registrato vCenter Server, accedere al plug-in JetStream DR utilizzando vSphere Web Client. Per eseguire questa operazione, accedere a Datacenter &gt; Configure &gt; JetStream DR.</block>
  <block id="623c8f2c05001c7eeecb0781c049f16b" category="paragraph"><block ref="623c8f2c05001c7eeecb0781c049f16b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5b9a2e255ce372cd80d886148efdd00" category="list-text">Dall'interfaccia DR di JetStream, selezionare il cluster appropriato.</block>
  <block id="699c846ab66a56017e37da99f6ea7320" category="paragraph"><block ref="699c846ab66a56017e37da99f6ea7320" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d18d2901e95370132a2545c2f511db3" category="list-text">Configurare il cluster con il pacchetto di filtri i/O.</block>
  <block id="34896ae2be725a2f3d42bd7b4b7888fd" category="paragraph"><block ref="34896ae2be725a2f3d42bd7b4b7888fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0598abb730b378c25cbbc28507342260" category="list-text">Aggiungere Azure Blob Storage situato nel sito di ripristino.</block>
  <block id="76ef667a7a95f046d391e54cea1b9142" category="list-text">Implementare un'appliance virtuale DR (DRVA) dalla scheda Appliances (appliance).</block>
  <block id="ba445d98067e8161fa165b8f25ad294d" category="admonition">I DRA possono essere creati automaticamente dal CPT, ma per le prove POC consigliamo di configurare ed eseguire manualmente il ciclo di DR (protezione dell'avvio &gt; failover &gt; failback).</block>
  <block id="60de8eac7ca6ad5f7321abf5b462b65d" category="paragraph">JetStream DRVA è un'appliance virtuale che facilita le funzioni chiave nel processo di replica dei dati. Un cluster protetto deve contenere almeno un DRVA e, in genere, un DRVA viene configurato per host. Ogni DRVA può gestire più domini protetti.</block>
  <block id="f55f11c27893cdacff776d302a9b9d07" category="paragraph"><block ref="f55f11c27893cdacff776d302a9b9d07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ece649567fdf82717852e0f8662d070" category="paragraph">In questo esempio, sono stati creati quattro DRVA per 80 macchine virtuali.</block>
  <block id="cf5c65945851f67013f23b2d83d4a346" category="list-text">Creare volumi di log di replica per ogni DRVA utilizzando VMDK dagli archivi dati disponibili o da pool di storage iSCSI condivisi indipendenti.</block>
  <block id="9ad06750519e0664bc1ec852cc5e07b6" category="list-text">Dalla scheda Protected Domains (domini protetti), creare il numero richiesto di domini protetti utilizzando le informazioni relative al sito Azure Blob Storage, all'istanza DRVA e al registro di replica. Un dominio protetto definisce una macchina virtuale specifica o un insieme di macchine virtuali all'interno del cluster che sono protetti insieme e assegnati a un ordine di priorità per le operazioni di failover/failback.</block>
  <block id="fae4ab5e0fd81c7cdb44eba33dbe42fc" category="paragraph"><block ref="fae4ab5e0fd81c7cdb44eba33dbe42fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e68391e0d2ed07243f438a1d725a243a" category="list-text">Selezionare le macchine virtuali che si desidera proteggere e avviare la protezione delle macchine virtuali del dominio protetto. In questo modo viene avviata la replica dei dati nell'archivio Blob designato.</block>
  <block id="24e5f5b0186cca0606b176380e3ee45c" category="admonition">Verificare che venga utilizzata la stessa modalità di protezione per tutte le macchine virtuali in un dominio protetto.</block>
  <block id="9870cb575efa482fab7fa9aa1fdf16ac" category="admonition">La modalità Write-Back (VMDK) può offrire performance superiori.</block>
  <block id="895d59858a04439859a33d3288706702" category="paragraph"><block ref="895d59858a04439859a33d3288706702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e6ea2b1c670425ac09f1aadbc26e266" category="paragraph">Verificare che i volumi dei log di replica siano posizionati su uno storage dalle performance elevate.</block>
  <block id="3237de27ecac8fd3a072d337514991eb" category="admonition">I run book di failover possono essere configurati per raggruppare le macchine virtuali (denominate Recovery Group), impostare la sequenza dell'ordine di avvio e modificare le impostazioni della CPU/memoria insieme alle configurazioni IP.</block>
  <block id="840c65296e1af99a67123dd9459e5548" category="section-title">Installare JetStream DR per AVS in un cloud privato Azure VMware Solution utilizzando il comando Run</block>
  <block id="d2441f955b3d04e99be7845bb7af68a6" category="paragraph">Una Best practice per un sito di recovery (AVS) consiste nella creazione anticipata di un cluster pilota a tre nodi. Ciò consente di preconfigurare l'infrastruttura del sito di ripristino, inclusi i seguenti elementi:</block>
  <block id="dab895f226673c73578b4c45dead73c0" category="list-text">Segmenti di rete di destinazione, firewall, servizi come DHCP e DNS e così via.</block>
  <block id="188d8743a82411348e186c7118e92c9a" category="list-text">Installazione di JetStream DR per AVS</block>
  <block id="fd3bf57ff38b27ccbf66886b71a34f76" category="list-text">Configurazione dei volumi ANF come datastore e inoltre JetStream DR supporta la modalità RTO quasi zero per i domini mission-critical. Per questi domini, lo storage di destinazione deve essere preinstallato. ANF è un tipo di storage consigliato in questo caso.</block>
  <block id="89aa12cc0cd4846ef86fbe8dfd78d8bc" category="admonition">La configurazione di rete, inclusa la creazione di segmenti, deve essere configurata sul cluster AVS per soddisfare i requisiti on-premise.</block>
  <block id="d50efdb8ff06cd2518521c1d4f68a67a" category="paragraph">A seconda dei requisiti SLA e RTO, è possibile utilizzare il failover continuo o la normale modalità di failover (standard). Per un RTO vicino allo zero, è necessario avviare una procedura di reidratazione continua presso il sito di ripristino.</block>
  <block id="91a827791bf5a23c98b3d5c7a69fe4ac" category="example-title">Come installare JetStream DR per AVS in un cloud privato</block>
  <block id="7c1dc76f383d9b6253a273d35f636909" category="paragraph">Per installare JetStream DR per AVS su un cloud privato Azure VMware Solution, attenersi alla seguente procedura:</block>
  <block id="7f0bec83fc0010707471d9d3b84fd45b" category="list-text">Dal portale Azure, accedere alla soluzione Azure VMware, selezionare il cloud privato e selezionare Esegui comando &gt; pacchetti &gt; Configurazione JSDR.</block>
  <block id="6e37d4d4f3c60de2fb2e2e218753f9ea" category="admonition">L'utente CloudAdmin predefinito in Azure VMware Solution non dispone di privilegi sufficienti per installare JetStream DR per AVS. Azure VMware Solution consente un'installazione semplificata e automatica del DR JetStream invocando il comando Azure VMware Solution Run per il DR JetStream.</block>
  <block id="832830e8d1c5e28f4e206c65a067fbfc" category="paragraph">La seguente schermata mostra l'installazione utilizzando un indirizzo IP basato su DHCP.</block>
  <block id="1ca67a15b29b11c686a17480c2ecde9c" category="paragraph"><block ref="1ca67a15b29b11c686a17480c2ecde9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23fac09aaa7dcea6eb534251f50feae2" category="list-text">Una volta completata l'installazione di JetStream DR per AVS, aggiornare il browser. Per accedere all'interfaccia utente DR JetStream, accedere a SDDC Datacenter &gt; Configure &gt; JetStream DR.</block>
  <block id="58517d8d2fa977f39ca2b76c09c43dc4" category="paragraph"><block ref="58517d8d2fa977f39ca2b76c09c43dc4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50bf7f298e2ed24c67b98b8d5c4e6dbe" category="list-text">Dall'interfaccia DR di JetStream, aggiungere l'account Azure Blob Storage utilizzato per proteggere il cluster on-premise come sito di storage, quindi eseguire l'opzione Scan Domains.</block>
  <block id="1e976589dd0f1f098c13f4564f91813c" category="paragraph"><block ref="1e976589dd0f1f098c13f4564f91813c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4e7f9056aa9f52fd1bff1e2837a4e84" category="list-text">Una volta importati i domini protetti, implementare le appliance DRVA. In questo esempio, la reidratazione continua viene avviata manualmente dal sito di ripristino utilizzando l'interfaccia utente DR JetStream.</block>
  <block id="7aa502331a6314a8d66df611c4538f75" category="admonition">Questi passaggi possono anche essere automatizzati utilizzando i piani creati da CPT.</block>
  <block id="bf4fdf975fae154bdca78e36bd7edbe3" category="list-text">Importare i domini protetti e configurare Recovery VA in modo che utilizzi il datastore ANF per il posizionamento delle macchine virtuali.</block>
  <block id="0a4fc536683686b518331dd2531934b5" category="paragraph"><block ref="0a4fc536683686b518331dd2531934b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="827098a514e7d7fc1579120ec370bfd9" category="admonition">Assicurarsi che DHCP sia attivato sul segmento selezionato e che sia disponibile un numero sufficiente di IP. Gli IP dinamici vengono temporaneamente utilizzati durante il ripristino dei domini. Ogni macchina virtuale di ripristino (inclusa la reidratazione continua) richiede un IP dinamico individuale. Una volta completato il ripristino, l'IP viene rilasciato e può essere riutilizzato.</block>
  <block id="10e011fef535dced7a4095544de7266d" category="list-text">Selezionare l'opzione di failover appropriata (failover o failover continuo). In questo esempio, viene selezionata la reidratazione continua (failover continuo).</block>
  <block id="adac1a1b7a65bae37b6bd9cbd66b248a" category="paragraph"><block ref="adac1a1b7a65bae37b6bd9cbd66b248a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6a68077ca82bffe5f08d96bdcd36e18" category="section-title">Esecuzione di failover/failover</block>
  <block id="60e3a8b4e353d775c34a7d4d16b3d797" category="example-title">Come eseguire un failover/failover</block>
  <block id="61a6473493a7f05f03d606cdfeb234d6" category="list-text">In caso di disastro nel cluster protetto dell'ambiente on-premise (errore parziale o completo), attivare il failover.</block>
  <block id="3a09da9a187f9208fcd685b78b772764" category="admonition">CPT può essere utilizzato per eseguire il piano di failover per ripristinare le macchine virtuali da Azure Blob Storage nel sito di ripristino del cluster AVS.</block>
  <block id="f66e570f82bdb271d0adb30435ad5b2b" category="admonition">Dopo il failover (per la reidratazione continua o standard) quando le macchine virtuali protette sono state avviate in AVS, la protezione viene automaticamente ripristinata e JetStream DR continua a replicare i propri dati nei container appropriati/originali in Azure Blob Storage.</block>
  <block id="d27309d11731255db072c47f9675d22f" category="paragraph"><block ref="d27309d11731255db072c47f9675d22f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef4a8f8fdcb45687697d39da1e99dc36" category="paragraph"><block ref="ef4a8f8fdcb45687697d39da1e99dc36" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf84d29276236d6a8b8e75f1a2c8f115" category="paragraph">La barra delle applicazioni mostra lo stato di avanzamento delle attività di failover.</block>
  <block id="8430656d9f62a51ed63ade1e47ad34f7" category="list-text">Una volta completata l'attività, accedere alle macchine virtuali ripristinate e il business continua normalmente.</block>
  <block id="f89c6dfb9ae23126d1e04570e23dcda9" category="paragraph"><block ref="f89c6dfb9ae23126d1e04570e23dcda9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c8214eaedd2bb37ba1d1b018bf4aa63" category="paragraph">Una volta che il sito primario è stato nuovamente operativo, è possibile eseguire il failback. La protezione delle macchine virtuali viene ripristinata e la coerenza dei dati deve essere verificata.</block>
  <block id="2743b11e431e1c7f8504d917d4ffc4d6" category="list-text">Ripristinare l'ambiente on-premise. A seconda del tipo di incidente, potrebbe essere necessario ripristinare e/o verificare la configurazione del cluster protetto. Se necessario, potrebbe essere necessario reinstallare il software DR JetStream.</block>
  <block id="232732afcd0f951efbcfaea123f0a632" category="admonition">Nota: Il<block ref="cad8a6b900ca13dfc8b04dee1f744111" prefix=" " category="inline-code"></block> Lo script fornito nel toolkit di automazione può essere utilizzato per pulire il sito protetto originale di tutte le macchine virtuali obsolete, le informazioni di dominio e così via.</block>
  <block id="6d52b59b59572c39053e3858b37fcc57" category="list-text">Accedere all'ambiente on-premise ripristinato, accedere all'interfaccia utente DR Jetstream e selezionare il dominio protetto appropriato. Una volta che il sito protetto è pronto per il failback, selezionare l'opzione failover nell'interfaccia utente.</block>
  <block id="7350f3b9fc85111b45034212957d9d98" category="paragraph"><block ref="7350f3b9fc85111b45034212957d9d98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82bc01d2feed0849423b6b5676888f97" category="admonition">Il piano di failback generato da CPT può anche essere utilizzato per avviare il ritorno delle macchine virtuali e dei relativi dati dall'archivio di oggetti all'ambiente VMware originale.</block>
  <block id="36e8c86c253ad3dad15eaab2f5de961c" category="admonition">Specificare il ritardo massimo dopo la pausa delle macchine virtuali nel sito di ripristino e il riavvio nel sito protetto. Questo tempo include il completamento della replica dopo l'arresto delle macchine virtuali di failover, il tempo necessario per pulire il sito di recovery e il tempo necessario per ricreare le macchine virtuali in un sito protetto. Il valore consigliato da NetApp è di 10 minuti.</block>
  <block id="c53daff4bd6065c0627bf739410f7e88" category="paragraph">Completare il processo di failback, quindi confermare la ripresa della protezione delle macchine virtuali e la coerenza dei dati.</block>
  <block id="ddd33ab61759ca3d4dcfcd934ab83b04" category="section-title">Recovery di Ransomeware</block>
  <block id="459d2a2d25c4ad6db53b9e0b367f3d4c" category="paragraph">Il ripristino dal ransomware può essere un compito scoraggiante. In particolare, può essere difficile per le organizzazioni IT determinare il punto di ritorno sicuro e, una volta determinato, come garantire che i carichi di lavoro recuperati siano protetti dagli attacchi che si verificano nuovamente (dal malware in sospensione o attraverso applicazioni vulnerabili).</block>
  <block id="414dfaa4bcffbd76b7f5ed891cdf1535" category="paragraph">Jetstream DR per AVS e gli archivi dati Azure NetApp Files possono risolvere questi problemi consentendo alle organizzazioni di eseguire il ripristino dai punti disponibili nel tempo, in modo che i carichi di lavoro vengano ripristinati in una rete funzionale e isolata, se necessario. Il ripristino consente alle applicazioni di funzionare e comunicare tra loro senza esporre le applicazioni al traffico nord-sud, offrendo così ai team di sicurezza un luogo sicuro per eseguire analisi forensi e altre azioni correttive necessarie.</block>
  <block id="a20215628470de7f6faa691cc18c4971" category="paragraph"><block ref="a20215628470de7f6faa691cc18c4971" category="inline-image-macro-rx" type="image"></block></block>
  <block id="63b9fbe67e7dd9b9f7623683244cb7f8" category="doc">Funzionalità NetApp per Azure AVS</block>
  <block id="9a130cd816dc8be85c4f198310f16e4c" category="paragraph">Scopri di più sulle funzionalità offerte da NetApp alla soluzione Azure VMware (AVS): Da NetApp come dispositivo di storage connesso come guest o come datastore NFS supplementare alla migrazione dei flussi di lavoro, all'estensione/diffusione nel cloud, al backup/ripristino e al disaster recovery.</block>
  <block id="1f0a2077c33b91b3daaaea05c7fadc07" category="inline-link-macro">Configurazione di AVS in Azure</block>
  <block id="9e98cd6f2c1243193cfc50a29bbe3bd4" category="list-text"><block ref="9e98cd6f2c1243193cfc50a29bbe3bd4" category="inline-link-macro-rx"></block></block>
  <block id="cdac9a2e7f1dc52240712d4a191378e8" category="inline-link-macro">Opzioni di storage NetApp per AVS</block>
  <block id="553bafb094b811158ae732981f2dbb4e" category="list-text"><block ref="553bafb094b811158ae732981f2dbb4e" category="inline-link-macro-rx"></block></block>
  <block id="9e348c60eb79913385ed14a65efffff6" category="paragraph">Visualizza i dettagli <block ref="be78464beb9b2a2b1696a7fe38c0e484" category="inline-link-macro-rx"></block>.</block>
  <block id="465fe02ad52f12cc5844200de029e385" category="paragraph">Lo storage NetApp può essere utilizzato in diversi modi, come congettura connessa o come datastore NFS supplementare, all'interno di Azure AVS.</block>
  <block id="026198900efc3d72ea20d8258c67523f" category="paragraph">Visualizza i dettagli <block ref="c21bcdb7b1f85738a3211dff01d327ef" category="inline-link-macro-rx"></block>. Visualizza i dettagli <block ref="266132cd9b913032bfeaea66cd238ea6" category="inline-link-macro-rx"></block>.</block>
  <block id="c9c270552e6f44a0219e4d2459cb4b90" category="paragraph">Con le soluzioni cloud NetApp e VMware, molti casi di utilizzo sono semplici da implementare in Azure AVS. I casi se sono definiti per ciascuna delle aree cloud definite da VMware:</block>
  <block id="79e4e4c7346c156a268641272a85c01e" category="inline-link-macro">Esplora le soluzioni NetApp per Azure AVS</block>
  <block id="6626f21cba60531fb6ab33c5b686fd03" category="paragraph"><block ref="6626f21cba60531fb6ab33c5b686fd03" category="inline-link-macro-rx"></block></block>
  <block id="a724b4fc4c5f79672a5c572466d5e001" category="doc">Opzioni di storage NetApp Guest Connected per Azure</block>
  <block id="3d98cfc43616995ea335b20aa9b10ef2" category="paragraph">Azure supporta lo storage NetApp connesso come guest con il servizio ANF (Azure NetApp Files) nativo o con Cloud Volumes ONTAP (CVO).</block>
  <block id="2295dc11d84df2756a1eaac36330b417" category="paragraph">Azure NetApp Files porta la gestione dei dati e lo storage di livello Enterprise in Azure, in modo da poter gestire i carichi di lavoro e le applicazioni con facilità. Migrare i carichi di lavoro nel cloud ed eseguirli senza sacrificare le performance.</block>
  <block id="806f1ffa4d2e1d7ee40a30337658a5ef" category="paragraph">Azure NetApp Files elimina gli ostacoli, in modo da poter spostare tutte le applicazioni basate su file nel cloud. Per la prima volta, non è necessario riprogettare le applicazioni e ottenere uno storage persistente per le applicazioni senza complessità.</block>
  <block id="12eb3a27c6c1134f55e12f1349b87a91" category="paragraph">Poiché il servizio viene fornito tramite il portale Microsoft Azure, gli utenti sperimentano un servizio completamente gestito come parte del contratto aziendale Microsoft. Il supporto di livello mondiale, gestito da Microsoft, ti offre la massima tranquillità. Questa singola soluzione consente di aggiungere in modo rapido e semplice carichi di lavoro multiprotocollo. È possibile creare e implementare applicazioni basate su file Windows e Linux, anche per ambienti legacy.</block>
  <block id="f43b203ec7020e7ea0e408d9d67255fc" category="example-title">Configurazione di Azure NetApp Files con la soluzione VMware Azure (AVS)</block>
  <block id="f9a184882060f3e5a8b6045e2a53107f" category="paragraph">Le condivisioni Azure NetApp Files possono essere montate da macchine virtuali create nell'ambiente SDDC della soluzione VMware Azure. I volumi possono anche essere montati sul client Linux e mappati sul client Windows perché Azure NetApp Files supporta i protocolli SMB e NFS. I volumi Azure NetApp Files possono essere configurati in cinque semplici passaggi.</block>
  <block id="5bb6f16c69df9b9f54bddaaa5e32b415" category="paragraph">La soluzione Azure NetApp Files e Azure deve trovarsi nella stessa regione di Azure.</block>
  <block id="763b2af90e10e00124392e31d5792be5" category="paragraph">Per creare e montare volumi Azure NetApp Files, attenersi alla seguente procedura:</block>
  <block id="e56fb44cec3cde26b63f919055458c3a" category="list-text">Accedi al portale Azure e accedi a Azure NetApp Files. Verificare l'accesso al servizio Azure NetApp Files e registrare il provider di risorse Azure NetApp Files utilizzando il comando _az provider register --namespace Microsoft.NetApp –wait_. Al termine della registrazione, creare un account NetApp.</block>
  <block id="792c2610bbb56b5803bae91a54f34f51" category="inline-link-macro">Condivisioni Azure NetApp Files</block>
  <block id="a7ad1b2194256789e815facefa65206d" category="paragraph">Per informazioni dettagliate, vedere <block ref="8dd8f38a60f74263b1cf35e18285061e" category="inline-link-macro-rx"></block>. Questa pagina guida l'utente attraverso il processo passo-passo.</block>
  <block id="710954ec785b2a7f67c2ef1c3f2f9d19" category="paragraph"><block ref="710954ec785b2a7f67c2ef1c3f2f9d19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe57bd1c78e967b463574e3089a42968" category="list-text">Una volta creato l'account NetApp, impostare i pool di capacità con il livello e le dimensioni di servizio richiesti.</block>
  <block id="3928a91ce2a9b26c809bec745d6b9daf" category="paragraph">Per ulteriori informazioni, vedere <block ref="e7281cc99a6c9a39d5a16325a46f1f7c" category="inline-link-macro-rx"></block>.</block>
  <block id="7ffd44a691267afdf7cc1178ab6115f8" category="paragraph"><block ref="7ffd44a691267afdf7cc1178ab6115f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="42e9b5ee697da49886fd18e89e6ab1af" category="inline-link-macro">Delegare una subnet a Azure NetApp Files</block>
  <block id="ee13d45546639cd210b35ce3665b6885" category="list-text">Configurare la subnet delegata per Azure NetApp Files e specificare questa subnet durante la creazione dei volumi. Per informazioni dettagliate sulla creazione di una subnet delegata, vedere <block ref="ad52de6b143679c946d36f9e4248f40c" category="inline-link-macro-rx"></block>.</block>
  <block id="70a08a2f18d96817bf63302571e62634" category="paragraph"><block ref="70a08a2f18d96817bf63302571e62634" category="inline-image-macro-rx" type="image"></block></block>
  <block id="96501b128e8ffab4b107cd6ffa7da649" category="list-text">Aggiungere un volume SMB utilizzando il blade Volumes sotto il blade Capacity Pools. Assicurarsi che Active Directory Connector sia configurato prima di creare il volume SMB.</block>
  <block id="f676bcdffa60a69ff49ba9ffdbb2b912" category="paragraph"><block ref="f676bcdffa60a69ff49ba9ffdbb2b912" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9095b4995e678294045e2a1501d1db3" category="list-text">Fare clic su Review + Create (Rivedi + Crea) per creare il volume SMB.</block>
  <block id="e48925dc65abf32faa19c5d430cf6d6d" category="paragraph">Se l'applicazione è SQL Server, attivare la disponibilità continua SMB.</block>
  <block id="be1613efbff068fd23ee511fe4e6dc51" category="paragraph"><block ref="be1613efbff068fd23ee511fe4e6dc51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2b999c81e324f553ec9720c334325ee" category="paragraph"><block ref="b2b999c81e324f553ec9720c334325ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c5ce17dd48f2551465b828065fd8300" category="paragraph">Per ulteriori informazioni sulle prestazioni dei volumi Azure NetApp Files in base alle dimensioni o alla quota, vedere <block ref="ffec162f488d413e68dfe18d328e177e" category="inline-link-macro-rx"></block>.</block>
  <block id="bef7cec065f33ededdd1b50d74800b72" category="list-text">Dopo aver attivato la connettività, è possibile montare e utilizzare il volume per i dati dell'applicazione.</block>
  <block id="8b3c17098d0d024937d60849b3bd8edb" category="paragraph">A tale scopo, dal portale Azure, fare clic sul blade Volumes, quindi selezionare il volume da montare e accedere alle istruzioni di montaggio. Copiare il percorso e utilizzare l'opzione Map Network Drive per montare il volume sulla macchina virtuale in esecuzione su Azure VMware Solution SDDC.</block>
  <block id="413fcfe1d831f95cd95f8f3bb9030eec" category="paragraph"><block ref="413fcfe1d831f95cd95f8f3bb9030eec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e50c675280580c3249f58f2f3eefdb86" category="paragraph"><block ref="e50c675280580c3249f58f2f3eefdb86" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13c8bc9575bbdc3a8a30021320abbd69" category="list-text">Per montare volumi NFS su macchine virtuali Linux eseguite su Azure VMware Solution SDDC, utilizzare questo stesso processo. Utilizza la riformizzazione dei volumi o la funzionalità del livello di servizio dinamico per soddisfare le esigenze dei carichi di lavoro.</block>
  <block id="ff817c6ff423e680ddf0a8398efdfb5a" category="paragraph"><block ref="ff817c6ff423e680ddf0a8398efdfb5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da94ac228f6efdf07fe7e43b1441faf2" category="paragraph">Per ulteriori informazioni, vedere <block ref="ea07f7f3cbdf3d62072fbe16546616d3" category="inline-link-macro-rx"></block>.</block>
  <block id="1d583a1a8ff1ca8ae3360c7e33ecd984" category="example-title">Implementa il nuovo Cloud Volumes ONTAP in Azure</block>
  <block id="ed1019c297fadb83e87437230788320c" category="paragraph">Le condivisioni e i LUN Cloud Volumes ONTAP possono essere montati da macchine virtuali create nell'ambiente SDDC della soluzione VMware Azure. I volumi possono essere montati anche sul client Linux e sul client Windows, poiché Cloud Volumes ONTAP supporta i protocolli iSCSI, SMB e NFS. I volumi Cloud Volumes ONTAP possono essere configurati in pochi semplici passaggi.</block>
  <block id="e9cac40069a313b824541cda06c18a06" category="paragraph">Per replicare i volumi da un ambiente on-premise al cloud per scopi di disaster recovery o migrazione, stabilire la connettività di rete con Azure, utilizzando una VPN site-to-site o ExpressRoute. La replica dei dati da on-premise a Cloud Volumes ONTAP non rientra nell'ambito di questo documento. Per replicare i dati tra sistemi on-premise e Cloud Volumes ONTAP, vedere <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>.</block>
  <block id="165fc07e6910d8748be18ecaaab5392d" category="admonition">Utilizzare <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> Per dimensionare con precisione le istanze di Cloud Volumes ONTAP. Monitorare anche le performance on-premise da utilizzare come input nel Cloud Volumes ONTAP Sizer.</block>
  <block id="a1d02afc571062ee1235156b645846f8" category="list-text">Accedi a NetApp Cloud Central: Viene visualizzata la schermata Fabric View. Individuare la scheda Cloud Volumes ONTAP (Gestione cloud) e selezionare Go to Cloud Manager (Vai a Gestione cloud). Una volta effettuato l'accesso, viene visualizzata la schermata Canvas.</block>
  <block id="1563f27024f7b2b0a96be687f878206d" category="paragraph"><block ref="1563f27024f7b2b0a96be687f878206d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f067fbf4a3196796318f7e878eaa2a3" category="list-text">Nella home page di Cloud Manager, fare clic su Add a Working Environment (Aggiungi ambiente di lavoro), quindi selezionare Microsoft Azure come cloud e il tipo di configurazione del sistema.</block>
  <block id="e59c8066b7736d6ede98e2b57d619b60" category="paragraph"><block ref="e59c8066b7736d6ede98e2b57d619b60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21568dd1e2a5acafeee9d119cd012876" category="list-text">Quando si crea il primo ambiente di lavoro Cloud Volumes ONTAP, viene richiesto di implementare un connettore.</block>
  <block id="4c3665ca095a8a103c69fac1ac46fb59" category="paragraph"><block ref="4c3665ca095a8a103c69fac1ac46fb59" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54ae357a0d5e74ebab86e52641490fc0" category="list-text">Una volta creato il connettore, aggiornare i campi Dettagli e credenziali.</block>
  <block id="9b971596a6ee599483fd04c84d2ce18d" category="paragraph"><block ref="9b971596a6ee599483fd04c84d2ce18d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf5341803b0061ef190495343f39fa02" category="list-text">Fornire i dettagli dell'ambiente da creare, inclusi il nome dell'ambiente e le credenziali di amministratore. Aggiungere tag di gruppo di risorse per l'ambiente Azure come parametro facoltativo. Al termine, fare clic su Continue (continua).</block>
  <block id="350a5c2219e5e14fd23dda8372344842" category="paragraph"><block ref="350a5c2219e5e14fd23dda8372344842" category="inline-image-macro-rx" type="image"></block></block>
  <block id="360a69a0b184770c2409949f2c7e1140" category="list-text">Seleziona i servizi aggiuntivi per l'implementazione di Cloud Volumes ONTAP, tra cui Cloud Data Sense, Cloud Backup e Cloud Insights. Selezionare i servizi e fare clic su continua.</block>
  <block id="11728d9ffc9e6944adf4891d5543e154" category="paragraph"><block ref="11728d9ffc9e6944adf4891d5543e154" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ee060e03da823e605453fbfa27743d77" category="list-text">Configurare la posizione e la connettività di Azure. Selezionare la regione Azure, il gruppo di risorse, VNET e la subnet da utilizzare.</block>
  <block id="4549d76a3daf0d322686b6d4f6fb1490" category="paragraph"><block ref="4549d76a3daf0d322686b6d4f6fb1490" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1c88093dde70f0165ade30b74c908ad" category="list-text">Selezionare l'opzione di licenza: Pay-as-you-Go o BYOL per utilizzare la licenza esistente. In questo esempio, viene utilizzata l'opzione Pay-as-You-Go.</block>
  <block id="10085b1c84507f0da366d741a248d728" category="paragraph"><block ref="10085b1c84507f0da366d741a248d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2c782d387cdd1de07d0119c2794edc8" category="list-text">Scegli tra diversi pacchetti preconfigurati disponibili per i vari tipi di carichi di lavoro.</block>
  <block id="942b902e3715b75e8e6257349bbe93ff" category="paragraph"><block ref="942b902e3715b75e8e6257349bbe93ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c7055bfbaac9b0236d0bedccfb616d0" category="list-text">Accettare i due accordi relativi all'attivazione del supporto e all'allocazione delle risorse di Azure.per creare l'istanza di Cloud Volumes ONTAP, fare clic su Vai.</block>
  <block id="c19dadb8117ac0d88e543accbb1c1096" category="paragraph"><block ref="c19dadb8117ac0d88e543accbb1c1096" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6bb322a7578acfb8670b3ce8bc96fc9" category="paragraph"><block ref="b6bb322a7578acfb8670b3ce8bc96fc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02cbbc24385dbe83fb42a1bd0c5668da" category="paragraph"><block ref="02cbbc24385dbe83fb42a1bd0c5668da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d923f79d8112841c7df8503e86f0af4a" category="list-text">La creazione del volume SMB è un processo semplice. Selezionare l'istanza CVO per creare il volume e fare clic sull'opzione Create Volume (Crea volume). Scegli le dimensioni appropriate e il cloud manager sceglie l'aggregato contenente o utilizza un meccanismo di allocazione avanzato da collocare su un aggregato specifico. Per questa demo, SMB viene selezionato come protocollo.</block>
  <block id="a74d409c32c4bc504768c6a7607fc409" category="paragraph"><block ref="a74d409c32c4bc504768c6a7607fc409" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e1a14aa082ec04534624b099e0a4bd9" category="list-text">Una volta eseguito il provisioning, il volume sarà disponibile nel riquadro Volumes (volumi). Poiché viene fornita una condivisione CIFS, assegnare agli utenti o ai gruppi l'autorizzazione per i file e le cartelle e verificare che tali utenti possano accedere alla condivisione e creare un file. Questo passaggio non è necessario se il volume viene replicato da un ambiente on-premise perché le autorizzazioni per file e cartelle vengono mantenute come parte della replica di SnapMirror.</block>
  <block id="8923d310a6b50c677ed6f68410181b46" category="paragraph"><block ref="8923d310a6b50c677ed6f68410181b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="776a8d832701253eb40b056e68086fcd" category="list-text">Una volta creato il volume, utilizzare il comando mount per connettersi alla condivisione dalla macchina virtuale in esecuzione sugli host Azure VMware Solution SDDC.</block>
  <block id="70307f46aa9c37929516c971f3445caa" category="list-text">Copiare il seguente percorso e utilizzare l'opzione Map Network Drive per montare il volume sulla macchina virtuale in esecuzione su Azure VMware Solution SDDC.</block>
  <block id="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="paragraph"><block ref="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d1f50043685559ea05d7c21ae5a6d8a" category="paragraph"><block ref="1d1f50043685559ea05d7c21ae5a6d8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2e7b38e3108ed39835e616f3a8eef4d9" category="paragraph">Per collegare il LUN a un host, attenersi alla seguente procedura:</block>
  <block id="2fc81fae057994bbe703cb2892b727c9" category="list-text">Nella pagina Canvas, fare doppio clic sull'ambiente di lavoro Cloud Volumes ONTAP per creare e gestire i volumi.</block>
  <block id="3a596dcd3d3dd43ed187aea6bea5842e" category="list-text">Fare clic su Add Volume (Aggiungi volume) &gt; New Volume (nuovo volume), quindi selezionare iSCSI e fare clic su Create Initiator Group (Crea Fare clic su continua.</block>
  <block id="06fcf6729491b5106094916e154fb565" category="paragraph"><block ref="06fcf6729491b5106094916e154fb565" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7af0094f03c81886be499600b8563647" category="paragraph">Per ottenere lo stesso risultato per l'host residente su Azure VMware Solution SDDC:</block>
  <block id="640e587a72f6b61dc8d20a6de477db96" category="list-text">RDP sulla macchina virtuale ospitata su Azure VMware Solution SDDC.</block>
  <block id="c4ab0fc2a07f004fb45eacc91a07e22c" category="list-text">Dalla scheda Target, selezionare la destinazione rilevata, quindi fare clic su Log on (Accedi) o Connect (Connetti).</block>
  <block id="4f04cc11e470becd190503a4cea0e217" category="list-text">Selezionare Enable multipath (attiva multipath), quindi selezionare Automatically Restore this Connection when the computer starts or Add this Connection to the List of Favorite targets (Ripristina automaticamente questa connessione all'avvio del computer). Fare clic su Avanzate.</block>
  <block id="2d5b864b177738fa7a03f083ae03d2a3" category="paragraph">*Nota:* l'host Windows deve disporre di una connessione iSCSI a ciascun nodo del cluster. Il DSM nativo seleziona i percorsi migliori da utilizzare.</block>
  <block id="829bd9f13853ee7a86f5805c316df650" category="paragraph"><block ref="829bd9f13853ee7a86f5805c316df650" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f2340e83f93b283dd5fc7023e4e72a2" category="paragraph">I LUN sulla macchina virtuale di storage (SVM) vengono visualizzati come dischi sull'host Windows. I nuovi dischi aggiunti non vengono rilevati automaticamente dall'host. Attivare una nuova scansione manuale per rilevare i dischi completando la seguente procedura:</block>
  <block id="d378c726809748df2090ec116c7232b4" category="paragraph"><block ref="d378c726809748df2090ec116c7232b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b3a58a7b9961d5d214b65da735d2f89" category="list-text">Seguire le istruzioni della procedura guidata. In questo esempio, viene montato il disco e:</block>
  <block id="586f9ee0f7d5544a894ea05b9df312d7" category="paragraph"><block ref="586f9ee0f7d5544a894ea05b9df312d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ff716a75c3423262418c90aad971f10" category="paragraph"><block ref="6ff716a75c3423262418c90aad971f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f95900d5509fa4de2d1c7e9489f4dc6" category="summary">Il disaster recovery nel cloud è un metodo resiliente e conveniente per proteggere i workload da interruzioni del sito e eventi di corruzione dei dati come ransomware. Con NetApp SnapMirror, è possibile replicare i workload VMware on-premise che utilizzano lo storage connesso con gli ospiti su NetApp Cloud Volumes ONTAP in esecuzione in Azure.</block>
  <block id="5f2df3110b7088a1c8d1659ffb728f46" category="doc">Disaster Recovery con CVO e AVS (storage connesso agli ospiti)</block>
  <block id="48b47eaa686f297ed741f5cb81de709d" category="paragraph">Autori: Ravi BCB e Niyaz Mohamed, NetApp</block>
  <block id="be93173f941fd10be0e9fddb606bd940" category="paragraph">Il disaster recovery nel cloud è un metodo resiliente e conveniente per proteggere i workload da interruzioni del sito e eventi di corruzione dei dati come ransomware. Con NetApp SnapMirror, è possibile replicare i workload VMware on-premise che utilizzano lo storage connesso con gli ospiti su NetApp Cloud Volumes ONTAP in esecuzione in Azure. Ciò riguarda i dati delle applicazioni, ma le macchine virtuali effettive. Il disaster recovery dovrebbe coprire tutti i componenti dipendenti, tra cui macchine virtuali, VMDK, dati applicativi e altro ancora. A tale scopo, SnapMirror e Jetstream possono essere utilizzati per ripristinare perfettamente i carichi di lavoro replicati da on-premise a Cloud Volumes ONTAP utilizzando lo storage vSAN per VM VMDK.</block>
  <block id="b25b60af8de6f7256f832e93e5651972" category="paragraph">Questo documento fornisce un approccio passo per passo per la configurazione e l'esecuzione del disaster recovery che utilizza NetApp SnapMirror, JetStream e Azure VMware Solution (AVS).</block>
  <block id="8f0e380cfb4a39395f72ab50e67ea50e" category="paragraph"><block ref="8f0e380cfb4a39395f72ab50e67ea50e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72916c3a8dffc193957f3809a8b4acbf" category="paragraph">Questo documento si concentra sullo storage in-guest per i dati delle applicazioni (noto anche come guest Connected) e si presume che l'ambiente on-premise stia utilizzando SnapCenter per backup coerenti con le applicazioni.</block>
  <block id="d2e057fdab62f3ae766c18c66acc57fd" category="admonition">Questo documento si riferisce a qualsiasi soluzione di backup o ripristino di terze parti. A seconda della soluzione utilizzata nell'ambiente, seguire le Best practice per creare policy di backup che soddisfino gli SLA dell'organizzazione.</block>
  <block id="380a8e9be36984cc009caa1b7aaadc5d" category="paragraph">Per la connettività tra l'ambiente on-premise e la rete virtuale Azure, utilizzare la portata globale di instradamento espresso o una WAN virtuale con un gateway VPN. I segmenti devono essere creati in base alla progettazione della VLAN on-premise.</block>
  <block id="057412b2bc7b34ca7066f70b80b69510" category="admonition">Esistono diverse opzioni per connettere i data center on-premise ad Azure, che ci impediscono di delineare un workflow specifico in questo documento. Consultare la documentazione di Azure per il metodo di connettività on-premise-to-Azure appropriato.</block>
  <block id="ecc1cadbbbb0ef1d84ddc861f4497661" category="section-title">Implementazione della soluzione DR</block>
  <block id="8eaa61639db3e085f8c7eb12151b3736" category="list-text">Assicurarsi che il backup dei dati dell'applicazione venga eseguito utilizzando SnapCenter con i requisiti RPO necessari.</block>
  <block id="a04938b02e6c8ce6c9dbb34eac7d6a0a" category="list-text">Eseguire il provisioning di Cloud Volumes ONTAP con la dimensione dell'istanza corretta utilizzando Cloud Manager all'interno dell'abbonamento appropriato e della rete virtuale.</block>
  <block id="15a6eec061b4c7d026aa504c05f01405" category="list-text">Configurare SnapMirror per i volumi applicativi rilevanti.</block>
  <block id="3d1e7fac653a4e240c35721f0e3902da" category="list-text">Aggiornare i criteri di backup in SnapCenter per attivare gli aggiornamenti di SnapMirror dopo i processi pianificati.</block>
  <block id="2a690d204d02bcc25768246a5c2082bb" category="list-text">Installare il software DR JetStream nel data center on-premise e iniziare la protezione per le macchine virtuali.</block>
  <block id="060b718b1c12d4bed763206429b5c467" category="list-text">Durante un evento di emergenza, interrompere la relazione di SnapMirror utilizzando Cloud Manager e attivare il failover delle macchine virtuali su Azure NetApp Files o su datastore vSAN nel sito di DR AVS designato.</block>
  <block id="16193a2e612115bbf00cb18e7a9ec1aa" category="list-text">Ricollegare I LUN ISCSI e i montaggi NFS per le macchine virtuali dell'applicazione.</block>
  <block id="d274e9c5c862dd28666a25176c344293" category="list-text">Richiamare il failback sul sito protetto risyncing inverso di SnapMirror dopo il ripristino del sito primario.</block>
  <block id="c99b24a6817b7fd3c4d8687fc4bb35df" category="section-title">Dettagli sull'implementazione</block>
  <block id="eb5301ce7e383557ea1c2ecc5d8df8a4" category="example-title">Configurare CVO su Azure e replicare i volumi su CVO</block>
  <block id="ebcd981f8224ab4325994da29465cf8c" category="paragraph">Il primo passaggio consiste nella configurazione di Cloud Volumes ONTAP su Azure <block ref="4e2a8d8afd7d7aca598f792d5d04f9c7" category="inline-link-rx"></block>) E replicare i volumi desiderati su Cloud Volumes ONTAP con le frequenze desiderate e le ritentioni di snapshot.</block>
  <block id="30200baf346b021de0310f8f8307fd8e" category="paragraph"><block ref="30200baf346b021de0310f8f8307fd8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b453212f1c9ff723da2989dbb439d57e" category="example-title">Configurare gli host AVS e l'accesso ai dati CVO</block>
  <block id="46fdc14ede3dd0a84faa31cf1cde9624" category="paragraph">Due fattori importanti da considerare durante l'implementazione di SDDC sono le dimensioni del cluster SDDC nella soluzione VMware di Azure e il tempo necessario per mantenere il SDDC in servizio. Queste due considerazioni chiave per una soluzione di disaster recovery contribuiscono a ridurre i costi operativi complessivi. Il controller SDDC può contenere fino a tre host, fino a un cluster multi-host in un'implementazione su larga scala.</block>
  <block id="938f299f0522c6e7bea183a8ea437225" category="paragraph">La decisione di implementare un cluster AVS si basa principalmente sui requisiti RPO/RTO. Con la soluzione VMware Azure, il provisioning SDDC può essere eseguito in tempo, in preparazione di test o di un evento di disastro effettivo. Un SDDC implementato Just in Time consente di risparmiare sui costi degli host ESXi quando non si affronta un disastro. Tuttavia, questa forma di implementazione influisce sull'RTO di alcune ore durante il provisioning di SDDC.</block>
  <block id="595875340c961d4ff4461ee8fe8a3ce3" category="paragraph">L'opzione implementata più comunemente è l'esecuzione di SDDC in una modalità di funzionamento always-on, con illuminazione pilota. Questa opzione offre un ingombro ridotto di tre host sempre disponibili e accelera le operazioni di recovery fornendo una base di riferimento per le attività di simulazione e i controlli di conformità, evitando così il rischio di deriva operativa tra i siti di produzione e DR. Il cluster pilota-light può essere scalato rapidamente fino al livello desiderato quando necessario per gestire un evento DR effettivo.</block>
  <block id="2f5ab77fee006682ed15a6dbfb54c2a0" category="paragraph">Per configurare AVS SDDC (sia esso on-demand o in modalità pilota-light), vedere<block ref="86c283cfb3c0f32634050918a847eb2d" category="inline-link-rx"></block>. Come prerequisito, verificare che le macchine virtuali guest che risiedono sugli host AVS siano in grado di utilizzare i dati provenienti da Cloud Volumes ONTAP dopo aver stabilito la connettività.</block>
  <block id="f63f01c08cfc3f386ad47993e097e207" category="paragraph">Dopo aver configurato correttamente Cloud Volumes ONTAP e AVS, iniziare a configurare Jetstream per automatizzare il ripristino dei carichi di lavoro on-premise su AVS (macchine virtuali con VMDK delle applicazioni e macchine virtuali con storage in-guest) utilizzando il meccanismo VAIO e sfruttando SnapMirror per le copie dei volumi delle applicazioni su Cloud Volumes ONTAP.</block>
  <block id="9f9a4d5afd3892f2b17ecc3ed2ad2630" category="example-title">Installare JetStream DR nel data center on-premise</block>
  <block id="68027d729e644485691d1aa185f22dad" category="paragraph">Il software Jetstream DR è costituito da tre componenti principali: L'appliance virtuale JetStream DR Management Server (MSA), l'appliance virtuale DR (DRVA) e i componenti host (pacchetti di filtri i/o). MSA viene utilizzato per installare e configurare i componenti host sul cluster di calcolo e quindi per amministrare il software DR JetStream. La procedura di installazione è la seguente:</block>
  <block id="2e5f490166b4cbb95848c72a3f3296cd" category="list-text">Verificare i prerequisiti.</block>
  <block id="01eb617ea64b2e2237c95fa866dc6c99" category="list-text">Eseguire Capacity Planning Tool per consigli su risorse e configurazione.</block>
  <block id="91d290eafae733f57fe1874a21a706be" category="list-text">Distribuire l'MSA DR JetStream su ciascun host vSphere nel cluster designato.</block>
  <block id="130231ab3f0401b0c0e0f66fadd45d5d" category="list-text">Registrare il server vCenter con MSA.</block>
  <block id="6f621d6c94ab64b27eea06de601902d1" category="list-text">Una volta implementato JetStream DR MSA e registrato vCenter Server, accedere al plug-in JetStream DR con vSphere Web Client. Per eseguire questa operazione, accedere a Datacenter &gt; Configure &gt; JetStream DR.</block>
  <block id="874efc870db36a204a974a32ac47c11e" category="paragraph"><block ref="874efc870db36a204a974a32ac47c11e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9aad471e9824a9ef2c43fae648b07613" category="list-text">Dall'interfaccia DR JetStream, completare le seguenti attività:</block>
  <block id="7ab4f3b382b4ad9e82615cacd27d739c" category="paragraph"><block ref="7ab4f3b382b4ad9e82615cacd27d739c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc59cbc4a86e6676ff3d70ba71ba6c0c" category="list-text">Aggiungere lo storage Azure Blob situato nel sito di ripristino.</block>
  <block id="c86146f54b5d798bebf8802ac8b9fcde" category="paragraph"><block ref="c86146f54b5d798bebf8802ac8b9fcde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="47d0f0f8f33fcbb5e022f9d64bbbed63" category="list-text">Implementare il numero richiesto di DRVA (DR Virtual Appliances) dalla scheda Appliances (appliance).</block>
  <block id="f609ba6f20a39912fd585d05df8bc4de" category="admonition">Utilizzare lo strumento di pianificazione della capacità per stimare il numero di DRA richiesti.</block>
  <block id="4c16a641767d4c33c410687e7b6613ef" category="paragraph"><block ref="4c16a641767d4c33c410687e7b6613ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a6b84958a757d2c38048bdf788c590f" category="paragraph"><block ref="1a6b84958a757d2c38048bdf788c590f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b7fbe3ea0d16e8cdd943c71406ee9095" category="list-text">Creare volumi di log di replica per ogni DRVA utilizzando VMDK dagli archivi dati disponibili o dal pool di storage iSCSI condiviso indipendente.</block>
  <block id="376f9301b1fb23692806f601a501bc1d" category="paragraph"><block ref="376f9301b1fb23692806f601a501bc1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3603870d5d8cd5f384cf0b1258a4276a" category="list-text">Dalla scheda Protected Domains (domini protetti), creare il numero richiesto di domini protetti utilizzando le informazioni relative al sito Azure Blob Storage, all'istanza DRVA e al registro di replica. Un dominio protetto definisce una macchina virtuale specifica o un insieme di macchine virtuali dell'applicazione all'interno del cluster che sono protetti insieme e assegnati un ordine di priorità per le operazioni di failover/failback.</block>
  <block id="fc72030b6d0a9889fccd2facfedc6b0e" category="paragraph"><block ref="fc72030b6d0a9889fccd2facfedc6b0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09795e4b943747b98cfc63dfc54275c3" category="paragraph"><block ref="09795e4b943747b98cfc63dfc54275c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb05314ca50bac72a0b13f171a2b6912" category="list-text">Selezionare le macchine virtuali da proteggere e raggrupparle in gruppi di applicazioni in base alla dipendenza. Le definizioni delle applicazioni consentono di raggruppare set di macchine virtuali in gruppi logici che contengono i relativi ordini di avvio, ritardi di avvio e validazioni opzionali delle applicazioni che possono essere eseguite al momento del ripristino.</block>
  <block id="818cadd78e726fcca2ca69a99c22df63" category="admonition">Assicurarsi di utilizzare la stessa modalità di protezione per tutte le macchine virtuali in un dominio protetto.</block>
  <block id="8cc32e4f2682b9a5731a285459a5d9c5" category="admonition">La modalità Write-Back (VMDK) offre performance superiori.</block>
  <block id="639f5dd27b8ff76608b346f78c673b4c" category="paragraph"><block ref="639f5dd27b8ff76608b346f78c673b4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c916465a580d8d569bd369e8e7f6d609" category="list-text">Assicurarsi che i volumi dei log di replica siano posizionati su uno storage dalle performance elevate.</block>
  <block id="1fc3826d710244fdb6c4a09d89f98d5f" category="paragraph"><block ref="1fc3826d710244fdb6c4a09d89f98d5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5038dd04f28442b45e40cc394920ed6" category="list-text">Al termine dell'operazione, fare clic su Start Protection (Avvia protezione) per il dominio protetto. In questo modo viene avviata la replica dei dati per le macchine virtuali selezionate nell'archivio Blob designato.</block>
  <block id="5ed7580bd1e6ae0cef691df5ee3b54a2" category="paragraph"><block ref="5ed7580bd1e6ae0cef691df5ee3b54a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e860406ba63567c5eccf30055287b47" category="list-text">Una volta completata la replica, lo stato di protezione della macchina virtuale viene contrassegnato come ripristinabile.</block>
  <block id="c873c8c59414399f210af5ec22a764d8" category="paragraph"><block ref="c873c8c59414399f210af5ec22a764d8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a918d27a636eddf2d16b9e8544402c44" category="admonition">Le runbook di failover possono essere configurate per raggruppare le macchine virtuali (denominate gruppo di ripristino), impostare la sequenza dell'ordine di avvio e modificare le impostazioni della CPU/memoria insieme alle configurazioni IP.</block>
  <block id="90ee2ee79e46dfb341705824bdba5b5a" category="list-text">Fare clic su Impostazioni, quindi sul collegamento Configura runbook per configurare il gruppo runbook.</block>
  <block id="92471f4927394b88148206ffbdc25dbd" category="paragraph"><block ref="92471f4927394b88148206ffbdc25dbd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c352449075dfd7c55f51cc486cc2541" category="list-text">Fare clic sul pulsante Create Group (Crea gruppo) per iniziare a creare un nuovo gruppo di runbook.</block>
  <block id="e2fbd552cab46f747bc672bf2e1b0fe9" category="admonition">Se necessario, nella parte inferiore della schermata, applicare pre-script e post-script personalizzati da eseguire automaticamente prima e dopo l'operazione del gruppo di runbook. Assicurarsi che gli script Runbook risiedano sul server di gestione.</block>
  <block id="27601285770e6db675411c9282459b87" category="paragraph"><block ref="27601285770e6db675411c9282459b87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f26b7048f93345b3726eb88bd506893a" category="list-text">Modificare le impostazioni della macchina virtuale secondo necessità. Specificare i parametri per il ripristino delle macchine virtuali, tra cui la sequenza di avvio, il ritardo di avvio (specificato in secondi), il numero di CPU e la quantità di memoria da allocare. Modificare la sequenza di avvio delle macchine virtuali facendo clic sulle frecce verso l'alto o verso il basso. Sono inoltre disponibili opzioni per conservare MAC.</block>
  <block id="ff0274a4eb386ebd23581a082f3b5b5b" category="paragraph"><block ref="ff0274a4eb386ebd23581a082f3b5b5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9c2cb19a0ef20564c20014e97d134168" category="list-text">Gli indirizzi IP statici possono essere configurati manualmente per le singole macchine virtuali del gruppo. Fare clic sul collegamento NIC View (visualizzazione NIC) di una macchina virtuale per configurare manualmente le impostazioni dell'indirizzo IP.</block>
  <block id="f26795dd104c3568722b09bce335c904" category="paragraph"><block ref="f26795dd104c3568722b09bce335c904" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a85bcb54a31960de00ecac27985d3f3a" category="list-text">Fare clic sul pulsante Configure (Configura) per salvare le impostazioni NIC per le rispettive macchine virtuali.</block>
  <block id="d6431b9ceb7168220978cc8a6f804dc2" category="paragraph"><block ref="d6431b9ceb7168220978cc8a6f804dc2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c295c7835a978c48c9f8253edc92e6ab" category="paragraph"><block ref="c295c7835a978c48c9f8253edc92e6ab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="423aff401e73269c665789c2a91cd2ba" category="paragraph">Lo stato dei runbook di failover e failback è ora elencato come configurato. I gruppi runbook di failover e failback vengono creati in coppie utilizzando lo stesso gruppo iniziale di macchine virtuali e impostazioni. Se necessario, le impostazioni di qualsiasi gruppo di runbook possono essere personalizzate singolarmente facendo clic sul relativo link Details (Dettagli) e apportando modifiche.</block>
  <block id="8868e7fa41b895d0441f3c000558500e" category="example-title">Installare JetStream DR per AVS nel cloud privato</block>
  <block id="ca2d476f98a102308a1ca46e0314f094" category="paragraph">Una Best practice per un sito di recovery (AVS) consiste nella creazione anticipata di un cluster pilota a tre nodi. Ciò consente di preconfigurare l'infrastruttura del sito di ripristino, tra cui:</block>
  <block id="03bd3d186e1fc83d47907ac1797d8eaf" category="list-text">Segmenti di rete di destinazione, firewall, servizi come DHCP e DNS e così via</block>
  <block id="543c0ee14bc42e7f38251e99ace0ea62" category="list-text">Configurazione dei volumi ANF come datastore e altro ancora</block>
  <block id="1e09668d117c7996e6a76a4aa2e44013" category="paragraph">Jetstream DR supporta una modalità RTO quasi zero per i domini mission-critical. Per questi domini, lo storage di destinazione deve essere preinstallato. ANF è un tipo di storage consigliato in questo caso.</block>
  <block id="d9a7d19a656972791042b00bc2a308fa" category="admonition">A seconda dei requisiti SLA e RTO, è possibile utilizzare il failover continuo o la normale modalità di failover (standard). Per un RTO vicino allo zero, è necessario avviare una reidratazione continua nel sito di ripristino.</block>
  <block id="4b2287bada3112a86338f8d33bb7f745" category="list-text">Per installare JetStream DR per AVS su un cloud privato Azure VMware Solution, utilizzare il comando Esegui. Dal portale Azure, accedere alla soluzione Azure VMware, selezionare il cloud privato e selezionare Esegui comando &gt; pacchetti &gt; Configurazione JSDR.</block>
  <block id="f36d2f16d7b758d071070007e41f1dc3" category="admonition">L'utente CloudAdmin predefinito di Azure VMware Solution non dispone di privilegi sufficienti per installare JetStream DR per AVS. Azure VMware Solution consente un'installazione semplificata e automatica del DR JetStream invocando il comando Azure VMware Solution Run per il DR JetStream.</block>
  <block id="d5c094ac3602dc70c812b6f203db3080" category="paragraph"><block ref="d5c094ac3602dc70c812b6f203db3080" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1059f69ded45aab3e16676f7655ce33e" category="paragraph"><block ref="1059f69ded45aab3e16676f7655ce33e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f56ba70e80cd5a9d7e833ae9c2a8d00b" category="list-text">Aggiungere l'account Azure Blob Storage utilizzato per proteggere il cluster on-premise come sito di storage, quindi eseguire l'opzione Scan Domains.</block>
  <block id="d46ac425273c7af91c98f03afab4d05d" category="list-text">Nella finestra di dialogo a comparsa visualizzata, selezionare il dominio protetto da importare, quindi fare clic sul relativo collegamento Importa.</block>
  <block id="8f6ce8893e72ca9a99ea54a38aa9123c" category="paragraph"><block ref="8f6ce8893e72ca9a99ea54a38aa9123c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="258e652acbaceeb040a052eb56f710ff" category="list-text">Il dominio viene importato per il ripristino. Accedere alla scheda Protected Domains (domini protetti) e verificare che sia stato selezionato il dominio desiderato oppure scegliere quello desiderato dal menu Select Protected Domain (Seleziona dominio protetto). Viene visualizzato un elenco delle macchine virtuali ripristinabili nel dominio protetto.</block>
  <block id="44f0914b6b6c354b3ed0d0f5c88f5f40" category="paragraph"><block ref="44f0914b6b6c354b3ed0d0f5c88f5f40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab8894857a9c27d55e00ceb59f0a0a9d" category="list-text">Una volta importati i domini protetti, implementare le appliance DRVA.</block>
  <block id="a594598fd21c66eb364972e1018fc5b1" category="admonition">Questi passaggi possono anche essere automatizzati utilizzando piani creati da CPT.</block>
  <block id="5dbd13899d13d449aaa288efb68bc4e7" category="list-text">Importare i domini protetti e configurare il VA di ripristino in modo che utilizzi un datastore ANF per il posizionamento delle macchine virtuali.</block>
  <block id="30c90d4c81b9e156fa124f63997bd267" category="paragraph"><block ref="30c90d4c81b9e156fa124f63997bd267" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27ece16fa591c8a94d158b6371824318" category="admonition">Assicurarsi che DHCP sia attivato sul segmento selezionato e che sia disponibile un numero sufficiente di IP. Gli IP dinamici vengono temporaneamente utilizzati durante il ripristino dei domini. Ogni macchina virtuale di ripristino (inclusa la reidratazione continua) richiede un IP dinamico individuale. Una volta completato il ripristino, l'IP viene rilasciato e può essere riutilizzato.</block>
  <block id="221af48bbe7986080d7f1ef43b7cc9af" category="admonition">Anche se le modalità di failover continuo e failover differiscono quando viene eseguita la configurazione, entrambe le modalità di failover vengono configurate utilizzando le stesse procedure. I passaggi di failover vengono configurati ed eseguiti insieme in risposta a un evento di emergenza. È possibile configurare il failover continuo in qualsiasi momento e consentire l'esecuzione in background durante il normale funzionamento del sistema. In seguito a un evento di emergenza, il failover continuo viene completato per trasferire immediatamente la proprietà delle macchine virtuali protette al sito di ripristino (RTO quasi nullo).</block>
  <block id="12d3f891efb3e0286e3d610d87fa763c" category="paragraph"><block ref="12d3f891efb3e0286e3d610d87fa763c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fad47d76ebfb2068cc150f23d3abc231" category="paragraph">Viene avviato il processo di failover continuo, che può essere monitorato dall'interfaccia utente. Facendo clic sull'icona blu nella sezione Current Step (fase corrente) viene visualizzata una finestra a comparsa che mostra i dettagli della fase corrente del processo di failover.</block>
  <block id="07216bb55061288a2fa29cda954742e3" category="example-title">Failover e failover</block>
  <block id="3dd9279db501526060882c484e7fa2eb" category="list-text">In caso di disastro nel cluster protetto dell'ambiente on-premise (errore parziale o completo), è possibile attivare il failover per le macchine virtuali utilizzando Jetstream dopo aver interrotto la relazione SnapMirror per i rispettivi volumi applicativi.</block>
  <block id="4e26d6c9cc7404940d6c72a71775d261" category="paragraph"><block ref="4e26d6c9cc7404940d6c72a71775d261" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7c749826108cc466667dcaeb67965a7" category="paragraph"><block ref="f7c749826108cc466667dcaeb67965a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="253d2b2bed504833d82e064634bbf83e" category="admonition">Questo passaggio può essere facilmente automatizzato per facilitare il processo di recovery.</block>
  <block id="9824ceea6f74aa9d72ed2bd7473b9362" category="list-text">Accedere all'interfaccia utente Jetstream su AVS SDDC (lato destinazione) e attivare l'opzione di failover per completare il failover. La barra delle applicazioni mostra lo stato di avanzamento delle attività di failover.</block>
  <block id="b39966f9c6438e5d60c1de37dfa3ed05" category="paragraph">Nella finestra di dialogo visualizzata al completamento del failover, è possibile specificare l'attività di failover come pianificata o presunta come forzata.</block>
  <block id="684bb098f20646b3f18e10bc17e2d3c4" category="paragraph"><block ref="684bb098f20646b3f18e10bc17e2d3c4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="562cb54fd49a347cfb889e6021e0be34" category="paragraph"><block ref="562cb54fd49a347cfb889e6021e0be34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="979b519fc9d5e27e5d114696ce4b1366" category="paragraph">Il failover forzato presuppone che il sito primario non sia più accessibile e che la proprietà del dominio protetto debba essere direttamente assunta dal sito di ripristino.</block>
  <block id="cfb2ac66b6e4f6580c9c1fb2cf3b42a5" category="paragraph"><block ref="cfb2ac66b6e4f6580c9c1fb2cf3b42a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9be51d726dd7c6ae76c2545a91f36d11" category="paragraph"><block ref="9be51d726dd7c6ae76c2545a91f36d11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fce15eac6afaa8615d7a00cc4972808" category="list-text">Una volta completato il failover continuo, viene visualizzato un messaggio che conferma il completamento dell'attività. Al termine dell'attività, accedere alle macchine virtuali ripristinate per configurare le sessioni ISCSI o NFS.</block>
  <block id="53839296d302ef4a3faf8220562c1ce4" category="admonition">La modalità di failover diventa in esecuzione in failover e lo stato della macchina virtuale è ripristinabile. Tutte le macchine virtuali del dominio protetto sono ora in esecuzione nel sito di ripristino nello stato specificato dalle impostazioni del runbook di failover.</block>
  <block id="50ff3dc4ca6f3eb140f2099f2b480b83" category="admonition">Per verificare la configurazione e l'infrastruttura di failover, è possibile utilizzare JetStream DR in modalità test (opzione Test failover) per osservare il ripristino delle macchine virtuali e dei relativi dati dall'archivio di oggetti in un ambiente di test recovery. Quando una procedura di failover viene eseguita in modalità test, il suo funzionamento assomiglia a un processo di failover effettivo.</block>
  <block id="a6687fcac4b89ac042d0bf01e0eed2c7" category="paragraph"><block ref="a6687fcac4b89ac042d0bf01e0eed2c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf3e40ce09f6fe770361fe49d398cad9" category="list-text">Una volta ripristinate le macchine virtuali, utilizzare il disaster recovery dello storage per lo storage in-guest. Per dimostrare questo processo, in questo esempio viene utilizzato SQL Server.</block>
  <block id="e5007f72fe428769908e4b66a64b1ace" category="list-text">Accedere alla macchina virtuale SnapCenter recuperata su AVS SDDC e attivare la modalità DR.</block>
  <block id="8bc57e8e0debd3b1f0e1c01431ceb73b" category="list-text">Accedere all'interfaccia utente di SnapCenter utilizzando il browserN.</block>
  <block id="b29ffa42af1df2e35cdf88be1740bdf8" category="paragraph"><block ref="b29ffa42af1df2e35cdf88be1740bdf8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="392d143fa78a9868b2d56197de458a8d" category="list-text">Nella pagina Settings (Impostazioni), accedere a Settings (Impostazioni) &gt; Global Settings (Impostazioni globali) &gt; Disaster Recovery (Ripristino di emergenza).</block>
  <block id="f4060a5dfc75e427eab8fc559b5c3873" category="list-text">Selezionare Enable Disaster Recovery (attiva ripristino di emergenza).</block>
  <block id="79bee17b4293b619c241ae80aef8ef62" category="list-text">Fare clic su Applica.</block>
  <block id="24049296b222c98c12a36098c1928b9f" category="paragraph"><block ref="24049296b222c98c12a36098c1928b9f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f31c54b6a166b6ab176f034d0f52e291" category="list-text">Verificare che il processo DR sia attivato facendo clic su Monitor &gt; Jobs (Monitor &gt; processi).</block>
  <block id="a194386b24136c162d5de560f2c4b3c9" category="admonition">Per il disaster recovery dello storage è necessario utilizzare NetApp SnapCenter 4.6 o versione successiva. Per le versioni precedenti, è necessario utilizzare snapshot coerenti con l'applicazione (replicati utilizzando SnapMirror) e eseguire il ripristino manuale nel caso in cui i backup precedenti debbano essere ripristinati nel sito di disaster recovery.</block>
  <block id="a1e59d581c6cda40186a3488aa35c0b5" category="list-text">Verificare che la relazione di SnapMirror non sia più stabilita.</block>
  <block id="ab99ab9f50b0f74bd7b676fbb522f5e8" category="paragraph"><block ref="ab99ab9f50b0f74bd7b676fbb522f5e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5fabb74faf982c31918e4a241092e386" category="list-text">Collegare il LUN da Cloud Volumes ONTAP alla macchina virtuale SQL guest recuperata con le stesse lettere di unità.</block>
  <block id="faedf38240e42a0e3f085f6acdc22aec" category="paragraph"><block ref="faedf38240e42a0e3f085f6acdc22aec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="458585a8fad71bd63549d32afd2c2f69" category="list-text">Aprire iSCSI Initiator, cancellare la sessione disconnessa precedente e aggiungere la nuova destinazione insieme al multipath per i volumi Cloud Volumes ONTAP replicati.</block>
  <block id="5d06816a9331ccf1bde11d80e2438672" category="paragraph"><block ref="5d06816a9331ccf1bde11d80e2438672" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2483b40da799327d80d5aa5c4683efee" category="list-text">Assicurarsi che tutti i dischi siano collegati utilizzando le stesse lettere di unità utilizzate prima del DR.</block>
  <block id="75c3e1de048df1f08f612bb44462afd4" category="paragraph"><block ref="75c3e1de048df1f08f612bb44462afd4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6048d3c947f6b9163f72586701cec853" category="list-text">Riavviare il servizio del server MSSQL.</block>
  <block id="9f8472ea6d004535fc1659d1e6863867" category="paragraph"><block ref="9f8472ea6d004535fc1659d1e6863867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="632dc72bd4eb731f74582d644a0f4b3c" category="list-text">Assicurarsi che le risorse SQL siano nuovamente in linea.</block>
  <block id="9d19926e46fa4cd818065a2726bcf42d" category="paragraph"><block ref="9d19926e46fa4cd818065a2726bcf42d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01fb98a09bb6b1d922a6275724f31823" category="admonition">Nel caso di NFS, collegare i volumi utilizzando il comando mount e aggiornare<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> voci.</block>
  <block id="8145668f843709bddb7b6c8b3f3abbfb" category="paragraph">A questo punto, è possibile eseguire le operazioni e continuare normalmente il business.</block>
  <block id="8020518363652d35b23a9585c780e480" category="admonition">Sull'estremità NSX-T, è possibile creare un gateway Tier-1 dedicato separato per simulare scenari di failover. Ciò garantisce che tutti i carichi di lavoro possano comunicare tra loro, ma che nessun traffico possa essere instradato all'interno o all'esterno dell'ambiente, in modo che qualsiasi attività di triage, contenimento o protezione avanzata possa essere eseguita senza rischi di contaminazione incrociata. Questa operazione non rientra nell'ambito del presente documento, ma può essere facilmente eseguita per simulare l'isolamento.</block>
  <block id="7d7b7ba342280685358aeb9937ce1118" category="paragraph">Una volta che il sito primario è stato nuovamente operativo, è possibile eseguire il failback. La protezione delle macchine virtuali viene ripristinata da Jetstream e la relazione SnapMirror deve essere invertita.</block>
  <block id="5a24d57462c6d674800fbb2a7e0c59ce" category="list-text">Ripristinare l'ambiente on-premise. A seconda del tipo di incidente, potrebbe essere necessario ripristinare e/o verificare la configurazione del cluster protetto. Se necessario, potrebbe essere necessario reinstallare il software DR JetStream.</block>
  <block id="5cf6cc1cdb0715aca121fb45bdc4f42e" category="admonition">Il piano di failback generato da CPT può anche essere utilizzato per avviare il ritorno delle macchine virtuali e dei relativi dati dall'archivio di oggetti all'ambiente VMware originale.</block>
  <block id="130f86be5d695ec045cce675d14637b8" category="paragraph"><block ref="130f86be5d695ec045cce675d14637b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="504e0be50ebedab76e2a7714a22354d3" category="admonition">Specificare il ritardo massimo dopo la pausa delle macchine virtuali nel sito di ripristino e il riavvio nel sito protetto. Il tempo necessario per completare questo processo include il completamento della replica dopo l'arresto delle macchine virtuali di failover, il tempo necessario per pulire il sito di ripristino e il tempo necessario per ricreare le macchine virtuali nel sito protetto. NetApp consiglia 10 minuti.</block>
  <block id="41f8873d7ef0fd0767f8ed6d7798fe87" category="paragraph"><block ref="41f8873d7ef0fd0767f8ed6d7798fe87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5752ed9acb85541568eca0327a24e09f" category="list-text">Completare il processo di failback e confermare la ripresa della protezione delle macchine virtuali e la coerenza dei dati.</block>
  <block id="f872505992d08e75adcaa8a9adbc0d18" category="paragraph"><block ref="f872505992d08e75adcaa8a9adbc0d18" category="inline-image-macro-rx" type="image"></block></block>
  <block id="684bcaaa7dda535165cb0b8f8e76a5ea" category="list-text">Una volta ripristinate le macchine virtuali, scollegare lo storage secondario dall'host e connettersi allo storage primario.</block>
  <block id="79f47ff1cd40017f1ef0eb31e7397d75" category="paragraph"><block ref="79f47ff1cd40017f1ef0eb31e7397d75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18f7dd50970b99e8a3cdeab8c42567b0" category="paragraph"><block ref="18f7dd50970b99e8a3cdeab8c42567b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f0269cfb1a6f24731b2bb3a15b436b2" category="list-text">Verificare che le risorse SQL siano nuovamente in linea.</block>
  <block id="bb9592df1a1b3d7ea469affe88be679f" category="paragraph"><block ref="bb9592df1a1b3d7ea469affe88be679f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f41823ca0d78e787fda8ba7b1c398a29" category="admonition">Per eseguire il failback allo storage primario, assicurarsi che la direzione della relazione rimanga la stessa di prima del failover eseguendo un'operazione di risincronizzazione inversa.</block>
  <block id="6decfeed5d1c375e40e96552e631df25" category="admonition">Per mantenere i ruoli dello storage primario e secondario dopo l'operazione di risincronizzazione inversa, eseguire nuovamente l'operazione di risincronizzazione inversa.</block>
  <block id="2087f49e4433786c996468974c61ae4a" category="paragraph">Questo processo è applicabile ad altre applicazioni come Oracle, ad altri tipi di database simili e ad altre applicazioni che utilizzano lo storage connesso al guest.</block>
  <block id="33b4e9a3c1a928dbdf5273b34d899e61" category="paragraph">Come sempre, verifica le fasi necessarie per il ripristino dei carichi di lavoro critici prima di portarli in produzione.</block>
  <block id="3a02a011f551429a5ec8b46a00017abd" category="list-text">Utilizza la replica efficiente e resiliente di SnapMirror.</block>
  <block id="74915666b8d10f77a73b526e91724cc8" category="list-text">Effettua il ripristino in qualsiasi punto disponibile in tempo con la conservazione delle snapshot di ONTAP.</block>
  <block id="a3704e4802422c6765dd406472307ba1" category="list-text">È disponibile un'automazione completa per tutte le fasi necessarie per il ripristino di centinaia o migliaia di macchine virtuali, dalle fasi di convalida di storage, calcolo, rete e applicazioni.</block>
  <block id="c0e8bb909ee76b5f9683012fd9418729" category="list-text">SnapCenter utilizza meccanismi di cloning che non modificano il volume replicato.</block>
  <block id="d92ea079cd9d83d3d60c1269804b766c" category="list-text">In questo modo si evita il rischio di corruzione dei dati per volumi e snapshot.</block>
  <block id="a29a4a29d457d4322f1f22ed58f9b06a" category="list-text">Sfrutta i dati di DR per flussi di lavoro oltre il DR, come sviluppo/test, test di sicurezza, test di patch e upgrade e test di correzione.</block>
  <block id="e04e963feedf7f0157e360dc2be6d7b3" category="list-text">L'ottimizzazione della CPU e della RAM può contribuire a ridurre i costi del cloud consentendo il ripristino di cluster di calcolo più piccoli.</block>
  <block id="bd3260deba05f8c5831890f164f83733" category="doc">Panoramica delle soluzioni ANF Datastore</block>
  <block id="626c4c46c0b0900648e0b954a96c4399" category="paragraph">Ogni organizzazione di successo sta passando per la trasformazione e la modernizzazione. Nell'ambito di questo processo, le aziende utilizzano solitamente i propri investimenti VMware esistenti, sfruttando al contempo i vantaggi del cloud e esplorando come rendere i processi di migrazione, burst, exteNd e disaster recovery il più possibile perfetti. I clienti che migrano al cloud devono valutare i problemi di flessibilità e burst, uscita dal data center, consolidamento del data center, scenari di fine vita, fusioni, acquisizioni e così via. L'approccio adottato da ciascuna organizzazione può variare in base alle rispettive priorità di business. Nella scelta delle operazioni basate sul cloud, la scelta di un modello a basso costo con performance appropriate e un minimo ostacolo è un obiettivo critico. Oltre a scegliere la piattaforma giusta, l'orchestrazione dello storage e del workflow è particolarmente importante per liberare la potenza dell'implementazione e dell'elasticità del cloud.</block>
  <block id="bcc2a83e573fb5cbbcd097908c609fa6" category="paragraph">Sebbene la soluzione Azure VMware offra funzionalità ibride uniche a un cliente, opzioni di storage nativo limitate ne hanno limitato l'utilità per le organizzazioni con carichi di lavoro elevati in termini di storage. Poiché lo storage è direttamente legato agli host, l'unico modo per scalare lo storage è aggiungere più host, che possono aumentare i costi del 35-40% o più per i carichi di lavoro a elevato utilizzo dello storage. Questi carichi di lavoro necessitano di storage aggiuntivo, non di potenza aggiuntiva, ma ciò significa pagare per host aggiuntivi.</block>
  <block id="abc79d01b4318a1c67504eb7714e360f" category="paragraph">Consideriamo il seguente scenario: Un cliente richiede sei host per la potenza (vCPU/VMEM), ma ha anche un requisito sostanziale per lo storage. In base alla loro valutazione, sono necessari 12 host per soddisfare i requisiti di storage. Questo aumenta il TCO complessivo perché devono acquistare tutta la potenza aggiuntiva quando è necessario solo uno storage maggiore. Questo è valido per qualsiasi caso di utilizzo, inclusi migrazione, disaster recovery, bursting, sviluppo/test, e così via.</block>
  <block id="f6faa113f88d1f8c4795fe189493d34f" category="paragraph">Un altro caso di utilizzo comune per Azure VMware Solution è il disaster recovery (DR). La maggior parte delle organizzazioni non dispone di una strategia di disaster recovery a prova di fool o potrebbe avere difficoltà a giustificare l'esecuzione di un data center fantasma solo per il DR. Gli amministratori possono esplorare opzioni di disaster recovery a impatto zero con un cluster pilota o un cluster on-demand. Quindi, potevano scalare lo storage senza aggiungere host aggiuntivi, un'opzione potenzialmente interessante.</block>
  <block id="feb87b8a766262f1649eb73f664b5237" category="paragraph">In sintesi, i casi di utilizzo possono essere classificati in due modi:</block>
  <block id="113270f68f35ffcbf2a57597bd22e665" category="list-text">Scalabilità della capacità di storage con datastore ANF</block>
  <block id="a46f3b69652b37f2becc5ad8def389fe" category="list-text">Utilizzo di datastore ANF come destinazione di disaster recovery per un workflow di recovery ottimizzato in termini di costi da aree locali o interne ad Azure tra i data center software-defined (SDDC). Questa guida fornisce informazioni sull'utilizzo di Azure NetApp Files per fornire storage ottimizzato per i datastore (attualmente in anteprima pubblica) Oltre alla protezione dei dati e alle funzionalità di DR Best-in-class di una soluzione VMware Azure, che consente di trasferire la capacità dello storage dallo storage vSAN.</block>
  <block id="94e2529c9624e06356bacdc7dc76dab9" category="admonition">Per ulteriori informazioni sull'utilizzo dei datastore ANF, contattare NetApp o i Solution Architect Microsoft della propria regione.</block>
  <block id="9d5486edf9a5ddec98d7f7509d50101c" category="section-title">Opzioni di VMware Cloud in Azure</block>
  <block id="809dd7fcec8077467eab0222ea68e259" category="paragraph">Azure VMware Solution (AVS) è un servizio di cloud ibrido che offre SDDC VMware pienamente funzionanti all'interno di un cloud pubblico Microsoft Azure. AVS è una soluzione di prima parte completamente gestita e supportata da Microsoft e verificata da VMware che utilizza l'infrastruttura Azure. Pertanto, i clienti ottengono VMware ESXi per la virtualizzazione del calcolo, vSAN per lo storage iperconvergente e NSX per il networking e la sicurezza, il tutto sfruttando la presenza globale di Microsoft Azure, le strutture di data center leader di settore e la vicinanza al ricco ecosistema di servizi e soluzioni Azure native. Una combinazione di SDDC e Azure NetApp Files per la soluzione VMware Azure offre le migliori performance con una latenza di rete minima.</block>
  <block id="8718654ef588a85b2a2e46a7727fa16d" category="paragraph">Indipendentemente dal cloud utilizzato, quando viene implementato un VMware SDDC, il cluster iniziale include i seguenti componenti:</block>
  <block id="b6955e4f04d87bd186e8f355b710c814" category="list-text">VMware ESXi ospita la virtualizzazione dell'elaborazione con un'appliance server vCenter per la gestione.</block>
  <block id="c865d5c3f7aef0fea827cecdf6da386c" category="list-text">Storage iperconvergente VMware vSAN che incorpora le risorse di storage fisico di ciascun host ESXi.</block>
  <block id="4d53c4a03b478ccb8f5a4a2cde37db71" category="list-text">VMware NSX per reti virtuali e sicurezza con cluster NSX Manager per la gestione.</block>
  <block id="94d43b2c8702afe74d26d3a9052e59b4" category="paragraph">Sia che tu stia prendendo come riferimento il cloud all-cloud o ibrido, Azure NetApp Files offre opzioni eccellenti per implementare e gestire i carichi di lavoro delle applicazioni insieme ai file service, riducendo al contempo il TCO rendendo i requisiti dei dati perfetti a livello applicativo. Qualunque sia il caso d'utilizzo, scegli Azure VMware Solution insieme a Azure NetApp Files per realizzare rapidamente i benefici del cloud, un'infrastruttura coerente e operazioni su cloud multipli e on-premise, portabilità bidirezionale dei carichi di lavoro e capacità e performance di livello Enterprise. Si tratta degli stessi processi e procedure familiari utilizzati per collegare lo storage. Ricorda che è solo la posizione dei dati che sono stati modificati insieme ai nuovi nomi; i tool e i processi rimangono tutti gli stessi e Azure NetApp Files aiuta a ottimizzare l'implementazione complessiva.</block>
  <block id="7017a5961c414dfbe07b539da73560fb" category="list-text">Ora puoi utilizzare Azure NetApp Files come datastore su AVS SDDC.</block>
  <block id="1997ea39c8d744bf66dd1b36df20eca0" category="list-text">Aumenta i tempi di risposta delle applicazioni e offri una maggiore disponibilità per fornire i dati del carico di lavoro di accesso quando e dove sono necessari.</block>
  <block id="d229778544c20c94bc3a4e634983743a" category="list-text">Semplifica la complessità generale dello storage vSAN con funzionalità di ridimensionamento semplici e istantanee.</block>
  <block id="220eb8ba4e87069e79226f808999d319" category="list-text">Performance garantite per carichi di lavoro mission-critical grazie a funzionalità di risagomatura dinamica.</block>
  <block id="de55b3d8d98ed7c720c8410fbbce524e" category="list-text">Se la destinazione è Azure VMware Solution Cloud, Azure NetApp Files è la soluzione di storage ideale per un'implementazione ottimizzata.</block>
  <block id="e7e97f343a76aab098fd05b8953ee1a5" category="list-text">Collegamento di datastore Azure NetApp Files agli host delle soluzioni VMware Azure (anteprima)</block>
  <block id="1838681ebe885a1a1e886cdf7e263065" category="inline-link"><block ref="1838681ebe885a1a1e886cdf7e263065" category="inline-link-rx"></block></block>
  <block id="2361f6fabb02c6060c638b5f1780cda2" category="paragraph"><block ref="2361f6fabb02c6060c638b5f1780cda2" category="inline-link-rx"></block></block>
  <block id="9e289e2a1ce460725108e7241e19b575" category="doc">Disponibilità regionale per datastore NFS supplementari su AWS, Azure e GCP</block>
  <block id="3ce209dcd58ed0c7d8cf39f37f2b1557" category="paragraph">Scopri di più sul supporto della Global Region per datastore NFS supplementari su AWS, Azure e Google Cloud Platform (GCP).</block>
  <block id="3b041c1182ede15a52a683344c9512e0" category="section-title">Disponibilità AWS Region</block>
  <block id="c5fde59b3560ee1ea5aeeebaf94bdf39" category="section-title">Disponibilità della regione di Azure</block>
  <block id="27dafc6e4e2e3563b0434812fa3fee7c" category="section-title">Disponibilità della regione GCP</block>
  <block id="68c6fcf9f9393805f0529c36994a9266" category="paragraph">La disponibilità della regione GCP verrà rilasciata quando GCP entrerà nella disponibilità pubblica.</block>
  <block id="a7714bc43e9a27f2c98a38e6b6d7f3d8" category="doc">Opzioni di storage NetApp per i provider di cloud pubblico</block>
  <block id="8db50e5729f7a5d770aaceef947a2982" category="paragraph">Esplora le opzioni per NetApp come storage nei tre principali hyperscaler.</block>
  <block id="0c138556fe4f10d4cdba4c61933afd91" category="doc">Soluzioni NetApp per Google Cloud Virtualization Engine (GCVE)</block>
  <block id="7c0dae765c7854235808e7e373346d06" category="paragraph">Scopri di più sulle soluzioni offerte da NetApp per il GCP.</block>
  <block id="58997b61f0fc8812c9977a9dd3d181c5" category="inline-link-macro">Disaster recovery applicativo con replica SnapCenter, Cloud Volumes ONTAP e Veeam</block>
  <block id="f22705ef66107a528d4982aa8fdd463d" category="list-text"><block ref="f22705ef66107a528d4982aa8fdd463d" category="inline-link-macro-rx"></block></block>
  <block id="c3b1da56e0792b4ce28bc91a4bf79841" category="inline-link-macro">Migrazione dei carichi di lavoro con VMware HCX al datastore NetApp Cloud Volume Service NFS</block>
  <block id="c2dd2858771476e1bd26526be2c1f5ad" category="list-text"><block ref="c2dd2858771476e1bd26526be2c1f5ad" category="inline-link-macro-rx"></block></block>
  <block id="e78040a1599894c3db7423e479a1f7d1" category="summary">Il disaster recovery nel cloud è un metodo resiliente e conveniente per proteggere i workload da interruzioni del sito e eventi di corruzione dei dati come ransomware. Con NetApp SnapMirror, è possibile replicare i workload VMware on-premise che utilizzano lo storage connesso agli ospiti su NetApp Cloud Volumes ONTAP in esecuzione su Google Cloud.</block>
  <block id="0fa916b50826c2fab3e504331d6b8ad1" category="paragraph">Autori: Suresh Thoppay, NetApp</block>
  <block id="366fe59477118cc36e7ef7936cc04771" category="paragraph">Il disaster recovery nel cloud è un metodo resiliente e conveniente per proteggere i workload da interruzioni del sito e eventi di corruzione dei dati come ransomware. Con NetApp SnapMirror, è possibile replicare i workload VMware on-premise che utilizzano lo storage connesso agli ospiti su NetApp Cloud Volumes ONTAP in esecuzione su Google Cloud. Ciò riguarda i dati delle applicazioni, ma le macchine virtuali effettive. Il disaster recovery dovrebbe coprire tutti i componenti dipendenti, tra cui macchine virtuali, VMDK, dati applicativi e altro ancora. A tale scopo, SnapMirror e Veeam possono essere utilizzati per ripristinare perfettamente i carichi di lavoro replicati da on-premise a Cloud Volumes ONTAP utilizzando lo storage vSAN per VM VMDK.</block>
  <block id="93fb0db9f34ab708d4c3e5d233e4d97f" category="paragraph">Questo documento fornisce un approccio passo per passo per la configurazione e l'esecuzione del disaster recovery che utilizza NetApp SnapMirror, Veeeam e Google Cloud VMware Engine (GCVE).</block>
  <block id="669129cbcdc854bf23fe7e672be9c44c" category="paragraph"><block ref="669129cbcdc854bf23fe7e672be9c44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c611c3f34a5f506ad20f441b78810981" category="paragraph">Per la connettività tra l'ambiente on-premise e la rete Google Cloud, utilizza le opzioni di connettività come l'interconnessione dedicata o la VPN cloud. I segmenti devono essere creati in base alla progettazione della VLAN on-premise.</block>
  <block id="b62c675a3e45635be4cc5a65dde4c55c" category="admonition">Esistono diverse opzioni per connettere i data center on-premise a Google Cloud, che ci impediscono di delineare un workflow specifico in questo documento. Fare riferimento alla documentazione di Google Cloud per il metodo di connettività on-premise-to-Google appropriato.</block>
  <block id="5e345ef39956138694764fce9921e498" category="list-text">Installare il software Veeam e avviare la replica delle macchine virtuali sull'istanza di Google Cloud VMware Engine.</block>
  <block id="7c6d17fe855de9f3821d0cead78f4d26" category="list-text">Durante un evento di disastro, interrompere la relazione SnapMirror utilizzando Cloud Manager e attivare il failover delle macchine virtuali con Veeam.</block>
  <block id="e36e9213012a15c95ec5048a09f751b0" category="list-text">Visualizzare le applicazioni online.</block>
  <block id="820f3ffde5403dbc2ca3d17b511f569e" category="example-title">Configurare CVO su Google Cloud e replicare i volumi su CVO</block>
  <block id="6765d7341fa9566a047031c62d2040b8" category="inline-link">cvo</block>
  <block id="14cdb7188d3a5edcc69cb9fe2ebf708b" category="paragraph">Il primo passo è configurare Cloud Volumes ONTAP su Google Cloud <block ref="21dbe7906aa79142ad8a44237d3d84a5" category="inline-link-rx"></block>) E replicare i volumi desiderati su Cloud Volumes ONTAP con le frequenze desiderate e le ritentioni di snapshot.</block>
  <block id="1b6eb09708583df3feb79dd7e7b9ed2a" category="paragraph"><block ref="1b6eb09708583df3feb79dd7e7b9ed2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b67ee8de7f0f6f1b68e41ce4be6b4a0b" category="inline-link">Configurazione della replica con SnapCenter</block>
  <block id="0fc2ee38d3f3fcee9b5d5d0bad287f93" category="paragraph">Per istruzioni dettagliate di esempio sull'impostazione di SnapCenter e la replica dei dati, fare riferimento a.<block ref="06275778c7333bddf485b7069aff5016" category="inline-link-rx"></block></block>
  <block id="5a101eac27a34cdc3b06c105760d0cee" category="example-title">Configurare gli host GCVE e l'accesso ai dati CVO</block>
  <block id="1fe9f40218e52161bc5e31e2cd383a0b" category="paragraph">Due fattori importanti da prendere in considerazione durante l'implementazione di SDDC sono le dimensioni del cluster SDDC nella soluzione GCVE e il tempo necessario per mantenere SDDC in servizio. Queste due considerazioni chiave per una soluzione di disaster recovery contribuiscono a ridurre i costi operativi complessivi. Il controller SDDC può contenere fino a tre host, fino a un cluster multi-host in un'implementazione su larga scala.</block>
  <block id="4f7b492a9eedf950f4dbd01357b22979" category="paragraph">Cloud Volumes ONTAP può essere implementato su qualsiasi VPC e deve disporre di una connessione privata a tale VPC per consentire la connessione della macchina virtuale alle LUN iSCSI.</block>
  <block id="cf3ac5a0dae3780b356e57c121b3eab0" category="inline-link">Implementare e configurare l'ambiente di virtualizzazione su Google Cloud Platform (GCP)</block>
  <block id="727eadb1fcad984cfa778a04f2181408" category="paragraph">Per configurare GCVE SDDC, vedere<block ref="06e1fa19855b73b0e800850663f265a2" category="inline-link-rx"></block>. Come prerequisito, verificare che le macchine virtuali guest che risiedono sugli host GCVE siano in grado di utilizzare i dati provenienti da Cloud Volumes ONTAP dopo aver stabilito la connettività.</block>
  <block id="fb75a211e033fa96e7f692258221c1da" category="paragraph">Dopo aver configurato correttamente Cloud Volumes ONTAP e GCVE, iniziare a configurare Veeam per automatizzare il ripristino dei carichi di lavoro on-premise su GCVE (macchine virtuali con VMDK delle applicazioni e macchine virtuali con storage in-guest) utilizzando la funzione di replica Veeam e sfruttando SnapMirror per le copie dei volumi delle applicazioni su Cloud Volumes ONTAP.</block>
  <block id="87e3cc18e14b0d78c8c46e3ed343fca7" category="example-title">Installare i componenti Veeam</block>
  <block id="9b6f25534617a536120885c9ce2bf30b" category="inline-link">Fare riferimento alla documentazione Veeam per la procedura di installazione</block>
  <block id="934282d2b6cc731f63bcc3cdfbba32a1" category="paragraph">In base allo scenario di implementazione, il server di backup Veeam, il repository di backup e il proxy di backup che devono essere implementati. In questo caso di utilizzo, non è necessario implementare l'archivio di oggetti per Veeam e il repository scale-out.<block ref="3798d8f6f1f14581181abe3a5ef34dc1" category="inline-link-rx"></block></block>
  <block id="60fec867397af265e1e757d06135859e" category="example-title">Configurazione della replica delle macchine virtuali con Veeam</block>
  <block id="d81c3dfdfda7fb8581660b5d218c6a3a" category="inline-link">Processo di replica di vSphere VM</block>
  <block id="6a67b79523a52a3a2b4e485485456565" category="paragraph">VCenter on-premise e gCVE vCenter devono essere registrati con Veeam.<block ref="9af60ccd7c779b77ba6ce43ae96a95f6" category="inline-link-rx"></block> Nella fase di elaborazione guest della procedura guidata, selezionare Disable application processing (Disattiva elaborazione applicazioni), in quanto verrà utilizzato SnapCenter per il backup e il ripristino consapevoli dell'applicazione.</block>
  <block id="34510608302d692ff6f3936359703d26" category="example-title">Failover di Microsoft SQL Server VM</block>
  <block id="ce137de4140fd114a7fb3fcb057328fa" category="list-text">La replica Veeam consente di modificare gli indirizzi IP delle macchine virtuali sul sito DR.</block>
  <block id="12709db6944c7fef6c2f181c42bd4741" category="doc">Soluzioni NetApp ibride multicloud per GCP/GCVE</block>
  <block id="7ca47d49ee6c57c993203315ea11c82b" category="doc">Migrazione dei carichi di lavoro nel datastore NetApp Cloud Volume Service su Google Cloud VMware Engine con VMware HCX - Guida rapida</block>
  <block id="925d41ba352b91ef0de674e109988a23" category="section-title">Panoramica: Migrazione di macchine virtuali con VMware HCX, datastore NetApp Cloud Volume Service e Google Cloud VMware Engine (GCVE)</block>
  <block id="ecca6d9dd6ca6c76191faa472f8c6df9" category="paragraph">Uno dei casi di utilizzo più comuni per il datastore Google Cloud VMware Engine e Cloud Volume Service è la migrazione dei carichi di lavoro VMware. VMware HCX è un'opzione preferita e offre vari meccanismi di migrazione per spostare macchine virtuali (VM) on-premise e i relativi dati negli archivi dati NFS Cloud Volume Service.</block>
  <block id="d5230db8260d991194ad332af34aa9de" category="paragraph">VMware HCX è principalmente una piattaforma di migrazione progettata per semplificare la migrazione delle applicazioni, il ribilanciamento dei carichi di lavoro e persino la business continuity tra i cloud. È incluso come parte di Google Cloud VMware Engine Private Cloud e offre diversi modi per migrare i workload e può essere utilizzato per le operazioni di disaster recovery (DR).</block>
  <block id="cac5c7468f43bdedfbaa5b47e384516c" category="paragraph">Il presente documento fornisce istruzioni dettagliate per il provisioning del datastore Cloud Volume Service, seguito dal download, dall'implementazione e dalla configurazione di VMware HCX, inclusi tutti i componenti principali on-premise e dal lato motore VMware di Google Cloud, tra cui Interconnect, Network Extension e ottimizzazione WAN per l'abilitazione di vari meccanismi di migrazione delle macchine virtuali.</block>
  <block id="256044a3a14b99a48569af0ee614f2c4" category="admonition">VMware HCX funziona con qualsiasi tipo di datastore poiché la migrazione è a livello di VM. Pertanto, questo documento è valido per i clienti NetApp esistenti e non NetApp che intendono implementare Cloud Volume Service con Google Cloud VMware Engine per un'implementazione cloud VMware conveniente.</block>
  <block id="b0568534d9aa25692e3a5fe6337361bc" category="paragraph">Questo elenco fornisce i passaggi di alto livello necessari per associare e migrare le macchine virtuali a HCX Cloud Manager sul lato Google Cloud VMware Engine da HCX Connector on-premise:</block>
  <block id="08ac9dd8c46a01de111ff552302c4b8b" category="list-text">Preparare HCX attraverso il portale Google VMware Engine.</block>
  <block id="c51c3de337c64144b065b508d7092f70" category="list-text">Associare il connettore VMware HCX on-premise con Google Cloud VMware Engine HCX Cloud Manager.</block>
  <block id="b8da85496a56d9f8f2c4db60c06b6c4a" category="paragraph">Prima di iniziare, assicurarsi che siano soddisfatti i seguenti prerequisiti. Per ulteriori informazioni, consulta questa sezione<block ref="d195855fe41d7993983c9e07318b9bad" category="inline-link-rx"></block>. Una volta soddisfatti i prerequisiti, inclusa la connettività, scaricare la chiave di licenza HCX dal portale VMware Engine di Google Cloud. Una volta scaricato il programma di installazione di OVA, procedere con la procedura di installazione come descritto di seguito.</block>
  <block id="e2f64bf47a1540374c40a3ede73573e5" category="admonition">HCX Advanced è l'opzione predefinita e VMware HCX Enterprise Edition è disponibile anche attraverso un ticket di supporto e supportato senza costi aggiuntivi. Fare riferimento a.<block ref="d860d3a39c377ffee7e9262276d5a062" category="inline-link-rx"></block></block>
  <block id="8cea371309574d6004c96292961aae25" category="inline-link">Link di Google</block>
  <block id="2fe1711b46889920c53ebb512b61bc78" category="list-text">Utilizza un data center software-defined (SDDC) Google Cloud VMware Engine esistente o crea un cloud privato utilizzando questo<block ref="e829d3b8e1188066e830ce55cc4a4e51" category="inline-link-rx"></block> o questo<block ref="a00f1cbf0fed787208cc1bff752e650f" category="inline-link-rx"></block>.</block>
  <block id="792178f6051d02890db289c3d249504a" category="inline-link">Configurare una connessione Cloud VPN o Cloud Interconnect</block>
  <block id="136020259e42699a5f3259ade2d1a34f" category="list-text">La migrazione delle macchine virtuali e dei dati associati dal data center abilitato VMware vSphere on-premise richiede la connettività di rete dal data center all'ambiente SDDC. Prima di migrare i carichi di lavoro,<block ref="bef4838acfa84f7c195dab1fed38f189" category="inline-link-rx"></block> tra l'ambiente on-premise e il rispettivo cloud privato.</block>
  <block id="b62ace404956042129e3b88bdf88cc9d" category="list-text">Il percorso di rete dall'ambiente VMware vCenter Server on-premise al cloud privato VMware Engine di Google Cloud deve supportare la migrazione delle macchine virtuali utilizzando vMotion.</block>
  <block id="20ced0e16abf47f28e1313f368ad6f6f" category="list-text">Assicurarsi di aver selezionato il necessario<block ref="75de7fce953864ac8abf1081d395e485" category="inline-link-rx"></block> Sono consentiti per il traffico vMotion tra vCenter Server on-premise e vCenter SDDC.</block>
  <block id="2991589cdf3c2d6d60db9953585e1b04" category="list-text">Il volume NFS Cloud Volume Service deve essere montato come datastore in Google Cloud VMware Engine. Seguire i passaggi descritti in questa sezione<block ref="5c088b3a89e196aaeb81f75ec6428544" category="inline-link-rx"></block> Per collegare gli archivi dati Cloud Volume Service agli host Google Cloud VMware Engines.</block>
  <block id="4d74daf8e004df493e26c50161d35bd9" category="paragraph">A scopo di test, l'ambiente di laboratorio on-premise utilizzato per questa convalida è stato connesso tramite una VPN cloud, che consente la connettività on-premise con Google Cloud VPC.</block>
  <block id="44197d2707e0d62a7cdddb22b96b5d73" category="paragraph"><block ref="44197d2707e0d62a7cdddb22b96b5d73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bdd8ea25a7e8ed9b55cbe0a3d16b342d" category="paragraph">Per uno schema più dettagliato su HCX, fare riferimento a.<block ref="7d6a057cc94389224fa6745cc76b1870" category="inline-link-rx"></block></block>
  <block id="cd7d4a329d381d6c2399222be4a728d6" category="example-title">Fase 1: Preparazione DI HCX attraverso il portale Google VMware Engine</block>
  <block id="5435b8e0738b76228bad99efecb45790" category="paragraph">Il componente HCX Cloud Manager viene installato automaticamente durante il provisioning del cloud privato con VMware Engine. Per prepararsi all'associazione del sito, attenersi alla seguente procedura:</block>
  <block id="f6f646bebf3c14227b9b610041749d2b" category="list-text">Accedi al portale Google VMware Engine e accedi A HCX Cloud Manager.</block>
  <block id="f3c4e020173d4055af3d73eabb546a5f" category="inline-image-macro">Accesso alla console HCX con link sulla risorsa GCVE</block>
  <block id="d481d49ad5e07c065daa1b652e1e93f6" category="inline-image-macro">Accesso alla console HCX con collegamento FQDN</block>
  <block id="1509189c3a021030c9c75afd5e0ee142" category="paragraph">È possibile accedere ALLA console HCX facendo clic sul collegamento alla versione HCX<block ref="e0eabfd77e9b6a166bd62bce317f2ca6" category="inline-image-macro-rx" type="image"></block>In alternativa, fare clic su HCX FQDN nella scheda vSphere Management Network (rete di gestione di vSphere).<block ref="1bc7b537d1e927f2f5e06674a9fb9636" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72580ca988ce9234d221d19195a8ced9" category="list-text">In HCX Cloud Manager, accedere a *Administration &gt; System Updates* (Amministrazione &gt; aggiornamenti del sistema).</block>
  <block id="4477d36b1c0d580b9493616b9a3cdc6a" category="inline-image-macro">Richiedi il link per il download</block>
  <block id="e3428ddcd1ea8611a819b5a63134abdd" category="list-text">Fare clic su *Richiedi il download* e scaricare il file OVA.<block ref="b27b0af334d354a85d901dbf7f557880" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b2574bff5f52ebae3e52462b6f64628" category="list-text">Aggiornare HCX Cloud Manager alla versione più recente disponibile dall'interfaccia utente DI HCX Cloud Manager.</block>
  <block id="71c11944a5e7c7a2e01d85bf931a4e0c" category="paragraph">Affinché il connettore on-premise si connetta a HCX Manager in Google Cloud VMware Engine, assicurarsi che le porte firewall appropriate siano aperte nell'ambiente on-premise.</block>
  <block id="cded3ab78e1131b2cb252673847fc8cd" category="list-text">Fare scaricare la OVA dalla console HCX su Google Cloud VMware Engine come indicato nella fase precedente.</block>
  <block id="80177ed47e2799b2f8133ec987c4f413" category="paragraph"><block ref="80177ed47e2799b2f8133ec987c4f413" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f35d393de16f7f328d28c3c3f9a36fd" category="paragraph">Per istruzioni dettagliate, consultare<block ref="6281ad4977a05e5987f07e864fefe4fe" category="inline-link-rx"></block>.</block>
  <block id="3981acf431a0cb2b387f1fc62e246114" category="paragraph">Dopo aver implementato VMware HCX Connector OVA on-premise e avviato l'appliance, completare la seguente procedura per attivare HCX Connector. Generare la chiave di licenza dal portale Google Cloud VMware Engine e attivarla in VMware HCX Manager.</block>
  <block id="842413b7e215b2d5b82a5bb3dd7a07cd" category="inline-image-macro">Scarica la licenza HCX</block>
  <block id="61b61b56e3a9ddaa25f900492dbfaafc" category="list-text">Dal portale VMware Engine, fare clic su Resources (risorse), selezionare il cloud privato e *fare clic sull'icona di download sotto HCX Manager Cloud Version*.<block ref="be9330ae20074d9fd27022c3077c5923" category="inline-image-macro-rx" type="image"></block>Aprire il file scaricato e copiare la stringa della chiave di licenza.</block>
  <block id="8680173d99521ba5a429ed524d3615e3" category="admonition">Utilizzare l'IP hcxmanagerIP e la password definiti durante l'implementazione di OVA.</block>
  <block id="35c93ae128c86187e819ac86d8df4979" category="list-text">In *Configure SSO/PSC* (Configura SSO/PSC), fornire l'indirizzo IP o il nome FQDN del Platform Services Controller (PSC) e fare clic su *Continue* (continua).</block>
  <block id="6098ad379dba0c94396b9b690b83b1b0" category="admonition">Per Embedded PSC, immettere l'indirizzo FQDN o IP di VMware vCenter Server.</block>
  <block id="09bf9812f77e2e14861b7f3360ca026c" category="paragraph"><block ref="09bf9812f77e2e14861b7f3360ca026c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b23a293b550e17ca6e836b05c01b4a76" category="example-title">Fase 4: Associazione on-premise di VMware HCX Connector con Google Cloud VMware Engine HCX Cloud Manager</block>
  <block id="47234b871b1edd33168f7394e72a5b4d" category="paragraph">Una volta implementato E configurato IL connettore HCX on-premise vCenter, stabilire la connessione a Cloud Manager aggiungendo l'accoppiamento. Per configurare l'associazione del sito, attenersi alla seguente procedura:</block>
  <block id="594e3fbccf355af479f921ff2a455e68" category="list-text">Per creare una coppia di siti tra l'ambiente vCenter on-premise e Google Cloud VMware Engine SDDC, accedere a vCenter Server on-premise e al nuovo plug-in HCX vSphere Web Client.</block>
  <block id="bf29c65588093243bdcd92d7e57d228c" category="paragraph"><block ref="bf29c65588093243bdcd92d7e57d228c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1b3c5cdedf84c785d5ee65ca00324e36" category="admonition">Inserire l'indirizzo IP o l'URL di Google Cloud VMware Engine HCX Cloud Manager e le credenziali per l'utente con privilegi di ruolo Cloud Owner per l'accesso al cloud privato.</block>
  <block id="6b5c33ae4600df59658bcd86a24ca532" category="inline-image-macro">URL o indirizzo IP della schermata e credenziali per il ruolo CloudOwner.</block>
  <block id="b7b6a499bbb533c0e3da098fa71d75c8" category="paragraph"><block ref="b7b6a499bbb533c0e3da098fa71d75c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3874f23d22312a1be0f07b98dda866c" category="paragraph"><block ref="a3874f23d22312a1be0f07b98dda866c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="593c226b2f1fa412557c01630aaaafa0" category="paragraph"><block ref="593c226b2f1fa412557c01630aaaafa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="575a0d0e1243eeff47338ea176157139" category="inline-image-macro">Schermata del profilo di rete.</block>
  <block id="47a6f72e73b15b7be0f3c4cf577c9229" category="paragraph"><block ref="47a6f72e73b15b7be0f3c4cf577c9229" category="inline-image-macro-rx" type="image"></block></block>
  <block id="179a1380fec15d2ca58ae44d36bc70ea" category="list-text">Creare la Service Mesh selezionando la scheda *Service Mesh* all'interno dell'opzione *Interconnect* e selezionando i siti SDDC on-premise e GCVE.</block>
  <block id="4200f06936ac63230a0663a772209a07" category="paragraph"><block ref="4200f06936ac63230a0663a772209a07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="347a982d83a0b2cce2d1ec814a70ae8f" category="inline-image-macro">Schermata delle appliance HCX nella pagina di interconnessione del client vSphere.</block>
  <block id="26c83c715efad97126cacdaebf25d274" category="paragraph"><block ref="26c83c715efad97126cacdaebf25d274" category="inline-image-macro-rx" type="image"></block></block>
  <block id="070b97376b0c0aea0c9cb598600c4662" category="paragraph">I carichi di lavoro possono essere migrati bidirezionalmente tra gli SDDC on-premise e GCVE utilizzando varie tecnologie di migrazione VMware HCX. Le VM possono essere spostate da e verso le entità attivate da VMware HCX utilizzando diverse tecnologie di migrazione, come LA migrazione in blocco HCX, HCX vMotion, HCX Cold Migration, HCX Replication Assisted vMotion (disponibile con HCX Enterprise Edition) e HCX OS Assisted Migration (disponibile con HCX Enterprise Edition).</block>
  <block id="a50268e48a4ee751d804978922edf189" category="paragraph">Per ulteriori informazioni sui vari meccanismi di migrazione HCX, vedere<block ref="78adb493f3638835899da003743379e3" category="inline-link-rx"></block>.</block>
  <block id="de5218d95fb66ad99c822109709a45af" category="paragraph">*HCX vMotion*</block>
  <block id="803853313afe589d091d3f55583d78c2" category="paragraph">In questa sezione viene descritto il meccanismo vMotion DI HCX. Questa tecnologia di migrazione utilizza il protocollo VMware vMotion per migrare una macchina virtuale in GCVE. L'opzione di migrazione vMotion viene utilizzata per la migrazione dello stato della macchina virtuale di una singola macchina virtuale alla volta. Durante questo metodo di migrazione non si verifica alcuna interruzione del servizio.</block>
  <block id="6b253c8fd6849183f558040da38608cb" category="paragraph"><block ref="6b253c8fd6849183f558040da38608cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="844c529dbe1866abc23447f68eb60ba6" category="list-text">Nella procedura guidata Migrate Virtual Machine, selezionare Remote Site Connection (GCVE di destinazione).</block>
  <block id="4e862b96a802868c38004aa7c404252b" category="paragraph"><block ref="4e862b96a802868c38004aa7c404252b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2a3abee640eaa37034e3ce3f7b7075e" category="list-text">Aggiornare i campi obbligatori (Cluster, Storage e Destination Network), quindi fare clic su Validate (convalida).</block>
  <block id="dbccaf1da09c1555918b6548737f4c62" category="paragraph"><block ref="dbccaf1da09c1555918b6548737f4c62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a88d0b48c0e4e339e4f73353d906d12" category="admonition">Il trasferimento vMotion acquisisce la memoria attiva della macchina virtuale, il suo stato di esecuzione, il suo indirizzo IP e il suo indirizzo MAC. Per ulteriori informazioni sui requisiti e sulle limitazioni di HCX vMotion, vedere<block ref="23e132bfd0fa1c0804ce8b87a8fad5cd" category="inline-link-rx"></block>.</block>
  <block id="9292100550c5fda83387e2e78b8a2a2a" category="paragraph"><block ref="9292100550c5fda83387e2e78b8a2a2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="38f70a328b4ae90f9650bc4c029b6a3f" category="admonition">Il datastore NFS CVS di destinazione deve disporre di spazio sufficiente per gestire la migrazione.</block>
  <block id="2de1e2776c8a8d3b752e50dc8c6550df" category="paragraph">Sia che tu stia prendendo di mira il cloud all-cloud o ibrido e i dati che risiedono su storage di qualsiasi tipo/vendor in on-premise, Cloud Volume Service e HCX offrono eccellenti opzioni per implementare e migrare i carichi di lavoro delle applicazioni, riducendo al contempo il TCO rendendo i requisiti dei dati perfetti per il livello applicativo. Qualunque sia il caso d'utilizzo, scegli Google Cloud VMware Engine insieme a Cloud Volume Service per una rapida realizzazione dei vantaggi del cloud, un'infrastruttura coerente e operazioni su cloud multipli e on-premise, portabilità bidirezionale dei carichi di lavoro e capacità e performance di livello Enterprise. Si tratta degli stessi processi e procedure familiari utilizzati per connettere lo storage e migrare le macchine virtuali utilizzando VMware vSphere Replication, VMware vMotion o persino la copia del file di rete (NFC).</block>
  <block id="6bb8d723218f4efa76cd05165c603ac6" category="list-text">Ora puoi utilizzare Cloud Volume Service come datastore su Google Cloud VMware Engine SDDC.</block>
  <block id="06b37831abeee3229c61a3285dc4100c" category="list-text">È possibile migrare facilmente i dati dall'archivio dati on-premise a Cloud Volume Service.</block>
  <block id="dcb763cc64570798740f3e41b84fff0e" category="list-text">È possibile espandere e ridurre facilmente il datastore Cloud Volume Service per soddisfare i requisiti di capacità e performance durante l'attività di migrazione.</block>
  <block id="267029140dfbe181dd69e7d084de9b69" category="section-title">Video di Google e VMware come riferimento</block>
  <block id="e35dee203b7c81af1f3954054112ba15" category="example-title">Da Google</block>
  <block id="50144090c2258cae139ecf6022e7367b" category="inline-link-macro">Implementare HCX Connector con GCVE</block>
  <block id="b7b1de0b057bbef976725c6fff3da9b9" category="list-text"><block ref="b7b1de0b057bbef976725c6fff3da9b9" category="inline-link-macro-rx"></block></block>
  <block id="328f11633999c58a7b282b8632e2797d" category="inline-link-macro">Configurare HCX ServiceMesh con GCVE</block>
  <block id="79cb5f4e657f45df30765c695fd1925a" category="list-text"><block ref="79cb5f4e657f45df30765c695fd1925a" category="inline-link-macro-rx"></block></block>
  <block id="7a749829f023d0ee25c026f4f6bbba9a" category="inline-link-macro">Migrare VM con HCX in GCVE</block>
  <block id="a53a9cd13cd53b632a558fc3657092ab" category="list-text"><block ref="a53a9cd13cd53b632a558fc3657092ab" category="inline-link-macro-rx"></block></block>
  <block id="252de7413389db6514f76f43d66fd8e3" category="example-title">Di VMware</block>
  <block id="13e623e9a14240dd859556650e9b531a" category="inline-link-macro">Implementazione DI HCX Connector per GCVE</block>
  <block id="d323fc5e6199a5240de090ee56887d79" category="list-text"><block ref="d323fc5e6199a5240de090ee56887d79" category="inline-link-macro-rx"></block></block>
  <block id="691fd2fc5f5666a82025c09044b4227e" category="inline-link-macro">Configurazione HCX ServiceMesh per GCVE</block>
  <block id="1d057bc0c304f69e3c2b912a056d3823" category="list-text"><block ref="1d057bc0c304f69e3c2b912a056d3823" category="inline-link-macro-rx"></block></block>
  <block id="f27a9b33e86b3a166fd93f5581d2fd88" category="inline-link-macro">Migrazione del carico di lavoro HCX in GCVE</block>
  <block id="4ac5ecc506f53d87d5405d25cca52053" category="list-text"><block ref="4ac5ecc506f53d87d5405d25cca52053" category="inline-link-macro-rx"></block></block>
  <block id="b5375bdf07e11b544fe361d241528cd4" category="list-text">Documentazione di Google Cloud VMware Engine</block>
  <block id="cc7538adb5f65b8e12ceeea77a9fe2b4" category="inline-link"><block ref="cc7538adb5f65b8e12ceeea77a9fe2b4" category="inline-link-rx"></block></block>
  <block id="c403f0f0cd3710f7ff6a40c31193feef" category="paragraph"><block ref="c403f0f0cd3710f7ff6a40c31193feef" category="inline-link-rx"></block></block>
  <block id="19e28367f565bf74c0b929f09ffdeb90" category="list-text">Documentazione Cloud Volume Service</block>
  <block id="87a450a8cc5c8bc3aa98266544b13aeb" category="inline-link"><block ref="87a450a8cc5c8bc3aa98266544b13aeb" category="inline-link-rx"></block></block>
  <block id="bc99ee2635f4933c3a1ae1a2d397722f" category="paragraph"><block ref="bc99ee2635f4933c3a1ae1a2d397722f" category="inline-link-rx"></block></block>
  <block id="92cbc7969081067fa7972b77f8b4c803" category="inline-link"><block ref="92cbc7969081067fa7972b77f8b4c803" category="inline-link-rx"></block></block>
  <block id="dccf3c5043aaab19b4c6eed2cd51be7e" category="paragraph"><block ref="dccf3c5043aaab19b4c6eed2cd51be7e" category="inline-link-rx"></block></block>
  <block id="0b6b52ed7135814c4a167640dee306f2" category="doc">Disponibilità regionale: Datastore NFS supplementare per Google Cloud Platform (GCP)</block>
  <block id="926f20c82f92e797825f3ddf31c8d15b" category="paragraph">La disponibilità di datastore NFS supplementari su GCP / GCVE è definita da Google. Innanzitutto, è necessario determinare se GCVE e CVS sono disponibili in una regione specifica. Quindi, è necessario determinare se il datastore NFS supplementare CVS è supportato in quella regione.</block>
  <block id="0970f21d33cd70a68d82d99f1d6abd42" category="list-text">Verificare la disponibilità di GCVE e CVS <block ref="007e08d33d89c24a1316c16966bb4055" category="inline-link-macro-rx"></block>.</block>
  <block id="52d36923e6e7f21dede2a88e87bd5528" category="list-text">Verificare la disponibilità del datastore NFS supplementare CVS <block ref="007e08d33d89c24a1316c16966bb4055" category="inline-link-macro-rx"></block>.</block>
  <block id="ade1814101b0113034e0f446307b3db3" category="doc">Funzionalità NetApp per Google Cloud Platform GCVE</block>
  <block id="ce2d3ab910808452912b4cae1adc8bd7" category="paragraph">Scopri di più sulle funzionalità offerte da NetApp per Google Cloud Platform (GCP) Google Cloud Virtualization Engine (GCVE), da NetApp come dispositivo di storage connesso agli ospiti o come datastore NFS supplementare alla migrazione dei flussi di lavoro, all'estensione/diffusione nel cloud, al backup/ripristino e al disaster recovery.</block>
  <block id="fdab91853bf925f2256c6d39ec3f5351" category="inline-link-macro">Configurazione di GCVE in GCP</block>
  <block id="370e7d693bc429e40244684cac20b0cf" category="list-text"><block ref="370e7d693bc429e40244684cac20b0cf" category="inline-link-macro-rx"></block></block>
  <block id="6eb516b97eae0ab93b8d6aab35fbb764" category="inline-link-macro">Opzioni di storage NetApp per GCVE</block>
  <block id="b4360d9dcce9e932e3b5b09fdc524745" category="list-text"><block ref="b4360d9dcce9e932e3b5b09fdc524745" category="inline-link-macro-rx"></block></block>
  <block id="80d79003a84a32474624e54935709e67" category="paragraph">Visualizza i dettagli <block ref="996ade122099ed78c4d5fea15d95f62c" category="inline-link-macro-rx"></block>.</block>
  <block id="275ed895f3f409270670131f7369b1ac" category="paragraph">Lo storage NetApp può essere utilizzato in diversi modi, come congettura connessa o come archivio dati NFS supplementare, all'interno di GCP GCVE.</block>
  <block id="80b43a415019d937ea5c38446043549a" category="paragraph">Visualizza i dettagli <block ref="8e20eef09273fc2519292ca4ed666573" category="inline-link-macro-rx"></block>.</block>
  <block id="e67def868f3133574b28ffe738ad44c1" category="inline-link-macro">Esplora le soluzioni NetApp per Google Cloud GCVE</block>
  <block id="5e7670e99ae7db80618f16965d677af6" category="paragraph"><block ref="5e7670e99ae7db80618f16965d677af6" category="inline-link-macro-rx"></block></block>
  <block id="66433e0e715221ebed495642af8005b7" category="doc">NetApp Supplemental NFS Datastore Options per GCP</block>
  <block id="74eb4c6138d4b8cd8399b01966c5af28" category="doc">Opzioni di storage NetApp per GCP</block>
  <block id="7973cdedf3e9a37ff146bc9fd29ff017" category="paragraph">GCP supporta lo storage NetApp connesso come guest con Cloud Volumes ONTAP (CVO) o Cloud Volumes Service (CVS).</block>
  <block id="4177c39712dda5976b0ba657b24af234" category="example-title">Implementare Cloud Volumes ONTAP in Google Cloud (fai da te)</block>
  <block id="2839d8571363b149cc3fd9db82a7183d" category="paragraph">Le condivisioni e le LUN Cloud Volumes ONTAP possono essere montate da macchine virtuali create nell'ambiente di cloud privato GCVE. I volumi possono essere montati anche sul client Linux e sul client Windows, mentre I LUN possono essere utilizzati su client Linux o Windows come dispositivi a blocchi quando montati su iSCSI, perché Cloud Volumes ONTAP supporta i protocolli iSCSI, SMB e NFS. I volumi Cloud Volumes ONTAP possono essere configurati in pochi semplici passaggi.</block>
  <block id="83f1904115d07e05de148ff5c69277db" category="paragraph">Per replicare i volumi da un ambiente on-premise al cloud per scopi di disaster recovery o migrazione, stabilire la connettività di rete a Google Cloud, utilizzando una VPN sito-sito o un'interconnessione cloud. La replica dei dati da on-premise a Cloud Volumes ONTAP non rientra nell'ambito di questo documento. Per replicare i dati tra sistemi on-premise e Cloud Volumes ONTAP, vedere <block ref="17b5522e2d467cfa8e1eed2f77bb1eff" category="inline-link-macro-rx"></block>.</block>
  <block id="52111b7d24cc23248fa9cf8138732943" category="paragraph"><block ref="52111b7d24cc23248fa9cf8138732943" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67b4a468763f61993484edb54b0d5eaa" category="list-text">Nella scheda Cloud Manager Canvas, fare clic su Add a Working Environment (Aggiungi ambiente di lavoro), quindi selezionare Google Cloud Platform come cloud e il tipo di configurazione del sistema. Quindi, fare clic su Next (Avanti).</block>
  <block id="da94c5003e26421e5282adb2dc7794bf" category="paragraph"><block ref="da94c5003e26421e5282adb2dc7794bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="956a76d4c71f02e39d36ada071ba66ca" category="list-text">Fornire i dettagli dell'ambiente da creare, inclusi il nome dell'ambiente e le credenziali di amministratore. Al termine, fare clic su Continue (continua).</block>
  <block id="786bd072b9aad97a5bb9b71b8988a176" category="paragraph"><block ref="786bd072b9aad97a5bb9b71b8988a176" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f716cee2acaef077786ecfa7a3f8bfe7" category="list-text">Seleziona o deseleziona i servizi aggiuntivi per l'implementazione di Cloud Volumes ONTAP, tra cui rilevamento e conformità dei dati o backup nel cloud. Quindi, fare clic su Continue (continua).</block>
  <block id="03e0c2afea8f7c3aff4a53d66784f843" category="paragraph">SUGGERIMENTO: Quando si disattivano i servizi aggiuntivi, viene visualizzato un messaggio a comparsa di verifica. I servizi add-on possono essere aggiunti/rimossi dopo l'implementazione di CVO; se non necessari, è consigliabile deselezionarli dall'inizio per evitare i costi.</block>
  <block id="d784fbb10e1bdb60322e86126fe6b77a" category="paragraph"><block ref="d784fbb10e1bdb60322e86126fe6b77a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faa5bffdcdb67efcb08e91a60de40950" category="list-text">Selezionare una posizione, scegliere un criterio firewall e selezionare la casella di controllo per confermare la connettività di rete allo storage Google Cloud.</block>
  <block id="5eb45a43e8f46d401f435ef2b77fc946" category="paragraph"><block ref="5eb45a43e8f46d401f435ef2b77fc946" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f73472fc9b5e80548aa8910eb7b409d7" category="list-text">Selezionare l'opzione di licenza: Pay-as-you-Go o BYOL per utilizzare la licenza esistente. In questo esempio, viene utilizzata l'opzione Freemium. Quindi, fare clic su Continue (continua).</block>
  <block id="ef8c5ea172d5c008d091f693a2a4b4bd" category="paragraph"><block ref="ef8c5ea172d5c008d091f693a2a4b4bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e3f0304199574fcad7150c8cbc80cf" category="list-text">Scegliere tra diversi pacchetti preconfigurati disponibili in base al tipo di carico di lavoro che verrà implementato sulle macchine virtuali in esecuzione sul cloud VMware su AWS SDDC.</block>
  <block id="1cd93d1b6baa56bdec898225ef3fea89" category="paragraph">SUGGERIMENTO: Passare il mouse sui riquadri per ulteriori dettagli o personalizzare i componenti CVO e la versione di ONTAP facendo clic su Modifica configurazione.</block>
  <block id="7498ab388fb0a7938d43af30f32657b5" category="paragraph"><block ref="7498ab388fb0a7938d43af30f32657b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcf4e1533222260897c2613078eae18e" category="paragraph"><block ref="fcf4e1533222260897c2613078eae18e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37030c826a75013cff1396c6351d33c0" category="paragraph"><block ref="37030c826a75013cff1396c6351d33c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f10b252acc74e058dc00a78e8c33250" category="paragraph">SUGGERIMENTO: Fare clic sull'icona Menu (º), selezionare Advanced (Avanzate) per visualizzare altre opzioni e selezionare CIFS setup (Configurazione CIFS).</block>
  <block id="0cd857f422db3bb835695ca4400e7afb" category="paragraph"><block ref="0cd857f422db3bb835695ca4400e7afb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c2efcf3ec5fbe68c5a418d6b0d5ed94" category="list-text">La creazione del volume SMB è un processo semplice. In Canvas, fare doppio clic sull'ambiente di lavoro Cloud Volumes ONTAP per creare e gestire i volumi e fare clic sull'opzione Crea volume. Scegli le dimensioni appropriate e il cloud manager sceglie l'aggregato contenente o utilizza un meccanismo di allocazione avanzato da collocare su un aggregato specifico. Per questa demo, CIFS/SMB è selezionato come protocollo.</block>
  <block id="597899b3d186b1c50739aeb0a82a2094" category="paragraph"><block ref="597899b3d186b1c50739aeb0a82a2094" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cdd5a747f01838b94117ef6fb699278" category="paragraph">SUGGERIMENTO: Fare clic sul menu del volume (º) per visualizzarne le opzioni.</block>
  <block id="368cd84bdda136cebde14eea38e8a0f2" category="paragraph"><block ref="368cd84bdda136cebde14eea38e8a0f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7a0ccac4888fc1553dadeee03d7e99" category="list-text">Una volta creato il volume, utilizzare il comando mount per visualizzare le istruzioni di connessione del volume, quindi connettersi alla condivisione dalle macchine virtuali su Google Cloud VMware Engine.</block>
  <block id="92890420fd7a7668e3b04db90e8a2ff2" category="paragraph"><block ref="92890420fd7a7668e3b04db90e8a2ff2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5ee926d870d7b6e5ee68e0001a9db42" category="list-text">Copiare il seguente percorso e utilizzare l'opzione Map Network Drive per montare il volume sulla macchina virtuale in esecuzione su Google Cloud VMware Engine.</block>
  <block id="809f33612149b405423b98b77a13d18f" category="paragraph"><block ref="809f33612149b405423b98b77a13d18f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0895b43b6a4f7ded9ce501e420da7cae" category="paragraph">Una volta mappato, è possibile accedervi facilmente e impostare le autorizzazioni NTFS di conseguenza.</block>
  <block id="2565b7a7d81a362c6b3fc5f32d83075b" category="paragraph"><block ref="2565b7a7d81a362c6b3fc5f32d83075b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="262a1d892164ab4100a969a952274934" category="example-title">Collegare il LUN su Cloud Volumes ONTAP a un host</block>
  <block id="049f63d3d6479b8801f942e53b31cfd6" category="paragraph">Per collegare il LUN Cloud Volumes ONTAP a un host, attenersi alla seguente procedura:</block>
  <block id="b5f2af2dc909b8d634ef7e8dd729c0bc" category="paragraph"><block ref="99dce170472373a603dcc6cab1306eea" category="inline-image-macro-rx" type="image"></block>
<block ref="99eed8d2ce50ff339d9bff41a9fe9a51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4296bb5afd2416d05f951e9d3380e5e4" category="list-text">Una volta eseguito il provisioning del volume, selezionare il menu del volume (º), quindi fare clic su Target IQN (IQN di destinazione). Per copiare il nome qualificato iSCSI (IQN), fare clic su Copy (Copia). Impostare una connessione iSCSI dall'host al LUN.</block>
  <block id="5bbe705670fa05ddb0b508acf301a379" category="paragraph">Per ottenere lo stesso risultato per l'host residente su Google Cloud VMware Engine:</block>
  <block id="a730e43d2afac8730f77c3fab06bcdc0" category="list-text">RDP sulla macchina virtuale ospitata su Google Cloud VMware Engine.</block>
  <block id="88c7456aa49f0bfe0258958c4c42a153" category="paragraph"><block ref="88c7456aa49f0bfe0258958c4c42a153" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da663e5eac7f594bcac6564a22726142" category="paragraph"><block ref="da663e5eac7f594bcac6564a22726142" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74edf50412d8a6c920ebdf456ca74d6f" category="paragraph"><block ref="74edf50412d8a6c920ebdf456ca74d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8bce76f68494174fa21e44b39be75e7" category="paragraph">Sui client Linux, assicurarsi che il daemon iSCSI sia in esecuzione. Una volta eseguito il provisioning dei LUN, fare riferimento alla guida dettagliata sulla configurazione iSCSI con Ubuntu come esempio qui. Per verificare, eseguire lsblk cmd dalla shell.</block>
  <block id="5800551032817b82a3780efc5c365b61" category="paragraph"><block ref="5d8610d622621cfaf5f5af9098efada8" category="inline-image-macro-rx" type="image"></block>
<block ref="0e5aea74b7dab4389459e8f03d7961e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a676f5d05c6d1f36341948d03289c3f" category="paragraph">Per montare il file system Cloud Volumes ONTAP (DIY) dalle macchine virtuali all'interno del motore VMware di Google Cloud, attenersi alla seguente procedura:</block>
  <block id="99ff74a348250b7148d219f224bc40b4" category="paragraph">Eseguire il provisioning del volume seguendo la procedura riportata di seguito</block>
  <block id="17d1d28660c0ff68f1ee26c3bc7c2e0d" category="list-text">Nella scheda Volumes (volumi), fare clic su Create New Volume (Crea nuovo volume).</block>
  <block id="6fa266ccf8c1f303a7ed67b355770afb" category="list-text">Nella pagina Create New Volume (Crea nuovo volume), selezionare un tipo di volume:</block>
  <block id="8d7c2959a73ccf424e912497fa729dfa" category="paragraph"><block ref="8d7c2959a73ccf424e912497fa729dfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e89e2106ea79d032d48e99a6498e2584" category="list-text">Nella scheda Volumes (volumi), posizionare il cursore del mouse sul volume, selezionare l'icona del menu (º), quindi fare clic su Mount Command.</block>
  <block id="1367b1db6f5a641c16b673b4f75f02de" category="paragraph"><block ref="1367b1db6f5a641c16b673b4f75f02de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8a4175c7cb7e059193f8bdcafc1395b0" category="list-text">Fare clic su Copia.</block>
  <block id="2432c695bbc97e5283e213ba846e86dc" category="paragraph"><block ref="2432c695bbc97e5283e213ba846e86dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5cbcad6705273d58a27b5b92fdc1700" category="list-text">Montare il volume NFS di Cloud Volumes ONTAP nella directory creata nel passaggio precedente.</block>
  <block id="f505f299a6f5e1e9f6b91adec6ef8f38" category="paragraph"><block ref="4aa22d1032194bb618fa2b2a8bbc5d82" category="inline-image-macro-rx" type="image"></block>
<block ref="73581b61100d82e506cc05faa5fc45c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="622f93ad4ff43627a425523c5e2538ad" category="section-title">Cloud Volumes Service (CVS)</block>
  <block id="b5a9beef520c0dd1f8e978800f35268e" category="paragraph">Cloud Volumes Services (CVS) è un portfolio completo di servizi dati per offrire soluzioni cloud avanzate. Cloud Volumes Services supporta diversi protocolli di accesso ai file per i principali cloud provider (supporto NFS e SMB).</block>
  <block id="82c8cb0896f20daa9ddbb9d49332f9b6" category="paragraph">Altri vantaggi e funzionalità includono: Protezione e ripristino dei dati con Snapshot, funzionalità speciali per replicare, sincronizzare e migrare le destinazioni dei dati on-premise o nel cloud e performance costantemente elevate a livello di un sistema di storage flash dedicato.</block>
  <block id="3c0dd0de38e3c9e55ef5f52e46641376" category="example-title">Configurare Cloud Volumes Service con VMware Engine</block>
  <block id="8e12272d11d90cdb919c737591f398f6" category="paragraph">Le condivisioni Cloud Volumes Service possono essere montate da macchine virtuali create nell'ambiente VMware Engine. I volumi possono anche essere montati sul client Linux e mappati sul client Windows perché Cloud Volumes Service supporta i protocolli SMB e NFS. I volumi Cloud Volumes Service possono essere configurati in semplici passaggi.</block>
  <block id="992031e7435f44536a649bfc9de30683" category="paragraph">Cloud Volume Service e il cloud privato VMware Engine di Google Cloud devono trovarsi nella stessa regione.</block>
  <block id="a0c391dc49c440fc9962168353cedde3" category="inline-link-macro">guida</block>
  <block id="e9676faeb0b33249abc3a47d95e55ed8" category="paragraph">Per acquistare, abilitare e configurare NetApp Cloud Volumes Service per Google Cloud da Google Cloud Marketplace, seguire questa procedura dettagliata <block ref="c9eb1a9870bc9f20357f50bf16ec5704" category="inline-link-macro-rx"></block>.</block>
  <block id="84c877bb77a313d307054a0824ffff03" category="example-title">Creare un volume NFS CVS nel cloud privato GCVE</block>
  <block id="1ec5bbc38708de3f8cfad6d6ca608742" category="paragraph">Per creare e montare volumi NFS, attenersi alla seguente procedura:</block>
  <block id="ca5470246976d59ea6a32d3e2094059d" category="list-text">Accedi a Cloud Volumes da Partner Solutions all'interno della console cloud di Google.</block>
  <block id="45ab48bbbad4380f09ef6b41f9eb8f8a" category="paragraph"><block ref="45ab48bbbad4380f09ef6b41f9eb8f8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46577653160772df2b1548b726d7c9ce" category="list-text">Nella Cloud Volumes Console, accedere alla pagina Volumes (volumi) e fare clic su Create (Crea).</block>
  <block id="4a43547530a8ef079adc80160de3dde9" category="paragraph"><block ref="4a43547530a8ef079adc80160de3dde9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="825700271a3acfeaf96fa0bfb5f15b65" category="list-text">Nella pagina Create file System (Crea file system), specificare il nome del volume e le etichette di fatturazione necessari per i meccanismi di chargeback.</block>
  <block id="8a81559c79124aa1a1cd2093faed73ee" category="paragraph"><block ref="8a81559c79124aa1a1cd2093faed73ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4bbe773302576667095a132b75c48fc" category="list-text">Selezionare il servizio appropriato. Per GCVE, scegliere CVS-Performance e il livello di servizio desiderato per una latenza migliorata e performance più elevate in base ai requisiti del carico di lavoro dell'applicazione.</block>
  <block id="184fe9f42c4d5eaab1cc6079778040c2" category="paragraph"><block ref="184fe9f42c4d5eaab1cc6079778040c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4492d6cb3c36c984d9f52d9461c5b69b" category="list-text">Specificare l'area di Google Cloud per il volume e il percorso del volume (il percorso del volume deve essere unico in tutti i volumi cloud del progetto)</block>
  <block id="594c2b024401023acd7deae8f3cb8ceb" category="paragraph"><block ref="594c2b024401023acd7deae8f3cb8ceb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4b0697a6c38463b0b06d7dc66b16b74" category="list-text">Selezionare il livello di performance per il volume.</block>
  <block id="aebc437f9bb3656c19ecebe1becc99fa" category="paragraph"><block ref="aebc437f9bb3656c19ecebe1becc99fa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dd9c26fe6b5f33ab2b0002050ff831d8" category="list-text">Specificare le dimensioni del volume e il tipo di protocollo. In questo test viene utilizzato NFSv3.</block>
  <block id="e5ba61d9c8c666d452e9e78256762019" category="paragraph"><block ref="e5ba61d9c8c666d452e9e78256762019" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea3a8099bd03f7da2c641e049e354ea1" category="list-text">In questa fase, selezionare la rete VPC da cui sarà possibile accedere al volume. Assicurarsi che il peering VPC sia in posizione.</block>
  <block id="d3dba730ef6d3f046910d94696ca086d" category="paragraph">SUGGERIMENTO: Se il peering VPC non è stato eseguito, viene visualizzato un pulsante a comparsa che guida l'utente attraverso i comandi di peering. Aprire una sessione della shell cloud ed eseguire i comandi appropriati per mettere in relazione il VPC con il produttore Cloud Volumes Service. Nel caso in cui si decida di preparare il peering VPC in anticipo, fare riferimento a queste istruzioni.</block>
  <block id="ecf942f7df1f072f5910afb3fa45f36e" category="paragraph"><block ref="ecf942f7df1f072f5910afb3fa45f36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ed1352ea98f362074fa7855ec6bb89c" category="list-text">Gestire le regole dei criteri di esportazione aggiungendo le regole appropriate e selezionare la casella di controllo per la versione NFS corrispondente.</block>
  <block id="3ae650d16c298e2f5dc9e005a2f8934a" category="paragraph">Nota: L'accesso ai volumi NFS non sarà possibile a meno che non venga aggiunta una policy di esportazione.</block>
  <block id="2f6d29a5c21fb51bb181c4b97241a955" category="paragraph"><block ref="2f6d29a5c21fb51bb181c4b97241a955" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a194552e035de341a4a7c99a1c687956" category="list-text">Fare clic su Save (Salva) per creare il volume.</block>
  <block id="fe18028768c2ffc16d5cb32aa5b70d5b" category="paragraph"><block ref="fe18028768c2ffc16d5cb32aa5b70d5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3588b0992732355d67655af9f6450c5d" category="example-title">Montare le esportazioni NFS sulle macchine virtuali in esecuzione su VMware Engine</block>
  <block id="87397baf86d56e19a3bdac712966da5d" category="paragraph">Prima di prepararsi al montaggio del volume NFS, assicurarsi che lo stato di peering della connessione privata sia indicato come attivo. Una volta che lo stato è attivo, utilizzare il comando mount.</block>
  <block id="c9f09539bbf502703a4f5e2d480a5972" category="paragraph">Per montare un volume NFS, procedere come segue:</block>
  <block id="726f902a0b5536d71345114fb942d81b" category="list-text">Nella Cloud Console, andare a Cloud Volumes &gt; Volumes (volumi cloud &gt; volumi).</block>
  <block id="1feaf778ab1cf141cf92a316d53e1365" category="list-text">Accedere alla pagina Volumes (volumi)</block>
  <block id="76d2df71caae5e1ec3f81822829504f5" category="list-text">Fare clic sul volume NFS per il quale si desidera montare le esportazioni NFS.</block>
  <block id="4fc82f44f951748bf462898e43d08054" category="list-text">Scorrere verso destra, sotto Mostra altri, fare clic su istruzioni di montaggio.</block>
  <block id="692afb2fddb72a6cfc89dd1df12945ab" category="paragraph">Per eseguire il processo di montaggio dal sistema operativo guest della macchina virtuale VMware, attenersi alla procedura riportata di seguito:</block>
  <block id="2c7df76595ada01b5b08659283021aa7" category="list-text">Utilizzare il client SSH e SSH per la macchina virtuale.</block>
  <block id="2b64d099377e2935e786009804205feb" category="list-text">Installare il client nfs sull'istanza.</block>
  <block id="d8aa2b3304fc65e5fd1cae735194aef6" category="list-text">Su Red Hat Enterprise Linux o istanza di SUSE Linux:</block>
  <block id="d610fa6d370a8d35fb4c26359f086aa0" category="list-text">Su un'istanza di Ubuntu o Debian:</block>
  <block id="9bc2e27c16ca55bfc1a7ba94b91a21dc" category="list-text">Creare una nuova directory sull'istanza, ad esempio "/nimCVSNFSol01":</block>
  <block id="9e21b9d85251decc0982b75506826828" category="paragraph"><block ref="9e21b9d85251decc0982b75506826828" category="inline-image-macro-rx" type="image"></block></block>
  <block id="174714918db1cc87ef113e3087cba5da" category="list-text">Montare il volume utilizzando il comando appropriato. Di seguito è riportato un esempio di comando del laboratorio:</block>
  <block id="1ec7767a139a3f95923511d7bf547a6c" category="paragraph"><block ref="811572ed35d4b134bc0d7769dd80ab6c" category="inline-image-macro-rx" type="image"></block>
<block ref="b780e126200cb608d0de968e965e9c71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3df234dd2e63d779a2d017bb1ef3375d" category="example-title">Creazione e montaggio di SMB Share sulle macchine virtuali in esecuzione su VMware Engine</block>
  <block id="400db805dd1f9fc929e5bf72fafb1661" category="paragraph">Per i volumi SMB, assicurarsi che le connessioni Active Directory siano configurate prima di creare il volume SMB.</block>
  <block id="94f9379544859ae4d8990b84731870aa" category="paragraph"><block ref="94f9379544859ae4d8990b84731870aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c62a73033a0e9f64b5b2b311ded0cc5" category="paragraph">Una volta stabilita la connessione ad, creare il volume con il livello di servizio desiderato. I passaggi sono simili alla creazione di un volume NFS, ad eccezione della selezione del protocollo appropriato.</block>
  <block id="228ba1c797822b63cd7c6f54ca40b87e" category="paragraph"><block ref="228ba1c797822b63cd7c6f54ca40b87e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54cd15dd2d6121aa16f0b4b87b46ef2a" category="list-text">Selezionare il servizio appropriato. Per GCVE, scegliere CVS-Performance e il livello di servizio desiderato per una latenza migliorata e performance più elevate in base ai requisiti del carico di lavoro.</block>
  <block id="b8eb8307790a9b22c2f6997c097b344e" category="paragraph"><block ref="b8eb8307790a9b22c2f6997c097b344e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb91d5f8a608e41cd1f217e30a536437" category="paragraph"><block ref="cb91d5f8a608e41cd1f217e30a536437" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e5a0a3c08f102d8c49c1d811b71d97f" category="paragraph"><block ref="7e5a0a3c08f102d8c49c1d811b71d97f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d1a06f98a1c133a8a0c74cc4222e23b" category="list-text">Specificare le dimensioni del volume e il tipo di protocollo. In questo test, viene utilizzato SMB.</block>
  <block id="6eb5a9152f38c77efc6d14902aa7dec8" category="paragraph"><block ref="6eb5a9152f38c77efc6d14902aa7dec8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">istruzioni</block>
  <block id="15adcf662b8b92c623f4256a65f605ed" category="paragraph">SUGGERIMENTO: Se il peering VPC non è stato eseguito, viene visualizzato un pulsante a comparsa che guida l'utente attraverso i comandi di peering. Aprire una sessione della shell cloud ed eseguire i comandi appropriati per mettere in relazione il VPC con il produttore Cloud Volumes Service. Nel caso in cui si decida di preparare il peering VPC in anticipo, fare riferimento a questi <block ref="3b4469537a7b14dcfd28e3d301600ff6" category="inline-link-macro-rx"></block>.</block>
  <block id="7f88d48c3b0283642fe6b1f3f061d0fd" category="paragraph"><block ref="7f88d48c3b0283642fe6b1f3f061d0fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ac40323c41c29fb75f6e19c4c683e47" category="paragraph"><block ref="8ac40323c41c29fb75f6e19c4c683e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4990031dcfbd871d95ce4ae0321e7156" category="paragraph">Per montare il volume SMB, procedere come segue:</block>
  <block id="fd78728be3a82142558c815267b8daa0" category="list-text">Fare clic sul volume SMB per il quale si desidera mappare una condivisione SMB.</block>
  <block id="58dc78a5cd30078188f7c605e636a975" category="paragraph">Per eseguire il processo di montaggio dal sistema operativo guest di Windows della macchina virtuale VMware, attenersi alla seguente procedura:</block>
  <block id="3dcb4e26f80951bdb3beeb0a03a3ba83" category="list-text">Fare clic sul pulsante Start, quindi su computer.</block>
  <block id="202bba1ab43a099f57e49b350eb2ad1a" category="list-text">Fare clic su Map Network Drive (Connetti unità di rete</block>
  <block id="7dea65bdd8e9fbcd8a5b7249c71e1f0b" category="list-text">Nell'elenco Drive (unità), fare clic su una lettera di unità disponibile.</block>
  <block id="695179e494f30a851f80409f824a80f8" category="list-text">Nella casella della cartella, digitare:</block>
  <block id="2653f3365feaf0a8bf80106cba1b9ad8" category="paragraph"><block ref="2653f3365feaf0a8bf80106cba1b9ad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cd95358048d9f5d18cf70f66126e1e7" category="paragraph">Per connettersi ogni volta che si accede al computer, selezionare la casella di controllo Reconnect at sign-in (riconnessione all'accesso).</block>
  <block id="7968f043139de8ff0e5df4451c437426" category="list-text">Fare clic su fine.</block>
  <block id="8902b5e2f0c169ccf7ad8b5c335531e5" category="paragraph"><block ref="8902b5e2f0c169ccf7ad8b5c335531e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9883d049f97d69a9f2326d61585d8fbe" category="paragraph">Come avviene per le applicazioni on-premise, la pianificazione di Google Cloud VMware Engine (GCVE) è fondamentale per un ambiente pronto per la produzione di successo per la creazione di macchine virtuali e la migrazione.</block>
  <block id="f0f52a47448cc3bc6237a09f83ad3e74" category="example-title">Distribuire e configurare GCVE</block>
  <block id="fd558e50adcdcb0d667a4790f70f75a9" category="paragraph">Per configurare un ambiente GCVE su GCP, accedere alla console GCP e al portale VMware Engine.</block>
  <block id="fb33f758c28f8ef8d56e41f74b4c47ab" category="paragraph">Fare clic sul pulsante "New Private Cloud" (nuovo cloud privato) e immettere la configurazione desiderata per il cloud privato GCVE. In "posizione", assicurarsi di implementare il cloud privato nella stessa regione/zona in cui viene implementato CVS/CVO, per garantire le migliori performance e la latenza più bassa.</block>
  <block id="63b31ca49de01854f780d1e1722cd1c1" category="paragraph">Prerequisiti:</block>
  <block id="d79b0ab3cbae1dcd79007a97d26af5b1" category="list-text">Configurare il ruolo IAM di VMware Engine Service Admin</block>
  <block id="72a7f08f840ab91a28a2558393971c47" category="inline-link-macro">Abilitare l'accesso API VMware Engine e la quota del nodo</block>
  <block id="88e3e4c9b1c9efec399f7dda7a0c5887" category="list-text"><block ref="88e3e4c9b1c9efec399f7dda7a0c5887" category="inline-link-macro-rx"></block></block>
  <block id="a88d670b04af96a871dad56001e8f742" category="list-text">Assicurati che la gamma CIDR non si sovrapponga a nessuna delle tue subnet on-premise o cloud. L'intervallo CIDR deve essere /27 o superiore.</block>
  <block id="33d7d6c631c2d2cb3608445ef761fe16" category="paragraph"><block ref="33d7d6c631c2d2cb3608445ef761fe16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65bdc0673006b33d0c876e18a9a98787" category="paragraph">Nota: La creazione di un cloud privato può richiedere da 30 minuti a 2 ore.</block>
  <block id="d77d7a022616e70a9987aa0974241779" category="paragraph">Una volta eseguito il provisioning del cloud privato, configurare l'accesso privato al cloud privato per una connessione con percorso dati a bassa latenza e throughput elevato.</block>
  <block id="256431e41a96deb49bcd86b1ca56393e" category="inline-link-macro">Documentazione GCP</block>
  <block id="e4cf8d7f33a9dafc85be0439cd8fbc4d" category="paragraph">In questo modo, la rete VPC in cui sono in esecuzione le istanze di Cloud Volumes ONTAP sarà in grado di comunicare con il cloud privato GCVE. Per eseguire questa operazione, seguire la <block ref="9cd64b8fb1b43e7f674c1b78b2a86f74" category="inline-link-macro-rx"></block>. Per il servizio volume cloud, stabilire una connessione tra VMware Engine e Cloud Volumes Service eseguendo un peering una tantum tra i progetti host del tenant. Per informazioni dettagliate, seguire questa procedura <block ref="04a9f04edfdd7b0a53da57f015378c5a" category="inline-link-macro-rx"></block>.</block>
  <block id="e6945148d9a888e52db99c5ebce86868" category="paragraph"><block ref="e6945148d9a888e52db99c5ebce86868" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3eb3a1c6330fe124fc0706cbdd91df" category="paragraph">Accedere a vcenter utilizzando CloudOwner@gve.local utente. Per accedere alle credenziali, accedere al portale VMware Engine, andare a risorse e selezionare il cloud privato appropriato. Nella sezione Basic info (informazioni di base), fare clic sul collegamento View (Visualizza) per le informazioni di accesso vCenter (vCenter Server, HCX Manager) o NSX-T (NSX Manager).</block>
  <block id="6f32389268763bedb9e6716b5f0973d0" category="paragraph"><block ref="6f32389268763bedb9e6716b5f0973d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ec2407381a4f65d228483b566b6907f" category="paragraph">In una macchina virtuale Windows, aprire un browser e accedere all'URL del client Web vCenter <block ref="d325f0342d122dda054a3ca8b0c44019" category="inline-link-rx"></block> E utilizzare il nome utente admin come CloudOwner@gve.local e incollare la password copiata. Allo stesso modo, è possibile accedere al gestore NSX-T anche utilizzando l'URL del client Web <block ref="c694eb5be92097a8fdea8cdda0ad5ea5" category="inline-link-rx"></block> e utilizzare il nome utente admin e incollare la password copiata per creare nuovi segmenti o modificare i gateway tier esistenti.</block>
  <block id="3a9cff0eb1abb119c1c264dbfff216f6" category="paragraph">Per la connessione da una rete on-premise al cloud privato VMware Engine, sfrutta la VPN cloud o l'interconnessione cloud per una connettività appropriata e assicurati che le porte richieste siano aperte. Per informazioni dettagliate, seguire questa procedura <block ref="6fe8ac83365e22e24c5c8eb9edc2d548" category="inline-link-macro-rx"></block>.</block>
  <block id="b433f901707e7fd0f6d64371dfca4af9" category="paragraph"><block ref="b433f901707e7fd0f6d64371dfca4af9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="989afab9e0dfcc6d523ddb1d23145834" category="paragraph"><block ref="989afab9e0dfcc6d523ddb1d23145834" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d3d4dd76fc599d6c513fa0434537bc08" category="summary">Serie di blog che discutono delle funzionalità delle soluzioni in tutti i contenuti delle soluzioni NetApp</block>
  <block id="4d46b81ad5db47d845e86c95088ff47a" category="doc">Soluzioni NetApp: Blog</block>
  <block id="a93daa19938c1852de52ce10350307a4" category="paragraph">Panoramica dei blog che evidenziano le funzionalità specifiche di molte delle soluzioni NetApp.</block>
  <block id="bf20a476dd72893f0f21a3d56a601784" category="open-title">Intelligenza artificiale</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">Inglese</block>
  <block id="37ce0afb395b0346118a74c4f05f20a7" category="list-text"><block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block>&amp;F:@facet_soultion_mktg=[ai,Analytics,artificial-intelligence]++[ai blog su NetApp.com]</block>
  <block id="750b570f7c6cacf7b9f43c1c7919ad96" category="inline-link-macro">Blog di ai sul Pub</block>
  <block id="183754618306c7f8d7df04f981d234f0" category="list-text"><block ref="183754618306c7f8d7df04f981d234f0" category="inline-link-macro-rx"></block></block>
  <block id="4549cdf15178a5f0535be7f0f86cdb4d" category="open-title">Database aziendale</block>
  <block id="577322186c067590a18f8891be57e7e4" category="inline-link-macro">Proteggi i carichi di lavoro di SQL Server con NetApp SnapCenter con Amazon FSX per NetApp ONTAP</block>
  <block id="c1b7f59fc598d7a811682707bcd4eb40" category="list-text"><block ref="c1b7f59fc598d7a811682707bcd4eb40" category="inline-link-macro-rx"></block></block>
  <block id="aeb79a141f3c3f603cee05dfa64277aa" category="inline-link-macro">Modernizza il tuo funzionamento del database Oracle nel cloud ibrido con lo storage Amazon FSX</block>
  <block id="a35641294527bf47526671d78d910a7e" category="list-text"><block ref="a35641294527bf47526671d78d910a7e" category="inline-link-macro-rx"></block></block>
  <block id="c4ff33edf6e94fb434fb59e4ad2c286b" category="inline-link-macro">Soluzioni di database per il cloud ibrido con SnapCenter</block>
  <block id="e6c9e9316fee7048645938d93d674056" category="list-text"><block ref="e6c9e9316fee7048645938d93d674056" category="inline-link-macro-rx"></block></block>
  <block id="fc25c016a8fb35a621842044a8d4f2e7" category="inline-link-macro">Automatizza la tua infrastruttura di database Oracle nel cloud ibrido</block>
  <block id="3e78754f8bb90f06073e18a2399d0b7f" category="list-text"><block ref="3e78754f8bb90f06073e18a2399d0b7f" category="inline-link-macro-rx"></block></block>
  <block id="8d7efa937e97b1a8187ff8f122d9732a" category="inline-link-macro">Ottimizza lo storage per le implementazioni VMware basate sul cloud</block>
  <block id="5a6bd3a9e0048284caf2b5f521d90959" category="list-text"><block ref="5a6bd3a9e0048284caf2b5f521d90959" category="inline-link-macro-rx"></block></block>
  <block id="00d07ce14f227693b9dabba2f52b53a5" category="inline-link-macro">Inizia a utilizzare Azure VMware Solution utilizzando le offerte cloud basate su NetApp</block>
  <block id="ac66988ead29ba5f4ed32ec3894527e7" category="list-text"><block ref="ac66988ead29ba5f4ed32ec3894527e7" category="inline-link-macro-rx"></block></block>
  <block id="dc32da64b7845bbbf4827a1513cd8daa" category="inline-link-macro">Configurare il cloud ibrido con FSX per NetApp ONTAP e VMware Cloud su AWS SDDC utilizzando VMware HCX</block>
  <block id="e51f186f2c7dd10d7f4c1196ab269d7c" category="list-text"><block ref="e51f186f2c7dd10d7f4c1196ab269d7c" category="inline-link-macro-rx"></block></block>
  <block id="7c3806f623157e3b19cc1801dd72a85d" category="inline-link-macro">Supporto del datastore NetApp Cloud Volumes Service per il motore VMware di Google Cloud (NetApp)</block>
  <block id="5e25da2b2b250c19fcd7efe36b782cc9" category="list-text"><block ref="5e25da2b2b250c19fcd7efe36b782cc9" category="inline-link-macro-rx"></block></block>
  <block id="c540d1dfacf4a64cc435acb640f4cbd4" category="inline-link-macro">Come utilizzare NetApp CVS come datastore per Google Cloud VMware Engine (Google)</block>
  <block id="4a8385e4a45d508eea692800bf2323d9" category="list-text"><block ref="4a8385e4a45d508eea692800bf2323d9" category="inline-link-macro-rx"></block></block>
  <block id="95e5ff389c2796a171f904ad5b9322f6" category="list-text">NetApp e VMware Cloud Foundation (VCF)</block>
  <block id="81cd1d42ffdb75544144e24cf0f8dc54" category="inline-link-macro">Parte 1: Introduzione</block>
  <block id="837bbffc16dc6e344470df1114a13c87" category="list-text"><block ref="837bbffc16dc6e344470df1114a13c87" category="inline-link-macro-rx"></block></block>
  <block id="0437c596200f9be8466a3200f5cf2438" category="inline-link-macro">Parte 2: Storage principale VCF e ONTAP</block>
  <block id="e361fc9a6477c5857207bca25b3d797f" category="list-text"><block ref="e361fc9a6477c5857207bca25b3d797f" category="inline-link-macro-rx"></block></block>
  <block id="14c9e898417d6b3caceb9c60335c4bb3" category="inline-link-macro">Parte 3: STORAGE VCF ed Element Principal</block>
  <block id="aa37de763ea804c1fb3fe637fb6ee5ef" category="list-text"><block ref="aa37de763ea804c1fb3fe637fb6ee5ef" category="inline-link-macro-rx"></block></block>
  <block id="fbbcbe8b70235742e3e6aa656c7815d9" category="inline-link-macro">Parte 4: Strumenti ONTAP per VMware e storage supplementare</block>
  <block id="de8f12d6d2f85119918d1bbb774d43c8" category="list-text"><block ref="de8f12d6d2f85119918d1bbb774d43c8" category="inline-link-macro-rx"></block></block>
  <block id="74d542ee52cd8400c9b9307ed9a99c12" category="list-text">Casi di utilizzo di Astra DevOps:</block>
  <block id="3da7df001d5e1f907d2527f52c6ccc00" category="inline-link-macro">Integra facilmente la protezione nella pipeline ci/CD di Kubernetes con NetApp Astra Control</block>
  <block id="3f1cbb7eb907b7cb7f46877360d4a588" category="list-text"><block ref="3f1cbb7eb907b7cb7f46877360d4a588" category="inline-link-macro-rx"></block></block>
  <block id="fa4bd1682f261cdd55edf3e8e7dbfef6" category="inline-link-macro">DevOps con NetApp: Utilizza Astra Control per eseguire l'analisi post-mortem e ripristinare l'applicazione</block>
  <block id="1188d1aaa4a5f54ec1dab3da3576377a" category="list-text"><block ref="1188d1aaa4a5f54ec1dab3da3576377a" category="inline-link-macro-rx"></block></block>
  <block id="ce932b248d7f57bcada97c64dd7429a7" category="inline-link-macro">NetApp Astra Control Center: Il semplice pulsante per la gestione dei dati della tua applicazione</block>
  <block id="0d47bfb381dd96470ac538b5a112db04" category="list-text"><block ref="0d47bfb381dd96470ac538b5a112db04" category="inline-link-macro-rx"></block></block>
  <block id="ec7f98a3714557d87968dc6a898f7912" category="inline-link-macro">Utilizzo di VMware Tanzu con ONTAP per accelerare il percorso di Kubernetes</block>
  <block id="32e124b0349f41e06bf1e03f11950665" category="list-text"><block ref="32e124b0349f41e06bf1e03f11950665" category="inline-link-macro-rx"></block></block>
  <block id="5137c3284aa2dc8893ef670919f28a5f" category="list-text">Prima di iniziare l'installazione, trasferire le immagini di Astra Control Center in un registro di immagini. Puoi scegliere di farlo con Docker o Podman; in questo passaggio sono fornite le istruzioni per entrambi.</block>
  <block id="123a55fe7e6f2398763a03f409e2c1de" category="admonition">In alternativa, è possibile creare un account di servizio, assegnare un ruolo di editor del Registro di sistema e/o di visualizzatore del Registro di sistema (a seconda che si richieda l'accesso push/pull) e accedere al Registro di sistema utilizzando il token dell'account di servizio.</block>
  <block id="a917b1e998a1fed8ddebd661c3ff12b3" category="list-text">Creare un file script della shell e incollarne il contenuto seguente.</block>
  <block id="f2f27bc59d06be1e1f58b94160cf9949" category="admonition">Se si utilizza<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> l'utente deve accedere al registro privato, quindi utilizzare un token invece di una password -<block ref="4c3c383f59a35199b206c06cf64ebc7c" prefix=" " category="inline-code"></block>.</block>
  <block id="61dbdb9822ed0d400254915ff02a4ee9" category="admonition">In alternativa, è possibile creare un account di servizio, assegnare un ruolo di editor del Registro di sistema e/o di visualizzatore del Registro di sistema (a seconda che si richieda l'accesso push/pull) e accedere al Registro di sistema utilizzando il token dell'account di servizio.</block>
  <block id="37a5c97f291196f8c672c75798a29beb" category="admonition">Se si utilizza un registro interno di OpenShift con certificati TLS predefiniti dall'operatore di ingresso con un percorso, è comunque necessario seguire la procedura precedente per applicare la patch ai certificati con il nome host del percorso. Per estrarre i certificati dall'operatore di ingresso, è possibile utilizzare il comando<block ref="f3181390f5ac7b194eebf3ad3042d2f7" prefix=" " category="inline-code"></block>.</block>
  <block id="08e6bc541e2517b4105b8ac0ccbfe0f3" category="list-text">Creare un segreto con le credenziali per accedere al registro delle immagini in<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> namespace.</block>
  <block id="1b8283857d1e7c1a4e80a12b3ba66ad9" category="paragraph"><block ref="1b8283857d1e7c1a4e80a12b3ba66ad9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e1e6f0b52690f367570b6c16ddf92d98" category="list-text">Selezionare<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> Affiancare e fare clic su Installa.</block>
  <block id="2540200d51d81caebf749b3eb92aa66f" category="paragraph"><block ref="2540200d51d81caebf749b3eb92aa66f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1c17ca035fc060e6a6c77e025e8f27a1" category="list-text">Nella schermata Install Operator (Installa operatore), accettare tutti i parametri predefiniti e fare clic su Install (Installa).</block>
  <block id="695cc7df9129054b4e4bd425d0094832" category="paragraph"><block ref="695cc7df9129054b4e4bd425d0094832" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79cdad7595deba66ecab4005ebe50206" category="paragraph"><block ref="79cdad7595deba66ecab4005ebe50206" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5fa86531d41ab8ca8bee80ba657a599d" category="list-text">Una volta completata l'installazione dell'operatore, selezionare View Operator (Visualizza operatore).</block>
  <block id="235db056b84e051c45e51c19dc088d7a" category="paragraph"><block ref="235db056b84e051c45e51c19dc088d7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72c52a676e647d2aa400f12fe446f9f1" category="list-text">Quindi, fare clic su Create Instance (Crea istanza) nel riquadro Astra Control Center dell'operatore.</block>
  <block id="54132be89475e52a0550d90f4b162e74" category="paragraph"><block ref="54132be89475e52a0550d90f4b162e74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="500c99ec2ed1582312d17f1ea94ab5d0" category="list-text">Riempire<block ref="9eca463036a902158489237df8eb93bf" prefix=" " category="inline-code"></block> Campi del modulo e fare clic su Create (Crea).</block>
  <block id="097026a522eed2b2c71f07efd97bcf31" category="list-text">Immettere un nome account per Astra Control Center e i dettagli dell'amministratore come nome, cognome e indirizzo e-mail.</block>
  <block id="ad2acc92f46f11a5d2a5ace0c933a44c" category="list-text">In Image Registry (Registro immagini), immettere l'FQDN del registro insieme al nome dell'organizzazione assegnato durante l'invio delle immagini al registro (in questo esempio,<block ref="6bde403d563a0c848b35e178652a7a84" prefix=" " category="inline-code"></block>).</block>
  <block id="3e99f691e1f9756e43f68a0aa28e61e0" category="list-text">Se si utilizza un registro che richiede l'autenticazione, inserire il nome segreto nella sezione Registro immagini.</block>
  <block id="f009662483a899fd0d4b99ff5f1912f3" category="list-text">Configurare le opzioni di scalabilità per i limiti delle risorse di Astra Control Center.</block>
  <block id="a7f329dfec2100f6b17e76aecd655cac" category="paragraph"><block ref="a7f329dfec2100f6b17e76aecd655cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1ad0944f93fe082ef02313cd33db47" category="paragraph"><block ref="ec1ad0944f93fe082ef02313cd33db47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73677e8d319e77c91f647e668e868ecb" category="paragraph">Per ulteriori informazioni, visita il sito Web di OpenShift<block ref="35d5a627a33ce17e4bd125258d59fbc4" category="inline-link-rx"></block>.</block>
  <block id="1268e1be2d69bcbe60fed1b018c4c7be" category="list-text">I sistemi storage NetApp Element coprono casi di utilizzo basati su blocchi (iSCSI) in un ambiente altamente scalabile.</block>
  <block id="0e2719bf8f96a980f38256b7a4060368" category="list-text">Per utilizzare i playbook Ansible per implementare Astra Control Center, è necessario disporre di una macchina Ubuntu/RHEL con Ansible installato. Seguire la procedura descritta<block ref="3c36e2d6ece22f6d90a18a4cf2722cef" category="inline-link-rx"></block> Per Ubuntu e.<block ref="94346839427703f278bfb2bc5962a814" category="inline-link-rx"></block> Per RHEL.</block>
  <block id="6238d4091e12ffa6643c0dc68d72ceab" category="list-text">Creare o ottenere un file kubeconfig con accesso amministratore al cluster OpenShift su cui deve essere installato Astra Control Center.</block>
  <block id="bf98d9390f43e942cd74d874e3bf6d68" category="list-text">Modificare la directory in<block ref="01199d5fee9fe01be523a2944ceef91d" prefix=" " category="inline-code"></block>.</block>
  <block id="4f31682e7040024757006eed6ba0344a" category="list-text">Modificare il file vars/vars.yml e inserire le variabili con le informazioni richieste.</block>
  <block id="f39d61476380fc033f45c2d744596b00" category="list-text">Quindi, caricare i certificati TLS del Registro di sistema delle immagini nei nodi OpenShift. A tale scopo, creare una configurazione nello spazio dei nomi openshift-config utilizzando i certificati TLS e applicarla alla configurazione dell'immagine del cluster per rendere attendibile il certificato.</block>
  <block id="b84034a4ed4e546b39d5bd268ff06eaa" category="sidebar">Guida introduttiva/Best Practice</block>
  <block id="1e6ad53e48d26e8f800d9e60c340e84d" category="sidebar">Novità di VMware vSphere 8</block>
  <block id="b0f878715a3d12827d6fb02b0df1f23c" category="sidebar">NetApp e VMware: Introduzione</block>
  <block id="690359e9e894d87f3144da561090e3f0" category="sidebar">Vantaggi di NetApp ONTAP per gli amministratori di VMware vSphere</block>
  <block id="c0bf5949fe87e1e5caf42e4746cd0080" category="sidebar">Best practice per VMware vSphere con ONTAP</block>
  <block id="082e2767897584434269db14d4ceda54" category="sidebar">Novità della virtualizzazione VMware</block>
  <block id="584132370dee3f2fccd2ca59888bee18" category="sidebar">VMware nel cloud pubblico</block>
  <block id="84145683557fc8692113a2a97c3ec239" category="sidebar">Multi-cloud ibrido NetApp con VMware</block>
  <block id="631ed8aac33a641d62d751c3abd77c57" category="sidebar">NetApp per AWS VMC</block>
  <block id="9f5fbecd7c791f090de17716e147c3a5" category="sidebar">NetApp per Azure AVS</block>
  <block id="b2ab132403a71f074bc776eb29725292" category="sidebar">NetApp per Google Cloud Platform GCVE</block>
  <block id="07a2344d318341cbbdb1983d22dc80f0" category="sidebar">Sicurezza e protezione dei dati</block>
  <block id="10e5369e04057873bcce3de87e2c6187" category="sidebar">VMware Site Recovery Manager (SRM) con NetApp ONTAP 9</block>
  <block id="9f4b95975f14f6481a322f453e05049c" category="sidebar">Strumenti ONTAP per VMware vSphere - sicurezza dei prodotti</block>
  <block id="c4f0254bef611d7217287539f6e00feb" category="sidebar">Automazione VMware vSphere</block>
  <block id="ce006038ddc2a04747fe5a2c9c43b8f5" category="sidebar">Demo ed esercitazioni</block>
  <block id="eccb6fc5c04122d7aef60d899a77089e" category="sidebar">Ulteriori risorse</block>
  <block id="5e4af7ed70d1a211f16d528dcdfc6474" category="sidebar">Soluzioni di desktop virtuale</block>
  <block id="bf647454e36069fd16f1a7a35cf6a865" category="sidebar">Per iniziare</block>
  <block id="365ee461cb4c118a8bc7c388fee3410a" category="sidebar">Proposte di valore</block>
  <block id="46d480fc201dd71bbb912a8bd377a13c" category="sidebar">Soluzioni validate</block>
  <block id="10a64a41f3a83289d75b9eb6ee0c0961" category="sidebar">Versioni validate</block>
  <block id="624e816c7f229d54827ad7bc018eb8da" category="sidebar">Opzioni di storage supportate</block>
  <block id="29656b7894a4e22578d8ffdacb29e484" category="sidebar">Carichi di lavoro on-premise</block>
  <block id="fdf2b7bbfae8a8d27a7457a3a248684e" category="sidebar">Soluzione on-premise</block>
  <block id="7c444e839aacd68c963d533d2f1a2ef1" category="sidebar">Configurare l'ambiente</block>
  <block id="9572c488eb363be83451418a6ff48c7f" category="sidebar">Protezione dei dati con ACC</block>
  <block id="5936437437dba0b49462bb1b4e9dcf6b" category="sidebar">Migrazione dei dati con ACC</block>
  <block id="c115e2b85b46823abe897a674f212329" category="sidebar">Carichi di lavoro del cloud ibrido (componenti a gestione automatica)</block>
  <block id="1ab1e2e36ef5b181341692ea36b79b5d" category="sidebar">Soluzione di cloud ibrido con componenti autogestiti</block>
  <block id="b99e808ac7f025e225519c5d70ae9489" category="sidebar">Carichi di lavoro del cloud ibrido (componenti gestiti dal provider)</block>
  <block id="de8191a0431e18dd95f1a5c6258b7076" category="sidebar">Soluzione di cloud ibrido con componenti gestiti dal provider</block>
  <block id="b43e25cad1f62f3428d20945ecbc7879" category="sidebar">Protezione dei dati con ACS</block>
  <block id="4776eb5da1441e8a2d19f5026a1a536d" category="sidebar">Migrazione dei dati con BlueXP</block>
  <block id="e2ed9dce9d5bb40e79fc6d3008de22ff" category="sidebar">Anthos con NetApp</block>
  <block id="ddffa1813009160db4406c9ef143dd1e" category="sidebar">Integrazioni di storage NetApp</block>
  <block id="c232cfc0ae9806d3ad6d34a51df58229" category="sidebar">Red Hat OpenShift con NetApp</block>
  <block id="1722f248c3b6574ad844b53f30ac236c" category="sidebar">VMware Tanzu con NetApp</block>
  <block id="500ce409f120039287d7670f42ff1821" category="sidebar">DevOps con NetApp</block>
  <block id="a5860a0f10641c9e31f8301d3f3ae548" category="sidebar">Informazioni sulle nostre risorse per container</block>
  <block id="b453397e87e54278a4cd32ac644d5934" category="sidebar">Informazioni sulle nostre soluzioni per partner</block>
  <block id="8cf2142329e586b4350d53a76071db82" category="sidebar">Sito web di anthos</block>
  <block id="ff94fd25dea669a1eb9fc9bad5af5e80" category="sidebar">Sito Web di Red Hat OpenShift</block>
  <block id="c9fc26b21b932419e6f167a5ef97a61a" category="sidebar">Sito Web VMware Tanzu</block>
  <block id="f0b83f1f7d211bfb4e278dafd2d6b4fa" category="sidebar">Apache Spark workload con la soluzione di storage NetApp</block>
  <block id="6bf79bc16e8a34cf5698aabd27cecef1" category="sidebar">Analisi dei dati moderna - Descrizione della soluzione</block>
  <block id="1bd369d8fc8172d625ac41a1815aa09d" category="sidebar">Best Practice per Confluent Kafka</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">NetApp e-Series E5700 e Splunk Enterprise</block>
  <block id="1da3fb2408fde551ca108534afed1987" category="sidebar">NetApp EF600 con Splunk Enterprise</block>
  <block id="3ed3645b4e41749082a0692a758a3132" category="sidebar">Soluzioni di cloud ibrido - casi di utilizzo di Spark e Hadoop</block>
  <block id="89d5e6802ef5a3ae4296f49d4d6bc447" category="sidebar">Risorse aggiuntive</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">Blog: Apache Spark gioca nel NetApp Data Analytics Playground</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">Blog: Utilizza XCP per la migrazione dei dati da un data Lake e HPC a NFS ONTAP</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV: Playlist di Big Data Analytics</block>
  <block id="22169240c9a4c0ab61a4ed13c981c5ef" category="sidebar">Infrastrutture convergenti per carichi di lavoro ai</block>
  <block id="12797522e94d75727dd0a05a4ed9f5ff" category="sidebar">ONTAP ai con NVIDIA</block>
  <block id="8508ab1994a5679882beb6400778e8ba" category="sidebar">EF-Series ai con NVIDIA</block>
  <block id="ec820f861118408d42b077dbf109f374" category="sidebar">IBM Spectrum Scale con lo storage NetApp e-Series</block>
  <block id="b63ada7ec650c01320cddeda05deb779" category="sidebar">Ai Inferencing at the Edge - NetApp con Lenovo ThinkSystem</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">NetApp ONTAP e Lenovo ThinkSystem SR670 per ai</block>
  <block id="e5c3eeefe82172631e21562a8d3672a5" category="sidebar">NetApp AFF A800 e Fujitsu Server PRIMERGY GX2570 M5 per ai</block>
  <block id="2fa3e2a0ff5682666455eed0a7b1b569" category="sidebar">Data Lake e pipeline di dati</block>
  <block id="6ac39037a7efa2708d15c0e0e20fb188" category="sidebar">Data Lake StorageGRID per carichi di lavoro di guida autonoma</block>
  <block id="eeb4980c2a89f07abf1a0b927066b23c" category="sidebar">Spostamento dei dati con e-Series e BeeGFS per l'ai</block>
  <block id="13f985aafb32ac9e387186e5a437f96e" category="sidebar">Cloud ibrido ai con caching dei dati</block>
  <block id="ac82c7a9ef13f3b604553ccfe1a5bd76" category="sidebar">Organizzazione e gestione</block>
  <block id="3cd04d0e6cf45786c9e94148f213b537" category="sidebar">NetApp ai Control Plane per la pipeline ai e l'organizzazione dello spazio di lavoro</block>
  <block id="447e8e0102d91009c125adb678cd7fb5" category="sidebar">Pipeline MLRun con Iguazio</block>
  <block id="d5c1931461d1e204a84a486796df2cca" category="sidebar">Soluzione di orchestrazione NetApp con Run:ai</block>
  <block id="71e6eb0dc5951ca93effe179d000f534" category="sidebar">Analisi del sentimento</block>
  <block id="cfff43e76ea0e95d290a279bdb279a2e" category="sidebar">Click-through Rate Prediction - formazione distribuita in Azure</block>
  <block id="29931fafbbc65eabe1029aee9a3a5a85" category="sidebar">Lane Detection - formazione distribuita in Azure</block>
  <block id="7656ac1f9ee1e1763f07a285578d922a" category="sidebar">Ai conversazionale con NVIDIA Jarvis</block>
  <block id="8f0148532a5b5382ec4f005c8a96a4fa" category="sidebar">Guida autonoma</block>
  <block id="f869ce5572b45e50fe014954c4248d60" category="sidebar">Settore sanitario - Imaging diagnostico</block>
  <block id="951b9c6690c2a4c1228ada2a9980d5a8" category="sidebar">Rilevamento delle frodi tramite carta di credito</block>
  <block id="197d6fccbd337f46908b50e1ac3ece5d" category="sidebar">SuperPOD: Una soluzione NetApp e NVIDIA</block>
  <block id="ed05ff1aa7ef3023c5dc2359de4e2d15" category="sidebar">BeeGFS su NetApp (Guida alla progettazione)</block>
  <block id="b877ddfe299c52df6f7a340fdcaa52eb" category="sidebar">BeeGFS su NetApp (Guida all'implementazione)</block>
  <block id="1edbb6849585c57ecbf402c0706ecf2d" category="sidebar">NVIDIA DGX SuperPOD con NetApp (guida alla progettazione)</block>
  <block id="885f346093197ca6295f5ac1ded93d82" category="sidebar">Oracle 19c in Standalone Restart su AWS FSX/EC2 con NFS/ASM</block>
  <block id="879f2366c198b1fc05740657cacebcc1" category="sidebar">Implementazione e protezione di database Oracle su Azure NetApp Files</block>
  <block id="0a2866cc3e2ba203c7e2e3ebeca395be" category="sidebar">SAP con Oracle su UNIX e NFS con NetApp Clustered Data ONTAP</block>
  <block id="c880b35e02dbb5854452c86028138e2a" category="sidebar">Implementare il database Oracle su NetApp ONTAP</block>
  <block id="e9dcec3e531a3cec5ee733f23baab91d" category="sidebar">Implementazione automatica di Oracle 19c per ONTAP su NFS</block>
  <block id="3e9d3644ee18a66c51ddd16b668eaa5a" category="sidebar">Protezione automatica dei dati Oracle</block>
  <block id="bc113eb23aa0579a5e1d93e97ca13635" category="sidebar">Database Oracle su NetApp EF-Series</block>
  <block id="a71f76c3256e4c206a4841d8eb0fed35" category="sidebar">SQL Server</block>
  <block id="89447eb7454239e11376250fa04a88f7" category="sidebar">SAP con Microsoft SQL Server su Windows con Clustered Data ONTAP</block>
  <block id="7c02456b91ace7501ea6f18d1657dcf7" category="sidebar">Modernizzazione di Microsoft SQL Server</block>
  <block id="5c008a8422e884d74da1d4b50a7ada55" category="sidebar">Guida alle Best Practice per Microsoft SQL Server con NetApp EF-Series</block>
  <block id="81d59bad51a910734812cab3d20641b0" category="sidebar">Soluzioni di database per il cloud ibrido</block>
  <block id="958dc0e3d1fcb4de4e8d506927ac81d3" category="sidebar">Implementazione di database Oracle su Best Practice EC2/FSX</block>
  <block id="760b7d532df381143dc946fd59bf0b62" category="sidebar">SQL Server su Azure NetApp Files</block>
  <block id="5d0dd45a93153403c2446a809dcb5fc3" category="sidebar">SQL Server su AWS EC2 con Amazon FSX per NetApp ONTAP</block>
  <block id="30b22b544972f5adb280ca2975099846" category="sidebar">Soluzioni di database per il cloud ibrido con SnapCenter</block>
  <block id="d5ae477fb23aecff7256445ae91344bc" category="sidebar">Backup e ripristino per Microsoft SQL Server su AWS FSX per ONTAP</block>
  <block id="51b19c4a2c13c8f8a69b0608959bdfca" category="sidebar">Database RAC Oracle 19c su FlexPod DataCenter</block>
  <block id="a54420e6e0f519f841f4280cf2545365" category="sidebar">Database open source</block>
  <block id="7e7efb7e7b278c5ce5253a775d1c8313" category="sidebar">Implementazione automatica di PostgreSQL High Availability e disaster recovery in AWS FSX/EC2</block>
  <block id="55418abe87135e6107123ca2c087964c" category="sidebar">Soluzioni NetApp per VMware nei cloud hyperscaler</block>
  <block id="195b49c0610d30d327f5440759b7b642" category="sidebar">Soluzioni supportate</block>
  <block id="844f1178f4ff7b95030ee50d8917da61" category="sidebar">Supporto regionale per datastore NFS</block>
  <block id="40d267fad784266cb59c36d76573e7c6" category="sidebar">NetApp su AWS (VMC)</block>
  <block id="749354a37dc4552d3c41bbf24ba08598" category="sidebar">Multicloud ibrido NetApp con VMware per VMC</block>
  <block id="e7060d0555f178d672a4197df38e1d39" category="sidebar">Configurare l'ambiente di virtualizzazione</block>
  <block id="00ec4042cd11b865f5a96645c8f6abca" category="sidebar">FSX ONTAP come archivio dati NFS supplementare: Panoramica</block>
  <block id="3ffbc70cc0bdd47bd7c4ed3cfa35be8a" category="sidebar">FSX ONTAP come storage connesso guest</block>
  <block id="045ec2e9b9dff589c32c257549300273" category="sidebar">CVO come Guest Connected Storage</block>
  <block id="ff106355f094608231dc8d7116a273e1" category="sidebar">Soluzioni multicloud ibride per VMC</block>
  <block id="15b1cf33f2d910f9ab5e6fdaeb331bcc" category="sidebar">Supporto regionale per datastore NFS in AWS</block>
  <block id="a64cd881ec955d17faa5e396a891e1e6" category="sidebar">NetApp su Azure (AVS)</block>
  <block id="0ab50f8c17f87a8eecee4603b22f16c8" category="sidebar">Multicloud ibrido NetApp con VMware per AVS</block>
  <block id="015a03470e91621621a76f7a4e3dc56e" category="sidebar">ANF as a Supplemental NFS Datastore: Panoramica</block>
  <block id="5ab938ef85bdfd3c94e8c4c5f1cfa448" category="sidebar">ANF come Guest Connected Storage</block>
  <block id="5ab22899d20e83b71d3c1cbbedea208e" category="sidebar">Soluzioni multicloud ibride per AVS</block>
  <block id="81a6037600add9bb79d72eb49534ff94" category="sidebar">Supporto regionale per datastore NFS in Azure</block>
  <block id="d1b0ccc0fc426266cf228929d5424ce4" category="sidebar">NetApp su Google Cloud Platform (GCVE)</block>
  <block id="9fe80f9f1edda788e503795e34b7eb80" category="sidebar">NetApp Hybrid Multifloud con VMware per GCVE</block>
  <block id="2284540fd2f120164fbe2ca5d318f1f4" category="sidebar">Annuncio supplementare del datastore NFS</block>
  <block id="f0476be9310e3a4606daded5c91d346f" category="sidebar">CVS come Guest Connected Storage</block>
  <block id="92db868215c2d725770eeb14e1e377e1" category="sidebar">CVS as a Supplemental Datastore (blog di NetApp)</block>
  <block id="e809dfa83f36389270c46ad868461471" category="sidebar">Soluzioni multicloud ibride per GCVE</block>
  <block id="d4cc78732ab0fdcd767ab42a015d34e0" category="sidebar">Panoramica sulla sicurezza - NetApp CVS in Google Cloud</block>
  <block id="8625e1de7be14c39b1d14dc03d822497" category="sidebar">Strumenti</block>
  <block id="e5365f39437feb49b24eddfa73253c24" category="sidebar">Calcolatore del TCO di FSX per ONTAP + VMC</block>
  <block id="4856ec39dcc21fb53484ef230701e66b" category="sidebar">FSX per ONTAP + Simulatore VMC</block>
  <block id="67c988a2e4a11132f6866cf0aff95568" category="sidebar">CALCOLATORE DEL TCO ANF + AVS</block>
  <block id="faeff2a13624e3552e026ffcba1c35dc" category="sidebar">ANF + Simulatore AVS</block>
  <block id="46d1e37416bef4df8c1962b95c983bb0" category="sidebar">TOOL PER LA STIMA DEL TCO DI GCVE + CVS</block>
  <block id="2f9ce81cf9e5f73733bacd731daaedbc" category="sidebar">Archivio dati NFS supplementare: Panoramica</block>
  <block id="cd9738c68373595541959c8e55ede29e" category="sidebar">Archivio dati NFS supplementare: Opzioni</block>
  <block id="2408eed8aca98d53134097e8990c8225" category="sidebar">Opzioni di storage connesso guest</block>
  <block id="c252fd6dfe5fa6dc4ba36515512a8070" category="sidebar">Soluzioni per la protezione dei carichi di lavoro</block>
  <block id="d7c05d05b1d6ce69dff2a4eaa1692f17" category="sidebar">Backup e ripristino Veeam in VMware Cloud con AWS FSX per NetApp ONTAP</block>
  <block id="33efddb311b6c85bba97e5349040815f" category="sidebar">Soluzioni per la migrazione dei workload</block>
  <block id="2579e0b6258e495e90e159e678bd55a8" category="sidebar">VMware Cloud su AWS: Nuova regione, storage esterno e opzioni di acquisto</block>
  <block id="5a9500ea180d9aa487f8a027550c1888" category="sidebar">Panoramica supplementare su NFS Datastore</block>
  <block id="f639f9fbf0a0ec97e697dc20f2dec14f" category="sidebar">Opzioni aggiuntive del datastore NFS</block>
  <block id="8ac2da66fa1da7b6cb74292caea13c74" category="sidebar">Disaster recovery (DRO) con Azure NetApp Files e AVS</block>
  <block id="5cc354638211ca59bc561a960afa71f9" category="sidebar">Archivio dati NFS supplementare - Anteprima pubblica (Microsoft)</block>
  <block id="d99ca343caa90da336986677343c31fa" category="sidebar">Opzioni aggiuntive del datastore NFS (blog NetApp)</block>
  <block id="16844b6a71b4ccf3790079518b5286c4" category="sidebar">Migrazione dei carichi di lavoro nel datastore NetApp Cloud Volume Service NFS con VMware HCX</block>
  <block id="f74a2791289e2f0411e5ffbd3e5a1d68" category="sidebar">Motore VMware per il cloud Google con NetApp Cloud Volumes Service</block>
  <block id="06e1970c26d133efed67d51224ceff1c" category="sidebar">Panoramica sulla sicurezza - NetApp Cloud Volumes Service (CVS) in Google Cloud</block>
  <block id="cf04feec36847ba9c9671b28661cd1fc" category="sidebar">Documentazione sulle soluzioni NetApp</block>
  <block id="6fb2815b4c371ee082a84cc14539d4cb" category="sidebar">Applicazioni aziendali</block>
  <block id="934553b3e6b7dd417ef37d2b3213dd00" category="sidebar">SAP E SAP HANA</block>
  <block id="38d9ffc674675d65fbb8aabd7e47acd3" category="sidebar">Soluzioni FlexPod</block>
  <block id="6f4bb0fa6fee4cf4ae1b8b1fc16e17cb" category="sidebar">Soluzioni NetApp HCI legacy</block>
  <block id="3523ec156cfc8217bb64d1273e5663fa" category="sidebar">Informazioni sulle soluzioni NetApp</block>
  <block id="d648f2a68a54fd1b3329efc3cf24d29c" category="sidebar">Note legali</block>
  <block id="1f036821b23def9a55e4116bdbd60c1b" category="sidebar">Cronologia delle modifiche</block>
  <block id="bb5dc731b06d417365e41cb2d0230213" category="sidebar">Video e demo</block>
  <block id="f9cffb4fda587c713c06e50699299f0f" category="sidebar">Pagine di destinazione della soluzione</block>
  <block id="bf8e2974cd692b57a29e42874b662b52" category="sidebar">Database aziendali</block>
  <block id="538d26f438b9f54f2e02fe3eff3093f8" category="sidebar">Multicloud ibrido NetApp con VMware</block>
  <block id="d8db237e75bdba6ccaea8d2944877403" category="sidebar">Multicloud ibrido NetApp con Red Hat</block>
  <block id="e340bc103d02ce2b8e016eb60705029c" category="sidebar">SAP E SAP HANA</block>
  <block id="0333ddced253ee1c6929eda5612dea92" category="sidebar">Automazione della richiesta</block>
  <block id="bdca592f24222e5064192bb9e2f9af6e" category="sidebar">FlexPod - Una soluzione NetApp e Cisco</block>
  <block id="0da8a1ebf94a3a1e650dbfbd01c69dd9" category="sidebar">Contenuti tecnici per le soluzioni FlexPod</block>
  <block id="32591d046a055939af0d128133dc8606" category="sidebar">Pagina di vendita FlexPod</block>
  <block id="9e2c62f406d88ad1ee253efd74f593df" category="sidebar">Proporre una nuova soluzione</block>
  <block id="7fd861566be88364067d817b54a44688" category="sidebar">Fornire un feedback sulla soluzione</block>
  <block id="68dfe5056c735db544868f482f9f1d6f" category="sidebar">Linee guida sulle Best practice per NetApp XCP</block>
  <block id="c5071cdf8081474104ef1eee5ec6d784" category="sidebar">Migrazione dei dati CIFS con ACL da uno storage box di origine a ONTAP</block>
  <block id="712d83d9ce8f26363e9bfd1cba104b88" category="sidebar">NetApp e-Series e CommVault Data Platform V11</block>
  <block id="aa8156dc9f7aa240e4f412f2f5fedaf5" category="sidebar">Architettura di riferimento e Best practice per lo storage e-Series ed EF-Series con Veeeam Backup &amp; Replication 9.5</block>
  <block id="74e4bedcc2ff5b37a8770caa0ef72975" category="sidebar">Implementazione di Veritas NetBackup con lo storage NetApp e-Series</block>
  <block id="029f60716c50acd9acf9ce4a9394c91a" category="sidebar">Controlli di sicurezza NIST per FISMA con HyTrust per l'infrastruttura multi-tenant</block>
  <block id="2a643eb4634917213492cef085506d45" category="sidebar">Inizia a utilizzare NetApp e VMware</block>
  <block id="6c30682e8603121e14abe8bab7bd88f3" category="sidebar">Virtualizzazione VMware per ONTAP</block>
  <block id="cadc483b04d069f993431e3ac64341bf" category="sidebar">Gestione basata su policy di storage e volumi virtuali</block>
  <block id="1918f1bc0ea91d0e5d8e37878d5ab562" category="sidebar">VMware Site Recovery Manager con NetApp ONTAP 9</block>
  <block id="2668a3fec665f31a26e9e428b4ee62a7" category="sidebar">Plug-in SnapCenter VMware vSphere - sicurezza del prodotto</block>
  <block id="86fbb5b9292be9b680987addfa410586" category="sidebar">Provisioning tradizionale dello storage a blocchi</block>
  <block id="805a0828a65bce146a58e3556113b017" category="sidebar">VMFS - Fibre Channel</block>
  <block id="26e113624e0cc32cbe2a26e1cde1da24" category="sidebar">VMFS - Fibre Channel over Ethernet</block>
  <block id="8237af9088e8905784b1cb373e3a080d" category="sidebar">VMFS - iSCSI</block>
  <block id="94cab344ef7124917167bd5415b137cf" category="sidebar">VMFS - NVMe su fabric</block>
  <block id="348ee034e8868e5211a6501c09d4b0f0" category="sidebar">Provisioning di file storage tradizionale</block>
  <block id="614b997c0fb5abcd68fda0ab9ca05d69" category="sidebar">NFS - v3</block>
  <block id="912655e9dd57ab01b86691021957e61e" category="sidebar">NFS - v4.1</block>
  <block id="ef55a9d1028eac237813e753d20134df" category="sidebar">VMware per il cloud pubblico</block>
  <block id="75fcfea0185575f935a7f5f149efd8ca" category="sidebar">Casi di utilizzo di VMware Hybrid Cloud</block>
  <block id="e251010eb0cac5793d760ab2e5f51473" category="sidebar">Panoramica del caso d'utilizzo</block>
  <block id="f27edcc7a209983dc37cbcdb0df49ce7" category="sidebar">Desktop virtuali</block>
  <block id="a87e5ca19422686ef96f1e6799e9111d" category="sidebar">Virtual Desktop Services (VDS)</block>
  <block id="b89c617ff394cc85df3935994baa194b" category="sidebar">Test di carico del server singolo con Login VSI</block>
  <block id="6abbceca4793ffe4b329045f63b4d219" category="sidebar">Gestione delle operazioni</block>
  <block id="1b31ca8ddb749644af37aa10b42e6930" category="sidebar">Considerazioni sulla GPU</block>
  <block id="a1da2a2d050a6b61256020afd015a056" category="sidebar">Soluzioni per il settore</block>
  <block id="4725a75839c620bb95363c5f7f2ee9bc" category="sidebar">VMware Horizon</block>
  <block id="e2a1b52ebd707739003f77464bbcaa80" category="sidebar">Soluzioni di virtualizzazione desktop FlexPod</block>
  <block id="9d0be07780aeb437025d4b3420d12540" category="sidebar">Migrazione dei dati NetApp XCP</block>
  <block id="bcea83da6f4b543efcfb552bffdd3b9c" category="sidebar">Multicloud ibrido NetApp con Red Hat OpenShift</block>
  <block id="0fca8d17afc46bb08bd2d70a26cdf886" category="sidebar">On-premise</block>
  <block id="2a39f365b05b58e7a535b6b047620174" category="sidebar">Configurare i carichi di lavoro dei container Red Hat OpenShift su VMware</block>
  <block id="609cb9f7998ec5bb4269ca1df422d4aa" category="sidebar">Proteggere i carichi di lavoro dei container su VMware</block>
  <block id="ec18322cbcfcc1ee3cdbe8a12013b96e" category="sidebar">Migrare i carichi di lavoro dei container su VMware</block>
  <block id="b6d78ec151619bb9a9331436f7debd97" category="sidebar">Cloud ibrido con componenti a gestione automatica</block>
  <block id="2a9707187bf8d0351412172cebd38919" category="sidebar">Configura i carichi di lavoro dei container Red Hat OpenShift su AWS</block>
  <block id="46d9362234fd1fb8fdbf3aff5d62f108" category="sidebar">Proteggere i carichi di lavoro dei container su AWS</block>
  <block id="bd0cd83be209951ff7339cce298b2e3d" category="sidebar">Migrare i carichi di lavoro dei container su AWS</block>
  <block id="effcc9c0e3cea8d66e69bb552e757275" category="sidebar">Cloud ibrido con componenti gestiti dal provider</block>
  <block id="b432f68713f4ab09d27d581993480c2d" category="sidebar">Migrare i carichi di lavoro dei container su AWS</block>
  <block id="645198fb2e03205a7f761aeaff8ef26f" category="sidebar">Introduzione all'automazione delle soluzioni NetApp e ad Ansible</block>
  <block id="44db359cccfc9a14e67b800f405a2078" category="sidebar">Configurare l'ambiente di automazione</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">Automazione della richiesta</block>
  <block id="82ebdc178ed6bd9adb7b66c2edfb70d0" category="sidebar">Panoramica dei sistemi storage NetApp</block>
  <block id="aef2d8db139dd41c9ae6c878ab92ae75" category="sidebar">Panoramica delle integrazioni di storage NetApp</block>
  <block id="b066abadb76f5e6776aa1e7cfdf56b38" category="sidebar">Panoramica di NetApp Astra Trident</block>
  <block id="1a4f47ee7c7d8b59e68be952ac121268" category="sidebar">Opzioni di configurazione avanzate per anthos</block>
  <block id="e131204502a58630f2f72937238604c8" category="sidebar">Video / Demo</block>
  <block id="5f6fc3deb668cb75e9e6c8932620df6a" category="sidebar">Panoramica di NetApp Astra Control Center</block>
  <block id="59b5f97219239806c778ffff9bda8ad0" category="sidebar">Convalide dei casi d'utilizzo</block>
  <block id="cdc53c90644739ab9cb455ad8b663d7b" category="sidebar">Panoramica di Red Hat OpenShift</block>
  <block id="846665f4ec19bffa9d9a8c3937c2f9fd" category="sidebar">Registra i tuoi Red Hat OpenShift Clusters</block>
  <block id="b1dbcb80c89b000949ef64c6d6d6c42b" category="sidebar">Scegliere le applicazioni da proteggere</block>
  <block id="2913361a2ab3fddb4242f1761d4a6e38" category="sidebar">Proteggi le tue applicazioni</block>
  <block id="938033783443233af5517c828deb6d1e" category="sidebar">Opzioni di configurazione avanzate per OpenShift</block>
  <block id="f99e4eb05e28c150680cb72ca8410d93" category="sidebar">Configura la multi-tenancy su Red Hat OpenShift con NetApp ONTAP</block>
  <block id="51a25aff8c490f11d9be543c7af23a0d" category="sidebar">Attività dell'amministratore del cluster</block>
  <block id="244e9cd91466ef1240c125511568880a" category="sidebar">Attività dell'amministratore dello storage</block>
  <block id="bc967dc2d57e6eff184a821bf7577a80" category="sidebar">Scalabilità</block>
  <block id="d6bf2b10101446c7afd28ff94926fc44" category="sidebar">Implementazione tramite operatore</block>
  <block id="e6b088db24ebe67ed0e9567d309387ec" category="sidebar">Flussi di lavoro</block>
  <block id="88c506562ebadd679bb16d76a4558619" category="sidebar">Clonazione di macchine virtuali</block>
  <block id="d313887d8fa4b2493a50d1e00bad440e" category="sidebar">Gestione del ciclo di vita delle applicazioni</block>
  <block id="03cae7751c31cc76a90cf5e94e86eb3a" category="sidebar">Governance e rischi</block>
  <block id="f55899cffbf639043209795d5a1af970" category="sidebar">Creazione di risorse</block>
  <block id="8a22a6c667b205ca4e784c0364ccc5ea" category="sidebar">Panoramica di VMware TKG (Tanzu Kubernetes Grid)</block>
  <block id="e5103defcbafcf380570238b4848f4a1" category="sidebar">Panoramica di VMware TKGS (Tanzu Kubernetes Grid Service)</block>
  <block id="a2ec151aed88d77a34df663b329daf31" category="sidebar">Panoramica di VMware TKGI (Tanzu Kubernetes Grid Integrated Edition)</block>
  <block id="e47703dd1fad3279269dda3b343b2272" category="sidebar">Registra i tuoi Clusters Tanzu Kubernetes</block>
  <block id="b0ed101b405f642695988c7ef3313b52" category="sidebar">Soluzioni archiviate</block>
  <block id="1d2114df6a9f8f5d7e8f597e9c70a6c1" category="sidebar">Gestione dei dati nel cloud con la dualità di file-object NetApp e AWS SageMaker</block>
  <block id="7d576967253ca2f566f9693183407367" category="sidebar">Carichi di lavoro Apache Kafka con storage NetApp NFS</block>
  <block id="a5428e6b4b42638886ab5870a883efb9" category="sidebar">Soluzione NetApp per problemi di ridenominazione sciocco nel carico di lavoro NFS-Kafka</block>
  <block id="0d7c7eeec9388fceaff3d06e03b45fe9" category="sidebar">Panoramica delle performance e validazione con AFF on-premise</block>
  <block id="b98ea9630b58bea0f022799ecefe4062" category="sidebar">Confluenza di Kafka con i controller di storage NetApp ONTAP</block>
  <block id="2ce0710320aace7b17c3af20eaac2918" category="sidebar">Riepilogo dei casi d'utilizzo</block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">Analisi dei big data dati per l'intelligenza artificiale</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">DA GPF a NFS - passaggi dettagliati</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">Best practice per Confluent Kafka</block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">Confluente cluster di auto-ribilanciamento</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">Soluzioni dati di cloud ibrido NetApp: Spark e Hadoop in base ai casi di utilizzo dei clienti</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">Caso d'utilizzo 1: Backup dei dati Hadoop</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">Caso d'utilizzo 2: Backup e disaster recovery dal cloud all'on-premise</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">Caso d'utilizzo 3 - abilitazione di DevTest sui dati Hadoop esistenti</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">Caso d'utilizzo 4: Protezione dei dati e connettività multicloud</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">Caso d'utilizzo 5 - accelerare i carichi di lavoro di analisi</block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">Soluzioni diverse per strategie di analisi diverse - Descrizione della soluzione</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">NetApp StorageGRID con Splunk SmartStore</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">Apache Spark workload with NetApp Storage Solution (Guida all'implementazione)</block>
  <block id="9a9891facf2fa1c878c0fc18c6638005" category="sidebar">Infrastrutture convergenti ai</block>
  <block id="f0cbafc85a7a8d2836dd3a3d51266f61" category="sidebar">Training sui modelli NetApp AFF A400 con Lenovo ThinkSystem SR670 V2 per ai e ML</block>
  <block id="687350c847aefbf978e16be26609d101" category="sidebar">Guida alla progettazione dei sistemi ONTAP ai con NVIDIA DGX A100</block>
  <block id="4c7a8c5b878fcdf733694f638b393b6b" category="sidebar">Guida all'implementazione dei sistemi ONTAP ai con NVIDIA DGX A100</block>
  <block id="74c684b866e5fcffcc9c5165a491d5b2" category="sidebar">Guida alla progettazione di sistemi ONTAP ai con NVIDIA DGX A100 e switch Ethernet Mellanox Spectrum</block>
  <block id="f8363659ae3ab117a0afa4163ca69fc7" category="sidebar">Guida all'implementazione di ONTAP ai con sistemi NVIDIA DGX A100 e switch Ethernet Mellanox Spectrum</block>
  <block id="c70e778edabe427cd2db90132a56e456" category="sidebar">EF-Series ai con sistemi NVIDIA DGX A100 e design BeeGFS</block>
  <block id="06aa576b3e3e95c5df800228d146af65" category="sidebar">EF-Series ai con sistemi NVIDIA DGX A100 e implementazione BeeGFS</block>
  <block id="9cb9fe27a24f987a1889d5fc1d5d139e" category="sidebar">Guida all'implementazione di BeeGFS con NetApp e-Series</block>
  <block id="2967ab4748573d0cb6f2c4084c4fd70f" category="sidebar">BeeGFS con architettura di riferimento NetApp e-Series</block>
  <block id="1db760587a86f5c1b9ab39aa8cf8cf3d" category="sidebar">Implementazione di IBM Spectrum Scale con lo storage NetApp e-Series</block>
  <block id="e648dd2d4df65a903e9c1204d81abaed" category="sidebar">NetApp AFF A800 e Fujitsu Server PRIMERGY GX2570 M5 per i carichi di lavoro di training modello ai e ML</block>
  <block id="6a571fb799acb43b64f874729f838e2a" category="sidebar">Pipeline di dati, data Lake e gestione</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">Data Lake NetApp StorageGRID per carichi di lavoro di guida autonoma</block>
  <block id="fad62e8b886e655813cc4ce635152f62" category="sidebar">Implementazione di Trident</block>
  <block id="8ad188089680179dea816084001d7bf0" category="sidebar">Spostamento dei dati con e-Series e BeeGFS per flussi di lavoro ai e Analytics</block>
  <block id="c94ba9961c97321b49a2f0af40a3c81b" category="sidebar">Ai responsabile e deduzione riservata - NetApp ai con Protopia Image Transformation</block>
  <block id="ae270ffdc87820776fadfe121aa13143" category="sidebar">Analisi del sentimento con NetApp ai</block>
  <block id="f74720767a0bf20cfdb6bba5f215d795" category="sidebar">Implementazione dell'analisi del sentimento del centro di supporto</block>
  <block id="1863627f5be51826024a24014fce26ff" category="sidebar">Formazione distribuita in Azure - previsione dei tassi click-through</block>
  <block id="7f39827ac712fa5b76b27ff0b267373c" category="sidebar">Creazione di versioni di set di dati e modelli con NetApp DataOps Toolkit</block>
  <block id="458df51beb3b33cfa61bdc8725403f5b" category="sidebar">Notebook Jupyter per riferimento</block>
  <block id="70be05b3500f28affc2d048f81c4f7ab" category="sidebar">Formazione distribuita su Azure - rilevamento di corsia</block>
  <block id="7767872606b9c99eb656c9568c1fdd83" category="sidebar">Lane Detection – formazione distribuita con RUN ai</block>
  <block id="ce3b746194cb1fb7d96dfe14187115e0" category="sidebar">Sistema operativo ai per il cloud ibrido con caching dei dati</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">Spostamento dei dati da un ambiente di big data a un ambiente ai</block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">Ai Inferencing at the Edge - NetApp con Lenovo ThinkSystem - progettazione di soluzioni</block>
  <block id="f1e7c981dec3bcee348bda96c55363c4" category="sidebar">Ai conversazionale con NVIDIA</block>
  <block id="c0a0f5bbb431dea70000d73b29e50249" category="sidebar">Utilizzo ottimale di cluster e GPU con Run ai</block>
  <block id="09c995632f33d1ee4a581eb951793f35" category="sidebar">Eseguire l'installazione ai</block>
  <block id="5c9e37e6d7e6f5e3a76854d8343d626b" category="sidebar">Esegui dashboard e viste ai</block>
  <block id="29ebede332931243e314d8a3f333c1a7" category="sidebar">Invio di job in Run ai CLI</block>
  <block id="2943702718c42a5063e0c70598cebdc6" category="sidebar">NetApp ONTAP ai per la progettazione di soluzioni per carichi di lavoro autonomi</block>
  <block id="d11813566a7c636e892d384601baf2c3" category="sidebar">Architettura di riferimento ai di NetApp ONTAP per il settore sanitario: Imaging diagnostico</block>
  <block id="ab8526a90cc9cc979ddd23c87fff57bd" category="sidebar">Architettura di riferimento ai di NetApp ONTAP per i carichi di lavoro dei servizi finanziari</block>
  <block id="6efd886c994d37b6577e22359be2310e" category="sidebar">Implementazione ai con NetApp e-Series e BeeGFS</block>
  <block id="3863e8a73e226ce0c0a6ad02b90ee75b" category="sidebar">Guida alla progettazione dei sistemi Quantum StorNext con NetApp e-Series</block>
  <block id="7891972f4586e6ee183ea541991ebe9f" category="sidebar">Quantum StorNext con NetApp e-Series Systems Deployment Guide</block>
  <block id="d36111f9de8e485ef98facff50b6fd6e" category="sidebar">Implementazione e protezione di database Oracle con iSCSI/ASM</block>
  <block id="d842058c0e8814799a596324a98e5323" category="sidebar">Implementazione di database Oracle su AWS EC2 e Best Practice FSX</block>
  <block id="71ab9d8f34c9ab92ef83627b823e9825" category="sidebar">Gestione del database</block>
  <block id="c3b88d5ff29715f5f8dd3c907b3f1bc3" category="sidebar">Migrazione del database</block>
  <block id="fc305603a3cb90ea71cabdf327aaf437" category="sidebar">Protezione del database</block>
  <block id="14c4dbb7c61081eee1c499c4cf138c96" category="sidebar">Database Oracle 19c RAC su FlexPod DataCenter con Cisco UCS e NetApp AFF A800 su FC</block>
  <block id="54d2cdd3035ca1cdff5803c30f2ed2e1" category="sidebar">Implementazione di Oracle Database</block>
  <block id="699700175d80778f1738d906ee9540d5" category="sidebar">Introduzione e requisiti</block>
  <block id="210fdbe41d80b2e8690a970de86a7ffb" category="sidebar">Implementazione automatizzata di Oracle 19c AWX/Tower</block>
  <block id="13cf6478a61a7904a3062d587248fb75" category="sidebar">Implementazione automatica di Oracle 19c CLI</block>
  <block id="12367669ba6a0b6e059b69b5a95f2902" category="sidebar">Oracle Database Data Protection</block>
  <block id="82be90bcfc8fd03855e030edaa25583a" category="sidebar">Oracle Data Protection automatica per AWX/Tower</block>
  <block id="78898e52fcbdc5337204a384f2456d4f" category="sidebar">Microsoft SQL Server</block>
  <block id="61def2ac347af2f10fd60cd67052a311" category="sidebar">Progettazione di riferimento (progettazione di alto livello in tempo reale)</block>
  <block id="1ae3eccde141a365ede8f18b188ae588" category="sidebar">Implementazione automatica di PostgreSQL ha e DR in AWS FSX/EC2</block>
  <block id="6fabfc29f0b3a196c8407c190bb67293" category="sidebar">SnapCenter per database</block>
  <block id="59f8ae0d5c4ba13dee4828e2727c8859" category="sidebar">Introduzione on-premise</block>
  <block id="27c378e12a7c59dc5aa13b13cc6cecff" category="sidebar">VMware Cloud su cloud hyperscaler</block>
  <block id="e673b6ab6c5649a4df8e874aaa9017b9" category="sidebar">Configurazioni supportate</block>
  <block id="d4a3e435684aa9918c9dd0bada78d4fb" category="sidebar">Configurare VMC per AWS</block>
  <block id="883512106f2cef4187ee5f6b5a94c6f8" category="sidebar">Configurare AVS per Azure</block>
  <block id="a271625e92b27bca4202ba79dab27301" category="sidebar">Configurare GCVE per GCP</block>
  <block id="452b0b090c1c37a0d467a8df764fd81f" category="sidebar">Storage NetApp nei cloud hyperscaler</block>
  <block id="74fed8860f1d0399cb4c6a16b2510cd1" category="sidebar">Datastore NFS supplementare per VMC</block>
  <block id="76862b378878c90a8052499ae898932f" category="sidebar">Storage guest connesso per VMC</block>
  <block id="95fd29d87d2c7d3100a5198bc7067e95" category="sidebar">Archivio dati NFS supplementare per AVS</block>
  <block id="5703f41cd5551fad387ed46631532278" category="sidebar">Storage guest connesso per AVS</block>
  <block id="1f9511a418cf9a352bacd19d937a5237" category="sidebar">Storage connesso guest per GCVE</block>
  <block id="2190ab0d2f6281b2f3a73e0fc8e1f560" category="sidebar">Riepilogo e conclusione</block>
  <block id="a0e8297bc18713002f47301829625ea1" category="sidebar">NetApp per AWS/VMC</block>
  <block id="b8aef6e50d3ed85ad8f7568c45050629" category="sidebar">Protezione dei carichi di lavoro</block>
  <block id="a20d2f7d44a6fc788ac6dbb4daa7fd01" category="sidebar">Backup e ripristino Veeam in VMware Cloud, con AWS FSX per NetApp ONTAP</block>
  <block id="e946411f5b47d53428345ae0e0e5f5fd" category="sidebar">Migrazione dei carichi di lavoro</block>
  <block id="dd5244d49dea74bb9effd68426155ca2" category="sidebar">Migrazione dei carichi di lavoro a FSX per datastore ONTAP con VMware HCX</block>
  <block id="d530fb3a1e80511b2d7787728700d3fa" category="sidebar">NetApp per Azure/AVS</block>
  <block id="93d153de96abb104b1cf0b56dddc7dfc" category="sidebar">Migrazione dei carichi di lavoro nel datastore ANF con VMware HCX</block>
  <block id="8d9d90a84ad6b34129f140e0b3e23326" category="sidebar">NetApp per GCP/GCVE</block>
  <block id="e9063f3c3631446cbaeef19e7965f491" category="sidebar">Disaster recovery applicativo con replica SnapCenter, CVO e Veeam</block>
  <block id="204c2f72244c7b6bb96fa507fcbfdde0" category="sidebar">Migrazione dei carichi di lavoro al datastore NFS Cloud Volume Service con VMware HCX</block>
  <block id="ebd8431a0b14e9588377860f5d21d80b" category="sidebar">Panoramica dell'architettura</block>
  <block id="a20fe2a1eb3b2546487a96f1e639d4f3" category="sidebar">Altre dipendenze del servizio infrastruttura NAS (KDC, LDAP, DNS)</block>
  <block id="87e6f97c8ec2f31df616ef84401ffaf4" category="paragraph">Sono disponibili diverse risorse per la risoluzione dei problemi con ulteriori informazioni.</block>
  <block id="9d2169c1c2855b78a7aeaa4f42d27dc7" category="section-title">Sito di supporto NetApp</block>
  <block id="890eb741924c425abbb11e4618560181" category="paragraph">Oltre a una serie di articoli della Knowledge base per i prodotti di virtualizzazione NetApp, il sito del supporto NetApp offre anche una comoda landing page per<block ref="6e90053136fd326e5d581844ca21966d" category="inline-link-rx"></block> prodotto. Questo portale fornisce link ad articoli, download, report tecnici e discussioni sulle soluzioni VMware sulla community NetApp. È disponibile all'indirizzo:</block>
  <block id="fff460b039580a1bd42725a397b4c8be" category="inline-link">_Sito di supporto NetApp_</block>
  <block id="897515b5a8a03f8d5cbed44fd47ef9f3" category="paragraph"><block ref="897515b5a8a03f8d5cbed44fd47ef9f3" category="inline-link-rx"></block></block>
  <block id="4020fd07f5ee2361dd23956e6a334ffd" category="paragraph">La documentazione aggiuntiva sulla soluzione è disponibile qui:</block>
  <block id="503a41e1e31e362793f7e86af9102c41" category="inline-link">_Soluzioni NetApp per la virtualizzazione_</block>
  <block id="33d455bce1363bad4500664eb6208860" category="paragraph"><block ref="33d455bce1363bad4500664eb6208860" category="inline-link-rx"></block></block>
  <block id="baf17f6d2396be5fd3676baf863a331f" category="section-title">Risoluzione dei problemi del prodotto</block>
  <block id="9d6d7fa1a5253698556ac2b0cda2207d" category="paragraph">I vari componenti degli strumenti ONTAP, come il plugin vCenter, il provider VASA e l'adattatore di replica dello storage, sono tutti documentati insieme nell'archivio dei documenti NetApp. Tuttavia, ciascuno di essi dispone di una sottosezione separata della Knowledge base e può disporre di procedure specifiche per la risoluzione dei problemi. Queste soluzioni risolvono i problemi più comuni che potrebbero verificarsi con il provider VASA.</block>
  <block id="ae2a93a809929192ecc7b468f234af84" category="section-title">Problemi dell'interfaccia utente del provider VASA</block>
  <block id="69aecee18a55993c779487758eb051cc" category="paragraph">Occasionalmente, il client Web vCenter vSphere incontra problemi con i componenti di Serenity, causando la mancata visualizzazione delle voci di menu del provider VASA per ONTAP. Consultare la sezione risoluzione dei problemi di registrazione del provider VASA nella Guida all'implementazione o nella presente Knowledge base<block ref="c8979f1604396ce5570d07774ba255f0" category="inline-link-rx"></block>.</block>
  <block id="03cc611b90575ea37b55959adaa1c754" category="section-title">Il provisioning del datastore di vVol non riesce</block>
  <block id="281b890be0e8280eea1aebb82de90961" category="paragraph">Occasionalmente, i servizi vCenter potrebbero subire un timeout durante la creazione del datastore vVols. Per correggerlo, riavviare il servizio vmware-sps e rimontare il datastore vVols utilizzando i menu vCenter (Storage &gt; New Datastore). Questo argomento viene trattato in vVols datastore provisioning fails with vCenter Server 6.5 nella Administration Guide.</block>
  <block id="3152add163cd8aaf116a259d85ebf8fb" category="section-title">L'aggiornamento di Unified Appliance non riesce a montare ISO</block>
  <block id="ffaa56a3f5a1157f2eb3955773bb41da" category="paragraph">A causa di un bug in vCenter, l'ISO utilizzato per aggiornare Unified Appliance da una release alla successiva potrebbe non essere in grado di eseguire il montaggio. Se è possibile collegare l'ISO all'appliance in vCenter, seguire la procedura descritta in questa Knowledge base<block ref="9839383ed04f777c0132b57ad0cb14ac" category="inline-link-rx"></block> per risolvere il problema.</block>
  <block id="cacba1b456347ce8f32c7f5ed0d81e64" category="doc">Implementazione dello storage vVol</block>
  <block id="4adcd8d9323839ff088dc4f8f0bdcce2" category="paragraph">La creazione dello storage vVol per le macchine virtuali prevede diversi passaggi.</block>
  <block id="cbdc7cd55996b900586ff0774db3a15a" category="paragraph">I primi due passaggi potrebbero non essere necessari per un ambiente vSphere esistente che utilizza ONTAP per i datastore tradizionali. È possibile che si stia già utilizzando gli strumenti ONTAP per la gestione, l'automazione e il reporting del VMFS o dello storage tradizionale basato su NFSv3. Questi passaggi sono descritti in modo più dettagliato nella sezione seguente.</block>
  <block id="e6b250235cc79b41eca96abe47f5da52" category="list-text">Creare SVM (configurazione del protocollo, NVMe/FC, NFSv3, iSCSI, FCP, O una combinazione di queste opzioni) utilizzando le procedure guidate di Gestione di sistema di ONTAP o la riga di comando.</block>
  <block id="ff882b525669df93cacfcb4f3a4d56a9" category="list-text">Almeno un LIF per nodo per ogni connessione switch/fabric. Preferibilmente due o più per nodo per i protocolli SAN.</block>
  <block id="612705dd95888cdc6345d01c93c84c39" category="list-text">È possibile creare i volumi in questo momento, ma è più semplice consentire la creazione guidata _Provision Datastore_. L'unica eccezione a questa regola è rappresentata dall'utilizzo della replica vVol con VMware Site Recovery Manager. Questa operazione è più semplice da configurare con volumi FlexVol preesistenti con relazioni SnapMirror esistenti. Prestare attenzione a non abilitare la qualità del servizio su alcun volume da utilizzare per i vVol, in quanto questa operazione deve essere gestita dai tool SPBM e ONTAP.</block>
  <block id="16421df834af873175559b678c2b3cd9" category="list-text">Implementare i tool ONTAP per VMware vSphere utilizzando il software OVA scaricato dal sito del supporto NetApp.</block>
  <block id="8bdb69b5934ff84bbaafd84585965a90" category="list-text">Configurare gli strumenti ONTAP per il proprio ambiente.</block>
  <block id="dd07accb290c9c1e3900692630a70767" category="list-text">Aggiungere il cluster ONTAP agli strumenti ONTAP in _sistemi storage_</block>
  <block id="8dcc9a08857efa12e82c3368d2f2529e" category="list-text">Mentre gli strumenti e gli SRA di ONTAP supportano sia le credenziali a livello di cluster che quelle a livello di SVM, il provider VASA supporta solo le credenziali a livello di cluster per i sistemi storage. Pertanto, se si intende utilizzare vVol, è necessario aggiungere i cluster ONTAP utilizzando le credenziali con ambito cluster.</block>
  <block id="869ce78032d85111f09ceb58bdb59a36" category="list-text">Se i dati ONTAP si trovano su sottoreti diverse dagli adattatori VMkernel, è necessario aggiungere le subnet dell'adattatore VMkernel all'elenco delle subnet selezionate nel menu delle impostazioni degli strumenti ONTAP. Per impostazione predefinita, gli strumenti ONTAP proteggono il traffico di storage consentendo solo l'accesso alla subnet locale.</block>
  <block id="aae7d69037c2654c7029189e5116b78c" category="list-text">I tool ONTAP vengono forniti con diverse policy predefinite che possono essere utilizzate oppure consultare la Sezione 3.3 per informazioni sulla creazione di SCP.</block>
  <block id="ef51190e4c839596248fc4173ed12a3c" category="list-text">Utilizzare il menu _ONTAP tools_ di vCenter per avviare la procedura guidata _provisioning datastore_.</block>
  <block id="66edaf6f622057aeadab950977c1f3e8" category="list-text">Fornire un nome significativo e selezionare il protocollo desiderato. È anche possibile fornire una descrizione del datastore.</block>
  <block id="d22d6de0c8f11375907a1c10d8d0f251" category="list-text">Selezionare uno o più SCP da supportare dal datastore vVols. In questo modo, i sistemi ONTAP che non sono in grado di corrispondere al profilo verranno filtrati. Dall'elenco visualizzato, selezionare il cluster e la SVM desiderati.</block>
  <block id="6a016a18a0c20e3b805cd9b8e713fb3e" category="list-text">Utilizzare la procedura guidata per creare nuovi volumi FlexVol per ciascuno degli SCP specificati o utilizzare volumi esistenti selezionando il pulsante di opzione appropriato.</block>
  <block id="2527effe721902a77755b8d628fdad93" category="list-text">Creare policy VM per ogni SCP che verrà utilizzato nell'archivio dati dal menu _Policies and Profiles_ dell'interfaccia utente di vCenter.</block>
  <block id="642dadaf5095b4c11730dca0ffcb0d27" category="list-text">Scegliere il set di regole di storage "NetApp.Clustered.Data.ONTAP.VP.vvol". Il set di regole di storage "NetApp.Clustered.Data.ONTAP.VP.VASA10" è per il supporto SPBM con datastore non vVols</block>
  <block id="c9565e0957e6e02cf12aef618bd30c3f" category="list-text">Quando si crea un criterio di storage VM, specificare il profilo di capacità dello storage in base al nome. In questa fase, è possibile configurare anche la corrispondenza dei criteri di SnapMirror utilizzando la scheda di replica e la corrispondenza basata su tag utilizzando la scheda dei tag. Tenere presente che i tag devono essere già creati per essere selezionabili.</block>
  <block id="af70f7acdeed8e2a702372f9bc85d960" category="list-text">Creare le macchine virtuali, selezionando la policy di storage delle macchine virtuali e il datastore compatibile in Select storage (Seleziona storage).</block>
  <block id="7321485ed96e81e6aab7c83cf7d36ddc" category="section-title">Migrazione delle macchine virtuali da datastore tradizionali a vVol</block>
  <block id="7be42b7840cc093ce6d05a247df8e63d" category="paragraph">La migrazione delle macchine virtuali dai datastore tradizionali a un datastore vVol è semplice quanto lo spostamento delle macchine virtuali tra datastore tradizionali. È sufficiente selezionare le macchine virtuali, quindi Migrate (Migra) dall'elenco delle azioni e selezionare un tipo di migrazione di _change storage only_. Le operazioni di copia della migrazione verranno trasferite con vSphere 6.0 e versioni successive per le migrazioni DA SAN VMFS a vVol, ma non da NAS VMDK a vVol.</block>
  <block id="94580004273fd761a79ab0629b3d3dc4" category="section-title">Gestione delle macchine virtuali con policy</block>
  <block id="a4b0c9e0658ed660dd8cebd613f2d889" category="paragraph">Per automatizzare il provisioning dello storage con la gestione basata su policy, dobbiamo:</block>
  <block id="10b68fb9cbee818a044f91644423640c" category="list-text">Definire le funzionalità dello storage (nodo ONTAP e volume FlexVol) con SCP (Storage Capability Profiles).</block>
  <block id="2e415dc7a6f21b4fd03f963858c9f680" category="list-text">Creare policy di storage delle macchine virtuali mappate alle SCP definite.</block>
  <block id="a2b245d35eba890ae914c5cd36b9a090" category="paragraph">NetApp ha semplificato le funzionalità e la mappatura a partire dal provider VASA 7.2 con continui miglioramenti nelle versioni successive. Questa sezione si concentra su questo nuovo approccio. Le versioni precedenti supportavano un maggior numero di funzionalità e consentiva di mapparle singolarmente alle policy di storage, ma questo approccio non è più supportato. La tabella 3 mette a confronto le funzionalità delle varie release.</block>
  <block id="0bd86c4955ab0bdce52b49644ce9396d" category="section-title">Funzionalità di profilo della capacità dello storage con la release di tool ONTAP</block>
  <block id="4a6af8a6e216dcc53a63f04143c13222" category="cell">*Funzionalità SCP*</block>
  <block id="048424cc97a54b673c837ee7d4c19de0" category="cell">*Valori di capacità*</block>
  <block id="098e77f7c5d9e0c2ad5454817edf0767" category="cell">*Versione supportata*</block>
  <block id="28f44037af103f0c930309365629f8ef" category="cell">*Note*</block>
  <block id="d031377688b064b729a0cc60fb7fbbff" category="cell">*Compressione*</block>
  <block id="cc6aee5037bdc5b051433a266ec7d4a3" category="cell">Sì, No, qualsiasi</block>
  <block id="b1c94ca2fbc3e78fc30069c8d0f01680" category="cell">Tutto</block>
  <block id="7778bddb1c205e9f74d08bd30be0aca3" category="cell">Obbligatorio per AFF nel 7.2 e versioni successive.</block>
  <block id="221baf8ad30299306e725e4fb395bf34" category="cell">*Deduplica*</block>
  <block id="6868f879256c802b106616a006671848" category="cell">M andatory for AFF nel 7.2 e versioni successive.</block>
  <block id="504897d4a6b59afadffd3cf9e5d3ea85" category="cell">*Crittografia*</block>
  <block id="95fddd53c531d6efe15e3ac7ace1d9eb" category="cell">7.2 e versioni successive</block>
  <block id="b3870ec121aeafa2e7ca8cb3894c0e3a" category="cell">Seleziona/crea un volume FlexVol crittografato. È richiesta la licenza ONTAP.</block>
  <block id="e2dcc78cf70dac34550234c95443ac37" category="cell">*IOPS max*</block>
  <block id="b78a981cc40fc4e66208bf5ee6d1a1eb" category="cell">&lt;number&gt;</block>
  <block id="130b32bc15d3fbe6d2e80ecda94135cc" category="cell">7.1 e versioni successive, ma le differenze</block>
  <block id="5ff4c1b30dc8d55d9b71c982001cf299" category="cell">Elencato in QoS Policy Group per 7.2 e versioni successive. Per ulteriori informazioni, vedere la Tabella 4.</block>
  <block id="993c56850c1da5de36e798b0c5a72513" category="cell">*Personalità*</block>
  <block id="8485fa08bf8c556b7b2275349d11eb05" category="cell">A FF, FAS</block>
  <block id="c0acd03e8ba6b951b8c6dff3e95b9560" category="cell">FAS include anche altri sistemi non AFF, come ONTAP Select. AFF include ASA.</block>
  <block id="dce365633ffb688b7532470dfaf4e118" category="cell">*Protocollo*</block>
  <block id="7cff0b96b4a6467ea880f49dd365a81f" category="cell">NFS, NFS 4.1, iSCSI, FCP, NVMe/FC, Qualsiasi</block>
  <block id="be18de5e88c84ba55eeb5bc42cca4c0d" category="cell">7.1 e versioni precedenti, 9.10 e versioni successive</block>
  <block id="cfca0bc0c0b481555ba52be1f4e21da6" category="cell">7.2-9.8 è effettivamente "qualsiasi". Ricominciare dal 9.10, dove NFS 4.1 e NVMe/FC sono stati aggiunti all'elenco originale.</block>
  <block id="3dd301ae5682df79e8687ead5b6a3ddf" category="cell">*Riserva di spazio (Thin Provisioning)*</block>
  <block id="03868a080fbf4cdbc006da45e13cfad7" category="cell">Sottile, spesso (qualsiasi)</block>
  <block id="0a74dc1caf6ce891d5cbd3878cae2221" category="cell">Tutto, ma le differenze</block>
  <block id="4b370bcc260aa96e343bbb24d3af2cc5" category="cell">Definito Thin Provisioning nel 7.1 e nelle versioni precedenti, che consentiva anche il valore di qualsiasi. Chiamata Space Reserve nel 7.2. Per impostazione predefinita, tutte le release sono impostate su Thin.</block>
  <block id="40e2e283d064264dd51846580adb367d" category="cell">*Policy di tiering*</block>
  <block id="06b815f81a7e7aceb1489e3888fb9534" category="cell">Qualsiasi, Nessuno, Snapshot, Auto</block>
  <block id="c60bb16bd5fbc2fc75d9e8e9be1699ab" category="cell">Utilizzato per FabricPool^^ – richiede AFF o ASA con ONTAP 9.4 o versione successiva. Si consiglia di utilizzare solo Snapshot, a meno che non si utilizzi una soluzione S3 on-premise come NetApp StorageGRID.</block>
  <block id="ffb0d092d584c15937dfacd5be3c684a" category="section-title">Creazione di profili di funzionalità storage</block>
  <block id="ad0b6bb809400347fc4806f18385015c" category="paragraph">Il NetApp VASA Provider viene fornito con diversi SCP predefiniti. I nuovi SCP possono essere creati manualmente, utilizzando l'interfaccia utente di vCenter o tramite automazione utilizzando le API REST. Specificando le funzionalità in un nuovo profilo, clonando un profilo esistente o generando automaticamente profili da datastore tradizionali esistenti. Questa operazione viene eseguita utilizzando i menu in ONTAP Tools (Strumenti di Windows). Utilizzare _Storage Capability Profiles_ per creare o clonare un profilo e _Storage Mapping_ per generare automaticamente un profilo.</block>
  <block id="62351556db3b0f6f13da226ca3e2df24" category="section-title">Funzionalità di storage per gli strumenti ONTAP 9.10 e versioni successive</block>
  <block id="14b49e2a6b56b1177a77be03a29dfc83" category="inline-image-macro">"Funzionalità di storage per gli strumenti ONTAP 9.10 e versioni successive"0,300</block>
  <block id="2a53cbcd07a15d9f13f0cc630c7cc44d" category="paragraph"><block ref="2a53cbcd07a15d9f13f0cc630c7cc44d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64ca5ade59a3a7351134cf0db3a8e06a" category="paragraph"><block ref="64ca5ade59a3a7351134cf0db3a8e06a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e6d46028a015a7f3860fc8fdf214b3c" category="paragraph"><block ref="4e6d46028a015a7f3860fc8fdf214b3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12bb128f53dfaac0a251798e4b4e6954" category="paragraph"><block ref="12bb128f53dfaac0a251798e4b4e6954" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd59d4e26c472ef1e14cadb688283604" category="paragraph"><block ref="fd59d4e26c472ef1e14cadb688283604" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c8f597441425c22b4ae09f872f8bcc4" category="paragraph"><block ref="2c8f597441425c22b4ae09f872f8bcc4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73b9eadf952cfa70c3453f1076473707" category="paragraph">*Creazione di archivi dati vVol*</block>
  <block id="bb3a966118acb276cca87f389952d2da" category="paragraph">Una volta creati, gli SCP necessari possono essere utilizzati per creare il datastore vVols (e, facoltativamente, i volumi FlexVol per il datastore). Fare clic con il pulsante destro del mouse sull'host, sul cluster o sul data center su cui si desidera creare il datastore vVols, quindi selezionare _ONTAP Tools_ &gt; _Provision Datastore_. Selezionare uno o più SCP da supportare dall'archivio dati, quindi scegliere tra i volumi FlexVol esistenti e/o eseguire il provisioning di nuovi volumi FlexVol per l'archivio dati. Infine, specificare l'SCP predefinito per l'archivio dati, che verrà utilizzato per le macchine virtuali che non dispongono di un SCP specificato dal criterio, nonché per i vVol di swap (che non richiedono uno storage dalle performance elevate).</block>
  <block id="a4332a81dbc3a9888be608dea640cd3d" category="section-title">Creazione di policy di storage delle macchine virtuali</block>
  <block id="5179cb9ccf20c0aca30b4635eae55b1a" category="paragraph">Le policy di storage delle macchine virtuali vengono utilizzate in vSphere per gestire funzionalità opzionali come Storage i/o Control o vSphere Encryption. Vengono inoltre utilizzati con vVol per applicare funzionalità di storage specifiche alla macchina virtuale. Utilizzare il tipo di storage "NetApp.Clustered.Data.ONTAP.VP.vvol" e la regola "ProfileName" per applicare un SCP specifico alle macchine virtuali attraverso l'utilizzo del criterio. Vedere la Figura 6 per un esempio con il provider VASA degli strumenti ONTAP. Le regole per lo storage "NetApp.Clustered.Data.ONTAP.VP.VASA10" devono essere utilizzate con datastore non basati su vVol.</block>
  <block id="4d4fc37d1795d9bc8e29e1924e7279a9" category="paragraph">Le versioni precedenti sono simili, ma come indicato nella Tabella 3, le opzioni variano.</block>
  <block id="031896c4337d887f92b537eab0d1ff1e" category="paragraph">Una volta creata, la policy di storage può essere utilizzata per il provisioning di nuove macchine virtuali, come illustrato nella Figura 1. Le linee guida per l'utilizzo delle funzionalità di gestione delle performance con il provider VASA 7.2 sono descritte nella Tabella 4.</block>
  <block id="5c9a40095429970f45242eebe5f4761d" category="section-title">Creazione dei criteri di storage delle macchine virtuali con i tool ONTAP Provider VASA 9.10</block>
  <block id="c0c5e719ad5439106e5a00588402f206" category="inline-image-macro">"Creazione dei criteri di storage delle macchine virtuali con i tool ONTAP Provider VASA 9.10",300</block>
  <block id="378e30f2a60dc28c4afc9ae4f11a39e1" category="paragraph"><block ref="378e30f2a60dc28c4afc9ae4f11a39e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95ac22478e141fde0d2878c71530a13a" category="section-title">Gestione delle performance con gli strumenti ONTAP 9.10 e versioni successive</block>
  <block id="c153012a9aa13e8ed8ce3f3e471a70b4" category="list-text">ONTAP Tools 9.10 utilizza il proprio algoritmo di posizionamento bilanciato per inserire un nuovo vVol nel miglior volume FlexVol all'interno di un datastore vVol. Il posizionamento si basa sui volumi SCP specificati e FlexVol corrispondenti. In questo modo si garantisce che il datastore e lo storage di backup soddisfino i requisiti di performance specificati.</block>
  <block id="e65bde48b0a84fcc60d957de90c3a128" category="list-text">La modifica delle funzionalità delle performance, ad esempio IOPS min e max, richiede un'attenzione particolare alla configurazione specifica.</block>
  <block id="c43f1c590aab42b849ee038e863a567d" category="list-text">*I valori minimo e massimo di IOPS* possono essere specificati in un SCP e utilizzati in una policy VM.</block>
  <block id="01040bcb73e042e4dc496e209bf36022" category="list-text">La modifica dell'IOPS in SCP non modifica la QoS sui vVol fino a quando il criterio VM non viene modificato e quindi riapplicato alle VM che lo utilizzano (vedere la Figura 7). Oppure creare un nuovo SCP con gli IOPS desiderati e modificare il criterio per utilizzarlo (e riapplicarlo alle macchine virtuali). In genere, si consiglia di definire semplicemente criteri di storage di SCP e VM separati per diversi livelli di servizio e di modificare semplicemente la policy di storage delle macchine virtuali sulla macchina virtuale.</block>
  <block id="0e05d638b7a9c7a5c32e6c22679eeb82" category="list-text">Le personalità AFF e FAS hanno impostazioni IOPS diverse. Sia min che Max sono disponibili su AFF. Tuttavia, i sistemi non AFF possono utilizzare solo le impostazioni relative al numero massimo di IOPS.</block>
  <block id="97659fa3c3a5aaf088f6020a38faf086" category="list-text">In alcuni casi, potrebbe essere necessario migrare un vVol dopo una modifica di policy (manualmente o automaticamente dal provider VASA e da ONTAP):</block>
  <block id="81c975fc79a19102fa04ad9c49f7538b" category="list-text">Alcune modifiche non richiedono alcuna migrazione (ad esempio, la modifica di Max IOPS, che può essere applicata immediatamente alla macchina virtuale come descritto sopra).</block>
  <block id="a426b56f86a12c200f3484efb990e81f" category="list-text">Se la modifica del criterio non può essere supportata dal volume FlexVol corrente che memorizza il vVol (ad esempio, la piattaforma non supporta il criterio di crittografia o di tiering richiesto), sarà necessario migrare manualmente la macchina virtuale in vCenter.</block>
  <block id="7de504873f20af5c8ce6dadd2f79b29a" category="list-text">Gli strumenti ONTAP creano policy QoS individuali non condivise con le versioni attualmente supportate di ONTAP. Pertanto, ogni singolo VMDK riceverà la propria allocazione di IOPS.</block>
  <block id="63a33ddbd2c3ccd2daac06020248049f" category="section-title">Riapplicazione dei criteri di storage delle macchine virtuali</block>
  <block id="d0f5986c3378364e5cb0eda0e98fd0fd" category="inline-image-macro">"Riapplicazione della policy di storage delle macchine virtuali"0,300</block>
  <block id="2a8c2026166e178134c7e19c2f4a2c15" category="paragraph"><block ref="2a8c2026166e178134c7e19c2f4a2c15" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57a033c33a8be6110be46b2914cc4989" category="doc">Utilizzo di vVol con ONTAP</block>
  <block id="69556d50c944e0a07ade0bea62f078a3" category="paragraph">La chiave per utilizzare vVol con ONTAP è il software del provider VASA incluso negli strumenti ONTAP per l'appliance virtuale VMware vSphere.</block>
  <block id="5e484430124a3d64541b75bbf3c8f529" category="paragraph">Gli strumenti ONTAP includono anche le estensioni dell'interfaccia utente di vCenter, il server REST API, l'adattatore di replica dello storage per VMware Site Recovery Manager, i tool di monitoraggio e configurazione degli host e una serie di report che consentono di gestire al meglio l'ambiente VMware.</block>
  <block id="21247c4392dc3c243f693dbf5b762553" category="section-title">Prodotti e documentazione</block>
  <block id="4fc5e15c4dc0d227bc5f8f26e4337083" category="paragraph">La licenza FlexClone di ONTAP (inclusa con ONTAP One) e l'appliance ONTAP Tools sono gli unici prodotti aggiuntivi necessari per utilizzare vVol con NetApp ONTAP. Le release recenti dei tool ONTAP sono fornite come singola appliance unificata che viene eseguita su ESXi, fornendo le funzionalità di quelle che in precedenza erano tre appliance e server diversi. Per i vVol, è importante utilizzare le estensioni dell'interfaccia utente di vCenter o LE API REST degli strumenti ONTAP come strumenti di gestione generali e interfacce utente per le funzioni ONTAP con vSphere, insieme al provider VASA che fornisce funzionalità vVol specifiche. Il componente SRA è incluso per gli archivi dati tradizionali, ma VMware Site Recovery Manager non utilizza SRA per vVol, implementando invece nuovi servizi in SRM 8.3 e versioni successive che sfruttano il provider VASA per la replica di vVol.</block>
  <block id="bf03408d75f93f6e28c07c3c2300b98a" category="section-title">ONTAP Tools architettura del provider VASA quando si utilizza iSCSI o FCP</block>
  <block id="94ef809dc16e728151bda996f8b4f8aa" category="inline-image-macro">ONTAP Tools architettura del provider VASA,240</block>
  <block id="d78de3410d86d345a548abdf67aff375" category="paragraph"><block ref="d78de3410d86d345a548abdf67aff375" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e5421e75636200787a4449a2cdaa1f1" category="section-title">Installazione del prodotto</block>
  <block id="3ef3033a2b9a744a1e4e7e93fa01f909" category="paragraph">Per le nuove installazioni, implementa l'appliance virtuale nel tuo ambiente vSphere. Le versioni correnti dei tool ONTAP si registreranno automaticamente con vCenter e abiliteranno il provider VASA per impostazione predefinita. Oltre alle informazioni su host ESXi e vCenter Server, sono necessari anche i dettagli di configurazione dell'indirizzo IP per l'appliance. Come indicato in precedenza, il provider VASA richiede che la licenza FlexClone di ONTAP sia già installata su qualsiasi cluster ONTAP che si intende utilizzare per vVol. L'appliance dispone di un watchdog integrato per garantire la disponibilità e, come Best practice, deve essere configurata con le funzionalità VMware High Availability e, facoltativamente, Fault Tolerance. Per ulteriori dettagli, vedere la sezione 4.1. Non installare o spostare l'appliance ONTAP Tools o l'appliance vCenter Server (VCSA) sullo storage vVol, in quanto ciò potrebbe impedire il riavvio delle appliance.</block>
  <block id="6a5c862f634c8967f7246f42eb9de6e1" category="paragraph">Gli aggiornamenti in-place dei tool ONTAP sono supportati utilizzando il file ISO di aggiornamento disponibile per il download sul sito del supporto NetApp (NSS). Per aggiornare l'appliance, seguire le istruzioni della Guida all'installazione e alla distribuzione.</block>
  <block id="3c07c9b4b562a16890d9fee571f0441e" category="inline-link">Guida al dimensionamento degli strumenti ONTAP per VMware vSphere</block>
  <block id="8eda831c03b7cd0d243f982500cca330" category="paragraph">Per il dimensionamento dell'appliance virtuale e la comprensione dei limiti di configurazione, consultare questo articolo della Knowledge base:<block ref="401e218ff1e8ab443c4d65a773762b1a" category="inline-link-rx"></block></block>
  <block id="72333dadacbc964761fb14f718f6d411" category="section-title">Documentazione del prodotto</block>
  <block id="e0644c46fdc2ced2c094f7db15e15a8a" category="paragraph">La seguente documentazione è disponibile per facilitare l'implementazione degli strumenti ONTAP.</block>
  <block id="09e308ed60d47b80b6cd16eb233f1bb9" category="inline-link">Per la documentazione completa repository&amp;amp; n. 44; visitare questo link all'indirizzo docs.netapp.com</block>
  <block id="8e82e7db4c110c5ac0993b1a1287901e" category="paragraph"><block ref="4ad7f48032df299e00e4b0f7f6bc9f77" category="inline-link-rx"></block></block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="section-title">Inizia subito</block>
  <block id="7d0ee6fed10d3d4e5c9ee496729ab519" category="inline-link">Note di rilascio</block>
  <block id="284faaea41a8c5db567ba2a92a3e1c66" category="list-text"><block ref="284faaea41a8c5db567ba2a92a3e1c66" category="inline-link-rx"></block></block>
  <block id="b1555cd6358e57b76c72e343dbe31846" category="inline-link">Scopri i tool ONTAP per VMware vSphere</block>
  <block id="0c35360b42e6098ebf515fcc7a6a9125" category="list-text"><block ref="0c35360b42e6098ebf515fcc7a6a9125" category="inline-link-rx"></block></block>
  <block id="e695b432b77d6bddfcb785c76f5e5442" category="inline-link">ONTAP Tools Avvio rapido</block>
  <block id="c4bdf6ea71d684f8c82d4f247659ba3a" category="list-text"><block ref="c4bdf6ea71d684f8c82d4f247659ba3a" category="inline-link-rx"></block></block>
  <block id="3d7fe3e43f9f24fffe5ed0d546d12f13" category="inline-link">Implementare gli strumenti ONTAP</block>
  <block id="9b021912d7ca70dcaf1a7acb7d847dc5" category="list-text"><block ref="9b021912d7ca70dcaf1a7acb7d847dc5" category="inline-link-rx"></block></block>
  <block id="a2fa58344be7fbd9a2be0320a8df0f77" category="inline-link">Aggiornare i tool ONTAP</block>
  <block id="74db0bbf69443fec0180c19070ef9833" category="list-text"><block ref="74db0bbf69443fec0180c19070ef9833" category="inline-link-rx"></block></block>
  <block id="21e2a89d708329706ec6ed3fc989a1f6" category="section-title">Utilizzare gli strumenti ONTAP</block>
  <block id="91a9cfdbaaa44e0a9ad72e92533f763f" category="inline-link">Provisioning di datastore tradizionali</block>
  <block id="bbb605e83998eba8002024860499b395" category="list-text"><block ref="bbb605e83998eba8002024860499b395" category="inline-link-rx"></block></block>
  <block id="fc7d7e475ac8c3868d7426bb41df9b09" category="inline-link">Provisioning degli archivi dati vVol</block>
  <block id="8fa1b37949132324b5e85882d16fda5f" category="list-text"><block ref="8fa1b37949132324b5e85882d16fda5f" category="inline-link-rx"></block></block>
  <block id="317bbf73ff27c5f981628c8fb83ebf22" category="inline-link">Configurare il controllo degli accessi in base al ruolo</block>
  <block id="957c8b408f6f832b9f98b22e583abf07" category="list-text"><block ref="957c8b408f6f832b9f98b22e583abf07" category="inline-link-rx"></block></block>
  <block id="48bc2d028cb2a507ef974230ca3ba793" category="inline-link">Configurare la diagnostica remota</block>
  <block id="8a1891b3e1a0ccaa3b278a9f5bda5bbf" category="list-text"><block ref="8a1891b3e1a0ccaa3b278a9f5bda5bbf" category="inline-link-rx"></block></block>
  <block id="641e9457539249e880725760f91d5ee2" category="inline-link">Configurare la disponibilità elevata</block>
  <block id="05c38c2aebdb7361774e0ea785d1d29a" category="list-text"><block ref="05c38c2aebdb7361774e0ea785d1d29a" category="inline-link-rx"></block></block>
  <block id="04edeb5424c826c14a69edb777edf395" category="section-title">Proteggere e gestire i datastore</block>
  <block id="e17534281670c5ea4e8d55420a63c98f" category="inline-link">Proteggere i datastore tradizionali</block>
  <block id="ff3547dad2a2ab5f2370bcadac388446" category="list-text"><block ref="605d6f3b804c977b816a35b03939a484" category="inline-link-rx"></block> Con SRM</block>
  <block id="bff05cbbc19cad2bd10b9fe25dc34a1b" category="inline-link">Proteggere le macchine virtuali basate su vVol</block>
  <block id="da1b3d112a40630ada8d735cf05d9b26" category="list-text"><block ref="a577d38d4a2bdc7145444d0242a4bbdf" category="inline-link-rx"></block> Con SRM</block>
  <block id="5267febc97a2cc385cc5c73995dc64df" category="inline-link">Monitoraggio di datastore e macchine virtuali tradizionali</block>
  <block id="fc73e11c92e027811f9f395c85523ab3" category="list-text"><block ref="fc73e11c92e027811f9f395c85523ab3" category="inline-link-rx"></block></block>
  <block id="3123ece3c3b36f605758cb0c9a28f904" category="inline-link">Monitorare datastore e macchine virtuali di vVol</block>
  <block id="42171b5e19dcf5e04055e469719d34a9" category="list-text"><block ref="42171b5e19dcf5e04055e469719d34a9" category="inline-link-rx"></block></block>
  <block id="73751ced5959ea3089346b01d42dde76" category="paragraph">Oltre alla documentazione del prodotto, sono disponibili articoli della Knowledge base di supporto che potrebbero essere utili.</block>
  <block id="23bd7442fd1cd75655289cc3a38dd825" category="inline-link">Come eseguire un Disaster Recovery del provider VASA</block>
  <block id="9d3709a590a0752ef80c44f608e782e5" category="list-text"><block ref="9d3709a590a0752ef80c44f608e782e5" category="inline-link-rx"></block></block>
  <block id="dd5138e8a4207a5b2fde43b411a4b5e1" category="section-title">Dashboard del provider VASA</block>
  <block id="6da01a643ea28efe37fa2d6fd06a634b" category="paragraph">Il provider VASA include una dashboard con informazioni su performance e capacità per le singole VM vVol. Queste informazioni provengono direttamente da ONTAP per i file vVol e le LUN, tra cui latenza, IOPS, throughput e uptime per le prime 5 macchine virtuali, latenza e IOPS per i primi 5 datastore. Questa opzione è attivata per impostazione predefinita quando si utilizza ONTAP 9.7 o versione successiva. Il recupero e la visualizzazione dei dati iniziali nella dashboard possono richiedere fino a 30 minuti.</block>
  <block id="9b78e1fecb2bcc40733f2180691c7507" category="section-title">Dashboard di ONTAP Tools vVol</block>
  <block id="4adf016da96258b45a1cf762298729b5" category="inline-image-macro">Dashboard di ONTAP Tools vVol,400</block>
  <block id="73c1e14ddf3f32984f869ac3f122b2ca" category="paragraph"><block ref="73c1e14ddf3f32984f869ac3f122b2ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e359caf0e19df1a0e93e8e30cbef2100" category="paragraph">Questa sezione raccoglie le Best practice note per l'utilizzo di vVol con ONTAP insieme ad altre informazioni.</block>
  <block id="9ae938622297e9d4b14dd0006a8f0bf4" category="paragraph">*Limiti*</block>
  <block id="b4f52a4fd0b07c9d904b95fc98a1cd45" category="inline-link">Valori massimi di configurazione</block>
  <block id="e5e09031843479ef9ef8cbbd4c2f404c" category="inline-link">NetApp Hardware Universe</block>
  <block id="f3611dac13440d932a9974fe8e1c1e0b" category="paragraph">In generale, ONTAP supporta i limiti vVol definiti da VMware (vedere pubblicato<block ref="e1f020301c7db823f264e7f72661a955" category="inline-link-rx"></block>). La seguente tabella riassume i limiti ONTAP specifici in termini di dimensione e numero di vVol. Controllare sempre<block ref="bf137fbaca3418d969a7cbbc6acb278c" category="inline-link-rx"></block> Per i limiti aggiornati su numeri e dimensioni di LUN e file.</block>
  <block id="9b7ad553354519b31ec860eef39e5f6b" category="paragraph">*Limiti di ONTAP vVol*</block>
  <block id="6231ad61105cd983d3f0042762d3233d" category="cell">SAN (SCSI o NVMe-of)</block>
  <block id="75d4e7871261a858356a58d682ab71de" category="cell">Dimensione massima vVol</block>
  <block id="9cfd7100738cee4daf7acd5e01d31e14" category="cell">62 TIB*</block>
  <block id="9a728251ad1e90577975ae9395374772" category="cell">Numero massimo di vVol per volume FlexVol</block>
  <block id="46ba990c143630f55072434a6ea958c0" category="cell">2 miliardi</block>
  <block id="cdbcf58620f0b4b0bbf3291386a99407" category="cell">Numero massimo di vVol per nodo ONTAP</block>
  <block id="342264031889898ec1a553b4dd58d98c" category="cell">Fino a 12,288**</block>
  <block id="659e5faa0bdb08327ba0719230e95be2" category="cell">50 miliardi</block>
  <block id="43b49f27d93c6f55f54a68e8983d5479" category="cell">Numero massimo di vVol per coppia ONTAP</block>
  <block id="3941694d19c2d1fc406f055ab62cb9eb" category="cell">Fino a 24,576**</block>
  <block id="d6b3e65f296fd23975dd6f1a915c4b22" category="cell">Numero massimo di vVol per cluster ONTAP</block>
  <block id="2702ff8627a3990fc940d6f53463925e" category="cell">Fino a 98,304**</block>
  <block id="4f0c25d6c688cf50460d11fecaa97fa8" category="cell">Nessun limite specifico del cluster</block>
  <block id="855ecc47bb0d239e1fdf6fee84e24c75" category="cell">Numero massimo di oggetti QoS (gruppo di policy condiviso e livello di servizio vVol singolo)</block>
  <block id="26890bd9dcb27c05f1ab5bcc859501b8" category="cell">Da 12,000 a ONTAP 9.3; 40,000 con ONTAP 9.4 e versioni successive</block>
  <block id="0e38f856cb713ce9eea79fa1c6b7dc32" category="list-text">Limite di dimensione basato sui sistemi ASA o AFF e FAS con ONTAP 9.12.1P2 e versioni successive.</block>
  <block id="f8758506ff3ae8b97990466a5bb13853" category="list-text">Il numero di vVol SAN (NVMe namespace o LUN) varia in base alla piattaforma. Controllare sempre<block ref="bf137fbaca3418d969a7cbbc6acb278c" category="inline-link-rx"></block> Per i limiti aggiornati su numeri e dimensioni di LUN e file.</block>
  <block id="304d5a3dcf64bf05141ead00f7ec768a" category="paragraph">*Best Practice*</block>
  <block id="72e0ee397942f7233122887584f94b8b" category="paragraph">L'utilizzo di ONTAP vVol con vSphere è semplice e segue i metodi vSphere pubblicati (per la versione di ESXi in uso, vedere utilizzo dei volumi virtuali in vSphere Storage nella documentazione VMware). Di seguito sono riportate alcune procedure aggiuntive da prendere in considerazione in combinazione con ONTAP.</block>
  <block id="d7c0472e9975808c3f2c3ea3a1cdd812" category="paragraph">Best practice per l'utilizzo di vVol con ONTAP.</block>
  <block id="83583580d98b69cb8317f9b285f3c8df" category="cell">*Utilizzare i tool ONTAP per le estensioni dell'interfaccia utente di VMware vSphere o le API REST per eseguire il provisioning degli archivi dati vVol* *e degli endpoint del protocollo.*</block>
  <block id="3ebd332a1490a9e2cafd1bbb29808091" category="cell">Anche se è possibile creare datastore vVol con l'interfaccia generale di vSphere, utilizzando gli strumenti ONTAP si creeranno automaticamente endpoint di protocollo in base alle necessità e si creeranno volumi FlexVol utilizzando le Best practice ONTAP e in conformità con i profili di capacità storage definiti. È sufficiente fare clic con il pulsante destro del mouse sull'host/cluster/data center, quindi selezionare _ONTAP tools_ e _provisioning datastore_. Da qui, è sufficiente scegliere le opzioni vVol desiderate nella procedura guidata.</block>
  <block id="e8d5f9dc0bff953a9e59755813c7e8bf" category="cell">*Non memorizzare mai l'appliance ONTAP Tools o l'appliance vCenter Server (VCSA) su un datastore vVol gestito.*</block>
  <block id="fbc95da978eb6294df217c47365b22fb" category="cell">In questo modo si può creare una "situazione di uova e polli" se è necessario riavviare le appliance perché non saranno in grado di riassociare i propri vVol durante il riavvio. È possibile memorizzarli in un datastore vVol gestito da un diverso tool ONTAP e da una distribuzione vCenter.</block>
  <block id="ab8d352870fb5334773c7177d3d5dcd1" category="cell">*Evitare le operazioni vVol in diverse release di ONTAP.*</block>
  <block id="8b2bcef781b7e1f6d64739147d50aae7" category="cell">Le funzionalità di storage supportate, come QoS, personalità e molto altro, sono cambiate in varie versioni del provider VASA e alcune dipendono dalla release di ONTAP. L'utilizzo di release diverse in un cluster ONTAP o lo spostamento di vVol tra cluster con release diverse può causare comportamenti imprevisti o allarmi di compliance.</block>
  <block id="b2da0eca57c759eff034e6fe26f153e6" category="cell">*Prima di utilizzare NVMe/FC o FCP per i vVol, è necessario eseguire un'area del fabric Fibre Channel.*</block>
  <block id="cd7bf0e1e61341c1aa3fa23401af8a27" category="inline-image-macro">Zoning initiator singolo con quattro nodi,400</block>
  <block id="51591d05b7e084ba8e5ae7f63172177e" category="inline-link">_TR-4080 Best practice per la MODERNA SAN ONTAP 9_</block>
  <block id="c1723e6a0e1d3dd28232b33e0cb6e61d" category="inline-link">_TR-4684 implementazione e configurazione delle moderne SAN con NVMe-of_</block>
  <block id="4b5ff74178a605e346f59d7147112bfc" category="cell">Il provider ONTAP Tools VASA si occupa della gestione degli igroup FCP e iSCSI, nonché dei sottosistemi NVMe in ONTAP in base agli iniziatori rilevati degli host ESXi gestiti. Tuttavia, non si integra con gli switch Fibre Channel per gestire lo zoning. Lo zoning deve essere eseguito in base alle Best practice prima di eseguire qualsiasi provisioning. Di seguito viene riportato un esempio di zoning con singolo iniziatore su quattro sistemi ONTAP: Zoning con singolo iniziatore:<block ref="17ccf64e30cb518fd7ca87ce752ad738" category="inline-image-macro-rx" type="image"></block>Fare riferimento ai seguenti documenti per ulteriori Best practice:<block ref="29fe20047de6ed3a64321e7515bc8890" category="inline-link-rx"></block>

<block ref="0c9a1714909f45c6f60c5e87c8627327" category="inline-link-rx"></block></block>
  <block id="9a36c8f0464a7ffce114044f1859c7ff" category="cell">*Pianificare FlexVol di supporto in base alle proprie esigenze.*</block>
  <block id="03d2e894fa9a05efefa4e8d6b2008a19" category="cell">È consigliabile aggiungere diversi volumi di backup al datastore vVol per distribuire il carico di lavoro nel cluster ONTAP, supportare diverse opzioni di policy o aumentare il numero di LUN o file consentiti. Tuttavia, se è richiesta la massima efficienza dello storage, posizionare tutti i volumi di backup su un singolo aggregato. In alternativa, se sono richieste le massime prestazioni di cloning, prendere in considerazione l'utilizzo di un singolo volume FlexVol e la conservazione dei modelli o della libreria di contenuti nello stesso volume. Il provider VASA trasferisce molte operazioni di storage vVol a ONTAP, tra cui migrazione, cloning e snapshot. Quando questa operazione viene eseguita all'interno di un singolo volume FlexVol, vengono utilizzati cloni di file efficienti in termini di spazio e sono quasi immediatamente disponibili. Quando questo viene eseguito su volumi FlexVol, le copie sono rapidamente disponibili e utilizzano la deduplica e la compressione inline, ma la massima efficienza dello storage potrebbe non essere ripristinata fino a quando i processi in background non vengono eseguiti su volumi che utilizzano la deduplica e la compressione in background. A seconda dell'origine e della destinazione, un certo livello di efficienza potrebbe risultare degradato.</block>
  <block id="80b15469535d95a1690f308427545c7e" category="cell">*Mantieni semplici gli SCP (Storage Capability Profiles).*</block>
  <block id="aa43415b7c2c6514c4b26c5de12142f0" category="cell">Evitare di specificare funzionalità non richieste impostandole su qualsiasi. In questo modo si riducono al minimo i problemi durante la selezione o la creazione di volumi FlexVol. Ad esempio, con il provider VASA 7.1 e versioni precedenti, se la compressione viene lasciata all'impostazione SCP predefinita No, tenterà di disattivare la compressione, anche su un sistema AFF.</block>
  <block id="5a6d5fdddf6fbd82f1952b532b03c9ef" category="cell">*Utilizzare gli SCP predefiniti come modelli di esempio per creare i propri.*</block>
  <block id="9ab96500ef87d6c0457f87322f3b0d05" category="cell">Gli SCP inclusi sono adatti per la maggior parte degli usi generici, ma i requisiti potrebbero essere diversi. *Prendere in considerazione l'utilizzo di IOPS massimi per controllare macchine virtuali sconosciute o di test.*</block>
  <block id="c0905f7932cce129e5491ca16a6f00a8" category="cell">Per la prima volta disponibile nel provider VASA 7.1, è possibile utilizzare il massimo IOPS per limitare gli IOPS a un vVol specifico per un carico di lavoro sconosciuto, in modo da evitare impatti su altri carichi di lavoro più critici. Per ulteriori informazioni sulla gestione delle performance, vedere la Tabella 4. *Assicurarsi di disporre di LIF di dati sufficienti.*</block>
  <block id="f5a3607cd11e645cf22997a47fc7a5d5" category="cell">Creare almeno due LIF per nodo per coppia ha. In base al carico di lavoro, potrebbe essere necessario un numero maggiore di risorse.</block>
  <block id="ee3cbda1c3c4a14ae024478c7ada6d11" category="cell">*Seguire tutte le Best practice del protocollo.*</block>
  <block id="6a2c1ac1da51eca0c1a65afffab8dfab" category="inline-image-macro">Configurazione di rete con vVol su NFS v3.500</block>
  <block id="c7d19c3dfdd9f4afb1b19f39e1efd7a0" category="cell">Fare riferimento alle altre guide alle Best practice di NetApp e VMware specifiche per il protocollo selezionato. In generale, non vi sono modifiche diverse da quelle già menzionate. Esempio di configurazione di rete con vVol su NFS v3:<block ref="53b4e37aeeb9aaf52da56528778439d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e7040600922b2a78715f856613a3c08" category="doc">Protezione di vVol</block>
  <block id="de92c927f248723e4668aec459709995" category="section-title">ALTA disponibilità del provider VASA</block>
  <block id="f4d4cb8868f07cad16bd7de7e36c5201" category="paragraph">NetApp VASA Provider viene eseguito come parte dell'appliance virtuale insieme al plug-in vCenter, al server REST API (precedentemente noto come Virtual Storage Console [VSC]) e allo Storage Replication Adapter. Se il provider VASA non è disponibile, le VM che utilizzano vVol continueranno a funzionare. Tuttavia, non è possibile creare nuovi datastore vVol e non è possibile creare o vinare vVol da vSphere. Ciò significa che le macchine virtuali che utilizzano vVol non possono essere attivate poiché vCenter non sarà in grado di richiedere la creazione dello swap vVol. Inoltre, le macchine virtuali in esecuzione non possono utilizzare vMotion per la migrazione a un altro host perché i vVol non possono essere associati al nuovo host.</block>
  <block id="3958bf41787d7fcc6a9f8dd9348c947f" category="paragraph">VASA Provider 7.1 e versioni successive supportano nuove funzionalità per garantire la disponibilità dei servizi quando necessario. Include nuovi processi di controllo che monitorano il provider VASA e i servizi di database integrati. Se rileva un errore, aggiorna i file di registro e riavvia automaticamente i servizi.</block>
  <block id="1acc458c695b0d3dfbf588309801fda2" category="paragraph">L'amministratore di vSphere deve configurare un'ulteriore protezione utilizzando le stesse funzionalità di disponibilità utilizzate per proteggere le altre macchine virtuali mission-critical da guasti del software, dell'hardware host e della rete. Non è richiesta alcuna configurazione aggiuntiva sull'appliance virtuale per utilizzare queste funzionalità; è sufficiente configurarle utilizzando gli approcci standard vSphere. Sono stati testati e supportati da NetApp.</block>
  <block id="ff43afff832597ff45e5abeab2826ccf" category="inline-link">Strumenti ONTAP per la documentazione di VMware vSphere (configurare l'alta disponibilità per i tool ONTAP)</block>
  <block id="d516ca4c9c18446a82d9fc9ee85bd955" category="paragraph">VSphere High Availability è facilmente configurabile per riavviare una macchina virtuale su un altro host nel cluster host in caso di guasto. VSphere Fault Tolerance offre una maggiore disponibilità creando una macchina virtuale secondaria che viene continuamente replicata e che può assumere il controllo in qualsiasi momento. Ulteriori informazioni su queste funzioni sono disponibili nella<block ref="b6d78cbf1d5afb52929c529b32a350ad" category="inline-link-rx"></block>, Oltre alla documentazione VMware vSphere (cercare vSphere Availability sotto ESXi e vCenter Server).</block>
  <block id="97ba24d475ff6fdc7743099992cc301f" category="paragraph">Il provider VASA di ONTAP Tools esegue automaticamente il backup della configurazione vVol in tempo reale sui sistemi ONTAP gestiti in cui le informazioni vVol vengono memorizzate nei metadati dei volumi FlexVol. Nel caso in cui l'appliance ONTAP Tools non fosse disponibile per qualsiasi motivo, è possibile implementarne una nuova e importarne la configurazione in modo semplice e rapido. Fare riferimento a questo articolo della Knowledge base per ulteriori informazioni sulle fasi di ripristino del provider VASA:</block>
  <block id="6799b6ec743f9159edf3b43790210a11" category="inline-link">Come eseguire un Disaster Recovery provider VASA - Guida alla risoluzione</block>
  <block id="9462790a7557a7eb2fe9daad4b875817" category="paragraph"><block ref="9462790a7557a7eb2fe9daad4b875817" category="inline-link-rx"></block></block>
  <block id="029a7740ecd792264454f9dbe194e980" category="section-title">Replica di vVol</block>
  <block id="f86463587c976439895f2dca4eecdc87" category="paragraph">Molti clienti ONTAP replicano i propri datastore tradizionali su sistemi storage secondari utilizzando NetApp SnapMirror, quindi utilizzano il sistema secondario per ripristinare singole macchine virtuali o un intero sito in caso di disastro. Nella maggior parte dei casi, i clienti utilizzano uno strumento software per gestire questa operazione, ad esempio un prodotto software di backup come il plug-in NetApp SnapCenter per VMware vSphere o una soluzione di disaster recovery come il gestore del ripristino del sito di VMware (insieme all'adattatore per la replica dello storage negli strumenti ONTAP).</block>
  <block id="bc6303e4538280b1b01d45a5f7d20039" category="paragraph">Questo requisito per uno strumento software è ancora più importante per gestire la replica di vVol. Sebbene alcuni aspetti possano essere gestiti da funzionalità native (ad esempio, le snapshot gestite da VMware di vVol vengono trasferite su ONTAP, che utilizza cloni di file o LUN rapidi ed efficienti), in generale l'orchestrazione è necessaria per gestire la replica e il ripristino. I metadati relativi ai vVol sono protetti da ONTAP e dal provider VASA, ma è necessaria un'ulteriore elaborazione per utilizzarli in un sito secondario.</block>
  <block id="c6a26835eb364bad22b16cb127b74135" category="paragraph">I tool ONTAP 9.7.1, insieme alla release 8.3 di VMware Site Recovery Manager (SRM), hanno aggiunto il supporto per il disaster recovery e l'orchestrazione del flusso di lavoro di migrazione sfruttando la tecnologia SnapMirror di NetApp.</block>
  <block id="d23ccd39419a2748ff63cce9f698cf10" category="paragraph">Nella versione iniziale del supporto SRM con i tool ONTAP 9.7.1 era necessario pre-creare FlexVol e abilitare la protezione SnapMirror prima di utilizzarli come volumi di backup per un datastore vVol. A partire dagli strumenti ONTAP 9.10, questo processo non è più necessario. È ora possibile aggiungere la protezione SnapMirror ai volumi di backup esistenti e aggiornare le policy di storage delle macchine virtuali per sfruttare la gestione basata su policy con disaster recovery, orchestrazione della migrazione e automazione integrate con SRM.</block>
  <block id="8142fcf496d02a58ce02a17558db863e" category="paragraph">Attualmente, VMware SRM è l'unica soluzione di disaster recovery e automazione della migrazione per vVol supportata da NetApp e i tool ONTAP verificheranno l'esistenza di un server SRM 8.3 o successivo registrato con vCenter prima di consentire la replica di vVol, Sebbene sia possibile sfruttare le API REST degli strumenti ONTAP per creare i propri servizi.</block>
  <block id="7d8e8eced8d8b1a50f20640ffb5d363a" category="section-title">Replica di vVol con SRM</block>
  <block id="4d30574e6d5bc9a71718858eeb30774c" category="inline-image-macro">Replica di vVol con SRM,300</block>
  <block id="5844b0ec1ad8db5185ec67effeb9a7b7" category="paragraph"><block ref="5844b0ec1ad8db5185ec67effeb9a7b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c95aede1de7a41511c9d962deba49054" category="section-title">Supporto MetroCluster</block>
  <block id="3f15bb720adb42bd521a2ce1cb3a2974" category="paragraph">Sebbene gli strumenti ONTAP non siano in grado di attivare uno switchover MetroCluster, supportano i sistemi NetApp MetroCluster per il backup dei volumi in una configurazione vMSC (vSphere Metro Storage Cluster) uniforme. La commutazione di un sistema MetroCluster viene gestita normalmente.</block>
  <block id="cde16c5ee89c209c821e120caf65bb81" category="paragraph">Anche se NetApp SnapMirror Business Continuity (SM-BC) può essere utilizzato come base per una configurazione vMSC, al momento non è supportato con vVol.</block>
  <block id="c859f5cd725cb2d1b163e4b066bede9a" category="paragraph">Consulta queste guide per ulteriori informazioni su NetApp MetroCluster:</block>
  <block id="e5e0fb3ae5564674a6548ade7c601578" category="inline-link">_Architettura e progettazione della soluzione IP TR-4689 MetroCluster_</block>
  <block id="e64de4e49a37e62ff7f8c37e859bbeb9" category="paragraph"><block ref="e64de4e49a37e62ff7f8c37e859bbeb9" category="inline-link-rx"></block></block>
  <block id="0229efec9dc9b9a7fdf144b025157176" category="inline-link">_TR-4705 architettura e progettazione della soluzione NetApp MetroCluster_</block>
  <block id="6aee4b78ffdfaf193918978472d660a7" category="paragraph"><block ref="6aee4b78ffdfaf193918978472d660a7" category="inline-link-rx"></block></block>
  <block id="876341bac548f230eb390348e8b075ad" category="inline-link">_VMware KB 2031038 supporto VMware vSphere con NetApp MetroCluster_</block>
  <block id="5e68486fffeebad2ed145408dc250367" category="paragraph"><block ref="5e68486fffeebad2ed145408dc250367" category="inline-link-rx"></block></block>
  <block id="50c323f7050912164118ba47eab75888" category="section-title">Panoramica del backup di vVol</block>
  <block id="6751e706567f4773c4f3138b4de51a0f" category="paragraph">Esistono diversi approcci per la protezione delle macchine virtuali, ad esempio l'utilizzo di agenti di backup in-guest, l'aggiunta di file di dati delle macchine virtuali a un proxy di backup o l'utilizzo di API definite come VMware VADP. I vVol possono essere protetti utilizzando gli stessi meccanismi e molti partner NetApp supportano i backup delle macchine virtuali, inclusi i vVol.</block>
  <block id="416d27c872769e934ac8a49ec98ccb53" category="paragraph">Come accennato in precedenza, le snapshot gestite da VMware vCenter vengono trasferite a cloni di file/LUN ONTAP efficienti in termini di spazio e veloci. Questi possono essere utilizzati per backup manuali e rapidi, ma sono limitati da vCenter a un massimo di 32 snapshot. È possibile utilizzare vCenter per creare snapshot e ripristinarli in base alle necessità.</block>
  <block id="8f3d5ae5bd7d8922841975ccd84b8526" category="paragraph">A partire dal plug-in SnapCenter per VMware vSphere (SCV) 4.6, se utilizzato insieme ai tool ONTAP 9.10 e versioni successive, aggiunge il supporto per backup e ripristino coerenti in caso di crash delle macchine virtuali basate su vVol, sfruttando le snapshot dei volumi ONTAP FlexVol con il supporto per SnapMirror e la replica SnapVault. Sono supportati fino a 1023 snapshot per volume. SCV può anche memorizzare più snapshot con una maggiore conservazione sui volumi secondari utilizzando SnapMirror con una policy di vault mirror.</block>
  <block id="1429a9379faa8e82f8b198e93eebdf61" category="paragraph">Il supporto di vSphere 8.0 è stato introdotto con SCV 4.7, che utilizzava un'architettura di plug-in locale isolata. Il supporto di vSphere 8.0U1 è stato aggiunto a SCV 4.8, che ha completato la transizione alla nuova architettura di plug-in remoto.</block>
  <block id="de1d77d00dae616276b6ceb6296a18f2" category="section-title">Backup vVol con plug-in SnapCenter per VMware vSphere</block>
  <block id="e6dd8114e37869555d63547ec96a68f7" category="paragraph">Con NetApp SnapCenter è ora possibile creare gruppi di risorse per vVol in base a tag e/o cartelle per sfruttare automaticamente le snapshot basate su FlexVol di ONTAP per le macchine virtuali basate su vVol. Ciò consente di definire servizi di backup e ripristino che proteggeranno automaticamente le macchine virtuali man mano che vengono sottoposte a provisioning dinamico all'interno dell'ambiente.</block>
  <block id="4549a2943666c4815098331d30a872da" category="paragraph">Il plug-in SnapCenter per VMware vSphere viene implementato come appliance standalone registrata come estensione vCenter, gestita tramite l'interfaccia utente di vCenter o tramite API REST per l'automazione dei servizi di backup e recovery.</block>
  <block id="26e2418d177df1dddb008e455ce28752" category="section-title">Architettura SnapCenter</block>
  <block id="3b345c0fb5d2f0451ef84d991b21dcac" category="inline-image-macro">Architettura SnapCenter,300</block>
  <block id="af9bca7d8452705ba7f607cd036dba01" category="paragraph"><block ref="af9bca7d8452705ba7f607cd036dba01" category="inline-image-macro-rx" type="image"></block></block>
  <block id="547b42d8cae46228bdeabcd52f3b1687" category="paragraph">Poiché gli altri plug-in di SnapCenter non supportano ancora vVol al momento della stesura di questo documento, ci concentreremo sul modello di distribuzione standalone in questo documento.</block>
  <block id="52ae22239ef1f753f75b8b7d83594a18" category="paragraph">Poiché SnapCenter utilizza snapshot ONTAP FlexVol, non è previsto alcun overhead su vSphere, né penalità in termini di performance, come si può vedere con le macchine virtuali tradizionali che utilizzano snapshot gestite da vCenter. Inoltre, poiché le funzionalità di SCV sono esposte tramite API REST, è facile creare workflow automatizzati utilizzando strumenti come VMware aria Automation, Ansible, Terraform e praticamente qualsiasi altro strumento di automazione in grado di utilizzare API REST standard.</block>
  <block id="0c889d77d71512ceb7241bd0f6d6ca23" category="inline-link">Panoramica delle API REST</block>
  <block id="35eab4195b135718da016e20979f9031" category="paragraph">Per informazioni sulle API REST di SnapCenter, vedere<block ref="33852d6f529e96c0b816da3945bcb1e5" category="inline-link-rx"></block></block>
  <block id="4ee2d383554981f4ea8eff4f35db6832" category="inline-link">Plug-in SnapCenter per le API REST di VMware vSphere</block>
  <block id="63ae61e98eec102c39264a819a3c522e" category="paragraph">Per informazioni sulle API REST del plug-in SnapCenter per VMware vSphere, vedere<block ref="40a6c7462de67e21480b7a31e406f8f9" category="inline-link-rx"></block></block>
  <block id="bdf03d5c2a7086b6c916dc96d06a0a6c" category="paragraph">Le seguenti Best practice possono aiutarti a ottenere il massimo dalla tua implementazione SnapCenter.</block>
  <block id="8e52de0d4b03d5fe87dc88da09616c7f" category="inline-link">qui.</block>
  <block id="60af6a4208b610da54a63a7e3658d5a5" category="list-text">SCV supporta sia vCenter Server RBAC che ONTAP RBAC e include ruoli vCenter predefiniti che vengono creati automaticamente al momento della registrazione del plug-in. Ulteriori informazioni sui tipi di RBAC supportati<block ref="a8ef9d6a500bd8288101245a3828ddb1" category="inline-link-rx"></block></block>
  <block id="0ed0835259b5b8c4b0f0910e7bfe2b17" category="list-text">Utilizzare l'interfaccia utente di vCenter per assegnare l'accesso agli account con privilegi minimi utilizzando i ruoli predefiniti descritti<block ref="17b3487f3493b9c198e03f92348bfca0" category="inline-link-rx"></block>.</block>
  <block id="d53326766687d6bc7fa2e28ee177e809" category="list-text">Se si utilizza SCV con il server SnapCenter, è necessario assegnare il ruolo _SnapCenterAdmin_.</block>
  <block id="b4f10077c4bbf4cf4c08c3295abaf41b" category="list-text">ONTAP RBAC si riferisce all'account utente utilizzato per aggiungere e gestire i sistemi di storage utilizzati da SCV. ONTAP RBAC non si applica ai backup basati su vVol. Scopri di più su ONTAP RBAC e SCV<block ref="e4e865178d3962f87ac5cef3d6d68942" category="inline-link-rx"></block>.</block>
  <block id="1c89ba258526186ea0ec98325b61371b" category="list-text">Replica i set di dati di backup su un secondo sistema utilizzando SnapMirror per repliche complete dei volumi di origine. Come indicato in precedenza, è anche possibile utilizzare policy di vault mirror per la conservazione a lungo termine dei dati di backup indipendentemente dalle impostazioni di conservazione delle snapshot del volume di origine. Entrambi i meccanismi sono supportati con vVol.</block>
  <block id="9792eeb3b91469abf77746b005d82d77" category="list-text">Poiché SCV richiede anche strumenti ONTAP per la funzionalità vVol di VMware vSphere, controllare sempre lo strumento matrice di interoperabilità NetApp (IMT) per verificare la compatibilità delle versioni specifiche</block>
  <block id="71c989bd68059e2ddfa4200c60b736c7" category="list-text">Se si utilizza la replica vVol con VMware SRM, prestare attenzione all'RPO delle policy e alla pianificazione del backup</block>
  <block id="604eb779cbb9af378f7bda71633b5b31" category="list-text">Progettare le policy di backup con impostazioni di conservazione che soddisfino gli obiettivi dei punti di ripristino (RPO) definiti dall'organizzazione</block>
  <block id="067ff91a08d3ff453b59d81993b96182" category="list-text">Configurare le impostazioni di notifica sui gruppi di risorse per ricevere una notifica dello stato durante l'esecuzione dei backup (vedere la figura 10 di seguito)</block>
  <block id="c3add00693172bbbb4dd864bf0ad9116" category="section-title">Opzioni di notifica del gruppo di risorse</block>
  <block id="c728df76dc3609672a7969e320e39e32" category="inline-image-macro">Opzioni di notifica del gruppo di risorse,300</block>
  <block id="45281309785094533b5880fe6d0fd1ea" category="paragraph"><block ref="45281309785094533b5880fe6d0fd1ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6eae9510711f8df8f55a15e1761875d9" category="section-title">Iniziare a utilizzare SCV utilizzando questi documenti</block>
  <block id="235a656535515ab3518937c09836e60d" category="inline-link">Scopri di più sul plug-in SnapCenter per VMware vSphere</block>
  <block id="79eb02d2a96cc634df87bec5bd511bbe" category="paragraph"><block ref="79eb02d2a96cc634df87bec5bd511bbe" category="inline-link-rx"></block></block>
  <block id="04e7bb0411c1c8f56ca4fc8000c62ad8" category="inline-link">Implementare il plug-in SnapCenter per VMware vSphere</block>
  <block id="d4ba0aa084ae1145248006481c881d29" category="paragraph"><block ref="d4ba0aa084ae1145248006481c881d29" category="inline-link-rx"></block></block>
  <block id="be7078ced01754e29e7276ca5a01643f" category="doc">TR-4400: Volumi virtuali VMware vSphere (vVol) con NetApp ONTAP</block>
  <block id="4026ea437231bdea0e1aa821e2f138d3" category="paragraph">Autore: Chance Bingen, NetApp</block>
  <block id="94c989bb3785c63a642797adefd42cae" category="section-title">Perché vVol per vSphere?</block>
  <block id="8fd5a6736dba0e512682c41ab54ca770" category="paragraph">Il software NetApp ONTAP^^ è una soluzione di storage leader per gli ambienti VMware vSphere da oltre vent'anni e continua ad aggiungere funzionalità innovative per semplificare la gestione e ridurre i costi. Questo documento tratta le funzionalità di ONTAP per i volumi virtuali VMware vSphere (vVol), incluse le informazioni più recenti sui prodotti e i casi di utilizzo, oltre a Best practice e altre informazioni per semplificare l'implementazione e ridurre gli errori.</block>
  <block id="d30f04665be7a6d9663004b1b5e61a9a" category="paragraph">Le Best practice integrano altri documenti come guide ed elenchi di compatibilità. Sono sviluppati in base a test di laboratorio e a un'ampia esperienza sul campo da parte di tecnici e clienti NetApp. Potrebbero non essere le uniche pratiche che funzionano o sono supportate, ma sono generalmente le soluzioni più semplici che soddisfano le esigenze della maggior parte dei clienti.</block>
  <block id="b010d2e253827dbb44b7ba4e1332e24e" category="admonition">Questo documento è stato aggiornato per includere le nuove funzionalità vVol di vSphere 8.0 update 1, supportate con la release 9.12 di ONTAP Tools.</block>
  <block id="9185e9fa3b02059aff127b75a9f4f3aa" category="section-title">Panoramica sui volumi virtuali (vVol)</block>
  <block id="64f0863a7fb5f52a7ac6a911e1ad6862" category="paragraph">Nel 2012, NetApp ha iniziato a collaborare con VMware per supportare le API vSphere per la consapevolezza dello storage (VASA) per vSphere 5. Questo primo provider VASA consentiva la definizione delle funzionalità di storage in un profilo che poteva essere utilizzato per filtrare i datastore durante il provisioning e per verificare successivamente la conformità con la policy. Nel corso del tempo, questo si è evoluto per aggiungere nuove funzionalità per consentire una maggiore automazione nel provisioning, oltre all'aggiunta di volumi virtuali o vVol, in cui i singoli oggetti storage vengono utilizzati per i file delle macchine virtuali e i dischi virtuali. Questi oggetti potrebbero essere LUN, file, e ora con vSphere 8 - NVMe namespaces.NetApp ha lavorato a stretto contatto con VMware come partner di riferimento per vVol rilasciato con vSphere 6 nel 2015, e ancora come partner di progettazione per vVol utilizzando NVMe su fabric in vSphere 8. NetApp continua a migliorare vVol per sfruttare le più recenti funzionalità di ONTAP.</block>
  <block id="cbf0aa9daeb855e4eace1a3bdc474ce2" category="paragraph">Esistono diversi componenti di cui tenere conto:</block>
  <block id="e2f6b83160ea0712fbc59dd84410c4b2" category="cell">*Provider VASA*</block>
  <block id="919601826e1d58bccaaab76d787871d2" category="cell">Questo è il componente software che gestisce la comunicazione tra VMware vSphere e il sistema storage. Per ONTAP, il provider VASA viene eseguito in un'appliance nota come tool ONTAP per VMware vSphere (in breve, strumenti ONTAP). Gli strumenti ONTAP includono anche un plugin vCenter, un adattatore per la replica dello storage (SRA) per VMware Site Recovery Manager e un server API REST per la creazione di automazione. Una volta configurati e registrati gli strumenti ONTAP con vCenter, non è più necessario interagire direttamente con il sistema ONTAP, poiché quasi tutte le esigenze di storage possono essere gestite direttamente dall'interfaccia utente di vCenter o tramite l'automazione delle API REST.</block>
  <block id="05ad8543ff165c6b8cd0cc5e976d3245" category="cell">*Protocol Endpoint (PE)*</block>
  <block id="fd2001f5b39da81afb1bc397afb83377" category="cell">L'endpoint del protocollo è un proxy per i/o tra gli host ESXi e il datastore vVols. Il provider VASA di ONTAP crea automaticamente questi dati, ovvero un LUN dell'endpoint del protocollo (dimensioni 4 MB) per volume FlexVol^® del datastore vVol o un punto di montaggio NFS per interfaccia NFS (LIF) sul nodo di storage che ospita un volume FlexVol nell'archivio dati. L'host ESXi monta questi endpoint di protocollo direttamente piuttosto che singoli LUN vVol e file di dischi virtuali. Non è necessario gestire gli endpoint del protocollo poiché vengono creati, montati, rimossi ed eliminati automaticamente dal provider VASA, insieme a eventuali gruppi di interfacce o policy di esportazione necessari.</block>
  <block id="d3f051e8316cfd36651af1e65be24a75" category="cell">*Virtual Protocol Endpoint (VPE)*</block>
  <block id="71afca0aa1a505ea2ac3ce5a1a681549" category="paragraph">Novità di vSphere 8: Quando si utilizza NVMe over Fabrics (NVMe-of) con vVol, il concetto di endpoint del protocollo non è più rilevante in ONTAP. Al contrario, l'host ESXi crea automaticamente un'istanza di PE virtuale per ciascun gruppo ANA non appena viene accesa la prima macchina virtuale. ONTAP crea automaticamente gruppi ANA per ogni volume FlexVol utilizzato dall'archivio dati.</block>
  <block id="8202498953d2ebcf9968c37a7e47f4f6" category="paragraph">Un ulteriore vantaggio dell'utilizzo di NVMe-of per vVol è che non sono richieste di bind da parte del provider VASA. L'host ESXi gestisce invece la funzionalità di binding vVol internamente in base a VPE. In questo modo si riduce l'opportunità di un vVol bind storm di impatto sul servizio.</block>
  <block id="70532c0374111d897ef1176b34b6396c" category="inline-link">NVMe e volumi virtuali</block>
  <block id="50ec55042a7f4e8c2c66219ac096cfb3" category="inline-link">vmware.com</block>
  <block id="e9b69020d11d23b42467fb43e2b5c80c" category="paragraph">Per ulteriori informazioni, vedere<block ref="1bbd67ae1166ecc3eaab633c8c9a14a7" category="inline-link-rx"></block> acceso<block ref="e65dbf61eaf823035eb0d06d70cc3509" category="inline-link-rx"></block></block>
  <block id="2d3573b991474634483daf9b3a9ed091" category="cell">*Virtual Volume Datastore*</block>
  <block id="b945cda41d7a84e7152e09343a17cbe6" category="cell">Il datastore del volume virtuale è una rappresentazione logica del datastore di un container vVol creato e gestito da un provider VASA. Il container rappresenta un pool di capacità di storage fornito dai sistemi storage gestiti dal provider VASA. Gli strumenti ONTAP supportano l'allocazione di più volumi FlexVol (noti come volumi di backup) a un singolo datastore vVols e questi datastore vVols possono estendersi su più nodi in un cluster ONTAP, combinando sistemi flash e ibridi con funzionalità diverse. L'amministratore può creare nuovi volumi FlexVol utilizzando la procedura guidata di provisioning o l'API REST oppure selezionare volumi FlexVol pre-creati per il backup dello storage, se disponibili.</block>
  <block id="c25d2cc7c6540f6ac98af67455eecc39" category="cell">*Volumi virtuali (vVol)*</block>
  <block id="9664cdf7951789389813facac649fec1" category="cell">I vVol sono i file e i dischi della macchina virtuale memorizzati nel datastore vVols. Il termine vVol (singolo) si riferisce a un singolo file, LUN o namespace specifico. ONTAP crea spazi dei nomi NVMe, LUN o file a seconda del protocollo utilizzato dal datastore. Esistono diversi tipi distinti di vVol; i più comuni sono Config (file di metadati), Data (disco virtuale o VMDK) e Swap (creato all'accensione della macchina virtuale). I vVol protetti dalla crittografia delle macchine virtuali VMware sono di tipo Altro. La crittografia di VMware VM non deve essere confusa con la crittografia aggregata o del volume ONTAP.</block>
  <block id="0be3366e739971ddaa9bc935c736579e" category="section-title">Gestione basata su policy</block>
  <block id="067a0f759e08dcc21ea50aaa1e92da40" category="paragraph">Le API VMware vSphere per la consapevolezza dello storage (VASA) semplificano l'utilizzo da parte di un amministratore delle macchine virtuali delle funzionalità di storage necessarie per il provisioning delle macchine virtuali senza dover interagire con il proprio team di storage. Prima di VASA, gli amministratori delle macchine virtuali potevano definire le policy di storage delle macchine virtuali, ma dovevano collaborare con gli amministratori dello storage per identificare gli archivi dati appropriati, spesso utilizzando la documentazione o le convenzioni di denominazione. Con VASA, gli amministratori di vCenter con le autorizzazioni appropriate possono definire una serie di funzionalità di storage che gli utenti di vCenter possono utilizzare per eseguire il provisioning delle macchine virtuali. La mappatura tra policy di storage delle macchine virtuali e profilo di funzionalità di storage del datastore consente a vCenter di visualizzare un elenco di datastore compatibili per la selezione, nonché di abilitare altre tecnologie come aria (precedentemente nota come vRealize) Automation o Tanzu Kubernetes Grid per selezionare automaticamente lo storage da una policy assegnata. Questo approccio è noto come gestione basata su policy di storage. Anche se i profili e le policy delle funzionalità di storage possono essere utilizzati anche con i datastore tradizionali, la nostra attenzione qui è dedicata agli archivi dati vVols.</block>
  <block id="631bdc7de6608fd57c3fa0b397c3c26f" category="paragraph">Esistono due elementi:</block>
  <block id="a156a7f38a3727ce705b5466eb11e0bf" category="cell">*Storage Capability Profile (SCP)*</block>
  <block id="43a258e66ca875fa9c5d3e35e06ba2b7" category="cell">Un SCP (Storage Capability Profile) è un modello di storage che consente all'amministratore di vCenter di definire le funzionalità di storage necessarie senza dover comprendere come gestire tali funzionalità in ONTAP. Adottando un approccio basato su modelli, l'amministratore può fornire facilmente servizi di storage in modo coerente e prevedibile. Le funzionalità descritte in un SCP includono performance, protocollo, efficienza dello storage e altre funzionalità. Le funzionalità specifiche variano in base alla versione. Vengono creati utilizzando il menu ONTAP Tools per VMware vSphere all'interno dell'interfaccia utente di vCenter. È inoltre possibile utilizzare le API REST per creare SCP. Possono essere creati manualmente selezionando singole funzionalità o generati automaticamente da datastore esistenti (tradizionali).</block>
  <block id="8f50a0757d99fe5dd0df8d19478d4921" category="cell">*Criterio di storage delle macchine virtuali*</block>
  <block id="f99c5cf9298b040025bd3dfe966cb86e" category="cell">I criteri di storage delle macchine virtuali vengono creati in vCenter in Criteri e profili. Per i vVol, creare un set di regole utilizzando le regole del provider del tipo di storage NetApp vVols. Gli strumenti di ONTAP offrono un approccio semplificato, consentendo di selezionare semplicemente un SCP piuttosto che obbligare a specificare singole regole.</block>
  <block id="5dda8b04866334dc92ee08001b15701a" category="paragraph">Come indicato in precedenza, l'utilizzo delle policy consente di ottimizzare l'attività di provisioning di un volume. È sufficiente selezionare una policy appropriata e il provider VASA mostrerà gli archivi dati vVol che supportano tale policy e inserirà vVol in un singolo volume FlexVol conforme (Figura 1).</block>
  <block id="2ce0d6ec59cca7e0b6e0bdc389301e63" category="section-title">Implementare la macchina virtuale utilizzando i criteri di storage</block>
  <block id="e0795f8b847058e171dec5a519757ece" category="image-alt">Implementare la macchina virtuale utilizzando i criteri di storage</block>
  <block id="f0d0f0a6174a5a9dde27782042e22ccf" category="paragraph">Una volta eseguito il provisioning di una macchina virtuale, il provider VASA continua a controllare la conformità e avvisa l'amministratore della macchina virtuale con un allarme in vCenter quando il volume di backup non è più conforme al criterio (Figura 2).</block>
  <block id="941431bc1cecb0ec5e89e78e9a5a96fc" category="section-title">Conformità delle policy di storage delle macchine virtuali</block>
  <block id="bfd6dec22a6a1724ff1b67f1f289cdfc" category="image-alt">Conformità alle policy di storage delle macchine virtuali</block>
  <block id="b9912aff6d744f574bb75b206dbd65be" category="section-title">Supporto di NetApp vVol</block>
  <block id="234ad0324c313ec05d0fa6fe8d430967" category="paragraph">NetApp ONTAP ha supportato la specifica VASA dalla sua release iniziale nel 2012. Sebbene altri sistemi storage NetApp possano supportare VASA, questo documento si concentra sulle versioni attualmente supportate di ONTAP 9.</block>
  <block id="4d53a8e49ac64213ffccdd970a35171e" category="paragraph">Oltre a ONTAP 9 su sistemi AFF, ASA e FAS, NetApp supporta i workload VMware su ONTAP Select, Amazon FSX per NetApp ONTAP con VMware Cloud su AWS, Azure NetApp Files con Azure VMware, Cloud Volumes Service con Google Cloud VMware Engine e NetApp Private Storage in Equinix, tuttavia, le funzionalità specifiche possono variare in base al provider di servizi e alla connettività di rete disponibile. È inoltre disponibile l'accesso dai guest vSphere ai dati memorizzati in tali configurazioni e a Cloud Volumes ONTAP.</block>
  <block id="9fe1fd556b933358881222d5c3da127c" category="paragraph">Al momento della pubblicazione, gli ambienti hyperscaler sono limitati solo agli archivi dati NFS v3 tradizionali, pertanto i vVol sono disponibili solo con sistemi ONTAP on-premise o con sistemi connessi al cloud che offrono la funzionalità completa di sistemi on-premise come quelli ospitati da partner e provider di servizi NetApp in tutto il mondo.</block>
  <block id="274bc582ca884fc158ea9ac9f79f9067" category="inline-link">Documentazione del prodotto ONTAP</block>
  <block id="36fba59f04e9066c552290e066dffde5" category="paragraph">_Per ulteriori informazioni su ONTAP, vedere<block ref="52ff2f282165f570ea77ca1c156cb56d" category="inline-link-rx"></block>_</block>
  <block id="3dffa984dadf9ff0006ee9cebd3b04b9" category="inline-link">TR-4597</block>
  <block id="8a80e07cc18b73a5c935d858ef13914b" category="paragraph">_Per ulteriori informazioni sulle Best practice di ONTAP e VMware vSphere, vedere<block ref="deb8d9d3730cc967d1b68a2ce611292b" category="inline-link-rx"></block>_</block>
  <block id="0433b6b62a2290665dd4be95b797a1a5" category="section-title">Vantaggi dell'utilizzo di vVol con ONTAP</block>
  <block id="d0f004282063136e91d76d1d43d7c95f" category="paragraph">Quando VMware ha introdotto il supporto vVol con VASA 2.0 nel 2015, lo ha descritto come "un framework di integrazione e gestione che offre un nuovo modello operativo per lo storage esterno (SAN/NAS)". Questo modello operativo offre diversi vantaggi insieme allo storage ONTAP.</block>
  <block id="268208b0fa10cfeb5423cddf7639a4fb" category="paragraph">Come descritto nella sezione 1.2, la gestione basata su policy consente il provisioning e la gestione delle macchine virtuali mediante policy predefinite. Questo può aiutare le operazioni IT in diversi modi:</block>
  <block id="e0eb51b6d319e14c2fbfc1f628021a26" category="list-text">*Aumentare la velocità.* i tool ONTAP eliminano il requisito per l'amministratore di vCenter di aprire i ticket con il team di storage per le attività di provisioning dello storage. Tuttavia, i ruoli RBAC dei tool ONTAP in vCenter e nel sistema ONTAP consentono ancora ai team indipendenti (come i team di storage) o alle attività indipendenti dello stesso team limitando l'accesso a funzioni specifiche, se necessario.</block>
  <block id="3f4dbd6687bd0d55bf69fe5fdd0137c4" category="list-text">*Provisioning più intelligente.* le funzionalità del sistema di storage possono essere esposte attraverso le API VASA, consentendo ai flussi di lavoro di provisioning di sfruttare funzionalità avanzate senza che l'amministratore delle macchine virtuali debba comprendere come gestire il sistema di storage.</block>
  <block id="a13fcc9220d042cae454e9ac073636ca" category="list-text">*Provisioning più rapido.* diverse funzionalità di storage possono essere supportate in un singolo datastore e selezionate automaticamente in base alla policy della macchina virtuale.</block>
  <block id="eb4c052226108afebf26e670208b9a55" category="list-text">*Evitare errori.* le policy di storage e macchine virtuali vengono sviluppate in anticipo e applicate in base alle necessità senza dover personalizzare lo storage ogni volta che viene eseguito il provisioning di una macchina virtuale. Gli allarmi di compliance vengono generati quando le funzionalità dello storage si scostano dalle policy definite. Come accennato in precedenza, gli SCP rendono il provisioning iniziale prevedibile e ripetibile, mentre basare le policy di storage delle macchine virtuali sugli SCP garantisce un posizionamento preciso.</block>
  <block id="9c520768a1d84268417335cf19a423b9" category="list-text">*Migliore gestione della capacità.* i tool VASA e ONTAP consentono di visualizzare la capacità dello storage fino al livello di aggregato induviale, se necessario, e di fornire più livelli di avviso nel caso in cui la capacità inizi a diminuire.</block>
  <block id="cd112acf7e8dafcc4d31529c179bbcf2" category="section-title">Gestione granulare delle macchine virtuali sulla MODERNA SAN</block>
  <block id="7e673a7c12cc256f29bcd7b2028d9d5a" category="paragraph">I sistemi storage SAN che utilizzano Fibre Channel e iSCSI sono stati i primi ad essere supportati da VMware per ESX, ma non hanno la capacità di gestire singoli file e dischi VM dal sistema storage. Al contrario, vengono forniti i LUN e VMFS gestisce i singoli file. Questo rende difficile per il sistema storage gestire direttamente le performance, la clonazione e la protezione dello storage delle singole macchine virtuali. VVol offre una granularità dello storage di cui già godono i clienti che utilizzano lo storage NFS, con le solide funzionalità SAN ad alte performance di ONTAP.</block>
  <block id="25a46370807e0eab0dfe3853abfb9b6e" category="paragraph">Ora, con gli strumenti vSphere 8 e ONTAP per VMware vSphere 9.12 e versioni successive, gli stessi controlli granulari utilizzati da vVol per i protocolli basati su SCSI legacy sono ora disponibili nella MODERNA SAN Fibre Channel che utilizza NVMe over Fabrics per ottenere performance ancora maggiori su larga scala. Con vSphere 8.0 update 1, è ora possibile implementare una soluzione NVMe end-to-end completa utilizzando vVol senza alcuna traduzione i/o nello stack di storage dell'hypervisor.</block>
  <block id="affa13d28700e0060e34417134ab94db" category="section-title">Maggiori funzionalità di offload dello storage</block>
  <block id="911fa02c34dda38cd69be06e524ed9d0" category="inline-link">Garanzia di efficienza</block>
  <block id="cda23566f54cf2f58e1e17a5be9d881e" category="paragraph">Mentre VAAI offre una varietà di operazioni che vengono trasferite allo storage, ci sono alcune lacune che vengono affrontate dal provider VASA. SAN VAAI non è in grado di trasferire le snapshot gestite da VMware al sistema storage. NFS VAAI è in grado di trasferire le snapshot gestite da macchine virtuali, ma esistono dei limiti per una macchina virtuale con snapshot native dello storage. Poiché i vVol utilizzano LUN, spazi dei nomi o file singoli per i dischi delle macchine virtuali, ONTAP può clonare in modo rapido ed efficiente i file o le LUN per creare snapshot granulari delle macchine virtuali che non richiedono più file delta. Inoltre, NFS VAAI non supporta operazioni di offload dei cloni per le migrazioni vMotion di storage a caldo (attivate). La macchina virtuale deve essere spenta per consentire l'offload della migrazione quando si utilizza VAAI con datastore NFS tradizionali. Il provider VASA negli strumenti ONTAP consente cloni quasi istantanei ed efficienti in termini di storage per le migrazioni a caldo e a freddo e supporta anche copie quasi istantanee per le migrazioni tra volumi di vVol. Grazie a questi significativi vantaggi in termini di efficienza dello storage, è possibile sfruttare al meglio i carichi di lavoro vVol in base a.<block ref="9d1af7a9d4f98887e53c1a9bedbce044" category="inline-link-rx"></block> programma. Allo stesso modo, se i cloni di più volumi che utilizzano VAAI non soddisfano i tuoi requisiti, probabilmente sarai in grado di risolvere la tua sfida di business grazie ai miglioramenti nell'esperienza di copia con vVol.</block>
  <block id="1151f86acf76dcbcfbc0e19217266c11" category="section-title">Casi di utilizzo comuni per vVol</block>
  <block id="48e535b80538b088fd868fde9372715c" category="paragraph">Oltre a questi vantaggi, vediamo anche questi casi di utilizzo comuni per lo storage vVol:</block>
  <block id="2f5b22aa750f7fdaa3605bfcafb0b16e" category="list-text">*Provisioning on-demand delle macchine virtuali*</block>
  <block id="bd652a918164d8fa5176b5f9b92c2e61" category="list-text">Cloud privato o provider di servizi IaaS.</block>
  <block id="fddccd9595370687015a5ab02bcff60f" category="list-text">Sfrutta l'automazione e l'orchestrazione tramite la suite aria (in precedenza vRealize), OpenStack, ecc.</block>
  <block id="4fbc1141a40f5259e3ab1545de52b1ea" category="list-text">*Dischi di prima classe (FCD)*</block>
  <block id="e83f2e4e8676ee8faac4d6af599fd7e7" category="list-text">VMware Tanzu Kubernetes Grid [TKG] volumi persistenti.</block>
  <block id="b2b81490f2245d3d566e0ccc6a29cfc2" category="list-text">Fornire servizi di Amazon EBS attraverso una gestione indipendente del ciclo di vita VMDK.</block>
  <block id="2511e4e8cbb72027ae20f24008d4b939" category="list-text">*Provisioning on-demand delle macchine virtuali temporanee*</block>
  <block id="eeb1044cc319a5d53503e45dbf762291" category="list-text">Laboratori di test/sviluppo</block>
  <block id="858d314810762abccaa7baf230e3dc18" category="list-text">Ambienti di training</block>
  <block id="ab7bbc294bf0f0354980a3014e8f4219" category="section-title">Vantaggi comuni con vVol</block>
  <block id="ccd6ea8c57e93a5401d07aab9c60f371" category="paragraph">Se utilizzato a pieno vantaggio, come nei casi di utilizzo precedenti, i vVol forniscono i seguenti miglioramenti specifici:</block>
  <block id="e039663980918c0c93d4ec65b03f0ce5" category="list-text">I cloni vengono creati rapidamente all'interno di un singolo volume o su più volumi in un cluster ONTAP, un vantaggio rispetto ai cloni abilitati VAAI tradizionali. Sono inoltre efficienti in termini di storage. I cloni all'interno di un volume utilizzano il clone di file ONTAP, che sono come i volumi FlexClone^® e memorizzano solo le modifiche dal file vVol di origine/LUN/namespace. In questo modo, le macchine virtuali a lungo termine per la produzione o altri scopi applicativi vengono create rapidamente, occupano poco spazio e possono beneficiare della protezione a livello di macchine virtuali (utilizzando il plug-in NetApp SnapCenter per VMware vSphere, le snapshot gestite da VMware o il backup VADP) e della gestione delle performance (con QoS ONTAP).</block>
  <block id="1c21847cdc5616af138ba0c03aad7adb" category="list-text">I vVol sono la tecnologia di storage ideale quando si utilizza TKG con vSphere CSI, fornendo classi di storage e capacità discrete gestite dall'amministratore di vCenter.</block>
  <block id="d5f068caef73978a5483badd927a7e98" category="list-text">Amazon EBS-like Services può essere fornito attraverso FCD perché un FCD VMDK, come suggerisce il nome, è un cittadino di prima classe in vSphere e ha un ciclo di vita che può essere gestito in modo indipendente separato dalle macchine virtuali a cui potrebbe essere collegato.</block>
  <block id="f890e0e534ac6a9b784c8bb0400fff41" category="cell">05/23/2023</block>
  <block id="3999d762a7e0bf52c3b5bb4c81e69fa3" category="cell">Aggiunto TR-4400: Volumi virtuali VMware vSphere (vVol) con NetApp ONTAP</block>
  <block id="cbed44df5ec7c45f2ff978c1548b0a51" category="cell">Aggiunto il nuovo TR-4974: Oracle 19c in Standalone Restart su AWS FSX/EC2 con NFS/ASM</block>
  <block id="ff1acb029b62c5c8f2a7b9fa9cd89004" category="doc">TR-4974: Oracle 19c in Standalone Restart su AWS FSX/EC2 con NFS/ASM</block>
  <block id="883c8d1cbd39f9d229e4d41d04637d5c" category="sidebar">Volumi virtuali VMware vSphere (vVol) con NetApp ONTAP</block>
  <block id="ade715591998b800c1cfe73575a49726" category="inline-link-macro">VIDEO: Integrazione DEL cluster ROSA con Amazon FSX per ONTAP</block>
  <block id="c8e393d522db54d3ac719e4998c2a654" category="paragraph"><block ref="c8e393d522db54d3ac719e4998c2a654" category="inline-link-macro-rx"></block></block>
  <block id="f8fb2d5adf2db87cf9d33e114cb80575" category="inline-link-macro">Dimostrazione degli scenari di failover e fail-back delle applicazioni utilizzando BlueXP e il CD Argo</block>
  <block id="55df569a88370497c8ccff939f1cdbf8" category="paragraph">Il seguente video è un <block ref="b4091ac5968eba755149e6cb1c2edfa3" category="inline-link-macro-rx"></block>.</block>
  <block id="66ed0c3109a99ed48b8e19b3ea3e112e" category="inline-link-macro">Integrazione di FSxN con Astra Trident per cluster ROSA</block>
  <block id="ffcb76e0c60e5a44b49519333dd0194c" category="list-text">Video dimostrativo: <block ref="58850cfea1fa121cea81f72dd009fa05" category="inline-link-macro-rx"></block></block>
  <block id="201e9faa1242e9b7183ff586a3ba3c2a" category="inline-link-macro">Backup di un'applicazione ROSA in esecuzione in una regione e ripristino in un'altra regione</block>
  <block id="abcb712f64351f6c5f0472721b87f5ae" category="paragraph">Il seguente video mostra <block ref="2dc8a5a2bc86074ad0a0e8e7f4e5b318" category="inline-link-macro-rx"></block>.</block>
  <block id="71a6bd696d2fae9b814517a7d92bfcbc" category="list-text"><block ref="71a6bd696d2fae9b814517a7d92bfcbc" category="inline-link-macro-rx"></block></block>
  <block id="388300e739012da938a81f6e1af1ff39" category="list-text"><block ref="388300e739012da938a81f6e1af1ff39" category="inline-link-macro-rx"></block></block>
  <block id="36157c9e209c8979447922ce87de3cd1" category="list-text"><block ref="36157c9e209c8979447922ce87de3cd1" category="inline-link-macro-rx"></block></block>
  <block id="817764a04f7d60378db2e847654c1539" category="list-text"><block ref="817764a04f7d60378db2e847654c1539" category="inline-link-macro-rx"></block></block>
  <block id="fee8fe82e522035a7aceafec3c7eb139" category="list-text"><block ref="fee8fe82e522035a7aceafec3c7eb139" category="inline-link-macro-rx"></block></block>
  <block id="36b649d911c5a639f1a7816791db7984" category="list-text"><block ref="36b649d911c5a639f1a7816791db7984" category="inline-link-macro-rx"></block></block>
  <block id="d630c209c8c42a9406fc5a34012e63ca" category="list-text"><block ref="d630c209c8c42a9406fc5a34012e63ca" category="inline-link-macro-rx"></block></block>
  <block id="6f3aa8cc391e48ef33c0bac1f0a61bcc" category="list-text"><block ref="6f3aa8cc391e48ef33c0bac1f0a61bcc" category="inline-link-macro-rx"></block></block>
  <block id="e43c7c28921efd6b3b8317da66940803" category="inline-link-macro">Dimostrazione della migrazione a VMotion con VMware HCX per VMC e FSxN</block>
  <block id="da7eb811cbd17bba8f12f27f38257f1d" category="list-text"><block ref="da7eb811cbd17bba8f12f27f38257f1d" category="inline-link-macro-rx"></block></block>
  <block id="5e3367880386fc41e711938f4bf627af" category="list-text"><block ref="5e3367880386fc41e711938f4bf627af" category="inline-link-macro-rx"></block></block>
  <block id="00d1fad18d0809f0c14b55e102486400" category="list-text"><block ref="00d1fad18d0809f0c14b55e102486400" category="inline-link-macro-rx"></block></block>
  <block id="4b8895eff9d52e0e8afb0ed211727598" category="list-text"><block ref="4b8895eff9d52e0e8afb0ed211727598" category="inline-link-macro-rx"></block></block>
  <block id="abe35f29ee68aeb6f84de5c4079074fb" category="list-text"><block ref="abe35f29ee68aeb6f84de5c4079074fb" category="inline-link-macro-rx"></block></block>
  <block id="003c1dd7b840f8456c4791182c9fde5a" category="list-text"><block ref="003c1dd7b840f8456c4791182c9fde5a" category="inline-link-macro-rx"></block></block>
  <block id="84921f8cc2bf20286ae17b9de74106a0" category="list-text"><block ref="84921f8cc2bf20286ae17b9de74106a0" category="inline-link-macro-rx"></block></block>
  <block id="af40f0e9ced2e668b6f08b591e4e8597" category="list-text"><block ref="af40f0e9ced2e668b6f08b591e4e8597" category="inline-link-macro-rx"></block></block>
  <block id="758b02fccea165bc8dfebac1544de665" category="list-text"><block ref="758b02fccea165bc8dfebac1544de665" category="inline-link-macro-rx"></block></block>
  <block id="e1ad6dfb06d02a2a99475f773655cd57" category="list-text"><block ref="e1ad6dfb06d02a2a99475f773655cd57" category="inline-link-macro-rx"></block></block>
  <block id="6f0facf1f54443bdc599b2133f9e4f4b" category="list-text"><block ref="6f0facf1f54443bdc599b2133f9e4f4b" category="inline-link-macro-rx"></block></block>
  <block id="e9a701073b3fd8acabf1bad2951a244e" category="list-text"><block ref="e9a701073b3fd8acabf1bad2951a244e" category="inline-link-macro-rx"></block></block>
  <block id="a0c46f7ca88d42325d9a279391f96391" category="inline-link-macro">Data Protection in pipeline ci/CD con Astra Control Center</block>
  <block id="22d2f4e375e6a1f84fdb3832953f4f7f" category="list-text"><block ref="22d2f4e375e6a1f84fdb3832953f4f7f" category="inline-link-macro-rx"></block></block>
  <block id="db562544764617393e919acaad8fd8b1" category="list-text"><block ref="db562544764617393e919acaad8fd8b1" category="inline-link-macro-rx"></block></block>
  <block id="6b8847bb26c687aff3755cd309c49318" category="inline-link-macro">Accelera lo sviluppo del software con Astra Control e la tecnologia FlexClone di NetApp</block>
  <block id="40b6826b067b46ed179407428b912a14" category="list-text"><block ref="40b6826b067b46ed179407428b912a14" category="inline-link-macro-rx"></block></block>
  <block id="92a855a1b8d950731fa531dc04dd0f9d" category="paragraph">I seguenti video mostrano alcune delle funzionalità documentate in questo documento:</block>
  <block id="a52898916cc1d93c0528b275e6753070" category="inline-link-macro">Accelera lo sviluppo del software con Astra Control e la tecnologia NetApp FlexClone - Red Hat OpenShift con NetApp</block>
  <block id="bc8cba96dcc9500f49d8351817ec2ab9" category="list-text"><block ref="bc8cba96dcc9500f49d8351817ec2ab9" category="inline-link-macro-rx"></block></block>
  <block id="c96541f511f34e58176bb7aa13511ea5" category="inline-link-macro">Migrazione dei workload con Centro di controllo Astra - Red Hat OpenShift con NetApp</block>
  <block id="ccdfb787e2e36aa03d5103295bdcf8e2" category="list-text"><block ref="ccdfb787e2e36aa03d5103295bdcf8e2" category="inline-link-macro-rx"></block></block>
  <block id="1fc270be1b5f2a77ff5dc8c38eef8377" category="list-text"><block ref="1fc270be1b5f2a77ff5dc8c38eef8377" category="inline-link-macro-rx"></block></block>
  <block id="f572afcba8a95128ddd328e44a23a189" category="inline-link-macro">Installazione della virtualizzazione OpenShift - Red Hat OpenShift con NetApp</block>
  <block id="8f38ce4604b19a8754310e38a5830e55" category="list-text"><block ref="8f38ce4604b19a8754310e38a5830e55" category="inline-link-macro-rx"></block></block>
  <block id="c9e349766e4968ee277d240ff7b169e6" category="inline-link-macro">Implementazione di una macchina virtuale con virtualizzazione OpenShift - Red Hat OpenShift con NetApp</block>
  <block id="6298a01de37c23ee55503f9d1b58a421" category="list-text"><block ref="6298a01de37c23ee55503f9d1b58a421" category="inline-link-macro-rx"></block></block>
  <block id="e110e2333a8febc7917146824eb919fd" category="inline-link-macro">NetApp HCI per Red Hat OpenShift sulla virtualizzazione Red Hat</block>
  <block id="9757cd789c0e1ed35924aecd3b72bd8f" category="list-text"><block ref="9757cd789c0e1ed35924aecd3b72bd8f" category="inline-link-macro-rx"></block></block>
  <block id="176e18501cba531e3471815ba9a59850" category="inline-link-macro">Utilizza Astra Trident per eseguire il provisioning dello storage persistente in VMware Tanzu - VMware Tanzu con NetApp</block>
  <block id="105ec97636a71578534f9edb06858fd6" category="list-text"><block ref="105ec97636a71578534f9edb06858fd6" category="inline-link-macro-rx"></block></block>
  <block id="c16700d624be3fd2dae451c45971452e" category="inline-link-macro">Utilizza il centro di controllo Astra per clonare le applicazioni in VMware Tanzu - VMware Tanzu con NetApp</block>
  <block id="a982ae8c95911d1a875df77c1a52b14a" category="list-text"><block ref="a982ae8c95911d1a875df77c1a52b14a" category="inline-link-macro-rx"></block></block>
  <block id="f02831926b719e575a346f87ac04a87e" category="admonition">Queste demo sono state registrate come anteprima tecnica utilizzando la versione 1.3.1 di TKG e la versione 21.12 di Astra Control Center. Consulta la matrice di supporto per le versioni ufficiali supportate.</block>
  <block id="fa7c3c752a982d726108dc5492181d9f" category="inline-link-macro">Implementazione di anthos su bare metal - anthos con NetApp</block>
  <block id="caf5a3c16432b74b4ccbe6776e6cd8e9" category="list-text"><block ref="caf5a3c16432b74b4ccbe6776e6cd8e9" category="inline-link-macro-rx"></block></block>
  <block id="1c8f005f3181fbcbb6ddbfcddf51852b" category="inline-link-macro">VIDEO: Protezione di SQL VM con SnapCenter</block>
  <block id="02d9a97cbba5909dfa25fa7f69a6dd64" category="paragraph"><block ref="02d9a97cbba5909dfa25fa7f69a6dd64" category="inline-link-macro-rx"></block></block>
  <block id="c21a77013b3aef1dd08dc7c4b96bbed3" category="inline-link-macro">VIDEO: Replica Veeam di SQL VM</block>
  <block id="e51211c534350ee4f4efdbabff96dc39" category="paragraph"><block ref="e51211c534350ee4f4efdbabff96dc39" category="inline-link-macro-rx"></block></block>
  <block id="8fecf29320ad59188acc8216233f31a8" category="inline-link-macro">VIDEO: Failover di SQL VM</block>
  <block id="6a3d39507033afd82699f9b9047f2652" category="paragraph"><block ref="6a3d39507033afd82699f9b9047f2652" category="inline-link-macro-rx"></block></block>
  <block id="cb01858134220220fc17af0ed61b6ec6" category="inline-link-macro">segui il video dettagliato</block>
  <block id="50204c1aeb418a9d4e9aae7cfedae231" category="paragraph">Per ulteriori informazioni su questo processo, non esitare a <block ref="964dac3586dc14d6b923e746f0773ecd" category="inline-link-macro-rx"></block>.</block>
  <block id="6c34509649c5f63230e4145b6f36c0da" category="paragraph">Per ulteriori informazioni su questo processo, non esitare a <block ref="b40e2696579d0c9abee322831e822ef1" category="inline-link-macro-rx"></block>.</block>
  <block id="fd905228252968e30159ddaf6b50a819" category="inline-link-macro">Guarda un video che spiega questo processo.</block>
  <block id="03f2db2657b7aac1b8b02a6f2ef447b8" category="paragraph"><block ref="03f2db2657b7aac1b8b02a6f2ef447b8" category="inline-link-macro-rx"></block></block>
  <block id="03902293420f82fb82005c74d6585bd6" category="inline-link-macro">Guarda un video che spiega questa fase.</block>
  <block id="1a5bbc34e788151c599920c6662d0543" category="paragraph"><block ref="1a5bbc34e788151c599920c6662d0543" category="inline-link-macro-rx"></block></block>
  <block id="f6cb5d265c266320c3d40f04afb21ecf" category="inline-link-macro">Montare Amazon FSX per ONTAP Volumes su VMC SDDC</block>
  <block id="f7e70a28c0a0cfc716693ebe0f1398f9" category="paragraph"><block ref="f7e70a28c0a0cfc716693ebe0f1398f9" category="inline-link-macro-rx"></block></block>
  <block id="1bc0426a42dc8da25c55d6f8852beec9" category="paragraph"><block ref="1bc0426a42dc8da25c55d6f8852beec9" category="inline-link-macro-rx"></block></block>
  <block id="627b3c41fe5df988246e05db6908af86" category="inline-link-macro">requisiti di spazio e dimensionamento</block>
  <block id="aac915d3befc8db9d5b3a3dee5c7a58a" category="paragraph">Per informazioni dettagliate, fare riferimento a. <block ref="904c80f66e5056357fd992ed854be90e" category="inline-link-macro-rx"></block>.</block>
  <block id="daeb122264557e55234c2004cdaa36e9" category="inline-link-macro">Implementa SQL Server su Amazon EC2 utilizzando AWS FSX per ONTAP</block>
  <block id="ba24a3d4798de52b7ab0cbed150170a1" category="paragraph"><block ref="ba24a3d4798de52b7ab0cbed150170a1" category="inline-link-macro-rx"></block></block>
  <block id="f314f22bf5afea67ed515de0ae918938" category="inline-link-macro">Implementazione e protezione automatizzate del database PostreSQL in AWS EC2/FSX</block>
  <block id="ea8ecea5c68b3f3986c013c41216bde7" category="paragraph"><block ref="ea8ecea5c68b3f3986c013c41216bde7" category="inline-link-macro-rx"></block></block>
  <block id="6bf42fd64d83f6451d1acd2cfbdd1ec6" category="list-text"><block ref="6bf42fd64d83f6451d1acd2cfbdd1ec6" category="inline-link-macro-rx"></block></block>
  <block id="ff1a0374aa003a5c50bcc68762f43ee5" category="list-text"><block ref="ff1a0374aa003a5c50bcc68762f43ee5" category="inline-link-macro-rx"></block></block>
  <block id="eb6d202d5596336c272b99d41ff7a35b" category="list-text"><block ref="eb6d202d5596336c272b99d41ff7a35b" category="inline-link-macro-rx"></block></block>
  <block id="2aa07559b2f406272e092d18777b4b80" category="list-text"><block ref="2aa07559b2f406272e092d18777b4b80" category="inline-link-macro-rx"></block></block>
  <block id="d26980e842e8f83f7d733162a7c95047" category="inline-link-macro">Backup/ripristino SaaS di SnapCenter con console BlueXP di NetApp</block>
  <block id="7ce639392a263e2e2411a5001d30055a" category="paragraph"><block ref="7ce639392a263e2e2411a5001d30055a" category="inline-link-macro-rx"></block></block>
  <block id="7dd562f7c78c1dd7cf2b7d454ceb2b8b" category="list-text"><block ref="7dd562f7c78c1dd7cf2b7d454ceb2b8b" category="inline-link-macro-rx"></block></block>
  <block id="cdc0f3bf4319566033942309f5be7428" category="list-text"><block ref="cdc0f3bf4319566033942309f5be7428" category="inline-link-macro-rx"></block></block>
  <block id="fba1eaafef41cd910ba38a2de7aa7816" category="list-text"><block ref="fba1eaafef41cd910ba38a2de7aa7816" category="inline-link-macro-rx"></block></block>
  <block id="f6df93e0647546f8d9dcd5133e376747" category="list-text"><block ref="f6df93e0647546f8d9dcd5133e376747" category="inline-link-macro-rx"></block></block>
  <block id="ee2f0846f969ae139f76b3e2074538b1" category="list-text"><block ref="ee2f0846f969ae139f76b3e2074538b1" category="inline-link-macro-rx"></block></block>
  <block id="e918336ffb95f3fb92ceb25195bd9494" category="list-text"><block ref="e918336ffb95f3fb92ceb25195bd9494" category="inline-link-macro-rx"></block></block>
  <block id="aa22f75ec52fada146256039b916943d" category="list-text"><block ref="aa22f75ec52fada146256039b916943d" category="inline-link-macro-rx"></block></block>
  <block id="5fbbc8b2dfdaf77ff31cf935e71056f3" category="list-text"><block ref="5fbbc8b2dfdaf77ff31cf935e71056f3" category="inline-link-macro-rx"></block></block>
  <block id="8a166bb9412979684883a9f295166e10" category="inline-link-macro">Implementa SQL Server su AWS EC2 utilizzando Amazon FSX per NetApp ONTAP
</block>
  <block id="a433c14b442ac027fd51cd03e0935cc8" category="list-text"><block ref="a433c14b442ac027fd51cd03e0935cc8" category="inline-link-macro-rx"></block></block>
  <block id="7753495730d0cba86e901996d651c999" category="list-text"><block ref="7753495730d0cba86e901996d651c999" category="inline-link-macro-rx"></block></block>
  <block id="3a30229aa77d2ff319b5648560b5c4fb" category="list-text"><block ref="3a30229aa77d2ff319b5648560b5c4fb" category="inline-link-macro-rx"></block></block>
  <block id="993e64eb12fccfcd60446d9022f4df0f" category="list-text"><block ref="993e64eb12fccfcd60446d9022f4df0f" category="inline-link-macro-rx"></block></block>
  <block id="8856d6754d87bd5cea98aca2dc6bae02" category="cell">Multicloud ibrido con Red Hat</block>
  <block id="ad7299eadf8b7bc851beaaf29efb9fad" category="cell">Definisce NetApp in un modello multicloud ibrido, che include la tecnologia Red Hat nel cloud pubblico e le opzioni di storage NetApp in ciascuno degli hyperscaler.  La landing page ibrida del Multibloud offre contenuti molto diffusi presentati in "tessere" specifici per i contenuti.</block>
  <block id="a4ab3fb5550933627c37dbd35217441e" category="inline-link-macro">Multicloud ibrido con contenuti Red Hat</block>
  <block id="a1e36e03e5410cb33f877c31957cf797" category="cell"><block ref="a1e36e03e5410cb33f877c31957cf797" category="inline-link-macro-rx"></block></block>
  <block id="09ee2ff894d42056476c4e659964e53d" category="cell">8.4.2105</block>
  <block id="fdd2aab0f0128709917906c63ac4ead9" category="cell">18.04.5 LTS (con kernel 5.4.0-81-generico)</block>
  <block id="c8d51ff28b5d8ab2f7a2a108c7318d3e" category="cell">20.04.2 LTS</block>
  <block id="60c153e0ec5ee4601950a2256ca730fa" category="cell">9.11.1P4</block>
  <block id="93edfe5491b7772fd10045fef48289e7" category="cell">23.01.0</block>
  <block id="1126fba791a29eca6a914fb9cc520b2d" category="inline-image-macro">Diagramma hardware fisico Anthos BareMetal</block>
  <block id="59c347a74805b3b681ca29fc54f07d9f" category="paragraph"><block ref="59c347a74805b3b681ca29fc54f07d9f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f95cad6e29b1c5d602bd5bc840867b18" category="inline-image-macro">Diagramma logico della rete Anthos BareMetal</block>
  <block id="ba294d7813cac4403ec9802c03c3e6aa" category="paragraph"><block ref="ba294d7813cac4403ec9802c03c3e6aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57359b8d2b77ce83f2e854fdd323377f" category="paragraph">Con il rilascio di SRM 8.7 e versioni successive e con le versioni 9.12 e successive dei tool ONTAP, è ora possibile proteggere le macchine virtuali in esecuzione su VMware vSphere 8 update 1.</block>
  <block id="59b1c22b20ea1c08eb95a351dd18a01e" category="paragraph">A partire dalla versione 8.3, SRM supporta ora la gestione basata su policy di storage (SPBM) della replica sfruttando vVol e la replica basata su array per gli archivi dati utilizzando iSCSI, FCP e NFS v3. A tale scopo, il server SRM è stato aggiornato per includere un nuovo servizio provider SRM vVol, che comunica con il servizio SMS del server vCenter per le attività correlate a VASA.</block>
  <block id="1b6204fa76bd422416757c4e2d6187bd" category="paragraph">Esempio di architettura vVol con FCP o iSCSI:</block>
  <block id="9abbd7aed7e9791d9c52e8e17f34a756" category="section-title">Supporto per server SRM basati su appliance</block>
  <block id="2a71574e89a69c8218fbac3f604b5728" category="paragraph">Le performance operative sono un requisito fondamentale per l'esecuzione delle attività SRM. Per soddisfare i requisiti degli RTO e degli RPO moderni, l'SRA con gli strumenti ONTAP ha aggiunto tre nuovi miglioramenti.</block>
  <block id="c82379d922d9cdc55fa21affe9f9b8bf" category="list-text">*ONTAP Tools 9.12 ha aggiunto il supporto per la funzionalità di risincronizzazione rapida di ONTAP SnapMirror.* ciò consente una rapida risincronizzazione dei mirror con l'obiettivo di dover ricalcolare i risparmi in termini di efficienza dello storage dopo il processo. Questa funzione non viene utilizzata per impostazione predefinita, ma può essere attivata in ambienti su larga scala in cui la risincronizzazione tradizionale richiede troppo tempo o sta per scadere.</block>
  <block id="10b8f80c23f8a44dfa6b10ae56d7dbe9" category="paragraph">Questo documento è incentrato sulle funzionalità delle recenti release di ONTAP 9, se utilizzato insieme ai tool ONTAP per VMware vSphere 9.12 (che include l'adattatore per la replica dello storage NetApp [SRA] e il provider VASA [VP]), nonché VMware Site Recovery Manager 8.7.</block>
</blocks>