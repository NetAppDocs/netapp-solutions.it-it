---
sidebar: sidebar 
permalink: ai/ai-edge-test-results.html 
keywords: test, results, aff, offline, single-stream, ef 
summary: 'Sono stati eseguiti numerosi test per valutare le performance dell"architettura proposta. Esistono sei diversi carichi di lavoro (classificazione delle immagini, rilevamento degli oggetti [piccoli], rilevamento degli oggetti [grandi], imaging medico, comunicazione vocale, E Natural Language Processing [NLP]), che è possibile eseguire in tre diversi scenari: Offline, single stream e multistream.' 
---
= Risultati del test
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
Sono stati eseguiti numerosi test per valutare le performance dell'architettura proposta.

Esistono sei diversi carichi di lavoro (classificazione delle immagini, rilevamento degli oggetti [piccoli], rilevamento degli oggetti [grandi], imaging medico, comunicazione vocale, E Natural Language Processing [NLP]), che è possibile eseguire in tre diversi scenari: Offline, single stream e multistream.


NOTE: L'ultimo scenario viene implementato solo per la classificazione delle immagini e il rilevamento degli oggetti.

Ciò offre 15 possibili carichi di lavoro, tutti testati in tre diverse configurazioni:

* Server singolo/storage locale
* Storage di rete/server singolo
* Storage di rete/multi-server


I risultati sono descritti nelle sezioni seguenti.



== Inferenza ai nello scenario offline per AFF

In questo scenario, tutti i dati erano disponibili per il server e il tempo impiegato per elaborare tutti i campioni è stato misurato. I risultati dei test riportano le larghezze di banda in campioni al secondo. Quando sono stati utilizzati più server di calcolo, si riporta la larghezza di banda totale sommata su tutti i server. I risultati per tutti e tre i casi di utilizzo sono mostrati nella figura seguente. Per il caso di due server, segnaliamo la larghezza di banda combinata di entrambi i server.

image:ai-edge-image12.png["Figura che mostra la finestra di dialogo input/output o rappresenta il contenuto scritto"]

I risultati mostrano che lo storage di rete non influisce negativamente sulle performance: La modifica è minima e per alcune attività non viene rilevata alcuna. Quando si aggiunge il secondo server, la larghezza di banda totale raddoppia esattamente o, nel peggiore dei casi, la modifica è inferiore all'1%.



== Inferenza ai in uno scenario a flusso singolo per AFF

Questo benchmark misura la latenza. Per il caso di più server di calcolo, segnaliamo la latenza media. I risultati per la suite di attività sono riportati nella figura seguente. Per il caso di due server, segnaliamo la latenza media di entrambi i server.

image:ai-edge-image13.png["Figura che mostra la finestra di dialogo input/output o rappresenta il contenuto scritto"]

I risultati, ancora una volta, mostrano che lo storage di rete è sufficiente per gestire le attività. La differenza tra storage locale e di rete nel caso di un server è minima o nulla. Allo stesso modo, quando due server utilizzano lo stesso storage, la latenza su entrambi i server rimane la stessa o cambia di molto.



== Inferenza ai nello scenario multistream per AFF

In questo caso, il risultato è il numero di flussi che il sistema è in grado di gestire, soddisfacendo al tempo stesso il limite di QoS. Pertanto, il risultato è sempre un numero intero. Per più di un server, viene riportato il numero totale di flussi sommati su tutti i server. Non tutti i carichi di lavoro supportano questo scenario, ma abbiamo eseguito quelli che lo fanno. I risultati dei nostri test sono riassunti nella figura seguente. Per il caso di due server, segnaliamo il numero combinato di flussi da entrambi i server.

image:ai-edge-image14.png["Figura che mostra la finestra di dialogo input/output o rappresenta il contenuto scritto"]

I risultati mostrano le performance perfette dell'installazione: Lo storage locale e di rete offrono gli stessi risultati e l'aggiunta del secondo server raddoppia il numero di flussi gestibili dall'installazione proposta.



== Risultati del test per EF

Sono stati eseguiti numerosi test per valutare le performance dell'architettura proposta. Esistono sei diversi carichi di lavoro (classificazione delle immagini, rilevamento degli oggetti [piccoli], rilevamento degli oggetti [grandi], imaging medico, comunicazione vocale, E Natural Language Processing [NLP]), eseguiti in due scenari diversi: Offline e single stream. I risultati sono descritti nelle sezioni seguenti.



=== Inferenza ai nello scenario offline per EF

In questo scenario, tutti i dati erano disponibili per il server e il tempo impiegato per elaborare tutti i campioni è stato misurato. I risultati dei test riportano le larghezze di banda in campioni al secondo. Per le esecuzioni a nodo singolo, segnaliamo la media di entrambi i server, mentre per due esecuzioni a server segnaliamo la larghezza di banda totale sommata su tutti i server. I risultati dei casi di utilizzo sono mostrati nella figura seguente.

image:ai-edge-image15.png["Figura che mostra la finestra di dialogo input/output o rappresenta il contenuto scritto"]

I risultati mostrano che lo storage di rete non influisce negativamente sulle performance: La modifica è minima e per alcune attività non viene rilevata alcuna. Quando si aggiunge il secondo server, la larghezza di banda totale raddoppia esattamente o, nel peggiore dei casi, la modifica è inferiore all'1%.



=== Inferenza ai in uno scenario a flusso singolo per EF

Questo benchmark misura la latenza. In tutti i casi, segnaliamo la latenza media su tutti i server coinvolti nelle esecuzioni. Vengono forniti i risultati per la suite di attività.

image:ai-edge-image16.png["Figura che mostra la finestra di dialogo input/output o rappresenta il contenuto scritto"]

I risultati mostrano ancora una volta che lo storage di rete è sufficiente per gestire le attività. La differenza tra lo storage locale e di rete nel caso di un server è minima o nulla. Allo stesso modo, quando due server utilizzano lo stesso storage, la latenza su entrambi i server rimane la stessa o cambia di molto.
