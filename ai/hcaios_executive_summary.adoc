---
sidebar: sidebar 
permalink: ai/hcaios_executive_summary.html 
keywords: hybrid cloud, NetApp, AI 
summary:  
---
= TR-4841: Sistema operativo ai per il cloud ibrido con caching dei dati
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


Rick Huang, David Arnette, NetApp Yochay Ettun, cnvrg.io

[role="lead"]
La crescita esplosiva dei dati e la crescita esponenziale di ML e ai sono convergenti per creare un'economia di zettabyte con sfide di sviluppo e implementazione uniche.

Sebbene sia noto che i modelli ML sono affamati di dati e richiedono uno storage dei dati ad alte performance prossimale alle risorse di calcolo, in pratica non è così semplice implementare questo modello, soprattutto con il cloud ibrido e le istanze di calcolo elastiche. In genere, enormi quantità di dati vengono memorizzate in data Lake a basso costo, dove le risorse di calcolo ai dalle performance elevate, come le GPU, non possono accedervi in modo efficiente. Questo problema è aggravato in un'infrastruttura di cloud ibrido in cui alcuni carichi di lavoro operano nel cloud e alcuni si trovano on-premise o in un ambiente HPC completamente diverso.

In questo documento, presentiamo una nuova soluzione che consente ai professionisti IT e ai data engineer di creare una piattaforma di cloud ai realmente ibrido con un data hub consapevole della topologia che consente ai data scientist di creare istantaneamente e automaticamente una cache dei propri set di dati in prossimità delle proprie risorse di calcolo. ovunque si trovino. Di conseguenza, non solo è possibile ottenere un training con modelli ad alte performance, ma si creano anche ulteriori benefici, tra cui la collaborazione di diversi professionisti dell'ai, che hanno accesso immediato a cache, versioni e linee di dati all'interno di un hub di versione del set di dati.
