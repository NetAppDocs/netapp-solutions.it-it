---
sidebar: sidebar 
permalink: ai/cainvidia_conclusion.html 
keywords: Conclusion 
summary:  
---
= Conclusione
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


[role="lead"]
Un vero e proprio sistema di ai conversa si impegna in un dialogo umano, comprende il contesto e fornisce risposte intelligenti. Tali modelli di ai sono spesso enormi e altamente complessi. Con le GPU NVIDIA e lo storage NetApp, è possibile formare e ottimizzare modelli di linguaggio all'avanguardia per eseguire rapidamente l'inferenza. Si tratta di un importante passo avanti verso la fine del compromesso tra un modello di ai veloce e uno grande e complesso. I modelli di comprensione del linguaggio ottimizzati per la GPU possono essere integrati nelle applicazioni di ai per settori come l'assistenza sanitaria, la vendita al dettaglio e i servizi finanziari, alimentando assistenti vocali digitali avanzati in altoparlanti intelligenti e linee di assistenza clienti. Questi sistemi di ai convergenti di alta qualità consentono alle aziende di tutti i mercati verticali di fornire servizi personalizzati precedentemente irraggiungibili quando si impegnano con i clienti.

Jarvis consente l'implementazione di casi di utilizzo come assistenti virtuali, avatar digitali, Fusion del sensore multimodale (CV fuso con ASR/NLP/TTS) o qualsiasi caso di utilizzo autonomo ASR/NLP/TTS/CV, ad esempio la trascrizione. Abbiamo creato un assistente virtuale al dettaglio in grado di rispondere a domande relative a meteo, punti di interesse e prezzi dell'inventario. Abbiamo anche dimostrato come migliorare le capacità di comprensione del linguaggio naturale del sistema ai conversazionale archiviando la cronologia delle conversazioni utilizzando Cloud Sync e formando modelli NEMO su nuovi dati.

link:cainvidia_acknowledgments.html["Avanti: Ringraziamenti"]
