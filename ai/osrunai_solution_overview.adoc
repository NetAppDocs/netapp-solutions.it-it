---
sidebar: sidebar 
permalink: ai/osrunai_solution_overview.html 
keywords:  
summary:  
---
= Panoramica della soluzione
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/




== Piano di controllo ai e ai di NetApp ONTAP

L'architettura NetApp ONTAP ai, sviluppata e verificata da NetApp e NVIDIA, è basata su sistemi NVIDIA DGX e sistemi storage connessi al cloud. Questa architettura di riferimento offre alle organizzazioni IT i seguenti vantaggi:

* Elimina le complessità di progettazione
* Consente una scalabilità indipendente di calcolo e storage
* Consente ai clienti di partire da piccoli e scalare perfettamente
* Offre una gamma di opzioni di storage per diverse performance e costi


NetApp ONTAP ai integra perfettamente i sistemi DGX e i sistemi storage NetApp AFF A800 con reti all'avanguardia. I sistemi NetApp ONTAP ai e DGX semplificano le implementazioni ai eliminando la complessità e le congetture di progettazione. I clienti possono iniziare a crescere in maniera ininterrotta e allo stesso tempo gestire in modo intelligente i dati dall'edge al core, fino al cloud e viceversa.

NetApp ai Control Plane è una soluzione per la gestione di dati e esperimenti di ai, ML e deep learning (DL) per data scientist e data engineer. Man mano che le organizzazioni aumentano l'utilizzo dell'ai, devono affrontare molte sfide, tra cui la scalabilità dei workload e la disponibilità dei dati. NetApp ai Control Plane affronta queste sfide attraverso funzionalità, come la clonazione rapida di uno spazio dei nomi dei dati come faresti con un Git repo, e la definizione e l'implementazione di workflow di training ai che incorporano la creazione quasi istantanea di dati e linee di base dei modelli per la tracciabilità e il controllo delle versioni. Con NetApp ai Control Plane, puoi replicare perfettamente i dati tra siti e regioni e fornire rapidamente spazi di lavoro Jupyter notebook con accesso a set di dati di grandi dimensioni.



== Run:ai Platform for ai workload Orchestration

Run:ai ha costruito la prima piattaforma di orchestrazione e virtualizzazione al mondo per l'infrastruttura ai. Astrando i carichi di lavoro dall'hardware sottostante, Run:ai crea un pool condiviso di risorse GPU che può essere sottoposto a provisioning dinamico, consentendo un'orchestrazione efficiente dei carichi di lavoro ai e un utilizzo ottimizzato delle GPU. I data scientist possono consumare senza problemi enormi quantità di energia GPU per migliorare e accelerare la ricerca, mentre i team IT mantengono un controllo centralizzato e cross-site e una visibilità in tempo reale su provisioning, accodamento e utilizzo delle risorse. La piattaforma Run:ai si basa su Kubernetes, consentendo una semplice integrazione con i flussi di lavoro IT e di data science esistenti.

La piattaforma Run:ai offre i seguenti vantaggi:

* *Time-to-innovation più veloce.* utilizzando i meccanismi di pool di risorse Run:ai, accodamento e prioritizzazione insieme a un sistema storage NetApp, i ricercatori vengono rimossi dai problemi di gestione dell'infrastruttura e possono concentrarsi esclusivamente sulla scienza dei dati. Esegui: I clienti ai e NetApp aumentano la produttività eseguendo tutti i carichi di lavoro necessari senza colli di bottiglia della pipeline di dati o di calcolo.
* *Maggiore produttività del team.* gli algoritmi Run:ai Fairness garantiscono che tutti gli utenti e i team ottenano la loro giusta quota di risorse. È possibile preimpostare le policy relative ai progetti prioritari e la piattaforma consente l'allocazione dinamica delle risorse da un utente o team all'altro, aiutando gli utenti a ottenere un accesso tempestivo alle risorse GPU più ambite.
* *Utilizzo migliorato della GPU.* il programma Run:ai Scheduler consente agli utenti di utilizzare facilmente GPU frazionali, GPU interi e nodi multipli di GPU per la formazione distribuita su Kubernetes. In questo modo, i carichi di lavoro ai vengono eseguiti in base alle tue esigenze, non alla capacità. I team di data science sono in grado di eseguire più esperimenti di ai sulla stessa infrastruttura.

