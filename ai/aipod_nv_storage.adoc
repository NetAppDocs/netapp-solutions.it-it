---
sidebar: sidebar 
permalink: ai/aipod_nv_storage.html 
keywords: NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NVIDIA AI Enterprise, NVIDIA BasePOD, NVIDIA DGX 
summary: Pod NetApp ai con sistemi NVIDIA DGX - Guida al dimensionamento e alla progettazione dei sistemi storage 
---
= Pod NetApp ai con sistemi NVIDIA DGX - Guida al dimensionamento e alla progettazione dei sistemi storage
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:aipod_nv_architecture.html["Precedente: Pod NetApp ai con sistemi NVIDIA DGX - architettura."]



== Progettazione del sistema storage

Ogni sistema storage AFF A800 è connesso tramite quattro porte 100 GbE da ciascun controller. Due porte da ciascun controller sono utilizzate per l'accesso ai dati dei carichi di lavoro dai sistemi DGX e due porte da ciascun controller sono configurate come un gruppo di interfacce LACP per supportare l'accesso dai server di piani di gestione per gli artefatti di gestione dei cluster e le home directory dell'utente. L'accesso ai dati dal sistema storage viene fornito tramite NFS, con una Storage Virtual Machine (SVM) dedicata all'accesso ai workload e una SVM separata dedicata agli utilizzi della gestione del cluster.

Il workload SVM è configurato con un totale di quattro interfacce logiche (LIF), con due LIF su ciascuna VLAN storage. Ogni porta fisica ospita due LIF, che ne generano due LIF per VLAN su ciascun controller. Questa configurazione offre la massima larghezza di banda oltre a mezzi per eseguire il failover di ciascuna LIF in un'altra porta dello stesso controller, in modo che entrambi i controller rimangano attivi in caso di guasto alla rete. Questa configurazione supporta anche NFS su RDMA per abilitare l'accesso allo storage GPUDirect. Il provisioning della capacità dello storage viene eseguito sotto forma di un singolo grande volume di FlexGroup che comprende entrambi i controller. Questo FlexGroup è accessibile da qualsiasi LIF presente nella SVM, e i punti di montaggio dei sistemi DGX A100 sono distribuiti tra le LIF disponibili per il bilanciamento del carico.

La SVM di gestione richiede un singolo LIF, ospitato nei gruppi di interfacce a 2 porte configurati su ciascun controller. Nella SVM di gestione viene eseguito il provisioning di altri volumi FlexGroup per alloggiare elementi legati alla gestione del cluster, come le immagini dei nodi del cluster, i dati storici del monitoraggio del sistema e le home directory degli utenti finali. Il disegno qui sotto mostra la configurazione logica del sistema di archiviazione.

image:oai_basepod1_logical.png["Errore: Immagine grafica mancante"]



== Guida al dimensionamento del sistema storage

Questa architettura è da intendersi come riferimento per clienti e partner che desiderano implementare un'infrastruttura DL con sistemi NVIDIA DGX e sistemi di storage NetApp AFF. La tabella seguente mostra una stima approssimativa del numero di GPU A100 e H100 supportate su ciascun modello AFF.

image:oai_sizing.png["Errore: Immagine grafica mancante"]

Come dimostrato in link:https://www.netapp.com/pdf.html?item=/media/21793-nva-1153-design.pdf["versioni precedenti di questa architettura di riferimento"], Il sistema AFF A800 supporta facilmente il workload di training DL generato da otto sistemi DGX A100. Le stime per gli altri sistemi storage precedenti sono state calcolate in base a questi risultati e le stime per le GPU di H100 sono state calcolate raddoppiando il throughput dello storage necessario per i sistemi A100.  Per implementazioni più estese con requisiti di performance dello storage più elevati, è possibile aggiungere sistemi AFF al cluster NetApp ONTAP fino a 12 coppie ha (24 nodi) in un singolo cluster. Utilizzando la tecnologia FlexGroup descritta in questa soluzione, un cluster a 24 nodi può offrire oltre 40 PB e un throughput fino a 300 Gbps in un singolo namespace. Altri sistemi storage NetApp come AFF A400, A250 e C800 offrono performance e/o capacità superiori per implementazioni più piccole a prezzi inferiori. Poiché ONTAP 9 supporta cluster di modelli misti, i clienti possono partire con un impatto iniziale minore e aggiungere al cluster più sistemi storage o più grandi man mano che crescono i requisiti di capacità e performance.
link:aipod_nv_conclusion.html["Pagina successiva: Pod ai NetApp con sistemi NVIDIA DGX - conclusioni."]
