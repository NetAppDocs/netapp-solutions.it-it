---
sidebar: sidebar 
permalink: ai/aks-anf_conclusion.html 
keywords: 'Azure NetApp Files, RAPIDS AI, click-though rate (CTR) prediction, Machine Learning, Retail, E-commerce, Azure, Jupyter Notebook, Cloud computing, Digital marketing, Kubernetes' 
summary: 'Azure NetApp Files, RAPIDS e Dek accelerano e semplificano l"implementazione di CORSI DI formazione E elaborazione ML su larga scala, integrati con tool di orchestrazione come Docker e Kubernetes. Unificando la pipeline di dati end-to-end, questa soluzione riduce la latenza e la complessità inerenti a molti carichi di lavoro di calcolo avanzati, colmando efficacemente il divario tra sviluppo e operazioni.' 
---
= Conclusione
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
Azure NetApp Files, RAPIDS e Dak accelerano e semplificano l'implementazione dell'elaborazione E della formazione ML su larga scala integrandosi con strumenti di orchestrazione come Docker e Kubernetes. Unificando la pipeline di dati end-to-end, questa soluzione riduce la latenza e la complessità inerenti a molti carichi di lavoro di calcolo avanzati, colmando efficacemente il divario tra sviluppo e operazioni. I data scientist possono eseguire query su set di dati di grandi dimensioni e condividere in modo sicuro dati e modelli algoritmici con altri utenti durante la fase di training.

Quando si creano pipeline ai/ML personalizzate, configurare l'integrazione, la gestione, la sicurezza e l'accessibilità dei componenti in un'architettura è un'attività complessa. Fornire agli sviluppatori l'accesso e il controllo del proprio ambiente presenta un'altra serie di sfide.

Creando un modello di training distribuito end-to-end e una pipeline di dati nel cloud, abbiamo dimostrato un miglioramento di due ordini di grandezza nel tempo totale di completamento del workflow rispetto a un approccio open-source convenzionale che non ha sfruttato i framework di elaborazione e di elaborazione dei dati accelerati dalla GPU.

La combinazione di NetApp, Microsoft, framework di orchestrazione open-source e NVIDIA riunisce le più recenti tecnologie come servizi gestiti con grande flessibilità per accelerare l'adozione della tecnologia e migliorare il time-to-market per le nuove applicazioni ai/ML. Questi servizi avanzati vengono forniti in un ambiente cloud nativo che può essere facilmente trasferito per architetture di implementazione on-premise e ibride.
