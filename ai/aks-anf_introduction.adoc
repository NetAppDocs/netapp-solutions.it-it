---
sidebar: sidebar 
permalink: ai/aks-anf_introduction.html 
keywords: introduction, tr-4904, 4904, tr4904, kubernetes, azure, anf, rapids, dask, ml, ai, machine learning, artificial intelligence, 
summary: 'Questa soluzione segue il ciclo di vita di un"applicazione ai/ML. Iniziamo con il lavoro dei data scientist per definire le diverse fasi necessarie per preparare i dati e formare i modelli. Sfruttando RAPIDS su Dask, eseguiamo training distribuiti nel cluster Azure Kubernetes Service (AKS) per ridurre drasticamente i tempi di training rispetto all"approccio convenzionale di Python scikit-Learn. Per completare il ciclo completo, integriamo la pipeline con Azure NetApp Files.' 
---
= TR-4904: Formazione distribuita in Azure - previsione dei tassi click-through
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


Rick Huang, Verron Martina, Muneer Ahmad, NetApp

[role="lead"]
Il lavoro di un data scientist dovrebbe essere incentrato sulla formazione e sulla messa a punto di modelli di apprendimento automatico (ML) e intelligenza artificiale (ai). Tuttavia, secondo una ricerca condotta da Google, i data scientist dedicano circa il 80% del loro tempo a capire come far funzionare i propri modelli con le applicazioni aziendali e a eseguirlo su larga scala.

Per gestire i progetti ai/ML end-to-end, è necessaria una maggiore comprensione dei componenti aziendali. Sebbene DevOps abbia assunto il controllo della definizione, dell'integrazione e dell'implementazione, questi tipi di componenti, le operazioni ML hanno come obiettivo un flusso simile che include i progetti ai/ML. Per avere un'idea di ciò che una pipeline ai/ML end-to-end tocca nell'azienda, consulta il seguente elenco di componenti richiesti:

* Storage
* Networking
* Database
* File system
* Container
* Pipeline ci/CD (Continuous Integration and Continuous Deployment)
* Ambiente di sviluppo integrato (IDE)
* Sicurezza
* Policy di accesso ai dati
* Hardware
* Cloud
* Virtualizzazione
* Set di strumenti e librerie per le scienze dei dati




== Pubblico di riferimento

Il mondo della scienza dei dati tocca diverse discipline nell'IT e nel business:

* Il data scientist ha bisogno della flessibilità necessaria per utilizzare i propri strumenti e le librerie preferite.
* Il data engineer deve sapere come i dati scorrono e dove risiedono.
* Un tecnico DevOps ha bisogno dei tool per integrare le nuove applicazioni ai/ML nelle pipeline ci/CD.
* Gli amministratori e gli architetti del cloud devono essere in grado di configurare e gestire le risorse di Azure.
* Gli utenti aziendali desiderano avere accesso alle applicazioni ai/ML.


In questo report tecnico, descriviamo in che modo Azure NetApp Files, RAPIDS ai, DAK e Azure aiutano ciascuno di questi ruoli a portare valore al business.



== Panoramica della soluzione

Questa soluzione segue il ciclo di vita di un'applicazione ai/ML. Iniziamo con il lavoro dei data scientist per definire le diverse fasi necessarie per preparare i dati e formare i modelli. Sfruttando RAPIDS su Dask, eseguiamo training distribuiti nel cluster Azure Kubernetes Service (AKS) per ridurre drasticamente i tempi di training rispetto all'approccio convenzionale di Python scikit-Learn. Per completare il ciclo completo, integriamo la pipeline con Azure NetApp Files.

Azure NetApp Files offre diversi livelli di performance. I clienti possono iniziare con un Tier Standard, scalare e scalare fino a un Tier dalle performance elevate senza interruzioni, senza spostare alcun dato. Questa funzionalità consente agli scienziati dei dati di formare modelli su larga scala senza problemi di performance, evitando i silos di dati nel cluster, come mostrato nella figura seguente.

image:aks-anf_image1.png[""]
