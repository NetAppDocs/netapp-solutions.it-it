---
sidebar: sidebar 
permalink: ai/osrunai_achieving_high_cluster_utilization.html 
keywords:  
summary:  
---
= Elevato utilizzo del cluster
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
In questa sezione, emuliamo uno scenario realistico in cui quattro team di data science inviano ciascuno i propri carichi di lavoro per dimostrare la soluzione di orchestrazione Run:ai che raggiunge un elevato utilizzo del cluster mantenendo al contempo la prioritizzazione e il bilanciamento delle risorse GPU. Iniziamo utilizzando il benchmark ResNet-50 descritto nella sezione link:osrunai_resnet-50_with_imagenet_dataset_benchmark_summary.html["ResNet-50 con ImageNet dataset Benchmark Summary"]:

....
$ runai submit netapp1 -i netapp/tensorflow-tf1-py3:20.01.0 --local-image --large-shm  -v /mnt:/mnt -v /tmp:/tmp --command python --args "/netapp/scripts/run.py" --args "--dataset_dir=/mnt/mount_0/dataset/imagenet/imagenet_original/" --args "--num_mounts=2"  --args "--dgx_version=dgx1" --args "--num_devices=1" -g 1
....
Abbiamo eseguito lo stesso benchmark ResNet-50 di https://www.netapp.com/pdf.html?item=/media/7677-nva1121designpdf.pdf["NVA-1121"^] . abbiamo utilizzato il flag `--local-image` per i container non residenti nell'archivio pubblico dei docker. Abbiamo montato le directory `/mnt` e `/tmp` sul nodo host DGX-1 `/mnt` `/tmp` rispettivamente nel e nel container. Il dataset si trova in NetApp AFFA800 con l' `dataset_dir`argomento che punta alla directory. Entrambi `--num_devices=1` e `-g 1` significano che assegniamo una GPU per questo lavoro. Il primo è un argomento per `run.py` lo script, mentre il secondo è un indicatore per il `runai submit` comando.

La figura seguente mostra una dashboard panoramica del sistema con il 97% di utilizzo della GPU e tutte le sedici GPU disponibili allocate. È possibile visualizzare facilmente il numero di GPU allocate per ciascun team nel grafico a barre GPU/progetto. Il riquadro dei job in esecuzione mostra i nomi dei job in esecuzione, il progetto, l'utente, il tipo, il nodo, GPU consumate, tempo di esecuzione, avanzamento e dettagli di utilizzo. Un elenco dei workload in coda con il relativo tempo di attesa viene visualizzato in lavori in sospeso. Infine, la casella Nodes offre i numeri GPU e l'utilizzo per i singoli nodi DGX-1 nel cluster.

image:osrunai_image6.png["Figura che mostra la finestra di dialogo input/output o rappresenta il contenuto scritto"]
