---
sidebar: sidebar 
permalink: data-analytics/bda-ai-introduction.html 
keywords: tr-4732, tr4732, 4732, introduction, concepts, components 
summary: 'Questo documento fornisce linee guida per lo spostamento dei dati di analisi dei big data e dei dati HPC nell"ai utilizzando NetApp XCP e NIPAM. Discutiamo inoltre dei vantaggi per il business derivanti dal passaggio dei dati da big data e HPC all"ai.' 
---
= TR-4732: Dai dati di analisi dei big data all'intelligenza artificiale
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


Karthikeyan Nagalingam, NetApp

[role="lead"]
Questo documento descrive come spostare i dati di analisi dei big data e i dati HPC nell'ai. L'ai elabora i dati NFS attraverso le esportazioni NFS, mentre i clienti spesso dispongono dei propri dati ai in una piattaforma di analisi dei big data, come lo storage HDFS, Blob o S3, oltre a piattaforme HPC come GPFS. Questo documento fornisce linee guida per lo spostamento dei dati di analisi dei big data e dei dati HPC nell'ai utilizzando NetApp XCP e NIPAM. Discutiamo inoltre dei vantaggi per il business derivanti dal passaggio dei dati da big data e HPC all'ai.



== Concetti e componenti



=== Storage per l'analisi dei big data

L'analisi dei big data è il principale provider di storage per HDFS. Un cliente utilizza spesso un file system compatibile con Hadoop (HCFS) come Windows Azure Blob Storage, MapR file System (MapR-FS) e lo storage a oggetti S3.



=== File system parallelo generale

Il GPFS di IBM è un file system aziendale che offre un'alternativa a HDFS. LE GPF offrono alle applicazioni la flessibilità necessaria per decidere le dimensioni dei blocchi e il layout di replica, garantendo buone performance ed efficienza.



=== Modulo NetApp in-place Analytics

Il NetApp in-place Analytics Module (NIPAM) funge da driver per i cluster Hadoop per accedere ai dati NFS. Ha quattro componenti: Un pool di connessioni, un NFS InputStream, una cache di handle di file e un NFS OutputStream. Per ulteriori informazioni, vedere https://www.netapp.com/us/media/tr-4382.pdf["TR-4382: Modulo NetApp in-place Analytics."^]



=== Copia distribuita Hadoop

La copia distribuita di Hadoop (DistCp) è uno strumento di copia distribuita utilizzato per attività di coping tra cluster e intra-cluster di grandi dimensioni. Questo strumento utilizza MapReduce per la distribuzione dei dati, la gestione degli errori e il reporting. Espande l'elenco di file e directory e li inserisce per mappare le attività per copiare i dati dall'elenco di origine. L'immagine seguente mostra l'operazione DistCp in HDFS e non in HDFS.

image:bda-ai-image1.png["Errore: Immagine grafica mancante"]

Hadoop DistCp sposta i dati tra i due sistemi HDFS senza utilizzare un driver aggiuntivo. NetApp fornisce il driver per i sistemi non HDFS. Per una destinazione NFS, NIPAM fornisce il driver per copiare i dati utilizzati da Hadoop DistCp per comunicare con le destinazioni NFS durante la copia dei dati.



== NetApp Cloud Volumes Service

NetApp Cloud Volumes Service è un file service nativo del cloud con performance estreme. Questo servizio aiuta i clienti ad accelerare il time-to-market, aumentando e diminuendo rapidamente le risorse e utilizzando le funzionalità NetApp per migliorare la produttività e ridurre i tempi di inattività del personale. Cloud Volumes Service è la giusta alternativa per il disaster recovery e il backup nel cloud, in quanto riduce l'impatto complessivo del data center e consuma meno storage di cloud pubblico nativo.



== XCP di NetApp

NetApp XCP è un software client che consente una migrazione dei dati rapida e affidabile da qualsiasi a NetApp e da NetApp a NetApp. Questo tool è progettato per copiare una grande quantità di dati NAS non strutturati da qualsiasi sistema NAS a un controller di storage NetApp. XCP Migration Tool utilizza un motore di streaming i/o multicore e multicanale in grado di elaborare molte richieste in parallelo, ad esempio migrazione dei dati, elenchi di file o directory e report di spazio. Questo è il tool di migrazione dei dati NetApp predefinito. È possibile utilizzare XCP per copiare i dati da un cluster Hadoop e HPC allo storage NetApp NFS. Il diagramma seguente mostra il trasferimento dei dati da un cluster Hadoop e HPC a un volume NetApp NFS utilizzando XCP.

image:bda-ai-image2.png["Errore: Immagine grafica mancante"]



== Copia e sincronizzazione di NetApp BlueXP

NetApp BlueXP Copy and Sync è un software-as-a-service di replica dei dati ibridi che trasferisce e sincronizza i dati NFS, S3 e CIFS in modo perfetto e sicuro tra storage on-premise e cloud storage. Questo software viene utilizzato per la migrazione dei dati, l'archiviazione, la collaborazione, l'analisi e altro ancora. Una volta trasferiti i dati, BlueXP Copy e Sync sincronizza costantemente i dati tra origine e destinazione. In futuro, trasferisce il delta. Inoltre, protegge i dati all'interno della tua rete, nel cloud o on-premise. Questo software si basa su un modello pay-as-you-go, che fornisce una soluzione conveniente e offre funzionalità di monitoraggio e reporting per il trasferimento dei dati.
