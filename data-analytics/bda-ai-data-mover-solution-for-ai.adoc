---
sidebar: sidebar 
permalink: data-analytics/bda-ai-data-mover-solution-for-ai.html 
keywords: data mover, ai, hadoop, nipam, nfs, azure, 
summary: 'La soluzione data mover per l"ai si basa sulle esigenze dei clienti di elaborare i dati Hadoop dalle operazioni ai. NetApp trasferisce i dati da HDFS a NFS utilizzando NIPAM. In un caso d"utilizzo, il cliente aveva bisogno di spostare i dati on-premise in NFS e un altro cliente aveva bisogno di spostare i dati dalla BLOB di archiviazione di Windows Azure ai volumi di Google Cloud NetApp per elaborare i dati dalle istanze cloud della GPU nel cloud.' 
---
= Soluzione di data mover per l'ai
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
La soluzione data mover per l'ai si basa sulle esigenze dei clienti di elaborare i dati Hadoop dalle operazioni ai. NetApp trasferisce i dati da HDFS a NFS utilizzando NIPAM. In un caso d'utilizzo, il cliente aveva bisogno di spostare i dati on-premise in NFS e un altro cliente aveva bisogno di spostare i dati dalla BLOB di archiviazione di Windows Azure ai volumi di Google Cloud NetApp per elaborare i dati dalle istanze cloud della GPU nel cloud.

Il seguente diagramma illustra i dettagli della soluzione data mover.

image:bda-ai-image4.png["Figura che mostra la finestra di dialogo input/output o rappresenta il contenuto scritto"]

Per creare la soluzione di data mover sono necessari i seguenti passaggi:

. LA SAN ONTAP fornisce HDFS e il NAS fornisce il volume NFS tramite NIPAM al cluster di data Lake di produzione.
. I dati del cliente sono in HDFS e NFS. I dati NFS possono essere dati di produzione di altre applicazioni utilizzate per l'analisi dei big data e le operazioni ai.
. La tecnologia NetApp FlexClone crea un clone del volume NFS di produzione e lo fornisce al cluster ai on-premise.
. I dati di un LUN SAN HDFS vengono copiati in un volume NFS con NIPAM e il `hadoop distcp` comando. NIPAM utilizza la larghezza di banda di più interfacce di rete per trasferire i dati. Questo processo riduce i tempi di copia dei dati in modo che sia possibile trasferire più dati.
. Entrambi i volumi NFS vengono forniti al cluster ai per le operazioni ai.
. Per elaborare i dati NFS on-the-premise con GPU nel cloud, i volumi NFS vengono mirrorati su NetApp Private Storage (NPS) con la tecnologia NetApp SnapMirror e montati sui cloud service provider per GPU.
. Il cliente desidera elaborare i dati nei servizi EC2/EMR, HDInsight o DataProc nelle GPU dei provider di servizi cloud. Lo strumento di spostamento dei dati di Hadoop sposta i dati dai servizi Hadoop nei volumi Google Cloud NetApp con NIPAM e il `hadoop distcp` comando.
. I dati dei volumi Google Cloud NetApp vengono forniti ai tramite il protocollo NFS. I dati elaborati tramite ai possono essere inviati on-premise per le analisi dei big data oltre al cluster NVIDIA tramite NIPAM, SnapMirror e NPS.


In questo scenario, il cliente dispone di dati con un elevato numero di file nel sistema NAS in una posizione remota richiesta per l'elaborazione dell'ai sul controller di storage NetApp on-premise. In questo scenario, è meglio utilizzare XCP Migration Tool per migrare i dati a una velocità superiore.

Il cliente con caso d'utilizzo ibrido può utilizzare BlueXP Copy e Sync per migrare i dati on-premise dai dati NFS, CIFS e S3 nel cloud e viceversa per l'elaborazione ai utilizzando GPU come quelle in un cluster NVIDIA. Sia BlueXP Copy che Sync e lo strumento di migrazione XCP sono utilizzati per la migrazione dei dati NFS in NetApp ONTAP NFS.
